[{"url": "https://api.github.com/repos/scrapy/scrapy/issues/5878", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5878/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5878/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5878/events", "html_url": "https://github.com/scrapy/scrapy/issues/5878", "id": 1643133593, "node_id": "I_kwDOAAgUXs5h8DqZ", "number": 5878, "title": "Scrapy docs: 'make htmlview' does not work", "user": {"login": "jxlil", "id": 61639983, "node_id": "MDQ6VXNlcjYxNjM5OTgz", "avatar_url": "https://avatars.githubusercontent.com/u/61639983?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jxlil", "html_url": "https://github.com/jxlil", "followers_url": "https://api.github.com/users/jxlil/followers", "following_url": "https://api.github.com/users/jxlil/following{/other_user}", "gists_url": "https://api.github.com/users/jxlil/gists{/gist_id}", "starred_url": "https://api.github.com/users/jxlil/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jxlil/subscriptions", "organizations_url": "https://api.github.com/users/jxlil/orgs", "repos_url": "https://api.github.com/users/jxlil/repos", "events_url": "https://api.github.com/users/jxlil/events{/privacy}", "received_events_url": "https://api.github.com/users/jxlil/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "xt1033", "id": 48678550, "node_id": "MDQ6VXNlcjQ4Njc4NTUw", "avatar_url": "https://avatars.githubusercontent.com/u/48678550?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xt1033", "html_url": "https://github.com/xt1033", "followers_url": "https://api.github.com/users/xt1033/followers", "following_url": "https://api.github.com/users/xt1033/following{/other_user}", "gists_url": "https://api.github.com/users/xt1033/gists{/gist_id}", "starred_url": "https://api.github.com/users/xt1033/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xt1033/subscriptions", "organizations_url": "https://api.github.com/users/xt1033/orgs", "repos_url": "https://api.github.com/users/xt1033/repos", "events_url": "https://api.github.com/users/xt1033/events{/privacy}", "received_events_url": "https://api.github.com/users/xt1033/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "xt1033", "id": 48678550, "node_id": "MDQ6VXNlcjQ4Njc4NTUw", "avatar_url": "https://avatars.githubusercontent.com/u/48678550?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xt1033", "html_url": "https://github.com/xt1033", "followers_url": "https://api.github.com/users/xt1033/followers", "following_url": "https://api.github.com/users/xt1033/following{/other_user}", "gists_url": "https://api.github.com/users/xt1033/gists{/gist_id}", "starred_url": "https://api.github.com/users/xt1033/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xt1033/subscriptions", "organizations_url": "https://api.github.com/users/xt1033/orgs", "repos_url": "https://api.github.com/users/xt1033/repos", "events_url": "https://api.github.com/users/xt1033/events{/privacy}", "received_events_url": "https://api.github.com/users/xt1033/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2023-03-28T03:22:04Z", "updated_at": "2023-03-29T08:06:09Z", "closed_at": "2023-03-29T08:06:09Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\n`Path.resolve()` returns the `PosixPath` _class_ so it is not possible to concatenate it with a string.\r\n\r\n```\r\nwebbrowser.open('file://' + Path('build/html/index.html').resolve())\r\n```\r\n\r\n\r\n### Steps to Reproduce\r\n\r\n```\r\ncd docs/\r\nmake html\r\nmake htmlview\r\n```\r\n\r\n**Expected behavior:** \r\n\r\n`webbrowser` should open the file `build/html/index.html`\r\n\r\n**Actual behavior:**\r\n\r\nGet the following error when trying to open the file:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nTypeError: can only concatenate str (not \"PosixPath\") to str\r\n```\r\n\r\n### Versions\r\n\r\n`2.8.0`\r\n\r\n### Possible solution\r\n\r\nInstead of trying to concatenate the string `file://` we could use [`as_uri()`](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.as_uri). For example:\r\n\r\n```\r\nhtmlview: html\r\n\t $(PYTHON) -c \"import webbrowser; from pathlib import Path; \\\r\n\t webbrowser.open(Path('build/html/index.html').resolve().as_uri())\"\r\n```\r\n\r\n\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5878/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5878/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5875", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5875/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5875/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5875/events", "html_url": "https://github.com/scrapy/scrapy/issues/5875", "id": 1641908193, "node_id": "I_kwDOAAgUXs5h3Yfh", "number": 5875, "title": "Fix broken JavaScript reference in the docs", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2023-03-27T11:07:45Z", "updated_at": "2023-03-28T10:05:49Z", "closed_at": "2023-03-28T10:05:48Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "As @Laerte [pointed out](https://github.com/scrapy/scrapy/pull/5072#issuecomment-1483391283), https://github.com/scrapy/scrapy.org/issues/224 also applies to docs.scrapy.org, so changes are needed in this repository as well. ", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5875/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5875/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5874", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5874/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5874/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5874/events", "html_url": "https://github.com/scrapy/scrapy/issues/5874", "id": 1641425968, "node_id": "I_kwDOAAgUXs5h1iww", "number": 5874, "title": "Scrapy does not decode base64 MD5 checksum from GCS", "user": {"login": "namelessGonbai", "id": 43787036, "node_id": "MDQ6VXNlcjQzNzg3MDM2", "avatar_url": "https://avatars.githubusercontent.com/u/43787036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/namelessGonbai", "html_url": "https://github.com/namelessGonbai", "followers_url": "https://api.github.com/users/namelessGonbai/followers", "following_url": "https://api.github.com/users/namelessGonbai/following{/other_user}", "gists_url": "https://api.github.com/users/namelessGonbai/gists{/gist_id}", "starred_url": "https://api.github.com/users/namelessGonbai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/namelessGonbai/subscriptions", "organizations_url": "https://api.github.com/users/namelessGonbai/orgs", "repos_url": "https://api.github.com/users/namelessGonbai/repos", "events_url": "https://api.github.com/users/namelessGonbai/events{/privacy}", "received_events_url": "https://api.github.com/users/namelessGonbai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2023-03-27T05:55:22Z", "updated_at": "2023-04-11T16:25:43Z", "closed_at": "2023-04-11T16:25:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\nIncorrect GCS Checksum processing\r\n\r\n### Steps to Reproduce\r\n\r\n1. Obtain the checksum for an up-to-date file.\r\n\r\n**Expected behavior:** [What you expect to happen]\r\nmatches the checksum of the file downloaded\r\n**Actual behavior:** [What actually happens]\r\nNOT matches the checksum of the file downloaded\r\n**Reproduces how often:** [What percentage of the time does it reproduce?]\r\nAlways\r\n### Versions\r\ncurrent\r\n\r\n### Additional context\r\n\r\nhttps://cloud.google.com/storage/docs/json_api/v1/objects\r\n> MD5 hash of the data, encoded using [base64](https://datatracker.ietf.org/doc/html/rfc4648#section-4).\r\n\r\nBut, Scrapy dose not decode MD5 from GCS.\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5874/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5874/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5872", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5872/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5872/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5872/events", "html_url": "https://github.com/scrapy/scrapy/issues/5872", "id": 1640954849, "node_id": "I_kwDOAAgUXs5hzvvh", "number": 5872, "title": "get_func_args does not fully work in CPython", "user": {"login": "jelgun", "id": 5639662, "node_id": "MDQ6VXNlcjU2Mzk2NjI=", "avatar_url": "https://avatars.githubusercontent.com/u/5639662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jelgun", "html_url": "https://github.com/jelgun", "followers_url": "https://api.github.com/users/jelgun/followers", "following_url": "https://api.github.com/users/jelgun/following{/other_user}", "gists_url": "https://api.github.com/users/jelgun/gists{/gist_id}", "starred_url": "https://api.github.com/users/jelgun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jelgun/subscriptions", "organizations_url": "https://api.github.com/users/jelgun/orgs", "repos_url": "https://api.github.com/users/jelgun/repos", "events_url": "https://api.github.com/users/jelgun/events{/privacy}", "received_events_url": "https://api.github.com/users/jelgun/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "serhii73", "id": 24910277, "node_id": "MDQ6VXNlcjI0OTEwMjc3", "avatar_url": "https://avatars.githubusercontent.com/u/24910277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/serhii73", "html_url": "https://github.com/serhii73", "followers_url": "https://api.github.com/users/serhii73/followers", "following_url": "https://api.github.com/users/serhii73/following{/other_user}", "gists_url": "https://api.github.com/users/serhii73/gists{/gist_id}", "starred_url": "https://api.github.com/users/serhii73/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/serhii73/subscriptions", "organizations_url": "https://api.github.com/users/serhii73/orgs", "repos_url": "https://api.github.com/users/serhii73/repos", "events_url": "https://api.github.com/users/serhii73/events{/privacy}", "received_events_url": "https://api.github.com/users/serhii73/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "serhii73", "id": 24910277, "node_id": "MDQ6VXNlcjI0OTEwMjc3", "avatar_url": "https://avatars.githubusercontent.com/u/24910277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/serhii73", "html_url": "https://github.com/serhii73", "followers_url": "https://api.github.com/users/serhii73/followers", "following_url": "https://api.github.com/users/serhii73/following{/other_user}", "gists_url": "https://api.github.com/users/serhii73/gists{/gist_id}", "starred_url": "https://api.github.com/users/serhii73/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/serhii73/subscriptions", "organizations_url": "https://api.github.com/users/serhii73/orgs", "repos_url": "https://api.github.com/users/serhii73/repos", "events_url": "https://api.github.com/users/serhii73/events{/privacy}", "received_events_url": "https://api.github.com/users/serhii73/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2023-03-26T15:22:09Z", "updated_at": "2023-04-13T09:44:22Z", "closed_at": "2023-04-13T09:44:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "As [shown in tests](https://github.com/scrapy/scrapy/blob/ada917307844950a81226f020b596d5932187f6e/tests/test_utils_python.py#L240-L243), `get_func_args` does not work in CPython with inputs like `str.split`, `\"\".join` or `itemgetter(2)`.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5872/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5872/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5858", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5858/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5858/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5858/events", "html_url": "https://github.com/scrapy/scrapy/pull/5858", "id": 1639629011, "node_id": "PR_kwDOAAgUXs5M2Jhe", "number": 5858, "title": "Don't call SSL_get_server_tmp_key() if not available.", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-03-24T15:43:59Z", "updated_at": "2023-04-08T14:44:48Z", "closed_at": "2023-03-27T10:44:45Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5858", "html_url": "https://github.com/scrapy/scrapy/pull/5858", "diff_url": "https://github.com/scrapy/scrapy/pull/5858.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5858.patch", "merged_at": "2023-03-27T10:44:44Z"}, "body": "Fixes #5857 ", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5858/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5858/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5857", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5857/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5857/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5857/events", "html_url": "https://github.com/scrapy/scrapy/issues/5857", "id": 1639558997, "node_id": "I_kwDOAAgUXs5hua9V", "number": 5857, "title": "TLS logging broken with new cryptography", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 320345582, "node_id": "MDU6TGFiZWwzMjAzNDU1ODI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/https", "name": "https", "color": "101e89", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2023-03-24T15:01:33Z", "updated_at": "2023-04-13T13:46:12Z", "closed_at": "2023-03-27T10:44:46Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://github.com/pyca/cryptography/pull/8391 dropped `SSL_get_server_tmp_key()` so we need to disable the code that uses it if it's not available.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5857/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5857/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5831", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5831/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5831/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5831/events", "html_url": "https://github.com/scrapy/scrapy/issues/5831", "id": 1587141949, "node_id": "I_kwDOAAgUXs5emd09", "number": 5831, "title": "Asyncio event loop handling results in hang in scrapy shell with scrapy-playwright", "user": {"login": "auxsvr", "id": 1886353, "node_id": "MDQ6VXNlcjE4ODYzNTM=", "avatar_url": "https://avatars.githubusercontent.com/u/1886353?v=4", "gravatar_id": "", "url": "https://api.github.com/users/auxsvr", "html_url": "https://github.com/auxsvr", "followers_url": "https://api.github.com/users/auxsvr/followers", "following_url": "https://api.github.com/users/auxsvr/following{/other_user}", "gists_url": "https://api.github.com/users/auxsvr/gists{/gist_id}", "starred_url": "https://api.github.com/users/auxsvr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/auxsvr/subscriptions", "organizations_url": "https://api.github.com/users/auxsvr/orgs", "repos_url": "https://api.github.com/users/auxsvr/repos", "events_url": "https://api.github.com/users/auxsvr/events{/privacy}", "received_events_url": "https://api.github.com/users/auxsvr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 3270783977, "node_id": "MDU6TGFiZWwzMjcwNzgzOTc3", "url": "https://api.github.com/repos/scrapy/scrapy/labels/asyncio", "name": "asyncio", "color": "fef2c0", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2023-02-16T07:04:15Z", "updated_at": "2023-03-14T08:31:15Z", "closed_at": "2023-03-14T08:31:15Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\nIf one attempts to use scrapy-playwright with scrapy shell, simply doing a `fetch` results in a hang.\r\n\r\n### Steps to Reproduce\r\n\r\n1. install scrapy-playwright,\r\n2. launch scrapy shell with the `AsyncioSelectorReactor`,\r\n3. run `fetch('https://www.google.com', meta={'playwright': True, 'playwright_include_page': True})`\r\n\r\n**Expected behavior:** \r\nThe request should be handled by scrapy-playwright and result in a response.\r\n\r\n**Actual behavior:** \r\nThe request is blocked soon after the second thread is created, right before the browser page is created. The traceback with Ctrl-C shows that execution is blocked in `blockingCallFromThread`. On closing the shell, the error message:\r\n\r\n> asyncio: Task was destroyed but it is pending!\r\n> task: <Task pending name='Task-163' coro=<ScrapyPlaywrightDownloadHandler._download_request() running at /home/petros/.local/lib/python3.10/site-packages/scrapy_playwright/handler.py:272> cb=[Deferred.fromFuture.<locals>.adapt() at /usr/lib/python3.10/site-packages/twisted/internet/defer.py:1063]>\r\n\r\nappears.\r\n\r\n**Reproduces how often:**\r\nAlways.\r\n\r\n### Versions\r\nScrapy       : 2.8.0\r\nlxml         : 4.9.2.0\r\nlibxml2      : 2.9.14\r\ncssselect    : 1.2.0\r\nparsel       : 1.7.0\r\nw3lib        : 1.22.0\r\nTwisted      : 22.10.0\r\nPython       : 3.10.9 (main, Dec 08 2022, 14:49:06) [GCC]\r\npyOpenSSL    : 23.0.0 (OpenSSL 3.0.7 1 Nov 2022)\r\ncryptography : 39.0.1\r\nPlatform     : Linux-6.1.8-1-default-x86_64-with-glibc2.36\r\n### Additional context\r\nThere is a long thread about the root cause in https://discord.com/channels/851364676688543744/1073689007927590932. The summary is that `set_asyncio_event_loop` seems to have the following issues:\r\n\r\n1. it uses `get_asyncio_event_loop_policy().get_event_loop()`, which results in the edge case described in https://github.com/python/cpython/issues/96377#issuecomment-1260006538, namely `set_asyncio_event_loop` creates an event loop, even though another already exists.\r\n2. it uses `asyncio.get_event_loop_policy()`, which will probably be deprecated, according to https://github.com/python/cpython/issues/96377#issuecomment-1258819222.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5831/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5831/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5826", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5826/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5826/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5826/events", "html_url": "https://github.com/scrapy/scrapy/pull/5826", "id": 1571402168, "node_id": "PR_kwDOAAgUXs5JR4Ez", "number": 5826, "title": "Skip/fix failing code block tests.", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2023-02-05T12:02:37Z", "updated_at": "2023-02-23T20:41:43Z", "closed_at": "2023-02-14T08:40:38Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5826", "html_url": "https://github.com/scrapy/scrapy/pull/5826", "diff_url": "https://github.com/scrapy/scrapy/pull/5826.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5826.patch", "merged_at": "2023-02-14T08:40:38Z"}, "body": "Fixes #5825, related to #5816", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5826/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5826/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5825", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5825/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5825/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5825/events", "html_url": "https://github.com/scrapy/scrapy/issues/5825", "id": 1571118015, "node_id": "I_kwDOAAgUXs5dpVu_", "number": 5825, "title": "Tests fail/hang after merging #5816", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2023-02-04T20:42:58Z", "updated_at": "2023-02-14T08:40:40Z", "closed_at": "2023-02-14T08:40:40Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Some of the doc tests fail after merging #5816, and the test for `docs/topics/practices.rst` hangs.\r\n\r\nI feel like it's because much more code is now marked as Python and some of that code doesn't work or hangs.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5825/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5825/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5819", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5819/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5819/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5819/events", "html_url": "https://github.com/scrapy/scrapy/issues/5819", "id": 1564133870, "node_id": "I_kwDOAAgUXs5dOsnu", "number": 5819, "title": "Scrapy parse doesn't support async callbacks with yield", "user": {"login": "GKukulski", "id": 82433489, "node_id": "MDQ6VXNlcjgyNDMzNDg5", "avatar_url": "https://avatars.githubusercontent.com/u/82433489?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GKukulski", "html_url": "https://github.com/GKukulski", "followers_url": "https://api.github.com/users/GKukulski/followers", "following_url": "https://api.github.com/users/GKukulski/following{/other_user}", "gists_url": "https://api.github.com/users/GKukulski/gists{/gist_id}", "starred_url": "https://api.github.com/users/GKukulski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GKukulski/subscriptions", "organizations_url": "https://api.github.com/users/GKukulski/orgs", "repos_url": "https://api.github.com/users/GKukulski/repos", "events_url": "https://api.github.com/users/GKukulski/events{/privacy}", "received_events_url": "https://api.github.com/users/GKukulski/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 3270783977, "node_id": "MDU6TGFiZWwzMjcwNzgzOTc3", "url": "https://api.github.com/repos/scrapy/scrapy/labels/asyncio", "name": "asyncio", "color": "fef2c0", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2023-01-31T11:28:32Z", "updated_at": "2023-03-10T15:20:17Z", "closed_at": "2023-03-10T15:20:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "When running `scrapy parse http://localhost:8080 -c parse --spider test` is rising error: `TypeError: 'async_generator' object is not iterable`. \r\n\r\nSimple Code of Spider:\r\n```\r\nimport scrapy\r\n\r\nclass TestSpider(scrapy.Spider):\r\n    name = 'test'\r\n    allowed_domains = ['localhost']\r\n    start_urls = ['http://localhost:8080']\r\n\r\n    async def parse(self, response):\r\n        for x in range(1, 5):\r\n            yield ({\"test\": x})\r\n```\r\n\r\nIt is happened when there is `yield` inside `async function`.\r\n\r\n`scrapy crawl test` - works fine", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5819/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5819/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5811", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5811/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5811/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5811/events", "html_url": "https://github.com/scrapy/scrapy/issues/5811", "id": 1560587135, "node_id": "I_kwDOAAgUXs5dBKt_", "number": 5811, "title": "`BaseSettings.setdefault` does nothing", "user": {"login": "Prometheus3375", "id": 35541026, "node_id": "MDQ6VXNlcjM1NTQxMDI2", "avatar_url": "https://avatars.githubusercontent.com/u/35541026?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Prometheus3375", "html_url": "https://github.com/Prometheus3375", "followers_url": "https://api.github.com/users/Prometheus3375/followers", "following_url": "https://api.github.com/users/Prometheus3375/following{/other_user}", "gists_url": "https://api.github.com/users/Prometheus3375/gists{/gist_id}", "starred_url": "https://api.github.com/users/Prometheus3375/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Prometheus3375/subscriptions", "organizations_url": "https://api.github.com/users/Prometheus3375/orgs", "repos_url": "https://api.github.com/users/Prometheus3375/repos", "events_url": "https://api.github.com/users/Prometheus3375/events{/privacy}", "received_events_url": "https://api.github.com/users/Prometheus3375/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2023-01-28T00:18:46Z", "updated_at": "2023-04-12T15:55:07Z", "closed_at": "2023-03-07T09:27:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nCalling `setdefault` method of class `BaseSettings` does nothing.\r\n\r\n### Steps to Reproduce\r\n\r\n ```python\r\n from scrapy.settings import BaseSettings\r\n settings = BaseSettings()\r\n stored = settings.setdefault('key', 'value')\r\n print(stored)  # prints None\r\n print(settings.copy_to_dict())  # prints empty dictionary\r\n ```\r\n\r\n**Expected behavior:**\r\n`settings.setdefault(key, default)` must work as described in `MutableMapping` interface: set `default` to `settings[key]` and return `default` if `key` is not present, otherwise return `settings[key]`.\r\n\r\n**Actual behavior:**\r\n`settings.setdefault(key, default)` does nothing regardless of holding `key` or not.\r\n\r\n**Reproduces how often:** 100%\r\n\r\n### Versions\r\n\r\nScrapy       : 2.7.1\r\nlxml         : 4.8.0.0\r\nlibxml2      : 2.9.12\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 22.4.0\r\nPython       : 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]\r\npyOpenSSL    : 22.0.0 (OpenSSL 3.0.3 3 May 2022)\r\ncryptography : 37.0.2\r\nPlatform     : Windows-10-10.0.19044-SP0\r\n\r\n\r\n### Additional context\r\n\r\n`BaseSettings` explicitly inherits from `MutableMapping` and does not redefine `setdefault` method. Thus, it uses base implementation:\r\n```python\r\ndef setdefault(self, key, default=None):\r\n    'D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D'\r\n    try:\r\n        return self[key]\r\n    except KeyError:\r\n        self[key] = default\r\n    return default\r\n```\r\nBase implementation refers to `self[key]` which is in fact `self.__getitem__[key]`. `BaseSettings` has own `__getitem__` implementation:\r\n```python\r\ndef __getitem__(self, opt_name):\r\n    if opt_name not in self:\r\n        return None\r\n    return self.attributes[opt_name].value\r\n```\r\nAnd here is the root of the problem: when passed `key` is not present, `__getitem__` returns `None`, and `setdefault` follows.\r\n\r\n**Solution**\r\nImplement own `setdefault` method. An example with matching signature:\r\n```python\r\ndef setdefault(self, opt_name, default=None):\r\n    if opt_name not in self:\r\n        self.set(opt_name, default)\r\n        return default\r\n    return self.attributes[opt_name].value\r\n```\r\n`priority='project'` argument can be added although this changes signature.\r\n\r\nOther way is to inherit from `Mapping` instead of `MutableMapping` if this method and other base methods are redundant.\r\n\r\n**Current workaround**\r\nConvert `BaseSettings` object to a dictionary and only then use `setdefault`.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5811/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5811/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5785", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5785/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5785/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5785/events", "html_url": "https://github.com/scrapy/scrapy/issues/5785", "id": 1522648480, "node_id": "I_kwDOAAgUXs5awcWg", "number": 5785, "title": "pypy3-pinned OpenSSL error", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2023-01-06T14:08:19Z", "updated_at": "2023-01-07T19:48:41Z", "closed_at": "2023-01-07T19:48:41Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Yet another CI issue, visible in https://github.com/scrapy/scrapy/actions/runs/3849823417/jobs/6559259481\r\n\r\n> /home/runner/work/scrapy/scrapy/.tox/pypy3-pinned/site-packages/cryptography/hazmat/bindings/_openssl.pypy37-pp73-x86_64-linux-gnu.so: undefined symbol: FIPS_mode\r\n\r\nThis may be a problem with that specific binary distribution (it's `cryptography==3.3`), not sure why it worked before, maybe something was rebuilt recently. ", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5785/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5785/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5765", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5765/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5765/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5765/events", "html_url": "https://github.com/scrapy/scrapy/issues/5765", "id": 1502536168, "node_id": "I_kwDOAAgUXs5ZjuHo", "number": 5765, "title": "AsyncioTest failures", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}, {"id": 3270783977, "node_id": "MDU6TGFiZWwzMjcwNzgzOTc3", "url": "https://api.github.com/repos/scrapy/scrapy/labels/asyncio", "name": "asyncio", "color": "fef2c0", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/41", "html_url": "https://github.com/scrapy/scrapy/milestone/41", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/41/labels", "id": 8583553, "node_id": "MI_kwDOAAgUXs4AgvmB", "number": 41, "title": "Scrapy 2.8", "description": "", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 11, "state": "closed", "created_at": "2022-10-26T14:59:30Z", "updated_at": "2023-02-02T09:08:31Z", "due_on": null, "closed_at": "2023-02-02T09:08:31Z"}, "comments": 1, "created_at": "2022-12-19T08:42:09Z", "updated_at": "2023-01-06T18:51:09Z", "closed_at": "2023-01-06T18:51:09Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "There are two new failing tests (`AsyncioTest.test_install_asyncio_reactor` and `AsyncioTest.test_is_asyncio_reactor_installed`) on 3.10 and 3.11, and it looks like they started failing after updating to 3.10.9 and 3.11.1 (it may be a coincidence though). I see an asyncio-related change in those versions: \"asyncio.get_event_loop() now only emits a deprecation warning when a new event loop was created implicitly. It no longer emits a deprecation warning if the current event loop was set.\" and it looks like it's the cause for the `test_install_asyncio_reactor` failure as that checks for a warning and maybe there is some new warning. But the second test is about installing the reactor and checking its type and the failure looks like the asyncio reactor is installed when it shouldn't.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5765/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5765/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5762", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5762/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5762/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5762/events", "html_url": "https://github.com/scrapy/scrapy/issues/5762", "id": 1498547868, "node_id": "I_kwDOAAgUXs5ZUgac", "number": 5762, "title": "reppy problems in CI", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/41", "html_url": "https://github.com/scrapy/scrapy/milestone/41", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/41/labels", "id": 8583553, "node_id": "MI_kwDOAAgUXs4AgvmB", "number": 41, "title": "Scrapy 2.8", "description": "", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 11, "state": "closed", "created_at": "2022-10-26T14:59:30Z", "updated_at": "2023-02-02T09:08:31Z", "due_on": null, "closed_at": "2023-02-02T09:08:31Z"}, "comments": 0, "created_at": "2022-12-15T14:32:47Z", "updated_at": "2023-01-02T15:13:46Z", "closed_at": "2023-01-02T15:13:46Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "As initially mentioned in #5749 we have `reppy` compilation failures in the envs that install it (`pylint` and `extra-deps`), breaking actions for those envs. We discussed reppy installation problems in #5230, and the gcc issue linked there matches the error on our CI. It's quite possible than the only way forward is not installing reppy on CI anymore, even if we don't want to deprecate it now.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5762/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5762/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5750", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5750/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5750/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5750/events", "html_url": "https://github.com/scrapy/scrapy/issues/5750", "id": 1486783618, "node_id": "I_kwDOAAgUXs5YnoSC", "number": 5750, "title": "test_follow_whitespace_* tests broken by new w3lib", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-12-09T13:41:40Z", "updated_at": "2022-12-12T18:49:25Z", "closed_at": "2022-12-12T18:49:25Z", "author_association": "MEMBER", "active_lock_reason": null, "body": null, "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5750/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5750/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5749", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5749/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5749/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5749/events", "html_url": "https://github.com/scrapy/scrapy/issues/5749", "id": 1486198273, "node_id": "I_kwDOAAgUXs5YlZYB", "number": 5749, "title": "Fix CI for the tox 4.0 changes", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/41", "html_url": "https://github.com/scrapy/scrapy/milestone/41", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/41/labels", "id": 8583553, "node_id": "MI_kwDOAAgUXs4AgvmB", "number": 41, "title": "Scrapy 2.8", "description": "", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 11, "state": "closed", "created_at": "2022-10-26T14:59:30Z", "updated_at": "2023-02-02T09:08:31Z", "due_on": null, "closed_at": "2023-02-02T09:08:31Z"}, "comments": 2, "created_at": "2022-12-09T07:17:29Z", "updated_at": "2023-01-06T18:53:21Z", "closed_at": "2023-01-06T18:53:21Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Looks like tox 4 broke several tests: [`docs` fails because it now runs pytest instead of sphinx-build](https://github.com/wRAR/scrapy/actions/runs/3655201285/jobs/6176311198) and [the `*pinned` actions fail because they apparently install newer Twisted](https://github.com/wRAR/scrapy/actions/runs/3655201280/jobs/6176311274) (and maybe newer versions for other pinned packages but we don't check those).\r\n\r\nThe changes are described at https://tox.wiki/en/latest/faq.html , though I don't see any obvious reasons there. \r\n\r\nAlso, the pylint and extra-deps actions now fail to build reppy, which is probably unrelated and may need a separate issue created.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5749/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5749/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5744", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5744/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5744/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5744/events", "html_url": "https://github.com/scrapy/scrapy/pull/5744", "id": 1474051760, "node_id": "PR_kwDOAAgUXs5ENKll", "number": 5744, "title": "Fix the name of the Proxy-Authorization header in release notes", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-12-03T14:08:12Z", "updated_at": "2023-04-08T14:44:48Z", "closed_at": "2022-12-05T10:44:40Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5744", "html_url": "https://github.com/scrapy/scrapy/pull/5744", "diff_url": "https://github.com/scrapy/scrapy/pull/5744.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5744.patch", "merged_at": "2022-12-05T10:44:40Z"}, "body": null, "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5744/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5744/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5740", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5740/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5740/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5740/events", "html_url": "https://github.com/scrapy/scrapy/issues/5740", "id": 1468521819, "node_id": "I_kwDOAAgUXs5Xh91b", "number": 5740, "title": "asyncio exception in scrapy shell", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 281088273, "node_id": "MDU6TGFiZWwyODEwODgyNzM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/help%20wanted", "name": "help wanted", "color": "009800", "default": true, "description": null}, {"id": 318523681, "node_id": "MDU6TGFiZWwzMTg1MjM2ODE=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/Windows", "name": "Windows", "color": "fad8c7", "default": false, "description": null}, {"id": 3270783977, "node_id": "MDU6TGFiZWwzMjcwNzgzOTc3", "url": "https://api.github.com/repos/scrapy/scrapy/labels/asyncio", "name": "asyncio", "color": "fef2c0", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/41", "html_url": "https://github.com/scrapy/scrapy/milestone/41", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/41/labels", "id": 8583553, "node_id": "MI_kwDOAAgUXs4AgvmB", "number": 41, "title": "Scrapy 2.8", "description": "", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 11, "state": "closed", "created_at": "2022-10-26T14:59:30Z", "updated_at": "2023-02-02T09:08:31Z", "due_on": null, "closed_at": "2023-02-02T09:08:31Z"}, "comments": 3, "created_at": "2022-11-29T18:32:23Z", "updated_at": "2023-01-25T10:40:57Z", "closed_at": "2022-12-15T05:22:02Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "We got a bug report that using `fetch(<url>)` in `scrapy shell` on Windows in a new project (so with `TWISTED_REACTOR` set to the asyncio one) raises \"There is no current event loop\" in `deferred_from_coro()`. The Python version is 3.9 and 3.10 and the Scrapy version is 2.7.1. It is possible that the recenty changed loop code indeed doesn't work correctly on Windows but I cannot test or fix it at this time.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5740/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5740/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5709", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5709/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5709/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5709/events", "html_url": "https://github.com/scrapy/scrapy/issues/5709", "id": 1441742052, "node_id": "I_kwDOAAgUXs5V7zzk", "number": 5709, "title": "scrapy -h outputs a stray \"commands\"", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-11-09T09:31:44Z", "updated_at": "2022-11-10T14:38:48Z", "closed_at": "2022-11-10T14:38:48Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "When I run `scrapy -h` in a project on all Scrapy versions starting with 2.1, I get:\r\n\r\n```\r\n[...]\r\nAvailable commands:\r\n  bench         Run quick benchmark test\r\n  check         Check spider contracts\r\n  **commands**      \r\n  crawl         Run a spider\r\n  edit          Edit spider\r\n  fetch         Fetch a URL using the Scrapy downloader\r\n[...]\r\n```\r\n\r\nThe stray line is not present on older versions. I haven't found its source but it should be easy I think. The list of commands is collected in `scrapy.cmdline._get_commands_dict()` and printed by `scrapy.cmdline._print_commands()`.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5709/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5709/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5688", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5688/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5688/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5688/events", "html_url": "https://github.com/scrapy/scrapy/pull/5688", "id": 1418407429, "node_id": "PR_kwDOAAgUXs5BSkwS", "number": 5688, "title": "Fix the flake8 per-file ignore syntax.", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}, {"id": 545314542, "node_id": "MDU6TGFiZWw1NDUzMTQ1NDI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/cleanup", "name": "cleanup", "color": "1d76db", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/42", "html_url": "https://github.com/scrapy/scrapy/milestone/42", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/42/labels", "id": 8585170, "node_id": "MI_kwDOAAgUXs4Agv_S", "number": 42, "title": "Scrapy 2.7.1", "description": "", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 9, "state": "closed", "created_at": "2022-10-26T20:08:49Z", "updated_at": "2022-11-22T17:25:51Z", "due_on": null, "closed_at": "2022-11-22T17:25:51Z"}, "comments": 0, "created_at": "2022-10-21T14:13:28Z", "updated_at": "2022-10-26T20:24:53Z", "closed_at": "2022-10-21T14:17:04Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5688", "html_url": "https://github.com/scrapy/scrapy/pull/5688", "diff_url": "https://github.com/scrapy/scrapy/pull/5688.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5688.patch", "merged_at": "2022-10-21T14:17:04Z"}, "body": null, "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5688/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5688/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5685", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5685/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5685/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5685/events", "html_url": "https://github.com/scrapy/scrapy/issues/5685", "id": 1416108887, "node_id": "I_kwDOAAgUXs5UaBtX", "number": 5685, "title": "DeprecationWarning: There is no current event loop", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 545314542, "node_id": "MDU6TGFiZWw1NDUzMTQ1NDI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/cleanup", "name": "cleanup", "color": "1d76db", "default": false, "description": null}, {"id": 3270783977, "node_id": "MDU6TGFiZWwzMjcwNzgzOTc3", "url": "https://api.github.com/repos/scrapy/scrapy/labels/asyncio", "name": "asyncio", "color": "fef2c0", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2022-10-20T07:25:25Z", "updated_at": "2022-10-27T12:02:13Z", "closed_at": "2022-10-27T12:02:13Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\r\n/home/runner/work/scrapy/scrapy/scrapy/utils/reactor.py:70: DeprecationWarning: There is no current event loop\r\n  event_loop = asyncio.get_event_loop()\r\ntests/test_downloadermiddleware.py: 2 warnings\r\ntests/test_utils_asyncgen.py: 2 warnings\r\ntests/test_utils_defer.py: 4 warnings\r\ntests/test_utils_python.py: 2 warnings\r\ntests/test_utils_signal.py: 2 warnings\r\n  /home/runner/work/scrapy/scrapy/scrapy/utils/defer.py:272: DeprecationWarning: There is no current event loop\r\n    return Deferred.fromFuture(asyncio.ensure_future(o))\r\ntests/test_utils_asyncio.py::AsyncioTest::test_install_asyncio_reactor\r\n  /home/runner/work/scrapy/scrapy/scrapy/utils/reactor.py:70: DeprecationWarning: There is no current event loop\r\n    event_loop = asyncio.get_event_loop()\r\n```\r\n\r\nNot sure yet what does this imply and when can this break (this is from tests on 3.10 and 3.11).", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5685/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5685/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5612", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5612/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5612/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5612/events", "html_url": "https://github.com/scrapy/scrapy/issues/5612", "id": 1353805024, "node_id": "I_kwDOAAgUXs5QsWzg", "number": 5612, "title": "A test fails with new w3lib", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-08-29T07:02:15Z", "updated_at": "2022-09-07T07:58:12Z", "closed_at": "2022-09-07T07:58:12Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "`tests/test_spider.py::CrawlSpiderTest::test_process_request_instance_method` requires the host in the URL to keep uppercase which no longer happens because of https://github.com/scrapy/w3lib/issues/188 (which I don't consider to be a bug, and which could happen in any other place that uses `urlsplit`).", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5612/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5612/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5602", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5602/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5602/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5602/events", "html_url": "https://github.com/scrapy/scrapy/issues/5602", "id": 1342577972, "node_id": "I_kwDOAAgUXs5QBh00", "number": 5602, "title": "Clarify the return type of callbacks", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-08-18T05:28:21Z", "updated_at": "2022-10-02T19:19:09Z", "closed_at": "2022-10-02T19:19:09Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://docs.scrapy.org/en/latest/topics/spiders.html#scrapy.Spider.parse says \"This method, as well as any other Request callback, must return an iterable of Request and/or item objects.\", but it can also return a single Request/an item object. It's possible there are other places with a similar omission.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5602/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5602/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5553", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5553/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5553/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5553/events", "html_url": "https://github.com/scrapy/scrapy/pull/5553", "id": 1301880408, "node_id": "PR_kwDOAAgUXs47QTAk", "number": 5553, "title": "Fix doc: `scrapy.exporter` to `scrapy.exporters`", "user": {"login": "Rotzbua", "id": 7337347, "node_id": "MDQ6VXNlcjczMzczNDc=", "avatar_url": "https://avatars.githubusercontent.com/u/7337347?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Rotzbua", "html_url": "https://github.com/Rotzbua", "followers_url": "https://api.github.com/users/Rotzbua/followers", "following_url": "https://api.github.com/users/Rotzbua/following{/other_user}", "gists_url": "https://api.github.com/users/Rotzbua/gists{/gist_id}", "starred_url": "https://api.github.com/users/Rotzbua/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Rotzbua/subscriptions", "organizations_url": "https://api.github.com/users/Rotzbua/orgs", "repos_url": "https://api.github.com/users/Rotzbua/repos", "events_url": "https://api.github.com/users/Rotzbua/events{/privacy}", "received_events_url": "https://api.github.com/users/Rotzbua/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-07-12T10:46:35Z", "updated_at": "2022-07-17T22:11:47Z", "closed_at": "2022-07-16T19:21:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5553", "html_url": "https://github.com/scrapy/scrapy/pull/5553", "diff_url": "https://github.com/scrapy/scrapy/pull/5553.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5553.patch", "merged_at": "2022-07-16T19:21:50Z"}, "body": "Fix the import in the example.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5553/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5553/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5515", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5515/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5515/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5515/events", "html_url": "https://github.com/scrapy/scrapy/issues/5515", "id": 1261712400, "node_id": "I_kwDOAAgUXs5LNDQQ", "number": 5515, "title": "Response.headers loses data on multiple values", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-06-06T11:25:01Z", "updated_at": "2022-06-27T18:03:01Z", "closed_at": "2022-06-27T18:03:01Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://github.com/scrapy/scrapy/issues/1262 reported that by default `response.headers` would only expose the first value of a header e.g. when casted as a `dict`, acknowledging that `response.headers.getlist` could be used instead to get all values.\r\n\r\nI have just found out that the latter is not true:\r\n\r\n```python\r\n>>> from scrapy.http import Response\r\n>>> response = Response(\"https://example.com\", headers=((\"a\", \"b\"), (\"a\", \"c\")))\r\n>>> response.headers.getlist(\"a\")\r\n[b'c']\r\n```\r\n\r\nI could verify the issue happening as far back as Scrapy 1.6, so it does not look like a recent bug.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5515/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5515/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5500", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5500/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5500/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5500/events", "html_url": "https://github.com/scrapy/scrapy/issues/5500", "id": 1235843669, "node_id": "I_kwDOAAgUXs5JqXpV", "number": 5500, "title": "Postprocessing feeds do not work for S3 feed storage", "user": {"login": "Nykakin", "id": 7022873, "node_id": "MDQ6VXNlcjcwMjI4NzM=", "avatar_url": "https://avatars.githubusercontent.com/u/7022873?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Nykakin", "html_url": "https://github.com/Nykakin", "followers_url": "https://api.github.com/users/Nykakin/followers", "following_url": "https://api.github.com/users/Nykakin/following{/other_user}", "gists_url": "https://api.github.com/users/Nykakin/gists{/gist_id}", "starred_url": "https://api.github.com/users/Nykakin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Nykakin/subscriptions", "organizations_url": "https://api.github.com/users/Nykakin/orgs", "repos_url": "https://api.github.com/users/Nykakin/repos", "events_url": "https://api.github.com/users/Nykakin/events{/privacy}", "received_events_url": "https://api.github.com/users/Nykakin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-05-14T02:59:10Z", "updated_at": "2023-04-11T11:06:14Z", "closed_at": "2023-04-11T11:06:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\nExample settings:\r\n```\r\nFEEDS = {\r\n    \"s3://base/file_%(batch_id)05d.gz\": {\r\n        \"format\": \"csv\",\r\n        \"postprocessing\": [GzipPlugin],\r\n        \"gzip_compresslevel\": 5,\r\n    },\r\n}\r\nFEED_EXPORT_BATCH_ITEM_COUNT = 50000\r\n```\r\nThis causes an exception:\r\n\r\n```python\r\n2022-05-14 01:02:12 [scrapy.extensions.feedexport] ERROR: Error storing csv feed (15 items) in: s3://base/file_00001.gz\r\nTraceback (most recent call last):\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/twisted/python/threadpool.py\", line 244, in inContext\r\n    result = inContext.theWork()  # type: ignore[attr-defined]\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/twisted/python/threadpool.py\", line 260, in <lambda>\r\n    inContext.theWork = lambda: context.call(  # type: ignore[attr-defined]\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/twisted/python/context.py\", line 117, in callWithContext\r\n    return self.currentContext().callWithContext(ctx, func, *args, **kw)\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/twisted/python/context.py\", line 82, in callWithContext\r\n    return func(*args, **kw)\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/scrapy/extensions/feedexport.py\", line 194, in _store_in_thread\r\n    file.seek(0)\r\nio.UnsupportedOperation: seek\r\n```\r\nApparently `scrapy.extensions.postprocessing.PostProcessingManager` doesn't fully implement file protocol. Adding this method to the class:\r\n```python\r\n    def seek(self, offset, whence=SEEK_SET):\r\n        return self.file.seek(offset, whence)\r\n```\r\nCause an exception in a different place:\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/twisted/python/threadpool.py\", line 244, in inContext\r\n    result = inContext.theWork()  # type: ignore[attr-defined]\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/twisted/python/threadpool.py\", line 260, in <lambda>\r\n    inContext.theWork = lambda: context.call(  # type: ignore[attr-defined]\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/twisted/python/context.py\", line 117, in callWithContext\r\n    return self.currentContext().callWithContext(ctx, func, *args, **kw)\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/twisted/python/context.py\", line 82, in callWithContext\r\n    return func(*args, **kw)\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/scrapy/extensions/feedexport.py\", line 196, in _store_in_thread\r\n    self.s3_client.put_object(\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/botocore/client.py\", line 395, in _api_call\r\n    return self._make_api_call(operation_name, kwargs)\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/botocore/client.py\", line 695, in _make_api_call\r\n    request_dict = self._convert_to_request_dict(\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/botocore/client.py\", line 745, in _convert_to_request_dict\r\n    request_dict = self._serializer.serialize_to_request(\r\n  File \"/home/mariusz/Documents/Praca/venv_wgsn/lib/python3.10/site-packages/botocore/validate.py\", line 360, in serialize_to_request\r\n    raise ParamValidationError(report=report.generate_report())\r\nbotocore.exceptions.ParamValidationError: Parameter validation failed:\r\nInvalid type for parameter Body, value: <scrapy.extensions.postprocessing.PostProcessingManager object at 0x7f1f245c6920>, type: <class 'scrapy.extensions.postprocessing.PostProcessingManager'>, valid types: <class 'bytes'>, <class 'bytearray'>, file-like object\r\n```\r\nApparently `boto` excepts a `read()` method to be present as well ([here](https://github.com/boto/botocore/blob/develop/botocore/validate.py#L320-L332)).\r\n\r\nTried to add `read()` method to `scrapy.extensions.postprocessing.PostProcessingManager` as well but I only received an incomplete file. I think it's possible because `gzip.GzipFile` use some buffering so it only save full file when `close()` is called on it. Since `S3FeedStorage` uses internally `tempfile.NamedTemporaryFile`, this cause the file to disappear right after creation.\r\n\r\n`PostProcessingManager` needs to be refactored so it can handle `BlockingFeedStorage` correctly.\r\n\r\n### Versions\r\n\r\n```\r\n$ scrapy version --verbose\r\nScrapy       : 2.6.1\r\nlxml         : 4.8.0.0\r\nlibxml2      : 2.9.12\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 22.2.0\r\nPython       : 3.10.4 (main, May 11 2022, 11:41:05) [GCC 11.0.1 20210417 (experimental) [master revision c1c86ab96c2:b6fb0ccbb48:8ae\r\npyOpenSSL    : 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021)\r\ncryptography : 36.0.1\r\nPlatform     : Linux-5.11.0-16-generic-x86_64-with-glibc2.33\r\n```\r\n\r\n### Additional context", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5500/reactions", "total_count": 4, "+1": 4, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5500/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5464", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5464/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5464/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5464/events", "html_url": "https://github.com/scrapy/scrapy/issues/5464", "id": 1193092740, "node_id": "I_kwDOAAgUXs5HHSaE", "number": 5464, "title": "2.6 introduced an undocumented field rename in request serialization", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/40", "html_url": "https://github.com/scrapy/scrapy/milestone/40", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/40/labels", "id": 7735764, "node_id": "MI_kwDOAAgUXs4AdgnU", "number": 40, "title": "2.6.2", "description": "Address regressions introduced in 2.6.", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 10, "state": "closed", "created_at": "2022-03-04T09:09:55Z", "updated_at": "2022-07-25T12:59:19Z", "due_on": "2022-04-27T07:00:00Z", "closed_at": "2022-07-25T12:59:19Z"}, "comments": 4, "created_at": "2022-04-05T12:38:17Z", "updated_at": "2022-04-13T17:17:44Z", "closed_at": "2022-04-13T17:17:44Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "After https://github.com/scrapy/scrapy/pull/5130 the `_encoding` field of serialized requests is now named `encoding`, which is a backward-incompatible change not covered in the release notes.\r\n\r\nWe should either update the release notes or revert that change in the 2.6 branch.\r\n\r\n I found out about this is a scenario where the change turned out to break some tests. But given the change seems for the better (that was the only field prefixed with `_`), I think it may be better to keep the change and simply mention it in the 2.6 release notes for completeness.\r\n\r\nI have no strong opinion either way, though.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5464/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5464/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5459", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5459/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5459/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5459/events", "html_url": "https://github.com/scrapy/scrapy/pull/5459", "id": 1180523826, "node_id": "PR_kwDOAAgUXs41AO7k", "number": 5459, "title": "Pin mitmproxy to < 8 for now.", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/40", "html_url": "https://github.com/scrapy/scrapy/milestone/40", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/40/labels", "id": 7735764, "node_id": "MI_kwDOAAgUXs4AdgnU", "number": 40, "title": "2.6.2", "description": "Address regressions introduced in 2.6.", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 10, "state": "closed", "created_at": "2022-03-04T09:09:55Z", "updated_at": "2022-07-25T12:59:19Z", "due_on": "2022-04-27T07:00:00Z", "closed_at": "2022-07-25T12:59:19Z"}, "comments": 5, "created_at": "2022-03-25T09:05:42Z", "updated_at": "2022-05-20T05:16:31Z", "closed_at": "2022-04-08T09:26:23Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5459", "html_url": "https://github.com/scrapy/scrapy/pull/5459", "diff_url": "https://github.com/scrapy/scrapy/pull/5459.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5459.patch", "merged_at": "2022-04-08T09:26:23Z"}, "body": "Related to #5454 \r\n\r\nShould this go into 2.6.2?", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5459/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5459/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5444", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5444/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5444/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5444/events", "html_url": "https://github.com/scrapy/scrapy/issues/5444", "id": 1162355301, "node_id": "I_kwDOAAgUXs5FSCJl", "number": 5444, "title": "-o - broken in 2.6", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/40", "html_url": "https://github.com/scrapy/scrapy/milestone/40", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/40/labels", "id": 7735764, "node_id": "MI_kwDOAAgUXs4AdgnU", "number": 40, "title": "2.6.2", "description": "Address regressions introduced in 2.6.", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 10, "state": "closed", "created_at": "2022-03-04T09:09:55Z", "updated_at": "2022-07-25T12:59:19Z", "due_on": "2022-04-27T07:00:00Z", "closed_at": "2022-07-25T12:59:19Z"}, "comments": 0, "created_at": "2022-03-08T08:19:36Z", "updated_at": "2022-03-15T10:31:07Z", "closed_at": "2022-03-15T10:31:07Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "`-o -:json` should be supported and means \"output to stdout in the JSON format\".\r\n\r\n```\r\n$ scrapy runspider sp.py -o -:json\r\nUsage\r\n=====\r\n  scrapy runspider [options] <spider_file>\r\nrunspider: error: argument -o/--output: expected one argument\r\n```\r\n\r\nThis works in 2.5 and was most likely broken after moving to argparse in #5374. I suspect it tries to interpret `-:json` as a separate option. Interesting that `-o -` isn't broken and correctly prints \"Unrecognized output format ''\"", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5444/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5444/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5437", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5437/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5437/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5437/events", "html_url": "https://github.com/scrapy/scrapy/issues/5437", "id": 1158397886, "node_id": "I_kwDOAAgUXs5FC7--", "number": 5437, "title": "CLOSESPIDER_TIMEOUT problem.", "user": {"login": "shahrom322", "id": 91263568, "node_id": "MDQ6VXNlcjkxMjYzNTY4", "avatar_url": "https://avatars.githubusercontent.com/u/91263568?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shahrom322", "html_url": "https://github.com/shahrom322", "followers_url": "https://api.github.com/users/shahrom322/followers", "following_url": "https://api.github.com/users/shahrom322/following{/other_user}", "gists_url": "https://api.github.com/users/shahrom322/gists{/gist_id}", "starred_url": "https://api.github.com/users/shahrom322/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shahrom322/subscriptions", "organizations_url": "https://api.github.com/users/shahrom322/orgs", "repos_url": "https://api.github.com/users/shahrom322/repos", "events_url": "https://api.github.com/users/shahrom322/events{/privacy}", "received_events_url": "https://api.github.com/users/shahrom322/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/40", "html_url": "https://github.com/scrapy/scrapy/milestone/40", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/40/labels", "id": 7735764, "node_id": "MI_kwDOAAgUXs4AdgnU", "number": 40, "title": "2.6.2", "description": "Address regressions introduced in 2.6.", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 10, "state": "closed", "created_at": "2022-03-04T09:09:55Z", "updated_at": "2022-07-25T12:59:19Z", "due_on": "2022-04-27T07:00:00Z", "closed_at": "2022-07-25T12:59:19Z"}, "comments": 9, "created_at": "2022-03-03T13:16:39Z", "updated_at": "2022-07-27T06:34:14Z", "closed_at": "2022-04-08T09:55:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nWhen switching from version 2.5.1 to 2.6.1, there was a problem with the parser terminating if the shutdown condition was CLOSESPIDER_TIMEOUT.\r\n\r\n### Steps to Reproduce\r\n\r\n1. pip install -U scrapy\r\n2. scrapy crawl --set 'CLOSESPIDER_TIMEOUT=1' some_crawler\r\n\r\n**Expected behavior:** [What you expect to happen]\r\n\r\n2022-03-03 16:09:30 [scrapy.core.engine] INFO: Spider closed (closespider_timeout)\r\n\r\n**Actual behavior:** [What actually happens]\r\n\r\n2022-03-03 16:09:30 [scrapy.core.engine] INFO: Spider closed (closespider_timeout)\r\n2022-03-03 16:09:30 [scrapy.core.engine] INFO: Error while scheduling new request\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\onedrive\\python\\scrapy_test\\venv\\lib\\site-packages\\twisted\\internet\\task.py\", line 528, in _oneWorkUnit\r\n    result = next(self._iterator)\r\nStopIteration\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\onedrive\\python\\scrapy_test\\venv\\lib\\site-packages\\twisted\\internet\\defer.py\", line 858, in _runCallbacks\r\n    current.result = callback(  # type: ignore[misc]\r\n  File \"c:\\users\\onedrive\\python\\scrapy_test\\venv\\lib\\site-packages\\scrapy\\core\\engine.py\", line 187, in <lambda>\r\n    d.addBoth(lambda _: self.slot.nextcall.schedule())\r\nAttributeError: 'NoneType' object has no attribute 'nextcall'\r\n\r\n**Reproduces how often:** [What percentage of the time does it reproduce?]\r\n\r\n\r\nIt always reproduce\r\n\r\n### Versions\r\n\r\nScrapy       : 2.6.1\r\nlxml         : 4.7.1.0\r\nlibxml2      : 2.9.12\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 21.7.0\r\nPython       : 3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]\r\npyOpenSSL    : 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021)\r\ncryptography : 36.0.1\r\nPlatform     : Windows-10-10.0.19044-SP0\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5437/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 1}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5437/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5435", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5435/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5435/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5435/events", "html_url": "https://github.com/scrapy/scrapy/issues/5435", "id": 1156953839, "node_id": "I_kwDOAAgUXs5E9bbv", "number": 5435, "title": "2.6.0 breaks calling multiple Spider in CrawlerProcess()", "user": {"login": "hideishi-m", "id": 92977868, "node_id": "U_kgDOBYq6zA", "avatar_url": "https://avatars.githubusercontent.com/u/92977868?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hideishi-m", "html_url": "https://github.com/hideishi-m", "followers_url": "https://api.github.com/users/hideishi-m/followers", "following_url": "https://api.github.com/users/hideishi-m/following{/other_user}", "gists_url": "https://api.github.com/users/hideishi-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/hideishi-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hideishi-m/subscriptions", "organizations_url": "https://api.github.com/users/hideishi-m/orgs", "repos_url": "https://api.github.com/users/hideishi-m/repos", "events_url": "https://api.github.com/users/hideishi-m/events{/privacy}", "received_events_url": "https://api.github.com/users/hideishi-m/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/40", "html_url": "https://github.com/scrapy/scrapy/milestone/40", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/40/labels", "id": 7735764, "node_id": "MI_kwDOAAgUXs4AdgnU", "number": 40, "title": "2.6.2", "description": "Address regressions introduced in 2.6.", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 10, "state": "closed", "created_at": "2022-03-04T09:09:55Z", "updated_at": "2022-07-25T12:59:19Z", "due_on": "2022-04-27T07:00:00Z", "closed_at": "2022-07-25T12:59:19Z"}, "comments": 11, "created_at": "2022-03-02T09:58:06Z", "updated_at": "2022-07-21T09:32:38Z", "closed_at": "2022-04-07T15:00:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\nSince 2.6.0, it breaks calling multiple Spiders from CrawlerProcess() as shown in the common practices \r\n\r\nhttps://docs.scrapy.org/en/latest/topics/practices.html#running-multiple-spiders-in-the-same-process\r\n\r\n### Steps to Reproduce\r\n\r\n1. use Scrapy=>2.6.0\r\n2. following is the code to reproduce\r\n\r\n```\r\nimport scrapy\r\nfrom scrapy.crawler import CrawlerProcess\r\nfrom scrapy.http import Request\r\n\r\n\r\nclass MySpider(scrapy.Spider):\r\n    name = 'MySpider'\r\n\r\n    def __init__(self, url, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.url = url\r\n\r\n    def start_requests(self):\r\n        yield Request(url=self.url, callback=self.parse)\r\n\r\n    def parse(self, response):\r\n        print(response.url)\r\n\r\n\r\nprocess = CrawlerProcess({\r\n    'DEPTH_LIMIT': 1,\r\n    'DEPTH_PRIORITY': 1\r\n})\r\nprocess.crawl(MySpider, url='https://www.google.com')\r\nprocess.crawl(MySpider, url='https://www.google.co.jp')\r\nprocess.start()\r\n```\r\n\r\n**Expected behavior:** [What you expect to happen]\r\n\r\nFollowing is the result from Scrapy 2.5.1\r\n\r\n```\r\n2022-03-02 18:49:45 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: scrapybot)\r\n2022-03-02 18:49:45 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.1.0, Python 3.9.10 (main, Jan 17 2022, 08:36:28) - [GCC 11.2.1 20210728 (Red Hat 11.2.1-1)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Linux-3.10.0-1160.59.1.el7.x86_64-x86_64-with-glibc2.17\r\n2022-03-02 18:49:45 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\r\n2022-03-02 18:49:45 [scrapy.crawler] INFO: Overridden settings:\r\n{'DEPTH_LIMIT': 1, 'DEPTH_PRIORITY': 1}\r\n2022-03-02 18:49:45 [scrapy.extensions.telnet] INFO: Telnet Password: afe09d724aae9642\r\n2022-03-02 18:49:45 [scrapy.middleware] INFO: Enabled extensions:\r\n['scrapy.extensions.corestats.CoreStats',\r\n 'scrapy.extensions.telnet.TelnetConsole',\r\n 'scrapy.extensions.memusage.MemoryUsage',\r\n 'scrapy.extensions.logstats.LogStats']\r\n2022-03-02 18:49:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\r\n['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\r\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\r\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\r\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\r\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\r\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\r\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\r\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\r\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\r\n2022-03-02 18:49:45 [scrapy.middleware] INFO: Enabled spider middlewares:\r\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\r\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\r\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\r\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\r\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\r\n2022-03-02 18:49:45 [scrapy.middleware] INFO: Enabled item pipelines:\r\n[]\r\n2022-03-02 18:49:45 [scrapy.core.engine] INFO: Spider opened\r\n2022-03-02 18:49:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2022-03-02 18:49:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\r\n2022-03-02 18:49:45 [scrapy.crawler] INFO: Overridden settings:\r\n{'DEPTH_LIMIT': 1, 'DEPTH_PRIORITY': 1}\r\n2022-03-02 18:49:45 [scrapy.extensions.telnet] INFO: Telnet Password: bd1670acfb7fb550\r\n2022-03-02 18:49:45 [scrapy.middleware] INFO: Enabled extensions:\r\n['scrapy.extensions.corestats.CoreStats',\r\n 'scrapy.extensions.telnet.TelnetConsole',\r\n 'scrapy.extensions.memusage.MemoryUsage',\r\n 'scrapy.extensions.logstats.LogStats']\r\n2022-03-02 18:49:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\r\n['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\r\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\r\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\r\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\r\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\r\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\r\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\r\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\r\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\r\n2022-03-02 18:49:45 [scrapy.middleware] INFO: Enabled spider middlewares:\r\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\r\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\r\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\r\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\r\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\r\n2022-03-02 18:49:45 [scrapy.middleware] INFO: Enabled item pipelines:\r\n[]\r\n2022-03-02 18:49:45 [scrapy.core.engine] INFO: Spider opened\r\n2022-03-02 18:49:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2022-03-02 18:49:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024\r\n2022-03-02 18:49:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.google.com> (referer: None)\r\n2022-03-02 18:49:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.google.co.jp> (referer: None)\r\nhttps://www.google.com\r\nhttps://www.google.co.jp\r\n2022-03-02 18:49:46 [scrapy.core.engine] INFO: Closing spider (finished)\r\n2022-03-02 18:49:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\r\n{'downloader/request_bytes': 214,\r\n 'downloader/request_count': 1,\r\n 'downloader/request_method_count/GET': 1,\r\n 'downloader/response_bytes': 7675,\r\n 'downloader/response_count': 1,\r\n 'downloader/response_status_count/200': 1,\r\n 'elapsed_time_seconds': 0.465932,\r\n 'finish_reason': 'finished',\r\n 'finish_time': datetime.datetime(2022, 3, 2, 9, 49, 46, 66477),\r\n 'httpcompression/response_bytes': 15980,\r\n 'httpcompression/response_count': 1,\r\n 'log_count/DEBUG': 2,\r\n 'log_count/INFO': 19,\r\n 'memusage/max': 47611904,\r\n 'memusage/startup': 47611904,\r\n 'response_received_count': 1,\r\n 'scheduler/dequeued': 1,\r\n 'scheduler/dequeued/memory': 1,\r\n 'scheduler/enqueued': 1,\r\n 'scheduler/enqueued/memory': 1,\r\n 'start_time': datetime.datetime(2022, 3, 2, 9, 49, 45, 600545)}\r\n2022-03-02 18:49:46 [scrapy.core.engine] INFO: Spider closed (finished)\r\n2022-03-02 18:49:46 [scrapy.core.engine] INFO: Closing spider (finished)\r\n2022-03-02 18:49:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\r\n{'downloader/request_bytes': 216,\r\n 'downloader/request_count': 1,\r\n 'downloader/request_method_count/GET': 1,\r\n 'downloader/response_bytes': 7602,\r\n 'downloader/response_count': 1,\r\n 'downloader/response_status_count/200': 1,\r\n 'elapsed_time_seconds': 0.431935,\r\n 'finish_reason': 'finished',\r\n 'finish_time': datetime.datetime(2022, 3, 2, 9, 49, 46, 98011),\r\n 'httpcompression/response_bytes': 14794,\r\n 'httpcompression/response_count': 1,\r\n 'log_count/DEBUG': 2,\r\n 'log_count/INFO': 13,\r\n 'memusage/max': 47669248,\r\n 'memusage/startup': 47669248,\r\n 'response_received_count': 1,\r\n 'scheduler/dequeued': 1,\r\n 'scheduler/dequeued/memory': 1,\r\n 'scheduler/enqueued': 1,\r\n 'scheduler/enqueued/memory': 1,\r\n 'start_time': datetime.datetime(2022, 3, 2, 9, 49, 45, 666076)}\r\n2022-03-02 18:49:46 [scrapy.core.engine] INFO: Spider closed (finished)\r\n```\r\n\r\n**Actual behavior:** [What actually happens]\r\n\r\nSpider fails with twisted.internet.error.ReactorAlreadyInstalledError\r\n\r\n```\r\n2022-03-02 18:49:12 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: scrapybot)\r\n2022-03-02 18:49:12 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.1.0, Python 3.9.10 (main, Jan 17 2022, 08:36:28) - [GCC 11.2.1 20210728 (Red Hat 11.2.1-1)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Linux-3.10.0-1160.59.1.el7.x86_64-x86_64-with-glibc2.17\r\n2022-03-02 18:49:12 [scrapy.crawler] INFO: Overridden settings:\r\n{'DEPTH_LIMIT': 1, 'DEPTH_PRIORITY': 1}\r\n2022-03-02 18:49:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\r\n2022-03-02 18:49:12 [scrapy.extensions.telnet] INFO: Telnet Password: ce57e6aa863bb786\r\n2022-03-02 18:49:12 [scrapy.middleware] INFO: Enabled extensions:\r\n['scrapy.extensions.corestats.CoreStats',\r\n 'scrapy.extensions.telnet.TelnetConsole',\r\n 'scrapy.extensions.memusage.MemoryUsage',\r\n 'scrapy.extensions.logstats.LogStats']\r\n2022-03-02 18:49:13 [scrapy.middleware] INFO: Enabled downloader middlewares:\r\n['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\r\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\r\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\r\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\r\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\r\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\r\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\r\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\r\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\r\n2022-03-02 18:49:13 [scrapy.middleware] INFO: Enabled spider middlewares:\r\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\r\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\r\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\r\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\r\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\r\n2022-03-02 18:49:13 [scrapy.middleware] INFO: Enabled item pipelines:\r\n[]\r\n2022-03-02 18:49:13 [scrapy.core.engine] INFO: Spider opened\r\n2022-03-02 18:49:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2022-03-02 18:49:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\r\n2022-03-02 18:49:13 [scrapy.crawler] INFO: Overridden settings:\r\n{'DEPTH_LIMIT': 1, 'DEPTH_PRIORITY': 1}\r\nTraceback (most recent call last):\r\n  File \"/home/kusanagi/work/scrapy/test.py\", line 25, in <module>\r\n    process.crawl(MySpider, url='https://www.google.co.jp')\r\n  File \"/usr/local/lib/python3.9/site-packages/scrapy/crawler.py\", line 205, in crawl\r\n    crawler = self.create_crawler(crawler_or_spidercls)\r\n  File \"/usr/local/lib/python3.9/site-packages/scrapy/crawler.py\", line 238, in create_crawler\r\n    return self._create_crawler(crawler_or_spidercls)\r\n  File \"/usr/local/lib/python3.9/site-packages/scrapy/crawler.py\", line 313, in _create_crawler\r\n    return Crawler(spidercls, self.settings, init_reactor=True)\r\n  File \"/usr/local/lib/python3.9/site-packages/scrapy/crawler.py\", line 82, in __init__\r\n    default.install()\r\n  File \"/usr/local/lib/python3.9/site-packages/twisted/internet/epollreactor.py\", line 256, in install\r\n    installReactor(p)\r\n  File \"/usr/local/lib/python3.9/site-packages/twisted/internet/main.py\", line 32, in installReactor\r\n    raise error.ReactorAlreadyInstalledError(\"reactor already installed\")\r\ntwisted.internet.error.ReactorAlreadyInstalledError: reactor already installed\r\n```\r\n\r\n**Reproduces how often:** [What percentage of the time does it reproduce?]\r\n\r\nAlways.\r\n\r\n### Versions\r\n\r\nScrapy       : 2.6.1\r\nlxml         : 4.8.0.0\r\nlibxml2      : 2.9.12\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 22.1.0\r\nPython       : 3.9.10 (main, Jan 17 2022, 08:36:28) - [GCC 11.2.1 20210728 (Red Hat 11.2.1-1)]\r\npyOpenSSL    : 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021)\r\ncryptography : 36.0.1\r\nPlatform     : Linux-3.10.0-1160.59.1.el7.x86_64-x86_64-with-glibc2.17\r\n\r\n### Additional context\r\n\r\nThe intension of using the same MySpider but from CrawlerProcess is to call Scrapy programatically using different initial url and some tweaks to parser depending on the initial url.\r\n\r\nI think this is very fair usage and was working fine before 2.6.0.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5435/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5435/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5427", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5427/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5427/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5427/events", "html_url": "https://github.com/scrapy/scrapy/pull/5427", "id": 1147967852, "node_id": "PR_kwDOAAgUXs4zVnMY", "number": 5427, "title": "Pin old markupsafe when we pin old mitmproxy.", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-02-23T11:22:53Z", "updated_at": "2022-02-23T18:52:19Z", "closed_at": "2022-02-23T18:52:18Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5427", "html_url": "https://github.com/scrapy/scrapy/pull/5427", "diff_url": "https://github.com/scrapy/scrapy/pull/5427.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5427.patch", "merged_at": "2022-02-23T18:52:18Z"}, "body": "Fixes #5425 ", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5427/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5427/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5425", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5425/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5425/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5425/events", "html_url": "https://github.com/scrapy/scrapy/issues/5425", "id": 1146937222, "node_id": "I_kwDOAAgUXs5EXN-G", "number": 5425, "title": "ImportError: cannot import name 'soft_unicode' from 'markupsafe'", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-02-22T13:50:45Z", "updated_at": "2022-02-23T18:52:18Z", "closed_at": "2022-02-23T18:52:18Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Looking at the CI jobs of https://github.com/scrapy/scrapy/pull/4267, https://github.com/pallets/markupsafe/issues/282 is hitting us in some scenarios.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5425/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5425/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5424", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5424/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5424/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5424/events", "html_url": "https://github.com/scrapy/scrapy/issues/5424", "id": 1145631777, "node_id": "I_kwDOAAgUXs5ESPQh", "number": 5424, "title": "scrapy parse doesn't support async callbacks", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 3270783977, "node_id": "MDU6TGFiZWwzMjcwNzgzOTc3", "url": "https://api.github.com/repos/scrapy/scrapy/labels/asyncio", "name": "asyncio", "color": "fef2c0", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-02-21T10:50:47Z", "updated_at": "2023-01-31T11:07:02Z", "closed_at": "2022-10-15T08:11:07Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "In master when running `scrapy parse` for a spider with `async def parse` the page is downloaded but then the spider hangs. In #4978  it instead raises `TypeError: 'async_generator' object is not iterable`. Both problems happen because the parse command calls `iterate_spider_output` and doesn't expect a Deferred or an async iterator. ", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5424/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5424/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5414", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5414/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5414/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5414/events", "html_url": "https://github.com/scrapy/scrapy/issues/5414", "id": 1135481373, "node_id": "I_kwDOAAgUXs5DrhId", "number": 5414, "title": "Change external link (for robots.txt parser comparison) in docs to a more lasting page", "user": {"login": "anubhavp28", "id": 29521514, "node_id": "MDQ6VXNlcjI5NTIxNTE0", "avatar_url": "https://avatars.githubusercontent.com/u/29521514?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anubhavp28", "html_url": "https://github.com/anubhavp28", "followers_url": "https://api.github.com/users/anubhavp28/followers", "following_url": "https://api.github.com/users/anubhavp28/following{/other_user}", "gists_url": "https://api.github.com/users/anubhavp28/gists{/gist_id}", "starred_url": "https://api.github.com/users/anubhavp28/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anubhavp28/subscriptions", "organizations_url": "https://api.github.com/users/anubhavp28/orgs", "repos_url": "https://api.github.com/users/anubhavp28/repos", "events_url": "https://api.github.com/users/anubhavp28/events{/privacy}", "received_events_url": "https://api.github.com/users/anubhavp28/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-02-13T08:42:54Z", "updated_at": "2022-02-14T18:16:53Z", "closed_at": "2022-02-14T18:16:53Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Scrapy documentation (at the end of [this section](https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.robotstxt)) links to a blog that contains performance numbers for different `robots.txt` parser backends. It would be better to change the link to point to [this issue](https://github.com/scrapy/scrapy/issues/3969) as it is more lasting. Currently, we are linking to a personal blog website which might disappear if the blog owner decides to change the hosting or blog name.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5414/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5414/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5407", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5407/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5407/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5407/events", "html_url": "https://github.com/scrapy/scrapy/pull/5407", "id": 1129666946, "node_id": "PR_kwDOAAgUXs4yXCJM", "number": 5407, "title": "Use toscrape.com instead of example.com in test_command_check.", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-02-10T08:59:10Z", "updated_at": "2022-02-10T09:50:12Z", "closed_at": "2022-02-10T09:50:12Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5407", "html_url": "https://github.com/scrapy/scrapy/pull/5407", "diff_url": "https://github.com/scrapy/scrapy/pull/5407.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5407.patch", "merged_at": "2022-02-10T09:50:12Z"}, "body": "Closes: #5404.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5407/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5407/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5405", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5405/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5405/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5405/events", "html_url": "https://github.com/scrapy/scrapy/pull/5405", "id": 1127599908, "node_id": "PR_kwDOAAgUXs4yQNWQ", "number": 5405, "title": "Fix running tests with Twisted 22.1.0", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-02-08T18:13:04Z", "updated_at": "2022-02-08T19:06:28Z", "closed_at": "2022-02-08T19:06:25Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5405", "html_url": "https://github.com/scrapy/scrapy/pull/5405", "diff_url": "https://github.com/scrapy/scrapy/pull/5405.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5405.patch", "merged_at": "2022-02-08T19:06:25Z"}, "body": "Fixes #5400, see the explanation there.\r\n\r\nI've decided to put the classes into mockserver.py because it already has a resource class and other two files already import from it. But it's possible to move them into a separate file (in which case I'd discuss if we want to keep those supplementary modules in tests/ or move them into a subdir).", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5405/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5405/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5404", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5404/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5404/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5404/events", "html_url": "https://github.com/scrapy/scrapy/issues/5404", "id": 1127596092, "node_id": "I_kwDOAAgUXs5DNcA8", "number": 5404, "title": "tests/test_command_check.py::CheckCommandTest depends on example.com", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-02-08T18:09:45Z", "updated_at": "2022-02-10T09:50:12Z", "closed_at": "2022-02-10T09:50:12Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Sometimes we get\r\n\r\n`'OK' not in '/home/runner/work/scrapy/scrapy/.tox/asyncio/lib/python3.10/site-packages/coverage/inorout.py:472: CoverageWarning: --include is ignored because --source is set (include-ignored)\\n  self.warn(\"--include is ignored because --source is set\", slug=\"include-ignored\")\\nE\\n======================================================================\\nERROR: [check_spider] parse (errback)\\n----------------------------------------------------------------------\\nTraceback (most recent call last):\\n  File \"/home/runner/work/scrapy/scrapy/.tox/asyncio/lib/python3.10/site-packages/twisted/internet/defer.py\", line 1660, in _inlineCallbacks\\n    result = current_context.run(gen.send, result)\\nStopIteration: <404 http://example.com>\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/home/runner/work/scrapy/scrapy/scrapy/core/spidermw.py\", line 52, in _process_spider_input\\n    result = method(response=response, spider=spider)\\n  File \"/home/runner/work/scrapy/scrapy/scrapy/spidermiddlewares/httperror.py\", line 45, in process_spider_input\\n    raise HttpError(response, \\'Ignoring non-200 response\\')\\nscrapy.spidermiddlewares.httperror.HttpError: Ignoring non-200 response\\n\\n----------------------------------------------------------------------\\nRan 0 contracts in 0.139s\\n\\nFAILED (errors=1)\\n'`\r\n\r\nThis seems to be caused by getting 404 from http://example.com which I can reproduce on some requests. We shouldn't make actual network requests in any case, but in this case this is also breaking the test.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5404/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5404/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5401", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5401/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5401/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5401/events", "html_url": "https://github.com/scrapy/scrapy/pull/5401", "id": 1126034888, "node_id": "PR_kwDOAAgUXs4yLGK6", "number": 5401, "title": "Temporarily pin Twisted to an older version in CI.", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-02-07T14:01:40Z", "updated_at": "2022-02-07T20:25:09Z", "closed_at": "2022-02-07T20:25:08Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5401", "html_url": "https://github.com/scrapy/scrapy/pull/5401", "diff_url": "https://github.com/scrapy/scrapy/pull/5401.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5401.patch", "merged_at": "2022-02-07T20:25:08Z"}, "body": "Related to #5400", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5401/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5401/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5400", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5400/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5400/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5400/events", "html_url": "https://github.com/scrapy/scrapy/issues/5400", "id": 1126020247, "node_id": "I_kwDOAAgUXs5DHbSX", "number": 5400, "title": "Tests broken with Twisted 22.1.0", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-02-07T13:48:23Z", "updated_at": "2022-02-08T19:06:25Z", "closed_at": "2022-02-08T19:06:25Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "`ImportError: cannot import name 'PayloadResource' from 'twisted.web.test.test_webclient'`\r\n\r\n`ImportError: cannot import name 'ForeverTakingResource' from 'twisted.web.test.test_webclient'`", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5400/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5400/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5391", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5391/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5391/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5391/events", "html_url": "https://github.com/scrapy/scrapy/issues/5391", "id": 1124931939, "node_id": "I_kwDOAAgUXs5DDRlj", "number": 5391, "title": "Incorrect initialization of `csviter` in `scrapy.spiders.feed.CSVFeedSpider`", "user": {"login": "dchaplinsky", "id": 131186, "node_id": "MDQ6VXNlcjEzMTE4Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/131186?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dchaplinsky", "html_url": "https://github.com/dchaplinsky", "followers_url": "https://api.github.com/users/dchaplinsky/followers", "following_url": "https://api.github.com/users/dchaplinsky/following{/other_user}", "gists_url": "https://api.github.com/users/dchaplinsky/gists{/gist_id}", "starred_url": "https://api.github.com/users/dchaplinsky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dchaplinsky/subscriptions", "organizations_url": "https://api.github.com/users/dchaplinsky/orgs", "repos_url": "https://api.github.com/users/dchaplinsky/repos", "events_url": "https://api.github.com/users/dchaplinsky/events{/privacy}", "received_events_url": "https://api.github.com/users/dchaplinsky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-02-05T13:32:04Z", "updated_at": "2022-02-08T13:57:19Z", "closed_at": "2022-02-08T13:57:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nAccording to the master branch, `scrapy.spiders.feed.CSVFeedSpider` initializes csviter like this:\r\n```python\r\nfor row in csviter(response, self.delimiter, self.headers, self.quotechar):\r\n```\r\nhttps://github.com/scrapy/scrapy/blob/master/scrapy/spiders/feed.py#L126\r\n\r\nBut `csviter` definition says:\r\n`def csviter(obj, delimiter=None, headers=None, encoding=None, quotechar=None):`\r\nhttps://github.com/scrapy/scrapy/blob/master/scrapy/utils/iterators.py#L96\r\n\r\nSo effectively it passed quotechar instead of encoding\r\n\r\n### Steps to Reproduce\r\n\r\n1. Check the first link\r\n2. Check the second link\r\n3. [and so on...]\r\n\r\n**Expected behavior:** CSVFeedSpider has a separate setting for the encoding or specify param names when calling csviter\r\n\r\n**Actual behavior:** Mess\r\n\r\n**Reproduces how often:** 100%\r\n\r\n### Versions\r\n\r\n```\r\nScrapy       : 2.5.0\r\nlxml         : 4.6.3.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 21.2.0\r\nPython       : 3.9.8 (main, Nov 10 2021, 09:21:22) - [Clang 13.0.0 (clang-1300.0.29.3)]\r\npyOpenSSL    : 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021)\r\ncryptography : 3.4.7\r\nPlatform     : macOS-11.6-x86_64-i386-64bit\r\n```\r\n\r\n### Additional context\r\n\r\nPlease fix it :)", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5391/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5391/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5386", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5386/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5386/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5386/events", "html_url": "https://github.com/scrapy/scrapy/issues/5386", "id": 1120895972, "node_id": "I_kwDOAAgUXs5Cz4Pk", "number": 5386, "title": "Fix SMTP STARTTLS for Twisted >= 21.2.0", "user": {"login": "TobiMayr", "id": 16239618, "node_id": "MDQ6VXNlcjE2MjM5NjE4", "avatar_url": "https://avatars.githubusercontent.com/u/16239618?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TobiMayr", "html_url": "https://github.com/TobiMayr", "followers_url": "https://api.github.com/users/TobiMayr/followers", "following_url": "https://api.github.com/users/TobiMayr/following{/other_user}", "gists_url": "https://api.github.com/users/TobiMayr/gists{/gist_id}", "starred_url": "https://api.github.com/users/TobiMayr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TobiMayr/subscriptions", "organizations_url": "https://api.github.com/users/TobiMayr/orgs", "repos_url": "https://api.github.com/users/TobiMayr/repos", "events_url": "https://api.github.com/users/TobiMayr/events{/privacy}", "received_events_url": "https://api.github.com/users/TobiMayr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/41", "html_url": "https://github.com/scrapy/scrapy/milestone/41", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/41/labels", "id": 8583553, "node_id": "MI_kwDOAAgUXs4AgvmB", "number": 41, "title": "Scrapy 2.8", "description": "", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 11, "state": "closed", "created_at": "2022-10-26T14:59:30Z", "updated_at": "2023-02-02T09:08:31Z", "due_on": null, "closed_at": "2023-02-02T09:08:31Z"}, "comments": 14, "created_at": "2022-02-01T16:09:00Z", "updated_at": "2023-01-19T18:45:00Z", "closed_at": "2023-01-19T18:44:59Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Summary\r\n\r\nThe [Mail settings](https://docs.scrapy.org/en/latest/topics/email.html#topics-email-settings) don't have an option to choose a TLS version. Only to enforce upgrading connections to use SSL/TLS.\r\nMail servers like smtp.office365.com dropped support for TLS1.0 and TLS1.1 and now require TLS1.2: https://techcommunity.microsoft.com/t5/exchange-team-blog/new-opt-in-endpoint-available-for-smtp-auth-clients-still/ba-p/2659652 \r\n\r\nIt seems that scrapy mail doesn't support TLS1.2. The error message (with `MAIL_TLS = True`):\r\n\r\n`[scrapy.mail] Unable to send mail: To=['user@gmail.com'] Cc=[] Subject=\"Test\" Attachs=0- 421 b'4.7.66 TLS 1.0 and 1.1 are not supported. Please upgrade/update your client to support TLS 1.2. Visit https://aka.ms/smtp_auth_tls. [AM6P194CA0047.EURP194.PROD.OUTLOOK.COM]'` \r\n\r\n## Motivation\r\n\r\nWithout TLS1.2 it's not possible anymore to send mails via smtp.office365.com. An option to use TLS1.2 would fix this issue\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5386/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5386/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5383", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5383/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5383/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5383/events", "html_url": "https://github.com/scrapy/scrapy/issues/5383", "id": 1118502173, "node_id": "I_kwDOAAgUXs5Cqv0d", "number": 5383, "title": "Type error when we try to retrieve the `FEEDS` setting via CLI and it has a `Path` objects as a key", "user": {"login": "waveFrontSet", "id": 4996688, "node_id": "MDQ6VXNlcjQ5OTY2ODg=", "avatar_url": "https://avatars.githubusercontent.com/u/4996688?v=4", "gravatar_id": "", "url": "https://api.github.com/users/waveFrontSet", "html_url": "https://github.com/waveFrontSet", "followers_url": "https://api.github.com/users/waveFrontSet/followers", "following_url": "https://api.github.com/users/waveFrontSet/following{/other_user}", "gists_url": "https://api.github.com/users/waveFrontSet/gists{/gist_id}", "starred_url": "https://api.github.com/users/waveFrontSet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/waveFrontSet/subscriptions", "organizations_url": "https://api.github.com/users/waveFrontSet/orgs", "repos_url": "https://api.github.com/users/waveFrontSet/repos", "events_url": "https://api.github.com/users/waveFrontSet/events{/privacy}", "received_events_url": "https://api.github.com/users/waveFrontSet/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-01-30T11:41:20Z", "updated_at": "2022-02-04T08:57:57Z", "closed_at": "2022-02-04T08:57:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\nWhen a `Path` object is used as a key in the `FEEDS` dictionary and we try to obtain the `FEEDS` setting via CLI `scrapy settings --get FEEDS`, a type error is raised:\r\n\r\n```\r\nTypeError: keys must be str, int, float, bool or None, not PosixPath\r\n```\r\n\r\nA complete stack trace is attached below under \"Actual behavior\".\r\n\r\n`Path` objects as keys are allowed as documented in [the FEEDS section of the Feed exports chapter](https://docs.scrapy.org/en/master/topics/feed-exports.html#feeds).\r\n\r\n### Steps to Reproduce\r\n\r\n1. In a freshly generated scrapy project (e.g. via `scrapy project feeds_bug`), prepend the following lines to `settings.py`:\r\n```python\r\nfrom pathlib import Path\r\n\r\nFEEDS = {\r\n    Path(\"some_path/file.csv\"): {\r\n        \"format\": \"csv\"\r\n    }\r\n}\r\n```\r\n2. Execute `scrapy settings --get FEEDS`\r\n\r\n**Expected behavior:** Some string representation of the `FEEDS` setting gets printed to standard out, maybe like this:\r\n```\r\n{\"some_path/file.csv\": {\"format\": \"csv\"}}\r\n```\r\n\r\n**Actual behavior:** A type error is raised:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/paul/Projects/feeds-bug/.direnv/python-3.9.7/bin/scrapy\", line 8, in <module>\r\n    sys.exit(execute())\r\n  File \"/Users/paul/Projects/feeds-bug/.direnv/python-3.9.7/lib/python3.9/site-packages/scrapy/cmdline.py\", line 145, in execute\r\n    _run_print_help(parser, _run_command, cmd, args, opts)\r\n  File \"/Users/paul/Projects/feeds-bug/.direnv/python-3.9.7/lib/python3.9/site-packages/scrapy/cmdline.py\", line 100, in _run_print_help\r\n    func(*a, **kw)\r\n  File \"/Users/paul/Projects/feeds-bug/.direnv/python-3.9.7/lib/python3.9/site-packages/scrapy/cmdline.py\", line 153, in _run_command\r\n    cmd.run(args, opts)\r\n  File \"/Users/paul/Projects/feeds-bug/.direnv/python-3.9.7/lib/python3.9/site-packages/scrapy/commands/settings.py\", line 37, in run\r\n    print(json.dumps(s.copy_to_dict()))\r\n  File \"/Users/paul/.pyenv/versions/3.9.7/lib/python3.9/json/__init__.py\", line 231, in dumps\r\n    return _default_encoder.encode(obj)\r\n  File \"/Users/paul/.pyenv/versions/3.9.7/lib/python3.9/json/encoder.py\", line 199, in encode\r\n    chunks = self.iterencode(o, _one_shot=True)\r\n  File \"/Users/paul/.pyenv/versions/3.9.7/lib/python3.9/json/encoder.py\", line 257, in iterencode\r\n    return _iterencode(o, 0)\r\nTypeError: keys must be str, int, float, bool or None, not PosixPath\r\n```\r\n\r\n**Reproduces how often:** 100%\r\n\r\n### Versions\r\n\r\n```\r\nScrapy       : 2.5.1\r\nlxml         : 4.7.1.0\r\nlibxml2      : 2.9.12\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 21.7.0\r\nPython       : 3.9.7 (default, Dec 11 2021, 11:25:57) - [Clang 13.0.0 (clang-1300.0.29.3)]\r\npyOpenSSL    : 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021)\r\ncryptography : 36.0.1\r\nPlatform     : macOS-11.6-x86_64-i386-64bit\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5383/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5383/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5359", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5359/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5359/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5359/events", "html_url": "https://github.com/scrapy/scrapy/pull/5359", "id": 1091104980, "node_id": "PR_kwDOAAgUXs4wZcmZ", "number": 5359, "title": "Fix a warning message.", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-12-30T13:26:19Z", "updated_at": "2021-12-30T13:55:16Z", "closed_at": "2021-12-30T13:55:16Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5359", "html_url": "https://github.com/scrapy/scrapy/pull/5359", "diff_url": "https://github.com/scrapy/scrapy/pull/5359.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5359.patch", "merged_at": "2021-12-30T13:55:16Z"}, "body": "I have no idea why this started to fail with a TypeError and I cannot reproduce it locally but it's definitely a mistake.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5359/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5359/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5323", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5323/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5323/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5323/events", "html_url": "https://github.com/scrapy/scrapy/issues/5323", "id": 1055680872, "node_id": "I_kwDOAAgUXs4-7Glo", "number": 5323, "title": "Warning: Unable to determine whether or not callable is a generator with a return value [unable to parse decorated class methods]", "user": {"login": "jefflester", "id": 44791802, "node_id": "MDQ6VXNlcjQ0NzkxODAy", "avatar_url": "https://avatars.githubusercontent.com/u/44791802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jefflester", "html_url": "https://github.com/jefflester", "followers_url": "https://api.github.com/users/jefflester/followers", "following_url": "https://api.github.com/users/jefflester/following{/other_user}", "gists_url": "https://api.github.com/users/jefflester/gists{/gist_id}", "starred_url": "https://api.github.com/users/jefflester/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jefflester/subscriptions", "organizations_url": "https://api.github.com/users/jefflester/orgs", "repos_url": "https://api.github.com/users/jefflester/repos", "events_url": "https://api.github.com/users/jefflester/events{/privacy}", "received_events_url": "https://api.github.com/users/jefflester/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-11-17T04:06:32Z", "updated_at": "2022-10-26T07:47:10Z", "closed_at": "2022-10-26T07:47:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nIf you have a decorated spider method, `scrapy.utils.misc` [throws a warning](https://github.com/scrapy/scrapy/blob/master/scrapy/utils/misc.py#L240-L264) saying that it cannot determine if the callable is a generator with a return value.\r\n\r\n`ast.parse()` fails [here](https://github.com/scrapy/scrapy/blob/master/scrapy/utils/misc.py#L228-L230) when called with a decorated method.\r\n\r\n### Steps to Reproduce\r\n\r\nI just copied the logic from `misc.py` and used it to analyze a class with the same overall code structure:\r\n\r\n```python\r\nimport re\r\nimport ast\r\nimport inspect\r\n\r\nclass Foo:\r\n    @classmethod\r\n    def func(self):\r\n        \"\"\"\r\n        Description of func\r\n        \"\"\"  \r\n        return\r\n\r\ncode = re.sub(r\"^[\\t ]+\", \"\", inspect.getsource(Foo.func))\r\ntree = ast.parse(code)\r\n```\r\n\r\n```\r\npython3 test.py\r\n> IndentationError: unexpected indent\r\n```\r\n\r\nThe regex replacement isn't accounting for a possible decorator, so the code ends up looking like:\r\n\r\n```\r\n@classmethod\r\n    def func(self):\r\n        \"\"\"\r\n        Description of func\r\n        \"\"\"  \r\n        return\r\n```\r\n\r\n**Expected behavior:** I'd like to be able to use decorated methods without dealing with noisy logs.\r\n\r\n**Actual behavior:** My container logs are filled with tons of warning messages. The only workaround is to avoid the usage of decorators.\r\n\r\n**Reproduces how often:** 100% of the time to my knowledge\r\n\r\n### Versions\r\n\r\n```\r\n$ scrapy version --verbose\r\n\r\nScrapy       : 2.5.1\r\nlxml         : 4.6.4.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 21.7.0\r\nPython       : 3.8.2 (default, Dec 21 2020, 15:06:04) - [Clang 12.0.0 (clang-1200.0.32.29)]\r\npyOpenSSL    : 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021)\r\ncryptography : 35.0.0\r\nPlatform     : macOS-10.15.7-x86_64-i386-64bit\r\n```\r\n\r\n### Additional context\r\n\r\nThis is my first time filing a Scrapy issue. I'm happy to add more context if necessary, and apologies in advance if this has already been discussed elsewhere (fwiw I couldn't find anything).", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5323/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5323/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5319", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5319/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5319/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5319/events", "html_url": "https://github.com/scrapy/scrapy/issues/5319", "id": 1053459361, "node_id": "I_kwDOAAgUXs4-yoOh", "number": 5319, "title": "Open in Browser `<base>` replacement will fail if `<head>` has attributes", "user": {"login": "zessx", "id": 3398490, "node_id": "MDQ6VXNlcjMzOTg0OTA=", "avatar_url": "https://avatars.githubusercontent.com/u/3398490?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zessx", "html_url": "https://github.com/zessx", "followers_url": "https://api.github.com/users/zessx/followers", "following_url": "https://api.github.com/users/zessx/following{/other_user}", "gists_url": "https://api.github.com/users/zessx/gists{/gist_id}", "starred_url": "https://api.github.com/users/zessx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zessx/subscriptions", "organizations_url": "https://api.github.com/users/zessx/orgs", "repos_url": "https://api.github.com/users/zessx/repos", "events_url": "https://api.github.com/users/zessx/events{/privacy}", "received_events_url": "https://api.github.com/users/zessx/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-11-15T10:09:46Z", "updated_at": "2021-12-21T12:49:32Z", "closed_at": "2021-12-21T12:49:32Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\nWhen using `open_in_browser()` feature, Scrapy will try to add a `<base>` tag to ensure remote resources are loaded, and to make external links to work in our local browser. This feature rely on the following code:\r\n\r\nhttps://github.com/scrapy/scrapy/blob/06f3d12c1208c380f9f1a16cb36ba2dfa3c244c5/scrapy/utils/response.py#L81-L84\r\n\r\nSome website are using attributes on the `<head>` tag, which will prevent the `<base>` tag to be injected, and therefore external resources to be loaded.\r\n\r\n### How to reproduce the issue \r\n\r\nSimply create a basic spider [following Scrapy tutorial](https://docs.scrapy.org/en/latest/intro/tutorial.html) and use the following code:\r\n\r\n```py\r\nimport scrapy\r\nfrom scrapy.utils.response import open_in_browser\r\n\r\nclass ExampleSpider(scrapy.Spider):\r\n    name = 'example'\r\n    allowed_domains = ['example.com']\r\n    start_urls = [\r\n        'https://example.com/head-without-argument.html', \r\n        'https://example.com/head-with-argument.html']\r\n\r\n    def parse(self, response):\r\n        open_in_browser(response)\r\n        pass\r\n```\r\n\r\nFor the scrapped pages itselves, use the simplest code possible (I've not been able to quickly find a public page using arguments on `<head>`, sorry):\r\n\r\n```html\r\n<!DOCTYPE html>\r\n<html>\r\n  <!-- head-without-argument.html -->\r\n  <head>\r\n    <title>Title</title>\r\n  </head>\r\n  <body>\r\n    <p>Foo</p>\r\n    <img src=\"./assets/image.jpg\">\r\n  </body>\r\n</html>\r\n```\r\n\r\n<!-- -->\r\n\r\n```html\r\n<!DOCTYPE html>\r\n<html>\r\n  <!-- head-with-argument.html -->\r\n  <head id=\"example\">\r\n    <title>Title</title>\r\n  </head>\r\n  <body>\r\n    <p>Foo</p>\r\n    <img src=\"./assets/image.jpg\">\r\n  </body>\r\n</html>\r\n```\r\n\r\nThen run the spider with `scrapy crawl example` and you'll see that:\r\n1. `head-without-argument.html` output renders resource correctly\r\n2. `head-with-argument.html` output doesn't render resource\r\n\r\n### How to fix the issue\r\n\r\nAt the very least, the literal `replace()` function should be replace by a regex replacement:\r\n```py\r\n if isinstance(response, HtmlResponse): \r\n     if b'<base' not in body: \r\n         repl = f'\\\\1<base href=\"{response.url}\">' \r\n         body = re.sub(b\"(<head.*?>)\", to_bytes(repl), body)\r\n```\r\n\r\n### Environment \r\n```\r\nScrapy       : 2.5.1\r\nlxml         : 4.6.3.0\r\nlibxml2      : 2.9.4\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 21.7.0\r\nPython       : 3.9.7 (default, Sep  3 2021, 04:31:11) - [Clang 12.0.5 (clang-1205.0.22.9)]\r\npyOpenSSL    : 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021)\r\ncryptography : 35.0.0\r\nPlatform     : macOS-11.6-arm64-arm-64bit\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5319/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5319/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5298", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5298/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5298/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5298/events", "html_url": "https://github.com/scrapy/scrapy/issues/5298", "id": 1037502069, "node_id": "I_kwDOAAgUXs491wZ1", "number": 5298, "title": "Tests failing with new Sybil", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2021-10-27T14:35:27Z", "updated_at": "2021-11-04T14:00:14Z", "closed_at": "2021-11-04T14:00:14Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Sybil 3.0.0 was just released, and at least the following change breaks our tests: `CodeBlockParser has been renamed to PythonCodeBlockParser`\r\n\r\n```python-traceback\r\ndocs/conftest.py:24: in <module>\r\n    CodeBlockParser(future_imports=['print_function']),\r\nE   TypeError: __init__() got an unexpected keyword argument 'future_imports'\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5298/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5298/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5286", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5286/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5286/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5286/events", "html_url": "https://github.com/scrapy/scrapy/issues/5286", "id": 1031744079, "node_id": "I_kwDOAAgUXs49fypP", "number": 5286, "title": "HTTPS TorGuard proxies time out", "user": {"login": "bezkos", "id": 22465838, "node_id": "MDQ6VXNlcjIyNDY1ODM4", "avatar_url": "https://avatars.githubusercontent.com/u/22465838?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bezkos", "html_url": "https://github.com/bezkos", "followers_url": "https://api.github.com/users/bezkos/followers", "following_url": "https://api.github.com/users/bezkos/following{/other_user}", "gists_url": "https://api.github.com/users/bezkos/gists{/gist_id}", "starred_url": "https://api.github.com/users/bezkos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bezkos/subscriptions", "organizations_url": "https://api.github.com/users/bezkos/orgs", "repos_url": "https://api.github.com/users/bezkos/repos", "events_url": "https://api.github.com/users/bezkos/events{/privacy}", "received_events_url": "https://api.github.com/users/bezkos/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2021-10-20T19:11:23Z", "updated_at": "2022-03-08T09:22:57Z", "closed_at": "2022-03-08T09:22:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "I used auth HTTP proxies with scrapy just fine.\r\nRecently my provider went from HTTP to SSL Proxies and scrapy stop to download through them.\r\nI dont know if its a bug report or new feature but can scrapy use SSL Proxies?\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5286/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5286/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5274", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5274/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5274/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5274/events", "html_url": "https://github.com/scrapy/scrapy/pull/5274", "id": 1023849043, "node_id": "PR_kwDOAAgUXs4tEuzg", "number": 5274, "title": "Removing unnecessary line from docs to prevent test failure to fix #5273", "user": {"login": "jmherbst", "id": 431342, "node_id": "MDQ6VXNlcjQzMTM0Mg==", "avatar_url": "https://avatars.githubusercontent.com/u/431342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jmherbst", "html_url": "https://github.com/jmherbst", "followers_url": "https://api.github.com/users/jmherbst/followers", "following_url": "https://api.github.com/users/jmherbst/following{/other_user}", "gists_url": "https://api.github.com/users/jmherbst/gists{/gist_id}", "starred_url": "https://api.github.com/users/jmherbst/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jmherbst/subscriptions", "organizations_url": "https://api.github.com/users/jmherbst/orgs", "repos_url": "https://api.github.com/users/jmherbst/repos", "events_url": "https://api.github.com/users/jmherbst/events{/privacy}", "received_events_url": "https://api.github.com/users/jmherbst/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2021-10-12T13:50:03Z", "updated_at": "2021-10-12T17:20:29Z", "closed_at": "2021-10-12T17:20:09Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5274", "html_url": "https://github.com/scrapy/scrapy/pull/5274", "diff_url": "https://github.com/scrapy/scrapy/pull/5274.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5274.patch", "merged_at": "2021-10-12T17:20:09Z"}, "body": "Fixes https://github.com/scrapy/scrapy/issues/5273", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5274/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5274/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5273", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5273/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5273/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5273/events", "html_url": "https://github.com/scrapy/scrapy/issues/5273", "id": 1023787771, "node_id": "I_kwDOAAgUXs49BcL7", "number": 5273, "title": "Doctest failure", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-10-12T12:53:24Z", "updated_at": "2021-10-12T17:20:09Z", "closed_at": "2021-10-12T17:20:09Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Merging #5256 introduced a doctest failure in `docs/intro/tutorial.rst`:\r\n\r\n```\r\nExpected:\r\n    Traceback (most recent call last):\r\n    File \"<console>\", line 1, in <module>\r\n    ...\r\n    IndexError: list index out of range\r\nGot:\r\n    Traceback (most recent call last):\r\n      File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/doctest.py\", line 1337, in __run\r\n        compileflags, 1), test.globs)\r\n      File \"<doctest None[0]>\", line 1, in <module>\r\n      File \"/home/runner/work/scrapy/scrapy/.tox/py/lib/python3.7/site-packages/parsel/selector.py\", line 70, in __getitem__\r\n        o = super(SelectorList, self).__getitem__(pos)\r\n    IndexError: list index out of range\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5273/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5273/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5237", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5237/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5237/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5237/events", "html_url": "https://github.com/scrapy/scrapy/issues/5237", "id": 983926974, "node_id": "MDU6SXNzdWU5ODM5MjY5NzQ=", "number": 5237, "title": "Scrapy > 2.3 prevents passing callback in cb_kwargs", "user": {"login": "jpmckinney", "id": 26463, "node_id": "MDQ6VXNlcjI2NDYz", "avatar_url": "https://avatars.githubusercontent.com/u/26463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpmckinney", "html_url": "https://github.com/jpmckinney", "followers_url": "https://api.github.com/users/jpmckinney/followers", "following_url": "https://api.github.com/users/jpmckinney/following{/other_user}", "gists_url": "https://api.github.com/users/jpmckinney/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpmckinney/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpmckinney/subscriptions", "organizations_url": "https://api.github.com/users/jpmckinney/orgs", "repos_url": "https://api.github.com/users/jpmckinney/repos", "events_url": "https://api.github.com/users/jpmckinney/events{/privacy}", "received_events_url": "https://api.github.com/users/jpmckinney/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/36", "html_url": "https://github.com/scrapy/scrapy/milestone/36", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/36/labels", "id": 6535042, "node_id": "MDk6TWlsZXN0b25lNjUzNTA0Mg==", "number": 36, "title": "2.6", "description": "[Async callback support](https://github.com/scrapy/scrapy/pull/4978).", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 9, "state": "closed", "created_at": "2021-03-11T14:28:09Z", "updated_at": "2022-03-04T09:08:50Z", "due_on": "2021-04-30T07:00:00Z", "closed_at": "2022-03-04T09:08:50Z"}, "comments": 3, "created_at": "2021-08-31T14:26:16Z", "updated_at": "2021-10-01T07:50:42Z", "closed_at": "2021-10-01T07:50:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "To reproduce:\r\n\r\n```bash\r\nscrapy startproject tutorial\r\ncd tutorial\r\nscrapy genspider example example.com\r\n```\r\n\r\nIn example.py\r\n\r\n```python\r\nimport scrapy\r\n\r\n\r\nclass ExampleSpider(scrapy.Spider):\r\n    name = 'example'\r\n\r\n    def start_requests(self):\r\n        yield scrapy.Request(\r\n            'http://example.com',\r\n            callback=self.parse_1,\r\n            cb_kwargs={'callback': self.parse_2}\r\n        )\r\n\r\n    def parse_1(self, response, **kwargs):\r\n        yield {'url': response.request.url}\r\n        yield scrapy.Request('https://httpbin.org/get', **kwargs)\r\n\r\n    def parse_2(self, response):\r\n        yield {'url': response.request.url}\r\n```\r\n\r\nThis works in Scrapy 2.3. In Scrapy > 2.3, it errors:\r\n\r\n```\r\n2021-08-31 10:24:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.com> (referer: None)\r\n2021-08-31 10:24:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://example.com> (referer: None)\r\nTraceback (most recent call last):\r\n  File \"lib/python3.6/site-packages/twisted/internet/defer.py\", line 1418, in _inlineCallbacks\r\n    result = g.send(result)\r\nStopIteration: <200 http://example.com>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"lib/python3.6/site-packages/scrapy/utils/defer.py\", line 55, in mustbe_deferred\r\n    result = f(*args, **kw)\r\n  File \"lib/python3.6/site-packages/scrapy/core/spidermw.py\", line 52, in _process_spider_input\r\n    return scrape_func(response, request, spider)\r\n  File \"lib/python3.6/site-packages/scrapy/core/scraper.py\", line 151, in call_spider\r\n    dfd.addCallback(callback, **result.request.cb_kwargs)\r\nTypeError: addCallback() got multiple values for argument 'callback'\r\n```\r\n\r\nI don't know if this scrapy commit is relevant to the change in behavior: https://github.com/scrapy/scrapy/commit/2aa4f3cbf96ad55aa4a1fa064758338daf16b110\r\n\r\nThis is a minimal example. Of course, in my application, I'm jumping through these hoops (controlling the callback of a subsequent request) to be able to reuse code in a complex project.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5237/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5237/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5221", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5221/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5221/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5221/events", "html_url": "https://github.com/scrapy/scrapy/pull/5221", "id": 959277446, "node_id": "MDExOlB1bGxSZXF1ZXN0NzAyNDE2MzMx", "number": 5221, "title": "Fixing tests for upcoming 3.10.", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2021-08-03T16:13:06Z", "updated_at": "2021-08-11T09:19:55Z", "closed_at": "2021-08-11T09:19:51Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5221", "html_url": "https://github.com/scrapy/scrapy/pull/5221", "diff_url": "https://github.com/scrapy/scrapy/pull/5221.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5221.patch", "merged_at": "2021-08-11T09:19:51Z"}, "body": "Closes: #5212.\r\n\r\nThere is an elusive problem in `SpiderLoaderTest` which I can't reproduce when running tests only for that module. It's related to #5160 because that test checks the warning list and gets an unexpected one (\"_SixMetaPathImporter.find_spec() not found;\").", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5221/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5221/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5212", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5212/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5212/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5212/events", "html_url": "https://github.com/scrapy/scrapy/issues/5212", "id": 948386267, "node_id": "MDU6SXNzdWU5NDgzODYyNjc=", "number": 5212, "title": "Test failures on 3.10", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-07-20T07:44:51Z", "updated_at": "2021-08-11T09:19:51Z", "closed_at": "2021-08-11T09:19:51Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I ran the test suite on 3.10b4, we have three test failures. One is easily fixed by replacing `collections` with `collections.abc` in `scrapy/utils/signal.py` (`collections.Sequence` no longer exists in 3.10 and is apparently deprecated before that), other two are less trivial: https://github.com/wRAR/scrapy/runs/3111526014?check_suite_focus=true", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5212/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 1, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5212/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5180", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5180/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5180/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5180/events", "html_url": "https://github.com/scrapy/scrapy/issues/5180", "id": 921169034, "node_id": "MDU6SXNzdWU5MjExNjkwMzQ=", "number": 5180, "title": "versionadded inside a warning in CrawlSpider docs", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-06-15T08:58:17Z", "updated_at": "2021-06-29T12:54:23Z", "closed_at": "2021-06-29T12:54:23Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://docs.scrapy.org/en/latest/topics/spiders.html#crawlspider has a warning block that includes the \"New in version\" line.\r\n\r\nBoth indenting the warning block (not sure what's the best practice for the indentation here; also, XMLFeedSpider below has the same block which should have the same indentation I think) and moving `versionadded` before it (I think I don't like it) will work but I don't know which is the correct way to position these blocks.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5180/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5180/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5160", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5160/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5160/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5160/events", "html_url": "https://github.com/scrapy/scrapy/pull/5160", "id": 899693077, "node_id": "MDExOlB1bGxSZXF1ZXN0NjUxMzU4OTg2", "number": 5160, "title": "Fix tests that expect a specific warning", "user": {"login": "whalebot-helmsman", "id": 1234272, "node_id": "MDQ6VXNlcjEyMzQyNzI=", "avatar_url": "https://avatars.githubusercontent.com/u/1234272?v=4", "gravatar_id": "", "url": "https://api.github.com/users/whalebot-helmsman", "html_url": "https://github.com/whalebot-helmsman", "followers_url": "https://api.github.com/users/whalebot-helmsman/followers", "following_url": "https://api.github.com/users/whalebot-helmsman/following{/other_user}", "gists_url": "https://api.github.com/users/whalebot-helmsman/gists{/gist_id}", "starred_url": "https://api.github.com/users/whalebot-helmsman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/whalebot-helmsman/subscriptions", "organizations_url": "https://api.github.com/users/whalebot-helmsman/orgs", "repos_url": "https://api.github.com/users/whalebot-helmsman/repos", "events_url": "https://api.github.com/users/whalebot-helmsman/events{/privacy}", "received_events_url": "https://api.github.com/users/whalebot-helmsman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/39", "html_url": "https://github.com/scrapy/scrapy/milestone/39", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/39/labels", "id": 7735762, "node_id": "MI_kwDOAAgUXs4AdgnS", "number": 39, "title": "2.7", "description": "", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 13, "state": "closed", "created_at": "2022-03-04T09:08:11Z", "updated_at": "2022-10-17T17:16:13Z", "due_on": "2022-05-17T07:00:00Z", "closed_at": "2022-10-17T17:16:13Z"}, "comments": 10, "created_at": "2021-05-24T14:06:02Z", "updated_at": "2022-10-13T08:50:15Z", "closed_at": "2022-10-13T08:50:14Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/5160", "html_url": "https://github.com/scrapy/scrapy/pull/5160", "diff_url": "https://github.com/scrapy/scrapy/pull/5160.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/5160.patch", "merged_at": null}, "body": "Two fixes a here:\r\n- solution for https://github.com/pypa/pip/issues/9215 in our python3.8 environment. https://github.com/scrapy/scrapy/pull/5146/checks?check_run_id=2570524886 python3.8 runs are killed by 6 hours timeout now.\r\n- don't rely on warnings order in tests", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5160/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5160/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5157", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5157/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5157/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5157/events", "html_url": "https://github.com/scrapy/scrapy/issues/5157", "id": 899019553, "node_id": "MDU6SXNzdWU4OTkwMTk1NTM=", "number": 5157, "title": "FileFeedStoragePreFeedOptionsTest fails if /tmp/foobar already exists with different ownership", "user": {"login": "risicle", "id": 807447, "node_id": "MDQ6VXNlcjgwNzQ0Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/807447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/risicle", "html_url": "https://github.com/risicle", "followers_url": "https://api.github.com/users/risicle/followers", "following_url": "https://api.github.com/users/risicle/following{/other_user}", "gists_url": "https://api.github.com/users/risicle/gists{/gist_id}", "starred_url": "https://api.github.com/users/risicle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/risicle/subscriptions", "organizations_url": "https://api.github.com/users/risicle/orgs", "repos_url": "https://api.github.com/users/risicle/repos", "events_url": "https://api.github.com/users/risicle/events{/privacy}", "received_events_url": "https://api.github.com/users/risicle/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-05-23T13:23:03Z", "updated_at": "2021-08-05T19:23:12Z", "closed_at": "2021-08-05T19:23:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "Quick one - if, for instance, you're running the the scrapy test suite in some sort of CI setup where builds get performed by random different dedicated \"build users\", you'll end up in a situation where `/tmp/foobar` already exists, owned by a different user. At which point `FileFeedStoragePreFeedOptionsTest` will fail:\r\n\r\n```\r\nE       PermissionError: [Errno 13] Permission denied: '/tmp/foobar'\r\n```\r\n\r\nFairly trivial to fix - you could put a random suffix on the filename.. better, generate a directory to contain it using `tempfile.mkdtemp`.. many options.\r\n\r\nFull build failure log: https://nix-cache.s3.amazonaws.com/log/5fdywg4w7s6cyf224j42yn9619kw5gw1-python3.8-Scrapy-2.4.1.drv\r\n\r\n### Versions\r\n\r\nScrapy 2.4.1, python 3.8, macos 10.15", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5157/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5157/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5105", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5105/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5105/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5105/events", "html_url": "https://github.com/scrapy/scrapy/issues/5105", "id": 862700381, "node_id": "MDU6SXNzdWU4NjI3MDAzODE=", "number": 5105, "title": "Scrapy is definitely slow when working from cache", "user": {"login": "dchaplinsky", "id": 131186, "node_id": "MDQ6VXNlcjEzMTE4Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/131186?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dchaplinsky", "html_url": "https://github.com/dchaplinsky", "followers_url": "https://api.github.com/users/dchaplinsky/followers", "following_url": "https://api.github.com/users/dchaplinsky/following{/other_user}", "gists_url": "https://api.github.com/users/dchaplinsky/gists{/gist_id}", "starred_url": "https://api.github.com/users/dchaplinsky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dchaplinsky/subscriptions", "organizations_url": "https://api.github.com/users/dchaplinsky/orgs", "repos_url": "https://api.github.com/users/dchaplinsky/repos", "events_url": "https://api.github.com/users/dchaplinsky/events{/privacy}", "received_events_url": "https://api.github.com/users/dchaplinsky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 20, "created_at": "2021-04-20T11:06:33Z", "updated_at": "2021-05-09T21:43:32Z", "closed_at": "2021-04-26T18:09:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\nI'm using scrapy with cache enabled to first crawl the pages I need over night and then polish the extraction, while working from cache. Suddenly, the speed of the processing of cached is pages quite slow, below 2k pages per minute. My data processing is trivial, my datastorage is mongo (I've tried to disable it to eliminate extra-factor, but that didn't affected the speed), my CPU/IO isn't even sweating. I've tried to bump `CONCURRENT_ITEMS` to a higher value, but got no result. I'm using twisted reactor. More than that, on decent internet connection my crawling speed on empty cache is roughly the same (1800 items per second).\r\n\r\nBelow are my cache settings.\r\n```\r\nHTTPCACHE_ENABLED = True\r\nHTTPCACHE_EXPIRATION_SECS = 0\r\nHTTPCACHE_DIR = \"httpcache\"\r\nHTTPCACHE_IGNORE_HTTP_CODES = []\r\nHTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\r\n```\r\n### Steps to Reproduce\r\n\r\n1. Crawl the website and cache all the pages\r\n2. Rerun the spider on cache\r\n3. Watch slow processing speed\r\n\r\n**Expected behavior:**\r\nReasonably higher parsing speed when working from cache\r\n\r\n**Actual behavior:** \r\nSpeed of parsing is quite low and basically the same as with empty cache on decent connection.\r\n\r\n**Reproduces how often:** \r\nAll of my spiders are suffering from this behavior.\r\n\r\n### Versions\r\n\r\n```\r\nScrapy       : 2.5.0\r\nlxml         : 4.6.3.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 21.2.0\r\nPython       : 3.9.1 (default, Apr 12 2021, 01:27:54) - [Clang 10.0.0 (clang-1000.10.44.4)]\r\npyOpenSSL    : 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021)\r\ncryptography : 3.4.7\r\nPlatform     : macOS-10.13.6-x86_64-i386-64bit\r\n```\r\n\r\n### Additional context\r\n\r\nMy full settings.py is below:\r\n```pyhon\r\nimport os\r\nfrom urllib.parse import quote_plus\r\n\r\n\r\ndef get_env_str(k, default):\r\n    return os.environ.get(k, default)\r\n\r\n\r\ndef get_env_int(k, default):\r\n    return int(get_env_str(k, default))\r\n\r\n\r\nBOT_NAME = \"corpora\"\r\n\r\nSPIDER_MODULES = [\"corpora.spiders\"]\r\nNEWSPIDER_MODULE = \"corpora.spiders\"\r\n\r\n\r\nROBOTSTXT_OBEY = False\r\n\r\n\r\nAUTOTHROTTLE_ENABLED = False\r\nAUTOTHROTTLE_START_DELAY = 5\r\nAUTOTHROTTLE_MAX_DELAY = 60\r\n\r\nHTTPCACHE_ENABLED = True\r\nHTTPCACHE_EXPIRATION_SECS = 0\r\nHTTPCACHE_DIR = \"httpcache\"\r\nHTTPCACHE_IGNORE_HTTP_CODES = []\r\nHTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\r\n\r\n\r\nITEM_PIPELINES = {\r\n    \"scrapy.pipelines.files.FilesPipeline\": 1,\r\n    \"corpora.pipelines.MongoDBPipeline\": 9000,\r\n}\r\n\r\nFILES_STORE = \"nanu_pdfs\"\r\n\r\nDOWNLOAD_WARNSIZE = 3355443200\r\nDOWNLOAD_TIMEOUT = 1800\r\nHTTPCACHE_IGNORE_HTTP_CODES = [500, 501, 502, 503, 401, 403]\r\nRETRY_ENABLED = True\r\n\r\nMONGODB_HOST = quote_plus(get_env_str(\"MONGODB_HOST\", \"localhost\"))\r\nMONGODB_PORT = get_env_int(\"MONGODB_PORT\", 27017)\r\nMONGODB_USERNAME = quote_plus(get_env_str(\"MONGODB_USERNAME\", \"\"))\r\nMONGODB_PASSWORD = quote_plus(get_env_str(\"MONGODB_PASSWORD\", \"\"))\r\nMONGODB_AUTH_DB = get_env_str(\"MONGODB_AUTH_DB\", \"admin\")\r\nMONGODB_DB = get_env_str(\"MONGODB_DB\", \"ubertext\")\r\nMONGODB_CONNECTION_POOL_KWARGS = {}\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5105/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5105/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5085", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5085/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5085/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5085/events", "html_url": "https://github.com/scrapy/scrapy/issues/5085", "id": 852319744, "node_id": "MDU6SXNzdWU4NTIzMTk3NDQ=", "number": 5085, "title": "HTTP2 test failures with some OpenSSL", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-04-07T11:41:25Z", "updated_at": "2021-04-15T07:20:52Z", "closed_at": "2021-04-14T17:02:00Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "As noticed on [Conda](https://dev.azure.com/conda-forge/84710dde-1620-425b-80d0-4cf5baca359d/_apis/build/builds/300551/logs/46), the testsuite can fail with a bunch of SSL-related errors in some cases. While it works on the Github CI and with local tox, it fails in the Conda CI (on different OSes) and on Debian sid. Looks like it may be caused by differences in some OpenSSL configuration.\r\n\r\nNormal tox runs will install cryptography from PyPI, which links OpenSSL statically (for all OSes, I suspect). On Debian I tested with the system OpenSSL 1.1.1k. Conda builds use cryptography from conda-forge, which links OpenSSL dynamically, and openssl from conda-forge as well.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5085/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5085/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5080", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5080/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5080/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5080/events", "html_url": "https://github.com/scrapy/scrapy/issues/5080", "id": 850245240, "node_id": "MDU6SXNzdWU4NTAyNDUyNDA=", "number": 5080, "title": "Allow building the documentation with make in systems without /bin/bash", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-04-05T09:46:24Z", "updated_at": "2021-04-21T09:30:50Z", "closed_at": "2021-04-21T09:30:50Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://github.com/scrapy/scrapy/commit/595146e158b1efec432b35128aab59878da81295#r48800250\r\n\r\nI\u2019m guessing the current code exists in line with https://stackoverflow.com/a/589300/939364, in order to force Bash to be used (instead of something like `sh`).\r\n\r\nIf there is a way to set SHELL to Bash so that it finds the right path to Bash regardless of the system, that would be great. Otherwise, maybe we can check if there is any Bash-specific code in this `Makefile`. If all commands work as intended with `sh`, for example, maybe we can just remove this line as suggested.\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5080/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5080/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5079", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5079/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5079/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5079/events", "html_url": "https://github.com/scrapy/scrapy/issues/5079", "id": 850141586, "node_id": "MDU6SXNzdWU4NTAxNDE1ODY=", "number": 5079, "title": "ImagePipeline breaks on invalid images", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 24, "created_at": "2021-04-05T07:08:04Z", "updated_at": "2021-07-13T16:57:07Z", "closed_at": "2021-07-13T16:27:56Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "@apalala reported this issue when a site sends some invalid images, and suggested a fix for the spider middleware:\r\n\r\n```\r\n        image_stream = self.get_images(response, request, info, item=item)\r\n        while True:\r\n            try:\r\n                path, image, buf = next(image_stream)\r\n            except StopIteration:\r\n                break\r\n            except Exception:\r\n                continue\r\n```\r\n\r\nI\u2019ve not checked if there\u2019s a cleaner fix possible (i.e. closer to the call to Pillow code), but it should be trivial to fix either way. I suspect writing a test may be the hardest part here.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5079/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5079/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5020", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/5020/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/5020/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/5020/events", "html_url": "https://github.com/scrapy/scrapy/issues/5020", "id": 819988913, "node_id": "MDU6SXNzdWU4MTk5ODg5MTM=", "number": 5020, "title": "test_pipeline_images.py fails with \"TypeError: Skipped expected string as 'msg' parameter, got 'bool' instead.\"", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2021-03-02T12:51:14Z", "updated_at": "2021-03-19T17:39:44Z", "closed_at": "2021-03-19T17:39:44Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "See e.g. https://github.com/scrapy/scrapy/pull/5019/checks?check_run_id=2012658916\r\n\r\nThis should be related to the skip attribute, though I'm not sure why did it start happening now.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/5020/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/5020/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4986", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4986/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4986/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4986/events", "html_url": "https://github.com/scrapy/scrapy/pull/4986", "id": 806213209, "node_id": "MDExOlB1bGxSZXF1ZXN0NTcxNjc4MTU0", "number": 4986, "title": "Skip uvloop 0.15.0+ on py36.", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-02-11T09:25:14Z", "updated_at": "2021-02-11T11:23:59Z", "closed_at": "2021-02-11T11:07:28Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4986", "html_url": "https://github.com/scrapy/scrapy/pull/4986", "diff_url": "https://github.com/scrapy/scrapy/pull/4986.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4986.patch", "merged_at": "2021-02-11T11:07:28Z"}, "body": "uvloop 0.15.0, released yesterday, dropped support for Python 3.6 and lower.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4986/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4986/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4976", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4976/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4976/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4976/events", "html_url": "https://github.com/scrapy/scrapy/issues/4976", "id": 801370954, "node_id": "MDU6SXNzdWU4MDEzNzA5NTQ=", "number": 4976, "title": "Fix and document asyncio reactor problems on Windows", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 318523681, "node_id": "MDU6TGFiZWwzMTg1MjM2ODE=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/Windows", "name": "Windows", "color": "fad8c7", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/36", "html_url": "https://github.com/scrapy/scrapy/milestone/36", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/36/labels", "id": 6535042, "node_id": "MDk6TWlsZXN0b25lNjUzNTA0Mg==", "number": 36, "title": "2.6", "description": "[Async callback support](https://github.com/scrapy/scrapy/pull/4978).", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 9, "state": "closed", "created_at": "2021-03-11T14:28:09Z", "updated_at": "2022-03-04T09:08:50Z", "due_on": "2021-04-30T07:00:00Z", "closed_at": "2022-03-04T09:08:50Z"}, "comments": 13, "created_at": "2021-02-04T15:08:05Z", "updated_at": "2023-01-26T20:03:36Z", "closed_at": "2021-12-31T19:38:10Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "As described in https://twistedmatrix.com/trac/ticket/9766 you cannot just enable AsyncioSelectorReactor on Windows with recent Python, you either need fixed Twisted (which is not released yet, the merged fix is https://github.com/twisted/twisted/pull/1338) or, supposedly, add some manual fix as documented [here](https://github.com/twisted/twisted/blob/09b96850c2ebcb635f448ed3f9bbf5f157be3693/src/twisted/internet/asyncioreactor.py#L35-L44). So if it's possible to add this code to Scrapy we should probably do that, at least until the next Twisted release, and even after it we should document that new enough Twisted is needed in this use case. ", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4976/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4976/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4962", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4962/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4962/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4962/events", "html_url": "https://github.com/scrapy/scrapy/issues/4962", "id": 792215015, "node_id": "MDU6SXNzdWU3OTIyMTUwMTU=", "number": 4962, "title": "FEED_URI_PARAMS: custom params throws KeyError", "user": {"login": "jas0nkim", "id": 768619, "node_id": "MDQ6VXNlcjc2ODYxOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/768619?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jas0nkim", "html_url": "https://github.com/jas0nkim", "followers_url": "https://api.github.com/users/jas0nkim/followers", "following_url": "https://api.github.com/users/jas0nkim/following{/other_user}", "gists_url": "https://api.github.com/users/jas0nkim/gists{/gist_id}", "starred_url": "https://api.github.com/users/jas0nkim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jas0nkim/subscriptions", "organizations_url": "https://api.github.com/users/jas0nkim/orgs", "repos_url": "https://api.github.com/users/jas0nkim/repos", "events_url": "https://api.github.com/users/jas0nkim/events{/privacy}", "received_events_url": "https://api.github.com/users/jas0nkim/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2021-01-22T18:24:19Z", "updated_at": "2022-01-28T17:30:30Z", "closed_at": "2022-01-28T17:30:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\nWith Scrapy version 2.4.1, any custom feed uri params (FEED_URI_PARAMS) throws KeyError. \r\n\r\n### Steps to Reproduce\r\n\r\n1. on myproject/settings.py\r\nFEED_URI_PARAMS = 'myproject.utils.uri_params'\r\n\r\n2. on myproject/utils.py\r\ndef uri_params(params, spider):\r\n    return {**params, 'spider_name': spider.name}\r\n\r\n3. scrapy crawl <spider_name> -o \"%(spider_name)s.jl\"\r\n\r\n**Expected behavior:** Should export the items to a jsonline file having the spider name.\r\n\r\n**Actual behavior:**\r\nERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x7fc68cb20bb0>>\r\nTraceback (most recent call last):\r\n  File \"/PROJECT_ROOT/.venv/lib/python3.8/site-packages/scrapy/utils/defer.py\", line 157, in maybeDeferred_coro\r\n    result = f(*args, **kw)\r\n  File \"/PROJECT_ROOT/.venv/lib/python3.8/site-packages/pydispatch/robustapply.py\", line 55, in robustApply\r\n    return receiver(*arguments, **named)\r\n  File \"/PROJECT_ROOT/.venv/lib/python3.8/site-packages/scrapy/extensions/feedexport.py\", line 294, in open_spider\r\n    uri=uri % uri_params,\r\nKeyError: 'spider_name'\r\n\r\n**Reproduces how often:** Everytime\r\n\r\n### Versions\r\nScrapy       : 2.4.1\r\nlxml         : 4.6.1.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 20.3.0\r\nPython       : 3.8.5 (default, Jul 28 2020, 12:59:40) - [GCC 9.3.0]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020)\r\ncryptography : 3.2.1\r\nPlatform     : Linux-4.19.104-microsoft-standard-x86_64-with-glibc2.29\r\n\r\n### Additional context\r\n\r\non line 480 in /scrapy/extensions/feedexport.py,\r\n**returns params** should be changed to **return uripar_function(params, spider)**", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4962/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4962/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4920", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4920/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4920/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4920/events", "html_url": "https://github.com/scrapy/scrapy/issues/4920", "id": 760391414, "node_id": "MDU6SXNzdWU3NjAzOTE0MTQ=", "number": 4920, "title": "Shell fetch does not use http_proxy", "user": {"login": "matsievskiysv", "id": 26824900, "node_id": "MDQ6VXNlcjI2ODI0OTAw", "avatar_url": "https://avatars.githubusercontent.com/u/26824900?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matsievskiysv", "html_url": "https://github.com/matsievskiysv", "followers_url": "https://api.github.com/users/matsievskiysv/followers", "following_url": "https://api.github.com/users/matsievskiysv/following{/other_user}", "gists_url": "https://api.github.com/users/matsievskiysv/gists{/gist_id}", "starred_url": "https://api.github.com/users/matsievskiysv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matsievskiysv/subscriptions", "organizations_url": "https://api.github.com/users/matsievskiysv/orgs", "repos_url": "https://api.github.com/users/matsievskiysv/repos", "events_url": "https://api.github.com/users/matsievskiysv/events{/privacy}", "received_events_url": "https://api.github.com/users/matsievskiysv/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-12-09T14:45:19Z", "updated_at": "2020-12-13T09:25:46Z", "closed_at": "2020-12-13T09:25:46Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\nWhen in shell mode,`fetch` function does not use proxy.\r\n\r\n### Steps to Reproduce\r\n\r\n1. `http_proxy=127.0.0.1:8118 scrapy shell -L WARN ident.me`\r\n2. `print(response.body)`. It should show your proxy IP\r\n3. `fetch('https://ident.me')`\r\n3. `print(response.body)`. It should show your real IP\r\n\r\n**Expected behavior:**\r\nAll outgoing connections should use `http_proxy`\r\n\r\n**Actual behavior:**\r\n`fetch` does not use `http_proxy`\r\n\r\n**Reproduces how often:**\r\n\r\nAlways\r\n\r\n### Versions\r\n\r\n```\r\nScrapy       : 2.4.1\r\nlxml         : 4.6.2.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 20.3.0\r\nPython       : 3.9.1 (default, Dec  8 2020, 07:51:42) - [GCC 10.2.0]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020)\r\ncryptography : 3.2.1\r\nPlatform     : Linux-5.9.0-4-amd64-x86_64-with-glibc2.31\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4920/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4920/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4907", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4907/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4907/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4907/events", "html_url": "https://github.com/scrapy/scrapy/issues/4907", "id": 752149829, "node_id": "MDU6SXNzdWU3NTIxNDk4Mjk=", "number": 4907, "title": "Typo in XML exporter serialize_field in Scrapy docs", "user": {"login": "Crank1d", "id": 11263105, "node_id": "MDQ6VXNlcjExMjYzMTA1", "avatar_url": "https://avatars.githubusercontent.com/u/11263105?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Crank1d", "html_url": "https://github.com/Crank1d", "followers_url": "https://api.github.com/users/Crank1d/followers", "following_url": "https://api.github.com/users/Crank1d/following{/other_user}", "gists_url": "https://api.github.com/users/Crank1d/gists{/gist_id}", "starred_url": "https://api.github.com/users/Crank1d/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Crank1d/subscriptions", "organizations_url": "https://api.github.com/users/Crank1d/orgs", "repos_url": "https://api.github.com/users/Crank1d/repos", "events_url": "https://api.github.com/users/Crank1d/events{/privacy}", "received_events_url": "https://api.github.com/users/Crank1d/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-11-27T10:31:38Z", "updated_at": "2020-11-29T20:28:13Z", "closed_at": "2020-11-29T20:28:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "Im using code from Scrapy documentation - https://docs.scrapy.org/en/latest/topics/exporters.html, with \"Product\" class item created\r\n```\r\nfrom scrapy.exporter import XmlItemExporter\r\n\r\nclass ProductXmlExporter(XmlItemExporter):\r\n\r\n    def serialize_field(self, field, name, value):\r\n        if field == 'price':\r\n            return f'$ {str(value)}'\r\n        return super(Product, self).serialize_field(field, name, value)\r\n\r\n```\r\nand always get error from command line\r\n\r\n**return super(Product, self).serialize_field(field, name, value)\r\nTypeError: super(Product, obj): obj must be an instance or subtype of type**\r\n\r\nIm relatively new to Python, but AFAIK, super function cannot accept Product class, it should be ProductXmlExporter, but when I change it, nothing happens to \"price\" field in XML export file.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4907/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4907/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4893", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4893/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4893/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4893/events", "html_url": "https://github.com/scrapy/scrapy/issues/4893", "id": 745544329, "node_id": "MDU6SXNzdWU3NDU1NDQzMjk=", "number": 4893, "title": "Corutines not working with signal spider_opened - spider freezes", "user": {"login": "ivanprado", "id": 895720, "node_id": "MDQ6VXNlcjg5NTcyMA==", "avatar_url": "https://avatars.githubusercontent.com/u/895720?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ivanprado", "html_url": "https://github.com/ivanprado", "followers_url": "https://api.github.com/users/ivanprado/followers", "following_url": "https://api.github.com/users/ivanprado/following{/other_user}", "gists_url": "https://api.github.com/users/ivanprado/gists{/gist_id}", "starred_url": "https://api.github.com/users/ivanprado/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ivanprado/subscriptions", "organizations_url": "https://api.github.com/users/ivanprado/orgs", "repos_url": "https://api.github.com/users/ivanprado/repos", "events_url": "https://api.github.com/users/ivanprado/events{/privacy}", "received_events_url": "https://api.github.com/users/ivanprado/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 3270783977, "node_id": "MDU6TGFiZWwzMjcwNzgzOTc3", "url": "https://api.github.com/repos/scrapy/scrapy/labels/asyncio", "name": "asyncio", "color": "fef2c0", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-11-18T10:42:15Z", "updated_at": "2021-08-17T15:06:48Z", "closed_at": "2020-11-18T11:11:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\nThe following spider was run with `asyncio` reactor enabled. It freezes:\r\n\r\n```py\r\nfrom scrapy import Spider, signals\r\nfrom scrapy.http import Response\r\n\r\n\r\nclass AsyncioSpider(Spider):\r\n    name = \"asyncio\"\r\n    start_urls = [\"http://blog.scrapinghub.com\"]\r\n\r\n    @classmethod\r\n    def from_crawler(cls, crawler, *args, **kwargs):\r\n        spider = super(AsyncioSpider, cls).from_crawler(crawler, *args, **kwargs)\r\n        crawler.signals.connect(spider.spider_opened, signals.spider_opened)\r\n        return spider\r\n\r\n    async def spider_opened(self):\r\n        print(\"hey!\")\r\n\r\n    def parse(self, response: Response):\r\n        yield dict(url=response.url, lenght=len(response.text))\r\n```\r\n\r\nWhen Ctrl+C is pressed, the following exception can be seen:\r\n\r\n```\r\n2020-11-18 10:38:09 [twisted] CRITICAL: \r\nTraceback (most recent call last):\r\n  File \"/home/ivan/Documentos/scrapinghub/dev/autocrawl_env/lib/python3.8/site-packages/scrapy/crawler.py\", line 109, in stop\r\n    yield defer.maybeDeferred(self.engine.stop)\r\n  File \"/home/ivan/Documentos/scrapinghub/dev/autocrawl_env/lib/python3.8/site-packages/twisted/internet/defer.py\", line 151, in maybeDeferred\r\n    result = f(*args, **kw)\r\n  File \"/home/ivan/Documentos/scrapinghub/dev/autocrawl_env/lib/python3.8/site-packages/scrapy/core/engine.py\", line 87, in stop\r\n    raise RuntimeError(\"Engine not running\")\r\nRuntimeError: Engine not running\r\n```\r\n\r\nNote that if `async` is removed from the method `spider_opened`, then it works. It suggests that this signal is not supporting coroutines properly. \r\n\r\n### Steps to Reproduce\r\n\r\nRun the given spider with asyncio reactor enabled.\r\n\r\n**Expected behavior:** [What you expect to happen]\r\n\r\nThe spider to run properly and corotines working well with `spider_opened` signal.\r\n\r\n**Actual behavior:** [What actually happens]\r\n\r\nThe spider freezes\r\n\r\n**Reproduces how often:** [What percentage of the time does it reproduce?]\r\n\r\nAlways\r\n\r\n### Versions\r\n\r\n```\r\nScrapy       : 2.3.0\r\nlxml         : 4.5.2.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 20.3.0\r\nPython       : 3.8.5 (default, Jul 20 2020, 19:48:14) - [GCC 7.5.0]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020)\r\ncryptography : 3.1\r\nPlatform     : Linux-5.7.1-050701-generic-x86_64-with-glibc2.27\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4893/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4893/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4892", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4892/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4892/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4892/events", "html_url": "https://github.com/scrapy/scrapy/issues/4892", "id": 745436283, "node_id": "MDU6SXNzdWU3NDU0MzYyODM=", "number": 4892, "title": "Update all links in installation guide", "user": {"login": "akshaysharmajs", "id": 42249933, "node_id": "MDQ6VXNlcjQyMjQ5OTMz", "avatar_url": "https://avatars.githubusercontent.com/u/42249933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akshaysharmajs", "html_url": "https://github.com/akshaysharmajs", "followers_url": "https://api.github.com/users/akshaysharmajs/followers", "following_url": "https://api.github.com/users/akshaysharmajs/following{/other_user}", "gists_url": "https://api.github.com/users/akshaysharmajs/gists{/gist_id}", "starred_url": "https://api.github.com/users/akshaysharmajs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akshaysharmajs/subscriptions", "organizations_url": "https://api.github.com/users/akshaysharmajs/orgs", "repos_url": "https://api.github.com/users/akshaysharmajs/repos", "events_url": "https://api.github.com/users/akshaysharmajs/events{/privacy}", "received_events_url": "https://api.github.com/users/akshaysharmajs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-11-18T08:12:49Z", "updated_at": "2020-12-03T09:56:37Z", "closed_at": "2020-12-03T09:56:37Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Some of the links like [cryptography installation](https://cryptography.io/en/latest/installation/) in file `install.rst` are outdated and require an update. \r\nIt will be nice to check for other parts of the documentation for the same issue.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4892/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4892/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4887", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4887/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4887/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4887/events", "html_url": "https://github.com/scrapy/scrapy/issues/4887", "id": 742957250, "node_id": "MDU6SXNzdWU3NDI5NTcyNTA=", "number": 4887, "title": "Not started engine if async open_spider", "user": {"login": "tonal", "id": 316216, "node_id": "MDQ6VXNlcjMxNjIxNg==", "avatar_url": "https://avatars.githubusercontent.com/u/316216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tonal", "html_url": "https://github.com/tonal", "followers_url": "https://api.github.com/users/tonal/followers", "following_url": "https://api.github.com/users/tonal/following{/other_user}", "gists_url": "https://api.github.com/users/tonal/gists{/gist_id}", "starred_url": "https://api.github.com/users/tonal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tonal/subscriptions", "organizations_url": "https://api.github.com/users/tonal/orgs", "repos_url": "https://api.github.com/users/tonal/repos", "events_url": "https://api.github.com/users/tonal/events{/privacy}", "received_events_url": "https://api.github.com/users/tonal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 3270783977, "node_id": "MDU6TGFiZWwzMjcwNzgzOTc3", "url": "https://api.github.com/repos/scrapy/scrapy/labels/asyncio", "name": "asyncio", "color": "fef2c0", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-11-14T08:08:11Z", "updated_at": "2021-08-17T15:07:00Z", "closed_at": "2020-11-16T14:38:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n[Description of the issue]\r\n\r\nIn 2.4.0 version\r\nIf the pipelines or extensions has an **async** signal handler **open_spider**, the engine will not start.\r\n\r\nBat 2.3.0 version work\r\n\r\n### Steps to Reproduce\r\n\r\n1. pip install Scrapy uvloop\r\n2. file quotes_spider.py:\r\n```python\r\n# -*- coding: utf-8 -*-\r\n\r\nfrom scrapy import signals, Spider\r\n\r\n\r\nclass QuotesSpider(Spider):\r\n    name = 'quotes'\r\n    start_urls = [\r\n        'http://quotes.toscrape.com/tag/humor/',\r\n    ]\r\n\r\n    custom_settings = dict(\r\n        TWISTED_REACTOR='twisted.internet.asyncioreactor.AsyncioSelectorReactor',\r\n        ASYNCIO_EVENT_LOOP='uvloop.Loop',\r\n        EXTENSIONS={'quotes_spider.AsyncOpenExt': 10},\r\n    )\r\n\r\n    def parse(self, response, **kwargs):\r\n        for quote in response.css('div.quote'):\r\n            yield {\r\n                'author': quote.xpath('span/small/text()').get(),\r\n                'text': quote.css('span.text::text').get(),\r\n            }\r\n\r\n        next_page = response.css('li.next a::attr(\"href\")').get()\r\n        if next_page is not None:\r\n            yield response.follow(next_page, self.parse)\r\n\r\n\r\nclass AsyncOpenExt:\r\n\r\n    @classmethod\r\n    def from_crawler(cls, crawler):\r\n        ext = cls()\r\n        crawler.signals.connect(ext.spider_opened, signal=signals.spider_opened)\r\n        return ext\r\n\r\n    async def spider_opened(self, spider:Spider, signal=None, sender=None):\r\n        pass\r\n```\r\n3. Start scrapy:\r\n```bash\r\n$ scrapy runspider quotes_spider.py -o quotes.jl -s TWISTED_REACTOR=twisted.internet.asyncioreactor.AsyncioSelectorReactor -s ASYNCIO_EVENT_LOOP=uvloop.Loop\r\n```\r\n**Expected behavior:**\r\n```\r\n2020-11-14 14:39:49 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: scrapybot)\r\n2020-11-14 14:39:49 [scrapy.utils.log] INFO: Versions: lxml 4.6.1.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.8.6 (default, Sep 28 2020, 10:21:29) - [GCC 9.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.2.1, Platform Linux-5.4.0-53-generic-x86_64-with-glibc2.2.5\r\n2020-11-14 14:39:49 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\r\n...\r\n2020-11-14 14:39:49 [scrapy.middleware] INFO: Enabled item pipelines:\r\n[]\r\n2020-11-14 14:39:49 [scrapy.core.engine] INFO: Spider opened\r\n2020-11-14 14:39:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2020-11-14 14:39:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\r\n2020-11-14 14:39:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/tag/humor/> (referer: None)\r\n...\r\n2020-11-14 14:39:50 [scrapy.core.engine] INFO: Closing spider (finished)\r\n2020-11-14 14:39:50 [scrapy.extensions.feedexport] INFO: Stored jl feed (12 items) in: quotes.jl\r\n2020-11-14 14:39:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\r\n{'downloader/request_bytes': 513,\r\n...\r\n 'finish_reason': 'finished',\r\n...\r\n 'start_time': datetime.datetime(2020, 11, 14, 7, 39, 49, 965142)}\r\n2020-11-14 14:39:50 [scrapy.core.engine] INFO: Spider closed (finished)\r\n```\r\n**Actual behavior:**\r\n```\r\n2020-11-14 14:41:39 [scrapy.utils.log] INFO: Scrapy 2.4.0 started (bot: scrapybot)\r\n2020-11-14 14:41:39 [scrapy.utils.log] INFO: Versions: lxml 4.6.1.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.8.6 (default, Sep 28 2020, 10:21:29) - [GCC 9.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.2.1, Platform Linux-5.4.0-53-generic-x86_64-with-glibc2.2.5\r\n2020-11-14 14:41:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\r\n2020-11-14 14:41:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: uvloop.Loop\r\n...\r\n2020-11-14 14:41:40 [scrapy.middleware] INFO: Enabled item pipelines:\r\n[]\r\n2020-11-14 14:41:40 [scrapy.core.engine] INFO: Spider opened\r\n2020-11-14 14:41:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2020-11-14 14:41:40 [asyncio] DEBUG: Using selector: EpollSelector\r\n2020-11-14 14:42:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n^C2020-11-14 14:42:51 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force \r\nUnhandled error in Deferred:\r\n2020-11-14 14:42:51 [twisted] CRITICAL: Unhandled error in Deferred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/tonal/.pyenv/versions/3.8.6/envs/err-scrapy-async/lib/python3.8/site-packages/twisted/internet/defer.py\", line 1613, in unwindGenerator\r\n    return _cancellableInlineCallbacks(gen)\r\n  File \"/home/tonal/.pyenv/versions/3.8.6/envs/err-scrapy-async/lib/python3.8/site-packages/twisted/internet/defer.py\", line 1529, in _cancellableInlineCallbacks\r\n    _inlineCallbacks(None, g, status)\r\n  File \"/home/tonal/.pyenv/versions/3.8.6/envs/err-scrapy-async/lib/python3.8/site-packages/twisted/internet/defer.py\", line 1418, in _inlineCallbacks\r\n    result = g.send(result)\r\n  File \"/home/tonal/.pyenv/versions/3.8.6/envs/err-scrapy-async/lib/python3.8/site-packages/scrapy/crawler.py\", line 109, in stop\r\n    yield defer.maybeDeferred(self.engine.stop)\r\n--- <exception caught here> ---\r\n  File \"/home/tonal/.pyenv/versions/3.8.6/envs/err-scrapy-async/lib/python3.8/site-packages/scrapy/crawler.py\", line 109, in stop\r\n    yield defer.maybeDeferred(self.engine.stop)\r\n  File \"/home/tonal/.pyenv/versions/3.8.6/envs/err-scrapy-async/lib/python3.8/site-packages/twisted/internet/defer.py\", line 151, in maybeDeferred\r\n    result = f(*args, **kw)\r\n  File \"/home/tonal/.pyenv/versions/3.8.6/envs/err-scrapy-async/lib/python3.8/site-packages/scrapy/core/engine.py\", line 87, in stop\r\n    raise RuntimeError(\"Engine not running\")\r\nbuiltins.RuntimeError: Engine not running\r\n\r\n2020-11-14 14:42:51 [twisted] CRITICAL: \r\nTraceback (most recent call last):\r\n  File \"/home/tonal/.pyenv/versions/3.8.6/envs/err-scrapy-async/lib/python3.8/site-packages/scrapy/crawler.py\", line 109, in stop\r\n    yield defer.maybeDeferred(self.engine.stop)\r\n  File \"/home/tonal/.pyenv/versions/3.8.6/envs/err-scrapy-async/lib/python3.8/site-packages/twisted/internet/defer.py\", line 151, in maybeDeferred\r\n    result = f(*args, **kw)\r\n  File \"/home/tonal/.pyenv/versions/3.8.6/envs/err-scrapy-async/lib/python3.8/site-packages/scrapy/core/engine.py\", line 87, in stop\r\n    raise RuntimeError(\"Engine not running\")\r\nRuntimeError: Engine not running\r\n```\r\n\r\n**Reproduces how often:**\r\nAlways after upgrade to 2.4.0\r\n\r\n### Versions\r\n\r\n```\r\n$ scrapy version --verbose\r\nScrapy       : 2.4.0\r\nlxml         : 4.6.1.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 20.3.0\r\nPython       : 3.8.6 (default, Sep 28 2020, 10:21:29) - [GCC 9.3.0]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020)\r\ncryptography : 3.2.1\r\nPlatform     : Linux-5.4.0-53-generic-x86_64-with-glibc2.2.5\r\n```\r\n\r\n### Additional context\r\n\r\nOperating System: KDE neon 5.20\r\nKDE Plasma Version: 5.20.3\r\nKDE Frameworks Version: 5.75.0\r\nQt Version: 5.15.1\r\nKernel Version: 5.4.0-53-generic\r\nOS Type: 64-bit\r\nProcessors: 4 \u00d7 Intel\u00ae Core\u2122 i5-6200U CPU @ 2.30GHz\r\nMemory: 31.2 \u0413\u0438\u0411 of RAM\r\nGraphics Processor: Mesa Intel\u00ae HD Graphics 520", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4887/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4887/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4857", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4857/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4857/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4857/events", "html_url": "https://github.com/scrapy/scrapy/issues/4857", "id": 730675731, "node_id": "MDU6SXNzdWU3MzA2NzU3MzE=", "number": 4857, "title": "Cannot overwrite an output file with -O", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-10-27T17:43:05Z", "updated_at": "2020-11-04T21:29:37Z", "closed_at": "2020-11-04T21:29:37Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Initially found at https://www.reddit.com/r/scrapy/comments/jhpc2f/o_doesnt_overwrite_on_wsl/\r\n\r\nLooks like `_get_storage()` doesn't pass `feed_options` anywhere?\r\n\r\nhttps://github.com/scrapy/scrapy/blob/75f35f558f5a9e0851c05dda85763b679d713ac1/scrapy/extensions/feedexport.py#L445", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4857/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4857/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4841", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4841/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4841/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4841/events", "html_url": "https://github.com/scrapy/scrapy/issues/4841", "id": 718680641, "node_id": "MDU6SXNzdWU3MTg2ODA2NDE=", "number": 4841, "title": "tests/test_downloadermiddleware.py bug with Twisted 17.9.0 ", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-10-10T18:54:44Z", "updated_at": "2020-11-18T06:38:10Z", "closed_at": "2020-11-18T06:38:10Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "As found in #4814 if you manage to install Twisted 17.9.0 (which our tests currently don't), the `tests/test_downloadermiddleware.py::MiddlewareUsingCoro::test_asyncdef` test hangs, probably because of http://twistedmatrix.com/trac/ticket/9390", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4841/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4841/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4835", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4835/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4835/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4835/events", "html_url": "https://github.com/scrapy/scrapy/pull/4835", "id": 715870213, "node_id": "MDExOlB1bGxSZXF1ZXN0NDk4NzA3MDEx", "number": 4835, "title": "Do not consider about: URLs invalid", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-10-06T17:14:32Z", "updated_at": "2020-10-07T09:50:28Z", "closed_at": "2020-10-07T09:50:28Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4835", "html_url": "https://github.com/scrapy/scrapy/pull/4835", "diff_url": "https://github.com/scrapy/scrapy/pull/4835.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4835.patch", "merged_at": "2020-10-07T09:50:28Z"}, "body": "https://github.com/scrapy/scrapy/pull/4094#issuecomment-704092404", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4835/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4835/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4829", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4829/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4829/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4829/events", "html_url": "https://github.com/scrapy/scrapy/issues/4829", "id": 715059442, "node_id": "MDU6SXNzdWU3MTUwNTk0NDI=", "number": 4829, "title": "CSV item exporter does not flush on close", "user": {"login": "scientes", "id": 34819304, "node_id": "MDQ6VXNlcjM0ODE5MzA0", "avatar_url": "https://avatars.githubusercontent.com/u/34819304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scientes", "html_url": "https://github.com/scientes", "followers_url": "https://api.github.com/users/scientes/followers", "following_url": "https://api.github.com/users/scientes/following{/other_user}", "gists_url": "https://api.github.com/users/scientes/gists{/gist_id}", "starred_url": "https://api.github.com/users/scientes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scientes/subscriptions", "organizations_url": "https://api.github.com/users/scientes/orgs", "repos_url": "https://api.github.com/users/scientes/repos", "events_url": "https://api.github.com/users/scientes/events{/privacy}", "received_events_url": "https://api.github.com/users/scientes/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-10-05T18:19:06Z", "updated_at": "2021-02-24T20:49:59Z", "closed_at": "2021-02-24T20:49:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\nThe csv item exporter does not flush on close.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Create pipeline with an CSV item exporter\r\n2. only export few items (one or two)\r\n3. Let spider close/finish\r\n\r\n**Expected behavior:** All exported items are in the CSV Files\r\n\r\n**Actual behavior:** Files with few items are empty (not even a header)\r\n\r\n**Reproduces how often:** 100%\r\n\r\n### Versions\r\n\r\nScrapy       : 2.3.0\r\nlxml         : 4.5.2.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 20.3.0\r\nPython       : 3.8.2 (default, Jul 16 2020, 14:00:26) - [GCC 9.3.0]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1f  31 Mar 2020)\r\ncryptography : 2.8\r\nPlatform     : Linux-5.4.0-7642-generic-x86_64-with-glibc2.29\r\n\r\n### Example pipline.py\r\n\r\n```python3\r\nfrom itemadapter import ItemAdapter\r\nfrom scrapy.exporters import CsvItemExporter\r\n\r\nclass CricketcrawlerPipeline:\r\n    def open_spider(self, spider):\r\n        self.name_to_exporter = {}\r\n\r\n    def close_spider(self, spider):\r\n        for exporter in self.name_to_exporter.values():\r\n            exporter.finish_exporting()\r\n\r\n    def process_item(self, item, spider):\r\n        exporter = self._exporter_for_item(item)\r\n        exporter.export_item(item)\r\n        return item\r\n\r\n    def _exporter_for_item(self, item):\r\n        name = item['name']\r\n        if name not in self.name_to_exporter:\r\n            f = open(f'{item.folder}/{name}.csv', 'wb')\r\n            exporter = CsvItemExporter(f)\r\n            exporter.start_exporting()\r\n            self.name_to_exporter[name] = exporter\r\n        return self.name_to_exporter[name]\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4829/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4829/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4805", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4805/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4805/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4805/events", "html_url": "https://github.com/scrapy/scrapy/issues/4805", "id": 707474834, "node_id": "MDU6SXNzdWU3MDc0NzQ4MzQ=", "number": 4805, "title": "Wrong annotations in scrapy.crawler.CrawlProcess.crawl docstrings", "user": {"login": "osjerick", "id": 8047984, "node_id": "MDQ6VXNlcjgwNDc5ODQ=", "avatar_url": "https://avatars.githubusercontent.com/u/8047984?v=4", "gravatar_id": "", "url": "https://api.github.com/users/osjerick", "html_url": "https://github.com/osjerick", "followers_url": "https://api.github.com/users/osjerick/followers", "following_url": "https://api.github.com/users/osjerick/following{/other_user}", "gists_url": "https://api.github.com/users/osjerick/gists{/gist_id}", "starred_url": "https://api.github.com/users/osjerick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/osjerick/subscriptions", "organizations_url": "https://api.github.com/users/osjerick/orgs", "repos_url": "https://api.github.com/users/osjerick/repos", "events_url": "https://api.github.com/users/osjerick/events{/privacy}", "received_events_url": "https://api.github.com/users/osjerick/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 281088273, "node_id": "MDU6TGFiZWwyODEwODgyNzM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/help%20wanted", "name": "help wanted", "color": "009800", "default": true, "description": null}, {"id": 2371092628, "node_id": "MDU6TGFiZWwyMzcxMDkyNjI4", "url": "https://api.github.com/repos/scrapy/scrapy/labels/typing", "name": "typing", "color": "6ec3d8", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-09-23T15:38:45Z", "updated_at": "2020-10-01T18:46:15Z", "closed_at": "2020-10-01T18:46:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\nSome [IDEs recognize type annotations](https://www.jetbrains.com/help/pycharm/using-docstrings-to-specify-types.html) within docstring to make suggestions or raise warnings related to your code. In the Scrapy source, there are some annotations in the docstring that are wrong.\r\n\r\n[Description of the issue]\r\nThis is a minor issue. The `scrapy.crawler.CrawlerProcess.crawl` method expects one mandatory positional argument, `crawler_or_spidercls`, and optional positional and keyword arguments through arbitrary argument lists. The type annotations for the arbitrary argument lists are wrong:\r\nhttps://github.com/scrapy/scrapy/blob/3989f64baa39f7e42b0f798dec15cd250e0fba21/scrapy/crawler.py#L183-L185\r\n\r\nWhen using `list` for `args` and `dict` for `kwargs`, the docstring suggests that the types of arguments passed through these lists should be `list` and `dict` respectively. According to [PEP 484](https://www.python.org/dev/peps/pep-0484/#arbitrary-argument-lists-and-default-argument-values), the types of `args` and `kwargs` will be automatically deduced as `Tuple[list, ...]` and `Dict[dict, int]`, so the specified types correspond to the values they contain. These annotations don't match the intention you have with this method, do they? BTW, `list` and `dict` weren't generic types for annotations until [Python 3.9](https://docs.python.org/3.9/whatsnew/3.9.html#pep-585-builtin-generic-types).\r\n\r\n### Versions\r\n```text\r\nScrapy       : 2.3.0\r\nlxml         : 4.5.2.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 20.3.0\r\nPython       : 3.8.5 | packaged by conda-forge | (default, Sep 16 2020, 17:43:11) - [Clang 10.0.1 ]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020)\r\ncryptography : 3.1\r\nPlatform     : macOS-10.14.6-x86_64-i386-64bit\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4805/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4805/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4802", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4802/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4802/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4802/events", "html_url": "https://github.com/scrapy/scrapy/issues/4802", "id": 705268362, "node_id": "MDU6SXNzdWU3MDUyNjgzNjI=", "number": 4802, "title": "CachingHostnameResolver does not work with reactor.resolve()", "user": {"login": "michael-lazar", "id": 5026795, "node_id": "MDQ6VXNlcjUwMjY3OTU=", "avatar_url": "https://avatars.githubusercontent.com/u/5026795?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michael-lazar", "html_url": "https://github.com/michael-lazar", "followers_url": "https://api.github.com/users/michael-lazar/followers", "following_url": "https://api.github.com/users/michael-lazar/following{/other_user}", "gists_url": "https://api.github.com/users/michael-lazar/gists{/gist_id}", "starred_url": "https://api.github.com/users/michael-lazar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michael-lazar/subscriptions", "organizations_url": "https://api.github.com/users/michael-lazar/orgs", "repos_url": "https://api.github.com/users/michael-lazar/repos", "events_url": "https://api.github.com/users/michael-lazar/events{/privacy}", "received_events_url": "https://api.github.com/users/michael-lazar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 839225636, "node_id": "MDU6TGFiZWw4MzkyMjU2MzY=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/upstream%20issue", "name": "upstream issue", "color": "c2e0c6", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-09-21T04:11:07Z", "updated_at": "2020-10-20T08:55:08Z", "closed_at": "2020-10-20T08:55:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nHi. Thank you for maintaining this awesome software :)\r\n\r\nI am working on a project using scrapy that implements a custom downloader class ([link](https://github.com/michael-lazar/mozz-archiver/blob/master/mozz_archiver/downloaders.py)).\r\n\r\nI want to resolve IPv6 addresses, and I found the section in the documentation about the ``DNS_RESOLVER`` setting that was added in #4227. I tried enabling the new ``DNS_RESOLVER = \"scrapy.resolver.CachingHostnameResolver\"`` and was immediately greeted with this exception.\r\n\r\n```\r\nUnhandled Error\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/site-packages/scrapy/commands/crawl.py\", line 27, in run\r\n    self.crawler_process.start()\r\n  File \"/usr/local/lib/python3.8/site-packages/scrapy/crawler.py\", line 327, in start\r\n    reactor.run(installSignalHandlers=False)  # blocking call\r\n  File \"/usr/local/lib/python3.8/site-packages/twisted/internet/base.py\", line 1283, in run\r\n    self.mainLoop()\r\n  File \"/usr/local/lib/python3.8/site-packages/twisted/internet/base.py\", line 1292, in mainLoop\r\n    self.runUntilCurrent()\r\n--- <exception caught here> ---\r\n  File \"/usr/local/lib/python3.8/site-packages/twisted/internet/base.py\", line 913, in runUntilCurrent\r\n    call.func(*call.args, **call.kw)\r\n  File \"/usr/local/lib/python3.8/site-packages/twisted/internet/tcp.py\", line 449, in resolveAddress\r\n    d = self.reactor.resolve(self.addr[0])\r\n  File \"/usr/local/lib/python3.8/site-packages/twisted/internet/base.py\", line 638, in resolve\r\n    return self.resolver.getHostByName(name, timeout)\r\n  File \"/usr/local/lib/python3.8/site-packages/twisted/internet/_resolver.py\", line 277, in getHostByName\r\n    self._nameResolver.resolveHostName(FirstOneWins(result), name, 0,\r\n  File \"/usr/local/lib/python3.8/site-packages/scrapy/resolver.py\", line 80, in resolveHostName\r\n    class CachingResolutionReceiver(resolutionReceiver):\r\nbuiltins.TypeError: __init__() takes 2 positional arguments but 4 were given\r\n```\r\n\r\n### Steps to Reproduce\r\n\r\nThis is also reproducible using the bundled FTP downloader\r\n\r\n1. ``scrapy startproject scrapy_test``\r\n2. ``scrapy genspider example mozz.us``\r\n3. Add ``DNS_RESOLVER = \"scrapy.resolver.CachingHostnameResolver\"`` to the settings file\r\n4. Change the spider start_url to ``ftp://mozz.us``\r\n5. ``scrapy crawl scrapy_test``\r\n\r\n### Versions\r\n\r\n```\r\nScrapy       : 2.3.0\r\nlxml         : 4.5.2.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 20.3.0\r\nPython       : 3.8.5 (default, Jul 21 2020, 10:48:26) - [Clang 11.0.3 (clang-1103.0.32.62)]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020)\r\ncryptography : 3.0\r\nPlatform     : macOS-10.15.6-x86_64-i386-64bit\r\n```\r\n\r\n### Additional context\r\n\r\nThis was a tricky one to debug because everything works as expected with the HTTP Agent downloader. This issue only appears when you implement a downloader that depends on calling ``reactor.resolve()`` directly without using ``twisted.internet.endpoints.HostnameEndpoint``.\r\n\r\nI discovered that in the twisted [IHostnameResolver](https://twistedmatrix.com/documents/current/api/twisted.internet.interfaces.IHostnameResolver.html) interface, the ``resolutionReceiver`` method argument is expected to be an *instance* of a resolution receiver class, and not a *type* of a resolution receiver class. So I believe the scrapy code below is incorrect:\r\n\r\nhttps://github.com/scrapy/scrapy/blob/5e997587d9b13344a0afa9bb4cf781829a66ce23/scrapy/resolver.py#L76-L80\r\n\r\nThe subclass here only works with the Scrapy Agent because the ``HostnameEndpoint`` does this weird thing where it defines a class with only static methods, so it can pass the class itself instead of instantiating it.\r\n\r\nhttps://github.com/twisted/twisted/blob/22f949f7ce187513f0c218b73186c8a73baa00b4/src/twisted/internet/endpoints.py#L942-L958\r\n\r\n```python\r\n        @provider(IResolutionReceiver)\r\n        class EndpointReceiver:\r\n            @staticmethod\r\n            def resolutionBegan(resolutionInProgress):\r\n                pass\r\n\r\n            @staticmethod\r\n            def addressResolved(address):\r\n                addresses.append(address)\r\n\r\n            @staticmethod\r\n            def resolutionComplete():\r\n                d.callback(addresses)\r\n\r\n        self._nameResolver.resolveHostName(\r\n            EndpointReceiver, self._hostText, portNumber=self._port\r\n        )\r\n```\r\n\r\nHowever, there are other places in the twisted reactor where twisted does pass an object instance directly to this method.\r\n\r\nhttps://github.com/twisted/twisted/blob/7e3ce790ca9f004ab386f9ecbba8f505d66cd3bd/src/twisted/internet/_resolver.py#L307\r\n\r\n```python\r\n        result = Deferred()\r\n        self._nameResolver.resolveHostName(FirstOneWins(result), name, 0, [IPv4Address])\r\n        return result\r\n```\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4802/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4802/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4766", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4766/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4766/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4766/events", "html_url": "https://github.com/scrapy/scrapy/issues/4766", "id": 688565257, "node_id": "MDU6SXNzdWU2ODg1NjUyNTc=", "number": 4766, "title": "Invalid cookies ('value' missing) - Added in 2.3.0 - scrapy/downloadermiddlewares/cookies.py ", "user": {"login": "L3NNYY", "id": 40499416, "node_id": "MDQ6VXNlcjQwNDk5NDE2", "avatar_url": "https://avatars.githubusercontent.com/u/40499416?v=4", "gravatar_id": "", "url": "https://api.github.com/users/L3NNYY", "html_url": "https://github.com/L3NNYY", "followers_url": "https://api.github.com/users/L3NNYY/followers", "following_url": "https://api.github.com/users/L3NNYY/following{/other_user}", "gists_url": "https://api.github.com/users/L3NNYY/gists{/gist_id}", "starred_url": "https://api.github.com/users/L3NNYY/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/L3NNYY/subscriptions", "organizations_url": "https://api.github.com/users/L3NNYY/orgs", "repos_url": "https://api.github.com/users/L3NNYY/repos", "events_url": "https://api.github.com/users/L3NNYY/events{/privacy}", "received_events_url": "https://api.github.com/users/L3NNYY/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-29T16:41:38Z", "updated_at": "2020-10-02T18:38:15Z", "closed_at": "2020-10-02T18:38:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\nWhen scraping certain sites and passing cookies to scrapy, I've had an issue pop up where the page wasn't able to scrape due to an error message `\"Invalid cookie found in request {}: {} ('{}' is missing)\"`. This is because some websites and pages form cookies with an empty value instead of not including the key altogether (hacky fix on their side), causing the newly added check in scrapy/downloadermiddlewares/cookies.py ln. 78 to pass and stop the request. \r\n\r\nPerhaps a setup variable that would let us toggle this cookie check would solve the issue, or perhaps removing this specific check/making it a warning, and not causing the function to return.\r\n\r\nThe only other solution temporarily right now if for scrapy users to have to re-format the cookies themselves, and some sites do want the empty value cookie object.\r\n\r\nSince 2.3.0 just got released, I've only seen one other thread (on stackoverflow) mentioning this issue. \r\nhttps://stackoverflow.com/questions/63204521/scrapy-and-invalid-cookie-found-in-request\r\n\r\n### Steps to Reproduce\r\n\r\n1. Get website cookies that aren't formatted properly (so a key with an empty value: eg. value:'')\r\n2. Pass the cookie to scrapy and see the request not go through\r\n\r\n**Expected behavior:** [What you expect to happen]\r\n2.2.0 and previous versions have allowed the request to go through even when cookie isn't properly formatted (in our case we are passing cookies from selenium webdriver to scrapy so we don't do any cookie formatting ourselves).\r\n**Actual behavior:** [What actually happens]\r\nStops the request\r\n**Reproduces how often:** [What percentage of the time does it reproduce?]\r\nEvery Time\r\n### Versions\r\n2.3.0\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4766/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4766/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4763", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4763/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4763/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4763/events", "html_url": "https://github.com/scrapy/scrapy/issues/4763", "id": 688011121, "node_id": "MDU6SXNzdWU2ODgwMTExMjE=", "number": 4763, "title": "Scrapy parses commented out <base> element", "user": {"login": "mauritsderuiter95", "id": 41860584, "node_id": "MDQ6VXNlcjQxODYwNTg0", "avatar_url": "https://avatars.githubusercontent.com/u/41860584?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mauritsderuiter95", "html_url": "https://github.com/mauritsderuiter95", "followers_url": "https://api.github.com/users/mauritsderuiter95/followers", "following_url": "https://api.github.com/users/mauritsderuiter95/following{/other_user}", "gists_url": "https://api.github.com/users/mauritsderuiter95/gists{/gist_id}", "starred_url": "https://api.github.com/users/mauritsderuiter95/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mauritsderuiter95/subscriptions", "organizations_url": "https://api.github.com/users/mauritsderuiter95/orgs", "repos_url": "https://api.github.com/users/mauritsderuiter95/repos", "events_url": "https://api.github.com/users/mauritsderuiter95/events{/privacy}", "received_events_url": "https://api.github.com/users/mauritsderuiter95/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 839225636, "node_id": "MDU6TGFiZWw4MzkyMjU2MzY=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/upstream%20issue", "name": "upstream issue", "color": "c2e0c6", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-08-28T11:32:50Z", "updated_at": "2023-01-29T21:23:47Z", "closed_at": "2023-01-29T21:23:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nI'm building a scraper that follows some urls with a pattern with the response.follow function. I'm currently stuck on a webpage which has the <base> element in the header commented out. The href in the <base> element is invalid. When I try to follow a relative url on the webpage it incorrectly tries to send me to the invalid url. It ignores the fact that it actually is a comment.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Use the response.follow function\r\n2. Go to http://prahm-stiftung.de/\r\n3. Try to follow the \"Kontakt & Impressum\" page\r\n4. It redirects to \" http://www.www.prahm-stifung.de/5-0-Kontakt-und-Impressum.html\" which is incorrect. The <base> element is commented out\r\n\r\n**Expected behavior:** Ignore the <base> element.\r\n\r\n**Actual behavior:** It uses the commented out <base> element to get the url to follow\r\n\r\n**Reproduces how often:** Always\r\n\r\n### Versions\r\n\r\nScrapy       : 2.1.0\r\nlxml         : 4.5.1.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 20.3.0\r\nPython       : 3.8.2 (v3.8.2:7b3ab5921f, Feb 24 2020, 17:52:18) - [Clang 6.0 (clang-600.0.57)]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020)\r\ncryptography : 2.9.2\r\nPlatform     : macOS-10.15.6-x86_64-i386-64bit\r\n\r\n### Additional context\r\n\r\npage = '5-0-Kontakt-und-Impressum.html'\r\nyield response.follow(page, callback=self.parse)\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4763/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4763/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4762", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4762/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4762/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4762/events", "html_url": "https://github.com/scrapy/scrapy/issues/4762", "id": 687485783, "node_id": "MDU6SXNzdWU2ODc0ODU3ODM=", "number": 4762, "title": "request fingerprint should separate different sections when building a hash", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-08-27T19:27:58Z", "updated_at": "2022-06-07T16:44:55Z", "closed_at": "2022-06-07T16:44:55Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "It looks like body & headers & values are not separated where fp is being built in request_fingerprint function. \r\n\r\nSo e.g. a request with header with \"foo\" and \"bar\" values would get the same fingerprint as a request with \"fo\" and \"obar\" values. The same applies for body, etc. URL is joined with the body, for example, so a POST request to http://example.com/foo with empty body gets the same fingerprint as a POST request to http://example.com/fo with \"o\" body:\r\n\r\n```py\r\nfrom scrapy import request\r\nfrom scrapy.utils.request import request_fingerprint\r\n\r\nreq1 = scrapy.Request(\"http://example.com/foo\", method=\"POST\", body=b'')\r\nreq2 = scrapy.Request(\"http://example.com/fo\", method=\"POST\", body=b'o')\r\n\r\nrequest_fingerprint(req1)  # 'ca64371a30748ddb06e28365b7e1177db7bfa8e9'\r\nrequest_fingerprint(req2)  # 'ca64371a30748ddb06e28365b7e1177db7bfa8e9'\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4762/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 1, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4762/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4760", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4760/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4760/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4760/events", "html_url": "https://github.com/scrapy/scrapy/issues/4760", "id": 686299706, "node_id": "MDU6SXNzdWU2ODYyOTk3MDY=", "number": 4760, "title": "Error when use scrapy in cmd", "user": {"login": "quochung-cyou", "id": 60738479, "node_id": "MDQ6VXNlcjYwNzM4NDc5", "avatar_url": "https://avatars.githubusercontent.com/u/60738479?v=4", "gravatar_id": "", "url": "https://api.github.com/users/quochung-cyou", "html_url": "https://github.com/quochung-cyou", "followers_url": "https://api.github.com/users/quochung-cyou/followers", "following_url": "https://api.github.com/users/quochung-cyou/following{/other_user}", "gists_url": "https://api.github.com/users/quochung-cyou/gists{/gist_id}", "starred_url": "https://api.github.com/users/quochung-cyou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/quochung-cyou/subscriptions", "organizations_url": "https://api.github.com/users/quochung-cyou/orgs", "repos_url": "https://api.github.com/users/quochung-cyou/repos", "events_url": "https://api.github.com/users/quochung-cyou/events{/privacy}", "received_events_url": "https://api.github.com/users/quochung-cyou/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 318523681, "node_id": "MDU6TGFiZWwzMTg1MjM2ODE=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/Windows", "name": "Windows", "color": "fad8c7", "default": false, "description": null}, {"id": 443680419, "node_id": "MDU6TGFiZWw0NDM2ODA0MTk=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/needs%20more%20info", "name": "needs more info", "color": "fef2c0", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-26T12:59:01Z", "updated_at": "2020-08-28T09:33:22Z", "closed_at": "2020-08-28T09:33:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\nI have some error when trying to install scrapy\r\n\r\n\r\n\r\n### Steps to Reproduce\r\n\r\n1. Installed Anaconda + OpenSSL\r\n2. Use conda install -c conda-forge scrapy\r\n3. Get error when type scrapy on cmd\r\n\r\n**Expected behavior:** Command scrapy should work\r\n\r\n**Actual behavior:**  Error log: \r\n\r\nhttps://pastebin.com/CqNmRYJT\r\n\r\n**Reproduces how often:** It happen for me on first install\r\n\r\n### Versions\r\n\r\nI can't get the version because it throw error\r\n\r\n### Additional context\r\n\r\nOutput error: https://pastebin.com/CqNmRYJT\r\n\r\nTried:\r\n\r\n+ Reinstall lxml with anaconda\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4760/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4760/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4726", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4726/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4726/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4726/events", "html_url": "https://github.com/scrapy/scrapy/issues/4726", "id": 679046070, "node_id": "MDU6SXNzdWU2NzkwNDYwNzA=", "number": 4726, "title": "Test failures on Debian Unstable", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-14T09:57:38Z", "updated_at": "2020-08-25T06:48:31Z", "closed_at": "2020-08-25T06:48:31Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I ran the 2.3.0 test suite on the current Debian Unstable and got the following failures.\r\n\r\nTwo related to those CAMELLIA tests (`Https11CustomCiphers.test_download` and `WebClientCustomCiphersSSLTestCase.testPayload`):\r\n\r\n```\r\n<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert internal error')]\r\n```\r\n\r\nTwo related to the mitmproxy cert:\r\n\r\n```\r\n  File \"/usr/lib/python3/dist-packages/mitmproxy/net/tls.py\", line 369, in create_server_context\r\n    context.use_certificate(cert.x509)\r\n  File \"/usr/lib/python3/dist-packages/OpenSSL/SSL.py\", line 960, in use_certificate\r\n    _raise_current_error()\r\n  File \"/usr/lib/python3/dist-packages/OpenSSL/_util.py\", line 54, in exception_from_error_queue\r\n    raise exception_type(errors)\r\nOpenSSL.SSL.Error: [('SSL routines', 'SSL_CTX_use_certificate', 'ee key too small')]\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4726/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4726/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4722", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4722/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4722/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4722/events", "html_url": "https://github.com/scrapy/scrapy/pull/4722", "id": 677770687, "node_id": "MDExOlB1bGxSZXF1ZXN0NDY2ODM1ODEy", "number": 4722, "title": "Do not let umask affect the permissions of startproject-generated files", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/33", "html_url": "https://github.com/scrapy/scrapy/milestone/33", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/33/labels", "id": 5660859, "node_id": "MDk6TWlsZXN0b25lNTY2MDg1OQ==", "number": 33, "title": "2.4", "description": "Drop Python 3.5 support.", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 15, "state": "closed", "created_at": "2020-07-16T13:00:02Z", "updated_at": "2020-10-11T20:15:19Z", "due_on": "2020-09-13T07:00:00Z", "closed_at": "2020-10-11T20:15:19Z"}, "comments": 1, "created_at": "2020-08-12T15:09:00Z", "updated_at": "2020-08-28T13:41:03Z", "closed_at": "2020-08-28T13:41:03Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4722", "html_url": "https://github.com/scrapy/scrapy/pull/4722", "diff_url": "https://github.com/scrapy/scrapy/pull/4722.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4722.patch", "merged_at": "2020-08-28T13:41:02Z"}, "body": "This should allow permission tests to pass in Conda Forge builds (see https://github.com/conda-forge/scrapy-feedstock/pull/42).\r\n\r\nIncludes changes (`maxDiff = None`, `get_permissions`) aimed at making test failures more readable.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4722/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4722/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4717", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4717/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4717/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4717/events", "html_url": "https://github.com/scrapy/scrapy/issues/4717", "id": 676077105, "node_id": "MDU6SXNzdWU2NzYwNzcxMDU=", "number": 4717, "title": "Request cookies not updated with values from previous response", "user": {"login": "alfredsasko", "id": 44699562, "node_id": "MDQ6VXNlcjQ0Njk5NTYy", "avatar_url": "https://avatars.githubusercontent.com/u/44699562?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alfredsasko", "html_url": "https://github.com/alfredsasko", "followers_url": "https://api.github.com/users/alfredsasko/followers", "following_url": "https://api.github.com/users/alfredsasko/following{/other_user}", "gists_url": "https://api.github.com/users/alfredsasko/gists{/gist_id}", "starred_url": "https://api.github.com/users/alfredsasko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alfredsasko/subscriptions", "organizations_url": "https://api.github.com/users/alfredsasko/orgs", "repos_url": "https://api.github.com/users/alfredsasko/repos", "events_url": "https://api.github.com/users/alfredsasko/events{/privacy}", "received_events_url": "https://api.github.com/users/alfredsasko/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/33", "html_url": "https://github.com/scrapy/scrapy/milestone/33", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/33/labels", "id": 5660859, "node_id": "MDk6TWlsZXN0b25lNTY2MDg1OQ==", "number": 33, "title": "2.4", "description": "Drop Python 3.5 support.", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 15, "state": "closed", "created_at": "2020-07-16T13:00:02Z", "updated_at": "2020-10-11T20:15:19Z", "due_on": "2020-09-13T07:00:00Z", "closed_at": "2020-10-11T20:15:19Z"}, "comments": 4, "created_at": "2020-08-10T11:51:38Z", "updated_at": "2020-10-08T15:20:33Z", "closed_at": "2020-10-08T15:20:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\n[Description of the issue]\r\n\r\n### Steps to Reproduce\r\n\r\n1. Create 2 conda environments one scrapy160 with scrapy 1.6.0 version installed and scrapy230 with scrapy 2.3.0. version installed.\r\n2. `conda activate scrapy160`\r\n3. `scrapy startproject test_login`\r\n4. `cd test_login`\r\n5. `scrapy genspider login quotes.toscrape.com/login`\r\n6. Adapt login.py\r\n\r\n```\r\nimport scrapy\r\nfrom scrapy import FormRequest\r\n\r\n\r\nclass LoginSpider(scrapy.Spider):\r\n    name = 'login'\r\n    # allowed_domains = ['quotes.toscrape.com']\r\n\r\n    start_urls = ['http://quotes.toscrape.com/login']\r\n\r\n    def parse(self, response):\r\n        csrf_token = response.xpath('//input[@name=\"csrf_token\"]/@value').get()\r\n        return FormRequest.from_response(\r\n            response,\r\n            # formname='',\r\n            # formcss='',\r\n            formxpath='//form',\r\n            formdata={\r\n                'csrf_token': csrf_token,\r\n                'username': 'admin',\r\n                'password': 'admin'\r\n            },\r\n            callback=self.after_login\r\n        )\r\n\r\n    def after_login(self, response):\r\n        logout = response.xpath(\"//a[text()='Logout']/text()\").get()\r\n        self.logger.info(logout)\r\n```\r\n7. `scrapy crawl login`\r\n8. `conda activate scrapy230`\r\n9. `scrapy crawl login`\r\n\r\n\r\n**Expected behavior:** \r\nAfter login into http://quotes.toscrape.com/login the spider is redirected to http://quotes.toscrape.com/ and locates and prints the text of the log out link on the right top side of the page for version 1.6.0 and also 2.3.0. Refer to valid `[login] INFO: Logout` vs invalid `[login] INFO: None`\r\n\r\n**Actual behavior:** Version 1.6.0. is able to locate log out link while version 2.3.0 can't\r\n\r\n**Reproduces how often:** 100%\r\n\r\n### Output of the Version 1.6.0 - OK\r\n```\r\n$ scrapy crawl login\r\n2020-08-10 12:49:55 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: test_login)\r\n2020-08-10 12:49:55 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.8.5 (default, Aug  5 2020, 09:44:06) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.9.2, Platform Windows-7-6.1.7601-SP1\r\n2020-08-10 12:49:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'test_login', 'NEWSPIDER_MODULE': 'test_login.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['test_login.spiders']}\r\n2020-08-10 12:49:55 [scrapy.extensions.telnet] INFO: Telnet Password: e0f8343159af7408\r\n2020-08-10 12:49:55 [scrapy.middleware] INFO: Enabled extensions:\r\n['scrapy.extensions.corestats.CoreStats',\r\n 'scrapy.extensions.telnet.TelnetConsole',\r\n 'scrapy.extensions.logstats.LogStats']\r\n2020-08-10 12:49:55 [scrapy.middleware] INFO: Enabled downloader middlewares:\r\n['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\r\n 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\r\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\r\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\r\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\r\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\r\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\r\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\r\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\r\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\r\n2020-08-10 12:49:55 [scrapy.middleware] INFO: Enabled spider middlewares:\r\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\r\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\r\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\r\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\r\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\r\n2020-08-10 12:49:55 [scrapy.middleware] INFO: Enabled item pipelines:\r\n[]\r\n2020-08-10 12:49:55 [scrapy.core.engine] INFO: Spider opened\r\n2020-08-10 12:49:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2020-08-10 12:49:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\r\n2020-08-10 12:49:55 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)\r\n2020-08-10 12:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/login> (referer: None)\r\n2020-08-10 12:49:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://quotes.toscrape.com/> from <POST http://quotes.toscrape.com/login>\r\n2020-08-10 12:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/> (referer: http://quotes.toscrape.com/login)\r\n2020-08-10 12:49:55 [login] INFO: Logout\r\n2020-08-10 12:49:55 [scrapy.core.engine] INFO: Closing spider (finished)\r\n2020-08-10 12:49:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\r\n{'downloader/request_bytes': 1437,\r\n 'downloader/request_count': 4,\r\n 'downloader/request_method_count/GET': 3,\r\n 'downloader/request_method_count/POST': 1,\r\n 'downloader/response_bytes': 4763,\r\n 'downloader/response_count': 4,\r\n 'downloader/response_status_count/200': 2,\r\n 'downloader/response_status_count/302': 1,\r\n 'downloader/response_status_count/404': 1,\r\n 'finish_reason': 'finished',\r\n 'finish_time': datetime.datetime(2020, 8, 10, 10, 49, 55, 999506),\r\n 'log_count/DEBUG': 4,\r\n 'log_count/INFO': 10,\r\n 'request_depth_max': 1,\r\n 'response_received_count': 3,\r\n 'robotstxt/request_count': 1,\r\n 'robotstxt/response_count': 1,\r\n 'robotstxt/response_status_count/404': 1,\r\n 'scheduler/dequeued': 3,\r\n 'scheduler/dequeued/memory': 3,\r\n 'scheduler/enqueued': 3,\r\n 'scheduler/enqueued/memory': 3,\r\n 'start_time': datetime.datetime(2020, 8, 10, 10, 49, 55, 497942)}\r\n2020-08-10 12:49:56 [scrapy.core.engine] INFO: Spider closed (finished)\r\n```\r\n\r\n### Output of the Version 2.3.0 - NOT OK\r\n\r\n```\r\n$ scrapy crawl login\r\n2020-08-10 12:51:37 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: test_login)\r\n2020-08-10 12:51:37 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Windows-7-6.1.7601-SP1\r\n2020-08-10 12:51:37 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\r\n2020-08-10 12:51:37 [scrapy.crawler] INFO: Overridden settings:\r\n{'BOT_NAME': 'test_login',\r\n 'NEWSPIDER_MODULE': 'test_login.spiders',\r\n 'ROBOTSTXT_OBEY': True,\r\n 'SPIDER_MODULES': ['test_login.spiders']}\r\n2020-08-10 12:51:37 [scrapy.extensions.telnet] INFO: Telnet Password: 445dedc895a440a5\r\n2020-08-10 12:51:37 [scrapy.middleware] INFO: Enabled extensions:\r\n['scrapy.extensions.corestats.CoreStats',\r\n 'scrapy.extensions.telnet.TelnetConsole',\r\n 'scrapy.extensions.logstats.LogStats']\r\n2020-08-10 12:51:38 [scrapy.middleware] INFO: Enabled downloader middlewares:\r\n['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\r\n 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\r\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\r\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\r\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\r\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\r\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\r\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\r\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\r\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\r\n2020-08-10 12:51:38 [scrapy.middleware] INFO: Enabled spider middlewares:\r\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\r\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\r\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\r\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\r\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\r\n2020-08-10 12:51:38 [scrapy.middleware] INFO: Enabled item pipelines:\r\n[]\r\n2020-08-10 12:51:38 [scrapy.core.engine] INFO: Spider opened\r\n2020-08-10 12:51:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2020-08-10 12:51:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\r\n2020-08-10 12:51:38 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)\r\n2020-08-10 12:51:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/login> (referer: None)\r\n2020-08-10 12:51:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://quotes.toscrape.com/> from <POST http://quotes.toscrape.com/login>\r\n2020-08-10 12:51:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/> (referer: http://quotes.toscrape.com/login)\r\n2020-08-10 12:51:38 [login] INFO: None\r\n2020-08-10 12:51:38 [scrapy.core.engine] INFO: Closing spider (finished)\r\n2020-08-10 12:51:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\r\n{'downloader/request_bytes': 1431,\r\n 'downloader/request_count': 4,\r\n 'downloader/request_method_count/GET': 3,\r\n 'downloader/request_method_count/POST': 1,\r\n 'downloader/response_bytes': 4585,\r\n 'downloader/response_count': 4,\r\n 'downloader/response_status_count/200': 2,\r\n 'downloader/response_status_count/302': 1,\r\n 'downloader/response_status_count/404': 1,\r\n 'elapsed_time_seconds': 0.502564,\r\n 'finish_reason': 'finished',\r\n 'finish_time': datetime.datetime(2020, 8, 10, 10, 51, 38, 622537),\r\n 'log_count/DEBUG': 4,\r\n 'log_count/INFO': 11,\r\n 'request_depth_max': 1,\r\n 'response_received_count': 3,\r\n 'robotstxt/request_count': 1,\r\n 'robotstxt/response_count': 1,\r\n 'robotstxt/response_status_count/404': 1,\r\n 'scheduler/dequeued': 3,\r\n 'scheduler/dequeued/memory': 3,\r\n 'scheduler/enqueued': 3,\r\n 'scheduler/enqueued/memory': 3,\r\n 'start_time': datetime.datetime(2020, 8, 10, 10, 51, 38, 119973)}\r\n2020-08-10 12:51:38 [scrapy.core.engine] INFO: Spider closed (finished)\r\n```\r\n### Additional context\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4717/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4717/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4702", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4702/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4702/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4702/events", "html_url": "https://github.com/scrapy/scrapy/issues/4702", "id": 667748434, "node_id": "MDU6SXNzdWU2Njc3NDg0MzQ=", "number": 4702, "title": "Tests fail because of pytest 6.0.0", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-07-29T10:53:38Z", "updated_at": "2020-07-30T06:27:26Z", "closed_at": "2020-07-30T06:27:26Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "See https://travis-ci.org/github/scrapy/scrapy/builds/712802460\r\n\r\n```\r\n.tox/pinned/lib/python3.5/site-packages/pluggy/hooks.py:286: in __call__\r\n    return self._hookexec(self, self.get_hookimpls(), kwargs)\r\n.tox/pinned/lib/python3.5/site-packages/pluggy/manager.py:93: in _hookexec\r\n    return self._inner_hookexec(hook, methods, kwargs)\r\n.tox/pinned/lib/python3.5/site-packages/pluggy/manager.py:87: in <lambda>\r\n    firstresult=hook.spec.opts.get(\"firstresult\") if hook.spec else False,\r\n.tox/pinned/lib/python3.5/site-packages/sybil/integration/pytest.py:118: in pytest_collect_file\r\n    return SybilFile(path, parent, sybil)\r\n.tox/pinned/lib/python3.5/site-packages/_pytest/nodes.py:95: in __call__\r\n    warnings.warn(NODE_USE_FROM_PARENT.format(name=self.__name__), stacklevel=2)\r\nE   pytest.PytestDeprecationWarning: Direct construction of SybilFile has been deprecated, please use SybilFile.from_parent.\r\nE   See https://docs.pytest.org/en/stable/deprecations.html#node-construction-changed-to-node-from-parent for more details.\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4702/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4702/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4671", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4671/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4671/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4671/events", "html_url": "https://github.com/scrapy/scrapy/issues/4671", "id": 653885668, "node_id": "MDU6SXNzdWU2NTM4ODU2Njg=", "number": 4671, "title": "Add docs for FEEDS.uri_params and FEED_URI_PARAMS", "user": {"login": "alex-ber", "id": 19841541, "node_id": "MDQ6VXNlcjE5ODQxNTQx", "avatar_url": "https://avatars.githubusercontent.com/u/19841541?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alex-ber", "html_url": "https://github.com/alex-ber", "followers_url": "https://api.github.com/users/alex-ber/followers", "following_url": "https://api.github.com/users/alex-ber/following{/other_user}", "gists_url": "https://api.github.com/users/alex-ber/gists{/gist_id}", "starred_url": "https://api.github.com/users/alex-ber/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alex-ber/subscriptions", "organizations_url": "https://api.github.com/users/alex-ber/orgs", "repos_url": "https://api.github.com/users/alex-ber/repos", "events_url": "https://api.github.com/users/alex-ber/events{/privacy}", "received_events_url": "https://api.github.com/users/alex-ber/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-09T08:50:52Z", "updated_at": "2020-08-14T09:47:56Z", "closed_at": "2020-08-14T09:47:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "In https://docs.scrapy.org/en/latest/topics/feed-exports.html#feeds \r\n\r\nThere is missing entry \r\n\r\n`uri_params: falls back to FEED_URI_PARAMS`\r\n\r\nAlso FEED_URI_PARAMS setting description is missing (see https://github.com/scrapy/scrapy/issues/4670)\r\n\r\nHere \r\n\r\n\r\n\r\n    format: the serialization format to be used for the feed. See Serialization formats for possible values. Mandatory, no fallback setting\r\n\r\n    encoding: falls back to FEED_EXPORT_ENCODING\r\n\r\n    fields: falls back to FEED_EXPORT_FIELDS\r\n\r\n    indent: falls back to FEED_EXPORT_INDENT\r\n\r\n    store_empty: falls back to FEED_STORE_EMPTY\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4671/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4671/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4667", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4667/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4667/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4667/events", "html_url": "https://github.com/scrapy/scrapy/issues/4667", "id": 653402809, "node_id": "MDU6SXNzdWU2NTM0MDI4MDk=", "number": 4667, "title": "List of fields incorrectly accessed for dataclass items", "user": {"login": "tadejsv", "id": 11489772, "node_id": "MDQ6VXNlcjExNDg5Nzcy", "avatar_url": "https://avatars.githubusercontent.com/u/11489772?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tadejsv", "html_url": "https://github.com/tadejsv", "followers_url": "https://api.github.com/users/tadejsv/followers", "following_url": "https://api.github.com/users/tadejsv/following{/other_user}", "gists_url": "https://api.github.com/users/tadejsv/gists{/gist_id}", "starred_url": "https://api.github.com/users/tadejsv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tadejsv/subscriptions", "organizations_url": "https://api.github.com/users/tadejsv/orgs", "repos_url": "https://api.github.com/users/tadejsv/repos", "events_url": "https://api.github.com/users/tadejsv/events{/privacy}", "received_events_url": "https://api.github.com/users/tadejsv/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/30", "html_url": "https://github.com/scrapy/scrapy/milestone/30", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/30/labels", "id": 5483684, "node_id": "MDk6TWlsZXN0b25lNTQ4MzY4NA==", "number": 30, "title": "v2.3", "description": "**Major goals:** [separate ItemLoaders library](https://github.com/scrapy/scrapy/pull/4516), and [coroutine syntax for `start_requests`](https://github.com/scrapy/scrapy/pull/4467)", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 6, "state": "closed", "created_at": "2020-06-01T04:21:57Z", "updated_at": "2020-08-05T15:01:11Z", "due_on": "2020-07-31T07:00:00Z", "closed_at": "2020-08-05T15:01:11Z"}, "comments": 1, "created_at": "2020-07-08T15:44:07Z", "updated_at": "2020-07-28T09:15:14Z", "closed_at": "2020-07-28T09:15:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nIf I make a `dataclass` item and want to export to csv, I get this error:\r\n\r\n```\r\n...\r\n  File \"/home/tadej/miniconda3/envs/main/lib/python3.7/site-packages/scrapy/exporters.py\", line 251, in _write_headers_and_set_fields_to_export\r\n    self.fields_to_export = list(item.fields.keys())\r\nAttributeError: 'CompanyItem' object has no attribute 'fields'\r\n```\r\nThe problem stems from here\r\n\r\nhttps://github.com/scrapy/scrapy/blob/master/scrapy/exporters.py#L243-L253\r\n\r\nThere should be an additional if case checking if the item is of type dataclass, and then accessing the fields differently, perhaps as\r\n```python\r\n[field.name for field in fields(item)]\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4667/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4667/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4665", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4665/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4665/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4665/events", "html_url": "https://github.com/scrapy/scrapy/issues/4665", "id": 652263073, "node_id": "MDU6SXNzdWU2NTIyNjMwNzM=", "number": 4665, "title": "startproject only allows creating the project on an existing folder if the path is specified with an invalid module name", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-07T11:57:51Z", "updated_at": "2021-08-24T07:18:49Z", "closed_at": "2021-08-24T07:18:49Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\r\n(venv) [adrian@afonsox temporal]$ mkdir existing_folder\r\n(venv) [adrian@afonsox temporal]$ scrapy startproject existing_folder\r\nError: Module 'existing_folder' already exists\r\n(venv) [adrian@afonsox temporal]$ cd existing_folder && scrapy startproject existing_folder .\r\nNew Scrapy project 'existing_folder', using template directory '/home/adrian/temporal/venv/lib/python3.8/site-packages/scrapy/templates/project', created in:\r\n    /home/adrian/temporal/existing_folder\r\n\r\nYou can start your first spider with:\r\n    cd .\r\n    scrapy genspider example example.com\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4665/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4665/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4662", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4662/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4662/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4662/events", "html_url": "https://github.com/scrapy/scrapy/issues/4662", "id": 651709561, "node_id": "MDU6SXNzdWU2NTE3MDk1NjE=", "number": 4662, "title": "scrapy startproject alters executable permissions in local virtualenv", "user": {"login": "dhosterman", "id": 3520372, "node_id": "MDQ6VXNlcjM1MjAzNzI=", "avatar_url": "https://avatars.githubusercontent.com/u/3520372?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dhosterman", "html_url": "https://github.com/dhosterman", "followers_url": "https://api.github.com/users/dhosterman/followers", "following_url": "https://api.github.com/users/dhosterman/following{/other_user}", "gists_url": "https://api.github.com/users/dhosterman/gists{/gist_id}", "starred_url": "https://api.github.com/users/dhosterman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dhosterman/subscriptions", "organizations_url": "https://api.github.com/users/dhosterman/orgs", "repos_url": "https://api.github.com/users/dhosterman/repos", "events_url": "https://api.github.com/users/dhosterman/events{/privacy}", "received_events_url": "https://api.github.com/users/dhosterman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/32", "html_url": "https://github.com/scrapy/scrapy/milestone/32", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/32/labels", "id": 5633575, "node_id": "MDk6TWlsZXN0b25lNTYzMzU3NQ==", "number": 32, "title": "v2.2.1", "description": "Bugfixes for the 2.2 release", "creator": {"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 2, "state": "closed", "created_at": "2020-07-08T17:03:09Z", "updated_at": "2020-08-05T15:01:15Z", "due_on": null, "closed_at": "2020-08-05T15:01:15Z"}, "comments": 1, "created_at": "2020-07-06T17:34:57Z", "updated_at": "2020-07-13T11:01:06Z", "closed_at": "2020-07-13T11:01:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nWhen running `scrapy startproject` after creating a virtualenv in .venv in the project directory, the executable files have their permissions changed.\r\n\r\n### Steps to Reproduce (using Poetry)\r\n\r\n1. Enter new project directory\r\n2. `poetry init -n`\r\n3. `poetry config virtualenvs.in-project true --local`\r\n4. `poetry add scrapy`\r\n5. `poetry shell`\r\n6. `scrapy startproject scraper .`\r\n7. `scrapy` <-- fails\r\n8. `python` <-- fails\r\n\r\n**Expected behavior:** [What you expect to happen]\r\n\r\nI expect to still be able to execute `scrapy` or `python` commands.\r\n\r\n**Actual behavior:** [What actually happens]\r\n\r\nI am unable to execute `scrapy` or `python` commands because everything in .venv/bin has had its executable permissions removed including the python executable that is the target of the `python` symlink.\r\n\r\n**Reproduces how often:** [What percentage of the time does it reproduce?]\r\n\r\n100%\r\n\r\n### Versions\r\n\r\nScrapy       : 2.2.0\r\nlxml         : 4.5.1.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 20.3.0\r\nPython       : 3.8.3 (default, Jun 27 2020, 12:47:10) - [Clang 11.0.0 (clang-1100.0.33.8)]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020)\r\ncryptography : 2.9.2\r\nPlatform     : macOS-10.15.5-x86_64-i386-64bit\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4662/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4662/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4644", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4644/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4644/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4644/events", "html_url": "https://github.com/scrapy/scrapy/issues/4644", "id": 643819021, "node_id": "MDU6SXNzdWU2NDM4MTkwMjE=", "number": 4644, "title": "test_integration_downloader_aware_priority_queue raises exception", "user": {"login": "Lukas0907", "id": 591792, "node_id": "MDQ6VXNlcjU5MTc5Mg==", "avatar_url": "https://avatars.githubusercontent.com/u/591792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lukas0907", "html_url": "https://github.com/Lukas0907", "followers_url": "https://api.github.com/users/Lukas0907/followers", "following_url": "https://api.github.com/users/Lukas0907/following{/other_user}", "gists_url": "https://api.github.com/users/Lukas0907/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lukas0907/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lukas0907/subscriptions", "organizations_url": "https://api.github.com/users/Lukas0907/orgs", "repos_url": "https://api.github.com/users/Lukas0907/repos", "events_url": "https://api.github.com/users/Lukas0907/events{/privacy}", "received_events_url": "https://api.github.com/users/Lukas0907/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-23T12:56:02Z", "updated_at": "2020-06-25T13:36:44Z", "closed_at": "2020-06-25T13:36:44Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\nThe test `tests/test_scheduler.py::TestIntegrationWithDownloaderAwareInMemory::test_integration_downloader_aware_priority_queue` raises the following exception:\r\n\r\n```\r\nERROR    scrapy.core.engine:engine.py:308 Stats close failure\r\nTraceback (most recent call last):\r\n  File \"/home/lukas/Projects/3rd/scrapy/.tox/py/lib/python3.8/site-packages/twisted/internet/defer.py\", line 654, in _runCallbacks\r\n    current.result = callback(current.result, *args, **kw)\r\n  File \"/home/lukas/Projects/3rd/scrapy/scrapy/core/engine.py\", line 328, in <lambda>\r\n    dfd.addBoth(lambda _: self.crawler.stats.close_spider(spider, reason=reason))\r\n  File \"/home/lukas/Projects/3rd/scrapy/scrapy/statscollectors.py\", line 48, in close_spider\r\n    self._persist_stats(self._stats, spider)\r\n  File \"/home/lukas/Projects/3rd/scrapy/scrapy/statscollectors.py\", line 61, in _persist_stats\r\n    self.spider_stats[spider.name] = stats\r\nTypeError: unhashable type: 'list'\r\n```\r\n\r\nThe exception is only logged by scrapy.core.engine and hence swallowed by py.test. I discovered it accidentally when using the `log_cli = true` pytest setting.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Set `log_cli = true` in pytest.ini\r\n2. Run `tox -e py -- tests/test_scheduler.py -k test_integration_downloader_aware_priority_queue`\r\n\r\n### Versions\r\n\r\nScrapy 2.1.0 / master\r\n\r\n### Additional context\r\n\r\nThe issue should be simple to fix, I will prepare a PR for it.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4644/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4644/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4643", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4643/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4643/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4643/events", "html_url": "https://github.com/scrapy/scrapy/issues/4643", "id": 643192399, "node_id": "MDU6SXNzdWU2NDMxOTIzOTk=", "number": 4643, "title": "Allow run pyw scripts", "user": {"login": "aerdnar", "id": 26771443, "node_id": "MDQ6VXNlcjI2NzcxNDQz", "avatar_url": "https://avatars.githubusercontent.com/u/26771443?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aerdnar", "html_url": "https://github.com/aerdnar", "followers_url": "https://api.github.com/users/aerdnar/followers", "following_url": "https://api.github.com/users/aerdnar/following{/other_user}", "gists_url": "https://api.github.com/users/aerdnar/gists{/gist_id}", "starred_url": "https://api.github.com/users/aerdnar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aerdnar/subscriptions", "organizations_url": "https://api.github.com/users/aerdnar/orgs", "repos_url": "https://api.github.com/users/aerdnar/repos", "events_url": "https://api.github.com/users/aerdnar/events{/privacy}", "received_events_url": "https://api.github.com/users/aerdnar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 318523681, "node_id": "MDU6TGFiZWwzMTg1MjM2ODE=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/Windows", "name": "Windows", "color": "fad8c7", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-22T16:03:21Z", "updated_at": "2020-10-01T18:53:09Z", "closed_at": "2020-10-01T18:53:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "scrapy/commands/runspider.py check for Python script source but it fails to allow .pyw files.\r\nCheck at row 14 is:\r\n`    if fext != '.py':`\r\nbut it should be:\r\n`    if fext != '.py' and fext != '.pyw':`", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4643/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4643/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4621", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4621/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4621/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4621/events", "html_url": "https://github.com/scrapy/scrapy/issues/4621", "id": 636022807, "node_id": "MDU6SXNzdWU2MzYwMjI4MDc=", "number": 4621, "title": "Storage.store is called only for the first feed when empty", "user": {"login": "StasDeep", "id": 17574404, "node_id": "MDQ6VXNlcjE3NTc0NDA0", "avatar_url": "https://avatars.githubusercontent.com/u/17574404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/StasDeep", "html_url": "https://github.com/StasDeep", "followers_url": "https://api.github.com/users/StasDeep/followers", "following_url": "https://api.github.com/users/StasDeep/following{/other_user}", "gists_url": "https://api.github.com/users/StasDeep/gists{/gist_id}", "starred_url": "https://api.github.com/users/StasDeep/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/StasDeep/subscriptions", "organizations_url": "https://api.github.com/users/StasDeep/orgs", "repos_url": "https://api.github.com/users/StasDeep/repos", "events_url": "https://api.github.com/users/StasDeep/events{/privacy}", "received_events_url": "https://api.github.com/users/StasDeep/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-10T07:57:56Z", "updated_at": "2020-06-17T15:08:15Z", "closed_at": "2020-06-17T15:08:15Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\nWhen having `FEED_STORE_EMPTY=False` and multiple feeds, and the output is empty, `storage.store` is called until first empty feed slot is encountered.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Create a `test.py` file with [this spider](https://gist.github.com/StasDeep/c7f0b775eb4897b1012f2c76ce6296f5)\r\n2. `scrapy runspider test.py -L INFO`\r\n\r\n**Expected behavior:**\r\n\r\n```\r\n2020-06-10 10:50:27 [test] INFO: Storing in thread: gs://bucket/output.json\r\n2020-06-10 10:50:27 [test] INFO: Storing in thread: gs://bucket/output.csv\r\n```\r\n\r\n**Actual behavior:**\r\n\r\n```\r\n2020-06-10 10:50:27 [test] INFO: Storing in thread: gs://bucket/output.json\r\n```\r\n\r\n**Reproduces how often:** always\r\n\r\n### Versions\r\n\r\n```\r\nScrapy       : 2.1.0\r\nlxml         : 4.5.1.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 20.3.0\r\nPython       : 3.7.4 (default, Sep  4 2019, 15:20:53) - [Clang 10.0.0 (clang-1000.10.44.4)]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020)\r\ncryptography : 2.9.2\r\nPlatform     : Darwin-19.4.0-x86_64-i386-64bit\r\n```\r\n\r\n### Reason\r\n\r\nIn `FeedExporter.close_spider`, it **returns** a deferred from inside a loop instead of adding it to `deferred_list`\r\n\r\n```\r\n        deferred_list = []\r\n        for slot in self.slots:\r\n            if not slot.itemcount and not slot.store_empty:\r\n                # We need to call slot.storage.store nonetheless to get the file\r\n                # properly closed.\r\n                return defer.maybeDeferred(slot.storage.store, slot.file)\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4621/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4621/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4619", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4619/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4619/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4619/events", "html_url": "https://github.com/scrapy/scrapy/issues/4619", "id": 635582080, "node_id": "MDU6SXNzdWU2MzU1ODIwODA=", "number": 4619, "title": "Duplicated feed logs when having multiple feeds", "user": {"login": "StasDeep", "id": 17574404, "node_id": "MDQ6VXNlcjE3NTc0NDA0", "avatar_url": "https://avatars.githubusercontent.com/u/17574404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/StasDeep", "html_url": "https://github.com/StasDeep", "followers_url": "https://api.github.com/users/StasDeep/followers", "following_url": "https://api.github.com/users/StasDeep/following{/other_user}", "gists_url": "https://api.github.com/users/StasDeep/gists{/gist_id}", "starred_url": "https://api.github.com/users/StasDeep/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/StasDeep/subscriptions", "organizations_url": "https://api.github.com/users/StasDeep/orgs", "repos_url": "https://api.github.com/users/StasDeep/repos", "events_url": "https://api.github.com/users/StasDeep/events{/privacy}", "received_events_url": "https://api.github.com/users/StasDeep/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-09T16:27:31Z", "updated_at": "2020-06-23T10:33:49Z", "closed_at": "2020-06-23T10:33:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\nWhen I have multiple feeds and a blocking feed storage, I get duplicated feed logs.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Create a `test.py` file with this [spider and settings](https://gist.github.com/StasDeep/236922e448ac33b354cf5ea6612e8fde)\r\n2. `scrapy runspider test.py -L INFO`\r\n\r\n**Expected behavior:**\r\n\r\n```\r\n2020-06-09 19:23:03 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: gs://bucket/output.json\r\n2020-06-09 19:23:03 [scrapy.extensions.feedexport] INFO: Stored csv feed (10 items) in: gs://bucket/output.csv\r\n```\r\n\r\n**Actual behavior:**\r\n\r\n```\r\n2020-06-09 19:23:03 [scrapy.extensions.feedexport] INFO: Stored csv feed (10 items) in: gs://bucket/output.csv\r\n2020-06-09 19:23:03 [scrapy.extensions.feedexport] INFO: Stored csv feed (10 items) in: gs://bucket/output.csv\r\n```\r\n\r\n### Versions\r\n\r\n```\r\nScrapy       : 2.1.0\r\nlxml         : 4.5.1.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.6.0\r\nw3lib        : 1.22.0\r\nTwisted      : 20.3.0\r\nPython       : 3.7.4 (default, Sep  4 2019, 15:20:53) - [Clang 10.0.0 (clang-1000.10.44.4)]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020)\r\ncryptography : 2.9.2\r\nPlatform     : Darwin-19.4.0-x86_64-i386-64bit\r\n```\r\n\r\n### Additional context\r\n\r\nWe use custom GoogleCloudFeedStorage and it takes some time to store the data. While it's doing uploading, next iteration of a for loop inside `FeedExporter.close_spider` comes and creates new `log_args` object, although the last one is used in closure.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4619/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4619/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4597", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4597/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4597/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4597/events", "html_url": "https://github.com/scrapy/scrapy/issues/4597", "id": 625431390, "node_id": "MDU6SXNzdWU2MjU0MzEzOTA=", "number": 4597, "title": "KeyError in is_generator_with_return_value", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-27T06:56:02Z", "updated_at": "2020-05-27T16:42:05Z", "closed_at": "2020-05-27T16:42:05Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "\r\n```Python traceback\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/site-packages/twisted/internet/defer.py\", line 1418, in _inlineCallbacks\r\n    result = g.send(result)\r\n  File \"/app/python/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py\", line 42, in process_request\r\n    defer.returnValue((yield download_func(request=request, spider=spider)))\r\n  File \"/usr/local/lib/python3.8/site-packages/twisted/internet/defer.py\", line 1362, in returnValue\r\n    raise _DefGen_Return(val)\r\ntwisted.internet.defer._DefGen_Return: <200 https://www.example.com>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/python/lib/python3.8/site-packages/scrapy/utils/defer.py\", line 55, in mustbe_deferred\r\n    result = f(*args, **kw)\r\n  File \"/app/python/lib/python3.8/site-packages/scrapy/core/spidermw.py\", line 60, in process_spider_input\r\n    return scrape_func(response, request, spider)\r\n  File \"/app/python/lib/python3.8/site-packages/scrapy/core/scraper.py\", line 148, in call_spider\r\n    warn_on_generator_with_return_value(spider, callback)\r\n  File \"/app/python/lib/python3.8/site-packages/scrapy/utils/misc.py\", line 202, in warn_on_generator_with_return_value\r\n    if is_generator_with_return_value(callable):\r\n  File \"/app/python/lib/python3.8/site-packages/scrapy/utils/misc.py\", line 180, in is_generator_with_return_value\r\n    return _generator_callbacks_cache[callable]\r\n  File \"/app/python/lib/python3.8/site-packages/scrapy/utils/datatypes.py\", line 281, in __getitem__\r\n    return super(LocalWeakReferencedCache, self).__getitem__(key)\r\n  File \"/usr/local/lib/python3.8/weakref.py\", line 383, in __getitem__\r\n    return self.data[ref(key)]\r\nKeyError: <weakref at 0x7f06ff011720; to 'method' at 0x7f07042b5e00 (parse_foo)>\r\n```\r\n\r\nThis is Scrapy 2.0.1. The problem happens only sometimes, but in different spiders in the same project.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4597/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4597/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4592", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4592/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4592/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4592/events", "html_url": "https://github.com/scrapy/scrapy/issues/4592", "id": 623264502, "node_id": "MDU6SXNzdWU2MjMyNjQ1MDI=", "number": 4592, "title": "Remove unneeded escape sequences from documentation API signatures", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-22T14:54:13Z", "updated_at": "2020-06-01T21:30:34Z", "closed_at": "2020-06-01T21:30:34Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I\u2019ve seen a few cases in the documentation like these:\r\n\r\n```rst\r\n.. method:: crawl(\\*args, \\**kwargs)\r\n.. class:: Contract(method, \\*args)\r\n.. method:: from_crawler(crawler, \\*args, \\**kwargs)\r\n```\r\n\r\nThe `\\` preceding the `*` does not seem necessary, and is reaching the rendered documentation.\r\n\r\nNoticed while working on #4161.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4592/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4592/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4587", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4587/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4587/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4587/events", "html_url": "https://github.com/scrapy/scrapy/pull/4587", "id": 621180398, "node_id": "MDExOlB1bGxSZXF1ZXN0NDIwMjc5NjIy", "number": 4587, "title": "logging.rst: remove unused, misleading import", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-19T18:05:58Z", "updated_at": "2020-05-20T17:23:43Z", "closed_at": "2020-05-20T17:23:43Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4587", "html_url": "https://github.com/scrapy/scrapy/pull/4587", "diff_url": "https://github.com/scrapy/scrapy/pull/4587.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4587.patch", "merged_at": "2020-05-20T17:23:43Z"}, "body": "Fixes #4510 ", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4587/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4587/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4578", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4578/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4578/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4578/events", "html_url": "https://github.com/scrapy/scrapy/issues/4578", "id": 618600739, "node_id": "MDU6SXNzdWU2MTg2MDA3Mzk=", "number": 4578, "title": "Downloadable documentation is missing for versions 2.0 and 2.1 on readthedocs.org", "user": {"login": "IlnarSelimcan", "id": 23083718, "node_id": "MDQ6VXNlcjIzMDgzNzE4", "avatar_url": "https://avatars.githubusercontent.com/u/23083718?v=4", "gravatar_id": "", "url": "https://api.github.com/users/IlnarSelimcan", "html_url": "https://github.com/IlnarSelimcan", "followers_url": "https://api.github.com/users/IlnarSelimcan/followers", "following_url": "https://api.github.com/users/IlnarSelimcan/following{/other_user}", "gists_url": "https://api.github.com/users/IlnarSelimcan/gists{/gist_id}", "starred_url": "https://api.github.com/users/IlnarSelimcan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/IlnarSelimcan/subscriptions", "organizations_url": "https://api.github.com/users/IlnarSelimcan/orgs", "repos_url": "https://api.github.com/users/IlnarSelimcan/repos", "events_url": "https://api.github.com/users/IlnarSelimcan/events{/privacy}", "received_events_url": "https://api.github.com/users/IlnarSelimcan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-14T23:43:56Z", "updated_at": "2020-05-19T19:15:55Z", "closed_at": "2020-05-19T15:45:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "For some reason downloadable documentation on https://readthedocs.org/projects/scrapy/downloads/ is available only up to version 1.8.\r\n\r\nThat's a minor issue, but I think that I'm not the only one who prefers to read technical papers in the pdf format (to be able to take notes).\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4578/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4578/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4570", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4570/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4570/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4570/events", "html_url": "https://github.com/scrapy/scrapy/issues/4570", "id": 616660380, "node_id": "MDU6SXNzdWU2MTY2NjAzODA=", "number": 4570, "title": "Flake8 build error in Travis", "user": {"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 839225636, "node_id": "MDU6TGFiZWw4MzkyMjU2MzY=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/upstream%20issue", "name": "upstream issue", "color": "c2e0c6", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-05-12T13:32:53Z", "updated_at": "2020-05-13T21:02:04Z", "closed_at": "2020-05-13T21:02:04Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Flake8 checks are currently failing with the following for all files:\r\n```\r\n.tox/flake8/lib/python3.8/site-packages/pluggy/hooks.py:286: in __call__\r\n    return self._hookexec(self, self.get_hookimpls(), kwargs)\r\n.tox/flake8/lib/python3.8/site-packages/pluggy/manager.py:93: in _hookexec\r\n    return self._inner_hookexec(hook, methods, kwargs)\r\n.tox/flake8/lib/python3.8/site-packages/pluggy/manager.py:84: in <lambda>\r\n    self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(\r\n.tox/flake8/lib/python3.8/site-packages/_pytest/runner.py:134: in pytest_runtest_call\r\n    item.runtest()\r\n.tox/flake8/lib/python3.8/site-packages/pytest_flake8.py:119: in runtest\r\n    found_errors, out, err = call(\r\n.tox/flake8/lib/python3.8/site-packages/py/_io/capture.py:150: in call\r\n    res = func(*args, **kwargs)\r\n.tox/flake8/lib/python3.8/site-packages/pytest_flake8.py:191: in check_file\r\n    app.parse_preliminary_options_and_args(args)\r\nE   AttributeError: 'Application' object has no attribute 'parse_preliminary_options_and_args'\r\n```\r\n\r\nFailed builds:\r\n* https://travis-ci.org/github/scrapy/scrapy/jobs/686060612\r\n* https://travis-ci.org/github/scrapy/scrapy/jobs/685973155\r\n\r\nI suspect there might have been some change in a recent release of `pytest-flake8`, and pinning the version would solve the problem.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4570/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4570/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4547", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4547/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4547/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4547/events", "html_url": "https://github.com/scrapy/scrapy/issues/4547", "id": 613920912, "node_id": "MDU6SXNzdWU2MTM5MjA5MTI=", "number": 4547, "title": "Review unicode references", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-05-07T09:47:03Z", "updated_at": "2020-08-04T18:34:12Z", "closed_at": "2020-08-04T18:34:12Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The documentation still has some references to Python 2\u2019s `unicode`. We need to review them, and update them as needed (usually changing them to `str` or \u201cstring\u201d).", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4547/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4547/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4514", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4514/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4514/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4514/events", "html_url": "https://github.com/scrapy/scrapy/issues/4514", "id": 607615491, "node_id": "MDU6SXNzdWU2MDc2MTU0OTE=", "number": 4514, "title": "Outdated item pipeline example about Deferred", "user": {"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-27T14:53:50Z", "updated_at": "2020-05-22T18:12:58Z", "closed_at": "2020-05-22T18:12:58Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The [_Take screenshot of item_](https://docs.scrapy.org/en/latest/topics/item-pipeline.html#take-screenshot-of-item) example says \"This example demonstrates how to return a Deferred from the process_item() method\", but that is no longer the case (async/await syntax is currently used).\r\nI think we should remove that sentence ~and add a reminder about [enabling the `asyncio` reactor](https://docs.scrapy.org/en/latest/topics/asyncio.html#installing-the-asyncio-reactor).~\r\n\r\nAlso, I wonder if it'd be good to also restore the previous `Deferred` example and keep both of them, since not all projects might be able/willing to switch to the `asyncio` reactor.\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4514/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4514/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4511", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4511/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4511/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4511/events", "html_url": "https://github.com/scrapy/scrapy/issues/4511", "id": 605675288, "node_id": "MDU6SXNzdWU2MDU2NzUyODg=", "number": 4511, "title": "Remove the asyncio warning from the page about coroutines", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-04-23T16:29:00Z", "updated_at": "2020-04-27T17:45:19Z", "closed_at": "2020-04-27T17:45:19Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "It\u2019s a leftover from a point where both the coroutines and the asyncio pages were a single page.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4511/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4511/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4510", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4510/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4510/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4510/events", "html_url": "https://github.com/scrapy/scrapy/issues/4510", "id": 604187291, "node_id": "MDU6SXNzdWU2MDQxODcyOTE=", "number": 4510, "title": "configure_logging documentation example incomplete", "user": {"login": "vccolombo", "id": 19277813, "node_id": "MDQ6VXNlcjE5Mjc3ODEz", "avatar_url": "https://avatars.githubusercontent.com/u/19277813?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vccolombo", "html_url": "https://github.com/vccolombo", "followers_url": "https://api.github.com/users/vccolombo/followers", "following_url": "https://api.github.com/users/vccolombo/following{/other_user}", "gists_url": "https://api.github.com/users/vccolombo/gists{/gist_id}", "starred_url": "https://api.github.com/users/vccolombo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vccolombo/subscriptions", "organizations_url": "https://api.github.com/users/vccolombo/orgs", "repos_url": "https://api.github.com/users/vccolombo/repos", "events_url": "https://api.github.com/users/vccolombo/events{/privacy}", "received_events_url": "https://api.github.com/users/vccolombo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-21T18:18:48Z", "updated_at": "2020-05-20T17:23:43Z", "closed_at": "2020-05-20T17:23:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello!\r\n\r\nI think the [configure_logging](https://docs.scrapy.org/en/latest/topics/logging.html#scrapy.utils.log.configure_logging) example is missing something. It imports `configure_logging` but never uses it.\r\n\r\nCould you take a look at it please?\r\nThank you!\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4510/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4510/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4496", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4496/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4496/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4496/events", "html_url": "https://github.com/scrapy/scrapy/issues/4496", "id": 600486666, "node_id": "MDU6SXNzdWU2MDA0ODY2NjY=", "number": 4496, "title": "Fix the hoverxref configuration", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/27", "html_url": "https://github.com/scrapy/scrapy/milestone/27", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/27/labels", "id": 5102632, "node_id": "MDk6TWlsZXN0b25lNTEwMjYzMg==", "number": 27, "title": "v2.1", "description": "", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 5, "state": "closed", "created_at": "2020-02-13T13:01:05Z", "updated_at": "2020-05-03T22:41:02Z", "due_on": "2020-04-24T07:00:00Z", "closed_at": "2020-05-03T22:41:02Z"}, "comments": 0, "created_at": "2020-04-15T18:00:50Z", "updated_at": "2020-04-16T13:19:46Z", "closed_at": "2020-04-16T13:19:46Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "> You shouldn't override hoverxref_version and hoverxref_project since they are taken automatically from Read the Docs.\r\n>\r\n> If you want to avoid your CI failing because of this, you can define the environment variables as Read the Docs does:\r\n> \r\n> READTHEDOCS_PROJECT=scrapy\r\n> READTHEDOCS_VERSION=''\r\n> \r\n> With the current configuration, all the versions built on Read the Docs will point to a different version on Read the Docs and this will conflict. For example, current master version in Read the Docs defines hoverxref_version='2.0.0' but that version does not exist on Read the Docs and the tooltip does not known where to get the content from.\r\n\r\n@humitos at https://github.com/scrapy/scrapy/pull/4480#discussion_r409026912", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4496/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4496/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4485", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4485/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4485/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4485/events", "html_url": "https://github.com/scrapy/scrapy/issues/4485", "id": 598399773, "node_id": "MDU6SXNzdWU1OTgzOTk3NzM=", "number": 4485, "title": "TWISTED_REACTOR setting not honored from Spider.custom_settings", "user": {"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 3270783977, "node_id": "MDU6TGFiZWwzMjcwNzgzOTc3", "url": "https://api.github.com/repos/scrapy/scrapy/labels/asyncio", "name": "asyncio", "color": "fef2c0", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2020-04-12T03:17:20Z", "updated_at": "2022-01-06T06:31:59Z", "closed_at": "2022-01-06T06:31:59Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "### Description\r\n\r\nThe value of the `TWISTED_REACTOR` setting is not taken into account if the setting is specified in a spider's `custom_settings` attribute.\r\nIt works well if the setting is specified in a project's settings file, as a parameter when creating a `CrawlerProcess` object (as the tests show) or as a CLI argument with the `-s` option. \r\n\r\n### Steps to Reproduce\r\n\r\n1. Create a file with the following contents:\r\n```python\r\n# asyncio_spider.py\r\nimport asyncio\r\n\r\nfrom scrapy import Spider\r\n\r\n\r\nclass AsyncIOSpider(Spider):\r\n    name = \"asyncio\"\r\n    start_urls = [\"https://example.org\"]\r\n    custom_settings = {\r\n        \"TWISTED_REACTOR\": \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\",\r\n    }\r\n\r\n    async def parse(self, response):\r\n        await asyncio.sleep(1)\r\n        yield {\"foo\": \"bar\"}\r\n```\r\n\r\n2. Execute the spider: `scrapy runspider asyncio_spider.py`\r\n\r\n**Expected behavior:** \r\nThe spider should run fine, without exceptions\r\n\r\n**Actual behavior:**\r\nThe following exception is raised:\r\n```\r\n2020-04-12 00:04:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://example.org> (referer: None)\r\nTraceback (most recent call last):\r\n  File \"/.../scrapy/venv-scrapy/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1418, in _inlineCallbacks\r\n    result = g.send(result)\r\n  File \"/.../scrapy/scrapy/utils/py36.py\", line 8, in collect_asyncgen\r\n    async for x in result:\r\n  File \"/.../scrapy/test-spiders/asyncio_spider.py\", line 14, in parse\r\n    await asyncio.sleep(1)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/tasks.py\", line 595, in sleep\r\n    return await future\r\nRuntimeError: await wasn't used with future\r\n```\r\nThis is because the `asyncio`-based reactor is not actually installed, as the third log line of the job shows:\r\n```\r\n2020-04-12 00:04:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\r\n```\r\n\r\nFull logs:\r\n```\r\n2020-04-12 00:04:23 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: scrapybot)\r\n2020-04-12 00:04:23 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.4 (v3.7.4:e09359112e, Jul  8 2019, 14:54:52) - [Clang 6.0 (clang-600.0.57)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-18.7.0-x86_64-i386-64bit\r\n2020-04-12 00:04:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\r\n2020-04-12 00:04:23 [scrapy.crawler] INFO: Overridden settings:\r\n{'EDITOR': 'nano',\r\n 'SPIDER_LOADER_WARN_ONLY': True,\r\n 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\r\n2020-04-12 00:04:23 [scrapy.extensions.telnet] INFO: Telnet Password: a2bd966307b319f0\r\n2020-04-12 00:04:23 [scrapy.middleware] INFO: Enabled extensions:\r\n['scrapy.extensions.corestats.CoreStats',\r\n 'scrapy.extensions.telnet.TelnetConsole',\r\n 'scrapy.extensions.memusage.MemoryUsage',\r\n 'scrapy.extensions.logstats.LogStats']\r\n2020-04-12 00:04:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\r\n['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\r\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\r\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\r\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\r\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\r\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\r\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\r\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\r\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\r\n2020-04-12 00:04:23 [scrapy.middleware] INFO: Enabled spider middlewares:\r\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\r\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\r\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\r\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\r\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\r\n2020-04-12 00:04:23 [scrapy.middleware] INFO: Enabled item pipelines:\r\n[]\r\n2020-04-12 00:04:23 [scrapy.core.engine] INFO: Spider opened\r\n2020-04-12 00:04:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2020-04-12 00:04:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\r\n2020-04-12 00:04:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://example.org> (referer: None)\r\n2020-04-12 00:04:23 [asyncio] DEBUG: Using selector: KqueueSelector\r\n2020-04-12 00:04:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://example.org> (referer: None)\r\nTraceback (most recent call last):\r\n  File \"/.../scrapy/venv-scrapy/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1418, in _inlineCallbacks\r\n    result = g.send(result)\r\n  File \"/.../scrapy/scrapy/utils/py36.py\", line 8, in collect_asyncgen\r\n    async for x in result:\r\n  File \"/.../scrapy/test-spiders/asyncio_spider.py\", line 14, in parse\r\n    await asyncio.sleep(1)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/tasks.py\", line 595, in sleep\r\n    return await future\r\nRuntimeError: await wasn't used with future\r\n2020-04-12 00:04:23 [scrapy.core.engine] INFO: Closing spider (finished)\r\n2020-04-12 00:04:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\r\n{'downloader/request_bytes': 211,\r\n 'downloader/request_count': 1,\r\n 'downloader/request_method_count/GET': 1,\r\n 'downloader/response_bytes': 1001,\r\n 'downloader/response_count': 1,\r\n 'downloader/response_status_count/200': 1,\r\n 'elapsed_time_seconds': 0.778025,\r\n 'finish_reason': 'finished',\r\n 'finish_time': datetime.datetime(2020, 4, 12, 3, 4, 23, 925629),\r\n 'log_count/DEBUG': 2,\r\n 'log_count/ERROR': 1,\r\n 'log_count/INFO': 10,\r\n 'memusage/max': 54767616,\r\n 'memusage/startup': 54767616,\r\n 'response_received_count': 1,\r\n 'scheduler/dequeued': 1,\r\n 'scheduler/dequeued/memory': 1,\r\n 'scheduler/enqueued': 1,\r\n 'scheduler/enqueued/memory': 1,\r\n 'spider_exceptions/RuntimeError': 1,\r\n 'start_time': datetime.datetime(2020, 4, 12, 3, 4, 23, 147604)}\r\n2020-04-12 00:04:23 [scrapy.core.engine] INFO: Spider closed (finished)\r\n```\r\n\r\n**Reproduces how often:**\r\n100% of the times.\r\n\r\n### Versions\r\n```\r\nScrapy       : 2.0.1\r\nlxml         : 4.5.0.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 20.3.0\r\nPython       : 3.7.4 (v3.7.4:e09359112e, Jul  8 2019, 14:54:52) - [Clang 6.0 (clang-600.0.57)]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019)\r\ncryptography : 2.8\r\nPlatform     : Darwin-18.7.0-x86_64-i386-64bit\r\n```\r\n```\r\nScrapy       : 2.0.1\r\nlxml         : 4.5.0.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.10.0\r\nPython       : 3.6.9 (default, Nov  7 2019, 10:44:02) - [GCC 8.3.0]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019)\r\ncryptography : 2.8\r\nPlatform     : Linux-4.15.0-96-generic-x86_64-with-LinuxMint-19.1-tessa\r\n```\r\n\r\n### Additional context\r\nFrom a quick look, it seems like this happens because the custom reactor is installed in [`CrawlerRunner.__init__`](https://github.com/scrapy/scrapy/blob/2.0.1/scrapy/crawler.py#L141), but the spider class is only available in [`CrawlerRunner.crawl`](https://github.com/scrapy/scrapy/blob/2.0.1/scrapy/crawler.py#L150) or [`CrawlerRunner.create_crawler`](https://github.com/scrapy/scrapy/blob/2.0.1/scrapy/crawler.py#L192).", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4485/reactions", "total_count": 7, "+1": 7, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4485/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4477", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4477/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4477/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4477/events", "html_url": "https://github.com/scrapy/scrapy/issues/4477", "id": 596257367, "node_id": "MDU6SXNzdWU1OTYyNTczNjc=", "number": 4477, "title": "is_generator_with_return_value raises IndentationError with a flush left doc string", "user": {"login": "mdaniel", "id": 22526, "node_id": "MDQ6VXNlcjIyNTI2", "avatar_url": "https://avatars.githubusercontent.com/u/22526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mdaniel", "html_url": "https://github.com/mdaniel", "followers_url": "https://api.github.com/users/mdaniel/followers", "following_url": "https://api.github.com/users/mdaniel/following{/other_user}", "gists_url": "https://api.github.com/users/mdaniel/gists{/gist_id}", "starred_url": "https://api.github.com/users/mdaniel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mdaniel/subscriptions", "organizations_url": "https://api.github.com/users/mdaniel/orgs", "repos_url": "https://api.github.com/users/mdaniel/repos", "events_url": "https://api.github.com/users/mdaniel/events{/privacy}", "received_events_url": "https://api.github.com/users/mdaniel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-08T02:04:08Z", "updated_at": "2021-03-22T14:51:12Z", "closed_at": "2021-03-22T14:51:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nCode that is accepted by the python interpreter raises when fed through `textwrap.dedent`\r\n\r\n### Steps to Reproduce\r\n\r\n1. Create `is_generator_bug.py` with the content below (which I simplified from [the `is_generator_with_return_value` method body](https://github.com/scrapy/scrapy/blob/2.0.1/scrapy/utils/misc.py#L186-L187)\r\n2. Run `python is_generator_bug.py`\r\n3. Observe the kaboom\r\n\r\n```python\r\nimport ast\r\nimport inspect\r\nfrom textwrap import dedent\r\nclass Bob:\r\n    def doit(self):\r\n        \"\"\"\r\nthis line is flush left\r\n        \"\"\"\r\n        if True:\r\n            yield 1234\r\n\r\nif __name__ == '__main__':\r\n    b = Bob()\r\n    c = b.doit\r\n    if inspect.isgeneratorfunction(c):\r\n        tree = ast.parse(dedent(inspect.getsource(c)))\r\n```\r\n\r\n**Expected behavior:** [What you expect to happen]\r\n\r\nNo Error\r\n\r\n**Actual behavior:** [What actually happens]\r\n\r\n```console\r\n$ python3.7 is_generator_bug.py\r\nTraceback (most recent call last):\r\n  File \"is_generator_bug.py\", line 16, in <module>\r\n    tree = ast.parse(dedent(inspect.getsource(c)))\r\n  File \"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\", line 35, in parse\r\n    return compile(source, filename, mode, PyCF_ONLY_AST)\r\n  File \"<unknown>\", line 1\r\n    def doit(self):\r\n    ^\r\nIndentationError: unexpected indent\r\n```\r\n\r\n**Reproduces how often:** [What percentage of the time does it reproduce?]\r\n\r\n100%\r\n\r\n### Versions\r\n\r\n```\r\nScrapy       : 2.0.1\r\nlxml         : 4.5.0.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 20.3.0\r\nPython       : 3.7.7 (default, Mar 11 2020, 23:30:22) - [Clang 10.0.0 (clang-1000.11.45.5)]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019)\r\ncryptography : 2.8\r\nPlatform     : Darwin-17.7.0-x86_64-i386-64bit\r\n```\r\n\r\n### Additional context\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4477/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4477/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4475", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4475/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4475/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4475/events", "html_url": "https://github.com/scrapy/scrapy/issues/4475", "id": 594729370, "node_id": "MDU6SXNzdWU1OTQ3MjkzNzA=", "number": 4475, "title": "The documentation cannot be built with Sphinx 3", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}, {"id": 839225636, "node_id": "MDU6TGFiZWw4MzkyMjU2MzY=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/upstream%20issue", "name": "upstream issue", "color": "c2e0c6", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/27", "html_url": "https://github.com/scrapy/scrapy/milestone/27", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/27/labels", "id": 5102632, "node_id": "MDk6TWlsZXN0b25lNTEwMjYzMg==", "number": 27, "title": "v2.1", "description": "", "creator": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 5, "state": "closed", "created_at": "2020-02-13T13:01:05Z", "updated_at": "2020-05-03T22:41:02Z", "due_on": "2020-04-24T07:00:00Z", "closed_at": "2020-05-03T22:41:02Z"}, "comments": 5, "created_at": "2020-04-06T00:29:27Z", "updated_at": "2020-04-15T17:42:50Z", "closed_at": "2020-04-15T17:42:50Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4475/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4475/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4408", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4408/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4408/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4408/events", "html_url": "https://github.com/scrapy/scrapy/issues/4408", "id": 577045275, "node_id": "MDU6SXNzdWU1NzcwNDUyNzU=", "number": 4408, "title": "follow_all fails with an empty list of URLs", "user": {"login": "ivanprado", "id": 895720, "node_id": "MDQ6VXNlcjg5NTcyMA==", "avatar_url": "https://avatars.githubusercontent.com/u/895720?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ivanprado", "html_url": "https://github.com/ivanprado", "followers_url": "https://api.github.com/users/ivanprado/followers", "following_url": "https://api.github.com/users/ivanprado/following{/other_user}", "gists_url": "https://api.github.com/users/ivanprado/gists{/gist_id}", "starred_url": "https://api.github.com/users/ivanprado/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ivanprado/subscriptions", "organizations_url": "https://api.github.com/users/ivanprado/orgs", "repos_url": "https://api.github.com/users/ivanprado/repos", "events_url": "https://api.github.com/users/ivanprado/events{/privacy}", "received_events_url": "https://api.github.com/users/ivanprado/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/28", "html_url": "https://github.com/scrapy/scrapy/milestone/28", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/28/labels", "id": 5194901, "node_id": "MDk6TWlsZXN0b25lNTE5NDkwMQ==", "number": 28, "title": "v2.0.1", "description": "", "creator": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 7, "state": "closed", "created_at": "2020-03-12T12:33:20Z", "updated_at": "2020-03-19T13:29:14Z", "due_on": "2020-03-31T07:00:00Z", "closed_at": "2020-03-19T13:29:14Z"}, "comments": 0, "created_at": "2020-03-06T16:36:29Z", "updated_at": "2020-03-12T13:44:49Z", "closed_at": "2020-03-12T13:44:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\n`follow_all` with an empty list of urls fails with `ValueError('Please supply exactly one of the following arguments: urls, css, xpath')`\r\n\r\nWhat I would expect instead is just an empty generator of requests. \r\n\r\n### Steps to Reproduce\r\n\r\n```py\r\nclass Spider(scrapy.Spider):\r\n\r\n    def parse(self, response):\r\n        yield from response.follow_all([], self.parse)\r\n```\r\n\r\n**Expected behavior:** \r\n\r\nNo error is raised\r\n\r\n**Actual behavior:**\r\n\r\n`ValueError('Please supply exactly one of the following arguments: urls, css, xpath')` exception is raised. \r\n\r\n\r\n### Versions\r\n\r\n2.0\r\n\r\n### Additional context\r\n\r\nI think the solution is just a matter of changing this line: https://github.com/scrapy/scrapy/blob/master/scrapy/http/response/text.py#L191\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4408/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4408/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4393", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4393/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4393/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4393/events", "html_url": "https://github.com/scrapy/scrapy/issues/4393", "id": 573885381, "node_id": "MDU6SXNzdWU1NzM4ODUzODE=", "number": 4393, "title": "scrapy parse emits ANSI color sequences in the Windows terminal", "user": {"login": "A-hoy", "id": 55936555, "node_id": "MDQ6VXNlcjU1OTM2NTU1", "avatar_url": "https://avatars.githubusercontent.com/u/55936555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/A-hoy", "html_url": "https://github.com/A-hoy", "followers_url": "https://api.github.com/users/A-hoy/followers", "following_url": "https://api.github.com/users/A-hoy/following{/other_user}", "gists_url": "https://api.github.com/users/A-hoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/A-hoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/A-hoy/subscriptions", "organizations_url": "https://api.github.com/users/A-hoy/orgs", "repos_url": "https://api.github.com/users/A-hoy/repos", "events_url": "https://api.github.com/users/A-hoy/events{/privacy}", "received_events_url": "https://api.github.com/users/A-hoy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 318523681, "node_id": "MDU6TGFiZWwzMTg1MjM2ODE=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/Windows", "name": "Windows", "color": "fad8c7", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-03-02T10:45:39Z", "updated_at": "2020-07-28T11:13:20Z", "closed_at": "2020-07-28T11:13:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\ni try to use `scrapy parse` command in cmd\uff08anaconda env\uff09\uff0cbut when it logs Scraped Items and Requests, there are full of  garbled code which i show you below\uff08Additional context\uff09. I have no idea of it, but it seems to have nothing to do with character encoding,\r\n\r\n### Steps to Reproduce\r\nrunning command\r\n```\r\n>>> scrapy parse --spider=quotes3 http://quotes.toscrape.com/page/1/\r\n```\r\nthe `quotes3` spider shows below\uff08Additional context\uff09\r\n\r\n**Expected behavior:** without garbled code\r\n\r\n**Actual behavior:** garbled code appears\r\n\r\n**Reproduces how often:** every time\r\n\r\n### Versions\r\nScrapy       : 1.8.0\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.10.0\r\nPython       : 3.7.4 (default, Aug  9 2019, 18:22:51) [MSC v.1915 32 bit (Intel)]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1d  10 Sep 2019)\r\ncryptography : 2.7\r\nPlatform     : Windows-10-10.0.18362-SP0\r\n\r\n### Additional context\r\nspider.py\r\n```\r\nclass QuotesSpider3(scrapy.Spider):\r\n    name = 'quotes3'\r\n    start_urls = ['http://quotes.toscrape.com/page/1/']\r\n\r\n    def parse(self, response):\r\n        for quote in response.xpath('//div[@class=\"quote\"]'):\r\n            yield {\r\n                'text':\r\n                quote.xpath('span[@class=\"text\"]/text()').get(),\r\n                'author':\r\n                quote.xpath('.//small[@class=\"author\"]/text()').get(),\r\n                'tags':\r\n                quote.xpath(\r\n                    'div[@class=\"tags\"]//a[@class=\"tag\"]/text()').getall()\r\n            }\r\n\r\n        next_page = response.xpath('//li[@class=\"next\"]//a/@href').get()\r\n        if next_page is not None:\r\n            next_page = response.urljoin(next_page)\r\n            yield scrapy.Request(next_page, callback=self.parse)\r\n```\r\n\r\n```\r\n(base) D:\\scrapy_project>chcp\r\nActive code page: 65001\r\n\r\n(base) D:\\scrapy_project>scrapy parse --spider=quotes3 http://quotes.toscrape.com/page/1/\r\n2020-03-02 18:27:36 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: demo1)\r\n2020-03-02 18:27:36 [scrapy.utils.log] INFO: Versions: lxml 4.4.1.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (default, Aug  9 2019, 18:22:51) [MSC v.1915 32 bit (Intel)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.7, Platform Windows-10-10.0.18362-SP0\r\n2020-03-02 18:27:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'demo1', 'NEWSPIDER_MODULE': 'demo1.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['demo1.spiders']}\r\n2020-03-02 18:27:36 [scrapy.extensions.telnet] INFO: Telnet Password: 67f8ee92329c4e99\r\n2020-03-02 18:27:37 [scrapy.middleware] INFO: Enabled extensions:\r\n['scrapy.extensions.corestats.CoreStats',\r\n 'scrapy.extensions.telnet.TelnetConsole',\r\n 'scrapy.extensions.logstats.LogStats']\r\n2020-03-02 18:27:39 [scrapy.middleware] INFO: Enabled downloader middlewares:\r\n['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\r\n 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\r\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\r\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\r\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\r\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\r\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\r\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\r\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\r\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\r\n2020-03-02 18:27:39 [scrapy.middleware] INFO: Enabled spider middlewares:\r\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\r\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\r\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\r\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\r\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\r\n2020-03-02 18:27:39 [scrapy.middleware] INFO: Enabled item pipelines:\r\n[]\r\n2020-03-02 18:27:39 [scrapy.core.engine] INFO: Spider opened\r\n2020-03-02 18:27:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2020-03-02 18:27:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\r\n2020-03-02 18:27:44 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)\r\n2020-03-02 18:27:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)\r\n2020-03-02 18:27:52 [scrapy.core.engine] INFO: Closing spider (finished)\r\n2020-03-02 18:27:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\r\n{'downloader/request_bytes': 453,\r\n 'downloader/request_count': 2,\r\n 'downloader/request_method_count/GET': 2,\r\n 'downloader/response_bytes': 2719,\r\n 'downloader/response_count': 2,\r\n 'downloader/response_status_count/200': 1,\r\n 'downloader/response_status_count/404': 1,\r\n 'elapsed_time_seconds': 12.789971,\r\n 'finish_reason': 'finished',\r\n 'finish_time': datetime.datetime(2020, 3, 2, 10, 27, 52, 44220),\r\n 'log_count/DEBUG': 2,\r\n 'log_count/INFO': 10,\r\n 'response_received_count': 2,\r\n 'robotstxt/request_count': 1,\r\n 'robotstxt/response_count': 1,\r\n 'robotstxt/response_status_count/404': 1,\r\n 'scheduler/dequeued': 1,\r\n 'scheduler/dequeued/memory': 1,\r\n 'scheduler/enqueued': 1,\r\n 'scheduler/enqueued/memory': 1,\r\n 'start_time': datetime.datetime(2020, 3, 2, 10, 27, 39, 254249)}\r\n2020-03-02 18:27:52 [scrapy.core.engine] INFO: Spider closed (finished)\r\n\r\n>>> STATUS DEPTH LEVEL 1 <<<\r\n# Scraped Items  ------------------------------------------------------------\r\n[{\u001b[33m'\u001b[39;49;00m\u001b[33mauthor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mAlbert Einstein\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtags\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mchange\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mdeep-thoughts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mthinking\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mworld\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m\u201cThe world as we have created it is a process of our thinking. It \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n          \u001b[33m'\u001b[39;49;00m\u001b[33mcannot be changed without changing our thinking.\u201d\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n {\u001b[33m'\u001b[39;49;00m\u001b[33mauthor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mJ.K. Rowling\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtags\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mabilities\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mchoices\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m\u201cIt is our choices, Harry, that show what we truly are, far more \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n          \u001b[33m'\u001b[39;49;00m\u001b[33mthan our abilities.\u201d\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n {\u001b[33m'\u001b[39;49;00m\u001b[33mauthor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mAlbert Einstein\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtags\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33minspirational\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mlife\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mlive\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mmiracle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mmiracles\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m\u201cThere are only two ways to live your life. One is as though \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n          \u001b[33m'\u001b[39;49;00m\u001b[33mnothing is a miracle. The other is as though everything is a \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n          \u001b[33m'\u001b[39;49;00m\u001b[33mmiracle.\u201d\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n {\u001b[33m'\u001b[39;49;00m\u001b[33mauthor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mJane Austen\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtags\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33maliteracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mbooks\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mclassic\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mhumor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m\u201cThe person, be it gentleman or lady, who has not pleasure in a \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n          \u001b[33m'\u001b[39;49;00m\u001b[33mgood novel, must be intolerably stupid.\u201d\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n {\u001b[33m'\u001b[39;49;00m\u001b[33mauthor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mMarilyn Monroe\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtags\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mbe-yourself\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33minspirational\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33m\u201cImperfection is beauty, madness is genius and it\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33ms better to be \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n          \u001b[33m'\u001b[39;49;00m\u001b[33mabsolutely ridiculous than absolutely boring.\u201d\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n {\u001b[33m'\u001b[39;49;00m\u001b[33mauthor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mAlbert Einstein\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtags\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33madulthood\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33msuccess\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mvalue\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m\u201cTry not to become a man of success. Rather become a man of \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n          \u001b[33m'\u001b[39;49;00m\u001b[33mvalue.\u201d\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n {\u001b[33m'\u001b[39;49;00m\u001b[33mauthor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mAndr\u00e9 Gide\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtags\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mlife\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mlove\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m\u201cIt is better to be hated for what you are than to be loved for \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n          \u001b[33m'\u001b[39;49;00m\u001b[33mwhat you are not.\u201d\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n {\u001b[33m'\u001b[39;49;00m\u001b[33mauthor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mThomas A. Edison\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtags\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33medison\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfailure\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33minspirational\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mparaphrased\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33m\u201cI have not failed. I\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mve just found 10,000 ways that won\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mt work.\u201d\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m},\r\n {\u001b[33m'\u001b[39;49;00m\u001b[33mauthor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mEleanor Roosevelt\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtags\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mmisattributed-eleanor-roosevelt\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m\u201cA woman is like a tea bag; you never know how strong it is until \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n          \u001b[33m\"\u001b[39;49;00m\u001b[33mit\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33ms in hot water.\u201d\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m},\r\n {\u001b[33m'\u001b[39;49;00m\u001b[33mauthor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mSteve Martin\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtags\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mhumor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mobvious\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33msimile\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\r\n  \u001b[33m'\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m\u201cA day without sunshine is like, you know, night.\u201d\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m}]\r\n\r\n# Requests  -----------------------------------------------------------------\r\n[<GET http://quotes.toscrape.com/page/\u001b[34m2\u001b[39;49;00m/>]\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4393/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4393/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4375", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4375/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4375/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4375/events", "html_url": "https://github.com/scrapy/scrapy/pull/4375", "id": 570846570, "node_id": "MDExOlB1bGxSZXF1ZXN0Mzc5ODEzMDQ3", "number": 4375, "title": "Stop deprecation warnings on arbitrary SCRAPY-prefixed env vars", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 255389929, "node_id": "MDU6TGFiZWwyNTUzODk5Mjk=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/backward-incompatible", "name": "backward-incompatible", "color": "eb6420", "default": false, "description": null}, {"id": 280218717, "node_id": "MDU6TGFiZWwyODAyMTg3MTc=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/discuss", "name": "discuss", "color": "cc317c", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/10", "html_url": "https://github.com/scrapy/scrapy/milestone/10", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/10/labels", "id": 1559173, "node_id": "MDk6TWlsZXN0b25lMTU1OTE3Mw==", "number": 10, "title": "v2.0", "description": "**Major goals:** experimental AsyncIO support, Python 2 support drop\r\n\r\n**ETA:** February 2020", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 30, "state": "closed", "created_at": "2016-02-02T17:21:27Z", "updated_at": "2020-03-12T17:34:07Z", "due_on": "2020-02-29T08:00:00Z", "closed_at": "2020-03-12T17:34:07Z"}, "comments": 5, "created_at": "2020-02-25T21:31:33Z", "updated_at": "2020-02-28T08:26:18Z", "closed_at": "2020-02-28T08:26:18Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4375", "html_url": "https://github.com/scrapy/scrapy/pull/4375", "diff_url": "https://github.com/scrapy/scrapy/pull/4375.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4375.patch", "merged_at": "2020-02-28T08:26:18Z"}, "body": "Noticed by @nyov.\r\n\r\nI\u2019m thinking that this is technically backward-incompatible. Before, we were actually defining a `SETTINGS_MODULE` setting, and potentially other variables. Should I just whitelist warning-wise but still allow the setting to be defined?\r\n\r\nDo we issue a specific warning about that? i.e. If a setting named after one of those white-listed variables is read from `Settings`, warn about it.\r\n\r\nTo-Do:\r\n\r\n- [x] Indicate the offending variables, as requested by @nyov \r\n\r\nFixes #4374", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4375/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4375/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4373", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4373/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4373/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4373/events", "html_url": "https://github.com/scrapy/scrapy/pull/4373", "id": 570823592, "node_id": "MDExOlB1bGxSZXF1ZXN0Mzc5NzkzNTg4", "number": 4373, "title": "Fix the ReadTheDocs build", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-02-25T20:49:43Z", "updated_at": "2020-02-25T21:27:13Z", "closed_at": "2020-02-25T21:27:03Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4373", "html_url": "https://github.com/scrapy/scrapy/pull/4373", "diff_url": "https://github.com/scrapy/scrapy/pull/4373.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4373.patch", "merged_at": "2020-02-25T21:27:03Z"}, "body": "@kmike noticed that autodoc was not working, any API documentation extracted from comments was missing in `master`.\r\n\r\nThis started happening when we removed Scrapy dependencies from `docs/requirements.txt`. The build log issued warnings, but Read The Docs was not configured to fail the build in case of warnings. Travis CI would have failed, weren\u2019t it because Tox automatically installs Scrapy from `setup.py`, which ReadTheDocs does not.\r\n\r\nThese changes add the dependencies back to the file, and make warnings cause build failures in ReadTheDocs.\r\n\r\nYou can see it working at https://scrapy-gallaecio.readthedocs.io/en/fix-readthedocs/topics/request-response.html\r\n\r\nI also tried just enabling to fail on warning, and indeed the ReadTheDocs build failed after that.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4373/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4373/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4346", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4346/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4346/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4346/events", "html_url": "https://github.com/scrapy/scrapy/issues/4346", "id": 567586861, "node_id": "MDU6SXNzdWU1Njc1ODY4NjE=", "number": 4346, "title": "FilesDownloader with GCS downloading updtodate files again", "user": {"login": "lblanche", "id": 33354335, "node_id": "MDQ6VXNlcjMzMzU0MzM1", "avatar_url": "https://avatars.githubusercontent.com/u/33354335?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lblanche", "html_url": "https://github.com/lblanche", "followers_url": "https://api.github.com/users/lblanche/followers", "following_url": "https://api.github.com/users/lblanche/following{/other_user}", "gists_url": "https://api.github.com/users/lblanche/gists{/gist_id}", "starred_url": "https://api.github.com/users/lblanche/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lblanche/subscriptions", "organizations_url": "https://api.github.com/users/lblanche/orgs", "repos_url": "https://api.github.com/users/lblanche/repos", "events_url": "https://api.github.com/users/lblanche/events{/privacy}", "received_events_url": "https://api.github.com/users/lblanche/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2020-02-19T13:55:38Z", "updated_at": "2020-05-07T09:30:24Z", "closed_at": "2020-05-07T09:06:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "# Description\r\n\r\nIt seems that when using Google Cloud Storage, the Files pipeline does not have the expected behavior regarding up to date files.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Clone this repo : `git clone https://github.com/QYQ323/python.git`\r\n2. Run the spider : `scrapy crawl examples`\r\n3. If you run it several times, the FilesPipeline has the right behavior : it does not download uptodate files \r\n\r\n```\r\n2020-02-19 14:41:36 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://matplotlib.org/examples/animation/basic_example_writer.py> referred in <None>\r\n2020-02-19 14:41:36 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://matplotlib.org/examples/animation/basic_example.py> referred in <None>\r\n2020-02-19 14:41:36 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://matplotlib.org/examples/animation/bayes_update.py> referred in <None>\r\n```\r\n\r\n4. Now change the `FILE_STORE` in `settings.py` to a gcs bucket\r\n\r\n `FILES_STORE = 'gs://mybucket/' `\r\n\r\n5. If you then run the spider several times, the files are downloaded everytime : \r\n```\r\n2020-02-19 14:50:44 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET https://matplotlib.org/examples/animation/simple_anim.py> referred in <None>\r\n2020-02-19 14:50:44 [urllib3.connectionpool] DEBUG: https://storage.googleapis.com:443 \"POST /upload/storage/v1/b/cdcscrapingresults/o?uploadType=multipart HTTP/1.1\" 200 843\r\n2020-02-19 14:50:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://matplotlib.org/examples/animation/double_pendulum_animated.py> (referer: None)\r\n2020-02-19 14:50:44 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET https://matplotlib.org/examples/animation/double_pendulum_animated.py> referred in <None>\r\n2020-02-19 14:50:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://matplotlib.org/examples/api/collections_demo.html>\r\n```\r\n\r\n\r\n**Expected behavior:** \r\nFiles should not be downloaded again when running the spider consecutively. If a file is allready on GCS (same folder), it should not be downloaded (provided it was uploaded less than 90 days ago) \r\n\r\n**Actual behavior:** \r\nEverytime the spider is launched every file is downloaded again.\r\n\r\n**Reproduces how often:** 100% \r\n\r\n### Versions\r\n\r\nScrapy       : 1.8.0\r\nlxml         : 4.5.0.0\r\nlibxml2      : 2.9.10\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.10.0\r\nPython       : 3.8.1 (default, Jan  8 2020, 16:15:59) - [Clang 4.0.1 (tags/RELEASE_401/final)]\r\npyOpenSSL    : 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019)\r\ncryptography : 2.8\r\nPlatform     : macOS-10.15.3-x86_64-i386-64bit\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4346/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4346/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4332", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4332/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4332/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4332/events", "html_url": "https://github.com/scrapy/scrapy/issues/4332", "id": 565566756, "node_id": "MDU6SXNzdWU1NjU1NjY3NTY=", "number": 4332, "title": "ie. \u2192 i.e.", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-02-14T21:34:24Z", "updated_at": "2020-02-19T15:49:20Z", "closed_at": "2020-02-19T15:49:20Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Looking for `\\bie\\.` in the source code there are quite a few matches.\r\n\r\nAs [noticed](https://github.com/scrapy/scrapy/pull/4331#discussion_r379552909) by @elacuesta, **i.e.** is the [right spelling](https://en.wikipedia.org/wiki/List_of_Latin_phrases_(I)#id_est).", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4332/reactions", "total_count": 2, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 2, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4332/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4308", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4308/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4308/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4308/events", "html_url": "https://github.com/scrapy/scrapy/issues/4308", "id": 560851205, "node_id": "MDU6SXNzdWU1NjA4NTEyMDU=", "number": 4308, "title": "Mac OS X, OS X \u2192 macOS", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-02-06T08:23:42Z", "updated_at": "2020-02-28T19:42:08Z", "closed_at": "2020-02-28T19:42:08Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "We have a few references in the documentation where we use the old name of that OS. We should update them.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4308/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4308/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4290", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4290/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4290/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4290/events", "html_url": "https://github.com/scrapy/scrapy/pull/4290", "id": 555274725, "node_id": "MDExOlB1bGxSZXF1ZXN0MzY3MjUxODIy", "number": 4290, "title": "FilesPipeline.file_path has optional arguments", "user": {"login": "dekimsey", "id": 90741, "node_id": "MDQ6VXNlcjkwNzQx", "avatar_url": "https://avatars.githubusercontent.com/u/90741?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dekimsey", "html_url": "https://github.com/dekimsey", "followers_url": "https://api.github.com/users/dekimsey/followers", "following_url": "https://api.github.com/users/dekimsey/following{/other_user}", "gists_url": "https://api.github.com/users/dekimsey/gists{/gist_id}", "starred_url": "https://api.github.com/users/dekimsey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dekimsey/subscriptions", "organizations_url": "https://api.github.com/users/dekimsey/orgs", "repos_url": "https://api.github.com/users/dekimsey/repos", "events_url": "https://api.github.com/users/dekimsey/events{/privacy}", "received_events_url": "https://api.github.com/users/dekimsey/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-01-26T19:22:22Z", "updated_at": "2020-02-07T18:41:48Z", "closed_at": "2020-02-07T18:41:32Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4290", "html_url": "https://github.com/scrapy/scrapy/pull/4290", "diff_url": "https://github.com/scrapy/scrapy/pull/4290.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4290.patch", "merged_at": "2020-02-07T18:41:32Z"}, "body": "Documented signature doesn't match the actual interface in [files.py](https://github.com/scrapy/scrapy/blob/master/scrapy/pipelines/files.py#L520).\r\n\r\nSpecifically, it looks like it may be [called](https://github.com/scrapy/scrapy/blob/master/scrapy/pipelines/files.py#L422) without a response value.\r\n\r\nI found this when I was implementing the pipeline with the signature `file_path(self, request, response, info)` and the following error was being return in my results :\r\n\r\n    [(False, <twisted.python.failure.Failure builtins.TypeError: file_path() missing 1 required positional argument: 'response'>)]\r\n\r\nScrapy==1.8.0", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4290/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4290/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4289", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4289/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4289/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4289/events", "html_url": "https://github.com/scrapy/scrapy/issues/4289", "id": 555236429, "node_id": "MDU6SXNzdWU1NTUyMzY0Mjk=", "number": 4289, "title": "Fatal error launching scrapy>1.6.0 from Anaconda Prompt", "user": {"login": "pwinzer", "id": 21200820, "node_id": "MDQ6VXNlcjIxMjAwODIw", "avatar_url": "https://avatars.githubusercontent.com/u/21200820?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pwinzer", "html_url": "https://github.com/pwinzer", "followers_url": "https://api.github.com/users/pwinzer/followers", "following_url": "https://api.github.com/users/pwinzer/following{/other_user}", "gists_url": "https://api.github.com/users/pwinzer/gists{/gist_id}", "starred_url": "https://api.github.com/users/pwinzer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pwinzer/subscriptions", "organizations_url": "https://api.github.com/users/pwinzer/orgs", "repos_url": "https://api.github.com/users/pwinzer/repos", "events_url": "https://api.github.com/users/pwinzer/events{/privacy}", "received_events_url": "https://api.github.com/users/pwinzer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 375162916, "node_id": "MDU6TGFiZWwzNzUxNjI5MTY=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/install", "name": "install", "color": "1d76db", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-01-26T14:30:25Z", "updated_at": "2020-05-11T20:02:20Z", "closed_at": "2020-04-09T19:45:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n\r\n### Description\r\n\r\nI'm having the same issue reported in [issue 4075](https://github.com/scrapy/scrapy/issues/4075), but I'd like to provide some more information.\r\n\r\n\r\n### Steps to Reproduce\r\n\r\nFresh Anaconda install, installed scrapy with `conda install -c conda-forge scrapy`, as specified in [official Windows installation instructions](https://docs.scrapy.org/en/latest/intro/install.html#windows). Scrapy 1.8.0 was successfully installed.\r\n\r\nEnter a scrapy command: `scrapy shell`, `scrapy version`, `scrapy startproject spam`, etc. \r\n\r\n**Expected behavior:**\r\n\r\nScrapy commands work as documented, as they have in the past.\r\n\r\n**Actual behavior:**\r\n\r\nScrapy commands yield \r\n`Fatal error in launcher: Unable to create process using '\"d:\\bld\\scrapy_1572360424769\\_h_env\\python.exe\"  \"C:\\Users\\path\\to\\Continuum\\anaconda3\\Scripts\\scrapy.exe\" version'`\r\n\r\nThere is no d:\\ on my machine. I have no idea where this path is coming from.\r\n\r\n**Reproduces how often:**\r\n\r\n100% in my current installation\r\n\r\n**Work around:**\r\n\r\n`python -m scrapy <command>` rather than `scrapy <command>`\r\n\r\n### Versions\r\n\r\n`python -m scrapy version --verbose` yields.\r\nScrapy       : 1.8.0\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.10.0\r\nPython       : 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1d  10 Sep 2019)\r\ncryptography : 2.7\r\nPlatform     : Windows-10-10.0.18362-SP0\r\n\r\n\r\n### Additional context\r\n\r\nIt appears any version after 1.6.0 has this issue. Downgrading to 1.6.0 with `conda install -c conda-forge scrapy=1.6.0` resolves the launching issue. I installed a few versions of 1.7 with `conda install -c conda-forge scrapy=1.7.x` and the launcher issue was present there.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4289/reactions", "total_count": 4, "+1": 4, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4289/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4285", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4285/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4285/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4285/events", "html_url": "https://github.com/scrapy/scrapy/issues/4285", "id": 554660467, "node_id": "MDU6SXNzdWU1NTQ2NjA0Njc=", "number": 4285, "title": "Fix \"Debugging memory leaks with Guppy\" section (docs)", "user": {"login": "noviluni", "id": 22377678, "node_id": "MDQ6VXNlcjIyMzc3Njc4", "avatar_url": "https://avatars.githubusercontent.com/u/22377678?v=4", "gravatar_id": "", "url": "https://api.github.com/users/noviluni", "html_url": "https://github.com/noviluni", "followers_url": "https://api.github.com/users/noviluni/followers", "following_url": "https://api.github.com/users/noviluni/following{/other_user}", "gists_url": "https://api.github.com/users/noviluni/gists{/gist_id}", "starred_url": "https://api.github.com/users/noviluni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/noviluni/subscriptions", "organizations_url": "https://api.github.com/users/noviluni/orgs", "repos_url": "https://api.github.com/users/noviluni/repos", "events_url": "https://api.github.com/users/noviluni/events{/privacy}", "received_events_url": "https://api.github.com/users/noviluni/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-01-24T10:37:54Z", "updated_at": "2020-04-03T02:27:47Z", "closed_at": "2020-04-03T02:27:47Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "After removing the Python 2.7 support, this section:\r\n\r\nhttps://docs.scrapy.org/en/latest/topics/leaks.html#debugging-memory-leaks-with-guppy\r\n\r\n should be removed or merged with this:\r\nhttps://docs.scrapy.org/en/latest/topics/leaks.html#topics-leaks-muppy\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4285/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4285/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4277", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4277/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4277/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4277/events", "html_url": "https://github.com/scrapy/scrapy/issues/4277", "id": 551415490, "node_id": "MDU6SXNzdWU1NTE0MTU0OTA=", "number": 4277, "title": "Response.follow() method not consistent with Request.__init__(). Missing `flags`.", "user": {"login": "LanetheGreat", "id": 15223575, "node_id": "MDQ6VXNlcjE1MjIzNTc1", "avatar_url": "https://avatars.githubusercontent.com/u/15223575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LanetheGreat", "html_url": "https://github.com/LanetheGreat", "followers_url": "https://api.github.com/users/LanetheGreat/followers", "following_url": "https://api.github.com/users/LanetheGreat/following{/other_user}", "gists_url": "https://api.github.com/users/LanetheGreat/gists{/gist_id}", "starred_url": "https://api.github.com/users/LanetheGreat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LanetheGreat/subscriptions", "organizations_url": "https://api.github.com/users/LanetheGreat/orgs", "repos_url": "https://api.github.com/users/LanetheGreat/repos", "events_url": "https://api.github.com/users/LanetheGreat/events{/privacy}", "received_events_url": "https://api.github.com/users/LanetheGreat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 281088273, "node_id": "MDU6TGFiZWwyODEwODgyNzM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/help%20wanted", "name": "help wanted", "color": "009800", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-01-17T13:28:19Z", "updated_at": "2020-02-10T18:48:32Z", "closed_at": "2020-02-10T18:48:32Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Versions Affected:\r\n\r\nAll versions after PR #2082 when flags were added to `Request`. (>1.4.0)\r\n\r\n### Response.follow() method not consistent with Request.__init__(). Missing `flags`.\r\n\r\nNo sure how this got missed since PR #2082 was merged, but looking at the parameters for `Request.__init__` and `Response.follow` it appears `flags` wasn't added to `Response.follow` to keep it in line with how creating new `Request` instances works. I'm not sure if this was just overlooked or was intentional, when `flags` support was added to requests. It's also missing for the subclasses of `Response` as well (`TextResponse` will need updated, the rest currently use inheritance).\r\n\r\nI was looking to be able to add custom `flags` to certain `Response.follow()` calls but realized looking at the source they wouldn't be carried over to the new responses, but this can easily be worked around by manually added the flag after Request creation. This seems like an easy fix to include in 1.8.1 or later but doesn't seem too high priority and I just thought you guys should know or that it should at least be noted somewhere on this repo since the [docs](https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Response.follow) still say, \"It accepts the same arguments as `Request.__init__` method...\".\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4277/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4277/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4272", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4272/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4272/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4272/events", "html_url": "https://github.com/scrapy/scrapy/pull/4272", "id": 547912459, "node_id": "MDExOlB1bGxSZXF1ZXN0MzYxMzEzMzk4", "number": 4272, "title": "Spider middleware: catch spider callback exceptions early", "user": {"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-01-10T07:28:03Z", "updated_at": "2020-02-07T20:38:53Z", "closed_at": "2020-02-07T18:40:51Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4272", "html_url": "https://github.com/scrapy/scrapy/pull/4272", "diff_url": "https://github.com/scrapy/scrapy/pull/4272.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4272.patch", "merged_at": "2020-02-07T18:40:51Z"}, "body": "Fixes #4260.\r\n\r\nEvaluates the output iterable right after the spider callback, as it's currently being done in the `process_spider_output` chain.\r\n\r\n(Plus some minor styling adjustments)", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4272/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4272/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4268", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4268/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4268/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4268/events", "html_url": "https://github.com/scrapy/scrapy/issues/4268", "id": 547417308, "node_id": "MDU6SXNzdWU1NDc0MTczMDg=", "number": 4268, "title": "Random failures in CrawlTestCase.test_fixed_delay", "user": {"login": "wRAR", "id": 241039, "node_id": "MDQ6VXNlcjI0MTAzOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/241039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wRAR", "html_url": "https://github.com/wRAR", "followers_url": "https://api.github.com/users/wRAR/followers", "following_url": "https://api.github.com/users/wRAR/following{/other_user}", "gists_url": "https://api.github.com/users/wRAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/wRAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wRAR/subscriptions", "organizations_url": "https://api.github.com/users/wRAR/orgs", "repos_url": "https://api.github.com/users/wRAR/repos", "events_url": "https://api.github.com/users/wRAR/events{/privacy}", "received_events_url": "https://api.github.com/users/wRAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2020-01-09T11:21:43Z", "updated_at": "2020-02-28T12:17:03Z", "closed_at": "2020-02-28T12:17:03Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "On some test runs `CrawlTestCase.test_fixed_delay`  fails with\r\n```\r\n>       yield self._test_delay(total=3, delay=0.1)\r\nE   twisted.trial.unittest.FailTest: twisted.trial.unittest.FailTest: True is not false : test total or delay values are too small\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4268/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4268/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4264", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4264/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4264/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4264/events", "html_url": "https://github.com/scrapy/scrapy/issues/4264", "id": 544714517, "node_id": "MDU6SXNzdWU1NDQ3MTQ1MTc=", "number": 4264, "title": "Document that Scrapy 1.7.0 breaks custom schedulers", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-01-02T19:34:01Z", "updated_at": "2020-02-06T21:21:34Z", "closed_at": "2020-02-06T21:21:34Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "[This signature change](https://github.com/scrapy/scrapy/commit/821f5bb26077d7f9a6b2b1a72f210f81779f5393#diff-1e8b9699ff2fb363b837e0da1b7eb876R16) introduced in 1.7.0 breaks custom schedulers. It should be covered in the list of 1.7.0 backward-incompatible changes.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4264/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4260", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4260/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4260/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4260/events", "html_url": "https://github.com/scrapy/scrapy/issues/4260", "id": 543821027, "node_id": "MDU6SXNzdWU1NDM4MjEwMjc=", "number": 4260, "title": "First Spider Middleware does not process exception for generator callback", "user": {"login": "StasDeep", "id": 17574404, "node_id": "MDQ6VXNlcjE3NTc0NDA0", "avatar_url": "https://avatars.githubusercontent.com/u/17574404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/StasDeep", "html_url": "https://github.com/StasDeep", "followers_url": "https://api.github.com/users/StasDeep/followers", "following_url": "https://api.github.com/users/StasDeep/following{/other_user}", "gists_url": "https://api.github.com/users/StasDeep/gists{/gist_id}", "starred_url": "https://api.github.com/users/StasDeep/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/StasDeep/subscriptions", "organizations_url": "https://api.github.com/users/StasDeep/orgs", "repos_url": "https://api.github.com/users/StasDeep/repos", "events_url": "https://api.github.com/users/StasDeep/events{/privacy}", "received_events_url": "https://api.github.com/users/StasDeep/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-12-30T10:02:52Z", "updated_at": "2020-02-07T18:40:51Z", "closed_at": "2020-02-07T18:40:51Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\n`process_spider_exception` method of a spider middleware is ignored when spider middleware is first and callback is a generator.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Create spider middleware with defined `process_spider_exception`\r\n2. Put it into `SPIDER_MIDDLEWARES` with number more than `900` (to make it first)\r\n3. Raise an exception in a spider callback\r\n4. UPD. Yield an item from the callback\r\n\r\n**Expected behavior:** `process_spider_exception` is called for this exception\r\n\r\n**Actual behavior:** `process_spider_exception` is not called\r\n\r\n### Versions\r\n\r\n```\r\nScrapy       : 1.7.1\r\nlxml         : 4.2.5.0\r\nlibxml2      : 2.9.8\r\ncssselect    : 1.0.3\r\nparsel       : 1.5.1\r\nw3lib        : 1.19.0\r\nTwisted      : 18.9.0\r\nPython       : 3.6.8 (default, May  8 2019, 05:35:00) - [GCC 6.3.0 20170516]\r\npyOpenSSL    : 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018)\r\ncryptography : 2.4.2\r\nPlatform     : Linux-4.9.184-linuxkit-x86_64-with-debian-9.9\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4260/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4260/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4249", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4249/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4249/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4249/events", "html_url": "https://github.com/scrapy/scrapy/pull/4249", "id": 540244195, "node_id": "MDExOlB1bGxSZXF1ZXN0MzU1MDg1OTYz", "number": 4249, "title": "Use Python 3.7 to build the documentation", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-19T11:07:34Z", "updated_at": "2019-12-19T20:54:31Z", "closed_at": "2019-12-19T20:54:27Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4249", "html_url": "https://github.com/scrapy/scrapy/pull/4249", "diff_url": "https://github.com/scrapy/scrapy/pull/4249.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4249.patch", "merged_at": "2019-12-19T20:54:27Z"}, "body": "I broke the build changing it to 3.8 in #4140, it turns out Read The Docs does not support 3.8 yet.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4249/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4249/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4229", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4229/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4229/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4229/events", "html_url": "https://github.com/scrapy/scrapy/issues/4229", "id": 537528943, "node_id": "MDU6SXNzdWU1Mzc1Mjg5NDM=", "number": 4229, "title": "mail attachs tcmime***", "user": {"login": "Apuyuseng", "id": 17330686, "node_id": "MDQ6VXNlcjE3MzMwNjg2", "avatar_url": "https://avatars.githubusercontent.com/u/17330686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Apuyuseng", "html_url": "https://github.com/Apuyuseng", "followers_url": "https://api.github.com/users/Apuyuseng/followers", "following_url": "https://api.github.com/users/Apuyuseng/following{/other_user}", "gists_url": "https://api.github.com/users/Apuyuseng/gists{/gist_id}", "starred_url": "https://api.github.com/users/Apuyuseng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Apuyuseng/subscriptions", "organizations_url": "https://api.github.com/users/Apuyuseng/orgs", "repos_url": "https://api.github.com/users/Apuyuseng/repos", "events_url": "https://api.github.com/users/Apuyuseng/events{/privacy}", "received_events_url": "https://api.github.com/users/Apuyuseng/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-12-13T12:39:22Z", "updated_at": "2019-12-17T14:43:31Z", "closed_at": "2019-12-17T14:43:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "```shell\r\n$scrapy shell\r\n2019-12-13 20:21:33 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: Book)\r\n2019-12-13 20:21:33 [scrapy.utils.log] INFO: Versions: lxml 4.4.1.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.0 (v3.8.0:fa919fdf25, Oct 14 2019, 10:23:27) - [Clang 6.0 (clang-600.0.57)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform macOS-10.15.2-x86_64-i386-64bit\r\n.....\r\nIn [1]: from scrapy.mail import MailSender                                                                                       \r\n\r\nIn [2]:  mailer = MailSender.from_settings(crawler.settings)                                                                     \r\n\r\nIn [3]:  book = open('\u4e3a\u4e86\u5ab3\u5987\u53bb\u4fee\u4ed9.zip', 'rb')                                                                                 \r\n\r\nIn [4]: attachments = [('\u4e3a\u4e86\u5ab3\u5987\u53bb\u4fee\u4ed9.zip', \r\n   ...:                             'application/zip', book)]                                                                    \r\n\r\nIn [5]: mailer.send(to=['1173372284@qq.com'], \r\n   ...:                                     attachs=attachments, \r\n   ...:                                     subject=\"Convert\", \r\n   ...:                                     body = '', \r\n   ...:                                     mimetype='application/zip' \r\n   ...:                                     ) \r\n\r\nIn [6]: mailer.e2019-12-13 20:25:33 [parso.python.diff] DEBUG: diff parser start\r\n2019-12-13 20:25:33 [parso.python.diff] DEBUG: line_lengths old: 1; new: 1\r\n2019-12-13 20:25:33 [parso.python.diff] DEBUG: -> code[replace] old[1:1] new[1:1]\r\n2019-12-13 20:25:33 [parso.python.diff] DEBUG: parse_part from 1 to 1 (to 0 in part parser)\r\n2019-12-13 20:25:33 [parso.python.diff] DEBUG: diff parser end\r\n2019-12-13 20:25:35 [scrapy.mail] INFO: Mail sent OK: To=['1173372284@qq.com'] Cc=[] Subject=\"Convert\" Attachs=1                 \r\n\r\n```\r\n\r\nget mail \r\n<img width=\"584\" alt=\"\u622a\u5c4f2019-12-13\u4e0b\u53488 34 15\" src=\"https://user-images.githubusercontent.com/17330686/70800846-45ddbf80-1de8-11ea-9a6f-d44b13791c20.png\">\r\n\r\nwhy attachs `\u4e3a\u4e86\u5ab3\u5987\u53bb\u4fee\u4ed9.zip` change  to `tcmime.954.1140.14065.bin `\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4229/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4229/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4197", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4197/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4197/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4197/events", "html_url": "https://github.com/scrapy/scrapy/pull/4197", "id": 529585997, "node_id": "MDExOlB1bGxSZXF1ZXN0MzQ2NDM2MjY3", "number": 4197, "title": "[Docs] Fix Twisted links", "user": {"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/10", "html_url": "https://github.com/scrapy/scrapy/milestone/10", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/10/labels", "id": 1559173, "node_id": "MDk6TWlsZXN0b25lMTU1OTE3Mw==", "number": 10, "title": "v2.0", "description": "**Major goals:** experimental AsyncIO support, Python 2 support drop\r\n\r\n**ETA:** February 2020", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 30, "state": "closed", "created_at": "2016-02-02T17:21:27Z", "updated_at": "2020-03-12T17:34:07Z", "due_on": "2020-02-29T08:00:00Z", "closed_at": "2020-03-12T17:34:07Z"}, "comments": 3, "created_at": "2019-11-27T21:45:05Z", "updated_at": "2020-02-07T20:38:46Z", "closed_at": "2020-02-07T18:51:16Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4197", "html_url": "https://github.com/scrapy/scrapy/pull/4197", "diff_url": "https://github.com/scrapy/scrapy/pull/4197.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4197.patch", "merged_at": "2020-02-07T18:51:16Z"}, "body": "The current link for the Twisted API is not working for me when I generate the docs. There are no public links to show, since this change has not been deployed to the main docs yet.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4197/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4197/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4175", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4175/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4175/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4175/events", "html_url": "https://github.com/scrapy/scrapy/issues/4175", "id": 524842444, "node_id": "MDU6SXNzdWU1MjQ4NDI0NDQ=", "number": 4175, "title": "Scrapy does not use a non-zero exit code when pipeline's open_spider throws the exception", "user": {"login": "gunblues", "id": 1292503, "node_id": "MDQ6VXNlcjEyOTI1MDM=", "avatar_url": "https://avatars.githubusercontent.com/u/1292503?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gunblues", "html_url": "https://github.com/gunblues", "followers_url": "https://api.github.com/users/gunblues/followers", "following_url": "https://api.github.com/users/gunblues/following{/other_user}", "gists_url": "https://api.github.com/users/gunblues/gists{/gist_id}", "starred_url": "https://api.github.com/users/gunblues/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gunblues/subscriptions", "organizations_url": "https://api.github.com/users/gunblues/orgs", "repos_url": "https://api.github.com/users/gunblues/repos", "events_url": "https://api.github.com/users/gunblues/events{/privacy}", "received_events_url": "https://api.github.com/users/gunblues/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-11-19T08:10:32Z", "updated_at": "2020-02-25T19:46:06Z", "closed_at": "2020-02-25T19:46:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\nIn our case, we execute command `scrapy crawl` in airflow task and the exit code would be used to judge this task success or failure. I agree that `scrapy crawl` ignores spider exceptions because it's unpredictable in the crawling process. \r\n\r\nBack to our case, we export data to file or database in the pipeline and we create the directory or database connection in `open_spider(self, spider)`. I think if there is an exception happens during this function, it's reasonable to propagate a non-zero exit code. it because we normally do some initialization in this function.\r\n\r\n### Steps to Reproduce\r\n\r\n- scrapy startproject test_spider\r\n- cd test_spider\r\n- scrapy genspider example example.com\r\n- modify spiders/example.py to  \r\n```\r\n# -*- coding: utf-8 -*-\r\nimport scrapy\r\n\r\n\r\nclass ExampleSpider(scrapy.Spider):\r\n    name = 'example'\r\n    allowed_domains = ['example.com']\r\n    start_urls = ['http://example.com/']\r\n\r\n    custom_settings = {\r\n        'ITEM_PIPELINES': {\r\n            'test_spider.pipelines.TestSpiderPipeline': 300\r\n        }\r\n    }\r\n\r\n    def parse(self, response):\r\n        pass\r\n```\r\n- modify pipelines.py to \r\n```\r\n# -*- coding: utf-8 -*-\r\n\r\n# Define your item pipelines here\r\n#\r\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\r\n# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html\r\n\r\n\r\nclass TestSpiderPipeline(object):\r\n\r\n    def open_spider(self, spider):\r\n        raise Exception('error')\r\n\r\n    def process_item(self, item, spider):\r\n        return item\r\n```\r\n- scrapy crawl example\r\n- echo $?  \r\n\r\n**Expected behavior:** [What you expect to happen]\r\nreturn non-zero exit code\r\n\r\n**Actual behavior:** [What actually happens]\r\nreturn zero exit code\r\n\r\n**Reproduces how often:** [What percentage of the time does it reproduce?]\r\n100%\r\n\r\n### Versions\r\nScrapy       : 1.8.0\r\nlxml         : 4.3.3.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.0.3\r\nparsel       : 1.5.1\r\nw3lib        : 1.20.0\r\nTwisted      : 19.2.0\r\nPython       : 3.7.3 (default, Mar 27 2019, 09:23:39) - [Clang 10.0.0 (clang-1000.11.45.5)]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019)\r\ncryptography : 2.6.1\r\nPlatform     : Darwin-18.5.0-x86_64-i386-64bit\r\n\r\n### Additional context\r\n\r\nI could get the expected behavior if I change `def run(self, args, opts)` in scrapy/commands/crawl.py  to \r\n```\r\n    def run(self, args, opts):\r\n        if len(args) < 1:\r\n            raise UsageError()\r\n        elif len(args) > 1:\r\n            raise UsageError(\"running 'scrapy crawl' with more than one spider is no longer supported\")\r\n        spname = args[0]\r\n\r\n        res = self.crawler_process.crawl(spname, **opts.spargs)\r\n\r\n        if hasattr(res, 'result') and res.result is not None and issubclass(res.result.type, Exception):\r\n            self.exitcode = 1\r\n        else:\r\n            self.crawler_process.start()\r\n\r\n            if self.crawler_process.bootstrap_failed:\r\n                self.exitcode = 1\r\n```\r\noriginal `def run(self, args, opts)`\r\n```\r\n    def run(self, args, opts):\r\n        if len(args) < 1:\r\n            raise UsageError()\r\n        elif len(args) > 1:\r\n            raise UsageError(\"running 'scrapy crawl' with more than one spider is no longer supported\")\r\n        spname = args[0]\r\n\r\n        self.crawler_process.crawl(spname, **opts.spargs)\r\n        self.crawler_process.start()\r\n\r\n        if self.crawler_process.bootstrap_failed:\r\n            self.exitcode = 1\r\n```\r\n\r\nIs it the proper way to modify the code for achieving this purpose? if it is, could I create a PR request for this issue?\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4175/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4175/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4169", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4169/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4169/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4169/events", "html_url": "https://github.com/scrapy/scrapy/pull/4169", "id": 524206317, "node_id": "MDExOlB1bGxSZXF1ZXN0MzQyMDIyNzQz", "number": 4169, "title": "Include /requirements-py3.txt from /docs/requirements.txt", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-18T08:19:34Z", "updated_at": "2019-11-20T14:37:02Z", "closed_at": "2019-11-20T14:36:44Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4169", "html_url": "https://github.com/scrapy/scrapy/pull/4169", "diff_url": "https://github.com/scrapy/scrapy/pull/4169.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4169.patch", "merged_at": "2019-11-20T14:36:44Z"}, "body": "With #4152 I broke the documentation build, because in Read the Docs we are installing the requirements from `/requirements-py3.txt`, and #4152 introduced into `/docs/requirements.txt` a new requirement that is not installed in Read the Docs by default.\r\n\r\nAfter this change, I count on fixing the Read the Docs build by changing the requirements file in Read the Docs to `/docs/requirements.txt`.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4169/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4169/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4145", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4145/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4145/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4145/events", "html_url": "https://github.com/scrapy/scrapy/issues/4145", "id": 521270913, "node_id": "MDU6SXNzdWU1MjEyNzA5MTM=", "number": 4145, "title": "only version 1.8.0   robots.txt forbidden", "user": {"login": "HisakaKoji", "id": 9940408, "node_id": "MDQ6VXNlcjk5NDA0MDg=", "avatar_url": "https://avatars.githubusercontent.com/u/9940408?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HisakaKoji", "html_url": "https://github.com/HisakaKoji", "followers_url": "https://api.github.com/users/HisakaKoji/followers", "following_url": "https://api.github.com/users/HisakaKoji/following{/other_user}", "gists_url": "https://api.github.com/users/HisakaKoji/gists{/gist_id}", "starred_url": "https://api.github.com/users/HisakaKoji/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HisakaKoji/subscriptions", "organizations_url": "https://api.github.com/users/HisakaKoji/orgs", "repos_url": "https://api.github.com/users/HisakaKoji/repos", "events_url": "https://api.github.com/users/HisakaKoji/events{/privacy}", "received_events_url": "https://api.github.com/users/HisakaKoji/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 839225636, "node_id": "MDU6TGFiZWw4MzkyMjU2MzY=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/upstream%20issue", "name": "upstream issue", "color": "c2e0c6", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-12T01:11:25Z", "updated_at": "2019-12-09T12:32:11Z", "closed_at": "2019-12-09T12:32:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe GitHub issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\nWhen I scrapyied  the url \"https://www.walkerplus.com/\" with scrapy , \r\nit is OK in version 1.7 ,  but it is forbidden by robots.txt in version 1.8. \r\n\r\nThe robots.txt \r\n`user-agent: *\r\ndisallow: http://ms-web00.walkerplus.com/\r\ndisallow: http://www-origin.walkerplus.com/\r\ndisallow: http://walkerplus.jp/\r\ndisallow: http://walkerplus.net/\r\ndisallow: https://ms.walkerplus.com/\r\n\r\nuser-agent: twitterbot\r\ndisallow:`\r\n### Steps to Reproduce\r\n\r\n1. scrapy \"https://www.walkerplus.com/\" with version1.8 scrapy\r\n\r\n\r\n**Expected behavior:** [What you expect to happen]\r\n\r\nIt is not forbidden.\r\n\r\n**Actual behavior:** [What actually happens]\r\n\r\nIt is forbidden.\r\n\r\n**Reproduces how often:** [What percentage of the time does it reproduce?]\r\n\r\nIt is 100% reproduced.\r\n\r\n### Versions\r\n\r\nScrapy       : 1.8.0\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.10.0\r\nPython       : 3.6.8 (default, Oct  7 2019, 12:59:55) - [GCC 8.3.0]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1  11 Sep 2018)\r\ncryptography : 2.1.4\r\nPlatform     : Linux-3.10.0-1062.4.1.el7.x86_64-x86_64-with-Ubuntu-18.04-bionic\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4145/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4145/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4139", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4139/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4139/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4139/events", "html_url": "https://github.com/scrapy/scrapy/pull/4139", "id": 519397464, "node_id": "MDExOlB1bGxSZXF1ZXN0MzM4MTQ2OTM5", "number": 4139, "title": "Improve the details about request serialization requirements for JOBDIR", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-07T17:07:28Z", "updated_at": "2019-11-08T17:49:34Z", "closed_at": "2019-11-08T17:49:34Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4139", "html_url": "https://github.com/scrapy/scrapy/pull/4139", "diff_url": "https://github.com/scrapy/scrapy/pull/4139.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4139.patch", "merged_at": "2019-11-08T17:49:34Z"}, "body": "Fixes #4124", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4139/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4139/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4124", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4124/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4124/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4124/events", "html_url": "https://github.com/scrapy/scrapy/issues/4124", "id": 517378758, "node_id": "MDU6SXNzdWU1MTczNzg3NTg=", "number": 4124, "title": "Fix wrong fact in JOBDIR documentation about requests needing to be pickle-serializable", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-04T20:19:06Z", "updated_at": "2019-11-08T17:49:34Z", "closed_at": "2019-11-08T17:49:34Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The documentation about using `JODBIR` says that requests need to be serializable with `pickle`.\r\n\r\nBut, thanks to feedback from @kmike, now I know that their callback and errback methods do not need to be `pickle`-serializable as long as they are spider methods.\r\n\r\nThe documentation should be clear about this.\r\n\r\nRelated to #4125.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4124/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4124/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4123", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4123/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4123/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4123/events", "html_url": "https://github.com/scrapy/scrapy/pull/4123", "id": 517160677, "node_id": "MDExOlB1bGxSZXF1ZXN0MzM2MjgzNjI2", "number": 4123, "title": "Fix LocalCache limit issue, add tests", "user": {"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-04T13:42:41Z", "updated_at": "2019-11-14T01:09:52Z", "closed_at": "2019-11-12T11:05:23Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4123", "html_url": "https://github.com/scrapy/scrapy/pull/4123", "diff_url": "https://github.com/scrapy/scrapy/pull/4123.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4123.patch", "merged_at": "2019-11-12T11:05:23Z"}, "body": "Taken from https://github.com/scrapy/scrapy/pull/3869/files#r342049190\r\n\r\nThis piece of code can fail with `TypeError: '>=' not supported between instances of 'int' and 'NoneType'`\r\n\r\nI think this patch is smaller and easier than #3869, it can be merged earlier.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4123/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4123/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4095", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4095/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4095/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4095/events", "html_url": "https://github.com/scrapy/scrapy/pull/4095", "id": 510702146, "node_id": "MDExOlB1bGxSZXF1ZXN0MzMxMDMwNDM1", "number": 4095, "title": "Use communicate() instead of wait() after killing the mock server", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-10-22T14:38:15Z", "updated_at": "2019-11-01T09:04:09Z", "closed_at": "2019-10-31T12:31:34Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4095", "html_url": "https://github.com/scrapy/scrapy/pull/4095", "diff_url": "https://github.com/scrapy/scrapy/pull/4095.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4095.patch", "merged_at": "2019-10-31T12:31:33Z"}, "body": "Fixes #4014\r\n\r\nWhen using pipes, and we are using a pipe for `stdout` in `MockServer`, you are meant to call `process.communicate()` instead of `process.wait()`.\r\n\r\nThis was causing unexpected warnings in `test_crawler.py` tests, when the garbage collection happened to warn about unclosed resources while one of the affected tests was capturing warnings.\r\n\r\nI\u2019ve run the tests a few rounds with this fix, and it seems to have worked.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4095/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4095/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4090", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4090/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4090/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4090/events", "html_url": "https://github.com/scrapy/scrapy/pull/4090", "id": 510122190, "node_id": "MDExOlB1bGxSZXF1ZXN0MzMwNTQyMjQw", "number": 4090, "title": "Fix references to Python types in parameter type fields", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-10-21T17:01:01Z", "updated_at": "2020-08-13T19:58:12Z", "closed_at": "2020-08-13T19:58:06Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4090", "html_url": "https://github.com/scrapy/scrapy/pull/4090", "diff_url": "https://github.com/scrapy/scrapy/pull/4090.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4090.patch", "merged_at": "2020-08-13T19:58:06Z"}, "body": "The values of these fields are automatically interpreted as Python types, and Sphinx tries to link them to the Python documentation, so they need to be valid types.\r\n\r\nAdditional details (e.g. that a list is a list of strings) must be provided in the field description instead.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4090/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4090/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4089", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4089/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4089/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4089/events", "html_url": "https://github.com/scrapy/scrapy/pull/4089", "id": 510089413, "node_id": "MDExOlB1bGxSZXF1ZXN0MzMwNTEzNzU4", "number": 4089, "title": "Updating link for miniconda", "user": {"login": "illgitthat", "id": 2256474, "node_id": "MDQ6VXNlcjIyNTY0NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/2256474?v=4", "gravatar_id": "", "url": "https://api.github.com/users/illgitthat", "html_url": "https://github.com/illgitthat", "followers_url": "https://api.github.com/users/illgitthat/followers", "following_url": "https://api.github.com/users/illgitthat/following{/other_user}", "gists_url": "https://api.github.com/users/illgitthat/gists{/gist_id}", "starred_url": "https://api.github.com/users/illgitthat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/illgitthat/subscriptions", "organizations_url": "https://api.github.com/users/illgitthat/orgs", "repos_url": "https://api.github.com/users/illgitthat/repos", "events_url": "https://api.github.com/users/illgitthat/events{/privacy}", "received_events_url": "https://api.github.com/users/illgitthat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-10-21T16:14:35Z", "updated_at": "2019-10-22T10:05:35Z", "closed_at": "2019-10-22T10:05:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4089", "html_url": "https://github.com/scrapy/scrapy/pull/4089", "diff_url": "https://github.com/scrapy/scrapy/pull/4089.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4089.patch", "merged_at": "2019-10-22T10:05:35Z"}, "body": "The previous link was a 404 (https://conda.io/docs/user-guide/install/index.html)\r\n\r\nI updated to https://docs.conda.io/en/latest/miniconda.html\r\n\r\nEDIT: https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4089/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4089/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4076", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4076/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4076/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4076/events", "html_url": "https://github.com/scrapy/scrapy/issues/4076", "id": 506561981, "node_id": "MDU6SXNzdWU1MDY1NjE5ODE=", "number": 4076, "title": "Docs: Broken link on developer-tools", "user": {"login": "tasawar-hussain", "id": 31658686, "node_id": "MDQ6VXNlcjMxNjU4Njg2", "avatar_url": "https://avatars.githubusercontent.com/u/31658686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tasawar-hussain", "html_url": "https://github.com/tasawar-hussain", "followers_url": "https://api.github.com/users/tasawar-hussain/followers", "following_url": "https://api.github.com/users/tasawar-hussain/following{/other_user}", "gists_url": "https://api.github.com/users/tasawar-hussain/gists{/gist_id}", "starred_url": "https://api.github.com/users/tasawar-hussain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tasawar-hussain/subscriptions", "organizations_url": "https://api.github.com/users/tasawar-hussain/orgs", "repos_url": "https://api.github.com/users/tasawar-hussain/repos", "events_url": "https://api.github.com/users/tasawar-hussain/events{/privacy}", "received_events_url": "https://api.github.com/users/tasawar-hussain/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-14T10:14:07Z", "updated_at": "2019-10-15T18:49:51Z", "closed_at": "2019-10-15T18:49:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Link broken to http://quotes.toscrape.com/scroll on developer-tools docs\r\n\r\nThe link quotes.toscrape.com/scroll on developer-tools docs opens incorrect page and thus returns 404\r\n\r\n### Steps to Reproduce\r\n\r\n1. Navigate to https://docs.scrapy.org/en/latest/topics/developer-tools.html#the-network-tool\r\n2. Click the link `quotes.toscrape.com/scroll` on end of first paragraph.\r\n\r\n**Expected behavior:** It should naigate to http://quotes.toscrape.com/scroll\r\n\r\n**Actual behavior:** It navigates to https://docs.scrapy.org/en/latest/topics/quotes.toscrape.com/scroll/\r\n\r\n**Reproduces how often:** 100%\r\n\r\n### Versions\r\n\r\nPlease paste here the output of executing `scrapy version --verbose` in the command line.\r\nScrapy       : 1.7.3\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.7.0\r\nPython       : 3.7.3 | packaged by conda-forge | (default, Jul  1 2019, 21:52:21) - [GCC 7.3.0]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1c  28 May 2019)\r\ncryptography : 2.7\r\nPlatform     : Linux-4.15.0-65-generic-x86_64-with-debian-buster-sid\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4076/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4076/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4072", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4072/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4072/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4072/events", "html_url": "https://github.com/scrapy/scrapy/issues/4072", "id": 505816860, "node_id": "MDU6SXNzdWU1MDU4MTY4NjA=", "number": 4072, "title": "BOT_NAME and the user agent", "user": {"login": "mohmad-null", "id": 22342282, "node_id": "MDQ6VXNlcjIyMzQyMjgy", "avatar_url": "https://avatars.githubusercontent.com/u/22342282?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mohmad-null", "html_url": "https://github.com/mohmad-null", "followers_url": "https://api.github.com/users/mohmad-null/followers", "following_url": "https://api.github.com/users/mohmad-null/following{/other_user}", "gists_url": "https://api.github.com/users/mohmad-null/gists{/gist_id}", "starred_url": "https://api.github.com/users/mohmad-null/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mohmad-null/subscriptions", "organizations_url": "https://api.github.com/users/mohmad-null/orgs", "repos_url": "https://api.github.com/users/mohmad-null/repos", "events_url": "https://api.github.com/users/mohmad-null/events{/privacy}", "received_events_url": "https://api.github.com/users/mohmad-null/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-11T12:15:12Z", "updated_at": "2019-10-16T12:15:00Z", "closed_at": "2019-10-16T12:15:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "The docs for `BOT_NAME` say that it is used for the User agent (https://docs.scrapy.org/en/latest/topics/settings.html#std:setting-BOT_NAME) :\r\n\r\n> This will be used to construct the User-Agent by default, and also for logging.\r\n\r\nHowever in reality it is not. Scrapy is using the user agent:\r\n`\"Scrapy/1.7.3 (+https://scrapy.org)\"`\r\n\r\nSetting `USER_AGENT` does change the user agent correctly.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4072/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4072/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4056", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4056/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4056/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4056/events", "html_url": "https://github.com/scrapy/scrapy/pull/4056", "id": 501469465, "node_id": "MDExOlB1bGxSZXF1ZXN0MzIzNzM1OTMy", "number": 4056, "title": "Fix internal links in the tutorial and release notes", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-10-02T12:51:32Z", "updated_at": "2019-10-18T22:00:10Z", "closed_at": "2019-10-18T22:00:02Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4056", "html_url": "https://github.com/scrapy/scrapy/pull/4056", "diff_url": "https://github.com/scrapy/scrapy/pull/4056.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4056.patch", "merged_at": "2019-10-18T22:00:02Z"}, "body": "", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4056/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4056/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4035", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4035/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4035/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4035/events", "html_url": "https://github.com/scrapy/scrapy/issues/4035", "id": 498012382, "node_id": "MDU6SXNzdWU0OTgwMTIzODI=", "number": 4035, "title": "CLOSESPIDER_TIMEOUT Settings 36000 Invalid Settings 60 ok ?", "user": {"login": "kjxy", "id": 35479340, "node_id": "MDQ6VXNlcjM1NDc5MzQw", "avatar_url": "https://avatars.githubusercontent.com/u/35479340?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kjxy", "html_url": "https://github.com/kjxy", "followers_url": "https://api.github.com/users/kjxy/followers", "following_url": "https://api.github.com/users/kjxy/following{/other_user}", "gists_url": "https://api.github.com/users/kjxy/gists{/gist_id}", "starred_url": "https://api.github.com/users/kjxy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kjxy/subscriptions", "organizations_url": "https://api.github.com/users/kjxy/orgs", "repos_url": "https://api.github.com/users/kjxy/repos", "events_url": "https://api.github.com/users/kjxy/events{/privacy}", "received_events_url": "https://api.github.com/users/kjxy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443680419, "node_id": "MDU6TGFiZWw0NDM2ODA0MTk=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/needs%20more%20info", "name": "needs more info", "color": "fef2c0", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-09-25T02:27:34Z", "updated_at": "2019-10-30T09:14:16Z", "closed_at": "2019-10-30T09:14:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe Github issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\nCLOSESPIDER_TIMEOUT Settings 36000 run for five days...\r\nCLOSESPIDER_TIMEOUT Settings 60 closespider_timeout(is ok)\r\n\r\n\r\n### Steps to Reproduce\r\n\r\ncustom_settings = {\r\n        \"CLOSESPIDER_TIMEOUT\": 60,\r\n}\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4035/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4035/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4033", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4033/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4033/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4033/events", "html_url": "https://github.com/scrapy/scrapy/pull/4033", "id": 497777592, "node_id": "MDExOlB1bGxSZXF1ZXN0MzIwODQzMTc4", "number": 4033, "title": "Fix documentation typo: accesible \u2192 accessible", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-24T15:53:32Z", "updated_at": "2019-09-25T09:13:39Z", "closed_at": "2019-09-25T09:13:38Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4033", "html_url": "https://github.com/scrapy/scrapy/pull/4033", "diff_url": "https://github.com/scrapy/scrapy/pull/4033.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4033.patch", "merged_at": "2019-09-25T09:13:38Z"}, "body": "Fixes #3597\r\n\r\nWhile this change will not be necessary after #3975 is merged, that could take a while, or not happen at all.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4033/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4033/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4032", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4032/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4032/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4032/events", "html_url": "https://github.com/scrapy/scrapy/issues/4032", "id": 496945818, "node_id": "MDU6SXNzdWU0OTY5NDU4MTg=", "number": 4032, "title": "Error 302 redirection with headers location starts with 3 slash", "user": {"login": "sicklife", "id": 8018334, "node_id": "MDQ6VXNlcjgwMTgzMzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/8018334?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sicklife", "html_url": "https://github.com/sicklife", "followers_url": "https://api.github.com/users/sicklife/followers", "following_url": "https://api.github.com/users/sicklife/following{/other_user}", "gists_url": "https://api.github.com/users/sicklife/gists{/gist_id}", "starred_url": "https://api.github.com/users/sicklife/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sicklife/subscriptions", "organizations_url": "https://api.github.com/users/sicklife/orgs", "repos_url": "https://api.github.com/users/sicklife/repos", "events_url": "https://api.github.com/users/sicklife/events{/privacy}", "received_events_url": "https://api.github.com/users/sicklife/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2019-09-23T07:56:49Z", "updated_at": "2019-10-30T08:09:13Z", "closed_at": "2019-10-30T08:09:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n### Description\r\n\r\nwhen the 302 response return a headers's location startswith 3 slash, the scrapy redirect to a url different from what the browser do.\r\n\r\n### Steps to Reproduce\r\n\r\n1.  scrapy shell https://www.hjenglish.com/new/p1285798/\r\n\r\n**Expected behavior:** \r\nredirect to `https://fr.hujiang.com/new/p1285798/` as browser `Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36`  do.\r\n\r\n\r\n**Actual behavior:** \r\nredirct to `https://www.hjenglish.com/fr.hujiang.com/new/p1285798`\r\n\r\n**Reproduces how often:** \r\n\r\neverytime\r\n\r\n### Versions\r\nScrapy       : 1.7.3\r\nlxml         : 4.3.2.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.20.0\r\nTwisted      : 19.7.0\r\nPython       : 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1c  28 May 2019)\r\ncryptography : 2.6.1\r\nPlatform     : Windows-10-10.0.17134-SP0\r\n\r\n\r\n### Additional context\r\n\r\nI check the defination of [Location in rfc](https://tools.ietf.org/html/rfc7231#section-7.1.2) and end with [reference resolution](https://tools.ietf.org/html/rfc3986#section-5.3). But I fail to findout how to resolve the Location startswith `///`. So I don't know why Chrome did so.\r\n\r\nThe behavior of scrapy is determined by [redirect.py#L73](https://github.com/scrapy/scrapy/blob/master/scrapy/downloadermiddlewares/redirect.py#L73), which will truncate `///` to `/`\u3002\r\n\r\nI'm wandering the differents betweent scarpy and browser...\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4032/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4032/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4027", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4027/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4027/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4027/events", "html_url": "https://github.com/scrapy/scrapy/issues/4027", "id": 495599951, "node_id": "MDU6SXNzdWU0OTU1OTk5NTE=", "number": 4027, "title": "Upgrading from 1.4 to 1.5 results in many 400 responses", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-09-19T06:30:27Z", "updated_at": "2020-04-23T12:19:55Z", "closed_at": "2020-04-23T12:19:46Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "@stav has a project where upgrading from Scrapy 1.4 to Scrapy 1.5 resulted in many 400 responses, and going back to Scrapy 1.4 solved the issue.\r\n\r\nSomeone else (Alejandro Marti) saw the same in a different project, so it seems confirmed. Now we need to figure out why.\r\n\r\n@kmike mentioned it *may* be related to #2743 and #2767.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4027/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4027/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4022", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4022/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4022/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4022/events", "html_url": "https://github.com/scrapy/scrapy/pull/4022", "id": 494442453, "node_id": "MDExOlB1bGxSZXF1ZXN0MzE4MTkyOTE2", "number": 4022, "title": "Fix the item exporter example", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-17T07:07:45Z", "updated_at": "2019-09-19T07:17:24Z", "closed_at": "2019-09-19T07:17:24Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/4022", "html_url": "https://github.com/scrapy/scrapy/pull/4022", "diff_url": "https://github.com/scrapy/scrapy/pull/4022.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/4022.patch", "merged_at": "2019-09-19T07:17:24Z"}, "body": "Fixes #3398", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4022/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4022/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4014", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4014/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4014/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4014/events", "html_url": "https://github.com/scrapy/scrapy/issues/4014", "id": 493367529, "node_id": "MDU6SXNzdWU0OTMzNjc1Mjk=", "number": 4014, "title": "Random(?) test_crawler.py failure on Travis", "user": {"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2019-09-13T14:49:40Z", "updated_at": "2019-11-01T08:53:24Z", "closed_at": "2019-10-31T12:31:34Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Every now and then the Travis build fails on [`tests.test_crawler.CrawlerRunnerTestCase.test_deprecated_attribute_spiders`](https://github.com/scrapy/scrapy/blob/1.7.3/tests/test_crawler.py#L173), I'm not sure why.\r\nSome examples:\r\n* https://travis-ci.org/scrapy/scrapy/jobs/582184413#L407\r\n* https://travis-ci.org/scrapy/scrapy/jobs/580207692#L419\r\n* https://travis-ci.org/scrapy/scrapy/jobs/584701732#L415\r\n* https://travis-ci.org/scrapy/scrapy/jobs/584762868#L418\r\n\r\nPS: Sorry, I feel bad for ignoring the bug report template, but I felt like it didn't apply in this case.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4014/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4014/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4007", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/4007/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/4007/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/4007/events", "html_url": "https://github.com/scrapy/scrapy/issues/4007", "id": 491060867, "node_id": "MDU6SXNzdWU0OTEwNjA4Njc=", "number": 4007, "title": "Exception when using DummyStatsCollector", "user": {"login": "Lukas0907", "id": 591792, "node_id": "MDQ6VXNlcjU5MTc5Mg==", "avatar_url": "https://avatars.githubusercontent.com/u/591792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lukas0907", "html_url": "https://github.com/Lukas0907", "followers_url": "https://api.github.com/users/Lukas0907/followers", "following_url": "https://api.github.com/users/Lukas0907/following{/other_user}", "gists_url": "https://api.github.com/users/Lukas0907/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lukas0907/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lukas0907/subscriptions", "organizations_url": "https://api.github.com/users/Lukas0907/orgs", "repos_url": "https://api.github.com/users/Lukas0907/repos", "events_url": "https://api.github.com/users/Lukas0907/events{/privacy}", "received_events_url": "https://api.github.com/users/Lukas0907/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 280218717, "node_id": "MDU6TGFiZWwyODAyMTg3MTc=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/discuss", "name": "discuss", "color": "cc317c", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-09-09T12:18:03Z", "updated_at": "2021-05-19T12:57:25Z", "closed_at": "2019-10-02T07:06:23Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\nUsing the DummyStatsCollector results in an exception:\r\n\r\n```\r\n2019-09-09 13:51:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method CoreStats.spider_closed of <scrapy.extensions.corestats.CoreStats object at 0x7f86269cac18>>\r\nTraceback (most recent call last):\r\n  File \".../lib/python3.6/site-packages/twisted/internet/defer.py\", line 150, in maybeDeferred\r\n    result = f(*args, **kw)\r\n  File \".../lib/python3.6/site-packages/pydispatch/robustapply.py\", line 55, in robustApply\r\n    return receiver(*arguments, **named)\r\n  File \".../lib/python3.6/site-packages/scrapy/extensions/corestats.py\", line 28, in spider_closed\r\n    elapsed_time = finish_time - self.stats.get_value('start_time')\r\nTypeError: unsupported operand type(s) for -: 'datetime.datetime' and 'NoneType'\r\n```\r\n\r\nThis problem has been introduced in aa46e1995cd5cb1099aba17535372b538bd656b3.\r\n\r\n### Steps to Reproduce\r\n\r\nSet `STATS_CLASS = \"scrapy.statscollectors.DummyStatsCollector\"` in the settings module as described in the documentation (https://docs.scrapy.org/en/latest/topics/stats.html#dummystatscollector).\r\n\r\n**Expected behavior:** no exception\r\n**Actual behavior:** exception thrown\r\n**Reproduces how often:** always\r\n\r\n### Versions\r\n\r\nAt least master as of 534de7395da3a53b5a2c89960db9ec5d8fdab60c\r\n\r\n### Fix\r\n\r\nA possible fix is to use the elapsed time as a default argument so that `get_value()` does not return None. I can prepare a PR if needed.\r\n\r\n```diff\r\n--- a/scrapy/extensions/corestats.py\r\n+++ b/scrapy/extensions/corestats.py\r\n@@ -25,7 +25,7 @@ class CoreStats(object):\r\n \r\n     def spider_closed(self, spider, reason):\r\n         finish_time = datetime.datetime.utcnow()\r\n-        elapsed_time = finish_time - self.stats.get_value('start_time')\r\n+        elapsed_time = finish_time - self.stats.get_value('start_time', finish_time)\r\n         elapsed_time_seconds = elapsed_time.total_seconds()\r\n         self.stats.set_value('elapsed_time_seconds', elapsed_time_seconds, spider=spider)\r\n         self.stats.set_value('finish_time', finish_time, spider=spider)\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/4007/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/4007/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3995", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3995/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3995/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3995/events", "html_url": "https://github.com/scrapy/scrapy/issues/3995", "id": 487733446, "node_id": "MDU6SXNzdWU0ODc3MzM0NDY=", "number": 3995, "title": "ImagesPipeline does not follow redirection", "user": {"login": "rsarky", "id": 24373707, "node_id": "MDQ6VXNlcjI0MzczNzA3", "avatar_url": "https://avatars.githubusercontent.com/u/24373707?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsarky", "html_url": "https://github.com/rsarky", "followers_url": "https://api.github.com/users/rsarky/followers", "following_url": "https://api.github.com/users/rsarky/following{/other_user}", "gists_url": "https://api.github.com/users/rsarky/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsarky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsarky/subscriptions", "organizations_url": "https://api.github.com/users/rsarky/orgs", "repos_url": "https://api.github.com/users/rsarky/repos", "events_url": "https://api.github.com/users/rsarky/events{/privacy}", "received_events_url": "https://api.github.com/users/rsarky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-31T05:39:56Z", "updated_at": "2019-09-27T14:32:27Z", "closed_at": "2019-09-27T14:32:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nThis issue was already reported #2397 but the reporter closed the issue after posting a temporary fix. I reckon there should be an elegant way to hande this as this is a common use case I guess. Maybe a configurable setting that allows image to be downloaded even when the URL is redirected.\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3995/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3995/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3985", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3985/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3985/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3985/events", "html_url": "https://github.com/scrapy/scrapy/issues/3985", "id": 486559659, "node_id": "MDU6SXNzdWU0ODY1NTk2NTk=", "number": 3985, "title": "Contracts can't be written for callbacks that receive cb_kwargs", "user": {"login": "jvani", "id": 16983853, "node_id": "MDQ6VXNlcjE2OTgzODUz", "avatar_url": "https://avatars.githubusercontent.com/u/16983853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jvani", "html_url": "https://github.com/jvani", "followers_url": "https://api.github.com/users/jvani/followers", "following_url": "https://api.github.com/users/jvani/following{/other_user}", "gists_url": "https://api.github.com/users/jvani/gists{/gist_id}", "starred_url": "https://api.github.com/users/jvani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jvani/subscriptions", "organizations_url": "https://api.github.com/users/jvani/orgs", "repos_url": "https://api.github.com/users/jvani/repos", "events_url": "https://api.github.com/users/jvani/events{/privacy}", "received_events_url": "https://api.github.com/users/jvani/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-28T19:11:27Z", "updated_at": "2019-09-07T23:23:16Z", "closed_at": "2019-09-07T23:23:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\n\r\nThanks for taking an interest in Scrapy!\r\n\r\nIf you have a question that starts with \"How to...\", please see the Scrapy Community page: https://scrapy.org/community/.\r\nThe Github issue tracker's purpose is to deal with bug reports and feature requests for the project itself.\r\n\r\nKeep in mind that by filing an issue, you are expected to comply with Scrapy's Code of Conduct, including treating everyone with respect: https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\r\n\r\nThe following is a suggested template to structure your issue, you can find more guidelines at https://doc.scrapy.org/en/latest/contributing.html#reporting-bugs\r\n\r\n-->\r\n\r\n### Description\r\n\r\nContracts can't be written for callbacks that receive `cb_kwargs`\r\n\r\n### Steps to Reproduce\r\n1. Run `scrapy check` with the following spider:\r\n```\r\nclass CbKwargsContract(scrapy.Spider):\r\n    name = 'cb_kwargs_contract'\r\n\r\n    def start_requests(self):\r\n        yield scrapy.Request(\"https://httpbin.org/get\", cb_kwargs={\"arg1\": \"foo\"})\r\n\r\n    def parse(self, response, arg1):\r\n        \"\"\"\r\n        @url https://httpbin.org/get\r\n        \"\"\"\r\n        self.logger.info(arg1)\r\n```\r\n\r\n**Expected behavior:**\r\nIdeally would be possible to add args to the contract (e.g., `@url https://httpbin.org/get foo`)\r\n\r\n**Actual behavior:** Fails with a TypeError\r\n\r\n**Reproduces how often:** 100%\r\n\r\n### Versions\r\nScrapy 1.7.3", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3985/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3985/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3976", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3976/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3976/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3976/events", "html_url": "https://github.com/scrapy/scrapy/issues/3976", "id": 485206717, "node_id": "MDU6SXNzdWU0ODUyMDY3MTc=", "number": 3976, "title": "`ItemLoader` fields initialized from `item` are reprocessed", "user": {"login": "alexander-matsievsky", "id": 3784691, "node_id": "MDQ6VXNlcjM3ODQ2OTE=", "avatar_url": "https://avatars.githubusercontent.com/u/3784691?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexander-matsievsky", "html_url": "https://github.com/alexander-matsievsky", "followers_url": "https://api.github.com/users/alexander-matsievsky/followers", "following_url": "https://api.github.com/users/alexander-matsievsky/following{/other_user}", "gists_url": "https://api.github.com/users/alexander-matsievsky/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexander-matsievsky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexander-matsievsky/subscriptions", "organizations_url": "https://api.github.com/users/alexander-matsievsky/orgs", "repos_url": "https://api.github.com/users/alexander-matsievsky/repos", "events_url": "https://api.github.com/users/alexander-matsievsky/events{/privacy}", "received_events_url": "https://api.github.com/users/alexander-matsievsky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-08-26T12:18:42Z", "updated_at": "2019-10-28T09:53:54Z", "closed_at": "2019-10-28T09:53:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\n#3804 introduced a bug where `ItemLoader` fields are reprocessed.\r\nRelated #3897.\r\n\r\n### Steps to Reproduce\r\n\r\n```python\r\nfrom pprint import pprint\r\n\r\nfrom scrapy import Field, Item\r\nfrom scrapy.loader import ItemLoader\r\nfrom scrapy.loader.processors import TakeFirst\r\n\r\n\r\nclass X(Item):\r\n    x = Field(output_processor=TakeFirst())\r\n\r\n\r\nloader = ItemLoader(X())\r\nloader.add_value(\"x\", [\"value1\", \"value2\"])\r\nx = loader.load_item()\r\npprint(x)\r\n# {'x': 'value1'}\r\n\r\npprint(ItemLoader(x).load_item())\r\n# {'x': 'v'}\r\n```\r\n\r\n**Expected behavior:** `ItemLoader` initialized from the `x` item does not reprocess its fields and  loads `{'x': 'value1'}`.\r\n\r\n**Actual behavior:** `ItemLoader` initialized from the `x` item reprocesses its fields and  loads `{'x': 'v'}`.\r\n\r\n### Versions\r\n\r\n```\r\nScrapy       : 1.7.3\r\nlxml         : 4.4.1.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.1.0\r\nparsel       : 1.5.2\r\nw3lib        : 1.21.0\r\nTwisted      : 19.7.0\r\nPython       : 3.6.5 (default, May  3 2018, 10:08:28) - [GCC 5.4.0 20160609]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1c  28 May 2019)\r\ncryptography : 2.7\r\nPlatform     : Linux-4.4.0-127-generic-x86_64-with-LinuxMint-18.1-serena\r\n```\r\n\r\n### Additional context\r\n\r\nHere's the behavior of the previous version:\r\n\r\n```\r\nScrapy       : 1.6.0\r\nlxml         : 4.4.0.0\r\nlibxml2      : 2.9.9\r\ncssselect    : 1.0.3\r\nparsel       : 1.5.1\r\nw3lib        : 1.20.0\r\nTwisted      : 19.7.0\r\nPython       : 3.6.5 (default, May  3 2018, 10:08:28) - [GCC 5.4.0 20160609]\r\npyOpenSSL    : 19.0.0 (OpenSSL 1.1.1c  28 May 2019)\r\ncryptography : 2.7\r\nPlatform     : Linux-4.4.0-127-generic-x86_64-with-LinuxMint-18.1-serena\r\n```\r\n\r\n```python\r\n# {'x': 'value1'}\r\n# {'x': 'value1'}\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3976/reactions", "total_count": 3, "+1": 3, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3976/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3953", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3953/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3953/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3953/events", "html_url": "https://github.com/scrapy/scrapy/issues/3953", "id": 479578644, "node_id": "MDU6SXNzdWU0Nzk1Nzg2NDQ=", "number": 3953, "title": "OSError when downloading a very long url", "user": {"login": "zaxtyson", "id": 20383074, "node_id": "MDQ6VXNlcjIwMzgzMDc0", "avatar_url": "https://avatars.githubusercontent.com/u/20383074?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zaxtyson", "html_url": "https://github.com/zaxtyson", "followers_url": "https://api.github.com/users/zaxtyson/followers", "following_url": "https://api.github.com/users/zaxtyson/following{/other_user}", "gists_url": "https://api.github.com/users/zaxtyson/gists{/gist_id}", "starred_url": "https://api.github.com/users/zaxtyson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zaxtyson/subscriptions", "organizations_url": "https://api.github.com/users/zaxtyson/orgs", "repos_url": "https://api.github.com/users/zaxtyson/repos", "events_url": "https://api.github.com/users/zaxtyson/events{/privacy}", "received_events_url": "https://api.github.com/users/zaxtyson/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-08-12T10:44:19Z", "updated_at": "2019-09-16T12:04:07Z", "closed_at": "2019-09-16T12:04:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "When you run into some horrible image url, like this\uff1a\r\n\r\n```\r\nhttps://o.aolcdn.com/images/dims?resize=2000%2C2000%2Cshrink&image_uri=https%3A%2F%2Fo.aolcdn.com%2Fimages%2Fdimse%2F5845cadfecd996e0372f%2Fccc34660c41122e3170c0d586c151a29397c0fcf%2FY3JvcD0xOTIwJTJDMTA5NyUyQzAlMkMwJnF1YWxpdHk9ODUmZm9ybWF0PWpwZyZyZXNpemU9MTYwMCUyQzkxNCZpbWFnZV91cmk9aHR0cHMlM0ElMkYlMkZzLnlpbWcuY29tJTJGb3MlMkZjcmVhdHItdXBsb2FkZWQtaW1hZ2VzJTJGMjAxOS0wOCUyRjg2YjNlYjkwLWI5YjgtMTFlOS05ZWFlLTQ5YWU2NTcxMjM0MyZjbGllbnQ9YTFhY2FjM2UxYjMyOTA5MTdkOTImc2lnbmF0dXJlPTZmZWJkYjQwN2E0NzU0YzM0YTJjY2ViMDczNDc1YTE1ZjBiODA3OGQ%3D&client=a1acac3e1b3290917d92&signature=bf3461468aef0cb3ecaea00d2ed611e04a88bc70\r\n```\r\nThen...\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"c:\\program files\\python37\\lib\\site-packages\\scrapy\\pipelines\\files.py\", line 419, in media_downloaded\r\n    checksum = self.file_downloaded(response, request, info)\r\n  File \"c:\\program files\\python37\\lib\\site-packages\\scrapy\\pipelines\\files.py\", line 452, in file_downloaded\r\n    self.store.persist_file(path, buf, info)\r\n  File \"c:\\program files\\python37\\lib\\site-packages\\scrapy\\pipelines\\files.py\", line 53, in persist_file\r\n    with open(absolute_path, 'wb') as f:\r\nOSError: [Errno 22] Invalid argument: 'E:\\\\2019-08-12\\\\resources\\\\885443110bae0e1149e017dbea5ca3935efa38c0.com%2Fimages%2Fdimse%2F5845cadfecd996e0372f%2F108a4af73772ae197fa2c4ec4e9fe7a47390433c%2FY3JvcD0xMTc0JTJDNTgwJTJDMCUyQzAmcXVhbGl0eT04NSZmb3JtYXQ9anBnJnJlc2l6ZT0xNjAwJTJDNzkxJmltYWdlX3VyaT1odHRwcyUzQSUyRiUyRnMueWltZy5jb20lMkZvcyUyRmNyZWF0ci11cGxvYWRlZC1pbWFnZXMlMkYyMDE5LTA4JTJGMWJmZGQxNDAtYjliYy0xMWU5LWJmZjMtMjMyNzcwMTg1MzE5JmNsaWVudD1hMWFjYWMzZTFiMzI5MDkxN2Q5MiZzaWduYXR1cmU9OTFiNzQ3Y2MyZTY5ODY3OGIxNWI0OTkyMjdjM2NmZWRlYTE1NGIxOA%3D%3D&client=a1acac3e1b3290917d92&signature=6517aece82e79d536edeaccc275ad88090df0252'\r\n```\r\n\r\nSo\uff0cI think that when downloading a file, you should use a random name instead of intercepting it from the url.For some particularly weird urls, this will cause an OSErro when writing to the file", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3953/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3953/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3887", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3887/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3887/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3887/events", "html_url": "https://github.com/scrapy/scrapy/pull/3887", "id": 470088563, "node_id": "MDExOlB1bGxSZXF1ZXN0Mjk5MTQ4NTEy", "number": 3887, "title": "Fix configparser import for python2", "user": {"login": "marsam", "id": 65531, "node_id": "MDQ6VXNlcjY1NTMx", "avatar_url": "https://avatars.githubusercontent.com/u/65531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marsam", "html_url": "https://github.com/marsam", "followers_url": "https://api.github.com/users/marsam/followers", "following_url": "https://api.github.com/users/marsam/following{/other_user}", "gists_url": "https://api.github.com/users/marsam/gists{/gist_id}", "starred_url": "https://api.github.com/users/marsam/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marsam/subscriptions", "organizations_url": "https://api.github.com/users/marsam/orgs", "repos_url": "https://api.github.com/users/marsam/repos", "events_url": "https://api.github.com/users/marsam/events{/privacy}", "received_events_url": "https://api.github.com/users/marsam/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2019-07-19T01:15:34Z", "updated_at": "2019-07-23T10:53:52Z", "closed_at": "2019-07-23T10:53:47Z", "author_association": "NONE", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/3887", "html_url": "https://github.com/scrapy/scrapy/pull/3887", "diff_url": "https://github.com/scrapy/scrapy/pull/3887.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/3887.patch", "merged_at": null}, "body": "The latest release breaks scrapy on python2\r\nCloses https://github.com/scrapy/scrapy/issues/3889", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3887/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3887/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3875", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3875/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3875/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3875/events", "html_url": "https://github.com/scrapy/scrapy/issues/3875", "id": 467742912, "node_id": "MDU6SXNzdWU0Njc3NDI5MTI=", "number": 3875, "title": "Problem using proxy with scrapy", "user": {"login": "Nizarazo", "id": 17083294, "node_id": "MDQ6VXNlcjE3MDgzMjk0", "avatar_url": "https://avatars.githubusercontent.com/u/17083294?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Nizarazo", "html_url": "https://github.com/Nizarazo", "followers_url": "https://api.github.com/users/Nizarazo/followers", "following_url": "https://api.github.com/users/Nizarazo/following{/other_user}", "gists_url": "https://api.github.com/users/Nizarazo/gists{/gist_id}", "starred_url": "https://api.github.com/users/Nizarazo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Nizarazo/subscriptions", "organizations_url": "https://api.github.com/users/Nizarazo/orgs", "repos_url": "https://api.github.com/users/Nizarazo/repos", "events_url": "https://api.github.com/users/Nizarazo/events{/privacy}", "received_events_url": "https://api.github.com/users/Nizarazo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-07-13T16:54:16Z", "updated_at": "2019-09-17T06:43:56Z", "closed_at": "2019-09-17T06:43:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi\r\n\r\nI am having problem using proxy with Scrapy, I have private proxy with HTTPS supported.\r\n\r\nI tried with simplest spider without proxy with the following extensions:\r\nEXTENSIONS = {\r\n    'scrapy.extensions.telnet.TelnetConsole': None,\r\n}\r\nSPIDER_MIDDLEWARES = {\r\n    'scrapy_splash.SplashDeduplicateArgsMiddleware': 100,\r\n}\r\nDOWNLOADER_MIDDLEWARES = {\r\n    'scrapy_splash.SplashCookiesMiddleware': 723,\r\n    'scrapy_splash.SplashMiddleware': 725,\r\n    'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 810,\r\n}\r\n\r\nIt worked fine 200 ok response\r\n\r\nThen I configured the proxy as suggested in the documenation:\r\nhttps://docs.scrapy.org/en/latest/topics/downloader-middleware.html?highlight=proxy#module-scrapy.downloadermiddlewares.httpproxy\r\n\r\n1.\r\nadded this to the middle ware:\r\nDOWNLOADER_MIDDLEWARES  = {\r\n...\r\n'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 1\r\n...\r\n}\r\n\r\n2. I added the meta key proxy per each request as follows:\r\nrequest = SplashRequest(url='https://www.example.com', callback=self.parse, endpoint='execute',\r\n                        args={'wait': 1,\r\n                              'lua_source': login_script,\r\n                              'timeout':90,\r\n                              }\r\n                        )\r\nrequest.meta['proxy'] = proxy\r\nyield request\r\n\r\nwhere proxy = 'https://username:password@proxyip:proxyport'\r\n\r\nI am getting the error below when running scrapy:\r\n2019-07-19 16:11:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.example.com via http://127.0.0.1:8050/execute> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL rout\r\nines', 'ssl3_get_record', 'wrong version number')]>]\r\n\r\nI tried to fix by using the values of DOWNLOADER_CLIENT_TLS_METHOD such as:\r\n'TLSv1.0' 'TLSv1.1' 'TLSv1.2' 'SSLv3' \r\nbut it didn't change anything same error.\r\n\r\nThanks", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3875/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3875/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3872", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3872/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3872/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3872/events", "html_url": "https://github.com/scrapy/scrapy/issues/3872", "id": 467437031, "node_id": "MDU6SXNzdWU0Njc0MzcwMzE=", "number": 3872, "title": "Document changed CrawlerProcess.crawl(spider) functionality in Release notes", "user": {"login": "nyov", "id": 438293, "node_id": "MDQ6VXNlcjQzODI5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/438293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nyov", "html_url": "https://github.com/nyov", "followers_url": "https://api.github.com/users/nyov/followers", "following_url": "https://api.github.com/users/nyov/following{/other_user}", "gists_url": "https://api.github.com/users/nyov/gists{/gist_id}", "starred_url": "https://api.github.com/users/nyov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nyov/subscriptions", "organizations_url": "https://api.github.com/users/nyov/orgs", "repos_url": "https://api.github.com/users/nyov/repos", "events_url": "https://api.github.com/users/nyov/events{/privacy}", "received_events_url": "https://api.github.com/users/nyov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/22", "html_url": "https://github.com/scrapy/scrapy/milestone/22", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/22/labels", "id": 3769862, "node_id": "MDk6TWlsZXN0b25lMzc2OTg2Mg==", "number": 22, "title": "v1.7", "description": "", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 76, "state": "closed", "created_at": "2018-10-25T20:34:06Z", "updated_at": "2019-07-23T20:39:53Z", "due_on": "2019-07-19T07:00:00Z", "closed_at": "2019-07-23T20:39:53Z"}, "comments": 2, "created_at": "2019-07-12T14:14:20Z", "updated_at": "2019-07-18T13:37:18Z", "closed_at": "2019-07-18T13:37:18Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Possible Regression. See explanation beneath spider.\r\n\r\nMWE Testcode:\r\n\r\n```python3\r\n#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n#\r\nimport logging\r\nimport scrapy\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\nclass Spider(scrapy.Spider):\r\n\r\n    name = 'Spidy'\r\n\r\n    def start_requests(self):\r\n        yield scrapy.Request('https://scrapy.org/')\r\n\r\n    def parse(self, response):\r\n        logger.info('Here I fetched %s for you. [%s]' % (response.url, response.status))\r\n        return {\r\n            'status': response.status,\r\n            'url': response.url,\r\n            'test': 'item',\r\n        }\r\n\r\n\r\nclass LogPipeline(object):\r\n\r\n    def process_item(self, item, spider):\r\n        logger.warning('HIT ME PLEASE')\r\n        logger.info('Got hit by:\\n %r' % item)\r\n        return item\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    from scrapy.settings import Settings\r\n    from scrapy.crawler import CrawlerProcess\r\n\r\n    settings = Settings(values={\r\n        'TELNETCONSOLE_ENABLED': False, # necessary evil :(\r\n        'EXTENSIONS': {\r\n            'scrapy.extensions.telnet.TelnetConsole': None,\r\n        },\r\n        'ITEM_PIPELINES': {\r\n            '__main__.LogPipeline': 800,\r\n        },\r\n    })\r\n\r\n    spider = Spider()\r\n\r\n    process = CrawlerProcess(settings=settings)\r\n    process.crawl(spider)\r\n    process.start()\r\n```\r\n\r\nI just tried this functional (with Scrapy 1.5.1) example script on current master codebase and I got this error:\r\n```\r\n2019-07-12 13:54:16 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: scrapybot)\r\n2019-07-12 13:54:16 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.0, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.3 (default, Apr  3 2019, 05:39:12) - [GCC 8.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.6.1, Platform Linux-4.9.0-8-amd64-x86_64-with-debian-10.0\r\nTraceback (most recent call last):\r\n  File \"./test.py\", line 60, in <module>\r\n    process.crawl(spider)\r\n  File \"[...]/scrapy.git/scrapy/crawler.py\", line 180, in crawl\r\n    'The crawler_or_spidercls argument cannot be a spider object, '\r\nValueError: The crawler_or_spidercls argument cannot be a spider object, it must be a spider class (or a Crawler object)\r\n```\r\n\r\nLooking at the codebase, blame blames this change: https://github.com/scrapy/scrapy/pull/3610\r\n\r\nBut that procedure (passing a spider instance as `process.crawl(spider)`) is taken pretty much verbatim from the (latest) docs, so it should continue to work, ~or first get deprecated~?: https://docs.scrapy.org/en/latest/topics/practices.html#run-scrapy-from-a-script\r\n\r\n**edit:/** to clarify, I don't mind the functionality getting removed without deprecation, if it was never documented, as it seems it wasn't.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3872/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3872/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3851", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3851/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3851/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3851/events", "html_url": "https://github.com/scrapy/scrapy/issues/3851", "id": 463906964, "node_id": "MDU6SXNzdWU0NjM5MDY5NjQ=", "number": 3851, "title": "HttpErrorMiddleware not honoring handle_httpstatus_all meta as documented", "user": {"login": "ddebernardy", "id": 225259, "node_id": "MDQ6VXNlcjIyNTI1OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/225259?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ddebernardy", "html_url": "https://github.com/ddebernardy", "followers_url": "https://api.github.com/users/ddebernardy/followers", "following_url": "https://api.github.com/users/ddebernardy/following{/other_user}", "gists_url": "https://api.github.com/users/ddebernardy/gists{/gist_id}", "starred_url": "https://api.github.com/users/ddebernardy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ddebernardy/subscriptions", "organizations_url": "https://api.github.com/users/ddebernardy/orgs", "repos_url": "https://api.github.com/users/ddebernardy/repos", "events_url": "https://api.github.com/users/ddebernardy/events{/privacy}", "received_events_url": "https://api.github.com/users/ddebernardy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-03T18:58:45Z", "updated_at": "2021-04-01T17:43:46Z", "closed_at": "2021-04-01T17:43:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\n    def process_spider_input(self, response, spider):\r\n        if 200 <= response.status < 300:  # common case\r\n            return\r\n        meta = response.meta\r\n        if 'handle_httpstatus_all' in meta:\r\n            return\r\n```\r\n\r\nShouldn't that be more like:\r\n\r\n```\r\n        if 'handle_httpstatus_all' in meta and meta['handle_httpstatus_all']:\r\n            return\r\n```\r\n\r\nAs I read the code, setting meta['handle_httpstatus_all'] = False would likely be treated as if it was set to `True`.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3851/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3851/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3821", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3821/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3821/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3821/events", "html_url": "https://github.com/scrapy/scrapy/issues/3821", "id": 453863824, "node_id": "MDU6SXNzdWU0NTM4NjM4MjQ=", "number": 3821, "title": "Issue with Twisted and Python 3.4 ", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-06-09T05:12:20Z", "updated_at": "2019-06-12T20:40:26Z", "closed_at": "2019-06-12T20:40:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Twisted had a patch 3 days ago and it's causing test suite to fail for py34 environment. \r\nTwisted , according to their Readme, support Python 3.5+. This needs to be fixed if the builds need to pass", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3821/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3821/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3812", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3812/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3812/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3812/events", "html_url": "https://github.com/scrapy/scrapy/pull/3812", "id": 452369262, "node_id": "MDExOlB1bGxSZXF1ZXN0Mjg1MjY4ODUy", "number": 3812, "title": "[MRG+1] Tutorial: scrapy shell example should say \"text\" not \"title\" (#3807)", "user": {"login": "duketemon", "id": 26257908, "node_id": "MDQ6VXNlcjI2MjU3OTA4", "avatar_url": "https://avatars.githubusercontent.com/u/26257908?v=4", "gravatar_id": "", "url": "https://api.github.com/users/duketemon", "html_url": "https://github.com/duketemon", "followers_url": "https://api.github.com/users/duketemon/followers", "following_url": "https://api.github.com/users/duketemon/following{/other_user}", "gists_url": "https://api.github.com/users/duketemon/gists{/gist_id}", "starred_url": "https://api.github.com/users/duketemon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/duketemon/subscriptions", "organizations_url": "https://api.github.com/users/duketemon/orgs", "repos_url": "https://api.github.com/users/duketemon/repos", "events_url": "https://api.github.com/users/duketemon/events{/privacy}", "received_events_url": "https://api.github.com/users/duketemon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/22", "html_url": "https://github.com/scrapy/scrapy/milestone/22", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/22/labels", "id": 3769862, "node_id": "MDk6TWlsZXN0b25lMzc2OTg2Mg==", "number": 22, "title": "v1.7", "description": "", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 76, "state": "closed", "created_at": "2018-10-25T20:34:06Z", "updated_at": "2019-07-23T20:39:53Z", "due_on": "2019-07-19T07:00:00Z", "closed_at": "2019-07-23T20:39:53Z"}, "comments": 1, "created_at": "2019-06-05T08:15:44Z", "updated_at": "2019-06-25T20:29:37Z", "closed_at": "2019-06-05T15:00:28Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/3812", "html_url": "https://github.com/scrapy/scrapy/pull/3812", "diff_url": "https://github.com/scrapy/scrapy/pull/3812.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/3812.patch", "merged_at": "2019-06-05T15:00:27Z"}, "body": "Tutorial: scrapy shell example should say \"text\" not \"title\"\r\n\r\nFixes #3812 ", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3812/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3812/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3809", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3809/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3809/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3809/events", "html_url": "https://github.com/scrapy/scrapy/issues/3809", "id": 451973110, "node_id": "MDU6SXNzdWU0NTE5NzMxMTA=", "number": 3809, "title": "Fix test_command_parse.py on Windows", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 318523681, "node_id": "MDU6TGFiZWwzMTg1MjM2ODE=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/Windows", "name": "Windows", "color": "fad8c7", "default": false, "description": null}, {"id": 443053983, "node_id": "MDU6TGFiZWw0NDMwNTM5ODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/CI", "name": "CI", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-06-04T12:40:42Z", "updated_at": "2019-06-12T20:40:09Z", "closed_at": "2019-06-12T20:40:09Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "All the tests from that test file are failing on the Windows CI platform.\r\n\r\nWe need to look into it, and fix the underlying issue or have those tests skipped on Windows if they are not meant to work on that platform.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3809/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3809/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3807", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3807/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3807/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3807/events", "html_url": "https://github.com/scrapy/scrapy/issues/3807", "id": 451698007, "node_id": "MDU6SXNzdWU0NTE2OTgwMDc=", "number": 3807, "title": "Tutorial: scrapy shell example should say \"text\" not \"title\"", "user": {"login": "kiwisquash", "id": 34022735, "node_id": "MDQ6VXNlcjM0MDIyNzM1", "avatar_url": "https://avatars.githubusercontent.com/u/34022735?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kiwisquash", "html_url": "https://github.com/kiwisquash", "followers_url": "https://api.github.com/users/kiwisquash/followers", "following_url": "https://api.github.com/users/kiwisquash/following{/other_user}", "gists_url": "https://api.github.com/users/kiwisquash/gists{/gist_id}", "starred_url": "https://api.github.com/users/kiwisquash/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kiwisquash/subscriptions", "organizations_url": "https://api.github.com/users/kiwisquash/orgs", "repos_url": "https://api.github.com/users/kiwisquash/repos", "events_url": "https://api.github.com/users/kiwisquash/events{/privacy}", "received_events_url": "https://api.github.com/users/kiwisquash/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-03T21:28:52Z", "updated_at": "2019-06-05T20:54:48Z", "closed_at": "2019-06-05T20:54:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "The text currently says:\r\n\r\n> Now, let\u2019s extract `title`, author and the tags from that quote using the quote object we just created:\r\n> \\>>> title = quote.css(\"span.text::text\").get()\r\n> \\>>>title\r\n> '\u201cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\u201d'\r\n\r\nThe`title` should be changed to `text`. In fact, if you scroll down slightly down in the for-loop, `text` is used instead of `title`. \r\n\r\nhttps://docs.scrapy.org/en/1.6/intro/tutorial.html#extracting-quotes-and-authors", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3807/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3807/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3806", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3806/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3806/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3806/events", "html_url": "https://github.com/scrapy/scrapy/pull/3806", "id": 451598919, "node_id": "MDExOlB1bGxSZXF1ZXN0Mjg0NjU3MzA3", "number": 3806, "title": "Fix a double indexing of the scrapy.statscollectors module in the doc\u2026", "user": {"login": "Gallaecio", "id": 705211, "node_id": "MDQ6VXNlcjcwNTIxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gallaecio", "html_url": "https://github.com/Gallaecio", "followers_url": "https://api.github.com/users/Gallaecio/followers", "following_url": "https://api.github.com/users/Gallaecio/following{/other_user}", "gists_url": "https://api.github.com/users/Gallaecio/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gallaecio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gallaecio/subscriptions", "organizations_url": "https://api.github.com/users/Gallaecio/orgs", "repos_url": "https://api.github.com/users/Gallaecio/repos", "events_url": "https://api.github.com/users/Gallaecio/events{/privacy}", "received_events_url": "https://api.github.com/users/Gallaecio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/22", "html_url": "https://github.com/scrapy/scrapy/milestone/22", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/22/labels", "id": 3769862, "node_id": "MDk6TWlsZXN0b25lMzc2OTg2Mg==", "number": 22, "title": "v1.7", "description": "", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 76, "state": "closed", "created_at": "2018-10-25T20:34:06Z", "updated_at": "2019-07-23T20:39:53Z", "due_on": "2019-07-19T07:00:00Z", "closed_at": "2019-07-23T20:39:53Z"}, "comments": 3, "created_at": "2019-06-03T17:22:26Z", "updated_at": "2019-06-25T20:29:51Z", "closed_at": "2019-06-04T13:11:08Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/3806", "html_url": "https://github.com/scrapy/scrapy/pull/3806", "diff_url": "https://github.com/scrapy/scrapy/pull/3806.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/3806.patch", "merged_at": "2019-06-04T13:11:08Z"}, "body": "\u2026umentation\r\n\r\nThe issue is being reported by the CI system.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3806/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3806/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3805", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3805/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3805/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3805/events", "html_url": "https://github.com/scrapy/scrapy/pull/3805", "id": 451438066, "node_id": "MDExOlB1bGxSZXF1ZXN0Mjg0NTI3NzU5", "number": 3805, "title": "fix retry's with another proxy_authorization", "user": {"login": "ljm9104", "id": 33405881, "node_id": "MDQ6VXNlcjMzNDA1ODgx", "avatar_url": "https://avatars.githubusercontent.com/u/33405881?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ljm9104", "html_url": "https://github.com/ljm9104", "followers_url": "https://api.github.com/users/ljm9104/followers", "following_url": "https://api.github.com/users/ljm9104/following{/other_user}", "gists_url": "https://api.github.com/users/ljm9104/gists{/gist_id}", "starred_url": "https://api.github.com/users/ljm9104/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ljm9104/subscriptions", "organizations_url": "https://api.github.com/users/ljm9104/orgs", "repos_url": "https://api.github.com/users/ljm9104/repos", "events_url": "https://api.github.com/users/ljm9104/events{/privacy}", "received_events_url": "https://api.github.com/users/ljm9104/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-06-03T11:47:04Z", "updated_at": "2022-07-25T13:10:54Z", "closed_at": "2022-07-25T13:10:53Z", "author_association": "NONE", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/3805", "html_url": "https://github.com/scrapy/scrapy/pull/3805", "diff_url": "https://github.com/scrapy/scrapy/pull/3805.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/3805.patch", "merged_at": null}, "body": "If one request is failed and the request uses ip proxy, in the fllowing times retry, if this times uses another ip  authorization, the request has already made request.headers.['Proxy-Authorization'] and this time we still use the original Proxy-Authorization, so I think we shouldn't judge the request.headers.get('Proxy-Authorization')  isexist or not, we should overwrite request.headers.['Proxy-Authorization'] every times,  or we should judge every time if it is isexsists and request.headers.['Proxy-Authorization'] is or not  the same with original. At last, I prefer the first  modify method.\r\n\r\n`\r\n# the downloadermiddlewares httpproxy\r\ndef process_request(self, request, spider):\r\n    # ignore if proxy is already set\r\n    if 'proxy' in request.meta:\r\n        if request.meta['proxy'] is None:\r\n            return\r\n        # extract credentials if present\r\n        creds, proxy_url = self._get_proxy(request.meta['proxy'], '')\r\n        request.meta['proxy'] = proxy_url\r\n        if creds and not request.headers.get('Proxy-Authorization'):\r\n            request.headers['Proxy-Authorization'] = b'Basic ' + creds\r\n        return\r\n    elif not self.proxies:\r\n        return\r\n`", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3805/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3805/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3804", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3804/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3804/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3804/events", "html_url": "https://github.com/scrapy/scrapy/issues/3804", "id": 451143623, "node_id": "MDU6SXNzdWU0NTExNDM2MjM=", "number": 3804, "title": "Items missing", "user": {"login": "FAIZ428", "id": 35243679, "node_id": "MDQ6VXNlcjM1MjQzNjc5", "avatar_url": "https://avatars.githubusercontent.com/u/35243679?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FAIZ428", "html_url": "https://github.com/FAIZ428", "followers_url": "https://api.github.com/users/FAIZ428/followers", "following_url": "https://api.github.com/users/FAIZ428/following{/other_user}", "gists_url": "https://api.github.com/users/FAIZ428/gists{/gist_id}", "starred_url": "https://api.github.com/users/FAIZ428/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FAIZ428/subscriptions", "organizations_url": "https://api.github.com/users/FAIZ428/orgs", "repos_url": "https://api.github.com/users/FAIZ428/repos", "events_url": "https://api.github.com/users/FAIZ428/events{/privacy}", "received_events_url": "https://api.github.com/users/FAIZ428/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-06-02T02:01:57Z", "updated_at": "2019-08-26T11:39:10Z", "closed_at": "2019-07-04T08:05:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n when working with the itemLoader()  to populate items from a created list in python.  Here I have attached a working of the suspected bug. \r\n\r\nThis appears to be present when the loader.get_output_value method has been executed. Once that executes then, the populated list initially created would have one of the items missing. This appears to be a malfunction bug within the software presented.  If we only have loader.load_item, the values are presented, however loder.get_output_value() fails to display the value/s in the data set as tested. \r\n<img width=\"1440\" alt=\"scrapybug\" src=\"https://user-images.githubusercontent.com/35243679/58755752-0d574380-849f-11e9-8ae7-7fd1f0c6dbd4.png\">\r\n\r\n\r\n\r\n loader.get_output_value causes the items value to be missing from School:\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3804/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3804/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3798", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3798/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3798/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3798/events", "html_url": "https://github.com/scrapy/scrapy/issues/3798", "id": 448958631, "node_id": "MDU6SXNzdWU0NDg5NTg2MzE=", "number": 3798, "title": "LinkExtractor with Unique = False doesn't extract fully identical Links", "user": {"login": "Ksianka", "id": 44999286, "node_id": "MDQ6VXNlcjQ0OTk5Mjg2", "avatar_url": "https://avatars.githubusercontent.com/u/44999286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ksianka", "html_url": "https://github.com/Ksianka", "followers_url": "https://api.github.com/users/Ksianka/followers", "following_url": "https://api.github.com/users/Ksianka/following{/other_user}", "gists_url": "https://api.github.com/users/Ksianka/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ksianka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ksianka/subscriptions", "organizations_url": "https://api.github.com/users/Ksianka/orgs", "repos_url": "https://api.github.com/users/Ksianka/repos", "events_url": "https://api.github.com/users/Ksianka/events{/privacy}", "received_events_url": "https://api.github.com/users/Ksianka/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-27T18:21:49Z", "updated_at": "2023-01-12T20:13:46Z", "closed_at": "2023-01-12T20:13:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "Case: \r\nunexpected behavior identified for LinkExctractor with Unique = False if the page contains fully identical links (the same URL and text).\r\nThe current result returns one unique link instead of two or more identical ones.\r\nFor example:\r\n\r\n1) Local http file \r\n\r\n```<your_path>Test_file.html\r\n<html>\r\n<body>\r\n<a href='sample3.html'>sample 3 repetition</a>\r\n<a href='sample3.html'>sample 3 repetition</a>\r\n</body>\r\n</html>```\r\n\r\n2) Scrapy test code:\r\nignore the error about <GET file:///robots.txt>  as we use local file\r\n\r\n`import scrapy\r\nfrom scrapy.linkextractors import LinkExtractor\r\n\r\nclass QuotesSpider(scrapy.Spider):\r\n    name = \u201ctest\u201d\r\n    start_urls = [\r\n        'file:///<insert_your_local_path>/Test_file.html',\r\n    ]\r\n\r\ndef __init__(self, *args, **kwargs):\r\n    super(QuotesSpider, self).__init__(*args, **kwargs)\r\n    self.le = LinkExtractor(unique=False)\r\n\r\ndef parse(self, response):\r\n    links = self.le.extract_links(response)\r\n    yield {'extract_link': links}`\r\n\r\n3) run the code: scrapy crawl test, and get the result with one link:\r\n\r\n{'extract_link': [Link(url='file:///<your_local_path>/sample3.html', text='sample 3 repetition', fragment='', nofollow=False)]}\r\n\r\nInstead of the result with two links from HTML:\r\n\r\n{'extract_link': [Link(url='file:///<your_local_path>/sample3.html', text='sample 3 repetition', fragment='', nofollow=False), \r\nLink(url='<your_local_path>/sample3.html', text='sample 3 repetition', fragment='', nofollow=False)]}\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3798/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3798/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3797", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3797/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3797/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3797/events", "html_url": "https://github.com/scrapy/scrapy/pull/3797", "id": 448750786, "node_id": "MDExOlB1bGxSZXF1ZXN0MjgyNDMyNDQ4", "number": 3797, "title": "[MRG+1] remove a \"is\"", "user": {"login": "mar-heaven", "id": 26325127, "node_id": "MDQ6VXNlcjI2MzI1MTI3", "avatar_url": "https://avatars.githubusercontent.com/u/26325127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mar-heaven", "html_url": "https://github.com/mar-heaven", "followers_url": "https://api.github.com/users/mar-heaven/followers", "following_url": "https://api.github.com/users/mar-heaven/following{/other_user}", "gists_url": "https://api.github.com/users/mar-heaven/gists{/gist_id}", "starred_url": "https://api.github.com/users/mar-heaven/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mar-heaven/subscriptions", "organizations_url": "https://api.github.com/users/mar-heaven/orgs", "repos_url": "https://api.github.com/users/mar-heaven/repos", "events_url": "https://api.github.com/users/mar-heaven/events{/privacy}", "received_events_url": "https://api.github.com/users/mar-heaven/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/22", "html_url": "https://github.com/scrapy/scrapy/milestone/22", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/22/labels", "id": 3769862, "node_id": "MDk6TWlsZXN0b25lMzc2OTg2Mg==", "number": 22, "title": "v1.7", "description": "", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 76, "state": "closed", "created_at": "2018-10-25T20:34:06Z", "updated_at": "2019-07-23T20:39:53Z", "due_on": "2019-07-19T07:00:00Z", "closed_at": "2019-07-23T20:39:53Z"}, "comments": 1, "created_at": "2019-05-27T09:15:55Z", "updated_at": "2019-06-25T20:30:02Z", "closed_at": "2019-05-28T18:12:05Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/3797", "html_url": "https://github.com/scrapy/scrapy/pull/3797", "diff_url": "https://github.com/scrapy/scrapy/pull/3797.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/3797.patch", "merged_at": "2019-05-28T18:12:05Z"}, "body": "When I translated in Chinese, I found a needless \"is\"", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3797/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3797/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3794", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3794/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3794/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3794/events", "html_url": "https://github.com/scrapy/scrapy/pull/3794", "id": 448442293, "node_id": "MDExOlB1bGxSZXF1ZXN0MjgyMjE3MTI2", "number": 3794, "title": "[MRG+1] Fix form methods in FormRequest.from_response (#3777)", "user": {"login": "csalazar", "id": 360285, "node_id": "MDQ6VXNlcjM2MDI4NQ==", "avatar_url": "https://avatars.githubusercontent.com/u/360285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/csalazar", "html_url": "https://github.com/csalazar", "followers_url": "https://api.github.com/users/csalazar/followers", "following_url": "https://api.github.com/users/csalazar/following{/other_user}", "gists_url": "https://api.github.com/users/csalazar/gists{/gist_id}", "starred_url": "https://api.github.com/users/csalazar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/csalazar/subscriptions", "organizations_url": "https://api.github.com/users/csalazar/orgs", "repos_url": "https://api.github.com/users/csalazar/repos", "events_url": "https://api.github.com/users/csalazar/events{/privacy}", "received_events_url": "https://api.github.com/users/csalazar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 326439252, "node_id": "MDU6TGFiZWwzMjY0MzkyNTI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/security", "name": "security", "color": "e11d21", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/22", "html_url": "https://github.com/scrapy/scrapy/milestone/22", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/22/labels", "id": 3769862, "node_id": "MDk6TWlsZXN0b25lMzc2OTg2Mg==", "number": 22, "title": "v1.7", "description": "", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 76, "state": "closed", "created_at": "2018-10-25T20:34:06Z", "updated_at": "2019-07-23T20:39:53Z", "due_on": "2019-07-19T07:00:00Z", "closed_at": "2019-07-23T20:39:53Z"}, "comments": 4, "created_at": "2019-05-25T09:05:36Z", "updated_at": "2019-07-02T15:08:31Z", "closed_at": "2019-07-02T15:08:15Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/3794", "html_url": "https://github.com/scrapy/scrapy/pull/3794", "diff_url": "https://github.com/scrapy/scrapy/pull/3794.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/3794.patch", "merged_at": "2019-07-02T15:08:15Z"}, "body": "Fixes #3777 ", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3794/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3794/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3791", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3791/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3791/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3791/events", "html_url": "https://github.com/scrapy/scrapy/pull/3791", "id": 448173860, "node_id": "MDExOlB1bGxSZXF1ZXN0MjgyMDE4MTE5", "number": 3791, "title": "[MRG+1] Fix documentation for spiderloader", "user": {"login": "barraponto", "id": 134005, "node_id": "MDQ6VXNlcjEzNDAwNQ==", "avatar_url": "https://avatars.githubusercontent.com/u/134005?v=4", "gravatar_id": "", "url": "https://api.github.com/users/barraponto", "html_url": "https://github.com/barraponto", "followers_url": "https://api.github.com/users/barraponto/followers", "following_url": "https://api.github.com/users/barraponto/following{/other_user}", "gists_url": "https://api.github.com/users/barraponto/gists{/gist_id}", "starred_url": "https://api.github.com/users/barraponto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/barraponto/subscriptions", "organizations_url": "https://api.github.com/users/barraponto/orgs", "repos_url": "https://api.github.com/users/barraponto/repos", "events_url": "https://api.github.com/users/barraponto/events{/privacy}", "received_events_url": "https://api.github.com/users/barraponto/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/22", "html_url": "https://github.com/scrapy/scrapy/milestone/22", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/22/labels", "id": 3769862, "node_id": "MDk6TWlsZXN0b25lMzc2OTg2Mg==", "number": 22, "title": "v1.7", "description": "", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 76, "state": "closed", "created_at": "2018-10-25T20:34:06Z", "updated_at": "2019-07-23T20:39:53Z", "due_on": "2019-07-19T07:00:00Z", "closed_at": "2019-07-23T20:39:53Z"}, "comments": 2, "created_at": "2019-05-24T13:33:12Z", "updated_at": "2019-06-25T20:29:57Z", "closed_at": "2019-05-28T18:16:13Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/3791", "html_url": "https://github.com/scrapy/scrapy/pull/3791", "diff_url": "https://github.com/scrapy/scrapy/pull/3791.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/3791.patch", "merged_at": "2019-05-28T18:16:13Z"}, "body": "Docs mentioned the wrong module.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3791/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3791/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3777", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3777/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3777/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3777/events", "html_url": "https://github.com/scrapy/scrapy/issues/3777", "id": 443777658, "node_id": "MDU6SXNzdWU0NDM3Nzc2NTg=", "number": 3777, "title": "Whitelist form methods in FormRequest.from_response", "user": {"login": "csalazar", "id": 360285, "node_id": "MDQ6VXNlcjM2MDI4NQ==", "avatar_url": "https://avatars.githubusercontent.com/u/360285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/csalazar", "html_url": "https://github.com/csalazar", "followers_url": "https://api.github.com/users/csalazar/followers", "following_url": "https://api.github.com/users/csalazar/following{/other_user}", "gists_url": "https://api.github.com/users/csalazar/gists{/gist_id}", "starred_url": "https://api.github.com/users/csalazar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/csalazar/subscriptions", "organizations_url": "https://api.github.com/users/csalazar/orgs", "repos_url": "https://api.github.com/users/csalazar/repos", "events_url": "https://api.github.com/users/csalazar/events{/privacy}", "received_events_url": "https://api.github.com/users/csalazar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 326439252, "node_id": "MDU6TGFiZWwzMjY0MzkyNTI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/security", "name": "security", "color": "e11d21", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-05-14T08:28:01Z", "updated_at": "2019-07-02T15:08:15Z", "closed_at": "2019-07-02T15:08:15Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi team, according to this [article](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/form#attr-method), there are 3 methods that are accepted in form's `method` attribute. I can't remember about other methods, but I'd agree to consider the rest of [REST verbs](https://restfulapi.net/http-methods/) if that's common. Anyway, I think it should be a good idea to whitelist the accepted methods to avoid scenarios like this [vulnerability exploitation](https://medium.com/alertot/web-scraping-considered-dangerous-exploiting-the-telnet-service-in-scrapy-1-5-2-ad5260fea0db) that took advantage of form's method.\r\n\r\nThis issue affects `FormRequest.from_response` and the affected line is: https://github.com/scrapy/scrapy/blob/a3d38041e230f886d55569f861a11a96ab8a1913/scrapy/http/request/form.py#L51\r\n\r\nI want to know if there some reason behind this behavior, otherwise I could send a pull request.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3777/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3777/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3747", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3747/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3747/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3747/events", "html_url": "https://github.com/scrapy/scrapy/issues/3747", "id": 434070783, "node_id": "MDU6SXNzdWU0MzQwNzA3ODM=", "number": 3747, "title": "invalid hostname", "user": {"login": "qq703048949", "id": 7246095, "node_id": "MDQ6VXNlcjcyNDYwOTU=", "avatar_url": "https://avatars.githubusercontent.com/u/7246095?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qq703048949", "html_url": "https://github.com/qq703048949", "followers_url": "https://api.github.com/users/qq703048949/followers", "following_url": "https://api.github.com/users/qq703048949/following{/other_user}", "gists_url": "https://api.github.com/users/qq703048949/gists{/gist_id}", "starred_url": "https://api.github.com/users/qq703048949/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qq703048949/subscriptions", "organizations_url": "https://api.github.com/users/qq703048949/orgs", "repos_url": "https://api.github.com/users/qq703048949/repos", "events_url": "https://api.github.com/users/qq703048949/events{/privacy}", "received_events_url": "https://api.github.com/users/qq703048949/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-04-17T03:03:59Z", "updated_at": "2019-04-17T04:28:50Z", "closed_at": "2019-04-17T04:28:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "when I request http://tjw_161130192022480.company.qihuiwang.com/\r\nreturn  this:    invalid hostname: tjw_161130192022480.company.qihuiwang.com,\r\nI don't know how to solve this question ! \r\nhlep me !\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3747/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3747/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3721", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3721/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3721/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3721/events", "html_url": "https://github.com/scrapy/scrapy/issues/3721", "id": 429078053, "node_id": "MDU6SXNzdWU0MjkwNzgwNTM=", "number": 3721, "title": "\"Edit on Github\" link gives 404 error from docs.scrapy.org documentation pages", "user": {"login": "float13", "id": 43447704, "node_id": "MDQ6VXNlcjQzNDQ3NzA0", "avatar_url": "https://avatars.githubusercontent.com/u/43447704?v=4", "gravatar_id": "", "url": "https://api.github.com/users/float13", "html_url": "https://github.com/float13", "followers_url": "https://api.github.com/users/float13/followers", "following_url": "https://api.github.com/users/float13/following{/other_user}", "gists_url": "https://api.github.com/users/float13/gists{/gist_id}", "starred_url": "https://api.github.com/users/float13/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/float13/subscriptions", "organizations_url": "https://api.github.com/users/float13/orgs", "repos_url": "https://api.github.com/users/float13/repos", "events_url": "https://api.github.com/users/float13/events{/privacy}", "received_events_url": "https://api.github.com/users/float13/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-04-04T04:29:17Z", "updated_at": "2019-09-17T06:55:32Z", "closed_at": "2019-09-17T06:55:32Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "For example, from this doc page: https://docs.scrapy.org/en/latest/topics/exporters.html\r\n\r\nclicking the \"Edit on Github\" link in the upper-right corner leads to a 404 error page (tested in Firefox and Safari):\r\nhttps://github.com/scrapy/scrapy/blob/origin/1.6/docs/topics/exporters.rst\r\n\r\nThis has happened on every doc page I tried the link from.\r\n\r\nI would like to help with some small grammatical edits in the docs (I'm new to Scrapy so I wouldn't make any technical edits). Would a pull request be appropriate for this type of doc edit? \r\n\r\nAlso, specifying which files certain code snippets belong in would be very helpful for beginners.\r\n ", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3721/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3721/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3597", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3597/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3597/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3597/events", "html_url": "https://github.com/scrapy/scrapy/issues/3597", "id": 402095438, "node_id": "MDU6SXNzdWU0MDIwOTU0Mzg=", "number": 3597, "title": "may be 'accessible'?", "user": {"login": "amchii", "id": 26922464, "node_id": "MDQ6VXNlcjI2OTIyNDY0", "avatar_url": "https://avatars.githubusercontent.com/u/26922464?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amchii", "html_url": "https://github.com/amchii", "followers_url": "https://api.github.com/users/amchii/followers", "following_url": "https://api.github.com/users/amchii/following{/other_user}", "gists_url": "https://api.github.com/users/amchii/gists{/gist_id}", "starred_url": "https://api.github.com/users/amchii/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amchii/subscriptions", "organizations_url": "https://api.github.com/users/amchii/orgs", "repos_url": "https://api.github.com/users/amchii/repos", "events_url": "https://api.github.com/users/amchii/events{/privacy}", "received_events_url": "https://api.github.com/users/amchii/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-01-23T06:50:26Z", "updated_at": "2019-09-25T09:13:38Z", "closed_at": "2019-09-25T09:13:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "in the function [request_fingerprint](https://github.com/scrapy/scrapy/blob/master/scrapy/utils/request.py) \uff0c\u2018accesible\u2019 may be \u2018accessible\u2019 in comments. OCD  XD..\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3597/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3597/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3575", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3575/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3575/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3575/events", "html_url": "https://github.com/scrapy/scrapy/issues/3575", "id": 397915507, "node_id": "MDU6SXNzdWUzOTc5MTU1MDc=", "number": 3575, "title": "Double-encoded cookies", "user": {"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-01-10T16:38:01Z", "updated_at": "2020-05-27T16:41:44Z", "closed_at": "2020-05-27T16:41:44Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "When cookies are passed as UTF8 encoded bytes to the `Request` constructor, they end up being encoded twice and escaped in the `Cookie` header.\r\n\r\n```\r\n$ scrapy shell\r\n(...)\r\nIn [1]: fetch(scrapy.Request('https://httpbin.org/cookies', cookies={'a': u'\u00e1'.encode('utf8')}))\r\n\r\nIn [2]: request.headers['Cookie']\r\nOut[2]: b\"a=b'\\\\xc3\\\\xa1'\"\r\n\r\nIn [3]: print(response.text)\r\n{\r\n  \"cookies\": {\r\n    \"a\": \"b'\\\\xc3\\\\xa1'\"\r\n  }\r\n}\r\n```\r\n\r\nThis seems to happen only in Python 3.\r\n```\r\n$ scrapy version -v\r\nScrapy       : 1.5.0\r\nlxml         : 4.2.6.0\r\nlibxml2      : 2.9.8\r\ncssselect    : 1.0.3\r\nparsel       : 1.5.1\r\nw3lib        : 1.19.0\r\nTwisted      : 18.9.0\r\nPython       : 3.6.0 (default, Sep  1 2017, 10:59:37) - [GCC 4.8.4]\r\npyOpenSSL    : 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018)\r\ncryptography : 2.4.2\r\nPlatform     : Linux-4.4.0-134-generic-x86_64-with-debian-jessie-sid\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3575/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3575/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3413", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3413/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3413/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3413/events", "html_url": "https://github.com/scrapy/scrapy/issues/3413", "id": 356594333, "node_id": "MDU6SXNzdWUzNTY1OTQzMzM=", "number": 3413, "title": "Resuming crawls gives the error: self.size, = struct.unpack(self.SIZE_FORMAT, qsize)", "user": {"login": "foomoto", "id": 5051087, "node_id": "MDQ6VXNlcjUwNTEwODc=", "avatar_url": "https://avatars.githubusercontent.com/u/5051087?v=4", "gravatar_id": "", "url": "https://api.github.com/users/foomoto", "html_url": "https://github.com/foomoto", "followers_url": "https://api.github.com/users/foomoto/followers", "following_url": "https://api.github.com/users/foomoto/following{/other_user}", "gists_url": "https://api.github.com/users/foomoto/gists{/gist_id}", "starred_url": "https://api.github.com/users/foomoto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/foomoto/subscriptions", "organizations_url": "https://api.github.com/users/foomoto/orgs", "repos_url": "https://api.github.com/users/foomoto/repos", "events_url": "https://api.github.com/users/foomoto/events{/privacy}", "received_events_url": "https://api.github.com/users/foomoto/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2018-09-03T20:26:54Z", "updated_at": "2023-01-03T09:41:46Z", "closed_at": "2019-08-19T15:17:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am running out of memory after crawling 60k pages on an 8GB server, so I am attempting the JOBSDIR settings to reduce memory consumption. If I stop scrapy and attempt to resume I get the below error: Please help.\r\n\r\n2018-09-03 21:24:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.therosefactory.com/bloom-box> (referer: None)\r\nTraceback (most recent call last):\r\n  File \"/Users/mrfobilli/IdeaProjects/octopus-gatherer/venv1/lib/python3.6/site-packages/scrapy/utils/defer.py\", line 102, in iter_errback\r\n    yield next(it)\r\nGeneratorExit\r\nException ignored in: <generator object iter_errback at 0x109230a98>\r\nRuntimeError: generator ignored GeneratorExit\r\nException ignored in: <generator object GlobalSpider.parse_new at 0x108aff1a8>\r\nRuntimeError: generator ignored GeneratorExit\r\nUnhandled error in Deferred:\r\n2018-09-03 21:24:06 [twisted] CRITICAL: Unhandled error in Deferred:\r\n\r\n2018-09-03 21:24:06 [twisted] CRITICAL: \r\nTraceback (most recent call last):\r\n  File \"/Users/mrfobilli/IdeaProjects/octopus-gatherer/venv1/lib/python3.6/site-packages/twisted/internet/task.py\", line 517, in _oneWorkUnit\r\n    result = next(self._iterator)\r\n  File \"/Users/mrfobilli/IdeaProjects/octopus-gatherer/venv1/lib/python3.6/site-packages/scrapy/utils/defer.py\", line 63, in <genexpr>\r\n    work = (callable(elem, *args, **named) for elem in iterable)\r\n  File \"/Users/mrfobilli/IdeaProjects/octopus-gatherer/venv1/lib/python3.6/site-packages/scrapy/core/scraper.py\", line 183, in _process_spidermw_output\r\n    self.crawler.engine.crawl(request=output, spider=spider)\r\n  File \"/Users/mrfobilli/IdeaProjects/octopus-gatherer/venv1/lib/python3.6/site-packages/scrapy/core/engine.py\", line 210, in crawl\r\n    self.schedule(request, spider)\r\n  File \"/Users/mrfobilli/IdeaProjects/octopus-gatherer/venv1/lib/python3.6/site-packages/scrapy/core/engine.py\", line 216, in schedule\r\n    if not self.slot.scheduler.enqueue_request(request):\r\n  File \"/Users/mrfobilli/IdeaProjects/octopus-gatherer/venv1/lib/python3.6/site-packages/scrapy/core/scheduler.py\", line 57, in enqueue_request\r\n    dqok = self._dqpush(request)\r\n  File \"/Users/mrfobilli/IdeaProjects/octopus-gatherer/venv1/lib/python3.6/site-packages/scrapy/core/scheduler.py\", line 86, in _dqpush\r\n    self.dqs.push(reqd, -request.priority)\r\n  File \"/Users/mrfobilli/IdeaProjects/octopus-gatherer/venv1/lib/python3.6/site-packages/queuelib/pqueue.py\", line 33, in push\r\n    self.queues[priority] = self.qfactory(priority)\r\n  File \"/Users/mrfobilli/IdeaProjects/octopus-gatherer/venv1/lib/python3.6/site-packages/scrapy/core/scheduler.py\", line 114, in _newdq\r\n    return self.dqclass(join(self.dqdir, 'p%s' % priority))\r\n  File \"/Users/mrfobilli/IdeaProjects/octopus-gatherer/venv1/lib/python3.6/site-packages/queuelib/queue.py\", line 142, in __init__\r\n    self.size, = struct.unpack(self.SIZE_FORMAT, qsize)\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3413/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3413/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3398", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3398/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3398/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3398/events", "html_url": "https://github.com/scrapy/scrapy/issues/3398", "id": 352758714, "node_id": "MDU6SXNzdWUzNTI3NTg3MTQ=", "number": 3398, "title": "AttributeError: 'XmlItemExporter' object has no attribute 'file'", "user": {"login": "vidarlee", "id": 16576010, "node_id": "MDQ6VXNlcjE2NTc2MDEw", "avatar_url": "https://avatars.githubusercontent.com/u/16576010?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vidarlee", "html_url": "https://github.com/vidarlee", "followers_url": "https://api.github.com/users/vidarlee/followers", "following_url": "https://api.github.com/users/vidarlee/following{/other_user}", "gists_url": "https://api.github.com/users/vidarlee/gists{/gist_id}", "starred_url": "https://api.github.com/users/vidarlee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vidarlee/subscriptions", "organizations_url": "https://api.github.com/users/vidarlee/orgs", "repos_url": "https://api.github.com/users/vidarlee/repos", "events_url": "https://api.github.com/users/vidarlee/events{/privacy}", "received_events_url": "https://api.github.com/users/vidarlee/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-08-22T00:36:22Z", "updated_at": "2019-09-19T07:17:24Z", "closed_at": "2019-09-19T07:17:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "The example in the document [Item Exporters](https://doc.scrapy.org/en/latest/topics/exporters.html)\r\ncalled the file attribute of  XmlItemExporter instance as follow:\r\n```\r\n    def close_spider(self, spider):\r\n        for exporter in self.year_to_exporter.values():\r\n            exporter.finish_exporting()\r\n            exporter.file.close()\r\n```\r\nI checked the source of scrapy/scrapy/exporters.py,\r\nactually, there is no attribute named 'file' in XmlItemExporter.\r\nSo, when i run the script the error occurred:\r\n\"AttributeError: 'XmlItemExporter' object has no attribute 'file'\".\r\n\r\nAlso, there is no 'file' attribute in CsvItemExporter  while exists in JsonItemExporter,\r\nPickleItemExporter,  MarshalItemExporter , PprintItemExporter.\r\n\r\nI think it is necessary to and a file descriptor attribute into XmlItemExporter and CsvItemExporter for consistency. Also the file descriptor should be closed when exporting has been finished.\r\n\r\nIf the file descriptor attribute will add to XmlItemExporter and CsvItemExporter, then i have another question:\r\nIs it a good idea to add the self.file.close() into the function finish_exporting()?\r\nIt seems it is simple for user just call  function finish_exporting() and won't care about the file descriptor whether closed.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3398/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3398/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3331", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3331/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3331/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3331/events", "html_url": "https://github.com/scrapy/scrapy/issues/3331", "id": 340137058, "node_id": "MDU6SXNzdWUzNDAxMzcwNTg=", "number": 3331, "title": "Documentation example fails with `proxy URL with no authority`", "user": {"login": "a-palchikov", "id": 965809, "node_id": "MDQ6VXNlcjk2NTgwOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/965809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/a-palchikov", "html_url": "https://github.com/a-palchikov", "followers_url": "https://api.github.com/users/a-palchikov/followers", "following_url": "https://api.github.com/users/a-palchikov/following{/other_user}", "gists_url": "https://api.github.com/users/a-palchikov/gists{/gist_id}", "starred_url": "https://api.github.com/users/a-palchikov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/a-palchikov/subscriptions", "organizations_url": "https://api.github.com/users/a-palchikov/orgs", "repos_url": "https://api.github.com/users/a-palchikov/repos", "events_url": "https://api.github.com/users/a-palchikov/events{/privacy}", "received_events_url": "https://api.github.com/users/a-palchikov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2018-07-11T08:15:32Z", "updated_at": "2020-10-01T18:57:01Z", "closed_at": "2020-10-01T18:57:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "Running the [example](https://doc.scrapy.org/en/1.5/intro/overview.html#walk-through-of-an-example-spider) from the documentation yields this:\r\n```\r\n10:11 $ scrapy runspider quotes.py \r\n2018-07-11 10:12:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)\r\n2018-07-11 10:12:04 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 0.9.1, parsel 1.5.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-130-generic-x86_64-with-Ubuntu-16.04-xenial\r\n2018-07-11 10:12:04 [scrapy.crawler] INFO: Overridden settings: {'SPIDER_LOADER_WARN_ONLY': True}\r\n2018-07-11 10:12:04 [scrapy.middleware] INFO: Enabled extensions:\r\n['scrapy.extensions.memusage.MemoryUsage',\r\n 'scrapy.extensions.logstats.LogStats',\r\n 'scrapy.extensions.telnet.TelnetConsole',\r\n 'scrapy.extensions.corestats.CoreStats']\r\nUnhandled error in Deferred:\r\n2018-07-11 10:12:04 [twisted] CRITICAL: Unhandled error in Deferred:\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/commands/runspider.py\", line 88, in run\r\n    self.crawler_process.crawl(spidercls, **opts.spargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py\", line 171, in crawl\r\n    return self._crawl(crawler, *args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py\", line 175, in _crawl\r\n    d = crawler.crawl(*args, **kwargs)\r\n  File \"/usr/lib/python2.7/dist-packages/twisted/internet/defer.py\", line 1274, in unwindGenerator\r\n    return _inlineCallbacks(None, gen, Deferred())\r\n--- <exception caught here> ---\r\n  File \"/usr/lib/python2.7/dist-packages/twisted/internet/defer.py\", line 1128, in _inlineCallbacks\r\n    result = g.send(result)\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py\", line 98, in crawl\r\n    six.reraise(*exc_info)\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py\", line 80, in crawl\r\n    self.engine = self._create_engine()\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py\", line 105, in _create_engine\r\n    return ExecutionEngine(self, lambda _: self.stop())\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/core/engine.py\", line 69, in __init__\r\n    self.downloader = downloader_cls(crawler)\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/__init__.py\", line 88, in __init__\r\n    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/middleware.py\", line 58, in from_crawler\r\n    return cls.from_settings(crawler.settings, crawler)\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/middleware.py\", line 36, in from_settings\r\n    mw = mwcls.from_crawler(crawler)\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/downloadermiddlewares/httpproxy.py\", line 29, in from_crawler\r\n    return cls(auth_encoding)\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/downloadermiddlewares/httpproxy.py\", line 22, in __init__\r\n    self.proxies[type] = self._get_proxy(url, type)\r\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/downloadermiddlewares/httpproxy.py\", line 39, in _get_proxy\r\n    proxy_type, user, password, hostport = _parse_proxy(url)\r\n  File \"/usr/lib/python2.7/urllib2.py\", line 721, in _parse_proxy\r\n    raise ValueError(\"proxy URL with no authority: %r\" % proxy)\r\nexceptions.ValueError: proxy URL with no authority: '/var/run/docker.sock'\r\n2018-07-11 10:12:04 [twisted] CRITICAL:\r\n```\r\nLooks like proxy code does not handle `no_proxy` correctly.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3331/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3331/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3297", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3297/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3297/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3297/events", "html_url": "https://github.com/scrapy/scrapy/issues/3297", "id": 333006718, "node_id": "MDU6SXNzdWUzMzMwMDY3MTg=", "number": 3297, "title": "Crawled (200) then returns Error downloading the page that was just crawled?", "user": {"login": "daffychuy", "id": 16250872, "node_id": "MDQ6VXNlcjE2MjUwODcy", "avatar_url": "https://avatars.githubusercontent.com/u/16250872?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daffychuy", "html_url": "https://github.com/daffychuy", "followers_url": "https://api.github.com/users/daffychuy/followers", "following_url": "https://api.github.com/users/daffychuy/following{/other_user}", "gists_url": "https://api.github.com/users/daffychuy/gists{/gist_id}", "starred_url": "https://api.github.com/users/daffychuy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daffychuy/subscriptions", "organizations_url": "https://api.github.com/users/daffychuy/orgs", "repos_url": "https://api.github.com/users/daffychuy/repos", "events_url": "https://api.github.com/users/daffychuy/events{/privacy}", "received_events_url": "https://api.github.com/users/daffychuy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-06-16T18:41:51Z", "updated_at": "2021-10-22T02:49:31Z", "closed_at": "2021-10-22T02:49:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "While I was writing a script to get links from the page when I run it, it seemed fine at first.\r\nIt crawled the page given with response (200) so that means page worked, but after 1 second, it returns Error downloading the page and keyError gives a `<GET URL>`.\r\n\r\nPage that scrapy said gave an error: https://www.masterani.me/api/anime/search?search=M%C3%A4rchen%20M%C3%A4dchen%20Specials\r\nbut actually has an json return and keyError doesn't make sense to me\r\n\r\nHere's the log:\r\nhttps://gist.github.com/daffychuy/aa0a6420d36cde138dbfcae64fd85cc9\r\n\r\nIt then keeps repeating the same error and gives the same for the next couple of pages as well. \r\n\r\nEDIT: I've moved the log to a gist page", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3297/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3297/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3264", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3264/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3264/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3264/events", "html_url": "https://github.com/scrapy/scrapy/issues/3264", "id": 324325824, "node_id": "MDU6SXNzdWUzMjQzMjU4MjQ=", "number": 3264, "title": "Command parse unhandled error :AttributeError: 'NoneType' object has no attribute 'start_requests'", "user": {"login": "wangrenlei", "id": 15920505, "node_id": "MDQ6VXNlcjE1OTIwNTA1", "avatar_url": "https://avatars.githubusercontent.com/u/15920505?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wangrenlei", "html_url": "https://github.com/wangrenlei", "followers_url": "https://api.github.com/users/wangrenlei/followers", "following_url": "https://api.github.com/users/wangrenlei/following{/other_user}", "gists_url": "https://api.github.com/users/wangrenlei/gists{/gist_id}", "starred_url": "https://api.github.com/users/wangrenlei/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wangrenlei/subscriptions", "organizations_url": "https://api.github.com/users/wangrenlei/orgs", "repos_url": "https://api.github.com/users/wangrenlei/repos", "events_url": "https://api.github.com/users/wangrenlei/events{/privacy}", "received_events_url": "https://api.github.com/users/wangrenlei/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-05-18T08:57:28Z", "updated_at": "2022-05-28T08:26:23Z", "closed_at": "2022-05-28T08:26:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "Scrapy version :1.5.0\r\nWhen i run the command **scrapy parse http://www.baidu.com**, and the url www.baidu.com dosn't  have spider matched , then i got the error:\r\n\r\n> 2018-03-11 16:23:35 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: DouTu)\r\n> 2018-03-11 16:23:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Linux-4.13.0-38-generic-x86_64-with-Ubuntu-16.04-xenial\r\n> 2018-05-18 16:23:35 [scrapy.commands.parse] ERROR: Unable to find spider for: http://www.baidu.com\r\n> Traceback (most recent call last):\r\n>   File \"/home/wangsir/code/sourceWorkSpace/scrapy/cmdline.py\", line 239, in <module>\r\n>     execute(['scrapy','parse','http://www.baidu.com'])\r\n>   File \"/home/wangsir/code/sourceWorkSpace/scrapy/cmdline.py\", line 168, in execute\r\n>     _run_print_help(parser, _run_command, cmd, args, opts)\r\n>   File \"/home/wangsir/code/sourceWorkSpace/scrapy/cmdline.py\", line 98, in _run_print_help\r\n>     func(*a, **kw)\r\n>   File \"/home/wangsir/code/sourceWorkSpace/scrapy/cmdline.py\", line 176, in _run_command\r\n>     cmd.run(args, opts)\r\n>   File \"/home/wangsir/code/sourceWorkSpace/scrapy/commands/parse.py\", line 250, in run\r\n>     self.set_spidercls(url, opts)\r\n>   File \"/home/wangsir/code/sourceWorkSpace/scrapy/commands/parse.py\", line 151, in set_spidercls\r\n>     self.spidercls.start_requests = _start_requests\r\n> AttributeError: 'NoneType' object has no attribute 'start_requests'.\r\n\r\nThe failed reason should be follwing code(scrapy/commands/parse.py line 151):\r\n         **`self.spidercls.start_requests = _start_requests`**\r\nbecause the url www.baidu.com dosn't  have spider matched,so self.spidercls is none,so self.spidercls.start_requests throw the error.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3264/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3246", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3246/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3246/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3246/events", "html_url": "https://github.com/scrapy/scrapy/issues/3246", "id": 320222542, "node_id": "MDU6SXNzdWUzMjAyMjI1NDI=", "number": 3246, "title": "OffsiteMiddleware silently filtering (invalid) URLs", "user": {"login": "jesuslosada", "id": 5754422, "node_id": "MDQ6VXNlcjU3NTQ0MjI=", "avatar_url": "https://avatars.githubusercontent.com/u/5754422?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jesuslosada", "html_url": "https://github.com/jesuslosada", "followers_url": "https://api.github.com/users/jesuslosada/followers", "following_url": "https://api.github.com/users/jesuslosada/following{/other_user}", "gists_url": "https://api.github.com/users/jesuslosada/gists{/gist_id}", "starred_url": "https://api.github.com/users/jesuslosada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jesuslosada/subscriptions", "organizations_url": "https://api.github.com/users/jesuslosada/orgs", "repos_url": "https://api.github.com/users/jesuslosada/repos", "events_url": "https://api.github.com/users/jesuslosada/events{/privacy}", "received_events_url": "https://api.github.com/users/jesuslosada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-05-04T10:18:55Z", "updated_at": "2023-03-08T20:03:21Z", "closed_at": "2023-03-08T20:03:21Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "We've recently run into a weird situation where the requests were created reading the URL values from a sitemap and as a result they contained leading and trailing newline characters (`\\nhttp://example.com\\n`).\r\n\r\nConsider this base example:\r\n```\r\nclass ToscrapeSpider(scrapy.Spider):\r\n    name = 'toscrape'\r\n    allowed_domains = ['toscrape.com']\r\n    start_urls = ['http://books.toscrape.com/']\r\n\r\n    def parse(self, response):\r\n        yield scrapy.Request(\r\n            'http://quotes.toscrape.com/',\r\n            callback=self.parse2,\r\n        )\r\n\r\n    def parse2(self, response):\r\n        pass\r\n```\r\nwhich sends 2 requests as expected:\r\n```\r\n2018-05-04 09:17:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://books.toscrape.com/> (referer: None)\r\n2018-05-04 09:17:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/> (referer: http://books.toscrape.com/)\r\n2018-05-04 09:17:49 [scrapy.core.engine] INFO: Closing spider (finished)\r\n``` \r\n\r\nAnd now check what happens when you replace `http://quotes.toscrape.com/` with `\\nhttp://quotes.toscrape.com/`:\r\n``` \r\nclass ToscrapeSpider(scrapy.Spider):\r\n    name = 'toscrape'\r\n    allowed_domains = ['toscrape.com']\r\n    start_urls = ['http://books.toscrape.com/']\r\n\r\n    def parse(self, response):\r\n        yield scrapy.Request(\r\n            '\\nhttp://quotes.toscrape.com/',\r\n            callback=self.parse2,\r\n        )\r\n\r\n    def parse2(self, response):\r\n        pass\r\n``` \r\nResults:\r\n``` \r\n2018-05-04 09:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://books.toscrape.com/> (referer: None)\r\n2018-05-04 09:19:49 [scrapy.core.engine] INFO: Closing spider (finished)\r\n``` \r\nSo Scrapy (the OffsiteMiddleware to be more specific) is silently filtering the second request and the only way to know this is by checking the stats: `'offsite/filtered': 1`. In this situation I would expect Scrapy to show some kind of warning (or even an error) when creating the Request or when processing the request in the OffsiteMiddleware.\r\n\r\nFor reference: https://github.com/scrapy/scrapy/blob/c4f096d3a55def4c986174d50ff8b84c8f00503d/scrapy/spidermiddlewares/offsite.py#L36\r\n`domain` is None in this case and the OffsiteMiddleware doesn't add any messages to the log. \r\nI think the OffsiteMiddleware should log the filtered requests even if it can't properly parse the domain.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3246/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3246/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3167", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3167/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3167/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3167/events", "html_url": "https://github.com/scrapy/scrapy/issues/3167", "id": 304432134, "node_id": "MDU6SXNzdWUzMDQ0MzIxMzQ=", "number": 3167, "title": "twisted.python.failure", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 320345582, "node_id": "MDU6TGFiZWwzMjAzNDU1ODI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/https", "name": "https", "color": "101e89", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-12T15:56:50Z", "updated_at": "2018-03-15T17:23:14Z", "closed_at": "2018-03-15T17:22:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "Scrapy       : 1.5.0\r\nlxml         : 4.1.1.0\r\nlibxml2      : 2.9.5\r\ncssselect    : 1.0.3\r\nparsel       : 1.4.0\r\nw3lib        : 1.19.0\r\nTwisted      : 17.9.0\r\nPython       : 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)]\r\npyOpenSSL    : 17.6.0.dev0 (OpenSSL 1.1.0g  2 Nov 2017)\r\ncryptography : 2.1.4\r\nPlatform     : Windows-7-6.1.7601-SP1\r\n\r\n\r\n2018-03-12 21:20:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.farmerscompress.com/> (referer: None)\r\n2018-03-12 21:20:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <POST https://www.farmerscompress.com/ProcessUser.aspx> (failed 1 times): [<t\r\nwisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]\r\n2018-03-12 21:20:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <POST https://www.farmerscompress.com/ProcessUser.aspx> (failed 2 times): [<t\r\nwisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]\r\n2018-03-12 21:20:50 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <POST https://www.farmerscompress.com/ProcessUser.aspx> (failed 3 tim\r\nes): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection\r\nlost.>]\r\n2018-03-12 21:20:50 [scrapy.core.scraper] ERROR: Error downloading <POST https://www.farmerscompress.com/ProcessUser.aspx>: [<twisted.python.failure.F\r\nailure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]\r\n2018-03-12 21:20:51 [scrapy.core.engine] INFO: Closing spider (finished)\r\n2018-03-12 21:20:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3167/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3167/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3161", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3161/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3161/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3161/events", "html_url": "https://github.com/scrapy/scrapy/issues/3161", "id": 303748923, "node_id": "MDU6SXNzdWUzMDM3NDg5MjM=", "number": 3161, "title": "Logging can't format stack trace with non-ascii chars on Python 2", "user": {"login": "tlinhart", "id": 12714153, "node_id": "MDQ6VXNlcjEyNzE0MTUz", "avatar_url": "https://avatars.githubusercontent.com/u/12714153?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tlinhart", "html_url": "https://github.com/tlinhart", "followers_url": "https://api.github.com/users/tlinhart/followers", "following_url": "https://api.github.com/users/tlinhart/following{/other_user}", "gists_url": "https://api.github.com/users/tlinhart/gists{/gist_id}", "starred_url": "https://api.github.com/users/tlinhart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tlinhart/subscriptions", "organizations_url": "https://api.github.com/users/tlinhart/orgs", "repos_url": "https://api.github.com/users/tlinhart/repos", "events_url": "https://api.github.com/users/tlinhart/events{/privacy}", "received_events_url": "https://api.github.com/users/tlinhart/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 20, "created_at": "2018-03-09T07:28:02Z", "updated_at": "2020-04-16T13:54:49Z", "closed_at": "2020-04-16T13:54:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI experience the same issue as described in #1602. However, I'm not using Django.\r\n\r\nThe stats look like this:\r\n\r\n```\r\n{'downloader/request_bytes': 47621,\r\n 'downloader/request_count': 103,\r\n 'downloader/request_method_count/GET': 103,\r\n 'downloader/response_bytes': 1162618,\r\n 'downloader/response_count': 103,\r\n 'downloader/response_status_count/200': 101,\r\n 'downloader/response_status_count/302': 2,\r\n 'dupefilter/filtered': 2,\r\n 'finish_reason': 'finished',\r\n 'finish_time': datetime.datetime(2018, 3, 9, 2, 3, 15, 748633),\r\n 'httpcache/firsthand': 72,\r\n 'httpcache/hit': 31,\r\n 'httpcache/miss': 72,\r\n 'httpcache/store': 72,\r\n 'item_scraped_count': 48,\r\n 'log_count/DEBUG': 215,\r\n 'log_count/ERROR': 1,\r\n 'log_count/INFO': 9,\r\n 'memusage/max': 121434112,\r\n 'memusage/startup': 69783552,\r\n 'mongodb/item_stored_count': 48,\r\n 'request_depth_max': 3,\r\n 'response_received_count': 101,\r\n 'scheduler/dequeued': 102,\r\n 'scheduler/dequeued/memory': 102,\r\n 'scheduler/enqueued': 102,\r\n 'scheduler/enqueued/memory': 102,\r\n 'spider_exceptions/AttributeError': 1,\r\n 'start_time': datetime.datetime(2018, 3, 9, 2, 0, 52, 510449)}\r\n```\r\n\r\nBut there's no mention about `AttributeError` (or any other error) in the log.\r\n\r\nI'm executing the spiders on Scrapyd instances running in Docker container. This is the first two lines of the log showing components' versions:\r\n\r\n```\r\n2018-03-09 02:00:52 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: realestate)\r\n2018-03-09 02:00:52 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.3.1, w3lib 1.18.0, Twisted 17.9.0, Python 2.7.12 (default, Nov 20 2017, 18:23:56) - [GCC 5.4.0 20160609], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.4.0-103-generic-x86_64-with-Ubuntu-16.04-xenial\r\n```\r\n\r\nThere's nothing special in the `settings.py`, but I can provide it if needed.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3161/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3161/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3153", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3153/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3153/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3153/events", "html_url": "https://github.com/scrapy/scrapy/pull/3153", "id": 301995367, "node_id": "MDExOlB1bGxSZXF1ZXN0MTcyNjY1Njk2", "number": 3153, "title": "[MRG+1] Fixed bug FormRequest.from_response() clickdata ignores input[type=image]", "user": {"login": "ViralMehtaSWE", "id": 30916185, "node_id": "MDQ6VXNlcjMwOTE2MTg1", "avatar_url": "https://avatars.githubusercontent.com/u/30916185?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ViralMehtaSWE", "html_url": "https://github.com/ViralMehtaSWE", "followers_url": "https://api.github.com/users/ViralMehtaSWE/followers", "following_url": "https://api.github.com/users/ViralMehtaSWE/following{/other_user}", "gists_url": "https://api.github.com/users/ViralMehtaSWE/gists{/gist_id}", "starred_url": "https://api.github.com/users/ViralMehtaSWE/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ViralMehtaSWE/subscriptions", "organizations_url": "https://api.github.com/users/ViralMehtaSWE/orgs", "repos_url": "https://api.github.com/users/ViralMehtaSWE/repos", "events_url": "https://api.github.com/users/ViralMehtaSWE/events{/privacy}", "received_events_url": "https://api.github.com/users/ViralMehtaSWE/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 280218717, "node_id": "MDU6TGFiZWwyODAyMTg3MTc=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/discuss", "name": "discuss", "color": "cc317c", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/20", "html_url": "https://github.com/scrapy/scrapy/milestone/20", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/20/labels", "id": 3005093, "node_id": "MDk6TWlsZXN0b25lMzAwNTA5Mw==", "number": 20, "title": "v1.6", "description": null, "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 73, "state": "closed", "created_at": "2017-12-31T19:45:38Z", "updated_at": "2019-02-06T14:17:12Z", "due_on": null, "closed_at": "2019-02-06T14:17:12Z"}, "comments": 8, "created_at": "2018-03-03T12:42:07Z", "updated_at": "2018-07-04T19:31:59Z", "closed_at": "2018-03-21T19:32:13Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/3153", "html_url": "https://github.com/scrapy/scrapy/pull/3153", "diff_url": "https://github.com/scrapy/scrapy/pull/3153.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/3153.patch", "merged_at": "2018-03-21T19:32:13Z"}, "body": "BugFix for issue #3139 ", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3153/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3153/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3139", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3139/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3139/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3139/events", "html_url": "https://github.com/scrapy/scrapy/issues/3139", "id": 300119876, "node_id": "MDU6SXNzdWUzMDAxMTk4NzY=", "number": 3139, "title": "FormRequest.from_response() clickdata ignores input[type=image]", "user": {"login": "demetranadya", "id": 24708415, "node_id": "MDQ6VXNlcjI0NzA4NDE1", "avatar_url": "https://avatars.githubusercontent.com/u/24708415?v=4", "gravatar_id": "", "url": "https://api.github.com/users/demetranadya", "html_url": "https://github.com/demetranadya", "followers_url": "https://api.github.com/users/demetranadya/followers", "following_url": "https://api.github.com/users/demetranadya/following{/other_user}", "gists_url": "https://api.github.com/users/demetranadya/gists{/gist_id}", "starred_url": "https://api.github.com/users/demetranadya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/demetranadya/subscriptions", "organizations_url": "https://api.github.com/users/demetranadya/orgs", "repos_url": "https://api.github.com/users/demetranadya/repos", "events_url": "https://api.github.com/users/demetranadya/events{/privacy}", "received_events_url": "https://api.github.com/users/demetranadya/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 281088273, "node_id": "MDU6TGFiZWwyODEwODgyNzM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/help%20wanted", "name": "help wanted", "color": "009800", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-02-26T06:05:33Z", "updated_at": "2018-05-04T06:03:48Z", "closed_at": "2018-05-04T06:03:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "No way to click image inputs now, see [here](https://github.com/scrapy/scrapy/blob/73668ce4076b87d2d2493f2c9b445c643da9055a/scrapy/http/request/form.py#L165).", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3139/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3139/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3131", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3131/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3131/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3131/events", "html_url": "https://github.com/scrapy/scrapy/pull/3131", "id": 298799836, "node_id": "MDExOlB1bGxSZXF1ZXN0MTcwMzQ3MDIx", "number": 3131, "title": "[MRG+1] Fix part of issue #3128 - None should not be a valid type for 'url' in Response.follow", "user": {"login": "NewUserHa", "id": 32261870, "node_id": "MDQ6VXNlcjMyMjYxODcw", "avatar_url": "https://avatars.githubusercontent.com/u/32261870?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NewUserHa", "html_url": "https://github.com/NewUserHa", "followers_url": "https://api.github.com/users/NewUserHa/followers", "following_url": "https://api.github.com/users/NewUserHa/following{/other_user}", "gists_url": "https://api.github.com/users/NewUserHa/gists{/gist_id}", "starred_url": "https://api.github.com/users/NewUserHa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NewUserHa/subscriptions", "organizations_url": "https://api.github.com/users/NewUserHa/orgs", "repos_url": "https://api.github.com/users/NewUserHa/repos", "events_url": "https://api.github.com/users/NewUserHa/events{/privacy}", "received_events_url": "https://api.github.com/users/NewUserHa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/20", "html_url": "https://github.com/scrapy/scrapy/milestone/20", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/20/labels", "id": 3005093, "node_id": "MDk6TWlsZXN0b25lMzAwNTA5Mw==", "number": 20, "title": "v1.6", "description": null, "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 73, "state": "closed", "created_at": "2017-12-31T19:45:38Z", "updated_at": "2019-02-06T14:17:12Z", "due_on": null, "closed_at": "2019-02-06T14:17:12Z"}, "comments": 2, "created_at": "2018-02-21T00:26:57Z", "updated_at": "2018-07-04T19:32:09Z", "closed_at": "2018-02-21T22:37:27Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/3131", "html_url": "https://github.com/scrapy/scrapy/pull/3131", "diff_url": "https://github.com/scrapy/scrapy/pull/3131.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/3131.patch", "merged_at": "2018-02-21T22:37:27Z"}, "body": "the issue reason should be: 'urljoin from urllib return baseurl if targeturl is None'\r\n\r\nthe empty url issue haven't been touched because @kmike says: 'this is an intended behavior.'", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3131/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3131/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3128", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3128/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3128/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3128/events", "html_url": "https://github.com/scrapy/scrapy/issues/3128", "id": 297952782, "node_id": "MDU6SXNzdWUyOTc5NTI3ODI=", "number": 3128, "title": "[suggest ] `response.follow` should raise a exception when called on None or an empty string, instead of crawling the current page again", "user": {"login": "NewUserHa", "id": 32261870, "node_id": "MDQ6VXNlcjMyMjYxODcw", "avatar_url": "https://avatars.githubusercontent.com/u/32261870?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NewUserHa", "html_url": "https://github.com/NewUserHa", "followers_url": "https://api.github.com/users/NewUserHa/followers", "following_url": "https://api.github.com/users/NewUserHa/following{/other_user}", "gists_url": "https://api.github.com/users/NewUserHa/gists{/gist_id}", "starred_url": "https://api.github.com/users/NewUserHa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NewUserHa/subscriptions", "organizations_url": "https://api.github.com/users/NewUserHa/orgs", "repos_url": "https://api.github.com/users/NewUserHa/repos", "events_url": "https://api.github.com/users/NewUserHa/events{/privacy}", "received_events_url": "https://api.github.com/users/NewUserHa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}, {"id": 281088273, "node_id": "MDU6TGFiZWwyODEwODgyNzM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/help%20wanted", "name": "help wanted", "color": "009800", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2018-02-16T23:38:44Z", "updated_at": "2018-02-22T12:30:56Z", "closed_at": "2018-02-21T22:38:14Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "`response.follow` will raise a exception when url='' or none in stead of crawl the (base) page itself again.\r\n\r\nnone will use follow to crawl the source(base) page again right? all parsers will be passed without warning if that way.\r\n\r\nthanks\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3128/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3128/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3093", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3093/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3093/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3093/events", "html_url": "https://github.com/scrapy/scrapy/issues/3093", "id": 291822205, "node_id": "MDU6SXNzdWUyOTE4MjIyMDU=", "number": 3093, "title": "Cannot override default Connection header", "user": {"login": "RavenHustler", "id": 33152859, "node_id": "MDQ6VXNlcjMzMTUyODU5", "avatar_url": "https://avatars.githubusercontent.com/u/33152859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RavenHustler", "html_url": "https://github.com/RavenHustler", "followers_url": "https://api.github.com/users/RavenHustler/followers", "following_url": "https://api.github.com/users/RavenHustler/following{/other_user}", "gists_url": "https://api.github.com/users/RavenHustler/gists{/gist_id}", "starred_url": "https://api.github.com/users/RavenHustler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RavenHustler/subscriptions", "organizations_url": "https://api.github.com/users/RavenHustler/orgs", "repos_url": "https://api.github.com/users/RavenHustler/repos", "events_url": "https://api.github.com/users/RavenHustler/events{/privacy}", "received_events_url": "https://api.github.com/users/RavenHustler/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443680419, "node_id": "MDU6TGFiZWw0NDM2ODA0MTk=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/needs%20more%20info", "name": "needs more info", "color": "fef2c0", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-01-26T07:46:47Z", "updated_at": "2019-08-14T09:26:49Z", "closed_at": "2019-08-14T09:26:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "Cannot override the default `Connection: close` header of scrapy requests. I want to scrape a site for which I need to send `Connection: keep-alive` headers and remove the default `Connection: close` header.\r\n\r\nTried using custom settings, custom headers and default headers to change `Connection: close` to `Connection: keep-alive` but it instead merges and sends two `Connection` headers.\r\n\r\nIt works in scrapy shell but not when used in a spider.\r\n\r\nI used Fiddler to check the headers scrapy was sending. Please use Fiddler or any other packet sniffing tool to check the headers as it works fine in scrapy shell.\r\n\r\nBelow is the different things I tried:\r\nUsing custom settings:\r\n```\r\ncustom_settings = {\r\n        'DEFAULT_REQUEST_HEADERS': {\r\n            'Connection': 'keep-alive'\r\n        }\r\n    }\r\n```\r\n\r\nUsing custom headers:\r\n```\r\nheaders = {\"Connection\": \"keep-alive\"}\r\n\r\nfor url in urls:\r\n        yield scrapy.Request(url=url, callback=self.parse, headers=headers)\r\n```\r\n\r\nChanging default header settings:\r\n```\r\nDEFAULT_REQUEST_HEADERS = {\r\n  'Connection': 'keep-alive',\r\n}\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3093/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3093/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3054", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3054/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3054/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3054/events", "html_url": "https://github.com/scrapy/scrapy/issues/3054", "id": 285126524, "node_id": "MDU6SXNzdWUyODUxMjY1MjQ=", "number": 3054, "title": "Request serialization should fail for non-picklable objects", "user": {"login": "elacuesta", "id": 1731933, "node_id": "MDQ6VXNlcjE3MzE5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1731933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elacuesta", "html_url": "https://github.com/elacuesta", "followers_url": "https://api.github.com/users/elacuesta/followers", "following_url": "https://api.github.com/users/elacuesta/following{/other_user}", "gists_url": "https://api.github.com/users/elacuesta/gists{/gist_id}", "starred_url": "https://api.github.com/users/elacuesta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elacuesta/subscriptions", "organizations_url": "https://api.github.com/users/elacuesta/orgs", "repos_url": "https://api.github.com/users/elacuesta/repos", "events_url": "https://api.github.com/users/elacuesta/events{/privacy}", "received_events_url": "https://api.github.com/users/elacuesta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-12-29T17:17:07Z", "updated_at": "2018-02-08T20:39:38Z", "closed_at": "2018-02-08T20:39:38Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The Pickle-based disk queues silently serialize requests that shouldn't be serialized in Python<=3.5. I found this problem when dumping a request with an `ItemLoader` object in its `meta` dict. Python 3.6 fails in [this line](https://github.com/scrapy/scrapy/blob/1.4/scrapy/squeues.py#L27) with `TypeError: can't pickle HtmlElement objects`, because the loader contains a `Selector`, which in turns contains an `HtmlElement` object.\r\n\r\nI tested this using the https://github.com/scrapinghub/scrapinghub-stack-scrapy repository, and found that `pickle.loads(pickle.dumps(selector))` doesn't fail, but generates a broken object.\r\n\r\n#### Python 2.7, Scrapy 1.3.3 (https://github.com/scrapinghub/scrapinghub-stack-scrapy/tree/branch-1.3)\r\n```\r\nroot@04bfc6cf84cd:/# scrapy version -v\r\nScrapy    : 1.3.3\r\nlxml      : 3.7.2.0\r\nlibxml2   : 2.9.3\r\ncssselect : 1.0.1\r\nparsel    : 1.1.0\r\nw3lib     : 1.17.0\r\nTwisted   : 16.6.0\r\nPython    : 2.7.14 (default, Dec 12 2017, 16:55:09) - [GCC 4.9.2]\r\npyOpenSSL : 16.2.0 (OpenSSL 1.0.1t  3 May 2016)\r\nPlatform  : Linux-4.9.44-linuxkit-aufs-x86_64-with-debian-8.10\r\nroot@04bfc6cf84cd:/# scrapy shell \"http://example.org\"\r\n2017-12-29 16:49:27 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: scrapybot)\r\n(...)\r\n>>> from six.moves import cPickle as pickle\r\n>>> s2 = pickle.loads(pickle.dumps(response.selector, protocol=2))\r\n>>> response.selector.css('a')\r\n[<Selector xpath=u'descendant-or-self::a' data=u'<a href=\"http://www.iana.org/domains/exa'>]\r\n>>> s2.css('a')\r\nTraceback (most recent call last):\r\n  File \"<console>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/site-packages/parsel/selector.py\", line 227, in css\r\n    return self.xpath(self._css2xpath(query))\r\n  File \"/usr/local/lib/python2.7/site-packages/parsel/selector.py\", line 203, in xpath\r\n    **kwargs)\r\n  File \"src/lxml/lxml.etree.pyx\", line 1584, in lxml.etree._Element.xpath (src/lxml/lxml.etree.c:59349)\r\n  File \"src/lxml/xpath.pxi\", line 257, in lxml.etree.XPathElementEvaluator.__init__ (src/lxml/lxml.etree.c:170478)\r\n  File \"src/lxml/apihelpers.pxi\", line 19, in lxml.etree._assertValidNode (src/lxml/lxml.etree.c:16482)\r\nAssertionError: invalid Element proxy at 140144569743064\r\n```\r\n\r\n\r\n#### Python 3.5, Scrapy 1.3.3 (https://github.com/scrapinghub/scrapinghub-stack-scrapy/tree/branch-1.3-py3)\r\n```\r\nroot@1945e2154919:/# scrapy version -v\r\nScrapy    : 1.3.3\r\nlxml      : 3.7.2.0\r\nlibxml2   : 2.9.3\r\ncssselect : 1.0.1\r\nparsel    : 1.1.0\r\nw3lib     : 1.17.0\r\nTwisted   : 16.6.0\r\nPython    : 3.5.4 (default, Dec 12 2017, 16:43:39) - [GCC 4.9.2]\r\npyOpenSSL : 16.2.0 (OpenSSL 1.0.1t  3 May 2016)\r\nPlatform  : Linux-4.9.44-linuxkit-aufs-x86_64-with-debian-8.10\r\nroot@1945e2154919:/# scrapy shell \"http://example.org\"\r\n2017-12-29 16:52:37 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: scrapybot)\r\n(...)\r\n>>> from six.moves import cPickle as pickle\r\n>>> s2 = pickle.loads(pickle.dumps(response.selector, protocol=2))\r\n>>> response.selector.css('a')\r\n[<Selector xpath='descendant-or-self::a' data='<a href=\"http://www.iana.org/domains/exa'>]\r\n>>> s2.css('a')\r\nTraceback (most recent call last):\r\n  File \"<console>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.5/site-packages/parsel/selector.py\", line 227, in css\r\n    return self.xpath(self._css2xpath(query))\r\n  File \"/usr/local/lib/python3.5/site-packages/parsel/selector.py\", line 203, in xpath\r\n    **kwargs)\r\n  File \"src/lxml/lxml.etree.pyx\", line 1584, in lxml.etree._Element.xpath (src/lxml/lxml.etree.c:59349)\r\n  File \"src/lxml/xpath.pxi\", line 257, in lxml.etree.XPathElementEvaluator.__init__ (src/lxml/lxml.etree.c:170478)\r\n  File \"src/lxml/apihelpers.pxi\", line 19, in lxml.etree._assertValidNode (src/lxml/lxml.etree.c:16482)\r\nAssertionError: invalid Element proxy at 139862544625976\r\n```\r\n\r\n\r\n#### Python 3.6, Scrapy 1.3.3 (https://github.com/scrapinghub/scrapinghub-stack-scrapy/tree/branch-1.3-py3)\r\n```\r\nroot@43e690443ca7:/# scrapy version -v\r\nScrapy    : 1.3.3\r\nlxml      : 3.7.2.0\r\nlibxml2   : 2.9.3\r\ncssselect : 1.0.1\r\nparsel    : 1.1.0\r\nw3lib     : 1.17.0\r\nTwisted   : 16.6.0\r\nPython    : 3.6.4 (default, Dec 21 2017, 01:35:12) - [GCC 4.9.2]\r\npyOpenSSL : 16.2.0 (OpenSSL 1.0.1t  3 May 2016)\r\nPlatform  : Linux-4.9.44-linuxkit-aufs-x86_64-with-debian-8.10\r\nroot@43e690443ca7:/# scrapy shell \"http://example.org\"\r\n2017-12-29 16:54:49 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: scrapybot)\r\n(...)\r\n>>> from six.moves import cPickle as pickle\r\n>>> s2 = pickle.loads(pickle.dumps(response.selector, protocol=2))\r\nTraceback (most recent call last):\r\n  File \"<console>\", line 1, in <module>\r\nTypeError: can't pickle HtmlElement objects\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3054/reactions", "total_count": 3, "+1": 3, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3054/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3046", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3046/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3046/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3046/events", "html_url": "https://github.com/scrapy/scrapy/issues/3046", "id": 283746014, "node_id": "MDU6SXNzdWUyODM3NDYwMTQ=", "number": 3046, "title": "Item loader missing values from base item", "user": {"login": "stummjr", "id": 1170435, "node_id": "MDQ6VXNlcjExNzA0MzU=", "avatar_url": "https://avatars.githubusercontent.com/u/1170435?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stummjr", "html_url": "https://github.com/stummjr", "followers_url": "https://api.github.com/users/stummjr/followers", "following_url": "https://api.github.com/users/stummjr/following{/other_user}", "gists_url": "https://api.github.com/users/stummjr/gists{/gist_id}", "starred_url": "https://api.github.com/users/stummjr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stummjr/subscriptions", "organizations_url": "https://api.github.com/users/stummjr/orgs", "repos_url": "https://api.github.com/users/stummjr/repos", "events_url": "https://api.github.com/users/stummjr/events{/privacy}", "received_events_url": "https://api.github.com/users/stummjr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-12-21T01:30:23Z", "updated_at": "2019-08-01T09:41:25Z", "closed_at": "2019-08-01T09:41:24Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "ItemLoaders behave oddly when they get a pre-populated item as an argument and `get_output_value()` gets called for one of the pre-populated fields before calling `load_item()`.\r\n\r\nCheck this out:\r\n\r\n```python\r\n>>> from scrapy.loader import ItemLoader\r\n>>> item = {'url': 'http://example.com', 'summary': 'foo bar'}\r\n>>> loader = ItemLoader(item)\r\n>>> loader.load_item()\r\n{'summary': 'foo bar', 'url': 'http://example.com'}\r\n\r\n# so far, so good... what about now?\r\n>>> item = {'url': 'http://example.com', 'summary': 'foo bar'}\r\n>>> loader = ItemLoader(item)\r\n>>> loader.get_output_value('url')\r\n[]\r\n>>> loader.load_item()\r\n{'summary': 'foo bar', 'url': []}\r\n```\r\n\r\nThere are **2** unexpected behaviors in this snippet (at least from my point of view):\r\n\r\n**1)** `loader.get_output_value()` doesn't return the pre-populated values, even though they end up in the final item.\r\n\r\nIt seems to be like this on purpose, though. The `get_output_value()` method only queries the `_local_values` defaultdict ([here](https://github.com/scrapy/scrapy/blob/master/scrapy/loader/__init__.py#L125)).\r\n\r\n\r\n**2)** once we call `loader.get_output_value('url')`, that field is not included in the `load_item()` result anymore.\r\n\r\nThis one doesn't look right, IMHO.\r\n\r\nIt happens because when we call `loader.get_output_value('url')` for the first time, such value is not available on `_local_values`, and so a new entry in the `_local_values` defaultdict will be created with an empty list on it ([here](https://github.com/scrapy/scrapy/blob/master/scrapy/loader/__init__.py#L121)). Then, when `loader.load_item()` gets called, [these lines](https://github.com/scrapy/scrapy/blob/master/scrapy/loader/__init__.py#L116-L117) overwrite the current value from the internal item because the value returned by `get_output_value()` is `[]` and not `None`.\r\n\r\nAny thoughts on this?", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3046/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3046/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3039", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3039/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3039/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3039/events", "html_url": "https://github.com/scrapy/scrapy/pull/3039", "id": 281512115, "node_id": "MDExOlB1bGxSZXF1ZXN0MTU3OTIwMjc1", "number": 3039, "title": "[MRG+1] Fix for #3034, CSV export unnecessary blank lines problem on Windows", "user": {"login": "ReLLL", "id": 16361200, "node_id": "MDQ6VXNlcjE2MzYxMjAw", "avatar_url": "https://avatars.githubusercontent.com/u/16361200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ReLLL", "html_url": "https://github.com/ReLLL", "followers_url": "https://api.github.com/users/ReLLL/followers", "following_url": "https://api.github.com/users/ReLLL/following{/other_user}", "gists_url": "https://api.github.com/users/ReLLL/gists{/gist_id}", "starred_url": "https://api.github.com/users/ReLLL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ReLLL/subscriptions", "organizations_url": "https://api.github.com/users/ReLLL/orgs", "repos_url": "https://api.github.com/users/ReLLL/repos", "events_url": "https://api.github.com/users/ReLLL/events{/privacy}", "received_events_url": "https://api.github.com/users/ReLLL/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 318523681, "node_id": "MDU6TGFiZWwzMTg1MjM2ODE=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/Windows", "name": "Windows", "color": "fad8c7", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/20", "html_url": "https://github.com/scrapy/scrapy/milestone/20", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/20/labels", "id": 3005093, "node_id": "MDk6TWlsZXN0b25lMzAwNTA5Mw==", "number": 20, "title": "v1.6", "description": null, "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 73, "state": "closed", "created_at": "2017-12-31T19:45:38Z", "updated_at": "2019-02-06T14:17:12Z", "due_on": null, "closed_at": "2019-02-06T14:17:12Z"}, "comments": 8, "created_at": "2017-12-12T19:40:12Z", "updated_at": "2018-07-27T13:37:23Z", "closed_at": "2018-07-03T21:22:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/3039", "html_url": "https://github.com/scrapy/scrapy/pull/3039", "diff_url": "https://github.com/scrapy/scrapy/pull/3039.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/3039.patch", "merged_at": "2018-07-03T21:22:25Z"}, "body": "Fixed the issue I've mentioned there, this is the pull request to merge, (added one line), hope all is fine. \r\nhttps://github.com/scrapy/scrapy/issues/3034\r\n\r\nCloses #3034 ", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3039/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3039/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3029", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/3029/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/3029/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/3029/events", "html_url": "https://github.com/scrapy/scrapy/issues/3029", "id": 278789294, "node_id": "MDU6SXNzdWUyNzg3ODkyOTQ=", "number": 3029, "title": "Invalid DNS pattern", "user": {"login": "cp2587", "id": 5306537, "node_id": "MDQ6VXNlcjUzMDY1Mzc=", "avatar_url": "https://avatars.githubusercontent.com/u/5306537?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cp2587", "html_url": "https://github.com/cp2587", "followers_url": "https://api.github.com/users/cp2587/followers", "following_url": "https://api.github.com/users/cp2587/following{/other_user}", "gists_url": "https://api.github.com/users/cp2587/gists{/gist_id}", "starred_url": "https://api.github.com/users/cp2587/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cp2587/subscriptions", "organizations_url": "https://api.github.com/users/cp2587/orgs", "repos_url": "https://api.github.com/users/cp2587/repos", "events_url": "https://api.github.com/users/cp2587/events{/privacy}", "received_events_url": "https://api.github.com/users/cp2587/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 320345582, "node_id": "MDU6TGFiZWwzMjAzNDU1ODI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/https", "name": "https", "color": "101e89", "default": false, "description": ""}, {"id": 839225636, "node_id": "MDU6TGFiZWw4MzkyMjU2MzY=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/upstream%20issue", "name": "upstream issue", "color": "c2e0c6", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2017-12-03T15:33:18Z", "updated_at": "2018-09-26T15:29:46Z", "closed_at": "2018-03-14T14:47:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nWe are using https proxies to crawl some website and sometimes i get the following stack trace:\r\n\r\n```\r\nError during info_callback\r\nTraceback (most recent call last):\r\n  File \"/home/wirebot/.virtualenvs/cayzn_tracking.scraping/local/lib/python2.7/site-packages/twisted/protocols/tls.py\", line 315, in dataReceived\r\n    self._checkHandshakeStatus()\r\n  File \"/home/wirebot/.virtualenvs/cayzn_tracking.scraping/local/lib/python2.7/site-packages/twisted/protocols/tls.py\", line 235, in _checkHandshakeStatus\r\n    self._tlsConnection.do_handshake()\r\n  File \"/home/wirebot/.virtualenvs/cayzn_tracking.scraping/local/lib/python2.7/site-packages/OpenSSL/SSL.py\", line 1442, in do_handshake\r\n    result = _lib.SSL_do_handshake(self._ssl)\r\n  File \"/home/wirebot/.virtualenvs/cayzn_tracking.scraping/local/lib/python2.7/site-packages/OpenSSL/SSL.py\", line 933, in wrapper\r\n    callback(Connection._reverse_mapping[ssl], where, return_code)\r\n--- <exception caught here> ---\r\n  File \"/home/wirebot/.virtualenvs/cayzn_tracking.scraping/local/lib/python2.7/site-packages/twisted/internet/_sslverify.py\", line 1102, in infoCallback\r\n    return wrapped(connection, where, ret)\r\n  File \"/home/wirebot/.virtualenvs/cayzn_tracking.scraping/local/lib/python2.7/site-packages/scrapy/core/downloader/tls.py\", line 67, in _identityVerifyingInfoCallback\r\n    verifyHostname(connection, self._hostnameASCII)\r\n  File \"/home/wirebot/.virtualenvs/cayzn_tracking.scraping/local/lib/python2.7/site-packages/service_identity/pyopenssl.py\", line 44, in verify_hostname\r\n    cert_patterns=extract_ids(connection.get_peer_certificate()),\r\n  File \"/home/wirebot/.virtualenvs/cayzn_tracking.scraping/local/lib/python2.7/site-packages/service_identity/pyopenssl.py\", line 73, in extract_ids\r\n    ids.append(DNSPattern(n.getComponent().asOctets()))\r\n  File \"/home/wirebot/.virtualenvs/cayzn_tracking.scraping/local/lib/python2.7/site-packages/service_identity/_common.py\", line 156, in __init__\r\n    \"Invalid DNS pattern {0!r}.\".format(pattern)\r\nservice_identity.exceptions.CertificateError: Invalid DNS pattern '194.167.13.105'.\r\n```\r\n\r\nI think this issue is somewhat similar to https://github.com/scrapy/scrapy/issues/2092 and this 'invalid DNS pattern' error should be caught similarly as the 'Invalid DNS-ID'. What do you think ?\r\n\r\nIn the meantime, how can i catch it myself and silent it ?\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/3029/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/3029/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2998", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2998/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2998/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2998/events", "html_url": "https://github.com/scrapy/scrapy/issues/2998", "id": 272527556, "node_id": "MDU6SXNzdWUyNzI1Mjc1NTY=", "number": 2998, "title": "dont_merge_cookies docs are incomplete", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-09T11:17:08Z", "updated_at": "2019-09-20T13:51:38Z", "closed_at": "2019-09-20T13:51:38Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "dont_merge_cookies [docs](https://doc.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request) are incomplete: they say that \r\n\r\n> When some site returns cookies (in a response) those are stored in the cookies for that domain and will be sent again in future requests. That\u2019s the typical behaviour of any regular web browser. However, if, for some reason, you want to avoid merging with existing cookies you can instruct Scrapy to do so by setting the dont_merge_cookies key to True in the Request.meta.\r\n\r\nBut this flag not only prevents merging of cookies, but also prevents sending of them: https://github.com/scrapy/scrapy/blob/b8870ee8a10360aaa74298324d97c823b88ec5c6/scrapy/downloadermiddlewares/cookies.py#L27\r\n\r\nMaybe a separate issue, but it'd be nice to have separate flags for sending and merging of cookies.\r\n\r\n//cc @whalebot-helmsman", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2998/reactions", "total_count": 4, "+1": 3, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 1}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2998/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2919", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2919/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2919/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2919/events", "html_url": "https://github.com/scrapy/scrapy/issues/2919", "id": 256507838, "node_id": "MDU6SXNzdWUyNTY1MDc4Mzg=", "number": 2919, "title": "FormRequest.formdata with GET method duplicates same key in query string", "user": {"login": "talhashraf", "id": 3428366, "node_id": "MDQ6VXNlcjM0MjgzNjY=", "avatar_url": "https://avatars.githubusercontent.com/u/3428366?v=4", "gravatar_id": "", "url": "https://api.github.com/users/talhashraf", "html_url": "https://github.com/talhashraf", "followers_url": "https://api.github.com/users/talhashraf/followers", "following_url": "https://api.github.com/users/talhashraf/following{/other_user}", "gists_url": "https://api.github.com/users/talhashraf/gists{/gist_id}", "starred_url": "https://api.github.com/users/talhashraf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/talhashraf/subscriptions", "organizations_url": "https://api.github.com/users/talhashraf/orgs", "repos_url": "https://api.github.com/users/talhashraf/repos", "events_url": "https://api.github.com/users/talhashraf/events{/privacy}", "received_events_url": "https://api.github.com/users/talhashraf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 280218717, "node_id": "MDU6TGFiZWwyODAyMTg3MTc=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/discuss", "name": "discuss", "color": "cc317c", "default": false, "description": null}, {"id": 281088273, "node_id": "MDU6TGFiZWwyODEwODgyNzM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/help%20wanted", "name": "help wanted", "color": "009800", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-09-10T12:45:51Z", "updated_at": "2021-06-24T17:18:08Z", "closed_at": "2021-06-24T17:18:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\n>>> from scrapy import FormRequest\r\n>>> FormRequest('http://example.com/?id=9', method='GET', formdata={'id': '8'}).url\r\n'http://example.com/?id=9&id=8'\r\n```\r\nNotice how `id` is being duplicated in query string. It must replace the value if same key is found. I believe this can be handled in [form.py#L36](https://github.com/scrapy/scrapy/blob/master/scrapy/http/request/form.py#L36).", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2919/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2919/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2853", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2853/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2853/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2853/events", "html_url": "https://github.com/scrapy/scrapy/issues/2853", "id": 245728447, "node_id": "MDU6SXNzdWUyNDU3Mjg0NDc=", "number": 2853, "title": "SitemapSpider support rel=\"alternate\" works not as expected", "user": {"login": "jenya", "id": 668941, "node_id": "MDQ6VXNlcjY2ODk0MQ==", "avatar_url": "https://avatars.githubusercontent.com/u/668941?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jenya", "html_url": "https://github.com/jenya", "followers_url": "https://api.github.com/users/jenya/followers", "following_url": "https://api.github.com/users/jenya/following{/other_user}", "gists_url": "https://api.github.com/users/jenya/gists{/gist_id}", "starred_url": "https://api.github.com/users/jenya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jenya/subscriptions", "organizations_url": "https://api.github.com/users/jenya/orgs", "repos_url": "https://api.github.com/users/jenya/repos", "events_url": "https://api.github.com/users/jenya/events{/privacy}", "received_events_url": "https://api.github.com/users/jenya/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/17", "html_url": "https://github.com/scrapy/scrapy/milestone/17", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/17/labels", "id": 2153485, "node_id": "MDk6TWlsZXN0b25lMjE1MzQ4NQ==", "number": 17, "title": "v1.5", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 69, "state": "closed", "created_at": "2016-11-23T11:25:01Z", "updated_at": "2018-07-04T19:33:00Z", "due_on": null, "closed_at": "2018-07-04T19:33:00Z"}, "comments": 4, "created_at": "2017-07-26T13:49:19Z", "updated_at": "2017-12-22T00:06:34Z", "closed_at": "2017-08-22T09:23:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "This functionality was added here: https://github.com/scrapy/scrapy/issues/360\r\nAccording to this https://github.com/scrapy/scrapy/blob/master/scrapy/spiders/sitemap.py#L46 `sitemap_alternate_links` used for sitemap type `sitemapindex`, but not `urlset`, which is common use case for `rel=\"alternate\"`.\r\nI don't think this is as expected, because that issue, docs and tests (which in fact tests xml parser, but not sitemap parser) in PR talks about `urlset`.\r\nPlease correct me if I'm wrong. Otherwise - I will prepare PR.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2853/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2853/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2844", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2844/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2844/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2844/events", "html_url": "https://github.com/scrapy/scrapy/issues/2844", "id": 244839168, "node_id": "MDU6SXNzdWUyNDQ4MzkxNjg=", "number": 2844, "title": "Redirect 308 missing", "user": {"login": "maugch", "id": 6808345, "node_id": "MDQ6VXNlcjY4MDgzNDU=", "avatar_url": "https://avatars.githubusercontent.com/u/6808345?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maugch", "html_url": "https://github.com/maugch", "followers_url": "https://api.github.com/users/maugch/followers", "following_url": "https://api.github.com/users/maugch/following{/other_user}", "gists_url": "https://api.github.com/users/maugch/gists{/gist_id}", "starred_url": "https://api.github.com/users/maugch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maugch/subscriptions", "organizations_url": "https://api.github.com/users/maugch/orgs", "repos_url": "https://api.github.com/users/maugch/repos", "events_url": "https://api.github.com/users/maugch/events{/privacy}", "received_events_url": "https://api.github.com/users/maugch/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 548863688, "node_id": "MDU6TGFiZWw1NDg4NjM2ODg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/http", "name": "http", "color": "006b75", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-07-22T10:30:52Z", "updated_at": "2017-07-26T18:29:24Z", "closed_at": "2017-07-26T18:29:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "I did a check on the RedirectMiddleware and noticed that code 308 is missing. Is there a reason for that?\r\nSome websites don't update their sitemap and have a long list of 308 from http to https.\r\n\r\n(side note: is there a way to add \"s\" before a link is scraped?)", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2844/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2844/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2842", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2842/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2842/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2842/events", "html_url": "https://github.com/scrapy/scrapy/issues/2842", "id": 244312442, "node_id": "MDU6SXNzdWUyNDQzMTI0NDI=", "number": 2842, "title": "XMLFeedSpider iternodes iterator does not work on XML document with namespace", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 281088273, "node_id": "MDU6TGFiZWwyODEwODgyNzM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/help%20wanted", "name": "help wanted", "color": "009800", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-07-20T10:16:18Z", "updated_at": "2020-10-06T18:07:13Z", "closed_at": "2020-10-06T18:07:13Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "(Opening the issue so that we track it, although it is already known.)\r\n\r\n**Sample input document:**\r\n```\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\r\n<url><loc>http://www.argos.ie/static/Product/partNumber/2353030.htm</loc></url>\r\n<url><loc>http://www.argos.ie/static/Product/partNumber/2717339.htm</loc></url>\r\n(...)\r\n```\r\n\r\n**Symptom:**\r\nWith Scrapy 1.4.0 (and earlier for sure)\r\nUsing `XMLFeedSpider` and the default `iternodes` iterator, nodes using `itertag='loc'` cannot be found, \r\n\r\n```\r\n    (...) site-packages/scrapy/utils/iterators.py\", line 31, in xmliter\r\n        yield Selector(text=nodetext, type='xml').xpath('//' + nodename)[0]\r\n    exceptions.IndexError: list index out of range\r\n```\r\n\r\nand registering namespaces and using `itertag='prefix:loc'` does not work either.\r\n\r\nRecently seen (again) [on StackOverflow](https://stackoverflow.com/questions/45195861/how-to-extract-urls-from-an-xml-using-scrapy-xmlfeedspider).\r\nWas already discussed [on scrapy-users](https://groups.google.com/d/topic/scrapy-users/VN6409UHexQ/discussion).\r\n\r\nThere's a WIP PR #861. Last comments were about moving to iterparse-based implementation", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2842/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2842/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2811", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2811/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2811/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2811/events", "html_url": "https://github.com/scrapy/scrapy/issues/2811", "id": 240184427, "node_id": "MDU6SXNzdWUyNDAxODQ0Mjc=", "number": 2811, "title": "DNSCACHE_ENABLED=False not working", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-07-03T14:10:23Z", "updated_at": "2017-07-06T10:53:34Z", "closed_at": "2017-07-06T10:53:34Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Originally reported by @softwarevamp on [StackOverflow](https://stackoverflow.com/questions/44877296/scrapy-with-dnscache-enabled-false-not-working):\r\n\r\n> When i run scrapy shell with `DNSCACHE_ENABLED=False` got\r\n```\r\nKeyError: 'dictionary is empty'\r\ntwisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.mydomain.com.\r\n```\r\n\r\n```\r\n    2017-07-03 03:09:12 [twisted] CRITICAL: while looking up www.mydomain.com with <scrapy.resolver.CachingThreadedResolver object at 0x3fd0050>\r\n    Traceback (most recent call last):\r\n      File \"/usr/lib64/python2.7/site-packages/twisted/internet/defer.py\", line 653, in _runCallbacks\r\n        current.result = callback(current.result, *args, **kw)\r\n      File \"/usr/lib64/python2.7/site-packages/scrapy/resolver.py\", line 29, in _cache_result\r\n        dnscache[name] = result\r\n      File \"/usr/lib64/python2.7/site-packages/scrapy/utils/datatypes.py\", line 305, in __setitem__\r\n        self.popitem(last=False)\r\n      File \"/usr/lib64/python2.7/collections.py\", line 159, in popitem\r\n        raise KeyError('dictionary is empty')\r\n    KeyError: 'dictionary is empty'\r\n    2017-07-03 03:09:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET //www.mydomain.com/> (failed 3 times): DNS lookup failed: no results for hostname lookup: www.mydomain.com.\r\n    Traceback (most recent call last):\r\n      File \"/usr/bin/scrapy\", line 11, in <module>\r\n        sys.exit(execute())\r\n      File \"/usr/lib64/python2.7/site-packages/scrapy/cmdline.py\", line 149, in execute\r\n        _run_print_help(parser, _run_command, cmd, args, opts)\r\n      File \"/usr/lib64/python2.7/site-packages/scrapy/cmdline.py\", line 89, in _run_print_help\r\n        func(*a, **kw)\r\n      File \"/usr/lib64/python2.7/site-packages/scrapy/cmdline.py\", line 156, in _run_command\r\n        cmd.run(args, opts)\r\n      File \"/usr/lib64/python2.7/site-packages/scrapy/commands/shell.py\", line 73, in run\r\n        shell.start(url=url, redirect=not opts.no_redirect)\r\n      File \"/usr/lib64/python2.7/site-packages/scrapy/shell.py\", line 48, in start\r\n        self.fetch(url, spider, redirect=redirect)\r\n      File \"/usr/lib64/python2.7/site-packages/scrapy/shell.py\", line 115, in fetch\r\n        reactor, self._schedule, request, spider)\r\n      File \"/usr/lib64/python2.7/site-packages/twisted/internet/threads.py\", line 122, in blockingCallFromThread\r\n        result.raiseException()\r\n      File \"<string>\", line 2, in raiseException\r\n    twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.mydomain.com.\r\n```\r\n\r\n> Any thoughts welcome", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2811/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2811/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2774", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2774/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2774/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2774/events", "html_url": "https://github.com/scrapy/scrapy/issues/2774", "id": 233094204, "node_id": "MDU6SXNzdWUyMzMwOTQyMDQ=", "number": 2774, "title": "Don`t fetch url", "user": {"login": "tonal", "id": 316216, "node_id": "MDQ6VXNlcjMxNjIxNg==", "avatar_url": "https://avatars.githubusercontent.com/u/316216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tonal", "html_url": "https://github.com/tonal", "followers_url": "https://api.github.com/users/tonal/followers", "following_url": "https://api.github.com/users/tonal/following{/other_user}", "gists_url": "https://api.github.com/users/tonal/gists{/gist_id}", "starred_url": "https://api.github.com/users/tonal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tonal/subscriptions", "organizations_url": "https://api.github.com/users/tonal/orgs", "repos_url": "https://api.github.com/users/tonal/repos", "events_url": "https://api.github.com/users/tonal/events{/privacy}", "received_events_url": "https://api.github.com/users/tonal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-06-02T07:02:47Z", "updated_at": "2017-08-03T13:46:06Z", "closed_at": "2017-08-03T13:46:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Url `http://www.tehnosad.ru/subcategory/?id=584&producers[]=524` do not fetch from **scrapy**.\r\nBat **httpie** and **chrome** get Ok.\r\nHow to correct it?\r\n```\r\n$ scrapy fetch --headers 'http://www.tehnosad.ru/subcategory/?id=584&producers[]=524'\r\n2017-06-02 13:49:44 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: remains)\r\n2017-06-02 13:49:44 [scrapy.utils.log] INFO: Overridden settings: {'RETRY_TIMES': 5, 'SPIDER_MODULES': ['remains.spiders'], 'FEED_URI': './%(name)s.csv', 'HTTPCACHE_EXPIRATION_SECS': 600, 'RETRY_HTTP_CODES': [400, 408, 420, 500, 502, 503, 504], 'BOT_NAME': 'remains', 'FEED_FORMAT': 'csv', 'AUTOTHROTTLE_ENABLED': True, 'HTTPCACHE_STORAGE': 'scrapy.contrib.httpcache.FilesystemCacheStorage', 'NEWSPIDER_MODULE': 'remains.spiders', 'HTTPCACHE_DIR': './httpcache', 'DOWNLOADER_CLIENTCONTEXTFACTORY': 'remains.ssl_context.CustomClientContextFactory'}\r\n2017-06-02 13:49:44 [scrapy.middleware] INFO: Enabled extensions:\r\n['scrapy.extensions.logstats.LogStats',\r\n 'scrapy.extensions.feedexport.FeedExporter',\r\n 'scrapy.extensions.memusage.MemoryUsage',\r\n 'scrapy.extensions.corestats.CoreStats',\r\n 'scrapy.extensions.throttle.AutoThrottle']\r\n2017-06-02 13:49:44 [scrapy.middleware] INFO: Enabled downloader middlewares:\r\n['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\r\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\r\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\r\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\r\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\r\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\r\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\r\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\r\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\r\n2017-06-02 13:49:44 [scrapy.middleware] INFO: Enabled spider middlewares:\r\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\r\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\r\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\r\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\r\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\r\n2017-06-02 13:49:44 [scrapy.middleware] INFO: Enabled item pipelines:\r\n['remains.pipelines.RemainsPipeline']\r\n2017-06-02 13:49:44 [scrapy.core.engine] INFO: Spider opened\r\n2017-06-02 13:49:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2017-06-02 13:49:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:49:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:49:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:50:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:50:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:50:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:50:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:50:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:50:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:50:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:50:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2017-06-02 13:50:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:50:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:50:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:51:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:51:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:51:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:51:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:51:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:51:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:51:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2017-06-02 13:51:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524> from <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>\r\n2017-06-02 13:51:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Discarding <GET http://www.tehnosad.ru/subcategory/?id=584&producers%5B%5D=524>: max redirections reached\r\n2017-06-02 13:51:54 [scrapy.core.engine] INFO: Closing spider (finished)\r\n2017-06-02 13:51:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\r\n{'downloader/request_bytes': 9196,\r\n 'downloader/request_count': 21,\r\n 'downloader/request_method_count/GET': 21,\r\n 'downloader/response_bytes': 14284,\r\n 'downloader/response_count': 21,\r\n 'downloader/response_status_count/301': 21,\r\n 'finish_reason': 'finished',\r\n 'finish_time': datetime.datetime(2017, 6, 2, 6, 51, 54, 206787),\r\n 'log_count/DEBUG': 21,\r\n 'log_count/INFO': 9,\r\n 'memusage/max': 50880512,\r\n 'memusage/startup': 49733632,\r\n 'scheduler/dequeued': 21,\r\n 'scheduler/dequeued/memory': 21,\r\n 'scheduler/enqueued': 21,\r\n 'scheduler/enqueued/memory': 21,\r\n 'start_time': datetime.datetime(2017, 6, 2, 6, 49, 44, 629809)}\r\n2017-06-02 13:51:54 [scrapy.core.engine] INFO: Spider closed (finished)\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2774/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2774/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2743", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2743/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2743/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2743/events", "html_url": "https://github.com/scrapy/scrapy/issues/2743", "id": 229231647, "node_id": "MDU6SXNzdWUyMjkyMzE2NDc=", "number": 2743, "title": "connection pooling do not work when using proxy", "user": {"login": "jdxin0", "id": 11607613, "node_id": "MDQ6VXNlcjExNjA3NjEz", "avatar_url": "https://avatars.githubusercontent.com/u/11607613?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdxin0", "html_url": "https://github.com/jdxin0", "followers_url": "https://api.github.com/users/jdxin0/followers", "following_url": "https://api.github.com/users/jdxin0/following{/other_user}", "gists_url": "https://api.github.com/users/jdxin0/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdxin0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdxin0/subscriptions", "organizations_url": "https://api.github.com/users/jdxin0/orgs", "repos_url": "https://api.github.com/users/jdxin0/repos", "events_url": "https://api.github.com/users/jdxin0/events{/privacy}", "received_events_url": "https://api.github.com/users/jdxin0/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443073766, "node_id": "MDU6TGFiZWw0NDMwNzM3NjY=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/patch%20available", "name": "patch available", "color": "c2e0c6", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/17", "html_url": "https://github.com/scrapy/scrapy/milestone/17", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/17/labels", "id": 2153485, "node_id": "MDk6TWlsZXN0b25lMjE1MzQ4NQ==", "number": 17, "title": "v1.5", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 69, "state": "closed", "created_at": "2016-11-23T11:25:01Z", "updated_at": "2018-07-04T19:33:00Z", "due_on": null, "closed_at": "2018-07-04T19:33:00Z"}, "comments": 13, "created_at": "2017-05-17T04:03:26Z", "updated_at": "2017-12-26T17:12:48Z", "closed_at": "2017-12-26T17:12:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Scrapy create a new `TCP4ClientEndpoint` for each request when using proxy in `ScrapyAgent` while `ProxyAgent`(twisted) use `key = (\"http-proxy\", self._proxyEndpoint)` as connection pool key.\r\nIt causes creating new connection for each request when using proxy\uff0c\r\nwill get `errno99: cannot assign requested address` when all ports has been used (socket TIME_WAIT).\r\n\r\n\r\nscrapy/core/downloader/handlers/http11.py\r\n```python\r\nclass ScrapyAgent(object):\r\n    def _get_agent(self, request, timeout):\r\n        bindaddress = request.meta.get('bindaddress') or self._bindAddress\r\n        proxy = request.meta.get('proxy')\r\n        if proxy:\r\n            _, _, proxyHost, proxyPort, proxyParams = _parse(proxy)\r\n            scheme = _parse(request.url)[0]\r\n            proxyHost = to_unicode(proxyHost)\r\n            omitConnectTunnel = b'noconnect' in proxyParams\r\n            if  scheme == b'https' and not omitConnectTunnel:\r\n                proxyConf = (proxyHost, proxyPort,\r\n                             request.headers.get(b'Proxy-Authorization', None))\r\n                return self._TunnelingAgent(reactor, proxyConf,\r\n                    contextFactory=self._contextFactory, connectTimeout=timeout,\r\n                    bindAddress=bindaddress, pool=self._pool)\r\n            else:\r\n                endpoint = TCP4ClientEndpoint(reactor, proxyHost, proxyPort,\r\n                    timeout=timeout, bindAddress=bindaddress)\r\n                return self._ProxyAgent(endpoint)\r\n\r\n        return self._Agent(reactor, contextFactory=self._contextFactory,\r\n            connectTimeout=timeout, bindAddress=bindaddress, pool=self._pool)\r\n```\r\n\r\ntwisted/web/client.py\r\n```python\r\n@implementer(IAgent)\r\nclass ProxyAgent(_AgentBase):\r\n    \"\"\"\r\n    An HTTP agent able to cross HTTP proxies.\r\n\r\n    @ivar _proxyEndpoint: The endpoint used to connect to the proxy.\r\n\r\n    @since: 11.1\r\n    \"\"\"\r\n\r\n    def __init__(self, endpoint, reactor=None, pool=None):\r\n        if reactor is None:\r\n            from twisted.internet import reactor\r\n        _AgentBase.__init__(self, reactor, pool)\r\n        self._proxyEndpoint = endpoint\r\n\r\n\r\n    def request(self, method, uri, headers=None, bodyProducer=None):\r\n        \"\"\"\r\n        Issue a new request via the configured proxy.\r\n        \"\"\"\r\n        # Cache *all* connections under the same key, since we are only\r\n        # connecting to a single destination, the proxy:\r\n        key = (\"http-proxy\", self._proxyEndpoint)\r\n\r\n        # To support proxying HTTPS via CONNECT, we will use key\r\n        # (\"http-proxy-CONNECT\", scheme, host, port), and an endpoint that\r\n        # wraps _proxyEndpoint with an additional callback to do the CONNECT.\r\n        return self._requestWithEndpoint(key, self._proxyEndpoint, method,\r\n                                         URI.fromBytes(uri), headers,\r\n                                         bodyProducer, uri)\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2743/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2743/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2728", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2728/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2728/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2728/events", "html_url": "https://github.com/scrapy/scrapy/issues/2728", "id": 226853679, "node_id": "MDU6SXNzdWUyMjY4NTM2Nzk=", "number": 2728, "title": "DNSLookupError raises on request cyrillic domains", "user": {"login": "shoreward", "id": 1315493, "node_id": "MDQ6VXNlcjEzMTU0OTM=", "avatar_url": "https://avatars.githubusercontent.com/u/1315493?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shoreward", "html_url": "https://github.com/shoreward", "followers_url": "https://api.github.com/users/shoreward/followers", "following_url": "https://api.github.com/users/shoreward/following{/other_user}", "gists_url": "https://api.github.com/users/shoreward/gists{/gist_id}", "starred_url": "https://api.github.com/users/shoreward/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shoreward/subscriptions", "organizations_url": "https://api.github.com/users/shoreward/orgs", "repos_url": "https://api.github.com/users/shoreward/repos", "events_url": "https://api.github.com/users/shoreward/events{/privacy}", "received_events_url": "https://api.github.com/users/shoreward/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2017-05-07T11:59:40Z", "updated_at": "2017-06-19T08:46:51Z", "closed_at": "2017-06-19T08:46:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello\r\n\r\nI had an error when requesting Cyrillic domains\r\n\r\n`scrapy shell '\u0448\u0430\u043d\u0442\u0438-\u0448\u0430\u043d\u0442\u0438.\u0440\u0444'`\r\n\r\n```\r\n  File \"/www/.venv/lib/python2.7/site-packages/scrapy/shell.py\", line 115, in fetch\r\n    reactor, self._schedule, request, spider)\r\n  File \"/www/.venv/lib/python2.7/site-packages/twisted/internet/threads.py\", line 122, in blockingCallFromThread\r\n    result.raiseException()\r\n  File \"<string>\", line 2, in raiseException\r\ntwisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: xn----7sbb4ac0ad0be6cf.xn--p1ai.\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2728/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2728/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2717", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2717/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2717/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2717/events", "html_url": "https://github.com/scrapy/scrapy/issues/2717", "id": 224196154, "node_id": "MDU6SXNzdWUyMjQxOTYxNTQ=", "number": 2717, "title": "TLS handshake failure", "user": {"login": "povilasb", "id": 1213442, "node_id": "MDQ6VXNlcjEyMTM0NDI=", "avatar_url": "https://avatars.githubusercontent.com/u/1213442?v=4", "gravatar_id": "", "url": "https://api.github.com/users/povilasb", "html_url": "https://github.com/povilasb", "followers_url": "https://api.github.com/users/povilasb/followers", "following_url": "https://api.github.com/users/povilasb/following{/other_user}", "gists_url": "https://api.github.com/users/povilasb/gists{/gist_id}", "starred_url": "https://api.github.com/users/povilasb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/povilasb/subscriptions", "organizations_url": "https://api.github.com/users/povilasb/orgs", "repos_url": "https://api.github.com/users/povilasb/repos", "events_url": "https://api.github.com/users/povilasb/events{/privacy}", "received_events_url": "https://api.github.com/users/povilasb/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 320345582, "node_id": "MDU6TGFiZWwzMjAzNDU1ODI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/https", "name": "https", "color": "101e89", "default": false, "description": ""}, {"id": 839225636, "node_id": "MDU6TGFiZWw4MzkyMjU2MzY=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/upstream%20issue", "name": "upstream issue", "color": "c2e0c6", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 27, "created_at": "2017-04-25T16:23:45Z", "updated_at": "2022-03-03T10:15:56Z", "closed_at": "2019-07-17T08:38:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have this simple spider:\r\n```\r\nimport scrapy\r\n\r\n\r\nclass FailingSpider(scrapy.Spider):\r\n    name = 'Failing Spider'\r\n    start_urls = ['https://www.skelbiu.lt/']\r\n\r\n    def parse(self, response: scrapy.http.Response) -> None:\r\n        pass\r\n```\r\nOn debian 9 it fails with:\r\n```\r\n2017-04-25 19:01:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.skelbiu.lt/>\r\nTraceback (most recent call last):\r\n  File \"/home/povilas/projects/skelbiu-scraper/pyenv/lib/python3.6/site-packages/twisted/internet/defer.py\", line 1299, in _inlineCallbacks\r\n    result = result.throwExceptionIntoGenerator(g)\r\n  File \"/home/povilas/projects/skelbiu-scraper/pyenv/lib/python3.6/site-packages/twisted/python/failure.py\", line 393, in throwExceptionIntoGenerator\r\n    return g.throw(self.type, self.value, self.tb)\r\n  File \"/home/povilas/projects/skelbiu-scraper/pyenv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py\", line 43, in process_request\r\n    defer.returnValue((yield download_func(request=request,spider=spider)))\r\ntwisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'sslv3 alert handshake failure')]>]\r\n```\r\nOn debian 8 it works well.\r\nAnd \"https://www.skelbiu.lt\" is the only target I can reproduce the problem.\r\n\r\nSome more context:\r\n```\r\n$ pyenv/bin/pip freeze\r\nasn1crypto==0.22.0\r\nattrs==16.3.0\r\nAutomat==0.5.0\r\ncffi==1.10.0\r\nconstantly==15.1.0\r\ncryptography==1.8.1\r\ncssselect==1.0.1\r\nfuncsigs==0.4\r\nidna==2.5\r\nincremental==16.10.1\r\nlxml==3.7.3\r\nmock==1.3.0\r\npackaging==16.8\r\nparsel==1.1.0\r\npbr==3.0.0\r\npy==1.4.33\r\npyasn1==0.2.3\r\npyasn1-modules==0.0.8\r\npycparser==2.17\r\nPyDispatcher==2.0.5\r\nPyHamcrest==1.8.5\r\npyOpenSSL==17.0.0\r\npyparsing==2.2.0\r\npytest==2.7.2\r\nqueuelib==1.4.2\r\nScrapy==1.3.3\r\nservice-identity==16.0.0\r\nsix==1.10.0\r\nTwisted==17.1.0\r\nw3lib==1.17.0\r\nzope.interface==4.4.0\r\n\r\n$ dpkg --get-selections | grep libssl\r\nlibssl-dev:amd64                                install\r\nlibssl-doc                                      install\r\nlibssl1.0.2:amd64                               install\r\nlibssl1.1:amd64                                 install\r\nlibssl1.1:i386                                  install\r\n\r\n\r\n$ apt-cache show libssl1.1\r\nPackage: libssl1.1\r\nSource: openssl\r\nVersion: 1.1.0e-1\r\n```\r\n\r\nAny ideas what I should look for? :)", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2717/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2717/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2677", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2677/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2677/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2677/events", "html_url": "https://github.com/scrapy/scrapy/issues/2677", "id": 216371737, "node_id": "MDU6SXNzdWUyMTYzNzE3Mzc=", "number": 2677, "title": "Duplicate Content-Length header for POST requests with empty body", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 548863688, "node_id": "MDU6TGFiZWw1NDg4NjM2ODg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/http", "name": "http", "color": "006b75", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/15", "html_url": "https://github.com/scrapy/scrapy/milestone/15", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/15/labels", "id": 1977308, "node_id": "MDk6TWlsZXN0b25lMTk3NzMwOA==", "number": 15, "title": "v1.4", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 67, "state": "closed", "created_at": "2016-09-01T09:43:32Z", "updated_at": "2017-08-28T11:12:21Z", "due_on": null, "closed_at": "2017-08-28T11:12:21Z"}, "comments": 3, "created_at": "2017-03-23T10:03:58Z", "updated_at": "2017-04-26T19:10:21Z", "closed_at": "2017-04-26T19:10:21Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Originally reported [on StackOverflow](https://stackoverflow.com/questions/42966405/scrapy-post-header-has-two-content-length-fields).\r\n\r\nHTTP requests with POST method and no request body are sent with 2 `Content-Length: 0` headers.\r\n\r\nReproducible with Scrapy 1.3.3 and Twisted 17.1:\r\n\r\n```\r\n$ scrapy version -v\r\nScrapy    : 1.3.3\r\nlxml      : 3.7.3.0\r\nlibxml2   : 2.9.3\r\ncssselect : 1.0.1\r\nparsel    : 1.1.0\r\nw3lib     : 1.17.0\r\nTwisted   : 17.1.0\r\nPython    : 2.7.12 (default, Nov 19 2016, 06:48:10) - [GCC 5.4.0 20160609]\r\npyOpenSSL : 16.2.0 (OpenSSL 1.0.2g  1 Mar 2016)\r\nPlatform  : Linux-4.8.0-41-generic-x86_64-with-Ubuntu-16.10-yakkety\r\n$ scrapy shell\r\n>>> fetch(scrapy.Request('http://httpbin.org/post', method='POST'))\r\n2017-03-23 10:58:34 [scrapy.core.engine] DEBUG: Crawled (200) <POST http://httpbin.org/post> (referer: None)\r\n```\r\n(note that httpbin.org/post output does not show duplicate headers, but the Wireshark capture does)\r\n\r\nWireshark sniffing:\r\n\r\n```\r\nPOST /post HTTP/1.1\r\nContent-Length: 0\r\nContent-Length: 0\r\nAccept-Language: en\r\nAccept-Encoding: gzip,deflate\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\nUser-Agent: Scrapy/1.3.3 (+http://scrapy.org)\r\nHost: httpbin.org\r\n\r\nHTTP/1.1 200 OK\r\nConnection: keep-alive\r\nServer: gunicorn/19.7.1\r\nDate: Thu, 23 Mar 2017 09:58:34 GMT\r\nContent-Type: application/json\r\nAccess-Control-Allow-Origin: *\r\nAccess-Control-Allow-Credentials: true\r\nContent-Length: 458\r\nVia: 1.1 vegur\r\n\r\n{\r\n  \"args\": {}, \r\n  \"data\": \"\", \r\n  \"files\": {}, \r\n  \"form\": {}, \r\n  \"headers\": {\r\n    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \r\n    \"Accept-Encoding\": \"gzip,deflate\", \r\n    \"Accept-Language\": \"en\", \r\n    \"Connection\": \"close\", \r\n    \"Content-Length\": \"0\", \r\n    \"Host\": \"httpbin.org\", \r\n    \"User-Agent\": \"Scrapy/1.3.3 (+http://scrapy.org)\"\r\n  }, \r\n  \"json\": null, \r\n  \"origin\": \"89.84.122.217\", \r\n  \"url\": \"http://httpbin.org/post\"\r\n}\r\n```\r\n\r\nThis is due to Twisted's https://github.com/twisted/twisted/pull/670 since v17.1 and Scrapy's https://github.com/scrapy/scrapy/pull/1800 since Scrapy 1.1.0", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2677/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2677/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2658", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2658/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2658/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2658/events", "html_url": "https://github.com/scrapy/scrapy/issues/2658", "id": 214872546, "node_id": "MDU6SXNzdWUyMTQ4NzI1NDY=", "number": 2658, "title": "large response causes scrapy to hang", "user": {"login": "rjbks", "id": 11906786, "node_id": "MDQ6VXNlcjExOTA2Nzg2", "avatar_url": "https://avatars.githubusercontent.com/u/11906786?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjbks", "html_url": "https://github.com/rjbks", "followers_url": "https://api.github.com/users/rjbks/followers", "following_url": "https://api.github.com/users/rjbks/following{/other_user}", "gists_url": "https://api.github.com/users/rjbks/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjbks/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjbks/subscriptions", "organizations_url": "https://api.github.com/users/rjbks/orgs", "repos_url": "https://api.github.com/users/rjbks/repos", "events_url": "https://api.github.com/users/rjbks/events{/privacy}", "received_events_url": "https://api.github.com/users/rjbks/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-03-16T23:59:41Z", "updated_at": "2023-01-17T08:59:05Z", "closed_at": "2023-01-17T08:59:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have tried stackoverflow but haven't received any answers for this as of yet.\r\n\r\n[scrapy hangs on large response](http://stackoverflow.com/questions/42822010/scrapy-hanging-on-api-call-which-returns-large-json-object)\r\n\r\nSummary:\r\n\r\nUsing scrapy to make thousands of API calls, all of them work fine except for 1 which returns a response of around 2GB (takes roughly 4 mins to complete using requests library). I have increased or disabled the related settings which may limit download size or timeout (DOWNLOAD_MAXSIZE DOWNLOAD_TIMEOUT). The logs show a 200 response then the warning for download size (which I left enabled just to indicate some form of progress) I then get 3 consecutive INFO logs from the stat tracker (1 minute apart), then it just hangs. I have left it running for up to 30 mins then I had to force quit (control-c does not work). Based on that, it would seem to hang after roughly 3 minutes after initiating that API call without any more logging whether I leave the download_timeout enable (for either 6.5 or 7 minutes when several attempts with requests package yields results in about 4 minutes) or disabled. Any ideas what could be causing this?", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2658/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2658/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2552", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2552/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2552/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2552/events", "html_url": "https://github.com/scrapy/scrapy/issues/2552", "id": 206476373, "node_id": "MDU6SXNzdWUyMDY0NzYzNzM=", "number": 2552, "title": "scrapy.Request no init error on invalid url", "user": {"login": "pawelmhm", "id": 2700942, "node_id": "MDQ6VXNlcjI3MDA5NDI=", "avatar_url": "https://avatars.githubusercontent.com/u/2700942?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pawelmhm", "html_url": "https://github.com/pawelmhm", "followers_url": "https://api.github.com/users/pawelmhm/followers", "following_url": "https://api.github.com/users/pawelmhm/following{/other_user}", "gists_url": "https://api.github.com/users/pawelmhm/gists{/gist_id}", "starred_url": "https://api.github.com/users/pawelmhm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pawelmhm/subscriptions", "organizations_url": "https://api.github.com/users/pawelmhm/orgs", "repos_url": "https://api.github.com/users/pawelmhm/repos", "events_url": "https://api.github.com/users/pawelmhm/events{/privacy}", "received_events_url": "https://api.github.com/users/pawelmhm/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2017-02-09T11:24:35Z", "updated_at": "2019-11-19T08:50:12Z", "closed_at": "2019-11-19T08:50:12Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I stumbled on some weird issue, spider got some invalid url, but instead of crashing loudly when trying to create scrapy.Request() with invalid url it just silently ignored this error. Sample to reproduce\r\n\r\n```python\r\nfrom scrapy.spiders import Spider\r\nfrom scrapy import Request\r\n\r\n\r\nclass DmozSpider(Spider):\r\n    name = \"dmoz\"\r\n    allowed_domains = [\"dmoz.org\"]\r\n    start_urls = [\r\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\",\r\n    ]\r\n\r\n    def parse(self, response):\r\n        invalid_url = \"/container.productlist.productslist.productthumbnail.articledetaillink.layerlink:open-layer/0/CLASSIC/-1/WEB$007cARBO$007c13263065/null$007cDisplay$0020Product$002f111499$002fAil$0020blanc$007c?t:ac=13263065\"\r\n        yield Request(invalid_url)\r\n```\r\n\r\nthis generates following output:\r\n\r\n```\r\n2017-02-09 12:21:04 [scrapy.core.engine] INFO: Spider opened\r\n2017-02-09 12:21:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2017-02-09 12:21:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024\r\n2017-02-09 12:21:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.dmoz.org/Computers/Programming/Languages/Python/Books/> (referer: None)\r\n2017-02-09 12:21:04 [scrapy.core.engine] INFO: Closing spider (finished)\r\n```\r\n\r\nthere is no information about trying to generate this Request with invalid_url, no stacktrace, no error info from middleware. Why?", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2552/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2552/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2511", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2511/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2511/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2511/events", "html_url": "https://github.com/scrapy/scrapy/issues/2511", "id": 202884425, "node_id": "MDU6SXNzdWUyMDI4ODQ0MjU=", "number": 2511, "title": "Python 3.6 Item inheritance fails", "user": {"login": "jeffcjohnson", "id": 585519, "node_id": "MDQ6VXNlcjU4NTUxOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/585519?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeffcjohnson", "html_url": "https://github.com/jeffcjohnson", "followers_url": "https://api.github.com/users/jeffcjohnson/followers", "following_url": "https://api.github.com/users/jeffcjohnson/following{/other_user}", "gists_url": "https://api.github.com/users/jeffcjohnson/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeffcjohnson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeffcjohnson/subscriptions", "organizations_url": "https://api.github.com/users/jeffcjohnson/orgs", "repos_url": "https://api.github.com/users/jeffcjohnson/repos", "events_url": "https://api.github.com/users/jeffcjohnson/events{/privacy}", "received_events_url": "https://api.github.com/users/jeffcjohnson/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-01-24T17:21:19Z", "updated_at": "2017-02-08T11:15:15Z", "closed_at": "2017-02-08T11:15:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "When trying to use inheritance on Item I get \r\n\r\n`TypeError: __class__ set to <class '__main__.SpecialItem'> defining 'SpecialItem' as <class '__main__.SpecialItem'>`\r\n\r\nSee more detail here:\r\nhttps://github.com/scrapy-plugins/scrapy-djangoitem/issues/18", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2511/reactions", "total_count": 3, "+1": 3, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2511/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2501", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2501/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2501/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2501/events", "html_url": "https://github.com/scrapy/scrapy/issues/2501", "id": 201872052, "node_id": "MDU6SXNzdWUyMDE4NzIwNTI=", "number": 2501, "title": "scrapy view <url> raise exc in v1.3.0", "user": {"login": "wingyiu", "id": 1861005, "node_id": "MDQ6VXNlcjE4NjEwMDU=", "avatar_url": "https://avatars.githubusercontent.com/u/1861005?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wingyiu", "html_url": "https://github.com/wingyiu", "followers_url": "https://api.github.com/users/wingyiu/followers", "following_url": "https://api.github.com/users/wingyiu/following{/other_user}", "gists_url": "https://api.github.com/users/wingyiu/gists{/gist_id}", "starred_url": "https://api.github.com/users/wingyiu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wingyiu/subscriptions", "organizations_url": "https://api.github.com/users/wingyiu/orgs", "repos_url": "https://api.github.com/users/wingyiu/repos", "events_url": "https://api.github.com/users/wingyiu/events{/privacy}", "received_events_url": "https://api.github.com/users/wingyiu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2017-01-19T14:16:37Z", "updated_at": "2017-02-02T16:24:56Z", "closed_at": "2017-02-02T16:24:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "````\r\n(py35) wingyiu@mbp101:~$scrapy view http://www.scrapy.org\r\n2017-01-19 22:13:54 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: scrapybot)\r\n2017-01-19 22:13:54 [scrapy.utils.log] INFO: Overridden settings: {}\r\nTraceback (most recent call last):\r\n  File \"/Users/user/venv/py35/bin/scrapy\", line 11, in <module>\r\n    sys.exit(execute())\r\n  File \"/Users/user/venv/py35/lib/python3.5/site-packages/scrapy/cmdline.py\", line 142, in execute\r\n    _run_print_help(parser, _run_command, cmd, args, opts)\r\n  File \"/Users/user/venv/py35/lib/python3.5/site-packages/scrapy/cmdline.py\", line 88, in _run_print_help\r\n    func(*a, **kw)\r\n  File \"/Users/user/venv/py35/lib/python3.5/site-packages/scrapy/cmdline.py\", line 149, in _run_command\r\n    cmd.run(args, opts)\r\n  File \"/Users/user/venv/py35/lib/python3.5/site-packages/scrapy/commands/fetch.py\", line 58, in run\r\n    if not opts.no_redirect:\r\nAttributeError: 'Values' object has no attribute 'no_redirect'\r\n````\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2501/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2501/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2491", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2491/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2491/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2491/events", "html_url": "https://github.com/scrapy/scrapy/issues/2491", "id": 199992780, "node_id": "MDU6SXNzdWUxOTk5OTI3ODA=", "number": 2491, "title": "TLS connection fails through HTTPS proxy after CONNECT tunnel is established", "user": {"login": "aiportal", "id": 878799, "node_id": "MDQ6VXNlcjg3ODc5OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/878799?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aiportal", "html_url": "https://github.com/aiportal", "followers_url": "https://api.github.com/users/aiportal/followers", "following_url": "https://api.github.com/users/aiportal/following{/other_user}", "gists_url": "https://api.github.com/users/aiportal/gists{/gist_id}", "starred_url": "https://api.github.com/users/aiportal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aiportal/subscriptions", "organizations_url": "https://api.github.com/users/aiportal/orgs", "repos_url": "https://api.github.com/users/aiportal/repos", "events_url": "https://api.github.com/users/aiportal/events{/privacy}", "received_events_url": "https://api.github.com/users/aiportal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 320345582, "node_id": "MDU6TGFiZWwzMjAzNDU1ODI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/https", "name": "https", "color": "101e89", "default": false, "description": ""}, {"id": 326439252, "node_id": "MDU6TGFiZWwzMjY0MzkyNTI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/security", "name": "security", "color": "e11d21", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2017-01-11T03:09:17Z", "updated_at": "2017-02-20T20:44:36Z", "closed_at": "2017-02-20T20:44:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "I set proxy by this code:\r\n```\r\nclass HttpProxyMiddleware(object):\r\n    def process_request(self, request, spider):\r\n        request.meta['proxy'] = 'https://127.0.0.1:8787'\r\n\r\n```\r\n\r\nIt's error is:\r\n> scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 127.0.0.1:8787\r\n\r\nThen I test the proxy by requests:\r\n`resp = requests.get('https://......', proxies={'https': 'https://127.0.0.1:8787'})`\r\nIt' work!\r\n\r\nSo, what is it happen?\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2491/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2491/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2479", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2479/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2479/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2479/events", "html_url": "https://github.com/scrapy/scrapy/issues/2479", "id": 198710368, "node_id": "MDU6SXNzdWUxOTg3MTAzNjg=", "number": 2479, "title": "Scrapy is incompatible with Twisted 16.7.0rc1", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-01-04T13:44:36Z", "updated_at": "2017-02-27T11:14:38Z", "closed_at": "2017-02-27T11:14:38Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "See [Twisted 16.7.0rc1 release annoucement](https://twistedmatrix.com/pipermail/twisted-python/2016-December/030984.html) for new features and changes.\r\n\r\nhttps://github.com/twisted/twisted/pull/624 seems to be causing trouble (may not be the only one).\r\n\r\nhttps://github.com/scrapy/scrapy/issues/2461 is also happening with 16.7.0rc1", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2479/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2479/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2461", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2461/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2461/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2461/events", "html_url": "https://github.com/scrapy/scrapy/issues/2461", "id": 197219248, "node_id": "MDU6SXNzdWUxOTcyMTkyNDg=", "number": 2461, "title": "TypeError: 'float' object is not iterable (on Twisted dev + Scrapy dev)", "user": {"login": "rmax", "id": 26015, "node_id": "MDQ6VXNlcjI2MDE1", "avatar_url": "https://avatars.githubusercontent.com/u/26015?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmax", "html_url": "https://github.com/rmax", "followers_url": "https://api.github.com/users/rmax/followers", "following_url": "https://api.github.com/users/rmax/following{/other_user}", "gists_url": "https://api.github.com/users/rmax/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmax/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmax/subscriptions", "organizations_url": "https://api.github.com/users/rmax/orgs", "repos_url": "https://api.github.com/users/rmax/repos", "events_url": "https://api.github.com/users/rmax/events{/privacy}", "received_events_url": "https://api.github.com/users/rmax/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2016-12-22T16:58:37Z", "updated_at": "2017-02-02T16:13:59Z", "closed_at": "2017-02-02T16:13:59Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "This happens on Twisted trunk and with latest Scrapy master.\r\n\r\n```\r\n$ scrapy shell http://localhost:8081/\r\n2016-12-22 12:52:01 [scrapy.utils.log] INFO: Scrapy 1.2.2 started (bot: scrapybot)\r\n2016-12-22 12:52:01 [scrapy.utils.log] INFO: Overridden settings: {'LOGSTATS_INTERVAL': 0, 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter'}\r\n2016-12-22 12:52:01 [scrapy.middleware] INFO: Enabled extensions:\r\n['scrapy.extensions.telnet.TelnetConsole',\r\n 'scrapy.extensions.corestats.CoreStats']\r\n2016-12-22 12:52:01 [scrapy.middleware] INFO: Enabled downloader middlewares:\r\n['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\r\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\r\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\r\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\r\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\r\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\r\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\r\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\r\n2016-12-22 12:52:01 [scrapy.middleware] INFO: Enabled spider middlewares:\r\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\r\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\r\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\r\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\r\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\r\n2016-12-22 12:52:01 [scrapy.middleware] INFO: Enabled item pipelines:\r\n[]\r\n2016-12-22 12:52:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023\r\n2016-12-22 12:52:01 [scrapy.core.engine] INFO: Spider opened\r\nTraceback (most recent call last):\r\n  File \"/Users/rolando/miniconda3/envs/dev/bin/scrapy\", line 11, in <module>\r\n    load_entry_point('Scrapy', 'console_scripts', 'scrapy')()\r\n  File \"/Users/rolando/Projects/sh/scrapy/scrapy/cmdline.py\", line 142, in execute\r\n    _run_print_help(parser, _run_command, cmd, args, opts)\r\n  File \"/Users/rolando/Projects/sh/scrapy/scrapy/cmdline.py\", line 88, in _run_print_help\r\n    func(*a, **kw)\r\n  File \"/Users/rolando/Projects/sh/scrapy/scrapy/cmdline.py\", line 149, in _run_command\r\n    cmd.run(args, opts)\r\n  File \"/Users/rolando/Projects/sh/scrapy/scrapy/commands/shell.py\", line 71, in run\r\n    shell.start(url=url)\r\n  File \"/Users/rolando/Projects/sh/scrapy/scrapy/shell.py\", line 47, in start\r\n    self.fetch(url, spider)\r\n  File \"/Users/rolando/Projects/sh/scrapy/scrapy/shell.py\", line 112, in fetch\r\n    reactor, self._schedule, request, spider)\r\n  File \"/Users/rolando/Projects/gh/twisted/src/twisted/internet/threads.py\", line 122, in blockingCallFromThread\r\n    result.raiseException()\r\n  File \"/Users/rolando/Projects/gh/twisted/src/twisted/python/failure.py\", line 372, in raiseException\r\n    raise self.value.with_traceback(self.tb)\r\nTypeError: 'float' object is not iterable\r\n```\r\n\r\n```\r\n(Pdb) w\r\n  /Users/rolando/Projects/sh/scrapy/scrapy/utils/defer.py(45)mustbe_deferred()\r\n-> result = f(*args, **kw)\r\n  /Users/rolando/Projects/sh/scrapy/scrapy/core/downloader/handlers/__init__.py(65)download_request()\r\n-> return handler.download_request(request, spider)\r\n  /Users/rolando/Projects/sh/scrapy/scrapy/core/downloader/handlers/http11.py(61)download_request()\r\n-> return agent.download_request(request)\r\n  /Users/rolando/Projects/sh/scrapy/scrapy/core/downloader/handlers/http11.py(286)download_request()\r\n-> method, to_bytes(url, encoding='ascii'), headers, bodyproducer)\r\n  /Users/rolando/Projects/gh/twisted/src/twisted/web/client.py(1601)request()\r\n-> parsedURI.originForm)\r\n  /Users/rolando/Projects/gh/twisted/src/twisted/web/client.py(1378)_requestWithEndpoint()\r\n-> d = self._pool.getConnection(key, endpoint)\r\n  /Users/rolando/Projects/gh/twisted/src/twisted/web/client.py(1264)getConnection()\r\n-> return self._newConnection(key, endpoint)\r\n  /Users/rolando/Projects/gh/twisted/src/twisted/web/client.py(1276)_newConnection()\r\n-> return endpoint.connect(factory)\r\n  /Users/rolando/Projects/gh/twisted/src/twisted/internet/endpoints.py(779)connect()\r\n-> EndpointReceiver, self._hostText, portNumber=self._port\r\n  /Users/rolando/Projects/gh/twisted/src/twisted/internet/_resolver.py(174)resolveHostName()\r\n-> onAddress = self._simpleResolver.getHostByName(hostName)\r\n  /Users/rolando/Projects/sh/scrapy/scrapy/resolver.py(21)getHostByName()\r\n-> d = super(CachingThreadedResolver, self).getHostByName(name, timeout)\r\n> /Users/rolando/Projects/gh/twisted/src/twisted/internet/base.py(276)getHostByName()\r\n-> timeoutDelay = sum(timeout)\r\n```\r\n\r\nAfter digging, I found out that the addition of `DNS_TIMEOUT` was not effective at all: https://github.com/scrapy/scrapy/commit/85aa3c7596c6e9c66daaa5503faadd03a16e1d59#diff-92d881d6568986904888f43c885240e2L13\r\n\r\nPreviously, on Twisted <=16.6.0, the method `getHostByName` was always called with a default timeout: https://github.com/twisted/twisted/blob/twisted-16.6.0/src/twisted/internet/base.py#L565-L573\r\n\r\nBut now, on Twisted trunk, the method is called without a timeout parameter: https://github.com/twisted/twisted/blob/trunk/src/twisted/internet/_resolver.py#L174\r\n\r\nThis makes the caching resolver to use the default value `timeout=60.0` which causes the error: https://github.com/twisted/twisted/blob/twisted-16.6.0/src/twisted/internet/base.py#L259-L268", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2461/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2461/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2452", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2452/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2452/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2452/events", "html_url": "https://github.com/scrapy/scrapy/issues/2452", "id": 195831800, "node_id": "MDU6SXNzdWUxOTU4MzE4MDA=", "number": 2452, "title": "Image Background converting to green.", "user": {"login": "mkaya93", "id": 6665723, "node_id": "MDQ6VXNlcjY2NjU3MjM=", "avatar_url": "https://avatars.githubusercontent.com/u/6665723?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mkaya93", "html_url": "https://github.com/mkaya93", "followers_url": "https://api.github.com/users/mkaya93/followers", "following_url": "https://api.github.com/users/mkaya93/following{/other_user}", "gists_url": "https://api.github.com/users/mkaya93/gists{/gist_id}", "starred_url": "https://api.github.com/users/mkaya93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mkaya93/subscriptions", "organizations_url": "https://api.github.com/users/mkaya93/orgs", "repos_url": "https://api.github.com/users/mkaya93/repos", "events_url": "https://api.github.com/users/mkaya93/events{/privacy}", "received_events_url": "https://api.github.com/users/mkaya93/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-12-15T15:18:44Z", "updated_at": "2019-07-09T10:57:54Z", "closed_at": "2019-07-09T10:57:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, \r\n\r\nProblem is I'm downloading images with crawler but they are transparency. So image is looking like this.\r\n\r\n![a2062c7f64b9a136c16f1a3d8491b70902986fc4](https://cloud.githubusercontent.com/assets/6665723/21229545/97a44c8c-c2ea-11e6-9f96-5e60106bd340.jpg)\r\n\r\nBut it should look like this.\r\n ##\r\n![wd-bvbz0120jch-12tb-my-cloud-ex2-ultra-gigabit-ethernet-kisisel-bulut-depolama](https://cloud.githubusercontent.com/assets/6665723/21229505/7bb3b8d2-c2ea-11e6-94fc-921adb2f21ee.png)\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2452/reactions", "total_count": 3, "+1": 3, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2452/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2407", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2407/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2407/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2407/events", "html_url": "https://github.com/scrapy/scrapy/issues/2407", "id": 191249091, "node_id": "MDU6SXNzdWUxOTEyNDkwOTE=", "number": 2407, "title": "SelectJmes fails to parse the right way due to arg_to_iter() turning the output into a list.", "user": {"login": "IAlwaysBeCoding", "id": 7705309, "node_id": "MDQ6VXNlcjc3MDUzMDk=", "avatar_url": "https://avatars.githubusercontent.com/u/7705309?v=4", "gravatar_id": "", "url": "https://api.github.com/users/IAlwaysBeCoding", "html_url": "https://github.com/IAlwaysBeCoding", "followers_url": "https://api.github.com/users/IAlwaysBeCoding/followers", "following_url": "https://api.github.com/users/IAlwaysBeCoding/following{/other_user}", "gists_url": "https://api.github.com/users/IAlwaysBeCoding/gists{/gist_id}", "starred_url": "https://api.github.com/users/IAlwaysBeCoding/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/IAlwaysBeCoding/subscriptions", "organizations_url": "https://api.github.com/users/IAlwaysBeCoding/orgs", "repos_url": "https://api.github.com/users/IAlwaysBeCoding/repos", "events_url": "https://api.github.com/users/IAlwaysBeCoding/events{/privacy}", "received_events_url": "https://api.github.com/users/IAlwaysBeCoding/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-11-23T11:42:01Z", "updated_at": "2020-01-14T23:20:12Z", "closed_at": "2020-01-14T23:20:11Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Here is an example of what I'm talking about:\r\n\r\n```python\r\nimport json\r\nfrom scrapy import Item\r\nfrom scrapy.loader import ItemLoader\r\nfrom scrapy.loader.processors import SelectJmes\r\nstring = r'''{\r\n  \"type\": [\r\n    \"http://schema.org/Physician\"\r\n  ], \r\n  \"properties\": {\r\n    \"url\": [\r\n      \"http://www.vitals.com/doctors/Dr_Patrick_B_Wright.html\"\r\n    ], \r\n    \"aggregateRating\": [\r\n      {\r\n        \"type\": [\r\n          \"http://schema.org/AggregateRating\"\r\n        ], \r\n        \"properties\": {\r\n          \"worstRating\": [\r\n            \"0\"\r\n          ], \r\n          \"reviewCount\": [\r\n            \"1\"\r\n          ], \r\n          \"bestRating\": [\r\n            \"5\"\r\n          ], \r\n          \"ratingValue\": [\r\n            \"4.3\"\r\n          ], \r\n          \"ratingCount\": [\r\n            \"6\"\r\n          ]\r\n        }\r\n      }\r\n    ], \r\n    \"medicalspecialty\": [\r\n      {\r\n        \"type\": [\r\n          \"http://schema.org/MedicalSpecialty\"\r\n        ], \r\n        \"properties\": {\r\n          \"name\": [\r\n            \"Pediatric Surgery\"\r\n          ]\r\n        }\r\n      }\r\n    ], \r\n    \"name\": [\r\n      \"Dr. Patrick Wright MD\"\r\n    ], \r\n    \"address\": [\r\n      {\r\n        \"type\": [\r\n          \"http://schema.org/PostalAddress\"\r\n        ], \r\n        \"properties\": {\r\n          \"addressLocality\": [\r\n            \"Jackson\"\r\n          ], \r\n          \"addressRegion\": [\r\n            \"MS\"\r\n          ], \r\n          \"streetAddress\": [\r\n            \"2500 N State St\"\r\n          ], \r\n          \"postalCode\": [\r\n            \"39216\"\r\n          ], \r\n          \"telephone\": [\r\n            \"(601) 984-2150\"\r\n          ]\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}'''\r\n\r\ndata = json.loads(string)\r\n\r\n#This will work fine\r\nproc = SelectJmes('properties.address[0].properties.postalCode[0]')\r\n\r\n\r\n#However, if its used in an input processor it will fail and will need to add `[0]` before the query in order to work.\r\n\r\nclass SomeItem(Item):\r\n     postal_code = Field(\r\n          input_processor = SelectJmes('properties.address[0].properties.postalCode[0]')\r\n     )\r\n\r\nloader = ItemLoader(SomeItem())\r\nloader.add_value('postal_code', data)\r\nitem = loader.load_item()\r\n\r\n```\r\n\r\nThe only way to make it work will be to always add `[0]` to the JmesQuery when done inside an input or output field processor.\r\n#This will work\r\n[0].properties.address[0].properties.postalCode[0]\r\n\r\nShould we document this odd behaviour due to arg_to_iter doing this?\r\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2407/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2407/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2390", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2390/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2390/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2390/events", "html_url": "https://github.com/scrapy/scrapy/issues/2390", "id": 188298706, "node_id": "MDU6SXNzdWUxODgyOTg3MDY=", "number": 2390, "title": "Sitemap spider not robust against wrong sitemap URLs in robots.txt", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/18", "html_url": "https://github.com/scrapy/scrapy/milestone/18", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/18/labels", "id": 2165995, "node_id": "MDk6TWlsZXN0b25lMjE2NTk5NQ==", "number": 18, "title": "v1.2.2", "description": null, "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 9, "state": "closed", "created_at": "2016-11-30T10:34:24Z", "updated_at": "2017-02-20T14:37:46Z", "due_on": null, "closed_at": "2017-02-20T14:37:46Z"}, "comments": 3, "created_at": "2016-11-09T16:58:53Z", "updated_at": "2016-12-01T13:24:58Z", "closed_at": "2016-12-01T13:24:54Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "[The \"specs\"](http://www.sitemaps.org/protocol.html#submit_robots) do say that the URL should be a \"full URL\":\r\n\r\n> You can specify the location of the Sitemap using a robots.txt file. To do this, simply add the following line including the full URL to the sitemap:\r\n> `Sitemap: http://www.example.com/sitemap.xml`\r\n\r\nBut some robots.txt use relative ones.\r\n\r\nExample: http://www.asos.com/robots.txt\r\n\r\n```\r\nUser-agent: *\r\nSitemap: /sitemap.ashx\r\nSitemap: http://www.asos.com/sitemap.xml\r\nDisallow: /basket/\r\n(...)\r\n```\r\n\r\nSpider:\r\n```\r\nfrom scrapy.spiders import SitemapSpider\r\n\r\n\r\nclass TestSpider(SitemapSpider):\r\n    name = \"test\"\r\n    sitemap_urls = [\r\n        'http://www.asos.com/robots.txt',\r\n    ]\r\n\r\n    def parse(self, response):\r\n        self.logger.info('parsing %r' % response.url)\r\n```\r\nLogs:\r\n\r\n```\r\n$ scrapy runspider spider.py\r\nLinux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.90 Safari/537.36'\r\n2016-11-09 17:46:19 [scrapy] INFO: Scrapy 1.2.1 started (bot: scrapybot)\r\n(...)\r\n2016-11-09 17:46:19 [scrapy] DEBUG: Crawled (200) <GET http://www.asos.com/robots.txt> (referer: None)\r\n2016-11-09 17:46:19 [scrapy] ERROR: Spider error processing <GET http://www.asos.com/robots.txt> (referer: None)\r\nTraceback (most recent call last):\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 102, in iter_errback\r\n    yield next(it)\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py\", line 29, in process_spider_output\r\n    for x in result:\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py\", line 22, in <genexpr>\r\n    return (_set_referer(r) for r in result or ())\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py\", line 37, in <genexpr>\r\n    return (r for r in result or () if _filter(r))\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py\", line 58, in <genexpr>\r\n    return (r for r in result or () if _filter(r))\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/spiders/sitemap.py\", line 36, in _parse_sitemap\r\n    yield Request(url, callback=self._parse_sitemap)\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/http/request/__init__.py\", line 25, in __init__\r\n    self._set_url(url)\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/http/request/__init__.py\", line 57, in _set_url\r\n    raise ValueError('Missing scheme in request url: %s' % self._url)\r\nValueError: Missing scheme in request url: /sitemap.ashx\r\n2016-11-09 17:46:19 [scrapy] INFO: Closing spider (finished)\r\n2016-11-09 17:46:19 [scrapy] INFO: Dumping Scrapy stats:\r\n{'downloader/request_bytes': 291,\r\n 'downloader/request_count': 1,\r\n 'downloader/request_method_count/GET': 1,\r\n 'downloader/response_bytes': 1857,\r\n 'downloader/response_count': 1,\r\n 'downloader/response_status_count/200': 1,\r\n 'finish_reason': 'finished',\r\n 'finish_time': datetime.datetime(2016, 11, 9, 16, 46, 19, 332383),\r\n 'log_count/DEBUG': 2,\r\n 'log_count/ERROR': 1,\r\n 'log_count/INFO': 7,\r\n 'response_received_count': 1,\r\n 'scheduler/dequeued': 1,\r\n 'scheduler/dequeued/memory': 1,\r\n 'scheduler/enqueued': 1,\r\n 'scheduler/enqueued/memory': 1,\r\n 'spider_exceptions/ValueError': 1,\r\n 'start_time': datetime.datetime(2016, 11, 9, 16, 46, 19, 71714)}\r\n2016-11-09 17:46:19 [scrapy] INFO: Spider closed (finished)\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2390/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2390/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2389", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2389/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2389/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2389/events", "html_url": "https://github.com/scrapy/scrapy/issues/2389", "id": 188269789, "node_id": "MDU6SXNzdWUxODgyNjk3ODk=", "number": 2389, "title": "gzip-Content-Encoded sitemap.xml.gz is not parsed", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 470641083, "node_id": "MDU6TGFiZWw0NzA2NDEwODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/in%20progress", "name": "in progress", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/15", "html_url": "https://github.com/scrapy/scrapy/milestone/15", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/15/labels", "id": 1977308, "node_id": "MDk6TWlsZXN0b25lMTk3NzMwOA==", "number": 15, "title": "v1.4", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 67, "state": "closed", "created_at": "2016-09-01T09:43:32Z", "updated_at": "2017-08-28T11:12:21Z", "due_on": null, "closed_at": "2017-08-28T11:12:21Z"}, "comments": 1, "created_at": "2016-11-09T15:07:59Z", "updated_at": "2017-03-07T11:56:55Z", "closed_at": "2017-03-07T11:56:54Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "From https://stackoverflow.com/questions/40499288/python-scrapy-sitemapspider-callbacks-not-being-called\r\n\r\nSitemap spider for http://www.newegg.com/Siteindex_USA.xml fails to parse sub-sitemaps files.\r\n\r\nExcerpt from sitemap file:\r\n\r\n```\r\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\r\n<sitemapindex xmlns=\"http://www.google.com/schemas/sitemap/0.9\">\r\n<sitemap>\r\n<loc>http://www.newegg.com/Sitemap/USA/newegg_sitemap_store01.xml.gz</loc>\r\n<lastmod>2016-11-06</lastmod>\r\n</sitemap>\r\n<sitemap>\r\n<loc>http://www.newegg.com/Sitemap/USA/newegg_sitemap_product01.xml.gz</loc>\r\n<lastmod>2016-11-06</lastmod>\r\n</sitemap>\r\n...\r\n```\r\n\r\nExample spider:\r\n\r\n```\r\nimport scrapy\r\n\r\n\r\nclass NeweggSpider(scrapy.spiders.SitemapSpider):\r\n    name = \"newegg\"\r\n    allowed_domains = [\"newegg.com\"]\r\n    sitemap_urls = ['http://www.newegg.com/Siteindex_USA.xml']\r\n\r\n    def parse(self, response):\r\n        self.logger.info('parsing %r' % response.url)\r\n```\r\n\r\nWith scrapy 1.2, you get the following exceptions:\r\n\r\n```\r\n$ scrapy runspider spider.py \r\n2016-11-09 15:53:10 [scrapy] INFO: Scrapy 1.2.1 started (bot: scrapybot)\r\n(...)\r\n2016-11-09 15:53:10 [scrapy] INFO: Spider opened\r\n2016-11-09 15:53:10 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2016-11-09 15:53:10 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023\r\n2016-11-09 15:53:11 [scrapy] DEBUG: Crawled (200) <GET http://www.newegg.com/Siteindex_USA.xml> (referer: None)\r\n2016-11-09 15:53:11 [scrapy] DEBUG: Crawled (200) <GET http://www.newegg.com/Sitemap/USA/newegg_sitemap_store01.xml.gz> (referer: http://www.newegg.com/Siteindex_USA.xml)\r\n2016-11-09 15:53:11 [scrapy] ERROR: Spider error processing <GET http://www.newegg.com/Sitemap/USA/newegg_sitemap_store01.xml.gz> (referer: http://www.newegg.com/Siteindex_USA.xml)\r\nTraceback (most recent call last):\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 102, in iter_errback\r\n    yield next(it)\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py\", line 29, in process_spider_output\r\n    for x in result:\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py\", line 22, in <genexpr>\r\n    return (_set_referer(r) for r in result or ())\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py\", line 37, in <genexpr>\r\n    return (r for r in result or () if _filter(r))\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py\", line 58, in <genexpr>\r\n    return (r for r in result or () if _filter(r))\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/spiders/sitemap.py\", line 44, in _parse_sitemap\r\n    s = Sitemap(body)\r\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/utils/sitemap.py\", line 17, in __init__\r\n    rt = self._root.tag\r\nAttributeError: 'NoneType' object has no attribute 'tag'\r\n\r\n```\r\n\r\nThe root cause seem to be that the server sends `.xml.gz` files, and gzip-encodes them:\r\n\r\n```\r\nGET /Sitemap/USA/newegg_sitemap_product29.xml.gz HTTP/1.1\r\nAccept-Language: en\r\nAccept-Encoding: gzip,deflate\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\nUser-Agent: Scrapy/1.2.1 (+http://scrapy.org)\r\nHost: www.newegg.com\r\nReferer: http://www.newegg.com/Siteindex_USA.xml\r\n\r\nHTTP/1.1 200 OK\r\nContent-Type: application/x-gzip\r\nLast-Modified: Tue, 08 Nov 2016 18:44:56 GMT\r\nAccept-Ranges: bytes\r\nETag: \"471fb033f039d21:0\"\r\nServer: NEWEGG\r\nx-server-id: 106\r\nX-Served-By: 40015\r\nX-Ver: 08161601\r\nx-newegg-flow: MISS\r\nX-newegg-index: 0\r\nAccept-Ranges: bytes\r\nX-Frame-Options: SAMEORIGIN\r\nVary: Accept-Encoding\r\nContent-Encoding: gzip\r\nExpires: Wed, 09 Nov 2016 14:15:46 GMT\r\nCache-Control: max-age=0, no-cache, no-store\r\nPragma: no-cache\r\nDate: Wed, 09 Nov 2016 14:15:46 GMT\r\nTransfer-Encoding:  chunked\r\nConnection: keep-alive\r\nConnection: Transfer-Encoding\r\n```\r\n\r\nSo scrapy should first gunzip the body to get that \"raw\" `.xml.gz` file, and then gunzip again to get a valid XML sitemap file.\r\n\r\nBut [`HttpCompressionMiddleware` does not touch the response](https://github.com/scrapy/scrapy/blob/129421c7e31b89b9b0f9c5f7d8ae59e47df36091/scrapy/downloadermiddlewares/httpcompression.py#L28) since `is_gzipped()` returns `True`, leaving it for subsequent layers to interpret.", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2389/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 1, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2389/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2377", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2377/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2377/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2377/events", "html_url": "https://github.com/scrapy/scrapy/issues/2377", "id": 186852490, "node_id": "MDU6SXNzdWUxODY4NTI0OTA=", "number": 2377, "title": "Invalid Codepoint in robots.txt", "user": {"login": "mohmad-null", "id": 22342282, "node_id": "MDQ6VXNlcjIyMzQyMjgy", "avatar_url": "https://avatars.githubusercontent.com/u/22342282?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mohmad-null", "html_url": "https://github.com/mohmad-null", "followers_url": "https://api.github.com/users/mohmad-null/followers", "following_url": "https://api.github.com/users/mohmad-null/following{/other_user}", "gists_url": "https://api.github.com/users/mohmad-null/gists{/gist_id}", "starred_url": "https://api.github.com/users/mohmad-null/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mohmad-null/subscriptions", "organizations_url": "https://api.github.com/users/mohmad-null/orgs", "repos_url": "https://api.github.com/users/mohmad-null/repos", "events_url": "https://api.github.com/users/mohmad-null/events{/privacy}", "received_events_url": "https://api.github.com/users/mohmad-null/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2016-11-02T16:33:24Z", "updated_at": "2016-11-10T10:32:09Z", "closed_at": "2016-11-10T10:32:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "During my scraping I had this error get thrown.\r\n\r\nPages that triggered it:\r\nhttps://www.gpo.gov:/robots.txt\r\nhttps://www.gpo.gov:/fdsys/pkg/FR-2006-12-28/html/E6-22242.htm\r\nhttps://www.gpo.gov:/fdsys/pkg/FR-2006-07-20/html/E6-11541.htm\r\nhttps://www.gpo.gov:/fdsys/pkg/FR-2006-05-10/html/06-4319.htm\r\nhttps://www.gpo.gov:/fdsys/pkg/FR-2006-08-02/html/E6-12432.htm\r\n\r\nPython 2.7.12\r\nScrapy 1.2.1\r\n\r\n\r\n```\r\n2016-11-02 15:30:04 [scrapy] ERROR: Error downloading <GET https://www.gpo.gov:/robots.txt>: Codepoint U+003A at position 4 of u'gov:' not allowed\r\nTraceback (most recent call last):\r\n  File \"c:\\python27_internet\\lib\\site-packages\\twisted\\internet\\defer.py\", line 1183, in _inlineCallbacks\r\n    result = result.throwExceptionIntoGenerator(g)\r\n  File \"c:\\python27_internet\\lib\\site-packages\\twisted\\python\\failure.py\", line 389, in throwExceptionIntoGenerator\r\n    return g.throw(self.type, self.value, self.tb)\r\n  File \"c:\\python27_internet\\lib\\site-packages\\scrapy\\core\\downloader\\middleware.py\", line 43, in process_request\r\n    defer.returnValue((yield download_func(request=request,spider=spider)))\r\n  File \"c:\\python27_internet\\lib\\site-packages\\scrapy\\utils\\defer.py\", line 45, in mustbe_deferred\r\n    result = f(*args, **kw)\r\n  File \"c:\\python27_internet\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\__init__.py\", line 65, in download_request\r\n    return handler.download_request(request, spider)\r\n  File \"c:\\python27_internet\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\http11.py\", line 60, in download_request\r\n    return agent.download_request(request)\r\n  File \"c:\\python27_internet\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\http11.py\", line 285, in download_request\r\n    method, to_bytes(url, encoding='ascii'), headers, bodyproducer)\r\n  File \"c:\\python27_internet\\lib\\site-packages\\twisted\\web\\client.py\", line 1596, in request\r\n    endpoint = self._getEndpoint(parsedURI)\r\n  File \"c:\\python27_internet\\lib\\site-packages\\twisted\\web\\client.py\", line 1580, in _getEndpoint\r\n    return self._endpointFactory.endpointForURI(uri)\r\n  File \"c:\\python27_internet\\lib\\site-packages\\twisted\\web\\client.py\", line 1456, in endpointForURI\r\n    uri.port)\r\n  File \"c:\\python27_internet\\lib\\site-packages\\scrapy\\core\\downloader\\contextfactory.py\", line 59, in creatorForNetloc\r\n    return ScrapyClientTLSOptions(hostname.decode(\"ascii\"), self.getContext())\r\n  File \"c:\\python27_internet\\lib\\site-packages\\twisted\\internet\\_sslverify.py\", line 1198, in __init__\r\n    self._hostnameBytes = _idnaBytes(hostname)\r\n  File \"c:\\python27_internet\\lib\\site-packages\\twisted\\internet\\_sslverify.py\", line 86, in _idnaBytes\r\n    return idna.encode(text)\r\n  File \"c:\\python27_internet\\lib\\site-packages\\idna\\core.py\", line 355, in encode\r\n    result.append(alabel(label))\r\n  File \"c:\\python27_internet\\lib\\site-packages\\idna\\core.py\", line 276, in alabel\r\n    check_label(label)\r\n  File \"c:\\python27_internet\\lib\\site-packages\\idna\\core.py\", line 253, in check_label\r\n    raise InvalidCodepoint('Codepoint {0} at position {1} of {2} not allowed'.format(_unot(cp_value), pos+1, repr(label)))\r\nInvalidCodepoint: Codepoint U+003A at position 4 of u'gov:' not allowed\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2377/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2377/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2373", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2373/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2373/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2373/events", "html_url": "https://github.com/scrapy/scrapy/issues/2373", "id": 186798128, "node_id": "MDU6SXNzdWUxODY3OTgxMjg=", "number": 2373, "title": "Wikipedia robots.txt raises exceptions", "user": {"login": "mohmad-null", "id": 22342282, "node_id": "MDQ6VXNlcjIyMzQyMjgy", "avatar_url": "https://avatars.githubusercontent.com/u/22342282?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mohmad-null", "html_url": "https://github.com/mohmad-null", "followers_url": "https://api.github.com/users/mohmad-null/followers", "following_url": "https://api.github.com/users/mohmad-null/following{/other_user}", "gists_url": "https://api.github.com/users/mohmad-null/gists{/gist_id}", "starred_url": "https://api.github.com/users/mohmad-null/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mohmad-null/subscriptions", "organizations_url": "https://api.github.com/users/mohmad-null/orgs", "repos_url": "https://api.github.com/users/mohmad-null/repos", "events_url": "https://api.github.com/users/mohmad-null/events{/privacy}", "received_events_url": "https://api.github.com/users/mohmad-null/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/18", "html_url": "https://github.com/scrapy/scrapy/milestone/18", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/18/labels", "id": 2165995, "node_id": "MDk6TWlsZXN0b25lMjE2NTk5NQ==", "number": 18, "title": "v1.2.2", "description": null, "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 9, "state": "closed", "created_at": "2016-11-30T10:34:24Z", "updated_at": "2017-02-20T14:37:46Z", "due_on": null, "closed_at": "2017-02-20T14:37:46Z"}, "comments": 7, "created_at": "2016-11-02T13:18:27Z", "updated_at": "2016-12-01T20:43:27Z", "closed_at": "2016-12-01T20:43:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm scraping a page which in turn links to wikipedia.\r\n\r\nBut the wikipedia robots.txt is creating some errors/exceptions as below.\r\n\r\nPython 2.7.12\r\nScrapy 1.2.1\r\n\r\n```\r\n2016-11-02 13:13:18 [scrapy] DEBUG: Crawled (200) <GET https://en.wikipedia.org/robots.txt> (referer: None)\r\n2016-11-02 13:13:18 [py.warnings] WARNING: C:\\Python27\\lib\\urllib.py:1303: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\r\n  return ''.join(map(quoter, s))\r\n\r\n2016-11-02 13:13:18 [scrapy] ERROR: Error downloading <GET http://en.wikipedia.org/robots.txt>: u'\\xd8'\r\nTraceback (most recent call last):\r\n  File \"C:\\Python27\\lib\\site-packages\\twisted\\internet\\defer.py\", line 587, in _runCallbacks\r\n    current.result = callback(current.result, *args, **kw)\r\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\downloadermiddlewares\\robotstxt.py\", line 97, in _parse_robots\r\n    rp.parse(body.splitlines())\r\n  File \"C:\\Python27\\lib\\robotparser.py\", line 120, in parse\r\n    entry.rulelines.append(RuleLine(line[1], False))\r\n  File \"C:\\Python27\\lib\\robotparser.py\", line 174, in __init__\r\n    self.path = urllib.quote(path)\r\n  File \"C:\\Python27\\lib\\urllib.py\", line 1303, in quote\r\n    return ''.join(map(quoter, s))\r\nKeyError: u'\\xd8'\r\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2373/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2373/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2362", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2362/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2362/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2362/events", "html_url": "https://github.com/scrapy/scrapy/issues/2362", "id": 185430692, "node_id": "MDU6SXNzdWUxODU0MzA2OTI=", "number": 2362, "title": "Unhelpful traces when there's an error in the pipeline", "user": {"login": "mohmad-null", "id": 22342282, "node_id": "MDQ6VXNlcjIyMzQyMjgy", "avatar_url": "https://avatars.githubusercontent.com/u/22342282?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mohmad-null", "html_url": "https://github.com/mohmad-null", "followers_url": "https://api.github.com/users/mohmad-null/followers", "following_url": "https://api.github.com/users/mohmad-null/following{/other_user}", "gists_url": "https://api.github.com/users/mohmad-null/gists{/gist_id}", "starred_url": "https://api.github.com/users/mohmad-null/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mohmad-null/subscriptions", "organizations_url": "https://api.github.com/users/mohmad-null/orgs", "repos_url": "https://api.github.com/users/mohmad-null/repos", "events_url": "https://api.github.com/users/mohmad-null/events{/privacy}", "received_events_url": "https://api.github.com/users/mohmad-null/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 281088273, "node_id": "MDU6TGFiZWwyODEwODgyNzM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/help%20wanted", "name": "help wanted", "color": "009800", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2016-10-26T15:37:43Z", "updated_at": "2016-11-08T12:33:40Z", "closed_at": "2016-11-08T12:33:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "I had a pretty basic error in my pipeline (i'd forgotten to `import os`).\nHowever, rather than get the customary `NameError: name 'os' is not defined`, I instead receive a long, drawn-out Twisted error:\n\n```\n2016-10-26 16:34:15 [scrapy] INFO: Closing spider (shutdown)\nUnhandled error in Deferred:\n2016-10-26 16:34:15 [twisted] CRITICAL: Unhandled error in Deferred:\n\n\nTraceback (most recent call last):\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\commands\\crawl.py\", line 57, in run\n    self.crawler_process.crawl(spname, **opts.spargs)\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\crawler.py\", line 163, in crawl\n    return self._crawl(crawler, *args, **kwargs)\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\crawler.py\", line 167, in _crawl\n    d = crawler.crawl(*args, **kwargs)\n  File \"C:\\Python27\\lib\\site-packages\\twisted\\internet\\defer.py\", line 1331, in unwindGenerator\n    return _inlineCallbacks(None, gen, Deferred())\n--- <exception caught here> ---\n  File \"C:\\Python27\\lib\\site-packages\\twisted\\internet\\defer.py\", line 1183, in _inlineCallbacks\n    result = result.throwExceptionIntoGenerator(g)\n  File \"C:\\Python27\\lib\\site-packages\\twisted\\python\\failure.py\", line 389, in throwExceptionIntoGenerator\n    return g.throw(self.type, self.value, self.tb)\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\crawler.py\", line 87, in crawl\n    yield self.engine.close()\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\core\\engine.py\", line 100, in close\n    return self._close_all_spiders()\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\core\\engine.py\", line 340, in _close_all_spiders\n    dfds = [self.close_spider(s, reason='shutdown') for s in self.open_spiders]\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\core\\engine.py\", line 298, in close_spider\n    dfd = slot.close()\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\core\\engine.py\", line 44, in close\n    self._maybe_fire_closing()\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\core\\engine.py\", line 51, in _maybe_fire_closing\n    self.heartbeat.stop()\n  File \"C:\\Python27\\lib\\site-packages\\twisted\\internet\\task.py\", line 202, in stop\n    assert self.running, (\"Tried to stop a LoopingCall that was \"\nexceptions.AssertionError: Tried to stop a LoopingCall that was not running.\n2016-10-26 16:34:15 [twisted] CRITICAL: \nTraceback (most recent call last):\n  File \"C:\\Python27\\lib\\site-packages\\twisted\\internet\\defer.py\", line 1183, in _inlineCallbacks\n    result = result.throwExceptionIntoGenerator(g)\n  File \"C:\\Python27\\lib\\site-packages\\twisted\\python\\failure.py\", line 389, in throwExceptionIntoGenerator\n    return g.throw(self.type, self.value, self.tb)\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\crawler.py\", line 87, in crawl\n    yield self.engine.close()\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\core\\engine.py\", line 100, in close\n    return self._close_all_spiders()\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\core\\engine.py\", line 340, in _close_all_spiders\n    dfds = [self.close_spider(s, reason='shutdown') for s in self.open_spiders]\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\core\\engine.py\", line 298, in close_spider\n    dfd = slot.close()\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\core\\engine.py\", line 44, in close\n    self._maybe_fire_closing()\n  File \"C:\\Python27\\lib\\site-packages\\scrapy\\core\\engine.py\", line 51, in _maybe_fire_closing\n    self.heartbeat.stop()\n  File \"C:\\Python27\\lib\\site-packages\\twisted\\internet\\task.py\", line 202, in stop\n    assert self.running, (\"Tried to stop a LoopingCall that was \"\nAssertionError: Tried to stop a LoopingCall that was not running.\n\n```\n\nWithout useful traceroutes this is going to make it _very_ difficult to develop a spider using pipelines.\n\nCould scrapy be made to more transparently handle failures in pipelines please? Thanks.\n\nScrapy 1.2\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2362/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2362/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2342", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2342/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2342/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2342/events", "html_url": "https://github.com/scrapy/scrapy/issues/2342", "id": 184239128, "node_id": "MDU6SXNzdWUxODQyMzkxMjg=", "number": 2342, "title": "Anonymous FTP download fails with KeyError: ftp_user", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 470641083, "node_id": "MDU6TGFiZWw0NzA2NDEwODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/in%20progress", "name": "in progress", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/15", "html_url": "https://github.com/scrapy/scrapy/milestone/15", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/15/labels", "id": 1977308, "node_id": "MDk6TWlsZXN0b25lMTk3NzMwOA==", "number": 15, "title": "v1.4", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 67, "state": "closed", "created_at": "2016-09-01T09:43:32Z", "updated_at": "2017-08-28T11:12:21Z", "due_on": null, "closed_at": "2017-08-28T11:12:21Z"}, "comments": 0, "created_at": "2016-10-20T14:05:08Z", "updated_at": "2017-02-20T17:19:55Z", "closed_at": "2017-02-20T17:19:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Tested with Scrapy 1.2.0\n\n```\n$ scrapy version -v\nScrapy    : 1.2.0\nlxml      : 3.6.4.0\nlibxml2   : 2.9.4\nTwisted   : 16.4.1\nPython    : 2.7.12 (default, Jul  1 2016, 15:12:24) - [GCC 5.4.0 20160609]\npyOpenSSL : 16.1.0 (OpenSSL 1.0.2g  1 Mar 2016)\nPlatform  : Linux-4.4.0-43-generic-x86_64-with-Ubuntu-16.04-xenial\n\n\n$ scrapy shell ftp://ftp.eu.metabrainz.org/pub/musicbrainz/data/fullexport/20161019-001816/MD5SUMS\n2016-10-20 16:01:27 [scrapy] INFO: Scrapy 1.2.0 started (bot: scrapybot)\n(...)\n2016-10-20 16:01:27 [scrapy] INFO: Spider opened\nTraceback (most recent call last):\n  File \"/home/paul/.virtualenvs/scrapy12/bin/scrapy\", line 11, in <module>\n    sys.exit(execute())\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/cmdline.py\", line 142, in execute\n    _run_print_help(parser, _run_command, cmd, args, opts)\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/cmdline.py\", line 88, in _run_print_help\n    func(*a, **kw)\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/cmdline.py\", line 149, in _run_command\n    cmd.run(args, opts)\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/commands/shell.py\", line 71, in run\n    shell.start(url=url)\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/shell.py\", line 47, in start\n    self.fetch(url, spider)\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/scrapy/shell.py\", line 112, in fetch\n    reactor, self._schedule, request, spider)\n  File \"/home/paul/.virtualenvs/scrapy12/local/lib/python2.7/site-packages/twisted/internet/threads.py\", line 122, in blockingCallFromThread\n    result.raiseException()\n  File \"<string>\", line 2, in raiseException\nKeyError: 'ftp_user'\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2342/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2342/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2323", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2323/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2323/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2323/events", "html_url": "https://github.com/scrapy/scrapy/issues/2323", "id": 182581454, "node_id": "MDU6SXNzdWUxODI1ODE0NTQ=", "number": 2323, "title": "`LxmlLinkExtractor` fails handling unicode netlocs in Python2", "user": {"login": "starrify", "id": 388828, "node_id": "MDQ6VXNlcjM4ODgyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/388828?v=4", "gravatar_id": "", "url": "https://api.github.com/users/starrify", "html_url": "https://github.com/starrify", "followers_url": "https://api.github.com/users/starrify/followers", "following_url": "https://api.github.com/users/starrify/following{/other_user}", "gists_url": "https://api.github.com/users/starrify/gists{/gist_id}", "starred_url": "https://api.github.com/users/starrify/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/starrify/subscriptions", "organizations_url": "https://api.github.com/users/starrify/orgs", "repos_url": "https://api.github.com/users/starrify/repos", "events_url": "https://api.github.com/users/starrify/events{/privacy}", "received_events_url": "https://api.github.com/users/starrify/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 388324163, "node_id": "MDU6TGFiZWwzODgzMjQxNjM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/link%20extraction", "name": "link extraction", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2016-10-12T17:10:55Z", "updated_at": "2019-12-24T13:42:25Z", "closed_at": "2019-12-24T13:42:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Affected version:**\ndc1f9ad\n\n**Affected Python version:**\nPython 2 only\n\n**Steps to reproduce:**\n\n``` Python\n>>> import scrapy.http\n>>> response = scrapy.http.TextResponse(url='http://foo.com', body=u'<a href=\"http://foo\\u263a\">', encoding='utf8')\n>>> response.css('a::attr(href)').extract()\n[u'http://foo\\u263a']\n>>> import scrapy.linkextractors\n>>> extractor = scrapy.linkextractors.LinkExtractor()\n>>> extractor.extract_links(response)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/tmp/virtualenv/src/scrapy/scrapy/linkextractors/lxmlhtml.py\", line 111, in extract_links\n    all_links.extend(self._process_links(links))\n  File \"/tmp/virtualenv/src/scrapy/scrapy/linkextractors/__init__.py\", line 104, in _process_links\n    link.url = canonicalize_url(urlparse(link.url))\n  File \"/tmp/virtualenv/lib/python2.7/site-packages/w3lib/url.py\", line 354, in canonicalize_url\n    parse_url(url), encoding=encoding)\n  File \"/tmp/virtualenv/lib/python2.7/site-packages/w3lib/url.py\", line 298, in _safe_ParseResult\n    netloc = parts.netloc.encode('idna')\n  File \"/tmp/virtualenv/lib/python2.7/encodings/idna.py\", line 164, in encode\n    result.append(ToASCII(label))\n  File \"/tmp/virtualenv/lib/python2.7/encodings/idna.py\", line 76, in ToASCII\n    label = nameprep(label)\n  File \"/tmp/virtualenv/lib/python2.7/encodings/idna.py\", line 21, in nameprep\n    newlabel.append(stringprep.map_table_b2(c))\n  File \"/usr/lib64/python2.7/stringprep.py\", line 197, in map_table_b2\n    b = unicodedata.normalize(\"NFKC\", al)\nTypeError: normalize() argument 2 must be unicode, not str\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2323/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2323/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2321", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2321/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2321/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2321/events", "html_url": "https://github.com/scrapy/scrapy/issues/2321", "id": 182494128, "node_id": "MDU6SXNzdWUxODI0OTQxMjg=", "number": 2321, "title": "Decoding of \"Location\" header on redirects using latin-1 can be wrong", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/16", "html_url": "https://github.com/scrapy/scrapy/milestone/16", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/16/labels", "id": 2054459, "node_id": "MDk6TWlsZXN0b25lMjA1NDQ1OQ==", "number": 16, "title": "v1.2.1", "description": null, "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 4, "state": "closed", "created_at": "2016-10-07T10:35:33Z", "updated_at": "2016-11-16T16:09:51Z", "due_on": null, "closed_at": "2016-11-16T16:09:51Z"}, "comments": 0, "created_at": "2016-10-12T10:48:27Z", "updated_at": "2016-10-20T02:26:12Z", "closed_at": "2016-10-20T02:26:12Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Web servers [should use encoded URLs in their \"Location\" headers](http://stackoverflow.com/questions/7654207/what-charset-should-be-used-for-a-location-header-in-a-301-response), but [they don't always do](http://stackoverflow.com/questions/4400678/what-character-encoding-should-i-use-for-a-http-header/4410331#4410331).\n\nThis website for example, for this URL http://www.yjc.ir/fa/news/1815565/\nredirects to www.yjc.ir/fa/news/1815565/\u0627\u0639\u0632\u0627\u0645-\u0643\u0648\u0647\u0646\u0648\u0631\u062f\u0627\u0646-\u0627\u064a\u0631\u0627\u0646\u064a-\u0628\u0647-\u0643\u064a\u0644\u064a\u0645\u0627\u0646\u062c\u0627\u0631\u0648\n\nbut the bytes received are UTF-8 encoded, and not percent-escaped:\n\n```\n'Location': ['/fa/news/1815565/\\xd8\\xa7\\xd8\\xb9\\xd8\\xb2\\xd8\\xa7\\xd9\\x85-\\xd9\\x83\\xd9\\x88\\xd9\\x87\\xd9\\x86\\xd9\\x88\\xd8\\xb1\\xd8\\xaf\\xd8\\xa7\\xd9\\x86-\\xd8\\xa7\\xd9\\x8a\\xd8\\xb1\\xd8\\xa7\\xd9\\x86\\xd9\\x8a-\\xd8\\xa8\\xd9\\x87-\\xd9\\x83\\xd9\\x8a\\xd9\\x84\\xd9\\x8a\\xd9\\x85\\xd8\\xa7\\xd9\\x86\\xd8\\xac\\xd8\\xa7\\xd8\\xb1\\xd9\\x88']\n```\n\n`RedirectMiddleware` decodes the header as \"latin1\" ([this is new in Scrapy 1.1](https://github.com/scrapy/scrapy/pull/1488)) and issues a request to http://www.yjc.ir/fa/news/1815565/%C3%98%C2%A7%C3%98%C2%B9%C3%98%C2%B2%C3%98%C2%A7%C3%99%C2%85-%C3%99%C2%83%C3%99%C2%88%C3%99%C2%87%C3%99%C2%86%C3%99%C2%88%C3%98%C2%B1%C3%98%C2%AF%C3%98%C2%A7%C3%99%C2%86-%C3%98%C2%A7%C3%99%C2%8A%C3%98%C2%B1%C3%98%C2%A7%C3%99%C2%86%C3%99%C2%8A-%C3%98%C2%A8%C3%99%C2%87-%C3%99%C2%83%C3%99%C2%8A%C3%99%C2%84%C3%99%C2%8A%C3%99%C2%85%C3%98%C2%A7%C3%99%C2%86%C3%98%C2%AC%C3%98%C2%A7%C3%98%C2%B1%C3%99%C2%88\n\nwhich is not correct.\n\n`curl -i \"http://www.yjc.ir/fa/news/1815565/\"` and `wget http://www.yjc.ir/fa/news/1815565/` handle it just fine and correctly follow http://www.yjc.ir/fa/news/1815565/%D8%A7%D8%B9%D8%B2%D8%A7%D9%85-%D9%83%D9%88%D9%87%D9%86%D9%88%D8%B1%D8%AF%D8%A7%D9%86-%D8%A7%D9%8A%D8%B1%D8%A7%D9%86%D9%8A-%D8%A8%D9%87-%D9%83%D9%8A%D9%84%D9%8A%D9%85%D8%A7%D9%86%D8%AC%D8%A7%D8%B1%D9%88\n\n(curl [fixed the issue not too long ago](https://github.com/curl/curl/issues/473) )\n\nThanks @stav for reporting!\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2321/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2321/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2311", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2311/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2311/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2311/events", "html_url": "https://github.com/scrapy/scrapy/issues/2311", "id": 181514715, "node_id": "MDU6SXNzdWUxODE1MTQ3MTU=", "number": 2311, "title": "SSL error", "user": {"login": "ricoxor", "id": 3131462, "node_id": "MDQ6VXNlcjMxMzE0NjI=", "avatar_url": "https://avatars.githubusercontent.com/u/3131462?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ricoxor", "html_url": "https://github.com/ricoxor", "followers_url": "https://api.github.com/users/ricoxor/followers", "following_url": "https://api.github.com/users/ricoxor/following{/other_user}", "gists_url": "https://api.github.com/users/ricoxor/gists{/gist_id}", "starred_url": "https://api.github.com/users/ricoxor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ricoxor/subscriptions", "organizations_url": "https://api.github.com/users/ricoxor/orgs", "repos_url": "https://api.github.com/users/ricoxor/repos", "events_url": "https://api.github.com/users/ricoxor/events{/privacy}", "received_events_url": "https://api.github.com/users/ricoxor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 320345582, "node_id": "MDU6TGFiZWwzMjAzNDU1ODI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/https", "name": "https", "color": "101e89", "default": false, "description": ""}, {"id": 326439252, "node_id": "MDU6TGFiZWwzMjY0MzkyNTI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/security", "name": "security", "color": "e11d21", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/16", "html_url": "https://github.com/scrapy/scrapy/milestone/16", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/16/labels", "id": 2054459, "node_id": "MDk6TWlsZXN0b25lMjA1NDQ1OQ==", "number": 16, "title": "v1.2.1", "description": null, "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 4, "state": "closed", "created_at": "2016-10-07T10:35:33Z", "updated_at": "2016-11-16T16:09:51Z", "due_on": null, "closed_at": "2016-11-16T16:09:51Z"}, "comments": 8, "created_at": "2016-10-06T20:17:01Z", "updated_at": "2017-12-03T03:52:18Z", "closed_at": "2016-10-17T09:44:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have lot of errors with SSL websites.\nFor exemple, when I call : `scrapy shell https://subscribe.wsj.com/printpack/`\n\nI have this error : \n\n```\n2016-10-06 22:15:40 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6043\n2016-10-06 22:15:40 [scrapy] INFO: Spider opened\n2016-10-06 22:15:40 [scrapy] DEBUG: Retrying <GET https://subscribe.wsj.com/printpack/> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'sslv3 alert handshake failure')]>]\n2016-10-06 22:15:40 [scrapy] DEBUG: Retrying <GET https://subscribe.wsj.com/printpack/> (failed 2 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'sslv3 alert handshake failure')]>]\n2016-10-06 22:15:40 [scrapy] DEBUG: Gave up retrying <GET https://subscribe.wsj.com/printpack/> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'sslv3 alert handshake failure')]>]\nTraceback (most recent call last):\n  File \"/usr/local/bin/scrapy\", line 11, in <module>\n    sys.exit(execute())\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/cmdline.py\", line 142, in execute\n    _run_print_help(parser, _run_command, cmd, args, opts)\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/cmdline.py\", line 88, in _run_print_help\n    func(*a, **kw)\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/cmdline.py\", line 149, in _run_command\n    cmd.run(args, opts)\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/commands/shell.py\", line 71, in run\n    shell.start(url=url)\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/shell.py\", line 47, in start\n    self.fetch(url, spider)\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/shell.py\", line 112, in fetch\n    reactor, self._schedule, request, spider)\n  File \"/usr/local/lib/python2.7/dist-packages/twisted/internet/threads.py\", line 122, in blockingCallFromThread\n    result.raiseException()\n  File \"<string>\", line 2, in raiseException\ntwisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'sslv3 alert handshake failure')]>]\n```\n\nHow fix that ?\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2311/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2311/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2304", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2304/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2304/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2304/events", "html_url": "https://github.com/scrapy/scrapy/issues/2304", "id": 180981505, "node_id": "MDU6SXNzdWUxODA5ODE1MDU=", "number": 2304, "title": "TypeError: normalize() argument 2 must be unicode, not str", "user": {"login": "ricoxor", "id": 3131462, "node_id": "MDQ6VXNlcjMxMzE0NjI=", "avatar_url": "https://avatars.githubusercontent.com/u/3131462?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ricoxor", "html_url": "https://github.com/ricoxor", "followers_url": "https://api.github.com/users/ricoxor/followers", "following_url": "https://api.github.com/users/ricoxor/following{/other_user}", "gists_url": "https://api.github.com/users/ricoxor/gists{/gist_id}", "starred_url": "https://api.github.com/users/ricoxor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ricoxor/subscriptions", "organizations_url": "https://api.github.com/users/ricoxor/orgs", "repos_url": "https://api.github.com/users/ricoxor/repos", "events_url": "https://api.github.com/users/ricoxor/events{/privacy}", "received_events_url": "https://api.github.com/users/ricoxor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2016-10-04T19:23:20Z", "updated_at": "2016-10-05T11:20:00Z", "closed_at": "2016-10-05T11:20:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "My crawler do lot of errors like this : \n\n```\n2016-10-04 21:21:24 [scrapy] ERROR: Spider error processing <GET http://xxxx.com/> (referer:)\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py\", line 102, in iter_errback\n    yield next(it)\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/offsite.py\", line 29, in process_spider_output\n    for x in result:\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/referer.py\", line 22, in <genexpr>\n    return (_set_referer(r) for r in result or ())\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/urllength.py\", line 37, in <genexpr>\n    return (r for r in result or () if _filter(r))\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/spidermiddlewares/depth.py\", line 58, in <genexpr>\n    return (r for r in result or () if _filter(r))\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py\", line 78, in _parse_response\n    for request_or_item in self._requests_to_follow(response):\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/spiders/crawl.py\", line 56, in _requests_to_follow\n    links = [lnk for lnk in rule.link_extractor.extract_links(response)\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/linkextractors/lxmlhtml.py\", line 111, in extract_links\n    all_links.extend(self._process_links(links))\n  File \"/usr/local/lib/python2.7/dist-packages/scrapy/linkextractors/__init__.py\", line 104, in _process_links\n    link.url = canonicalize_url(urlparse(link.url))\n  File \"/usr/local/lib/python2.7/dist-packages/w3lib/url.py\", line 354, in canonicalize_url\n    parse_url(url), encoding=encoding)\n  File \"/usr/local/lib/python2.7/dist-packages/w3lib/url.py\", line 298, in _safe_ParseResult\n    netloc = parts.netloc.encode('idna')\n  File \"/usr/lib/python2.7/encodings/idna.py\", line 164, in encode\n    result.append(ToASCII(label))\n  File \"/usr/lib/python2.7/encodings/idna.py\", line 76, in ToASCII\n    label = nameprep(label)\n  File \"/usr/lib/python2.7/encodings/idna.py\", line 21, in nameprep\n    newlabel.append(stringprep.map_table_b2(c))\n  File \"/usr/lib/python2.7/stringprep.py\", line 197, in map_table_b2\n    b = unicodedata.normalize(\"NFKC\", al)\nTypeError: normalize() argument 2 must be unicode, not str\n```\n\nCan someone help me to fix that ?\nThank's\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2304/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2304/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2199", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2199/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2199/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2199/events", "html_url": "https://github.com/scrapy/scrapy/issues/2199", "id": 173140688, "node_id": "MDU6SXNzdWUxNzMxNDA2ODg=", "number": 2199, "title": "there is frequent logging error while i scrap web pages", "user": {"login": "Canidy", "id": 9302875, "node_id": "MDQ6VXNlcjkzMDI4NzU=", "avatar_url": "https://avatars.githubusercontent.com/u/9302875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Canidy", "html_url": "https://github.com/Canidy", "followers_url": "https://api.github.com/users/Canidy/followers", "following_url": "https://api.github.com/users/Canidy/following{/other_user}", "gists_url": "https://api.github.com/users/Canidy/gists{/gist_id}", "starred_url": "https://api.github.com/users/Canidy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Canidy/subscriptions", "organizations_url": "https://api.github.com/users/Canidy/orgs", "repos_url": "https://api.github.com/users/Canidy/repos", "events_url": "https://api.github.com/users/Canidy/events{/privacy}", "received_events_url": "https://api.github.com/users/Canidy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 317415181, "node_id": "MDU6TGFiZWwzMTc0MTUxODE=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/logging", "name": "logging", "color": "fbca04", "default": false, "description": null}, {"id": 443054750, "node_id": "MDU6TGFiZWw0NDMwNTQ3NTA=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/not%20reproducible", "name": "not reproducible", "color": "f9d0c4", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2016-08-25T08:18:27Z", "updated_at": "2018-02-15T17:18:03Z", "closed_at": "2018-02-15T16:37:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "Logged from file retry.py, line 68\nTraceback (most recent call last):\n  File \"c:\\python27\\lib\\logging__init__.py\", line 884, in emit\n    stream.write(fs % msg.encode(\"UTF-8\"))\nUnicodeDecodeError: 'utf8' codec can't decode byte 0xd3 in position 234: invalid continuation byte\nLogged from file retry.py, line 68\nTraceback (most recent call last):\n  File \"c:\\python27\\lib\\logging__init__.py\", line 884, in emit\n    stream.write(fs % msg.encode(\"UTF-8\"))\nUnicodeDecodeError: 'utf8' codec can't decode byte 0xd3 in position 234: invalid continuation byte\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2199/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2199/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2198", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2198/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2198/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2198/events", "html_url": "https://github.com/scrapy/scrapy/issues/2198", "id": 173139911, "node_id": "MDU6SXNzdWUxNzMxMzk5MTE=", "number": 2198, "title": "Custom ImagesPipeline doesn't generate thumbnails", "user": {"login": "briehanlombaard", "id": 375716, "node_id": "MDQ6VXNlcjM3NTcxNg==", "avatar_url": "https://avatars.githubusercontent.com/u/375716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/briehanlombaard", "html_url": "https://github.com/briehanlombaard", "followers_url": "https://api.github.com/users/briehanlombaard/followers", "following_url": "https://api.github.com/users/briehanlombaard/following{/other_user}", "gists_url": "https://api.github.com/users/briehanlombaard/gists{/gist_id}", "starred_url": "https://api.github.com/users/briehanlombaard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/briehanlombaard/subscriptions", "organizations_url": "https://api.github.com/users/briehanlombaard/orgs", "repos_url": "https://api.github.com/users/briehanlombaard/repos", "events_url": "https://api.github.com/users/briehanlombaard/events{/privacy}", "received_events_url": "https://api.github.com/users/briehanlombaard/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/14", "html_url": "https://github.com/scrapy/scrapy/milestone/14", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/14/labels", "id": 1964977, "node_id": "MDk6TWlsZXN0b25lMTk2NDk3Nw==", "number": 14, "title": "v1.1.3", "description": null, "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 3, "state": "closed", "created_at": "2016-08-26T11:55:41Z", "updated_at": "2016-09-26T10:37:28Z", "due_on": null, "closed_at": "2016-09-26T10:37:28Z"}, "comments": 6, "created_at": "2016-08-25T08:13:43Z", "updated_at": "2016-09-19T16:43:52Z", "closed_at": "2016-09-19T16:43:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "For some reason, when using a customised ImagesPipeline thumbnails are no longer generated. This seems to be the case for 1.1.1 and 1.1.2 but not for 1.0.0 so somewhere between those releases something must have changed.\n\nThis [example](https://gist.github.com/briehanlombaard/b19885f99b9ee26363070fd9883695b9) should reproduce the problem.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2198/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2198/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2162", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2162/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2162/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2162/events", "html_url": "https://github.com/scrapy/scrapy/issues/2162", "id": 168824226, "node_id": "MDU6SXNzdWUxNjg4MjQyMjY=", "number": 2162, "title": "Error load chunked xls-file", "user": {"login": "tonal", "id": 316216, "node_id": "MDQ6VXNlcjMxNjIxNg==", "avatar_url": "https://avatars.githubusercontent.com/u/316216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tonal", "html_url": "https://github.com/tonal", "followers_url": "https://api.github.com/users/tonal/followers", "following_url": "https://api.github.com/users/tonal/following{/other_user}", "gists_url": "https://api.github.com/users/tonal/gists{/gist_id}", "starred_url": "https://api.github.com/users/tonal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tonal/subscriptions", "organizations_url": "https://api.github.com/users/tonal/orgs", "repos_url": "https://api.github.com/users/tonal/repos", "events_url": "https://api.github.com/users/tonal/events{/privacy}", "received_events_url": "https://api.github.com/users/tonal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 470641083, "node_id": "MDU6TGFiZWw0NzA2NDEwODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/in%20progress", "name": "in progress", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2016-08-02T08:09:36Z", "updated_at": "2017-03-07T11:56:55Z", "closed_at": "2017-03-07T11:56:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I try get xls-file from http://www.wilo.ru/no_cache/glavnaja-stranica/library/dokumentacija/prais-list/?cid=108257&did=20858&sechash=27bdca8a\nBut scrapy load only first part:\n\n```\n$ scrapy fetch 'http://www.wilo.ru/no_cache/glavnaja-stranica/library/dokumentacija/prais-list/?cid=108257&did=20858&sechash=27bdca8a' > ddd.xls\n2016-08-02 15:04:24 [scrapy] INFO: Scrapy 1.1.1 started (bot: scrapybot)\n2016-08-02 15:04:24 [scrapy] INFO: Overridden settings: {}\n2016-08-02 15:04:24 [scrapy] INFO: Enabled extensions:\n['scrapy.extensions.logstats.LogStats',\n 'scrapy.extensions.telnet.TelnetConsole',\n 'scrapy.extensions.corestats.CoreStats']\n2016-08-02 15:04:24 [scrapy] INFO: Enabled downloader middlewares:\n['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n2016-08-02 15:04:24 [scrapy] INFO: Enabled spider middlewares:\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n2016-08-02 15:04:24 [scrapy] INFO: Enabled item pipelines:\n[]\n2016-08-02 15:04:24 [scrapy] INFO: Spider opened\n2016-08-02 15:04:24 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2016-08-02 15:04:24 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023\n2016-08-02 15:04:27 [scrapy] DEBUG: Crawled (200) <GET http://www.wilo.ru/no_cache/glavnaja-stranica/library/dokumentacija/prais-list/?cid=108257&did=20858&sechash=27bdca8a> (referer: None)\n2016-08-02 15:04:27 [scrapy] INFO: Closing spider (finished)\n2016-08-02 15:04:27 [scrapy] INFO: Dumping Scrapy stats:\n{'downloader/request_bytes': 307,\n 'downloader/request_count': 1,\n 'downloader/request_method_count/GET': 1,\n 'downloader/response_bytes': 928590,\n 'downloader/response_count': 1,\n 'downloader/response_status_count/200': 1,\n 'finish_reason': 'finished',\n 'finish_time': datetime.datetime(2016, 8, 2, 8, 4, 27, 849093),\n 'log_count/DEBUG': 2,\n 'log_count/INFO': 7,\n 'response_received_count': 1,\n 'scheduler/dequeued': 1,\n 'scheduler/dequeued/memory': 1,\n 'scheduler/enqueued': 1,\n 'scheduler/enqueued/memory': 1,\n 'start_time': datetime.datetime(2016, 8, 2, 8, 4, 24, 687076)}\n2016-08-02 15:04:27 [scrapy] INFO: Spider closed (finished)\n$ ll ddd.xls \n-rw-rw-r-- 1 tonal tonal 928218 2016-08-02 15:04 ddd.xls\n```\n\nIf get from curl, all file load:\n\n```\n$ curl -v 'http://www.wilo.ru/no_cache/glavnaja-stranica/library/dokumentacija/prais-list/?cid=108257&did=20858&sechash=27bdca8a' > dddd.xls\n* Hostname was NOT found in DNS cache\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying 46.30.61.245...\n* Connected to www.wilo.ru (46.30.61.245) port 80 (#0)\n> GET /no_cache/glavnaja-stranica/library/dokumentacija/prais-list/?cid=108257&did=20858&sechash=27bdca8a HTTP/1.1\n> User-Agent: curl/7.35.0\n> Host: www.wilo.ru\n> Accept: */*\n> \n  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0< HTTP/1.1 200 OK\n< Date: Tue, 02 Aug 2016 08:08:28 GMT\n* Server Apache is not blacklisted\n< Server: Apache\n< X-Powered-By: PHP/5.3.19\n< Pragma: private\n< Cache-control: private, must-revalidate\n< Content-disposition: attachment; filename=\"Price_04_2016.xls\"\n< Set-Cookie: fe_typo_user=4b09a3460fc97ad39a657da3e69bd734; path=/\n< Transfer-Encoding: chunked\n< Content-Type: application/octet-stream\n< \n{ [data not shown]\n100 5825k    0 5825k    0     0   204k      0 --:--:--  0:00:28 --:--:-- 66331\n* Connection #0 to host www.wilo.ru left intact\n$ ll dddd.xls \n-rw-rw-r-- 1 tonal tonal 5965312 2016-08-02 15:08 dddd.xls\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2162/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2162/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2145", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2145/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2145/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2145/events", "html_url": "https://github.com/scrapy/scrapy/issues/2145", "id": 167632942, "node_id": "MDU6SXNzdWUxNjc2MzI5NDI=", "number": 2145, "title": "Disabling RedirectMiddleware results in HttpCompressionMiddleware errors", "user": {"login": "barraponto", "id": 134005, "node_id": "MDQ6VXNlcjEzNDAwNQ==", "avatar_url": "https://avatars.githubusercontent.com/u/134005?v=4", "gravatar_id": "", "url": "https://api.github.com/users/barraponto", "html_url": "https://github.com/barraponto", "followers_url": "https://api.github.com/users/barraponto/followers", "following_url": "https://api.github.com/users/barraponto/following{/other_user}", "gists_url": "https://api.github.com/users/barraponto/gists{/gist_id}", "starred_url": "https://api.github.com/users/barraponto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/barraponto/subscriptions", "organizations_url": "https://api.github.com/users/barraponto/orgs", "repos_url": "https://api.github.com/users/barraponto/repos", "events_url": "https://api.github.com/users/barraponto/events{/privacy}", "received_events_url": "https://api.github.com/users/barraponto/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 470641083, "node_id": "MDU6TGFiZWw0NzA2NDEwODM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/in%20progress", "name": "in progress", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/15", "html_url": "https://github.com/scrapy/scrapy/milestone/15", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/15/labels", "id": 1977308, "node_id": "MDk6TWlsZXN0b25lMTk3NzMwOA==", "number": 15, "title": "v1.4", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 67, "state": "closed", "created_at": "2016-09-01T09:43:32Z", "updated_at": "2017-08-28T11:12:21Z", "due_on": null, "closed_at": "2017-08-28T11:12:21Z"}, "comments": 4, "created_at": "2016-07-26T15:13:20Z", "updated_at": "2017-03-07T08:23:36Z", "closed_at": "2017-03-07T08:23:36Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I wanted not to redirect `303` responses, but instead retry them.\nFrom the docs, I thought I could achieve it through two settings:\n\n```\nREDIRECT_ENABLED = False\nRETRY_HTTP_CODES = [301, 302, 307, 308, 500, 502, 503, 504, 408]\n```\n\nIt ended up giving me errors on `HttpCompressionMiddleware`:\n\n```\nTraceback (most recent call last):\n  File \"twisted/internet/defer.py\", line 1128, in _inlineCallbacks\n    result = g.send(result)\n  File \"scrapy/core/downloader/middleware.py\", line 53, in process_response\n    spider=spider)\n  File \"scrapy/downloadermiddlewares/httpcompression.py\", line 38, in process_response\n    response = response.replace(**kwargs)\n  File \"scrapy/http/response/text.py\", line 50, in replace\n    return Response.replace(self, *args, **kwargs)\n  File \"scrapy/http/response/__init__.py\", line 77, in replace\n    return cls(*args, **kwargs)\nTypeError: __init__() got an unexpected keyword argument 'encoding'\n```", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2145/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2145/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2140", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2140/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2140/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2140/events", "html_url": "https://github.com/scrapy/scrapy/pull/2140", "id": 167098859, "node_id": "MDExOlB1bGxSZXF1ZXN0Nzg1MTU4NjQ=", "number": 2140, "title": "[MRG+1] Fix IMAGES_EXPIRES default value", "user": {"login": "jesuslosada", "id": 5754422, "node_id": "MDQ6VXNlcjU3NTQ0MjI=", "avatar_url": "https://avatars.githubusercontent.com/u/5754422?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jesuslosada", "html_url": "https://github.com/jesuslosada", "followers_url": "https://api.github.com/users/jesuslosada/followers", "following_url": "https://api.github.com/users/jesuslosada/following{/other_user}", "gists_url": "https://api.github.com/users/jesuslosada/gists{/gist_id}", "starred_url": "https://api.github.com/users/jesuslosada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jesuslosada/subscriptions", "organizations_url": "https://api.github.com/users/jesuslosada/orgs", "repos_url": "https://api.github.com/users/jesuslosada/repos", "events_url": "https://api.github.com/users/jesuslosada/events{/privacy}", "received_events_url": "https://api.github.com/users/jesuslosada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-07-22T17:56:49Z", "updated_at": "2016-08-11T09:59:37Z", "closed_at": "2016-08-06T01:52:27Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/2140", "html_url": "https://github.com/scrapy/scrapy/pull/2140", "diff_url": "https://github.com/scrapy/scrapy/pull/2140.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/2140.patch", "merged_at": "2016-08-06T01:52:27Z"}, "body": "It looks like commit 4cef1a1d0060148716ffec4ad6ce9bf709ad1ea2 introduced a little bug. According to the documentation IMAGES_EXPIRES should be 90.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2140/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2140/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2125", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2125/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2125/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2125/events", "html_url": "https://github.com/scrapy/scrapy/issues/2125", "id": 165475481, "node_id": "MDU6SXNzdWUxNjU0NzU0ODE=", "number": 2125, "title": "scrapy.utils.log.StreamLogger doesn't seem to have flush method - breaks Python3", "user": {"login": "zelenij", "id": 5512551, "node_id": "MDQ6VXNlcjU1MTI1NTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5512551?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zelenij", "html_url": "https://github.com/zelenij", "followers_url": "https://api.github.com/users/zelenij/followers", "following_url": "https://api.github.com/users/zelenij/following{/other_user}", "gists_url": "https://api.github.com/users/zelenij/gists{/gist_id}", "starred_url": "https://api.github.com/users/zelenij/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zelenij/subscriptions", "organizations_url": "https://api.github.com/users/zelenij/orgs", "repos_url": "https://api.github.com/users/zelenij/repos", "events_url": "https://api.github.com/users/zelenij/events{/privacy}", "received_events_url": "https://api.github.com/users/zelenij/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 317415181, "node_id": "MDU6TGFiZWwzMTc0MTUxODE=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/logging", "name": "logging", "color": "fbca04", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-07-14T04:51:38Z", "updated_at": "2016-09-19T08:44:45Z", "closed_at": "2016-09-19T08:44:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Might be necessary to add the flush method to StreamLogger class, to make this work with Python3 and `LOG_STDOUT = True`:\n\n```\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\n\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\n\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\n\n  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\n\n  File \"<frozen importlib._bootstrap_external>\", line 658, in exec_module\n\n  File \"<frozen importlib._bootstrap_external>\", line 764, in get_code\n\n  File \"<frozen importlib._bootstrap_external>\", line 724, in source_to_code\n\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\n\nbuiltins.SyntaxError: invalid syntax (pipelines.py, line 19)\nException ignored in: <scrapy.utils.log.StreamLogger object at 0x10fddd978>\nAttributeError: 'StreamLogger' object has no attribute 'flush'\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2125/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2125/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2092", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2092/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2092/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2092/events", "html_url": "https://github.com/scrapy/scrapy/issues/2092", "id": 163963906, "node_id": "MDU6SXNzdWUxNjM5NjM5MDY=", "number": 2092, "title": "Scrapy 1.1 - exceptions.ValueError: Invalid DNS-ID.", "user": {"login": "nealhnguyen", "id": 6827627, "node_id": "MDQ6VXNlcjY4Mjc2Mjc=", "avatar_url": "https://avatars.githubusercontent.com/u/6827627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nealhnguyen", "html_url": "https://github.com/nealhnguyen", "followers_url": "https://api.github.com/users/nealhnguyen/followers", "following_url": "https://api.github.com/users/nealhnguyen/following{/other_user}", "gists_url": "https://api.github.com/users/nealhnguyen/gists{/gist_id}", "starred_url": "https://api.github.com/users/nealhnguyen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nealhnguyen/subscriptions", "organizations_url": "https://api.github.com/users/nealhnguyen/orgs", "repos_url": "https://api.github.com/users/nealhnguyen/repos", "events_url": "https://api.github.com/users/nealhnguyen/events{/privacy}", "received_events_url": "https://api.github.com/users/nealhnguyen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 320345582, "node_id": "MDU6TGFiZWwzMjAzNDU1ODI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/https", "name": "https", "color": "101e89", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/11", "html_url": "https://github.com/scrapy/scrapy/milestone/11", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/11/labels", "id": 1760818, "node_id": "MDk6TWlsZXN0b25lMTc2MDgxOA==", "number": 11, "title": "v1.1.1", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 31, "state": "closed", "created_at": "2016-05-11T18:24:06Z", "updated_at": "2016-07-14T16:56:26Z", "due_on": null, "closed_at": "2016-07-14T16:56:26Z"}, "comments": 3, "created_at": "2016-07-05T22:52:18Z", "updated_at": "2016-07-13T10:48:08Z", "closed_at": "2016-07-13T10:48:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello I'm crawling websites with insecure connections. When I try to crawl, I get the stack trace,\n\n```\n2016-07-05 15:50:17 [twisted] CRITICAL: Error during info_callback\nTraceback (most recent call last):\n  File \"c:\\python27\\lib\\site-packages\\twisted\\protocols\\tls.py\", line 421, in dataReceived\n    self._write(bytes)\n  File \"c:\\python27\\lib\\site-packages\\twisted\\protocols\\tls.py\", line 569, in _write\n    sent = self._tlsConnection.send(toSend)\n  File \"c:\\python27\\lib\\site-packages\\OpenSSL\\SSL.py\", line 1270, in send\n    result = _lib.SSL_write(self._ssl, buf, len(buf))\n  File \"c:\\python27\\lib\\site-packages\\OpenSSL\\SSL.py\", line 933, in wrapper\n    callback(Connection._reverse_mapping[ssl], where, return_code)\n--- <exception caught here> ---\n  File \"c:\\python27\\lib\\site-packages\\twisted\\internet\\_sslverify.py\", line 1154, in infoCallback\n    return wrapped(connection, where, ret)\n  File \"c:\\python27\\lib\\site-packages\\scrapy\\core\\downloader\\tls.py\", line 45, in _identityVerifyingInfoCallback\n    verifyHostname(connection, self._hostnameASCII)\n  File \"c:\\python27\\lib\\site-packages\\service_identity\\pyopenssl.py\", line 45, in verify_hostname\n    obligatory_ids=[DNS_ID(hostname)],\n  File \"c:\\python27\\lib\\site-packages\\service_identity\\_common.py\", line 245, in __init__\n    raise ValueError(\"Invalid DNS-ID.\")\nexceptions.ValueError: Invalid DNS-ID.\n```\n\nIs there any way to ignore the invalid certificate?\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2092/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2092/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2063", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2063/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2063/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2063/events", "html_url": "https://github.com/scrapy/scrapy/issues/2063", "id": 161068034, "node_id": "MDU6SXNzdWUxNjEwNjgwMzQ=", "number": 2063, "title": "IOError, 'Not a gzipped file'", "user": {"login": "DharmeshPandav", "id": 5565556, "node_id": "MDQ6VXNlcjU1NjU1NTY=", "avatar_url": "https://avatars.githubusercontent.com/u/5565556?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DharmeshPandav", "html_url": "https://github.com/DharmeshPandav", "followers_url": "https://api.github.com/users/DharmeshPandav/followers", "following_url": "https://api.github.com/users/DharmeshPandav/following{/other_user}", "gists_url": "https://api.github.com/users/DharmeshPandav/gists{/gist_id}", "starred_url": "https://api.github.com/users/DharmeshPandav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DharmeshPandav/subscriptions", "organizations_url": "https://api.github.com/users/DharmeshPandav/orgs", "repos_url": "https://api.github.com/users/DharmeshPandav/repos", "events_url": "https://api.github.com/users/DharmeshPandav/events{/privacy}", "received_events_url": "https://api.github.com/users/DharmeshPandav/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/11", "html_url": "https://github.com/scrapy/scrapy/milestone/11", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/11/labels", "id": 1760818, "node_id": "MDk6TWlsZXN0b25lMTc2MDgxOA==", "number": 11, "title": "v1.1.1", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 31, "state": "closed", "created_at": "2016-05-11T18:24:06Z", "updated_at": "2016-07-14T16:56:26Z", "due_on": null, "closed_at": "2016-07-14T16:56:26Z"}, "comments": 3, "created_at": "2016-06-19T11:15:35Z", "updated_at": "2016-11-09T16:14:03Z", "closed_at": "2016-07-11T10:15:38Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "while trying to access sitemap from robots.txt , Scrapy fails with **IOError, 'Not a gzipped file'** error\n\nnot sure if this issue is related to following issue(s)\nhttps://github.com/scrapy/scrapy/issues/193 -> closed issue\nhttps://github.com/scrapy/scrapy/pull/660 -> merged pull request to address issue 193\nhttps://github.com/scrapy/scrapy/issues/951 -> open issue\n\n> line where code fails in gzip.py at line # 197\n> \n> ``` python\n> def _read_gzip_header(self):\n>         magic = self.fileobj.read(2)\n>         if magic != '\\037\\213':\n>             raise IOError, 'Not a gzipped file'\n> ```\n# Response Header\n\n```\nContent-Encoding: gzip\nAccept-Ranges: bytes\nX-Amz-Request-Id: BFFF010DDE6268DA\nVary: Accept-Encoding\nServer: AmazonS3\nLast-Modified: Wed, 15 Jun 2016 19:02:20 GMT\nEtag: \"300bb71d6897cb2a22bba0bd07978c84\"\nCache-Control: no-transform\nDate: Sun, 19 Jun 2016 10:54:53 GMT\nContent-Type: binary/octet-stream\n```\n\nError Log:\n\n``` log\n Traceback (most recent call last):\n  File \"c:\\venv\\scrapy1.0\\lib\\site-packages\\scrapy\\utils\\defer.py\", line 102, in iter_errback\n    yield next(it)\n  File \"c:\\venv\\scrapy1.0\\lib\\site-packages\\scrapy\\spidermiddlewares\\offsite.py\", line 29, in process_spider_output\n    for x in result:\n  File \"c:\\venv\\scrapy1.0\\lib\\site-packages\\scrapy\\spidermiddlewares\\referer.py\", line 22, in <genexpr>\n    return (_set_referer(r) for r in result or ())\n  File \"c:\\venv\\scrapy1.0\\lib\\site-packages\\scrapy\\spidermiddlewares\\urllength.py\", line 37, in <genexpr>\n    return (r for r in result or () if _filter(r))\n  File \"c:\\venv\\scrapy1.0\\lib\\site-packages\\scrapy\\spidermiddlewares\\depth.py\", line 58, in <genexpr>\n    return (r for r in result or () if _filter(r))\n  File \"D:\\projects\\sitemap_spider\\sitemap_spider\\spiders\\mainspider.py\", line 31, in _parse_sitemap\n    body = self._get_sitemap_body(response)\n  File \"c:\\venv\\scrapy1.0\\lib\\site-packages\\scrapy\\spiders\\sitemap.py\", line 67, in _get_sitemap_body\n    return gunzip(response.body)\n  File \"c:\\venv\\scrapy1.0\\lib\\site-packages\\scrapy\\utils\\gz.py\", line 37, in gunzip\n    chunk = read1(f, 8196)\n  File \"c:\\venv\\scrapy1.0\\lib\\site-packages\\scrapy\\utils\\gz.py\", line 21, in read1\n    return gzf.read(size)\n  File \"c:\\python27\\Lib\\gzip.py\", line 268, in read\n    self._read(readsize)\n  File \"c:\\python27\\Lib\\gzip.py\", line 303, in _read\n    self._read_gzip_header()\n  File \"c:\\python27\\Lib\\gzip.py\", line 197, in _read_gzip_header\n    raise IOError, 'Not a gzipped file'\n```\n\ni did download file manually and was able to extract the content so it is not like file is corrupted \n\nas an example sitemap url : you can follow amazon robots.txt\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2063/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2063/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2049", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2049/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2049/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2049/events", "html_url": "https://github.com/scrapy/scrapy/issues/2049", "id": 159800888, "node_id": "MDU6SXNzdWUxNTk4MDA4ODg=", "number": 2049, "title": "utils.is_gzipped returns false on application/x-gzip;charset=utf-8", "user": {"login": "Tethik", "id": 298627, "node_id": "MDQ6VXNlcjI5ODYyNw==", "avatar_url": "https://avatars.githubusercontent.com/u/298627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tethik", "html_url": "https://github.com/Tethik", "followers_url": "https://api.github.com/users/Tethik/followers", "following_url": "https://api.github.com/users/Tethik/following{/other_user}", "gists_url": "https://api.github.com/users/Tethik/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tethik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tethik/subscriptions", "organizations_url": "https://api.github.com/users/Tethik/orgs", "repos_url": "https://api.github.com/users/Tethik/repos", "events_url": "https://api.github.com/users/Tethik/events{/privacy}", "received_events_url": "https://api.github.com/users/Tethik/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/11", "html_url": "https://github.com/scrapy/scrapy/milestone/11", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/11/labels", "id": 1760818, "node_id": "MDk6TWlsZXN0b25lMTc2MDgxOA==", "number": 11, "title": "v1.1.1", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 31, "state": "closed", "created_at": "2016-05-11T18:24:06Z", "updated_at": "2016-07-14T16:56:26Z", "due_on": null, "closed_at": "2016-07-14T16:56:26Z"}, "comments": 1, "created_at": "2016-06-12T00:46:14Z", "updated_at": "2016-07-13T15:53:50Z", "closed_at": "2016-07-08T11:51:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I had a site return the following header, which caused SitemapSpider to not parse a sitemap xml that was gzipped. \n\n```\nContent-Type: application/x-gzip;charset=utf-8\n```\n\nLooking into the code it seems that the function [utils.is_gzipped](https://github.com/scrapy/scrapy/blob/master/scrapy/utils/gz.py#L54) does not take into account cases where the Content-Type header would include charset.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2049/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2049/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2010", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2010/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2010/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2010/events", "html_url": "https://github.com/scrapy/scrapy/issues/2010", "id": 156851213, "node_id": "MDU6SXNzdWUxNTY4NTEyMTM=", "number": 2010, "title": "Unicode Link Extractor", "user": {"login": "k-m-engin", "id": 17865999, "node_id": "MDQ6VXNlcjE3ODY1OTk5", "avatar_url": "https://avatars.githubusercontent.com/u/17865999?v=4", "gravatar_id": "", "url": "https://api.github.com/users/k-m-engin", "html_url": "https://github.com/k-m-engin", "followers_url": "https://api.github.com/users/k-m-engin/followers", "following_url": "https://api.github.com/users/k-m-engin/following{/other_user}", "gists_url": "https://api.github.com/users/k-m-engin/gists{/gist_id}", "starred_url": "https://api.github.com/users/k-m-engin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/k-m-engin/subscriptions", "organizations_url": "https://api.github.com/users/k-m-engin/orgs", "repos_url": "https://api.github.com/users/k-m-engin/repos", "events_url": "https://api.github.com/users/k-m-engin/events{/privacy}", "received_events_url": "https://api.github.com/users/k-m-engin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 388324163, "node_id": "MDU6TGFiZWwzODgzMjQxNjM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/link%20extraction", "name": "link extraction", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/11", "html_url": "https://github.com/scrapy/scrapy/milestone/11", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/11/labels", "id": 1760818, "node_id": "MDk6TWlsZXN0b25lMTc2MDgxOA==", "number": 11, "title": "v1.1.1", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 31, "state": "closed", "created_at": "2016-05-11T18:24:06Z", "updated_at": "2016-07-14T16:56:26Z", "due_on": null, "closed_at": "2016-07-14T16:56:26Z"}, "comments": 5, "created_at": "2016-05-25T21:10:26Z", "updated_at": "2016-07-08T04:47:54Z", "closed_at": "2016-07-08T04:47:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "When using the following to extract all of the links from a response:\n\n```\nself.link_extractor = LinkExtractor()\n...\nlinks = self.link_extractor.extract_links(response)\n```\n\nOn rare occasions, the following error is thrown:\n\n```\n2016-05-25 12:13:55,432 [root] [ERROR]  Error on http://detroit.curbed.com/2016/5/5/11605132/tiny-house-designer-show, traceback: Traceback (most recent call last):\n  File \"/usr/local/lib/python2.7/site-packages/twisted/internet/base.py\", line 1203, in mainLoop\n    self.runUntilCurrent()\n  File \"/usr/local/lib/python2.7/site-packages/twisted/internet/base.py\", line 825, in runUntilCurrent\n    call.func(*call.args, **call.kw)\n  File \"/usr/local/lib/python2.7/site-packages/twisted/internet/defer.py\", line 393, in callback\n    self._startRunCallbacks(result)\n  File \"/usr/local/lib/python2.7/site-packages/twisted/internet/defer.py\", line 501, in _startRunCallbacks\n    self._runCallbacks()\n--- <exception caught here> ---\n  File \"/usr/local/lib/python2.7/site-packages/twisted/internet/defer.py\", line 588, in _runCallbacks\n    current.result = callback(current.result, *args, **kw)\n  File \"/var/www/html/DomainCrawler/DomainCrawler/spiders/hybrid_spider.py\", line 223, in parse\n    items.extend(self._extract_requests(response))\n  File \"/var/www/html/DomainCrawler/DomainCrawler/spiders/hybrid_spider.py\", line 477, in _extract_requests\n    links = self.link_extractor.extract_links(response)\n  File \"/usr/local/lib/python2.7/site-packages/scrapy/linkextractors/lxmlhtml.py\", line 111, in extract_links\n    all_links.extend(self._process_links(links))\n  File \"/usr/local/lib/python2.7/site-packages/scrapy/linkextractors/__init__.py\", line 103, in _process_links\n    link.url = canonicalize_url(urlparse(link.url))\n  File \"/usr/local/lib/python2.7/site-packages/scrapy/utils/url.py\", line 85, in canonicalize_url\n    parse_url(url), encoding=encoding)\n  File \"/usr/local/lib/python2.7/site-packages/scrapy/utils/url.py\", line 46, in _safe_ParseResult\n    to_native_str(parts.netloc.encode('idna')),\n  File \"/usr/local/lib/python2.7/encodings/idna.py\", line 164, in encode\n    result.append(ToASCII(label))\n  File \"/usr/local/lib/python2.7/encodings/idna.py\", line 73, in ToASCII\n    raise UnicodeError(\"label empty or too long\")\nexceptions.UnicodeError: label empty or too long\n```\n\nI was able to find some information concerning the error from [here](http://stackoverflow.com/questions/25103126/label-empty-or-too-long-python-urllib2).\nMy question is: What is the best way to handle this? Even if there is one bad link in the response, I'd want all of the other good links to be extracted.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2010/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2010/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2004", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/2004/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/2004/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/2004/events", "html_url": "https://github.com/scrapy/scrapy/issues/2004", "id": 156165703, "node_id": "MDU6SXNzdWUxNTYxNjU3MDM=", "number": 2004, "title": "MediaPipeline (and ImagesPipeline/FilesPipeline) does not handle HTTP redirections", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/15", "html_url": "https://github.com/scrapy/scrapy/milestone/15", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/15/labels", "id": 1977308, "node_id": "MDk6TWlsZXN0b25lMTk3NzMwOA==", "number": 15, "title": "v1.4", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 67, "state": "closed", "created_at": "2016-09-01T09:43:32Z", "updated_at": "2017-08-28T11:12:21Z", "due_on": null, "closed_at": "2017-08-28T11:12:21Z"}, "comments": 11, "created_at": "2016-05-22T18:34:24Z", "updated_at": "2017-03-16T10:31:28Z", "closed_at": "2017-03-16T10:31:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "Basically, what's happened is that my spider is unable to download the files because the file_urls provided are actually redirected to the final download link. However, because of the following code, the redirect download middleware is effectively disabled, which makes the download fail.\n\n```\ndef _check_media_to_download(self, result, request, info):\n        if result is not None:\n            return result\n        if self.download_func:\n            # this ugly code was left only to support tests. TODO: remove\n            dfd = mustbe_deferred(self.download_func, request, info.spider)\n            dfd.addCallbacks(\n                callback=self.media_downloaded, callbackArgs=(request, info),\n                errback=self.media_failed, errbackArgs=(request, info))\n        else:\n            request.meta['handle_httpstatus_all'] = True\n            dfd = self.crawler.engine.download(request, info.spider)\n            dfd.addCallbacks(\n                callback=self.media_downloaded, callbackArgs=(request, info),\n                errback=self.media_failed, errbackArgs=(request, info))\n        return dfd\n```\n\nAnd here is the check in the redirect middleware that disables it:\n\n```\nif (request.meta.get('dont_redirect', False) or\n                response.status in getattr(spider, 'handle_httpstatus_list', []) or\n                response.status in request.meta.get('handle_httpstatus_list', []) or\n                request.meta.get('handle_httpstatus_all', False)):\n            return response\n\n```\n\nMy question is: What is the point of enabling the handling of httpstatus_all, when it effectively disables all of the checks?  \n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/2004/reactions", "total_count": 12, "+1": 4, "-1": 0, "laugh": 0, "hooray": 0, "confused": 8, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/2004/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1985", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1985/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1985/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1985/events", "html_url": "https://github.com/scrapy/scrapy/issues/1985", "id": 154309806, "node_id": "MDU6SXNzdWUxNTQzMDk4MDY=", "number": 1985, "title": "Scrapy 1.1.0 ImagesPipeline backward incompatibility", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/11", "html_url": "https://github.com/scrapy/scrapy/milestone/11", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/11/labels", "id": 1760818, "node_id": "MDk6TWlsZXN0b25lMTc2MDgxOA==", "number": 11, "title": "v1.1.1", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 31, "state": "closed", "created_at": "2016-05-11T18:24:06Z", "updated_at": "2016-07-14T16:56:26Z", "due_on": null, "closed_at": "2016-07-14T16:56:26Z"}, "comments": 3, "created_at": "2016-05-11T18:24:09Z", "updated_at": "2016-07-13T14:44:00Z", "closed_at": "2016-07-13T14:44:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "#1891 is not backward compatible.\n\nUsers of Scrapy<1.1 `ImagesPipeline` could access upper-case attributes,\ne.g. \n\n```\nclass CustomImagesPipeline(ImagesPipeline):\n    (...)\n    def item_completed(self, results, item, info):\n        item = super(CustomImagesPipeline, self).item_completed(\n            results, item, info)\n        # Note: not all items do have an images field.\n        if self.IMAGES_RESULT_FIELD not in item.fields:\n            return item\n```\n\nLeading to the following exception in 1.1.0(rc4):\n\n```\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/site-packages/twisted/internet/defer.py\", line 588, in _runCallbacks\n    current.result = callback(current.result, *args, **kw)\n  File \"/tmp/unpacked-eggs/__main__.egg/*****/pipelines/screenshots.py\", line 539, in item_completed\n    results, item, info)\n  File \"/tmp/unpacked-eggs/__main__.egg/*****/pipelines/screenshots.py\", line 242, in item_completed\n    images = item.pop(self.IMAGES_RESULT_FIELD, [])\nAttributeError: 'CustomImagesPipeline' object has no attribute 'IMAGES_RESULT_FIELD'\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1985/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1985/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1936", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1936/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1936/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1936/events", "html_url": "https://github.com/scrapy/scrapy/issues/1936", "id": 149043300, "node_id": "MDU6SXNzdWUxNDkwNDMzMDA=", "number": 1936, "title": "SSL errors crawling https sites using proxies", "user": {"login": "lhuaizhong", "id": 13061739, "node_id": "MDQ6VXNlcjEzMDYxNzM5", "avatar_url": "https://avatars.githubusercontent.com/u/13061739?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lhuaizhong", "html_url": "https://github.com/lhuaizhong", "followers_url": "https://api.github.com/users/lhuaizhong/followers", "following_url": "https://api.github.com/users/lhuaizhong/following{/other_user}", "gists_url": "https://api.github.com/users/lhuaizhong/gists{/gist_id}", "starred_url": "https://api.github.com/users/lhuaizhong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lhuaizhong/subscriptions", "organizations_url": "https://api.github.com/users/lhuaizhong/orgs", "repos_url": "https://api.github.com/users/lhuaizhong/repos", "events_url": "https://api.github.com/users/lhuaizhong/events{/privacy}", "received_events_url": "https://api.github.com/users/lhuaizhong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 320345582, "node_id": "MDU6TGFiZWwzMjAzNDU1ODI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/https", "name": "https", "color": "101e89", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-04-18T05:05:36Z", "updated_at": "2016-04-19T03:36:52Z", "closed_at": "2016-04-19T03:36:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm unable to scrape below https sites through https supported proxies, have tried version 1.0.5 and 1.1.0rc3. I'm using proxymesh, but https://www.python.org and others work well.\n\n(env-scrapy-1.1) D:\\work>scrapy version -v\nScrapy    : 1.1.0rc3\nlxml      : 3.6.0.0\nlibxml2   : 2.9.0\nTwisted   : 16.1.1\nPython    : 2.7.11 (v2.7.11:6d1b6a68f775, Dec  5 2015, 20:32:19) [MSC v.1500 32 bit (Intel)]\npyOpenSSL : 16.0.0 (OpenSSL 1.0.2g  1 Mar 2016)\nPlatform  : Windows-10-10.0.10586\n\n`2016-04-18 12:56:25 [scrapy] DEBUG: Gave up retrying <GET https://xxx.xxx.xxx/> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'sslv3 alert handshake failure')]>]\n2016-04-18 12:56:25 [scrapy] ERROR: Error downloading <GET https://xxx.xxx.xxx/>: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'sslv3 alert handshake failure')]>]`\n# \n\nD:\\work>scrapy version -v\nScrapy    : 1.0.5\nlxml      : 3.5.0.0\nlibxml2   : 2.9.3\nTwisted   : 15.5.0\nPython    : 2.7.11 (v2.7.11:6d1b6a68f775, Dec  5 2015, 20:32:19) [MSC v.1500 32 bit (Intel)]\npyOpenSSL : 0.15.1 (OpenSSL 1.0.2f  28 Jan 2016)\nPlatform  : Windows-10-10.0.10586\n\n`2016-04-18 12:58:29 [scrapy] ERROR: Error downloading <GET https://xxx.xxx.xxx/>: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'sslv3 alert handshake failure')]>]`\n\nThe https://github.com/scrapy/scrapy/issues/1429#issuecomment-131782133 doesn't work as well.\n\nMay anyone help? thanks a lot in advance.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1936/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1936/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1930", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1930/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1930/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1930/events", "html_url": "https://github.com/scrapy/scrapy/issues/1930", "id": 148151545, "node_id": "MDU6SXNzdWUxNDgxNTE1NDU=", "number": 1930, "title": "Scrapy 1.1.0 RC3 - exception thrown with invalid ssl certificate", "user": {"login": "natoinet", "id": 594800, "node_id": "MDQ6VXNlcjU5NDgwMA==", "avatar_url": "https://avatars.githubusercontent.com/u/594800?v=4", "gravatar_id": "", "url": "https://api.github.com/users/natoinet", "html_url": "https://github.com/natoinet", "followers_url": "https://api.github.com/users/natoinet/followers", "following_url": "https://api.github.com/users/natoinet/following{/other_user}", "gists_url": "https://api.github.com/users/natoinet/gists{/gist_id}", "starred_url": "https://api.github.com/users/natoinet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/natoinet/subscriptions", "organizations_url": "https://api.github.com/users/natoinet/orgs", "repos_url": "https://api.github.com/users/natoinet/repos", "events_url": "https://api.github.com/users/natoinet/events{/privacy}", "received_events_url": "https://api.github.com/users/natoinet/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 320345582, "node_id": "MDU6TGFiZWwzMjAzNDU1ODI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/https", "name": "https", "color": "101e89", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/7", "html_url": "https://github.com/scrapy/scrapy/milestone/7", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/7/labels", "id": 1008005, "node_id": "MDk6TWlsZXN0b25lMTAwODAwNQ==", "number": 7, "title": "v1.1", "description": "", "creator": {"login": "pablohoffman", "id": 185212, "node_id": "MDQ6VXNlcjE4NTIxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/185212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pablohoffman", "html_url": "https://github.com/pablohoffman", "followers_url": "https://api.github.com/users/pablohoffman/followers", "following_url": "https://api.github.com/users/pablohoffman/following{/other_user}", "gists_url": "https://api.github.com/users/pablohoffman/gists{/gist_id}", "starred_url": "https://api.github.com/users/pablohoffman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pablohoffman/subscriptions", "organizations_url": "https://api.github.com/users/pablohoffman/orgs", "repos_url": "https://api.github.com/users/pablohoffman/repos", "events_url": "https://api.github.com/users/pablohoffman/events{/privacy}", "received_events_url": "https://api.github.com/users/pablohoffman/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 99, "state": "closed", "created_at": "2015-03-05T18:14:46Z", "updated_at": "2016-05-11T18:55:46Z", "due_on": "2016-03-15T07:00:00Z", "closed_at": "2016-05-11T18:55:46Z"}, "comments": 4, "created_at": "2016-04-13T18:56:45Z", "updated_at": "2017-10-05T04:24:01Z", "closed_at": "2016-04-20T12:57:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\n\nI am crawling sometimes websites with an invalid ssl certificate. For example, Scrapy 1.1.0 RC3 fails to open when I do:\n\n> scrapy shell https://www.directoriosanitario.com/directorio\n> or\n> scrapy shell https://saobinv.5go.cc/top/\n\nand throws the following exception:\n\n> twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure service_identity.exceptions.VerificationError: VerificationError(errors=[DNSMismatch(mismatched_id=DNS_ID(hostname=b'www.directoriosanitario.com'))])>]\n\nI tried it with Scrapy 1.0.5 on python 2.7 and the spider opens but warns with: \n\n> AttributeError: 'NoneType' object has no attribute 'failVerification'\n\nIs there a way to force the spider to open with Scrapy 1.1.0 RC3?\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1930/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1930/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1890", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1890/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1890/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1890/events", "html_url": "https://github.com/scrapy/scrapy/issues/1890", "id": 144364314, "node_id": "MDU6SXNzdWUxNDQzNjQzMTQ=", "number": 1890, "title": "Disk queues don't preserve Request class", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-03-29T19:32:20Z", "updated_at": "2017-02-08T17:30:08Z", "closed_at": "2017-02-08T17:30:08Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "When a Request subclass (e.g. FormRequest) is sent to a disk queue a bare Request is what you get back. \n\nThis is inconvenient for scrapy-splash: Splash requests all have Splash URL as request.url, but for logging it is nice to display the requested URL, not only Splash URL. In scrapy-splash this is implemented by changing `__repr__` in a Request subclass, but it works only when request is kept in memory.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1890/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1890/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1850", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1850/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1850/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1850/events", "html_url": "https://github.com/scrapy/scrapy/issues/1850", "id": 138746026, "node_id": "MDU6SXNzdWUxMzg3NDYwMjY=", "number": 1850, "title": "EXPIRES in Files/ImagesPipeline should be a instance attribute and not a class attribute", "user": {"login": "djunzu", "id": 8784122, "node_id": "MDQ6VXNlcjg3ODQxMjI=", "avatar_url": "https://avatars.githubusercontent.com/u/8784122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/djunzu", "html_url": "https://github.com/djunzu", "followers_url": "https://api.github.com/users/djunzu/followers", "following_url": "https://api.github.com/users/djunzu/following{/other_user}", "gists_url": "https://api.github.com/users/djunzu/gists{/gist_id}", "starred_url": "https://api.github.com/users/djunzu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/djunzu/subscriptions", "organizations_url": "https://api.github.com/users/djunzu/orgs", "repos_url": "https://api.github.com/users/djunzu/repos", "events_url": "https://api.github.com/users/djunzu/events{/privacy}", "received_events_url": "https://api.github.com/users/djunzu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 280218717, "node_id": "MDU6TGFiZWwyODAyMTg3MTc=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/discuss", "name": "discuss", "color": "cc317c", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-03-06T02:45:13Z", "updated_at": "2016-04-08T10:55:09Z", "closed_at": "2016-04-08T10:55:09Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Currently `EXPIRES` in `FilesPipeline` and `ImagesPipeline` is defined as a class attribute. When running more than one spider with `CrawlerProcess` it is impossible to have different expires values for different spiders. Changing the `EXPIRES` attribute to an instance attribute solves the problem.\n\n(I would do a pull request, but I have no idea how to properly update the tests.)\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1850/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1850/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1832", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1832/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1832/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1832/events", "html_url": "https://github.com/scrapy/scrapy/issues/1832", "id": 137591111, "node_id": "MDU6SXNzdWUxMzc1OTExMTE=", "number": 1832, "title": "IPv6 addresses not correctly recognized", "user": {"login": "nyov", "id": 438293, "node_id": "MDQ6VXNlcjQzODI5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/438293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nyov", "html_url": "https://github.com/nyov", "followers_url": "https://api.github.com/users/nyov/followers", "following_url": "https://api.github.com/users/nyov/following{/other_user}", "gists_url": "https://api.github.com/users/nyov/gists{/gist_id}", "starred_url": "https://api.github.com/users/nyov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nyov/subscriptions", "organizations_url": "https://api.github.com/users/nyov/orgs", "repos_url": "https://api.github.com/users/nyov/repos", "events_url": "https://api.github.com/users/nyov/events{/privacy}", "received_events_url": "https://api.github.com/users/nyov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2016-03-01T14:41:34Z", "updated_at": "2022-11-17T14:15:34Z", "closed_at": "2022-11-17T14:15:34Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "In a follow-up to #1116 scrapy does not recognize IPv6 addresses correctly.\n\nIPv6 address notation should be written inside brackets as `[<ip>]`.\n(Check browser behavior for [http://::1/](http://::1/) and [http://[::1]/](http://[::1]/). But beware of the wrongly urlescaped `[]` when copying the second link).\n\nScrapy seems to do the exact opposite:\n\n``` pytb\n$ scrapy-dev shell \"http://[::1]/\"\n2016-03-01 14:31:34 [scrapy] INFO: Scrapy 1.2.0dev2 started (bot: testbot)\n2016-03-01 14:31:34 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'testbot.spiders', 'SPIDER_MODULES': ['testbot.spiders'], 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'LOGSTATS_INTERVAL': 0, 'BOT_NAME': 'testbot'}\n2016-03-01 14:31:34 [scrapy] INFO: Enabled extensions:\n['scrapy.extensions.telnet.TelnetConsole',\n 'scrapy.extensions.corestats.CoreStats']\n2016-03-01 14:31:34 [scrapy] INFO: Enabled downloader middlewares:\n['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n2016-03-01 14:31:34 [scrapy] INFO: Enabled spider middlewares:\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n2016-03-01 14:31:34 [scrapy] INFO: Enabled item pipelines:\n[]\n2016-03-01 14:31:34 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023\n2016-03-01 14:31:34 [scrapy] INFO: Spider opened\n2016-03-01 14:31:34 [scrapy] DEBUG: Retrying <GET http://%5B::1%5D/> (failed 1 times): 503 Service Unavailable\n2016-03-01 14:31:34 [scrapy] DEBUG: Retrying <GET http://%5B::1%5D/> (failed 2 times): 503 Service Unavailable\n2016-03-01 14:31:34 [scrapy] DEBUG: Gave up retrying <GET http://%5B::1%5D/> (failed 3 times): 503 Service Unavailable\n2016-03-01 14:31:34 [scrapy] DEBUG: Crawled (503) <GET http://%5B::1%5D/> (referer: None)\n2016-03-01 14:31:34 [root] DEBUG: Using default logger\n2016-03-01 14:31:34 [root] DEBUG: Using default logger\n[s] Available Scrapy objects:\n[s]   crawler    <scrapy.crawler.Crawler object at 0x7f29e720d590>\n[s]   item       {}\n[s]   request    <GET http://%5B::1%5D/>\n[s]   response   <503 http://%5B::1%5D/>\n[s]   settings   <scrapy.settings.Settings object at 0x7f29e720d610>\n[s]   spider     <DefaultSpider 'default' at 0x7f29e1d0b7d0>\n[s] Useful shortcuts:\n[s]   shelp()           Shell help (print this help)\n[s]   fetch(req_or_url) Fetch request (or URL) and update local objects\n[s]   view(response)    View response in a browser\nIn [1]: \n```\n\n...without the brackets it seems to work. Where it shouldn't, IMO.\n\n``` pytb\n$ scrapy-dev shell \"http://::1/\"\n# <snip>\nIn [1]: response.status\nOut[1]: 200\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1832/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1832/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1807", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1807/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1807/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1807/events", "html_url": "https://github.com/scrapy/scrapy/issues/1807", "id": 135731476, "node_id": "MDU6SXNzdWUxMzU3MzE0NzY=", "number": 1807, "title": "Scrapy keep wrong proxy setting", "user": {"login": "DrJackilD", "id": 1544738, "node_id": "MDQ6VXNlcjE1NDQ3Mzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1544738?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DrJackilD", "html_url": "https://github.com/DrJackilD", "followers_url": "https://api.github.com/users/DrJackilD/followers", "following_url": "https://api.github.com/users/DrJackilD/following{/other_user}", "gists_url": "https://api.github.com/users/DrJackilD/gists{/gist_id}", "starred_url": "https://api.github.com/users/DrJackilD/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DrJackilD/subscriptions", "organizations_url": "https://api.github.com/users/DrJackilD/orgs", "repos_url": "https://api.github.com/users/DrJackilD/repos", "events_url": "https://api.github.com/users/DrJackilD/events{/privacy}", "received_events_url": "https://api.github.com/users/DrJackilD/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 320345582, "node_id": "MDU6TGFiZWwzMjAzNDU1ODI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/https", "name": "https", "color": "101e89", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2016-02-23T13:04:14Z", "updated_at": "2016-05-03T11:27:27Z", "closed_at": "2016-04-20T11:32:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi! I have one issue, when trying to test proxies with Scrapy. I want to check proxies with httpbin.org, and make crawler:\n\n``` python\nclass CheckerSpider(scrapy.Spider):\n    name = \"checker\"\n    start_urls = (\n        'https://www.httpbin.org/ip'\n    )\n    connection = get_connection()\n\n    def start_requests(self):\n\n        with self.connection.cursor() as cursor:\n            limit = int((datetime.now() - datetime(1970, 1, 1)).total_seconds()) - 3600\n            q = \"\"\" SELECT *\n                    FROM {}\n                    WHERE active = 1 AND last_checked <= {} OR last_checked IS NULL;\"\"\".format(DB_TABLE, limit)\n            cursor.execute(q)\n            proxy_list = cursor.fetchall()\n\n        for proxy in proxy_list[:15]:\n            word = get_random_word()\n            req = scrapy.Request(self.start_urls, self.check_proxy, dont_filter=True)\n            req.meta['proxy'] = 'https://{}:8080'.format(proxy['ip'])\n            req.meta['item'] = proxy\n            user_pass = base64.encodestring('{}:{}'.format(PROXY_USER, PROXY_PASSWORD))\n            req.headers['Proxy-Authorization'] = 'Basic {}'.format(user_pass)\n            req.headers['User-Agent'] = get_user_agent()\n            yield req\n\n    def check_proxy(self, response):\n        print response.request.meta['proxy']\n        print response.meta['item']['ip']\n        print response.body\n```\n\nBut when I'm testing it, I've see that Scrapy connect to url only with 5 proxies and then didn't change it. Example output (just messed IP):\n\n``` python\n2016-02-23 14:54:36 [scrapy] DEBUG: Crawled (200) <GET https://www.httpbin.org/ip> (referer: None)\nhttps://192.168.100.130:8080\n192.168.100.130\n{\n  \"origin\": \"192.168.100.130\"\n}\n\n2016-02-23 14:54:36 [scrapy] DEBUG: Crawled (200) <GET https://www.httpbin.org/ip> (referer: None)\nhttps://192.168.100.131:8080\n192.168.100.131\n{\n  \"origin\": \"192.168.100.131\"\n}\n2016-02-23 14:54:37 [scrapy] DEBUG: Crawled (200) <GET https://www.httpbin.org/ip> (referer: None)\nhttps://192.168.100.132:8080\n192.168.100.132\n{\n  \"origin\": \"192.168.100.132\"\n}\n\n# Here Scrapy used wrong proxy to connect to site.\n2016-02-23 14:54:37 [scrapy] DEBUG: Crawled (200) <GET https://www.httpbin.org/ip> (referer: None)\nhttps://192.168.100.134:8080\n192.168.100.134\n{\n  \"origin\": \"192.168.100.130\"\n}\n```\n\nMay be I've make something wrong? Any idea? Thank you.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1807/reactions", "total_count": 3, "+1": 3, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1807/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1783", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1783/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1783/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1783/events", "html_url": "https://github.com/scrapy/scrapy/issues/1783", "id": 134094793, "node_id": "MDU6SXNzdWUxMzQwOTQ3OTM=", "number": 1783, "title": "get_base_url fails for non-ascii URLs in Python 3", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/7", "html_url": "https://github.com/scrapy/scrapy/milestone/7", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/7/labels", "id": 1008005, "node_id": "MDk6TWlsZXN0b25lMTAwODAwNQ==", "number": 7, "title": "v1.1", "description": "", "creator": {"login": "pablohoffman", "id": 185212, "node_id": "MDQ6VXNlcjE4NTIxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/185212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pablohoffman", "html_url": "https://github.com/pablohoffman", "followers_url": "https://api.github.com/users/pablohoffman/followers", "following_url": "https://api.github.com/users/pablohoffman/following{/other_user}", "gists_url": "https://api.github.com/users/pablohoffman/gists{/gist_id}", "starred_url": "https://api.github.com/users/pablohoffman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pablohoffman/subscriptions", "organizations_url": "https://api.github.com/users/pablohoffman/orgs", "repos_url": "https://api.github.com/users/pablohoffman/repos", "events_url": "https://api.github.com/users/pablohoffman/events{/privacy}", "received_events_url": "https://api.github.com/users/pablohoffman/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 99, "state": "closed", "created_at": "2015-03-05T18:14:46Z", "updated_at": "2016-05-11T18:55:46Z", "due_on": "2016-03-15T07:00:00Z", "closed_at": "2016-05-11T18:55:46Z"}, "comments": 3, "created_at": "2016-02-16T20:56:33Z", "updated_at": "2016-04-12T14:56:08Z", "closed_at": "2016-04-12T14:56:08Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "E.g. for this page\n\n> http://naftir.com/index.php/%D9%85%D8%AE%D8%A7%D8%B2%D9%86-%D8%B0%D8%AE%DB%8C%D8%B1%D9%87\n\nscrapy.utils.response.get_base_url raises the following exception in Pyhton 3:\n\n```\nFile \"/Users/kmike/svn/scrapy/scrapy/utils/response.py\", line 30, in get_base_url\n    response.encoding)\n  File \"/Users/kmike/envs/dl/lib/python3.5/site-packages/w3lib-1.13.0-py3.5.egg/w3lib/html.py\", line 287, in get_base_url\n    baseurl = moves.urllib.parse.urljoin(baseurl, m.group(1).encode(encoding))\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/urllib/parse.py\", line 415, in urljoin\n    base, url, _coerce_result = _coerce_args(base, url)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/urllib/parse.py\", line 114, in _coerce_args\n    return _decode_args(args) + (_encode_result,)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/urllib/parse.py\", line 98, in _decode_args\n    return tuple(x.decode(encoding, errors) if x else '' for x in args)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/urllib/parse.py\", line 98, in <genexpr>\n    return tuple(x.decode(encoding, errors) if x else '' for x in args)\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xd9 in position 28: ordinal not in range(128)\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1783/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1783/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1782", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1782/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1782/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1782/events", "html_url": "https://github.com/scrapy/scrapy/issues/1782", "id": 134070286, "node_id": "MDU6SXNzdWUxMzQwNzAyODY=", "number": 1782, "title": "PY3: error decoding Content-Disposition header", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/7", "html_url": "https://github.com/scrapy/scrapy/milestone/7", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/7/labels", "id": 1008005, "node_id": "MDk6TWlsZXN0b25lMTAwODAwNQ==", "number": 7, "title": "v1.1", "description": "", "creator": {"login": "pablohoffman", "id": 185212, "node_id": "MDQ6VXNlcjE4NTIxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/185212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pablohoffman", "html_url": "https://github.com/pablohoffman", "followers_url": "https://api.github.com/users/pablohoffman/followers", "following_url": "https://api.github.com/users/pablohoffman/following{/other_user}", "gists_url": "https://api.github.com/users/pablohoffman/gists{/gist_id}", "starred_url": "https://api.github.com/users/pablohoffman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pablohoffman/subscriptions", "organizations_url": "https://api.github.com/users/pablohoffman/orgs", "repos_url": "https://api.github.com/users/pablohoffman/repos", "events_url": "https://api.github.com/users/pablohoffman/events{/privacy}", "received_events_url": "https://api.github.com/users/pablohoffman/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 99, "state": "closed", "created_at": "2015-03-05T18:14:46Z", "updated_at": "2016-05-11T18:55:46Z", "due_on": "2016-03-15T07:00:00Z", "closed_at": "2016-05-11T18:55:46Z"}, "comments": 4, "created_at": "2016-02-16T19:09:44Z", "updated_at": "2016-02-18T22:24:28Z", "closed_at": "2016-02-18T22:24:28Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "This request\n\n```\nscrapy shell 'http://npe.com.cn/plus/save_to_doc.php?id=1666'\n```\n\nraises this error:\n\n```\nTraceback (most recent call last):\n  File \"/Users/kmike/envs/dl/bin/scrapy\", line 9, in <module>\n    load_entry_point('Scrapy', 'console_scripts', 'scrapy')()\n  File \"/Users/kmike/svn/scrapy/scrapy/cmdline.py\", line 142, in execute\n    _run_print_help(parser, _run_command, cmd, args, opts)\n  File \"/Users/kmike/svn/scrapy/scrapy/cmdline.py\", line 88, in _run_print_help\n    func(*a, **kw)\n  File \"/Users/kmike/svn/scrapy/scrapy/cmdline.py\", line 149, in _run_command\n    cmd.run(args, opts)\n  File \"/Users/kmike/svn/scrapy/scrapy/commands/shell.py\", line 71, in run\n    shell.start(url=url)\n  File \"/Users/kmike/svn/scrapy/scrapy/shell.py\", line 47, in start\n    self.fetch(url, spider)\n  File \"/Users/kmike/svn/scrapy/scrapy/shell.py\", line 112, in fetch\n    reactor, self._schedule, request, spider)\n  File \"/Users/kmike/envs/dl/lib/python3.5/site-packages/Twisted-15.5.0-py3.5.egg/twisted/internet/threads.py\", line 122, in blockingCallFromThread\n    result.raiseException()\n  File \"/Users/kmike/envs/dl/lib/python3.5/site-packages/Twisted-15.5.0-py3.5.egg/twisted/python/failure.py\", line 368, in raiseException\n    raise self.value.with_traceback(self.tb)\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xb8 in position 25: invalid start byte\n```\n\nThe error points to a wrong location (similar to #1760); the real traceback is\n\n```\nTraceback (most recent call last):\n  File \"/Users/kmike/envs/dl/lib/python3.5/site-packages/Twisted-15.5.0-py3.5.egg/twisted/internet/defer.py\", line 1126, in _inlineCallbacks\n    result = result.throwExceptionIntoGenerator(g)\n  File \"/Users/kmike/envs/dl/lib/python3.5/site-packages/Twisted-15.5.0-py3.5.egg/twisted/python/failure.py\", line 389, in throwExceptionIntoGenerator\n    return g.throw(self.type, self.value, self.tb)\n  File \"/Users/kmike/svn/scrapy/scrapy/core/downloader/middleware.py\", line 43, in process_request\n    defer.returnValue((yield download_func(request=request,spider=spider)))\n  File \"/Users/kmike/envs/dl/lib/python3.5/site-packages/Twisted-15.5.0-py3.5.egg/twisted/internet/defer.py\", line 588, in _runCallbacks\n    current.result = callback(current.result, *args, **kw)\n  File \"/Users/kmike/svn/scrapy/scrapy/core/downloader/handlers/http11.py\", line 272, in _cb_bodydone\n    respcls = responsetypes.from_args(headers=headers, url=url)\n  File \"/Users/kmike/svn/scrapy/scrapy/responsetypes.py\", line 110, in from_args\n    cls = self.from_headers(headers)\n  File \"/Users/kmike/svn/scrapy/scrapy/responsetypes.py\", line 78, in from_headers\n    cls = self.from_content_disposition(headers[b'Content-Disposition'])\n  File \"/Users/kmike/svn/scrapy/scrapy/responsetypes.py\", line 62, in from_content_disposition\n    filename = to_native_str(content_disposition).split(';')[1].split('=')[1]\n  File \"/Users/kmike/svn/scrapy/scrapy/utils/python.py\", line 129, in to_native_str\n    return to_unicode(text, encoding, errors)\n  File \"/Users/kmike/svn/scrapy/scrapy/utils/python.py\", line 107, in to_unicode\n    return text.decode(encoding, errors)\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xb8 in position 25: invalid start byte\n```\n\nIt looks like Content-Disposition is decoded using utf-8, but the encoding was not UTF-8.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1782/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1782/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1764", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1764/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1764/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1764/events", "html_url": "https://github.com/scrapy/scrapy/issues/1764", "id": 131659833, "node_id": "MDU6SXNzdWUxMzE2NTk4MzM=", "number": 1764, "title": "sslv3 alert handshake failure when making a request", "user": {"login": "lagenar", "id": 38682, "node_id": "MDQ6VXNlcjM4Njgy", "avatar_url": "https://avatars.githubusercontent.com/u/38682?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lagenar", "html_url": "https://github.com/lagenar", "followers_url": "https://api.github.com/users/lagenar/followers", "following_url": "https://api.github.com/users/lagenar/following{/other_user}", "gists_url": "https://api.github.com/users/lagenar/gists{/gist_id}", "starred_url": "https://api.github.com/users/lagenar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lagenar/subscriptions", "organizations_url": "https://api.github.com/users/lagenar/orgs", "repos_url": "https://api.github.com/users/lagenar/repos", "events_url": "https://api.github.com/users/lagenar/events{/privacy}", "received_events_url": "https://api.github.com/users/lagenar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 320345582, "node_id": "MDU6TGFiZWwzMjAzNDU1ODI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/https", "name": "https", "color": "101e89", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 36, "created_at": "2016-02-05T14:34:13Z", "updated_at": "2016-07-11T07:24:31Z", "closed_at": "2016-07-11T07:24:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi there, I recently upgraded to the latest scrapy and on some sites SSL enabled sites I get an exception when trying to make requests to it, while on previous scrapy versions I didn't have this issue.\nThe issue can be seen by making a request with scrapy shell:\n\n`scrapy shell \"https://www.gohastings.com/\"`\n\nThe error I get is: \n`Retrying <GET https://www.gohastings.com/> (failed 1 times): <twisted.python.failure.Failure OpenSSL.SSL.Error: ('SSL routines', 'SSL3_READ_BYTES', 'sslv3 alert handshake failure'), ('SSL routines', 'SSL3_WRITE_BYTES', 'ssl handshake failure')>`\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1764/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1764/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1738", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1738/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1738/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1738/events", "html_url": "https://github.com/scrapy/scrapy/issues/1738", "id": 129223286, "node_id": "MDU6SXNzdWUxMjkyMjMyODY=", "number": 1738, "title": "AttributeError when exporting non-string types through XMLFeedExporter", "user": {"login": "stummjr", "id": 1170435, "node_id": "MDQ6VXNlcjExNzA0MzU=", "avatar_url": "https://avatars.githubusercontent.com/u/1170435?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stummjr", "html_url": "https://github.com/stummjr", "followers_url": "https://api.github.com/users/stummjr/followers", "following_url": "https://api.github.com/users/stummjr/following{/other_user}", "gists_url": "https://api.github.com/users/stummjr/gists{/gist_id}", "starred_url": "https://api.github.com/users/stummjr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stummjr/subscriptions", "organizations_url": "https://api.github.com/users/stummjr/orgs", "repos_url": "https://api.github.com/users/stummjr/repos", "events_url": "https://api.github.com/users/stummjr/events{/privacy}", "received_events_url": "https://api.github.com/users/stummjr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/7", "html_url": "https://github.com/scrapy/scrapy/milestone/7", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/7/labels", "id": 1008005, "node_id": "MDk6TWlsZXN0b25lMTAwODAwNQ==", "number": 7, "title": "v1.1", "description": "", "creator": {"login": "pablohoffman", "id": 185212, "node_id": "MDQ6VXNlcjE4NTIxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/185212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pablohoffman", "html_url": "https://github.com/pablohoffman", "followers_url": "https://api.github.com/users/pablohoffman/followers", "following_url": "https://api.github.com/users/pablohoffman/following{/other_user}", "gists_url": "https://api.github.com/users/pablohoffman/gists{/gist_id}", "starred_url": "https://api.github.com/users/pablohoffman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pablohoffman/subscriptions", "organizations_url": "https://api.github.com/users/pablohoffman/orgs", "repos_url": "https://api.github.com/users/pablohoffman/repos", "events_url": "https://api.github.com/users/pablohoffman/events{/privacy}", "received_events_url": "https://api.github.com/users/pablohoffman/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 99, "state": "closed", "created_at": "2015-03-05T18:14:46Z", "updated_at": "2016-05-11T18:55:46Z", "due_on": "2016-03-15T07:00:00Z", "closed_at": "2016-05-11T18:55:46Z"}, "comments": 1, "created_at": "2016-01-27T18:03:42Z", "updated_at": "2016-02-03T14:37:49Z", "closed_at": "2016-02-02T04:35:39Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Scrapy 1.0.4 fails to export items to XML when those items have non-string types. I tested it with a spider that generates an item like this: `{'int': 2, 'boolean1': True, 'boolean2': False, 'time': datetime.datetime(2015, 1, 1, 1, 1, 1)}`.\n\nHere is what I got when running the Spider to export XML items:\n\n```\n$ scrapy runspider example.py -o items.xml\n...\n2016-01-27 15:55:42 [scrapy] DEBUG: Scraped from <200 http://www.example.com/>\n{'int': 2, 'boolean': True, 'boolean2': False, 'time': datetime.datetime(2015, 1, 1, 1, 1, 1)}\n2016-01-27 15:55:42 [scrapy] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x7f5f70075650>>\nTraceback (most recent call last):\n  File \"/home/stummjr/.virtualenvs/scrapy/local/lib/python2.7/site-packages/twisted/internet/defer.py\", line 150, in maybeDeferred\n    result = f(*args, **kw)\n  File \"/home/stummjr/.virtualenvs/scrapy/local/lib/python2.7/site-packages/scrapy/xlib/pydispatch/robustapply.py\", line 57, in robustApply\n    return receiver(*arguments, **named)\n  File \"/home/stummjr/.virtualenvs/scrapy/local/lib/python2.7/site-packages/scrapy/extensions/feedexport.py\", line 193, in item_scraped\n    slot.exporter.export_item(item)\n  File \"/home/stummjr/.virtualenvs/scrapy/local/lib/python2.7/site-packages/scrapy/exporters.py\", line 130, in export_item\n    self._export_xml_field(name, value)\n  File \"/home/stummjr/.virtualenvs/scrapy/local/lib/python2.7/site-packages/scrapy/exporters.py\", line 146, in _export_xml_field\n    self._xg_characters(serialized_value)\n  File \"/home/stummjr/.virtualenvs/scrapy/local/lib/python2.7/site-packages/scrapy/exporters.py\", line 157, in _xg_characters\n    serialized_value = serialized_value.decode(self.encoding)\nAttributeError: 'int' object has no attribute 'decode'\n...\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1738/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1738/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1733", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1733/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1733/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1733/events", "html_url": "https://github.com/scrapy/scrapy/issues/1733", "id": 129115128, "node_id": "MDU6SXNzdWUxMjkxMTUxMjg=", "number": 1733, "title": "KeyError in robotstxt middleware", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/7", "html_url": "https://github.com/scrapy/scrapy/milestone/7", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/7/labels", "id": 1008005, "node_id": "MDk6TWlsZXN0b25lMTAwODAwNQ==", "number": 7, "title": "v1.1", "description": "", "creator": {"login": "pablohoffman", "id": 185212, "node_id": "MDQ6VXNlcjE4NTIxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/185212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pablohoffman", "html_url": "https://github.com/pablohoffman", "followers_url": "https://api.github.com/users/pablohoffman/followers", "following_url": "https://api.github.com/users/pablohoffman/following{/other_user}", "gists_url": "https://api.github.com/users/pablohoffman/gists{/gist_id}", "starred_url": "https://api.github.com/users/pablohoffman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pablohoffman/subscriptions", "organizations_url": "https://api.github.com/users/pablohoffman/orgs", "repos_url": "https://api.github.com/users/pablohoffman/repos", "events_url": "https://api.github.com/users/pablohoffman/events{/privacy}", "received_events_url": "https://api.github.com/users/pablohoffman/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 99, "state": "closed", "created_at": "2015-03-05T18:14:46Z", "updated_at": "2016-05-11T18:55:46Z", "due_on": "2016-03-15T07:00:00Z", "closed_at": "2016-05-11T18:55:46Z"}, "comments": 1, "created_at": "2016-01-27T11:25:14Z", "updated_at": "2016-02-03T15:30:06Z", "closed_at": "2016-02-03T15:30:06Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I'm getting these errors in robots.txt middleware:\n\n```\n2016-01-27 16:18:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://yellowpages.co.th>\nTraceback (most recent call last):\n  File \"/Users/kmike/envs/scraping/lib/python2.7/site-packages/twisted/internet/defer.py\", line 150, in maybeDeferred\n    result = f(*args, **kw)\n  File \"/Users/kmike/svn/scrapy/scrapy/downloadermiddlewares/robotstxt.py\", line 65, in robot_parser\n    if isinstance(self._parsers[netloc], Deferred):\nKeyError: 'yellowpages.co.th'\n```\n\nIt looks like https://github.com/scrapy/scrapy/pull/1473 caused it (I can't get this issue in Scrapy 1.0.4, but it present in Scrapy master). It happens when page failed to download and HTTP cache is enabled. I haven't debugged it further.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1733/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1733/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1685", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1685/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1685/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1685/events", "html_url": "https://github.com/scrapy/scrapy/issues/1685", "id": 127100973, "node_id": "MDU6SXNzdWUxMjcxMDA5NzM=", "number": 1685, "title": "django.setup() used for django_item causes a massive memory leak in Scrapy", "user": {"login": "jschilling1", "id": 12403565, "node_id": "MDQ6VXNlcjEyNDAzNTY1", "avatar_url": "https://avatars.githubusercontent.com/u/12403565?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jschilling1", "html_url": "https://github.com/jschilling1", "followers_url": "https://api.github.com/users/jschilling1/followers", "following_url": "https://api.github.com/users/jschilling1/following{/other_user}", "gists_url": "https://api.github.com/users/jschilling1/gists{/gist_id}", "starred_url": "https://api.github.com/users/jschilling1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jschilling1/subscriptions", "organizations_url": "https://api.github.com/users/jschilling1/orgs", "repos_url": "https://api.github.com/users/jschilling1/repos", "events_url": "https://api.github.com/users/jschilling1/events{/privacy}", "received_events_url": "https://api.github.com/users/jschilling1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-01-17T15:15:32Z", "updated_at": "2019-08-19T16:07:43Z", "closed_at": "2019-08-19T16:07:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "I need to call django.setup() to use django_item, when i do, Scrapy's memory usage keeps growing with the number of returned items.\n\nMy actual spider returns about 100 pages per html, but 1000 makes it grow to a gigabyte in minutes for the purposes of this.\n    def parse(self, response):\n        return ({'url': 'http://localhost/=%s' % randint(1, 9999999)} for i in xrange(1000))\n\nDisabling 'debug_toolbar' in INSTALLED_APPS fixes this problem.\nI'd really like to know how its affecting Scrapy. It took me a while to track it down django, guppy and trackrefs didn't point to a specific problem except a unicode() and dict() object count build up. \n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1685/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1685/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1646", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1646/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1646/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1646/events", "html_url": "https://github.com/scrapy/scrapy/issues/1646", "id": 123191351, "node_id": "MDU6SXNzdWUxMjMxOTEzNTE=", "number": 1646, "title": "ipython 4.0.1 / python 2.7.11 \"scrapy shell\" breaks with \"ValueError: fallback required, but not specified\"", "user": {"login": "jschilling1", "id": 12403565, "node_id": "MDQ6VXNlcjEyNDAzNTY1", "avatar_url": "https://avatars.githubusercontent.com/u/12403565?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jschilling1", "html_url": "https://github.com/jschilling1", "followers_url": "https://api.github.com/users/jschilling1/followers", "following_url": "https://api.github.com/users/jschilling1/following{/other_user}", "gists_url": "https://api.github.com/users/jschilling1/gists{/gist_id}", "starred_url": "https://api.github.com/users/jschilling1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jschilling1/subscriptions", "organizations_url": "https://api.github.com/users/jschilling1/orgs", "repos_url": "https://api.github.com/users/jschilling1/repos", "events_url": "https://api.github.com/users/jschilling1/events{/privacy}", "received_events_url": "https://api.github.com/users/jschilling1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 281088273, "node_id": "MDU6TGFiZWwyODEwODgyNzM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/help%20wanted", "name": "help wanted", "color": "009800", "default": true, "description": null}, {"id": 317415181, "node_id": "MDU6TGFiZWwzMTc0MTUxODE=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/logging", "name": "logging", "color": "fbca04", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2015-12-21T00:07:25Z", "updated_at": "2023-01-29T20:57:44Z", "closed_at": "2023-01-29T20:57:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "scrapy shell \"url\" breaks with the following traceback:\n\nTraceback (most recent call last):\n  File \"/home/user/.pyenv/versions/master2/bin/scrapy\", line 11, in <module>\n    sys.exit(execute())\n  File \"/home/user/.pyenv/versions/2.7.11/envs/master2/lib/python2.7/site-packages/scrapy/cmdline.py\", line 143, in execute\n    _run_print_help(parser, _run_command, cmd, args, opts)\n  File \"/home/user/.pyenv/versions/2.7.11/envs/master2/lib/python2.7/site-packages/scrapy/cmdline.py\", line 89, in _run_print_help\n    func(_a, *_kw)\n  File \"/home/user/.pyenv/versions/2.7.11/envs/master2/lib/python2.7/site-packages/scrapy/cmdline.py\", line 150, in _run_command\n    cmd.run(args, opts)\n  File \"/home/user/.pyenv/versions/2.7.11/envs/master2/lib/python2.7/site-packages/scrapy/commands/shell.py\", line 63, in run\n    shell.start(url=url)\n  File \"/home/user/.pyenv/versions/2.7.11/envs/master2/lib/python2.7/site-packages/scrapy/shell.py\", line 55, in start\n    start_python_console(self.vars)\n  File \"/home/user/.pyenv/versions/2.7.11/envs/master2/lib/python2.7/site-packages/scrapy/utils/console.py\", line 24, in start_python_console\n    banner1=banner, user_ns=namespace, config=config)\n  File \"/home/user/.pyenv/versions/2.7.11/envs/master2/lib/python2.7/site-packages/IPython/terminal/embed.py\", line 68, in __init__\n    super(InteractiveShellEmbed,self).**init**(**kw)\n  File \"/home/user/.pyenv/versions/2.7.11/envs/master2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 547, in **init**\n    self.init_io()\n  File \"/home/user/.pyenv/versions/2.7.11/envs/master2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 718, in init_io\n    io.stdout = io.IOStream(sys.stdout)\n  File \"/home/user/.pyenv/versions/2.7.11/envs/master2/lib/python2.7/site-packages/IPython/utils/io.py\", line 28, in **init**\n    raise ValueError(\"fallback required, but not specified\")\nValueError: fallback required, but not specified\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1646/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1646/timeline", "performed_via_github_app": null, "state_reason": "not_planned"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1616", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1616/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1616/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1616/events", "html_url": "https://github.com/scrapy/scrapy/issues/1616", "id": 118829431, "node_id": "MDU6SXNzdWUxMTg4Mjk0MzE=", "number": 1616, "title": "Big download is not being cancelled properly", "user": {"login": "katcipis", "id": 157634, "node_id": "MDQ6VXNlcjE1NzYzNA==", "avatar_url": "https://avatars.githubusercontent.com/u/157634?v=4", "gravatar_id": "", "url": "https://api.github.com/users/katcipis", "html_url": "https://github.com/katcipis", "followers_url": "https://api.github.com/users/katcipis/followers", "following_url": "https://api.github.com/users/katcipis/following{/other_user}", "gists_url": "https://api.github.com/users/katcipis/gists{/gist_id}", "starred_url": "https://api.github.com/users/katcipis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/katcipis/subscriptions", "organizations_url": "https://api.github.com/users/katcipis/orgs", "repos_url": "https://api.github.com/users/katcipis/repos", "events_url": "https://api.github.com/users/katcipis/events{/privacy}", "received_events_url": "https://api.github.com/users/katcipis/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/15", "html_url": "https://github.com/scrapy/scrapy/milestone/15", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/15/labels", "id": 1977308, "node_id": "MDk6TWlsZXN0b25lMTk3NzMwOA==", "number": 15, "title": "v1.4", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 67, "state": "closed", "created_at": "2016-09-01T09:43:32Z", "updated_at": "2017-08-28T11:12:21Z", "due_on": null, "closed_at": "2017-08-28T11:12:21Z"}, "comments": 2, "created_at": "2015-11-25T12:46:06Z", "updated_at": "2017-05-04T14:44:52Z", "closed_at": "2017-05-04T14:44:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am running scrapy 1.0.1 in my pyhon web crawler and setting the max download size like this: \n\n`DOWNLOAD_MAXSIZE = 41943040 #40MB`.\n\nWhen I run into a bigger file, scrappy keeps logging the error: `ERROR: Received (51316256) bytes larger than download max size (41943040)` but never stops. I have looked into the code and saw a call to cancel the processe [here](https://github.com/scrapy/scrapy/blob/1.0.1/scrapy/core/downloader/handlers/http11.py#L306), but in my case is not working, the download keeps going on.\n\nAny thoughts on why this would happen ? It seems to be something wrong on twisted not cancelling the download.\n\nDetailed version info:\n\n```\nscrapy version -v\n2015-11-25 10:44:54 [scrapy] INFO: Scrapy 1.0.1 started (bot:)\n2015-11-25 10:44:54 [scrapy] INFO: Optional features available: ssl, http11\n2015-11-25 10:44:54 [scrapy] INFO: Overridden settings: {'COOKIES_DEBUG': True, 'DOWNLOAD_TIMEOUT': 600, 'SPIDER_MODULES': ['spiders'], 'CONCURRENT_REQUESTS': 10, 'RANDOMIZE_DOWNLOAD_DELAY': False, 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'RETRY_TIMES': 10, 'BOT_NAME': 'bot', 'DOWNLOAD_MAXSIZE': 41943040, 'USER_AGENT': 'Mozilla/5.0 (X11; Linux i686; rv:23.0) Gecko/20100101 Firefox/23.0', 'NEWSPIDER_MODULE': 'spiders'}\nScrapy  : 1.0.1\nlxml    : 3.5.0.0\nlibxml2 : 2.9.2\nTwisted : 15.4.0\nPython  : 2.7.10 (default, Aug 13 2015, 12:27:27) - [GCC 4.9.2]\nPlatform: Linux-3.16.0-38-generic-x86_64-with\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1616/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1616/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1612", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1612/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1612/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1612/events", "html_url": "https://github.com/scrapy/scrapy/issues/1612", "id": 118304261, "node_id": "MDU6SXNzdWUxMTgzMDQyNjE=", "number": 1612, "title": "scrapy LOG_LEVEL setting in Spider.custom_settings does not work", "user": {"login": "YAmikep", "id": 1226080, "node_id": "MDQ6VXNlcjEyMjYwODA=", "avatar_url": "https://avatars.githubusercontent.com/u/1226080?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YAmikep", "html_url": "https://github.com/YAmikep", "followers_url": "https://api.github.com/users/YAmikep/followers", "following_url": "https://api.github.com/users/YAmikep/following{/other_user}", "gists_url": "https://api.github.com/users/YAmikep/gists{/gist_id}", "starred_url": "https://api.github.com/users/YAmikep/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YAmikep/subscriptions", "organizations_url": "https://api.github.com/users/YAmikep/orgs", "repos_url": "https://api.github.com/users/YAmikep/repos", "events_url": "https://api.github.com/users/YAmikep/events{/privacy}", "received_events_url": "https://api.github.com/users/YAmikep/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 317415181, "node_id": "MDU6TGFiZWwzMTc0MTUxODE=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/logging", "name": "logging", "color": "fbca04", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2015-11-23T01:33:57Z", "updated_at": "2017-03-09T11:47:32Z", "closed_at": "2017-03-09T11:47:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "I set the `LOG_LEVEL` setting to `INFO` in the Spider class via the `custom_settings` attribute but I still see the `DEBUG` messages in the console.\n\nWhen I set it on the `settings.py` file or via the command line option `--loglevel`, it works.\n\nI thought any settings could be set via the `custom_settings` attribute. Is that a bug? (Scrapy 1.0.3 and python 2.7.10)\n\n```\nclass TestSpider(scrapy.Spider):\n    name = \"Test\"\n    ...\n    custom_settings = {\n        'LOG_LEVEL': 'INFO',\n    }\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1612/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1612/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1611", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1611/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1611/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1611/events", "html_url": "https://github.com/scrapy/scrapy/issues/1611", "id": 118222724, "node_id": "MDU6SXNzdWUxMTgyMjI3MjQ=", "number": 1611, "title": "_sent_failed cut the errback chain in MailSender", "user": {"login": "aplanas", "id": 645701, "node_id": "MDQ6VXNlcjY0NTcwMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/645701?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aplanas", "html_url": "https://github.com/aplanas", "followers_url": "https://api.github.com/users/aplanas/followers", "following_url": "https://api.github.com/users/aplanas/following{/other_user}", "gists_url": "https://api.github.com/users/aplanas/gists{/gist_id}", "starred_url": "https://api.github.com/users/aplanas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aplanas/subscriptions", "organizations_url": "https://api.github.com/users/aplanas/orgs", "repos_url": "https://api.github.com/users/aplanas/repos", "events_url": "https://api.github.com/users/aplanas/events{/privacy}", "received_events_url": "https://api.github.com/users/aplanas/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Prathm-s", "id": 40636045, "node_id": "MDQ6VXNlcjQwNjM2MDQ1", "avatar_url": "https://avatars.githubusercontent.com/u/40636045?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Prathm-s", "html_url": "https://github.com/Prathm-s", "followers_url": "https://api.github.com/users/Prathm-s/followers", "following_url": "https://api.github.com/users/Prathm-s/following{/other_user}", "gists_url": "https://api.github.com/users/Prathm-s/gists{/gist_id}", "starred_url": "https://api.github.com/users/Prathm-s/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Prathm-s/subscriptions", "organizations_url": "https://api.github.com/users/Prathm-s/orgs", "repos_url": "https://api.github.com/users/Prathm-s/repos", "events_url": "https://api.github.com/users/Prathm-s/events{/privacy}", "received_events_url": "https://api.github.com/users/Prathm-s/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Prathm-s", "id": 40636045, "node_id": "MDQ6VXNlcjQwNjM2MDQ1", "avatar_url": "https://avatars.githubusercontent.com/u/40636045?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Prathm-s", "html_url": "https://github.com/Prathm-s", "followers_url": "https://api.github.com/users/Prathm-s/followers", "following_url": "https://api.github.com/users/Prathm-s/following{/other_user}", "gists_url": "https://api.github.com/users/Prathm-s/gists{/gist_id}", "starred_url": "https://api.github.com/users/Prathm-s/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Prathm-s/subscriptions", "organizations_url": "https://api.github.com/users/Prathm-s/orgs", "repos_url": "https://api.github.com/users/Prathm-s/repos", "events_url": "https://api.github.com/users/Prathm-s/events{/privacy}", "received_events_url": "https://api.github.com/users/Prathm-s/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2015-11-21T21:42:13Z", "updated_at": "2023-04-11T13:38:08Z", "closed_at": "2023-04-11T13:38:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "`MailSender._sent_failed` return `None`, instead of `failure`.  This cut the errback call chain, making impossible to detect in the code fail in the mails in client code.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1611/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1611/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1606", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1606/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1606/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1606/events", "html_url": "https://github.com/scrapy/scrapy/issues/1606", "id": 117210478, "node_id": "MDU6SXNzdWUxMTcyMTA0Nzg=", "number": 1606, "title": "response.body is duplicate", "user": {"login": "fanpei91", "id": 5484841, "node_id": "MDQ6VXNlcjU0ODQ4NDE=", "avatar_url": "https://avatars.githubusercontent.com/u/5484841?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fanpei91", "html_url": "https://github.com/fanpei91", "followers_url": "https://api.github.com/users/fanpei91/followers", "following_url": "https://api.github.com/users/fanpei91/following{/other_user}", "gists_url": "https://api.github.com/users/fanpei91/gists{/gist_id}", "starred_url": "https://api.github.com/users/fanpei91/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fanpei91/subscriptions", "organizations_url": "https://api.github.com/users/fanpei91/orgs", "repos_url": "https://api.github.com/users/fanpei91/repos", "events_url": "https://api.github.com/users/fanpei91/events{/privacy}", "received_events_url": "https://api.github.com/users/fanpei91/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2015-11-16T20:27:06Z", "updated_at": "2016-08-17T12:51:30Z", "closed_at": "2016-08-17T12:51:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "Access the [text page(not mine)](http://files.qidian.com/Author4/3615059/88542882.txt) by browsers or wget and you will find  the response content is not duplicate, but scrapy's `response.body` is duplicate. I had tried set the scrapy's headers same as a real brower's, but it is still duplicate.\n\nJust use the follow sample code, and you will find the issue.\n\n```\nscrapy shell \"http://files.qidian.com/Author4/3615059/88542882.txt\"\n```\n\nSorry for my bad english. \n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1606/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1606/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1596", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1596/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1596/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1596/events", "html_url": "https://github.com/scrapy/scrapy/issues/1596", "id": 116648620, "node_id": "MDU6SXNzdWUxMTY2NDg2MjA=", "number": 1596, "title": "FormRequest doesn't handle input elements without type attribute", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 281088273, "node_id": "MDU6TGFiZWwyODEwODgyNzM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/help%20wanted", "name": "help wanted", "color": "009800", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2015-11-12T21:50:29Z", "updated_at": "2015-12-04T12:57:31Z", "closed_at": "2015-12-04T12:57:31Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "When `<input>` element has no `type` attribute browsers use default input type ('text'). See https://html.spec.whatwg.org/multipage/forms.html#attr-input-type: \n\n> The missing value default is the Text state.\n\nFormRequest doesn't submit such fields at all. Likely adding `or not(@type)` somewhere to xpaths can fix it.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1596/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1596/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1595", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1595/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1595/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1595/events", "html_url": "https://github.com/scrapy/scrapy/issues/1595", "id": 116647113, "node_id": "MDU6SXNzdWUxMTY2NDcxMTM=", "number": 1595, "title": "FormRequest should consider input type values case-insensitive", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 281088273, "node_id": "MDU6TGFiZWwyODEwODgyNzM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/help%20wanted", "name": "help wanted", "color": "009800", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2015-11-12T21:41:48Z", "updated_at": "2015-12-04T12:56:52Z", "closed_at": "2015-12-04T12:56:52Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "`<input>` [type](https://html.spec.whatwg.org/multipage/forms.html#attr-input-type) attribute is an [enumerated attribute](https://html.spec.whatwg.org/multipage/infrastructure.html#enumerated-attribute); values of such attributes are case-insensitive. All XPaths in FormRequest [source code](https://github.com/scrapy/scrapy/blob/master/scrapy/http/request/form.py) treat them as case-sensitive.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1595/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1595/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1593", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1593/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1593/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1593/events", "html_url": "https://github.com/scrapy/scrapy/issues/1593", "id": 116461644, "node_id": "MDU6SXNzdWUxMTY0NjE2NDQ=", "number": 1593, "title": "Fix REDIRECT_PRIORITY_ADJUST docs", "user": {"login": "curita", "id": 213781, "node_id": "MDQ6VXNlcjIxMzc4MQ==", "avatar_url": "https://avatars.githubusercontent.com/u/213781?v=4", "gravatar_id": "", "url": "https://api.github.com/users/curita", "html_url": "https://github.com/curita", "followers_url": "https://api.github.com/users/curita/followers", "following_url": "https://api.github.com/users/curita/following{/other_user}", "gists_url": "https://api.github.com/users/curita/gists{/gist_id}", "starred_url": "https://api.github.com/users/curita/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/curita/subscriptions", "organizations_url": "https://api.github.com/users/curita/orgs", "repos_url": "https://api.github.com/users/curita/repos", "events_url": "https://api.github.com/users/curita/events{/privacy}", "received_events_url": "https://api.github.com/users/curita/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 183224248, "node_id": "MDU6TGFiZWwxODMyMjQyNDg=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2015-11-12T01:45:52Z", "updated_at": "2016-01-27T17:52:39Z", "closed_at": "2016-01-27T17:52:39Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Not sure about it, but what's explained here: http://scrapy.readthedocs.org/en/latest/topics/settings.html#redirect-priority-adjust about priorities seems wrong, priorities in requests work the other way around (higher priority executes first), so a negative adjust would meant to decrease the original request priority to execute the redirect later.\n\nBy all means if this isn't the case, some note about why it seems to contradict what it is said about priorities in http://scrapy.readthedocs.org/en/latest/topics/request-response.html#request-objects would be helpful, got really confused there :(\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1593/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1593/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1486", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1486/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1486/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1486/events", "html_url": "https://github.com/scrapy/scrapy/issues/1486", "id": 105614791, "node_id": "MDU6SXNzdWUxMDU2MTQ3OTE=", "number": 1486, "title": "twisted.web._newclient.ResponseNeverReceived:", "user": {"login": "VMRuiz", "id": 5072090, "node_id": "MDQ6VXNlcjUwNzIwOTA=", "avatar_url": "https://avatars.githubusercontent.com/u/5072090?v=4", "gravatar_id": "", "url": "https://api.github.com/users/VMRuiz", "html_url": "https://github.com/VMRuiz", "followers_url": "https://api.github.com/users/VMRuiz/followers", "following_url": "https://api.github.com/users/VMRuiz/following{/other_user}", "gists_url": "https://api.github.com/users/VMRuiz/gists{/gist_id}", "starred_url": "https://api.github.com/users/VMRuiz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/VMRuiz/subscriptions", "organizations_url": "https://api.github.com/users/VMRuiz/orgs", "repos_url": "https://api.github.com/users/VMRuiz/repos", "events_url": "https://api.github.com/users/VMRuiz/events{/privacy}", "received_events_url": "https://api.github.com/users/VMRuiz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 320345582, "node_id": "MDU6TGFiZWwzMjAzNDU1ODI=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/https", "name": "https", "color": "101e89", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/7", "html_url": "https://github.com/scrapy/scrapy/milestone/7", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/7/labels", "id": 1008005, "node_id": "MDk6TWlsZXN0b25lMTAwODAwNQ==", "number": 7, "title": "v1.1", "description": "", "creator": {"login": "pablohoffman", "id": 185212, "node_id": "MDQ6VXNlcjE4NTIxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/185212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pablohoffman", "html_url": "https://github.com/pablohoffman", "followers_url": "https://api.github.com/users/pablohoffman/followers", "following_url": "https://api.github.com/users/pablohoffman/following{/other_user}", "gists_url": "https://api.github.com/users/pablohoffman/gists{/gist_id}", "starred_url": "https://api.github.com/users/pablohoffman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pablohoffman/subscriptions", "organizations_url": "https://api.github.com/users/pablohoffman/orgs", "repos_url": "https://api.github.com/users/pablohoffman/repos", "events_url": "https://api.github.com/users/pablohoffman/events{/privacy}", "received_events_url": "https://api.github.com/users/pablohoffman/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 99, "state": "closed", "created_at": "2015-03-05T18:14:46Z", "updated_at": "2016-05-11T18:55:46Z", "due_on": "2016-03-15T07:00:00Z", "closed_at": "2016-05-11T18:55:46Z"}, "comments": 5, "created_at": "2015-09-09T14:57:11Z", "updated_at": "2016-02-24T22:01:25Z", "closed_at": "2016-02-24T22:01:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hello, When I try to load this website https://www.notjustalabel.com/products/womens I get this error:\n\n``` python\n2015-09-09 16:51:16 [scrapy] INFO: Spider opened\nTraceback (most recent call last):\n  File \"/usr/local/bin/scrapy\", line 11, in <module>\n    sys.exit(execute())\n  File \"/home/victor/.local/lib/python2.7/site-packages/scrapy/cmdline.py\", line 143, in execute\n    _run_print_help(parser, _run_command, cmd, args, opts)\n  File \"/home/victor/.local/lib/python2.7/site-packages/scrapy/cmdline.py\", line 89, in _run_print_help\n    func(*a, **kw)\n  File \"/home/victor/.local/lib/python2.7/site-packages/scrapy/cmdline.py\", line 150, in _run_command\n    cmd.run(args, opts)\n  File \"/home/victor/.local/lib/python2.7/site-packages/scrapy/commands/shell.py\", line 63, in run\n    shell.start(url=url)\n  File \"/home/victor/.local/lib/python2.7/site-packages/scrapy/shell.py\", line 44, in start\n    self.fetch(url, spider)\n  File \"/home/victor/.local/lib/python2.7/site-packages/scrapy/shell.py\", line 87, in fetch\n    reactor, self._schedule, request, spider)\n  File \"/usr/local/lib/python2.7/dist-packages/twisted/internet/threads.py\", line 122, in blockingCallFromThread\n    result.raiseException()\n  File \"<string>\", line 2, in raiseException\ntwisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL3_READ_BYTES', 'ssl handshake failure')]>]\n```\n\nI have also checked that TLSv1 can negociate this cert with curl and everything is fine\n\n``` bash\ncurl --tlsv1 -k https://www.notjustalabel.com/products/womens\n```\n\nThis is my scrapy deployment:\n\n```\n\u279c  mencanta-spiders git:(master) \u2717 scrapy version -v\n2015-09-09 16:55:31 [scrapy] INFO: Scrapy 1.0.3 started (bot: mencanta)\n2015-09-09 16:55:31 [scrapy] INFO: Optional features available: ssl, http11, boto\n2015-09-09 16:55:31 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'mencanta.spiders', 'LOG_LEVEL': 'INFO', 'HTTPCACHE_EXPIRATION_SECS': 604800, 'HTTPCACHE_IGNORE_HTTP_CODES': [301, 302, 307, 403, 404, 401, 400, 402, 407, 500], 'SPIDER_MODULES': ['mencanta.spiders'], 'HTTPCACHE_ENABLED': True, 'BOT_NAME': 'mencanta', 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36'}\nScrapy  : 1.0.3\nlxml    : 3.4.4.0\nlibxml2 : 2.9.2\nTwisted : 15.4.0\nPython  : 2.7.9 (default, Apr  2 2015, 15:33:21) - [GCC 4.9.2]\nPlatform: Linux-3.19.0-26-generic-x86_64-with-Ubuntu-15.04-vivid\n\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1486/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1486/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1459", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1459/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1459/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1459/events", "html_url": "https://github.com/scrapy/scrapy/issues/1459", "id": 103235295, "node_id": "MDU6SXNzdWUxMDMyMzUyOTU=", "number": 1459, "title": "Headers object serializes to json differently depending on the indent value", "user": {"login": "dvdbng", "id": 224189, "node_id": "MDQ6VXNlcjIyNDE4OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/224189?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dvdbng", "html_url": "https://github.com/dvdbng", "followers_url": "https://api.github.com/users/dvdbng/followers", "following_url": "https://api.github.com/users/dvdbng/following{/other_user}", "gists_url": "https://api.github.com/users/dvdbng/gists{/gist_id}", "starred_url": "https://api.github.com/users/dvdbng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dvdbng/subscriptions", "organizations_url": "https://api.github.com/users/dvdbng/orgs", "repos_url": "https://api.github.com/users/dvdbng/repos", "events_url": "https://api.github.com/users/dvdbng/events{/privacy}", "received_events_url": "https://api.github.com/users/dvdbng/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2015-08-26T10:45:01Z", "updated_at": "2022-06-06T11:20:51Z", "closed_at": "2022-06-06T11:20:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "A scrapy.http.headers.Headers instance will serialize to a shallow object if indent=None and wrap the values in a list if indent is a number:\n\n```\n>>> from scrapy.http.headers import Headers\n>>> h = Headers({ \"X-Foo\": \"bar\" })\n>>> print json.dumps(h)\n{\"X-Foo\": \"bar\"}\n>>> print json.dumps(h, indent=3)\n{\n   \"X-Foo\": [\n      \"bar\"\n   ]\n}\n```\n\nTested in Scrapy 1.0.3\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1459/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1459/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1428", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1428/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1428/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1428/events", "html_url": "https://github.com/scrapy/scrapy/issues/1428", "id": 100445126, "node_id": "MDU6SXNzdWUxMDA0NDUxMjY=", "number": 1428, "title": "XML serialiser corrupts output when encountering None values", "user": {"login": "Malvineous", "id": 171656, "node_id": "MDQ6VXNlcjE3MTY1Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/171656?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Malvineous", "html_url": "https://github.com/Malvineous", "followers_url": "https://api.github.com/users/Malvineous/followers", "following_url": "https://api.github.com/users/Malvineous/following{/other_user}", "gists_url": "https://api.github.com/users/Malvineous/gists{/gist_id}", "starred_url": "https://api.github.com/users/Malvineous/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Malvineous/subscriptions", "organizations_url": "https://api.github.com/users/Malvineous/orgs", "repos_url": "https://api.github.com/users/Malvineous/repos", "events_url": "https://api.github.com/users/Malvineous/events{/privacy}", "received_events_url": "https://api.github.com/users/Malvineous/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2015-08-12T01:07:01Z", "updated_at": "2022-12-01T05:17:03Z", "closed_at": "2022-11-28T20:49:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "If you set a field to the value `None` then use the XML serialiser, the output XML becomes corrupted (invalid XML, missing tags, etc.) and you get the following exception for each item during the scrapy run:\n\n```\n2015-08-12 11:01:43 [scrapy] ERROR: Error caught on signal handler: <bound method ?.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x7f70e7723ed0>>\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/site-packages/twisted/internet/defer.py\", line 150, in maybeDeferred\n    result = f(*args, **kw)\n  File \"/usr/lib/python2.7/site-packages/scrapy/xlib/pydispatch/robustapply.py\", line 57, in robustApply\n    return receiver(*arguments, **named)\n  File \"/usr/lib/python2.7/site-packages/scrapy/extensions/feedexport.py\", line 193, in item_scraped\n    slot.exporter.export_item(item)\n  File \"/usr/lib/python2.7/site-packages/scrapy/exporters.py\", line 130, in export_item\n    self._export_xml_field(name, value)\n  File \"/usr/lib/python2.7/site-packages/scrapy/exporters.py\", line 146, in _export_xml_field\n    self._xg_characters(serialized_value)\n  File \"/usr/lib/python2.7/site-packages/scrapy/exporters.py\", line 157, in _xg_characters\n    serialized_value = serialized_value.decode(self.encoding)\nAttributeError: 'NoneType' object has no attribute 'decode'\n```\n\nThis was happening for me because I was using a CSS selector and `extract_first()`, but the element was optional, so for those items where the element was missing, the field was being set to `None`, causing this problem.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1428/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1428/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1404", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1404/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1404/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1404/events", "html_url": "https://github.com/scrapy/scrapy/issues/1404", "id": 98606253, "node_id": "MDU6SXNzdWU5ODYwNjI1Mw==", "number": 1404, "title": "Exception in LxmLinkExtractor.extract_links 'NoneType' object has no attribute 'iter'", "user": {"login": "aldarund", "id": 571159, "node_id": "MDQ6VXNlcjU3MTE1OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/571159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aldarund", "html_url": "https://github.com/aldarund", "followers_url": "https://api.github.com/users/aldarund/followers", "following_url": "https://api.github.com/users/aldarund/following{/other_user}", "gists_url": "https://api.github.com/users/aldarund/gists{/gist_id}", "starred_url": "https://api.github.com/users/aldarund/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aldarund/subscriptions", "organizations_url": "https://api.github.com/users/aldarund/orgs", "repos_url": "https://api.github.com/users/aldarund/repos", "events_url": "https://api.github.com/users/aldarund/events{/privacy}", "received_events_url": "https://api.github.com/users/aldarund/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443054750, "node_id": "MDU6TGFiZWw0NDMwNTQ3NTA=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/not%20reproducible", "name": "not reproducible", "color": "f9d0c4", "default": false, "description": null}, {"id": 443680419, "node_id": "MDU6TGFiZWw0NDM2ODA0MTk=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/needs%20more%20info", "name": "needs more info", "color": "fef2c0", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2015-08-02T12:26:27Z", "updated_at": "2019-08-19T16:01:19Z", "closed_at": "2019-08-19T16:01:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\nStacktrace (most recent call last):\n\n  File \"scrapy/utils/defer.py\", line 102, in iter_errback\n    yield next(it)\n  File \"scrapy/spidermiddlewares/offsite.py\", line 28, in process_spider_output\n    for x in result:\n  File \"scrapy/spidermiddlewares/referer.py\", line 22, in <genexpr>\n    return (_set_referer(r) for r in result or ())\n  File \"scrapy/spidermiddlewares/offsite.py\", line 28, in process_spider_output\n    for x in result:\n  File \"scrapy/spidermiddlewares/urllength.py\", line 37, in <genexpr>\n    return (r for r in result or () if _filter(r))\n  File \"scrapy/spidermiddlewares/depth.py\", line 54, in <genexpr>\n    return (r for r in result or () if _filter(r))\n  File \"scrapy/spiders/crawl.py\", line 69, in _parse_response\n    for requests_or_item in iterate_spider_output(cb_res):\n  File \"ex_link_crawl/spiders/external_link_spider.py\", line 45, in parse_obj\n    for link in LxmlLinkExtractor(allow=(), deny=self.allowed_domains).extract_links(response):\n  File \"scrapy/linkextractors/lxmlhtml.py\", line 108, in extract_links\n    links = self._extract_links(doc, response.url, response.encoding, base_url)\n  File \"scrapy/linkextractors/__init__.py\", line 103, in _extract_links\n    return self.link_extractor._extract_links(*args, **kwargs)\n  File \"scrapy/linkextractors/lxmlhtml.py\", line 50, in _extract_links\n    for el, attr, attr_val in self._iter_links(selector._root):\n  File \"scrapy/linkextractors/lxmlhtml.py\", line 38, in _iter_links\n    for el in document.iter(etree.Element):\n```\n\nMy use of extractor is following:\n\n```\ndef parse_obj(self, response):\n        if not isinstance(response, HtmlResponse):\n            return\n        for link in LxmlLinkExtractor(allow=(), deny=self.allowed_domains).extract_links(response):\n            if not link.nofollow:\n                yield LinkCrawlItem(domain=link.url)\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1404/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1404/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1403", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1403/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1403/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1403/events", "html_url": "https://github.com/scrapy/scrapy/issues/1403", "id": 98606172, "node_id": "MDU6SXNzdWU5ODYwNjE3Mg==", "number": 1403, "title": "Exception in LxmLinkExtractor.extract_links 'charmap' codec can't encode character ", "user": {"login": "aldarund", "id": 571159, "node_id": "MDQ6VXNlcjU3MTE1OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/571159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aldarund", "html_url": "https://github.com/aldarund", "followers_url": "https://api.github.com/users/aldarund/followers", "following_url": "https://api.github.com/users/aldarund/following{/other_user}", "gists_url": "https://api.github.com/users/aldarund/gists{/gist_id}", "starred_url": "https://api.github.com/users/aldarund/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aldarund/subscriptions", "organizations_url": "https://api.github.com/users/aldarund/orgs", "repos_url": "https://api.github.com/users/aldarund/repos", "events_url": "https://api.github.com/users/aldarund/events{/privacy}", "received_events_url": "https://api.github.com/users/aldarund/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2015-08-02T12:23:58Z", "updated_at": "2020-02-19T13:19:22Z", "closed_at": "2020-02-19T13:19:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\nStacktrace (most recent call last):\n\n  File \"scrapy/utils/defer.py\", line 102, in iter_errback\n    yield next(it)\n  File \"scrapy/spidermiddlewares/offsite.py\", line 28, in process_spider_output\n    for x in result:\n  File \"scrapy/spidermiddlewares/referer.py\", line 22, in <genexpr>\n    return (_set_referer(r) for r in result or ())\n  File \"scrapy/spidermiddlewares/offsite.py\", line 28, in process_spider_output\n    for x in result:\n  File \"scrapy/spidermiddlewares/urllength.py\", line 37, in <genexpr>\n    return (r for r in result or () if _filter(r))\n  File \"scrapy/spidermiddlewares/depth.py\", line 54, in <genexpr>\n    return (r for r in result or () if _filter(r))\n  File \"scrapy/spiders/crawl.py\", line 69, in _parse_response\n    for requests_or_item in iterate_spider_output(cb_res):\n  File \"ex_link_crawl/spiders/external_link_spider.py\", line 45, in parse_obj\n    for link in LxmlLinkExtractor(allow=(), deny=self.allowed_domains).extract_links(response):\n  File \"scrapy/linkextractors/lxmlhtml.py\", line 108, in extract_links\n    links = self._extract_links(doc, response.url, response.encoding, base_url)\n  File \"scrapy/linkextractors/__init__.py\", line 103, in _extract_links\n    return self.link_extractor._extract_links(*args, **kwargs)\n  File \"scrapy/linkextractors/lxmlhtml.py\", line 57, in _extract_links\n    url = url.encode(response_encoding)\n  File \"encodings/cp1252.py\", line 12, in encode\n    return codecs.charmap_encode(input,errors,encoding_table)\n\n```\n\nMy use of extractor is following:\n\n```\ndef parse_obj(self, response):\n        if not isinstance(response, HtmlResponse):\n            return\n        for link in LxmlLinkExtractor(allow=(), deny=self.allowed_domains).extract_links(response):\n            if not link.nofollow:\n                yield LinkCrawlItem(domain=link.url)\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1403/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1403/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1402", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1402/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1402/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1402/events", "html_url": "https://github.com/scrapy/scrapy/issues/1402", "id": 98606067, "node_id": "MDU6SXNzdWU5ODYwNjA2Nw==", "number": 1402, "title": "Exception in LxmLinkExtractor.extract_links ValueError(\"Invalid IPv6 URL\")", "user": {"login": "aldarund", "id": 571159, "node_id": "MDQ6VXNlcjU3MTE1OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/571159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aldarund", "html_url": "https://github.com/aldarund", "followers_url": "https://api.github.com/users/aldarund/followers", "following_url": "https://api.github.com/users/aldarund/following{/other_user}", "gists_url": "https://api.github.com/users/aldarund/gists{/gist_id}", "starred_url": "https://api.github.com/users/aldarund/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aldarund/subscriptions", "organizations_url": "https://api.github.com/users/aldarund/orgs", "repos_url": "https://api.github.com/users/aldarund/repos", "events_url": "https://api.github.com/users/aldarund/events{/privacy}", "received_events_url": "https://api.github.com/users/aldarund/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2015-08-02T12:21:30Z", "updated_at": "2019-07-08T13:39:16Z", "closed_at": "2019-07-08T13:38:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a lot of this records in my error log.\n\n```\nStacktrace (most recent call last):\n\n  File \"scrapy/utils/defer.py\", line 102, in iter_errback\n    yield next(it)\n  File \"scrapy/spidermiddlewares/offsite.py\", line 28, in process_spider_output\n    for x in result:\n  File \"scrapy/spidermiddlewares/referer.py\", line 22, in <genexpr>\n    return (_set_referer(r) for r in result or ())\n  File \"scrapy/spidermiddlewares/offsite.py\", line 28, in process_spider_output\n    for x in result:\n  File \"scrapy/spidermiddlewares/urllength.py\", line 37, in <genexpr>\n    return (r for r in result or () if _filter(r))\n  File \"scrapy/spidermiddlewares/depth.py\", line 54, in <genexpr>\n    return (r for r in result or () if _filter(r))\n  File \"scrapy/spiders/crawl.py\", line 69, in _parse_response\n    for requests_or_item in iterate_spider_output(cb_res):\n  File \"ex_link_crawl/spiders/external_link_spider.py\", line 45, in parse_obj\n    for link in LxmlLinkExtractor(allow=(), deny=self.allowed_domains).extract_links(response):\n  File \"scrapy/linkextractors/lxmlhtml.py\", line 108, in extract_links\n    links = self._extract_links(doc, response.url, response.encoding, base_url)\n  File \"scrapy/linkextractors/__init__.py\", line 103, in _extract_links\n    return self.link_extractor._extract_links(*args, **kwargs)\n  File \"scrapy/linkextractors/lxmlhtml.py\", line 52, in _extract_links\n    attr_val = urljoin(base_url, attr_val)\n  File \"python2.7/urlparse.py\", line 261, in urljoin\n    urlparse(url, bscheme, allow_fragments)\n  File \"python2.7/urlparse.py\", line 143, in urlparse\n    tuple = urlsplit(url, scheme, allow_fragments)\n  File \"python2.7/urlparse.py\", line 191, in urlsplit\n    raise ValueError(\"Invalid IPv6 URL\")\n```\n\nI pass the response to the link extractor and get this error, so dont think its a error in my code. \n\n```\n    def parse_obj(self, response):\n        if not isinstance(response, HtmlResponse):\n            return\n        for link in LxmlLinkExtractor(allow=(), deny=self.allowed_domains).extract_links(response):\n            if not link.nofollow:\n                yield LinkCrawlItem(domain=link.url)\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1402/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1402/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1368", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1368/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1368/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1368/events", "html_url": "https://github.com/scrapy/scrapy/issues/1368", "id": 95481318, "node_id": "MDU6SXNzdWU5NTQ4MTMxOA==", "number": 1368, "title": "ImagesPipeline not updating the 'images' attribute in item", "user": {"login": "ritesh-gopal", "id": 12277975, "node_id": "MDQ6VXNlcjEyMjc3OTc1", "avatar_url": "https://avatars.githubusercontent.com/u/12277975?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ritesh-gopal", "html_url": "https://github.com/ritesh-gopal", "followers_url": "https://api.github.com/users/ritesh-gopal/followers", "following_url": "https://api.github.com/users/ritesh-gopal/following{/other_user}", "gists_url": "https://api.github.com/users/ritesh-gopal/gists{/gist_id}", "starred_url": "https://api.github.com/users/ritesh-gopal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ritesh-gopal/subscriptions", "organizations_url": "https://api.github.com/users/ritesh-gopal/orgs", "repos_url": "https://api.github.com/users/ritesh-gopal/repos", "events_url": "https://api.github.com/users/ritesh-gopal/events{/privacy}", "received_events_url": "https://api.github.com/users/ritesh-gopal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2015-07-16T17:10:27Z", "updated_at": "2019-08-19T15:33:53Z", "closed_at": "2019-08-19T15:33:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am using Scrapy 0.25 with Portia to scrape sites. \nI enabled the ImagesPipeline in my project\n\nAfter deploying to scrapyd, I have been able to save the images to my specified directory. \n\nAccording to the documentation, the ImagesPipeline will update the 'item' with an attribute 'images' indicating the file name of the saved image. The issue is that when I inspect my items scraped from the scrapyd UI, there is no 'images' attribute.So there is no way to link the downloaded images to my items.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1368/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1368/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1343", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1343/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1343/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1343/events", "html_url": "https://github.com/scrapy/scrapy/issues/1343", "id": 93415303, "node_id": "MDU6SXNzdWU5MzQxNTMwMw==", "number": 1343, "title": "custom_settings isn't reflected in the \"Overridden settings:\" log message", "user": {"login": "canhduong28", "id": 4472857, "node_id": "MDQ6VXNlcjQ0NzI4NTc=", "avatar_url": "https://avatars.githubusercontent.com/u/4472857?v=4", "gravatar_id": "", "url": "https://api.github.com/users/canhduong28", "html_url": "https://github.com/canhduong28", "followers_url": "https://api.github.com/users/canhduong28/followers", "following_url": "https://api.github.com/users/canhduong28/following{/other_user}", "gists_url": "https://api.github.com/users/canhduong28/gists{/gist_id}", "starred_url": "https://api.github.com/users/canhduong28/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/canhduong28/subscriptions", "organizations_url": "https://api.github.com/users/canhduong28/orgs", "repos_url": "https://api.github.com/users/canhduong28/repos", "events_url": "https://api.github.com/users/canhduong28/events{/privacy}", "received_events_url": "https://api.github.com/users/canhduong28/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 317415181, "node_id": "MDU6TGFiZWwzMTc0MTUxODE=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/logging", "name": "logging", "color": "fbca04", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/17", "html_url": "https://github.com/scrapy/scrapy/milestone/17", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/17/labels", "id": 2153485, "node_id": "MDk6TWlsZXN0b25lMjE1MzQ4NQ==", "number": 17, "title": "v1.5", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 69, "state": "closed", "created_at": "2016-11-23T11:25:01Z", "updated_at": "2018-07-04T19:33:00Z", "due_on": null, "closed_at": "2018-07-04T19:33:00Z"}, "comments": 12, "created_at": "2015-07-07T01:38:43Z", "updated_at": "2017-12-22T00:07:04Z", "closed_at": "2017-08-29T14:20:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\n\nI would like to notice that custom_settings per spider does not work properly. Global settings updated nothing when I added custom_settings in spiders, and unittests for that are missing too.\n\nRegards,\nCanh\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1343/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1343/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1322", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1322/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1322/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1322/events", "html_url": "https://github.com/scrapy/scrapy/issues/1322", "id": 91191427, "node_id": "MDU6SXNzdWU5MTE5MTQyNw==", "number": 1322, "title": "Request url transcoding causes error results.", "user": {"login": "lhuaizhong", "id": 13061739, "node_id": "MDQ6VXNlcjEzMDYxNzM5", "avatar_url": "https://avatars.githubusercontent.com/u/13061739?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lhuaizhong", "html_url": "https://github.com/lhuaizhong", "followers_url": "https://api.github.com/users/lhuaizhong/followers", "following_url": "https://api.github.com/users/lhuaizhong/following{/other_user}", "gists_url": "https://api.github.com/users/lhuaizhong/gists{/gist_id}", "starred_url": "https://api.github.com/users/lhuaizhong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lhuaizhong/subscriptions", "organizations_url": "https://api.github.com/users/lhuaizhong/orgs", "repos_url": "https://api.github.com/users/lhuaizhong/repos", "events_url": "https://api.github.com/users/lhuaizhong/events{/privacy}", "received_events_url": "https://api.github.com/users/lhuaizhong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2015-06-26T08:41:41Z", "updated_at": "2019-04-27T01:26:46Z", "closed_at": "2019-04-27T01:22:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "Request fetching URL:\nhttp://www.lightingproducts.philips.com/search-tool.html?brand=Chloride#!f=%40Brand%3aChloride&brandId=ba1bd486-2f99-4f80-9546-f05501e66013&isCatSearch=1\n\nWithin version 0.16.x:\n2015-06-26 16:14:06+0800 [philips3Spider] DEBUG: Crawled (200) GET http://www.lightingproducts.philips.com/search-tool.html?brand=Chloride?_escaped_fragment_=f=%40Brand%3aChloride&brandId=ba1bd486-2f99-4f80-9546-f05501e66013&isCatSearch=1 (referer: http://www.lightingproducts.philips.com/)\n\nWithin version 0.24.x and 1.0:\n2015-06-26 16:12:35+0800 [philips3Spider] DEBUG: Crawled (200) GET http://www.lightingproducts.philips.com/search-tool.html?brand=Chloride&_escaped_fragment_=f%3D%2540Brand%253aChloride%26brandId%3Dba1bd486-2f99-4f80-9546-f05501e66013%26isCatSearch%3D1 (referer: http://www.lightingproducts.philips.com/)\n\nIt works on version 0.16 without url encode while fetching, not works on 0.24 and 1.0 due to url encode automatically.\n\nHow can I avoid url encode in request fetching?\nThanks a lot for help.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1322/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1322/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1287", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1287/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1287/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1287/events", "html_url": "https://github.com/scrapy/scrapy/issues/1287", "id": 85740157, "node_id": "MDU6SXNzdWU4NTc0MDE1Nw==", "number": 1287, "title": "Files Pipeline fails on URLs with \"?\"/get attributes", "user": {"login": "mrwonko", "id": 220725, "node_id": "MDQ6VXNlcjIyMDcyNQ==", "avatar_url": "https://avatars.githubusercontent.com/u/220725?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrwonko", "html_url": "https://github.com/mrwonko", "followers_url": "https://api.github.com/users/mrwonko/followers", "following_url": "https://api.github.com/users/mrwonko/following{/other_user}", "gists_url": "https://api.github.com/users/mrwonko/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrwonko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrwonko/subscriptions", "organizations_url": "https://api.github.com/users/mrwonko/orgs", "repos_url": "https://api.github.com/users/mrwonko/repos", "events_url": "https://api.github.com/users/mrwonko/events{/privacy}", "received_events_url": "https://api.github.com/users/mrwonko/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2015-06-06T11:29:51Z", "updated_at": "2019-09-16T12:04:07Z", "closed_at": "2019-09-16T12:04:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "The Files Pipeline does not strip get parameters from the extension and then fails to write the file, at least on Windows/NTFS where \"?\" is disallowed in filenames.\n\ne.g. `files_urls = [ \"http://foo.bar/baz.txt?fizz\" ]` tries to create `<hash>.txt?fizz`, raising an IOError.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1287/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1287/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1265", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1265/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1265/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1265/events", "html_url": "https://github.com/scrapy/scrapy/issues/1265", "id": 82445832, "node_id": "MDU6SXNzdWU4MjQ0NTgzMg==", "number": 1265, "title": "Backward incompatibility for relocated paths in settings", "user": {"login": "curita", "id": 213781, "node_id": "MDQ6VXNlcjIxMzc4MQ==", "avatar_url": "https://avatars.githubusercontent.com/u/213781?v=4", "gravatar_id": "", "url": "https://api.github.com/users/curita", "html_url": "https://github.com/curita", "followers_url": "https://api.github.com/users/curita/followers", "following_url": "https://api.github.com/users/curita/following{/other_user}", "gists_url": "https://api.github.com/users/curita/gists{/gist_id}", "starred_url": "https://api.github.com/users/curita/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/curita/subscriptions", "organizations_url": "https://api.github.com/users/curita/orgs", "repos_url": "https://api.github.com/users/curita/repos", "events_url": "https://api.github.com/users/curita/events{/privacy}", "received_events_url": "https://api.github.com/users/curita/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/6", "html_url": "https://github.com/scrapy/scrapy/milestone/6", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/6/labels", "id": 914091, "node_id": "MDk6TWlsZXN0b25lOTE0MDkx", "number": 6, "title": "Scrapy 1.0", "description": "", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 43, "state": "closed", "created_at": "2014-12-24T09:57:08Z", "updated_at": "2015-06-26T02:05:35Z", "due_on": null, "closed_at": "2015-06-26T02:05:35Z"}, "comments": 2, "created_at": "2015-05-29T14:14:45Z", "updated_at": "2015-06-01T23:31:53Z", "closed_at": "2015-06-01T23:31:53Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Reported by @dangra\n\nThis issue manifests when mixing old paths and new ones for extensions and middlewares (this can happen for example while using a newer version of Scrapy in a project that hasn't updated to the new paths yet). Since paths aren't normalized, the same component can be loaded twice.\n\nTake these settings for example:\n\n``` python\n# scrapy/settings/default_settings.py\nEXTENSIONS_BASE = {\n    'scrapy.extensions.debug.StackTraceDump': 100,  # new path\n} \n```\n\n``` python\n# myproject/settings.py\nEXTENSIONS = {\n    'scrapy.contrib.debug.StackTraceDump': 200,  # old path\n}\n```\n\nWhile merging both dictionaries to build the list of components, the same StackTraceDump class is going to be loaded twice since it appears in two different keys. \n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1265/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1265/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1236", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1236/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1236/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1236/events", "html_url": "https://github.com/scrapy/scrapy/pull/1236", "id": 76646316, "node_id": "MDExOlB1bGxSZXF1ZXN0MzU0OTM0MDc=", "number": 1236, "title": "Replace FailureFormatter with direct failure to exc_info conversions in log calls", "user": {"login": "curita", "id": 213781, "node_id": "MDQ6VXNlcjIxMzc4MQ==", "avatar_url": "https://avatars.githubusercontent.com/u/213781?v=4", "gravatar_id": "", "url": "https://api.github.com/users/curita", "html_url": "https://github.com/curita", "followers_url": "https://api.github.com/users/curita/followers", "following_url": "https://api.github.com/users/curita/following{/other_user}", "gists_url": "https://api.github.com/users/curita/gists{/gist_id}", "starred_url": "https://api.github.com/users/curita/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/curita/subscriptions", "organizations_url": "https://api.github.com/users/curita/orgs", "repos_url": "https://api.github.com/users/curita/repos", "events_url": "https://api.github.com/users/curita/events{/privacy}", "received_events_url": "https://api.github.com/users/curita/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/6", "html_url": "https://github.com/scrapy/scrapy/milestone/6", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/6/labels", "id": 914091, "node_id": "MDk6TWlsZXN0b25lOTE0MDkx", "number": 6, "title": "Scrapy 1.0", "description": "", "creator": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 43, "state": "closed", "created_at": "2014-12-24T09:57:08Z", "updated_at": "2015-06-26T02:05:35Z", "due_on": null, "closed_at": "2015-06-26T02:05:35Z"}, "comments": 0, "created_at": "2015-05-15T08:24:03Z", "updated_at": "2015-05-19T21:44:27Z", "closed_at": "2015-05-15T18:00:37Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/1236", "html_url": "https://github.com/scrapy/scrapy/pull/1236", "diff_url": "https://github.com/scrapy/scrapy/pull/1236.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/1236.patch", "merged_at": "2015-05-15T18:00:36Z"}, "body": "`logging.Filter`s can't override log messages in logger children, they can only do so in the logger they are attached. That's why FailureFormatter (the filter that takes care of extracting the exc_info from failures to print tracebacks) doesn't propagate to the descendants of the `scrapy` logger.\n\n(TopLevelFormatter works because it doesn't override the \"entire\" log message, just the logger name, which is formatted at the end with string like `'%(name)s %(msg)'`. It's only the `msg` variable that is compute on the first logger and then propagated to the parents as it is).\n\nI fixed it by converting each failure to exc_info before making the log call.\n\nThis pr fixes #1229 and fixes #1230.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1236/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1236/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1192", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1192/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1192/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1192/events", "html_url": "https://github.com/scrapy/scrapy/issues/1192", "id": 71705409, "node_id": "MDU6SXNzdWU3MTcwNTQwOQ==", "number": 1192, "title": "UnicodeDecodeError in LxmlLinkExtractor ", "user": {"login": "Djayb6", "id": 357813, "node_id": "MDQ6VXNlcjM1NzgxMw==", "avatar_url": "https://avatars.githubusercontent.com/u/357813?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Djayb6", "html_url": "https://github.com/Djayb6", "followers_url": "https://api.github.com/users/Djayb6/followers", "following_url": "https://api.github.com/users/Djayb6/following{/other_user}", "gists_url": "https://api.github.com/users/Djayb6/gists{/gist_id}", "starred_url": "https://api.github.com/users/Djayb6/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Djayb6/subscriptions", "organizations_url": "https://api.github.com/users/Djayb6/orgs", "repos_url": "https://api.github.com/users/Djayb6/repos", "events_url": "https://api.github.com/users/Djayb6/events{/privacy}", "received_events_url": "https://api.github.com/users/Djayb6/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 388324163, "node_id": "MDU6TGFiZWwzODgzMjQxNjM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/link%20extraction", "name": "link extraction", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2015-04-28T21:21:57Z", "updated_at": "2020-09-01T09:31:48Z", "closed_at": "2020-09-01T09:31:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "The following links triggers a `UnicodeDecodeError` exception when being extracted by LxmlLinkExtractor:\n\n`<a href=\"http://gostariadefazerinscri\u00e7\u00e3oposcursos,obrigada.\">A link</a>`\n`<a href=\"http://www.domain.org\u00a0\">Another link</a>`\n\n```\n>>> 'http://gostariadefazerinscri\u00e7\u00e3oposcursos,obrigada.'\n'http://gostariadefazerinscri\\xc3\\xa7\\xc3\\xa3oposcursos,obrigada.'\n>>> 'http://www.domain.org\u00a0'\n'http://www.domain.org\\xc2\\xa0'\n```\n\nHere is the traceback:\n\n```\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py\", line 50, in <genexpr>\n return (r for r in result or () if _filter(r))\n\nFile \"build/bdist.macosx-10.10-x86_64/egg/Spider/spiders/spider.py\", line 271, in parse_response        \n\nFile \"build/bdist.macosx-10.10-x86_64/egg/Spider/spiders/spider.py\", line 293, in extract_requests_from_response\n\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/contrib/linkextractors/lxmlhtml.py\", line 108, in extract_links\n    all_links.extend(self._process_links(links))\n\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/linkextractor.py\", line 86, in _process_links\n    links = [x for x in links if self._link_allowed(x)]\n\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/linkextractor.py\", line 66, in _link_allowed\n    if self.allow_domains and not url_is_from_any_domain(parsed_url, self.allow_domains):\n\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/utils/url.py\", line 23, in url_is_from_any_domain\n    return any(((host == d.lower()) or (host.endswith('.%s' % d.lower())) for d in domains))\n\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/utils/url.py\", line 23, in <genexpr>\n    return any(((host == d.lower()) or (host.endswith('.%s' % d.lower())) for d in domains))\n\nexceptions.UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 1: ordinal not in range(128)\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1192/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1192/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1034", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1034/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1034/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1034/events", "html_url": "https://github.com/scrapy/scrapy/issues/1034", "id": 56597858, "node_id": "MDU6SXNzdWU1NjU5Nzg1OA==", "number": 1034, "title": "HTTP/1.1 requests cause bad calls w/ twisted 15", "user": {"login": "mkb218", "id": 88753, "node_id": "MDQ6VXNlcjg4NzUz", "avatar_url": "https://avatars.githubusercontent.com/u/88753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mkb218", "html_url": "https://github.com/mkb218", "followers_url": "https://api.github.com/users/mkb218/followers", "following_url": "https://api.github.com/users/mkb218/following{/other_user}", "gists_url": "https://api.github.com/users/mkb218/gists{/gist_id}", "starred_url": "https://api.github.com/users/mkb218/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mkb218/subscriptions", "organizations_url": "https://api.github.com/users/mkb218/orgs", "repos_url": "https://api.github.com/users/mkb218/repos", "events_url": "https://api.github.com/users/mkb218/events{/privacy}", "received_events_url": "https://api.github.com/users/mkb218/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2015-02-04T22:29:29Z", "updated_at": "2015-02-16T19:18:02Z", "closed_at": "2015-02-16T19:18:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "Twisted 15.0 appears to have changed the signature of the _getEndpoint method on twisted.web.client.Agent. This causes the http11 handler to throw exceptions like so:\n\n```\nTraceback (most recent call last):\n  File \"/usr/share/python/spotify-prelude2-directed-crawlers/local/lib/python2.7/site-packages/scrapy/core/downloader/middleware.py\", line 38, in process_request\n    return download_func(request=request, spider=spider)\n  File \"/usr/share/python/spotify-prelude2-directed-crawlers/local/lib/python2.7/site-packages/scrapy/core/downloader/__init__.py\", line 123, in _enqueue_request\n    self._process_queue(spider, slot)\n  File \"/usr/share/python/spotify-prelude2-directed-crawlers/local/lib/python2.7/site-packages/scrapy/core/downloader/__init__.py\", line 143, in _process_queue\n    dfd = self._download(slot, request, spider)\n  File \"/usr/share/python/spotify-prelude2-directed-crawlers/local/lib/python2.7/site-packages/scrapy/core/downloader/__init__.py\", line 154, in _download\n    dfd = mustbe_deferred(self.handlers.download_request, request, spider)\n--- <exception caught here> ---\n  File \"/usr/share/python/spotify-prelude2-directed-crawlers/local/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 39, in mustbe_deferred\n    result = f(*args, **kw)\n  File \"/usr/share/python/spotify-prelude2-directed-crawlers/local/lib/python2.7/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 40, in download_request\n    return handler(request, spider)\n  File \"/usr/share/python/spotify-prelude2-directed-crawlers/local/lib/python2.7/site-packages/scrapy/core/downloader/handlers/http11.py\", line 36, in download_request\n    return agent.download_request(request)\n  File \"/usr/share/python/spotify-prelude2-directed-crawlers/local/lib/python2.7/site-packages/scrapy/core/downloader/handlers/http11.py\", line 174, in download_request\n    d = agent.request(method, url, headers, bodyproducer)\n  File \"/usr/share/python/spotify-prelude2-directed-crawlers/local/lib/python2.7/site-packages/twisted/web/client.py\", line 1560, in request\n    endpoint = self._getEndpoint(parsedURI)\nexceptions.TypeError: _getEndpoint() takes exactly 4 arguments (2 given)\n```\n\nThat method's signature in Twisted 15.0.0 is `def _getEndpoint(self, uri):` while in version 14.0.2 it is `def _getEndpoint(self, scheme, host, port):`\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1034/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1034/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1015", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/1015/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/1015/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/1015/events", "html_url": "https://github.com/scrapy/scrapy/issues/1015", "id": 54702723, "node_id": "MDU6SXNzdWU1NDcwMjcyMw==", "number": 1015, "title": "process_spider_exception not called with exception from spider", "user": {"login": "aufziehvogel", "id": 3071022, "node_id": "MDQ6VXNlcjMwNzEwMjI=", "avatar_url": "https://avatars.githubusercontent.com/u/3071022?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aufziehvogel", "html_url": "https://github.com/aufziehvogel", "followers_url": "https://api.github.com/users/aufziehvogel/followers", "following_url": "https://api.github.com/users/aufziehvogel/following{/other_user}", "gists_url": "https://api.github.com/users/aufziehvogel/gists{/gist_id}", "starred_url": "https://api.github.com/users/aufziehvogel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aufziehvogel/subscriptions", "organizations_url": "https://api.github.com/users/aufziehvogel/orgs", "repos_url": "https://api.github.com/users/aufziehvogel/repos", "events_url": "https://api.github.com/users/aufziehvogel/events{/privacy}", "received_events_url": "https://api.github.com/users/aufziehvogel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2015-01-18T17:12:02Z", "updated_at": "2019-07-04T17:19:08Z", "closed_at": "2019-07-04T17:19:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "According to the documentation, `process_spider_exception` should also be called when a spider throws an exception. To my understanding, this would include throwing an exception from any parse method like this:\n\n``` python\n    def parse_item(self, response):\n        log.msg(\"[parse_item] Now in exceptional parse\", level=log.INFO)\n        raise Exception('foo')\n```\n\nMy middleware looks like this:\n\n``` python\nclass ManyExceptionsMiddleware(object):\n    def process_spider_output(self, response, result, spider):\n        log.msg(\"[process_spider_output] Shows that middleware IS installed\", level=log.INFO)\n        return result\n\n    def process_spider_exception(self, response, exception, spider):\n        log.msg(\"[process_spider_exception] Many exceptions on %s\" % spider.name, level=log.WARNING)\n        return []\n```\n\nThis results in:\n\n```\n2015-01-18 18:08:01+0100 [example] DEBUG: Crawled (200) <GET some-secret-url> (referer: some-other-url)\n2015-01-18 18:08:01+0100 [scrapy] INFO: [process_spider_output] Shows that middleware IS installed\n2015-01-18 18:08:01+0100 [scrapy] INFO: [parse_item] Now in exceptional parse\n2015-01-18 18:08:01+0100 [example] ERROR: Spider error processing <GET some-secret-url>\n    Traceback (most recent call last):\n[...]\n    exceptions.Exception: foo\n```\n\nThen I added the following additional method to check that `process_spider_exception` works (because the only exception handling in scrapy itself is done like this).\n\n``` python\ndef process_spider_input(self, response, spider):\n    raise Exception('foo')\n```\n\nThen the output looks like this:\n\n```\n2015-01-18 18:09:53+0100 [example] DEBUG: Crawled (200) <GET some-secret-url> (referer: None)\n2015-01-18 18:09:53+0100 [scrapy] WARNING: [process_spider_exception] Many exceptions on some-secret-domain\n2015-01-18 18:09:53+0100 [scrapy] INFO: [process_spider_output] Shows that middleware IS installed\n```\n\nIf you could tell me, where this all should happen, I could look into the code to fix it (if I understand it well enough).\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/1015/reactions", "total_count": 6, "+1": 6, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/1015/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/951", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/951/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/951/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/951/events", "html_url": "https://github.com/scrapy/scrapy/issues/951", "id": 48825639, "node_id": "MDU6SXNzdWU0ODgyNTYzOQ==", "number": 951, "title": "Extraction of gzipped sitemap fails in Scrapy 0.24.4", "user": {"login": "mercutio79", "id": 2805180, "node_id": "MDQ6VXNlcjI4MDUxODA=", "avatar_url": "https://avatars.githubusercontent.com/u/2805180?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mercutio79", "html_url": "https://github.com/mercutio79", "followers_url": "https://api.github.com/users/mercutio79/followers", "following_url": "https://api.github.com/users/mercutio79/following{/other_user}", "gists_url": "https://api.github.com/users/mercutio79/gists{/gist_id}", "starred_url": "https://api.github.com/users/mercutio79/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mercutio79/subscriptions", "organizations_url": "https://api.github.com/users/mercutio79/orgs", "repos_url": "https://api.github.com/users/mercutio79/repos", "events_url": "https://api.github.com/users/mercutio79/events{/privacy}", "received_events_url": "https://api.github.com/users/mercutio79/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2014-11-14T18:48:52Z", "updated_at": "2016-09-14T13:24:10Z", "closed_at": "2016-09-14T13:24:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "retrieving a gzipped sitemap xml (tested on amazon.de) fails.\n\nReproduce with :\nmodify /utils/gz.py gunzip method to write the incoming data to a file.\n\ngunzip the file on the command line.\n\nthe unzipped file contains garbled content\n\ngunzip that file with garbled content a second time and get the correct content\n\n-> I suspect that the content coming from the target server is already gzip compressed and scrapy has a bug that causes the gzip decompression to not work properly, resulting in a double compressed file arriving at the  /utils/gz.py gunzip method  \n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/951/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/951/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/950", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/950/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/950/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/950/events", "html_url": "https://github.com/scrapy/scrapy/issues/950", "id": 48699259, "node_id": "MDU6SXNzdWU0ODY5OTI1OQ==", "number": 950, "title": "Scrapy built-in email system doesn't work for me", "user": {"login": "Lazar-T", "id": 8344912, "node_id": "MDQ6VXNlcjgzNDQ5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/8344912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lazar-T", "html_url": "https://github.com/Lazar-T", "followers_url": "https://api.github.com/users/Lazar-T/followers", "following_url": "https://api.github.com/users/Lazar-T/following{/other_user}", "gists_url": "https://api.github.com/users/Lazar-T/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lazar-T/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lazar-T/subscriptions", "organizations_url": "https://api.github.com/users/Lazar-T/orgs", "repos_url": "https://api.github.com/users/Lazar-T/repos", "events_url": "https://api.github.com/users/Lazar-T/events{/privacy}", "received_events_url": "https://api.github.com/users/Lazar-T/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 443054750, "node_id": "MDU6TGFiZWw0NDMwNTQ3NTA=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/not%20reproducible", "name": "not reproducible", "color": "f9d0c4", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2014-11-13T22:11:23Z", "updated_at": "2018-02-15T16:21:28Z", "closed_at": "2018-02-15T16:21:28Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "So i asked this question on Stackoverflow and IRC channel but no luck, anyway when i try to send email when spider is done scraping i got it to work when using something custom like this: https://gist.github.com/Lazar-T/73694c9bfb609ee85a3a, but with MailSender i can't get it to work somehow, this is pseudo code that i got so far in spider: https://gist.github.com/Lazar-T/9b3fa684a13fb175e125\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/950/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/950/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/875", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/875/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/875/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/875/events", "html_url": "https://github.com/scrapy/scrapy/issues/875", "id": 41859695, "node_id": "MDU6SXNzdWU0MTg1OTY5NQ==", "number": 875, "title": "log_observer is beign started twice within a crawl", "user": {"login": "nramirezuy", "id": 1042865, "node_id": "MDQ6VXNlcjEwNDI4NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1042865?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nramirezuy", "html_url": "https://github.com/nramirezuy", "followers_url": "https://api.github.com/users/nramirezuy/followers", "following_url": "https://api.github.com/users/nramirezuy/following{/other_user}", "gists_url": "https://api.github.com/users/nramirezuy/gists{/gist_id}", "starred_url": "https://api.github.com/users/nramirezuy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nramirezuy/subscriptions", "organizations_url": "https://api.github.com/users/nramirezuy/orgs", "repos_url": "https://api.github.com/users/nramirezuy/repos", "events_url": "https://api.github.com/users/nramirezuy/events{/privacy}", "received_events_url": "https://api.github.com/users/nramirezuy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2014-09-03T20:04:12Z", "updated_at": "2015-04-29T18:20:34Z", "closed_at": "2015-04-29T18:20:34Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The order of execution is as listed:\n- https://github.com/scrapy/scrapy/pull/816/files#diff-017ca5ab6671590721d197e95de3cea3R91\n- https://github.com/scrapy/scrapy/pull/816/files#diff-017ca5ab6671590721d197e95de3cea3R130\n\n/cc @curita\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/875/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/875/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/874", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/874/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/874/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/874/events", "html_url": "https://github.com/scrapy/scrapy/issues/874", "id": 41859343, "node_id": "MDU6SXNzdWU0MTg1OTM0Mw==", "number": 874, "title": "Enabled extensions, middlewares, pipelines", "user": {"login": "nramirezuy", "id": 1042865, "node_id": "MDQ6VXNlcjEwNDI4NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1042865?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nramirezuy", "html_url": "https://github.com/nramirezuy", "followers_url": "https://api.github.com/users/nramirezuy/followers", "following_url": "https://api.github.com/users/nramirezuy/following{/other_user}", "gists_url": "https://api.github.com/users/nramirezuy/gists{/gist_id}", "starred_url": "https://api.github.com/users/nramirezuy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nramirezuy/subscriptions", "organizations_url": "https://api.github.com/users/nramirezuy/orgs", "repos_url": "https://api.github.com/users/nramirezuy/repos", "events_url": "https://api.github.com/users/nramirezuy/events{/privacy}", "received_events_url": "https://api.github.com/users/nramirezuy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2014-09-03T20:00:04Z", "updated_at": "2014-09-08T17:32:11Z", "closed_at": "2014-09-08T17:32:11Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I found that this information isn't being printed anymore.\n\nThe responsible of this bug is [this line](https://github.com/scrapy/scrapy/pull/816/files#diff-fee03a44ad4de98d9361d89947c8aba3R83), seems that `spider` is `None` on `eventDict` at the moment the components are instantiated.\n\nI'm not sure how to fix it because I 'm not quite sure what it is attempting to block.\n\n/cc @curita\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/874/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/874/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/863", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/863/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/863/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/863/events", "html_url": "https://github.com/scrapy/scrapy/issues/863", "id": 41169197, "node_id": "MDU6SXNzdWU0MTE2OTE5Nw==", "number": 863, "title": "`bindaddress` parameter fails for IPv6", "user": {"login": "Mimino666", "id": 1270393, "node_id": "MDQ6VXNlcjEyNzAzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/1270393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mimino666", "html_url": "https://github.com/Mimino666", "followers_url": "https://api.github.com/users/Mimino666/followers", "following_url": "https://api.github.com/users/Mimino666/following{/other_user}", "gists_url": "https://api.github.com/users/Mimino666/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mimino666/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mimino666/subscriptions", "organizations_url": "https://api.github.com/users/Mimino666/orgs", "repos_url": "https://api.github.com/users/Mimino666/repos", "events_url": "https://api.github.com/users/Mimino666/events{/privacy}", "received_events_url": "https://api.github.com/users/Mimino666/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2014-08-26T13:00:46Z", "updated_at": "2022-11-17T15:31:22Z", "closed_at": "2022-11-17T15:31:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Trying to pass IPv6 address as _bindaddress_ parameter, for example:\n`Request('http://whatismyv6.com/', meta={'bindaddress': ('1234:5678:111::0a', 0)})`\nraises the following error:\n`TypeError: getsockaddrarg() takes exactly 2 arguments (4 given)`\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/863/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/863/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/838", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/838/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/838/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/838/events", "html_url": "https://github.com/scrapy/scrapy/issues/838", "id": 39347211, "node_id": "MDU6SXNzdWUzOTM0NzIxMQ==", "number": 838, "title": "Links with a preceding space are not parsed correctly.", "user": {"login": "jpswade", "id": 1087963, "node_id": "MDQ6VXNlcjEwODc5NjM=", "avatar_url": "https://avatars.githubusercontent.com/u/1087963?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpswade", "html_url": "https://github.com/jpswade", "followers_url": "https://api.github.com/users/jpswade/followers", "following_url": "https://api.github.com/users/jpswade/following{/other_user}", "gists_url": "https://api.github.com/users/jpswade/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpswade/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpswade/subscriptions", "organizations_url": "https://api.github.com/users/jpswade/orgs", "repos_url": "https://api.github.com/users/jpswade/repos", "events_url": "https://api.github.com/users/jpswade/events{/privacy}", "received_events_url": "https://api.github.com/users/jpswade/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 388324163, "node_id": "MDU6TGFiZWwzODgzMjQxNjM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/link%20extraction", "name": "link extraction", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2014-08-02T11:11:53Z", "updated_at": "2017-02-20T14:08:33Z", "closed_at": "2017-02-20T14:08:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "For example:\n\nImagine on this page http://www.example.co.uk/?post=123 we have this markup:\n\n```\n<a href=\" http://test.example.co.uk/\">Test</a>\n```\n\nIt's subtle but there's a preceding space before the URL in the href.\n\nInstead of crawling to the URL http://test.example.co.uk/ it crawls this:\n\nhttp://www.example.co.uk/?post=123%20http://test.example.co.uk/\n\nFurther more, if this page exists, then it may likely contain the same link, which means there's a link like this:\n\nhttp://www.example.co.uk/?post=123%20http://test.example.co.uk/%20http://test.example.co.uk/\n\nThis causes an infinite loop.\n\nEssentially, the solution is to trim URLs before crawling them.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/838/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/838/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/809", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/809/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/809/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/809/events", "html_url": "https://github.com/scrapy/scrapy/pull/809", "id": 38131632, "node_id": "MDExOlB1bGxSZXF1ZXN0MTg1NTc3NzU=", "number": 809, "title": "get_func_args maximum recursion fix #728", "user": {"login": "nramirezuy", "id": 1042865, "node_id": "MDQ6VXNlcjEwNDI4NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1042865?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nramirezuy", "html_url": "https://github.com/nramirezuy", "followers_url": "https://api.github.com/users/nramirezuy/followers", "following_url": "https://api.github.com/users/nramirezuy/following{/other_user}", "gists_url": "https://api.github.com/users/nramirezuy/gists{/gist_id}", "starred_url": "https://api.github.com/users/nramirezuy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nramirezuy/subscriptions", "organizations_url": "https://api.github.com/users/nramirezuy/orgs", "repos_url": "https://api.github.com/users/nramirezuy/repos", "events_url": "https://api.github.com/users/nramirezuy/events{/privacy}", "received_events_url": "https://api.github.com/users/nramirezuy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "nramirezuy", "id": 1042865, "node_id": "MDQ6VXNlcjEwNDI4NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1042865?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nramirezuy", "html_url": "https://github.com/nramirezuy", "followers_url": "https://api.github.com/users/nramirezuy/followers", "following_url": "https://api.github.com/users/nramirezuy/following{/other_user}", "gists_url": "https://api.github.com/users/nramirezuy/gists{/gist_id}", "starred_url": "https://api.github.com/users/nramirezuy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nramirezuy/subscriptions", "organizations_url": "https://api.github.com/users/nramirezuy/orgs", "repos_url": "https://api.github.com/users/nramirezuy/repos", "events_url": "https://api.github.com/users/nramirezuy/events{/privacy}", "received_events_url": "https://api.github.com/users/nramirezuy/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "nramirezuy", "id": 1042865, "node_id": "MDQ6VXNlcjEwNDI4NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1042865?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nramirezuy", "html_url": "https://github.com/nramirezuy", "followers_url": "https://api.github.com/users/nramirezuy/followers", "following_url": "https://api.github.com/users/nramirezuy/following{/other_user}", "gists_url": "https://api.github.com/users/nramirezuy/gists{/gist_id}", "starred_url": "https://api.github.com/users/nramirezuy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nramirezuy/subscriptions", "organizations_url": "https://api.github.com/users/nramirezuy/orgs", "repos_url": "https://api.github.com/users/nramirezuy/repos", "events_url": "https://api.github.com/users/nramirezuy/events{/privacy}", "received_events_url": "https://api.github.com/users/nramirezuy/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2014-07-17T22:09:13Z", "updated_at": "2014-07-21T16:45:15Z", "closed_at": "2014-07-21T16:41:03Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/809", "html_url": "https://github.com/scrapy/scrapy/pull/809", "diff_url": "https://github.com/scrapy/scrapy/pull/809.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/809.patch", "merged_at": "2014-07-21T16:41:03Z"}, "body": "Fix for the issue: #728\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/809/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/809/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/769", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/769/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/769/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/769/events", "html_url": "https://github.com/scrapy/scrapy/issues/769", "id": 36662038, "node_id": "MDU6SXNzdWUzNjY2MjAzOA==", "number": 769, "title": "CrawlerSettings is broken in scrapy 0.24", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2014-06-27T13:11:36Z", "updated_at": "2014-06-27T15:40:12Z", "closed_at": "2014-06-27T15:40:12Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "This line raises an exception because overrides became a property: https://github.com/scrapy/scrapy/blob/master/scrapy/settings/__init__.py#L135\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/769/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/769/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/763", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/763/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/763/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/763/events", "html_url": "https://github.com/scrapy/scrapy/issues/763", "id": 36510963, "node_id": "MDU6SXNzdWUzNjUxMDk2Mw==", "number": 763, "title": "Broken test suite after LxmlLinkExtractor promotion", "user": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2014-06-25T18:55:35Z", "updated_at": "2014-06-25T19:29:16Z", "closed_at": "2014-06-25T19:29:16Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\n$ trial scrapy.tests.test_crawl.CrawlTestCase\nscrapy.tests.test_crawl\n  CrawlTestCase\n    test_delay ...                                                         [OK]\n    test_engine_status ...                                                 [OK]\n    test_follow_all ...                                                  [FAIL]\n    test_referer_header ...                                                [OK]\n    test_retry_503 ...                                                     [OK]\n    test_retry_conn_aborted ...                                            [OK]\n    test_retry_conn_failed ...                                             [OK]\n    test_retry_conn_lost ...                                               [OK]\n    test_retry_dns_error ...                                               [OK]\n    test_start_requests_bug_before_yield ...                               [OK]\n    test_start_requests_bug_yielding ...                                   [OK]\n    test_start_requests_dupes ...                                          [OK]\n    test_start_requests_lazyness ...                                       [OK]\n    test_timeout_failure ...                                               [OK]\n    test_timeout_success ...                                               [OK]\n    test_unbounded_response ...                                            [OK]\n\n===============================================================================\n[FAIL]\nTraceback (most recent call last):\n  File \"/home/daniel/envs/scrapy/lib/python2.7/site-packages/twisted/internet/defer.py\", line 1099, in _inlineCallbacks\n    result = g.send(result)\n  File \"/home/daniel/src/scrapy/scrapy/tests/test_crawl.py\", line 26, in test_follow_all\n    self.assertEqual(len(spider.urls_visited), 11)  # 10 + start_url\n  File \"/home/daniel/envs/scrapy/lib/python2.7/site-packages/twisted/trial/_synctest.py\", line 356, in assertEqual\n    % (msg, pformat(first), pformat(second)))\ntwisted.trial.unittest.FailTest: not equal:\na = 31\nb = 11\n\n\nscrapy.tests.test_crawl.CrawlTestCase.test_follow_all\n-------------------------------------------------------------------------------\nRan 16 tests in 90.150s\n\nFAILED (failures=1, successes=15)\n\n$ trial scrapy.tests.test_crawl.CrawlTestCase.test_follow_all\nscrapy.tests.test_crawl\n  CrawlTestCase\n    test_follow_all ...                                                    [OK]\n\n-------------------------------------------------------------------------------\nRan 1 tests in 0.874s\n\nPASSED (successes=1)\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/763/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/763/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/728", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/728/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/728/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/728/events", "html_url": "https://github.com/scrapy/scrapy/issues/728", "id": 34003664, "node_id": "MDU6SXNzdWUzNDAwMzY2NA==", "number": 728, "title": "get_func_args maximum recursion", "user": {"login": "nramirezuy", "id": 1042865, "node_id": "MDQ6VXNlcjEwNDI4NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1042865?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nramirezuy", "html_url": "https://github.com/nramirezuy", "followers_url": "https://api.github.com/users/nramirezuy/followers", "following_url": "https://api.github.com/users/nramirezuy/following{/other_user}", "gists_url": "https://api.github.com/users/nramirezuy/gists{/gist_id}", "starred_url": "https://api.github.com/users/nramirezuy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nramirezuy/subscriptions", "organizations_url": "https://api.github.com/users/nramirezuy/orgs", "repos_url": "https://api.github.com/users/nramirezuy/repos", "events_url": "https://api.github.com/users/nramirezuy/events{/privacy}", "received_events_url": "https://api.github.com/users/nramirezuy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2014-05-21T17:05:43Z", "updated_at": "2014-07-21T16:41:06Z", "closed_at": "2014-07-21T16:41:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "https://github.com/scrapy/scrapy/blob/master/scrapy/utils/python.py#L149\n\nToday I was working on a project were I have to skip the first item of a list, and then join the rest. Instead of writing the typical slice I tried something much more good looking `Compose(itemgetter(slice(1, None)), Join())` but I found out this maximum recursion. I did some research and ask @dangra about it, but nothing came up.\nI think the main problem is that `inspect` isn't able recognize `itemgetter` as `something`.\n\n``` python\n>>> inspect.getmembers(itemgetter(2))\n[('__call__',\n  <method-wrapper '__call__' of operator.itemgetter object at 0x7f79aeffb990>),\n ('__class__', <type 'operator.itemgetter'>),\n ('__delattr__',\n  <method-wrapper '__delattr__' of operator.itemgetter object at 0x7f79aeffb990>),\n ('__doc__',\n  'itemgetter(item, ...) --> itemgetter object\\n\\nReturn a callable object that fetches the given item(s) from its operand.\\nAfter, f=itemgetter(2), the call f(r) returns r[2].\\nAfter, g=itemgetter(2,5,3), the call g(r) returns (r[2], r[5], r[3])'),\n ('__format__',\n  <built-in method __format__ of operator.itemgetter object at 0x7f79aeffb990>),\n ('__getattribute__',\n  <method-wrapper '__getattribute__' of operator.itemgetter object at 0x7f79aeffb990>),\n ('__hash__',\n  <method-wrapper '__hash__' of operator.itemgetter object at 0x7f79aeffb990>),\n ('__init__',\n  <method-wrapper '__init__' of operator.itemgetter object at 0x7f79aeffb990>),\n ('__new__', <built-in method __new__ of type object at 0x8c1ec0>),\n ('__reduce__',\n  <built-in method __reduce__ of operator.itemgetter object at 0x7f79aeffb990>),\n ('__reduce_ex__',\n  <built-in method __reduce_ex__ of operator.itemgetter object at 0x7f79aeffb990>),\n ('__repr__',\n  <method-wrapper '__repr__' of operator.itemgetter object at 0x7f79aeffb990>),\n ('__setattr__',\n  <method-wrapper '__setattr__' of operator.itemgetter object at 0x7f79aeffb990>),\n ('__sizeof__',\n  <built-in method __sizeof__ of operator.itemgetter object at 0x7f79aeffb990>),\n ('__str__',\n  <method-wrapper '__str__' of operator.itemgetter object at 0x7f79aeffb990>),\n ('__subclasshook__',\n  <built-in method __subclasshook__ of type object at 0x8c1ec0>)]\n>>> inspect.getargspec(itemgetter(2).__call__)\nTraceback (most recent call last):\n  File \"<console>\", line 1, in <module>\n  File \"/usr/lib/python2.7/inspect.py\", line 815, in getargspec\n    raise TypeError('{!r} is not a Python function'.format(func))\nTypeError: <method-wrapper '__call__' of operator.itemgetter object at 0xb3ddd0> is not a Python function\n>>> inspect.getargspec(itemgetter(slice(None, 2)).__init__)\nTraceback (most recent call last):\n  File \"<console>\", line 1, in <module>\n  File \"/usr/lib/python2.7/inspect.py\", line 815, in getargspec\n    raise TypeError('{!r} is not a Python function'.format(func))\nTypeError: <method-wrapper '__init__' of operator.itemgetter object at 0xb3de10> is not a Python function\n```\n\nEDIT: Looks like the reason was C functions weren't covered by inspect module until Python 3.4 (http://bugs.python.org/issue17481)\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/728/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/728/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/706", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/706/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/706/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/706/events", "html_url": "https://github.com/scrapy/scrapy/issues/706", "id": 32235871, "node_id": "MDU6SXNzdWUzMjIzNTg3MQ==", "number": 706, "title": "scrapy engine can stop even if start_requests is not empty", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2014-04-25T14:20:49Z", "updated_at": "2014-04-28T16:13:42Z", "closed_at": "2014-04-28T16:13:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Consider this example spider\n\n``` python\nfrom scrapy.spider import Spider\nfrom scrapy.selector import Selector\nfrom scrapy.http import Request\n\nclass DmozSpider(Spider):\n    name = \"dmoz\"\n    allowed_domains = [\"dmoz.org\"]\n    start_urls = [\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\",\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\",\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\",\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\",\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/\"\n    ]\n\n    def start_requests(self):\n        for url in self.start_urls:\n            yield Request(\n                url,\n                #dont_filter=True\n            )\n\n    def parse(self, response):\n        self.log(\"parse %r\" % response.url)\n\n```\n\nand run it with `CONCURRENT_REQUESTS=1` and `DupeFilter` enabled,\nit will only visit `http://www.dmoz.org/Computers/Programming/Languages/Python/Books/`\n\nEven with higher concurrency settings, it can happen that the spider is considered idle because the next request from `start_requests` iterator was filtered.\n\nhttps://github.com/scrapy/scrapy/blob/master/scrapy/core/engine.py#L120 or https://github.com/scrapy/scrapy/blob/master/scrapy/core/engine.py#L155 seems to be missing a test on `slot.start_requests is None`\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/706/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/706/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/671", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/671/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/671/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/671/events", "html_url": "https://github.com/scrapy/scrapy/issues/671", "id": 30256491, "node_id": "MDU6SXNzdWUzMDI1NjQ5MQ==", "number": 671, "title": "Override of TEMPLATES_DIR does not work for \"startproject\" command", "user": {"login": "marksoenen", "id": 1322173, "node_id": "MDQ6VXNlcjEzMjIxNzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1322173?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marksoenen", "html_url": "https://github.com/marksoenen", "followers_url": "https://api.github.com/users/marksoenen/followers", "following_url": "https://api.github.com/users/marksoenen/following{/other_user}", "gists_url": "https://api.github.com/users/marksoenen/gists{/gist_id}", "starred_url": "https://api.github.com/users/marksoenen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marksoenen/subscriptions", "organizations_url": "https://api.github.com/users/marksoenen/orgs", "repos_url": "https://api.github.com/users/marksoenen/repos", "events_url": "https://api.github.com/users/marksoenen/events{/privacy}", "received_events_url": "https://api.github.com/users/marksoenen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2014-03-26T22:02:34Z", "updated_at": "2016-02-02T16:46:21Z", "closed_at": "2016-02-02T16:46:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "The following documentation is incorrect:\n\nhttp://doc.scrapy.org/en/latest/topics/settings.html#templates-dir\n\nThe following command line does not work:\n\nscrapy startproject -s TEMPLATES_DIR=../lib/python2.7/sitepackages/mypackage/templates test_projectA\n\nThe same command line for \"gendspider\" does work.  So the -s option appears to be working.  It appears that the code in startproject.py does not check for overridden settings:\n\nTEMPLATES_PATH = join(scrapy.**path**[0], 'templates', 'project')\n\nas opposed to genspider.py which checks:\n\n```\n    _templates_base_dir = self.settings['TEMPLATES_DIR'] or \\\n        join(scrapy.__path__[0], 'templates')\n    return join(_templates_base_dir, 'spiders')\n```\n\nAt minimum, the documentation is incorrect and needs to be updated.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/671/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/671/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/652", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/652/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/652/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/652/events", "html_url": "https://github.com/scrapy/scrapy/issues/652", "id": 29592573, "node_id": "MDU6SXNzdWUyOTU5MjU3Mw==", "number": 652, "title": "SgmlLinkExtractor default value for 'attrs' argument should be tuple", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 80417179, "node_id": "MDU6TGFiZWw4MDQxNzE3OQ==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/good%20first%20issue", "name": "good first issue", "color": "bfe5bf", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2014-03-17T19:47:45Z", "updated_at": "2014-03-28T11:44:01Z", "closed_at": "2014-03-28T11:44:01Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "It is now a string, and `attrs_func` doesn't make sense if `attrs` is a string. See https://github.com/scrapy/scrapy/blob/master/scrapy/contrib/linkextractors/sgml.py#L98\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/652/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/652/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/582", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/582/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/582/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/582/events", "html_url": "https://github.com/scrapy/scrapy/pull/582", "id": 26913162, "node_id": "MDExOlB1bGxSZXF1ZXN0MTIxOTUyODg=", "number": 582, "title": "[WIP] Handle cases when inspect.stack() fails", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2014-02-04T20:34:28Z", "updated_at": "2014-06-24T05:23:05Z", "closed_at": "2014-02-07T03:41:32Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/582", "html_url": "https://github.com/scrapy/scrapy/pull/582", "diff_url": "https://github.com/scrapy/scrapy/pull/582.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/582.patch", "merged_at": "2014-02-07T03:41:32Z"}, "body": "Ricardo @Panaggio reported an error: creating BaseSpider class fails if the first import is inside jinja2 template. Stacktrace:\n\n```\n[redacted]\n  2. from slybot.spider import IblSpider\nFile \"/usr/lib/pymodules/python2.7/slybot/spider.py\" in <module>\n  9.     from scrapy.spider import Spider\nFile \"/usr/lib/pymodules/python2.7/scrapy/spider.py\" in <module>\n  68. BaseSpider = create_deprecated_class('BaseSpider', Spider)\nFile \"/usr/lib/pymodules/python2.7/scrapy/utils/deprecate.py\" in create_deprecated_class\n  98.     frm = inspect.stack()[1]\nFile \"/usr/lib/python2.7/inspect.py\" in stack\n  1054.     return getouterframes(sys._getframe(1), context)\nFile \"/usr/lib/python2.7/inspect.py\" in getouterframes\n  1032.         framelist.append((frame,) + getframeinfo(frame, context))\nFile \"/usr/lib/python2.7/inspect.py\" in getframeinfo\n  1007.             lines, lnum = findsource(frame)\nFile \"/usr/lib/python2.7/inspect.py\" in findsource\n  580.             if pat.match(lines[lnum]): break\n\nException Type: IndexError at /p/1844/spiders/\nException Value: list index out of range\n```\n\n`lines` list contain lines of jinja2 template, not the python source code in this case, and it looks like inspect.stack() gets confused. In this PR such errors are catched and converted to warnings.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/582/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/582/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/581", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/581/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/581/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/581/events", "html_url": "https://github.com/scrapy/scrapy/issues/581", "id": 26903658, "node_id": "MDU6SXNzdWUyNjkwMzY1OA==", "number": 581, "title": "Deprecated class inheritance check bug", "user": {"login": "nramirezuy", "id": 1042865, "node_id": "MDQ6VXNlcjEwNDI4NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1042865?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nramirezuy", "html_url": "https://github.com/nramirezuy", "followers_url": "https://api.github.com/users/nramirezuy/followers", "following_url": "https://api.github.com/users/nramirezuy/following{/other_user}", "gists_url": "https://api.github.com/users/nramirezuy/gists{/gist_id}", "starred_url": "https://api.github.com/users/nramirezuy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nramirezuy/subscriptions", "organizations_url": "https://api.github.com/users/nramirezuy/orgs", "repos_url": "https://api.github.com/users/nramirezuy/repos", "events_url": "https://api.github.com/users/nramirezuy/events{/privacy}", "received_events_url": "https://api.github.com/users/nramirezuy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2014-02-04T18:24:01Z", "updated_at": "2014-02-05T21:48:40Z", "closed_at": "2014-02-05T21:48:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "``` python\n>>> from scrapy.spider import BaseSpider\n>>> class A(BaseSpider):\n...     pass\n... \n>>> class B(BaseSpider):\n...     pass\n... \n>>> isinstance(A('foo'), B)\nTrue\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/581/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/581/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/529", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/529/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/529/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/529/events", "html_url": "https://github.com/scrapy/scrapy/issues/529", "id": 25606115, "node_id": "MDU6SXNzdWUyNTYwNjExNQ==", "number": 529, "title": "MemoryUsage extension works incorrectly on OS X", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/5", "html_url": "https://github.com/scrapy/scrapy/milestone/5", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/5/labels", "id": 538556, "node_id": "MDk6TWlsZXN0b25lNTM4NTU2", "number": 5, "title": "Scrapy 0.22", "description": "", "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 45, "state": "closed", "created_at": "2014-01-16T22:04:15Z", "updated_at": "2014-11-25T12:56:07Z", "due_on": null, "closed_at": "2014-11-25T12:56:07Z"}, "comments": 2, "created_at": "2014-01-14T21:16:13Z", "updated_at": "2014-01-16T22:33:40Z", "closed_at": "2014-01-14T21:56:02Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The problem is that it uses `ru_maxrss` which is non-standard. It is in KB on Linux, but on OS X 10.9.1 it is in bytes:\n\n```\n$ python -c \"import resource; print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\"\n4235264\n```\n\nI don't know if it is in bytes or in kilobytes in earlier OS X versions. It'll be great if somebody who have not updated to Mavericks check that. Anyone here? If not supporting OS X versions earlier than Maverick is fine, we could add a `sys.platform` check.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/529/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/529/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/500", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/500/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/500/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/500/events", "html_url": "https://github.com/scrapy/scrapy/issues/500", "id": 24818835, "node_id": "MDU6SXNzdWUyNDgxODgzNQ==", "number": 500, "title": "dbm-based cache can become corrupted when spider is killed", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2013-12-27T13:01:51Z", "updated_at": "2014-06-23T18:30:14Z", "closed_at": "2014-06-23T18:30:14Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Hi,\n\nScrapy uses shelve-based cache by default; this could lead to a bad experience with scrapy because shelve databases can become corrupted if spider is stopped forcefully.\n\nWhat do you think about the following?\n1. Check if it can be fixed - for example, by closing databases at certain points;\n2. if it can't be fixed, then switch to an another cache backend.\n\nThis ticket could be related: https://github.com/scrapy/scrapy/issues/491 - I haven't looked at that ticket in details, but user mentions `close_spider` is not called on middleware - this could cause DB corruption for dbm backend. Any ideas?\n\nFile-based cache doesn't seem to have this issue. Another option is sqlite - in my experience it is much harder to get sqlite database corrupted, compared to dbm.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/500/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/500/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/483", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/483/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/483/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/483/events", "html_url": "https://github.com/scrapy/scrapy/issues/483", "id": 23791845, "node_id": "MDU6SXNzdWUyMzc5MTg0NQ==", "number": 483, "title": "Logging system writes lots of Error when initiated", "user": {"login": "verganis", "id": 2316685, "node_id": "MDQ6VXNlcjIzMTY2ODU=", "avatar_url": "https://avatars.githubusercontent.com/u/2316685?v=4", "gravatar_id": "", "url": "https://api.github.com/users/verganis", "html_url": "https://github.com/verganis", "followers_url": "https://api.github.com/users/verganis/followers", "following_url": "https://api.github.com/users/verganis/following{/other_user}", "gists_url": "https://api.github.com/users/verganis/gists{/gist_id}", "starred_url": "https://api.github.com/users/verganis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/verganis/subscriptions", "organizations_url": "https://api.github.com/users/verganis/orgs", "repos_url": "https://api.github.com/users/verganis/repos", "events_url": "https://api.github.com/users/verganis/events{/privacy}", "received_events_url": "https://api.github.com/users/verganis/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2013-12-05T14:57:54Z", "updated_at": "2015-04-29T18:20:34Z", "closed_at": "2015-04-29T18:20:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "When I try to use the scrapy logging system and I run the scraper I get a lot of error messages on STDOUT. \nI call log.start() in the **init** method of my spider only once.\nCode Below:\n\n``` python\nclass BilancioSpider(BaseSpider):\n    name = \"bilancio\"\n    allowed_domains = [\"http://finanzalocale.interno.it\"]\n    start_urls = [\"http://finanzalocale.interno.it\",]\n    lista_comuni = []\n\n    def __init__(self,**kwargs):\n        log.start()\n        super(BilancioSpider, self).__init__(self.name, **kwargs)\n\n        # initialize start_urls with all comune codes, years and type of bilancio\n        udr = None\n        udr = UnicodeDictReader(f=open(FILE_PATH,mode='r'), dialect=\"excel\",)\n        return\n\n    def parse(self, response):\n        return None\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/483/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/483/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/450", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/450/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/450/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/450/events", "html_url": "https://github.com/scrapy/scrapy/issues/450", "id": 21958235, "node_id": "MDU6SXNzdWUyMTk1ODIzNQ==", "number": 450, "title": "Crawlers won't shutdown gracefully on SIGINT", "user": {"login": "demji", "id": 5831382, "node_id": "MDQ6VXNlcjU4MzEzODI=", "avatar_url": "https://avatars.githubusercontent.com/u/5831382?v=4", "gravatar_id": "", "url": "https://api.github.com/users/demji", "html_url": "https://github.com/demji", "followers_url": "https://api.github.com/users/demji/followers", "following_url": "https://api.github.com/users/demji/following{/other_user}", "gists_url": "https://api.github.com/users/demji/gists{/gist_id}", "starred_url": "https://api.github.com/users/demji/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/demji/subscriptions", "organizations_url": "https://api.github.com/users/demji/orgs", "repos_url": "https://api.github.com/users/demji/repos", "events_url": "https://api.github.com/users/demji/events{/privacy}", "received_events_url": "https://api.github.com/users/demji/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/4", "html_url": "https://github.com/scrapy/scrapy/milestone/4", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/4/labels", "id": 437899, "node_id": "MDk6TWlsZXN0b25lNDM3ODk5", "number": 4, "title": "Scrapy 0.20", "description": null, "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 54, "state": "closed", "created_at": "2013-09-26T17:35:12Z", "updated_at": "2016-11-29T10:28:33Z", "due_on": null, "closed_at": "2014-11-25T12:56:04Z"}, "comments": 2, "created_at": "2013-11-01T13:57:47Z", "updated_at": "2013-11-08T17:38:17Z", "closed_at": "2013-11-05T02:02:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\n\nCrawlers won't shutdown gracefully since CrawlerProcess' `_start_crawler` method pops crawlers off the `self.crawlers` list, which is where the `stop` method looks for crawlers to stop.\n\nSteps to reproduce:\n\n1) scrapy crawl <spider>\n2) Send SIGINT via Ctrl-c\n3) Crawler continues running after displaying \"2013-11-01 09:24:49-0400 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force\"\n\n$ scrapy version -v\nScrapy  : 0.18.4\nlxml    : 3.2.3.0\nlibxml2 : 2.9.1\nTwisted : 13.1.0\nPython  : 2.7.5 (default, Aug 17 2013, 13:35:16) - [GCC 4.6.3]\nPlatform: Linux-3.10.7-gentoo-r1-x86_64-Intel-R-_Core-TM-2_Quad_CPU_Q9550_@_2.83GHz-with-gentoo-2.2\n\nRegards,\ndemji\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/450/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/450/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/432", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/432/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/432/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/432/events", "html_url": "https://github.com/scrapy/scrapy/pull/432", "id": 21273065, "node_id": "MDExOlB1bGxSZXF1ZXN0OTIzNTk0MA==", "number": 432, "title": "Removed URL reference in crawl command and .tld suffix in docs for spider names", "user": {"login": "rmax", "id": 26015, "node_id": "MDQ6VXNlcjI2MDE1", "avatar_url": "https://avatars.githubusercontent.com/u/26015?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmax", "html_url": "https://github.com/rmax", "followers_url": "https://api.github.com/users/rmax/followers", "following_url": "https://api.github.com/users/rmax/following{/other_user}", "gists_url": "https://api.github.com/users/rmax/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmax/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmax/subscriptions", "organizations_url": "https://api.github.com/users/rmax/orgs", "repos_url": "https://api.github.com/users/rmax/repos", "events_url": "https://api.github.com/users/rmax/events{/privacy}", "received_events_url": "https://api.github.com/users/rmax/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/4", "html_url": "https://github.com/scrapy/scrapy/milestone/4", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/4/labels", "id": 437899, "node_id": "MDk6TWlsZXN0b25lNDM3ODk5", "number": 4, "title": "Scrapy 0.20", "description": null, "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 54, "state": "closed", "created_at": "2013-09-26T17:35:12Z", "updated_at": "2016-11-29T10:28:33Z", "due_on": null, "closed_at": "2014-11-25T12:56:04Z"}, "comments": 0, "created_at": "2013-10-20T03:19:59Z", "updated_at": "2014-06-12T16:08:02Z", "closed_at": "2013-10-21T16:40:58Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/432", "html_url": "https://github.com/scrapy/scrapy/pull/432", "diff_url": "https://github.com/scrapy/scrapy/pull/432.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/432.patch", "merged_at": "2013-10-21T16:40:58Z"}, "body": "Additionally did a pep8 improvement to the crawl.py source code.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/432/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/432/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/429", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/429/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/429/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/429/events", "html_url": "https://github.com/scrapy/scrapy/pull/429", "id": 21201953, "node_id": "MDExOlB1bGxSZXF1ZXN0OTE5ODgxMg==", "number": 429, "title": "wrong variable name", "user": {"login": "alexanderlukanin13", "id": 4417580, "node_id": "MDQ6VXNlcjQ0MTc1ODA=", "avatar_url": "https://avatars.githubusercontent.com/u/4417580?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexanderlukanin13", "html_url": "https://github.com/alexanderlukanin13", "followers_url": "https://api.github.com/users/alexanderlukanin13/followers", "following_url": "https://api.github.com/users/alexanderlukanin13/following{/other_user}", "gists_url": "https://api.github.com/users/alexanderlukanin13/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexanderlukanin13/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexanderlukanin13/subscriptions", "organizations_url": "https://api.github.com/users/alexanderlukanin13/orgs", "repos_url": "https://api.github.com/users/alexanderlukanin13/repos", "events_url": "https://api.github.com/users/alexanderlukanin13/events{/privacy}", "received_events_url": "https://api.github.com/users/alexanderlukanin13/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/4", "html_url": "https://github.com/scrapy/scrapy/milestone/4", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/4/labels", "id": 437899, "node_id": "MDk6TWlsZXN0b25lNDM3ODk5", "number": 4, "title": "Scrapy 0.20", "description": null, "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 54, "state": "closed", "created_at": "2013-09-26T17:35:12Z", "updated_at": "2016-11-29T10:28:33Z", "due_on": null, "closed_at": "2014-11-25T12:56:04Z"}, "comments": 8, "created_at": "2013-10-18T05:59:47Z", "updated_at": "2014-06-12T16:08:02Z", "closed_at": "2013-10-18T09:28:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/429", "html_url": "https://github.com/scrapy/scrapy/pull/429", "diff_url": "https://github.com/scrapy/scrapy/pull/429.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/429.patch", "merged_at": "2013-10-18T09:28:06Z"}, "body": "", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/429/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/429/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/417", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/417/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/417/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/417/events", "html_url": "https://github.com/scrapy/scrapy/issues/417", "id": 20678723, "node_id": "MDU6SXNzdWUyMDY3ODcyMw==", "number": 417, "title": "`python setup.py bdist_rpm` fails with `cp: cannot stat 'examples': No such file or directory`", "user": {"login": "ciupicri", "id": 133797, "node_id": "MDQ6VXNlcjEzMzc5Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/133797?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ciupicri", "html_url": "https://github.com/ciupicri", "followers_url": "https://api.github.com/users/ciupicri/followers", "following_url": "https://api.github.com/users/ciupicri/following{/other_user}", "gists_url": "https://api.github.com/users/ciupicri/gists{/gist_id}", "starred_url": "https://api.github.com/users/ciupicri/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ciupicri/subscriptions", "organizations_url": "https://api.github.com/users/ciupicri/orgs", "repos_url": "https://api.github.com/users/ciupicri/repos", "events_url": "https://api.github.com/users/ciupicri/events{/privacy}", "received_events_url": "https://api.github.com/users/ciupicri/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/4", "html_url": "https://github.com/scrapy/scrapy/milestone/4", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/4/labels", "id": 437899, "node_id": "MDk6TWlsZXN0b25lNDM3ODk5", "number": 4, "title": "Scrapy 0.20", "description": null, "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 54, "state": "closed", "created_at": "2013-09-26T17:35:12Z", "updated_at": "2016-11-29T10:28:33Z", "due_on": null, "closed_at": "2014-11-25T12:56:04Z"}, "comments": 2, "created_at": "2013-10-08T13:31:34Z", "updated_at": "2013-11-08T18:17:02Z", "closed_at": "2013-10-08T17:18:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\n$ python setup.py bdist_rpm\n...\n+ cd /home/ciupicri/3rdparty-projects/scrapy/build/bdist.linux-x86_64/rpm/BUILD\n+ cd Scrapy-0.19.0\n+ DOCDIR=/home/ciupicri/3rdparty-projects/scrapy/build/bdist.linux-x86_64/rpm/BUILDROOT/Scrapy-0.19.0-1.x86_64/usr/share/doc/Scrapy-0.19.0\n+ export DOCDIR\n+ /usr/bin/mkdir -p /home/ciupicri/3rdparty-projects/scrapy/build/bdist.linux-x86_64/rpm/BUILDROOT/Scrapy-0.19.0-1.x86_64/usr/share/doc/Scrapy-0.19.0\n+ cp -pr docs /home/ciupicri/3rdparty-projects/scrapy/build/bdist.linux-x86_64/rpm/BUILDROOT/Scrapy-0.19.0-1.x86_64/usr/share/doc/Scrapy-0.19.0\n+ cp -pr examples /home/ciupicri/3rdparty-projects/scrapy/build/bdist.linux-x86_64/rpm/BUILDROOT/Scrapy-0.19.0-1.x86_64/usr/share/doc/Scrapy-0.19.0\ncp: cannot stat 'examples': No such file or directory\nerror: Bad exit status from /var/tmp/rpm-tmp.eslvBl (%doc)\n\n\nRPM build errors:\n    Bad exit status from /var/tmp/rpm-tmp.eslvBl (%doc)\nerror: command 'rpmbuild' failed with exit status 1\n```\n\nIf I remove `examples` from `setup.cfg` it stops complaining.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/417/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/417/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/414", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/414/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/414/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/414/events", "html_url": "https://github.com/scrapy/scrapy/issues/414", "id": 20620954, "node_id": "MDU6SXNzdWUyMDYyMDk1NA==", "number": 414, "title": "\"pip install Scrapy\" fails to build dependencies on Fedora 19", "user": {"login": "castedo", "id": 1416766, "node_id": "MDQ6VXNlcjE0MTY3NjY=", "avatar_url": "https://avatars.githubusercontent.com/u/1416766?v=4", "gravatar_id": "", "url": "https://api.github.com/users/castedo", "html_url": "https://github.com/castedo", "followers_url": "https://api.github.com/users/castedo/followers", "following_url": "https://api.github.com/users/castedo/following{/other_user}", "gists_url": "https://api.github.com/users/castedo/gists{/gist_id}", "starred_url": "https://api.github.com/users/castedo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/castedo/subscriptions", "organizations_url": "https://api.github.com/users/castedo/orgs", "repos_url": "https://api.github.com/users/castedo/repos", "events_url": "https://api.github.com/users/castedo/events{/privacy}", "received_events_url": "https://api.github.com/users/castedo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/4", "html_url": "https://github.com/scrapy/scrapy/milestone/4", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/4/labels", "id": 437899, "node_id": "MDk6TWlsZXN0b25lNDM3ODk5", "number": 4, "title": "Scrapy 0.20", "description": null, "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 54, "state": "closed", "created_at": "2013-09-26T17:35:12Z", "updated_at": "2016-11-29T10:28:33Z", "due_on": null, "closed_at": "2014-11-25T12:56:04Z"}, "comments": 6, "created_at": "2013-10-07T16:01:37Z", "updated_at": "2013-11-08T18:17:02Z", "closed_at": "2013-10-14T18:43:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was able to work around this failure of \"pip install Scrapy\" by manually using yum with the usual Fedora repositories:\nyum install libxslt-devel\nyum install pyOpenSSL\nyum install python-lxml\nyum install python-twisted\nand then doing pip install Scrapy.\n\nThe main error is that dependencies want gcc-4.5 but the default gcc on Fedora 19 is version 4.8:\n\"\n...\n    creating build/temp.linux-i686-2.7/src/lxml\n    gcc-4.5 -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m32 -march=i686 -mtune=atom -fasynchronous-unwind-tables -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m32 -march=i686 -mtune=atom -fasynchronous-unwind-tables -D_GNU_SOURCE -fPIC -fwrapv -fPIC -I/usr/include/libxml2 -I/tmp/pip-build-castedo/lxml/src/lxml/includes -I/usr/include/python2.7 -c src/lxml/lxml.etree.c -o build/temp.linux-i686-2.7/src/lxml/lxml.etree.o\n\n```\nunable to execute gcc-4.5: No such file or directory\n\nerror: command 'gcc-4.5' failed with exit status 1\n```\n\n....\n\"\n\nYou might want to update install instructions to warn folks that they might need to manually run yum for those dependencies.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/414/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/414/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/411", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/411/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/411/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/411/events", "html_url": "https://github.com/scrapy/scrapy/issues/411", "id": 20432011, "node_id": "MDU6SXNzdWUyMDQzMjAxMQ==", "number": 411, "title": "Scrapy hangs if an exception raises in start_requests", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/4", "html_url": "https://github.com/scrapy/scrapy/milestone/4", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/4/labels", "id": 437899, "node_id": "MDk6TWlsZXN0b25lNDM3ODk5", "number": 4, "title": "Scrapy 0.20", "description": null, "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 54, "state": "closed", "created_at": "2013-09-26T17:35:12Z", "updated_at": "2016-11-29T10:28:33Z", "due_on": null, "closed_at": "2014-11-25T12:56:04Z"}, "comments": 5, "created_at": "2013-10-03T00:59:48Z", "updated_at": "2013-11-08T18:17:02Z", "closed_at": "2013-10-10T01:04:50Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Symptoms are the same as in https://github.com/scrapy/scrapy/issues/83, but the reason is different, so I opened a new ticket. This issue starts to happen after this commit: https://github.com/alexcepoi/scrapy/commit/902208ca58aa99bacea57488642e0ea4129bd180. @alexcepoi any ideas?\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/411/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/411/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/407", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/407/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/407/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/407/events", "html_url": "https://github.com/scrapy/scrapy/issues/407", "id": 20368436, "node_id": "MDU6SXNzdWUyMDM2ODQzNg==", "number": 407, "title": "Twisted exception `AlreadyCalledError` when I follow the documentation", "user": {"login": "gkb", "id": 2376363, "node_id": "MDQ6VXNlcjIzNzYzNjM=", "avatar_url": "https://avatars.githubusercontent.com/u/2376363?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gkb", "html_url": "https://github.com/gkb", "followers_url": "https://api.github.com/users/gkb/followers", "following_url": "https://api.github.com/users/gkb/following{/other_user}", "gists_url": "https://api.github.com/users/gkb/gists{/gist_id}", "starred_url": "https://api.github.com/users/gkb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gkb/subscriptions", "organizations_url": "https://api.github.com/users/gkb/orgs", "repos_url": "https://api.github.com/users/gkb/repos", "events_url": "https://api.github.com/users/gkb/events{/privacy}", "received_events_url": "https://api.github.com/users/gkb/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/4", "html_url": "https://github.com/scrapy/scrapy/milestone/4", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/4/labels", "id": 437899, "node_id": "MDk6TWlsZXN0b25lNDM3ODk5", "number": 4, "title": "Scrapy 0.20", "description": null, "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 54, "state": "closed", "created_at": "2013-09-26T17:35:12Z", "updated_at": "2016-11-29T10:28:33Z", "due_on": null, "closed_at": "2014-11-25T12:56:04Z"}, "comments": 5, "created_at": "2013-10-02T00:43:50Z", "updated_at": "2013-11-08T17:47:46Z", "closed_at": "2013-10-10T01:50:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "I worked through an example from the [documentation](http://doc.scrapy.org/en/latest/topics/shell.html) on the scrapy shell. One of the commands there did not work however and I got an `AlreadyCalledError` from a deferred in Twisted. \n\nMore specifically, [this example](http://doc.scrapy.org/en/latest/topics/shell.html#example-of-shell-session) failed during the call to `request.replace(method=\"POST\")`. The method should return a new object according to its doc, but I think the reason Twisted throws the `AlreadyCalledError` is because it has run through the deferred's callbacks already in the new object. In other words, `request.replace()` is not returning an independent clone.\n\nHere's a [gist](https://gist.github.com/gkb/c55c21316ccb2355d792) containing the exact error message.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/407/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/407/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/406", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/406/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/406/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/406/events", "html_url": "https://github.com/scrapy/scrapy/pull/406", "id": 20328234, "node_id": "MDExOlB1bGxSZXF1ZXN0ODczNzAwOA==", "number": 406, "title": "Handling inconsistencies among Twisted releases", "user": {"login": "nopper", "id": 129937, "node_id": "MDQ6VXNlcjEyOTkzNw==", "avatar_url": "https://avatars.githubusercontent.com/u/129937?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nopper", "html_url": "https://github.com/nopper", "followers_url": "https://api.github.com/users/nopper/followers", "following_url": "https://api.github.com/users/nopper/following{/other_user}", "gists_url": "https://api.github.com/users/nopper/gists{/gist_id}", "starred_url": "https://api.github.com/users/nopper/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nopper/subscriptions", "organizations_url": "https://api.github.com/users/nopper/orgs", "repos_url": "https://api.github.com/users/nopper/repos", "events_url": "https://api.github.com/users/nopper/events{/privacy}", "received_events_url": "https://api.github.com/users/nopper/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/4", "html_url": "https://github.com/scrapy/scrapy/milestone/4", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/4/labels", "id": 437899, "node_id": "MDk6TWlsZXN0b25lNDM3ODk5", "number": 4, "title": "Scrapy 0.20", "description": null, "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 54, "state": "closed", "created_at": "2013-09-26T17:35:12Z", "updated_at": "2016-11-29T10:28:33Z", "due_on": null, "closed_at": "2014-11-25T12:56:04Z"}, "comments": 0, "created_at": "2013-10-01T12:39:01Z", "updated_at": "2014-06-12T16:08:02Z", "closed_at": "2013-10-01T16:59:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/406", "html_url": "https://github.com/scrapy/scrapy/pull/406", "diff_url": "https://github.com/scrapy/scrapy/pull/406.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/406.patch", "merged_at": "2013-10-01T16:59:00Z"}, "body": "Using scrapy with Twisted 13 produce this exception if a user visit a not-defined resource. The patch should solve the issue.\n\n```\n    Traceback (most recent call last):\n      File \"/Users/nopper/.pythonbrew/venvs/Python-2.7.3/frugal/lib/python2.7/site-packages/twisted/protocols/basic.py\", line 571, in dataReceived\n        why = self.lineReceived(line)\n      File \"/Users/nopper/.pythonbrew/venvs/Python-2.7.3/frugal/lib/python2.7/site-packages/twisted/web/http.py\", line 1619, in lineReceived\n        self.allContentReceived()\n      File \"/Users/nopper/.pythonbrew/venvs/Python-2.7.3/frugal/lib/python2.7/site-packages/twisted/web/http.py\", line 1694, in allContentReceived\n        req.requestReceived(command, path, version)\n      File \"/Users/nopper/.pythonbrew/venvs/Python-2.7.3/frugal/lib/python2.7/site-packages/twisted/web/http.py\", line 790, in requestReceived\n        self.process()\n    --- <exception caught here> ---\n      File \"/Users/nopper/.pythonbrew/venvs/Python-2.7.3/frugal/lib/python2.7/site-packages/twisted/web/server.py\", line 184, in process\n        resrc = self.site.getResourceFor(self)\n      File \"/Users/nopper/.pythonbrew/venvs/Python-2.7.3/frugal/lib/python2.7/site-packages/twisted/web/server.py\", line 701, in getResourceFor\n        return resource.getChildForRequest(self.resource, request)\n      File \"/Users/nopper/.pythonbrew/venvs/Python-2.7.3/frugal/lib/python2.7/site-packages/twisted/web/resource.py\", line 98, in getChildForRequest\n        resource = resource.getChildWithDefault(pathElement, request)\n      File \"/Users/nopper/.pythonbrew/venvs/Python-2.7.3/frugal/lib/python2.7/site-packages/twisted/web/resource.py\", line 201, in getChildWithDefault\n        return self.getChild(path, request)\n      File \"/Users/nopper/.pythonbrew/venvs/Python-2.7.3/frugal/lib/python2.7/site-packages/scrapy/webservice.py\", line 48, in getChild\n        return error.NoResource(\"No such child resource.\")\n    exceptions.AttributeError: 'module' object has no attribute 'NoResource'\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/406/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/406/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/402", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/402/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/402/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/402/events", "html_url": "https://github.com/scrapy/scrapy/pull/402", "id": 20236049, "node_id": "MDExOlB1bGxSZXF1ZXN0ODY5MTkxMg==", "number": 402, "title": "Corrected typo.", "user": {"login": "LorenDavie", "id": 505117, "node_id": "MDQ6VXNlcjUwNTExNw==", "avatar_url": "https://avatars.githubusercontent.com/u/505117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LorenDavie", "html_url": "https://github.com/LorenDavie", "followers_url": "https://api.github.com/users/LorenDavie/followers", "following_url": "https://api.github.com/users/LorenDavie/following{/other_user}", "gists_url": "https://api.github.com/users/LorenDavie/gists{/gist_id}", "starred_url": "https://api.github.com/users/LorenDavie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LorenDavie/subscriptions", "organizations_url": "https://api.github.com/users/LorenDavie/orgs", "repos_url": "https://api.github.com/users/LorenDavie/repos", "events_url": "https://api.github.com/users/LorenDavie/events{/privacy}", "received_events_url": "https://api.github.com/users/LorenDavie/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/4", "html_url": "https://github.com/scrapy/scrapy/milestone/4", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/4/labels", "id": 437899, "node_id": "MDk6TWlsZXN0b25lNDM3ODk5", "number": 4, "title": "Scrapy 0.20", "description": null, "creator": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 54, "state": "closed", "created_at": "2013-09-26T17:35:12Z", "updated_at": "2016-11-29T10:28:33Z", "due_on": null, "closed_at": "2014-11-25T12:56:04Z"}, "comments": 0, "created_at": "2013-09-29T21:08:26Z", "updated_at": "2014-06-12T16:08:02Z", "closed_at": "2013-09-29T21:21:04Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/scrapy/scrapy/pulls/402", "html_url": "https://github.com/scrapy/scrapy/pull/402", "diff_url": "https://github.com/scrapy/scrapy/pull/402.diff", "patch_url": "https://github.com/scrapy/scrapy/pull/402.patch", "merged_at": "2013-09-29T21:21:04Z"}, "body": "", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/402/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/402/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/396", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/396/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/396/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/396/events", "html_url": "https://github.com/scrapy/scrapy/issues/396", "id": 19998882, "node_id": "MDU6SXNzdWUxOTk5ODg4Mg==", "number": 396, "title": "inspect_response(response) yields incorrect response in IPython shell", "user": {"login": "xEtherealx", "id": 3417501, "node_id": "MDQ6VXNlcjM0MTc1MDE=", "avatar_url": "https://avatars.githubusercontent.com/u/3417501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xEtherealx", "html_url": "https://github.com/xEtherealx", "followers_url": "https://api.github.com/users/xEtherealx/followers", "following_url": "https://api.github.com/users/xEtherealx/following{/other_user}", "gists_url": "https://api.github.com/users/xEtherealx/gists{/gist_id}", "starred_url": "https://api.github.com/users/xEtherealx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xEtherealx/subscriptions", "organizations_url": "https://api.github.com/users/xEtherealx/orgs", "repos_url": "https://api.github.com/users/xEtherealx/repos", "events_url": "https://api.github.com/users/xEtherealx/events{/privacy}", "received_events_url": "https://api.github.com/users/xEtherealx/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/18", "html_url": "https://github.com/scrapy/scrapy/milestone/18", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/18/labels", "id": 2165995, "node_id": "MDk6TWlsZXN0b25lMjE2NTk5NQ==", "number": 18, "title": "v1.2.2", "description": null, "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 9, "state": "closed", "created_at": "2016-11-30T10:34:24Z", "updated_at": "2017-02-20T14:37:46Z", "due_on": null, "closed_at": "2017-02-20T14:37:46Z"}, "comments": 12, "created_at": "2013-09-24T19:06:44Z", "updated_at": "2016-11-30T12:49:52Z", "closed_at": "2016-11-30T12:49:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "Example case (requires registration at example site, and even then would be hard to use as a use-case; modify to suit your needs): http://pastebin.com/GT8N893q\n\nIn the above example, the response.meta printout in after_submit callback does not match that within the inspect_response shell on the second iteration (the first is correct).  It appears that inspect_response has a stale response the second time.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/396/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/396/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/383", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/383/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/383/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/383/events", "html_url": "https://github.com/scrapy/scrapy/issues/383", "id": 19243456, "node_id": "MDU6SXNzdWUxOTI0MzQ1Ng==", "number": 383, "title": "Close spider using jsonrpc is broken", "user": {"login": "askender", "id": 1472850, "node_id": "MDQ6VXNlcjE0NzI4NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/1472850?v=4", "gravatar_id": "", "url": "https://api.github.com/users/askender", "html_url": "https://github.com/askender", "followers_url": "https://api.github.com/users/askender/followers", "following_url": "https://api.github.com/users/askender/following{/other_user}", "gists_url": "https://api.github.com/users/askender/gists{/gist_id}", "starred_url": "https://api.github.com/users/askender/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/askender/subscriptions", "organizations_url": "https://api.github.com/users/askender/orgs", "repos_url": "https://api.github.com/users/askender/repos", "events_url": "https://api.github.com/users/askender/events{/privacy}", "received_events_url": "https://api.github.com/users/askender/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2013-09-10T08:11:13Z", "updated_at": "2013-09-28T05:09:27Z", "closed_at": "2013-09-27T21:18:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "http://doc.scrapy.org/en/0.18/topics/webservice.html\n\n> jsonrpc_call(opts, 'crawler/engine', 'close_spider', args[0])\n> return:\n> code: -32603\n> data: \"Traceback (most recent call last): File \"/usr/local/lib/python2.7/dist-packages/scrapy/utils/jsonrpc.py\", line 74, in jsonrpc_server_call return jsonrpc_result(id, method(_a, *_kw)) File \"/usr/local/lib/python2.7/dist-packages/scrapy/core/engine.py\", line 252, in close_spider slot = self.slots[spider] KeyError: u'dianping' \"\n\nMany thanks~\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/383/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/383/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/345", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/345/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/345/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/345/events", "html_url": "https://github.com/scrapy/scrapy/issues/345", "id": 16614659, "node_id": "MDU6SXNzdWUxNjYxNDY1OQ==", "number": 345, "title": "Scrapy chokes on HTTP response status lines without a Reason phrase", "user": {"login": "tonal", "id": 316216, "node_id": "MDQ6VXNlcjMxNjIxNg==", "avatar_url": "https://avatars.githubusercontent.com/u/316216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tonal", "html_url": "https://github.com/tonal", "followers_url": "https://api.github.com/users/tonal/followers", "following_url": "https://api.github.com/users/tonal/following{/other_user}", "gists_url": "https://api.github.com/users/tonal/gists{/gist_id}", "starred_url": "https://api.github.com/users/tonal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tonal/subscriptions", "organizations_url": "https://api.github.com/users/tonal/orgs", "repos_url": "https://api.github.com/users/tonal/repos", "events_url": "https://api.github.com/users/tonal/events{/privacy}", "received_events_url": "https://api.github.com/users/tonal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 37, "created_at": "2013-07-11T05:16:14Z", "updated_at": "2019-07-24T23:48:01Z", "closed_at": "2017-06-20T15:29:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Try fetch page:\n\n```\n$ scrapy fetch 'http://www.gidroprofmontag.ru/bassein/sbornue_basseynu'\n```\n\noutput:\n\n```\n2013-07-11 09:15:37+0400 [scrapy] INFO: Scrapy 0.17.0-304-g3fe2a32 started (bot: amon)\n/home/tonal/amon/amon/amon/downloadermiddleware/blocked.py:6: ScrapyDeprecationWarning: Module `scrapy.stats` is deprecated, use `crawler.stats` attribute instead\n  from scrapy.stats import stats\n2013-07-11 09:15:37+0400 [amon_ra] INFO: Spider opened\n2013-07-11 09:15:37+0400 [amon_ra] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2013-07-11 09:15:37+0400 [amon_ra] ERROR: Error downloading <GET http://www.gidroprofmontag.ru/bassein/sbornue_basseynu>: [<twisted.python.failure.Failure <class 'scrapy.xlib.tx._newclient.ParseError'>>]\n2013-07-11 09:15:37+0400 [amon_ra] INFO: Closing spider (finished)\n2013-07-11 09:15:37+0400 [amon_ra] INFO: Dumping Scrapy stats:\n        {'downloader/exception_count': 1,\n         'downloader/exception_type_count/scrapy.xlib.tx._newclient.ResponseFailed': 1,\n         'downloader/request_bytes': 256,\n         'downloader/request_count': 1,\n         'downloader/request_method_count/GET': 1,\n         'finish_reason': 'finished',\n         'finish_time': datetime.datetime(2013, 7, 11, 5, 15, 37, 512010),\n         'log_count/ERROR': 1,\n         'log_count/INFO': 4,\n         'scheduler/dequeued': 1,\n         'scheduler/dequeued/memory': 1,\n         'scheduler/enqueued': 1,\n         'scheduler/enqueued/memory': 1,\n         'start_time': datetime.datetime(2013, 7, 11, 5, 15, 37, 257898)}\n2013-07-11 09:15:37+0400 [amon_ra] INFO: Spider closed (finished)\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/345/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/345/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/220", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/220/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/220/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/220/events", "html_url": "https://github.com/scrapy/scrapy/issues/220", "id": 9634974, "node_id": "MDU6SXNzdWU5NjM0OTc0", "number": 220, "title": "process_spider_exception() not invoked for generators", "user": {"login": "Mimino666", "id": 1270393, "node_id": "MDQ6VXNlcjEyNzAzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/1270393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mimino666", "html_url": "https://github.com/Mimino666", "followers_url": "https://api.github.com/users/Mimino666/followers", "following_url": "https://api.github.com/users/Mimino666/following{/other_user}", "gists_url": "https://api.github.com/users/Mimino666/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mimino666/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mimino666/subscriptions", "organizations_url": "https://api.github.com/users/Mimino666/orgs", "repos_url": "https://api.github.com/users/Mimino666/repos", "events_url": "https://api.github.com/users/Mimino666/events{/privacy}", "received_events_url": "https://api.github.com/users/Mimino666/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 281088273, "node_id": "MDU6TGFiZWwyODEwODgyNzM=", "url": "https://api.github.com/repos/scrapy/scrapy/labels/help%20wanted", "name": "help wanted", "color": "009800", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2013-01-03T03:23:03Z", "updated_at": "2019-04-01T07:43:20Z", "closed_at": "2019-04-01T07:43:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "When a spider implements _parse()_ function through generator (i.e. returning results with _yields_) and an exception raises in _parse()_, then spidermiddleware's _process_spider_exception()_ is not called.\n\nThe reason is that exception is finally invoked in one of the spidermiddlewares.\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/220/reactions", "total_count": 6, "+1": 6, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/220/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/209", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/209/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/209/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/209/events", "html_url": "https://github.com/scrapy/scrapy/issues/209", "id": 9430556, "node_id": "MDU6SXNzdWU5NDMwNTU2", "number": 209, "title": "Parse commando doesn't work without specifying concrete spider", "user": {"login": "enagorny", "id": 1202150, "node_id": "MDQ6VXNlcjEyMDIxNTA=", "avatar_url": "https://avatars.githubusercontent.com/u/1202150?v=4", "gravatar_id": "", "url": "https://api.github.com/users/enagorny", "html_url": "https://github.com/enagorny", "followers_url": "https://api.github.com/users/enagorny/followers", "following_url": "https://api.github.com/users/enagorny/following{/other_user}", "gists_url": "https://api.github.com/users/enagorny/gists{/gist_id}", "starred_url": "https://api.github.com/users/enagorny/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/enagorny/subscriptions", "organizations_url": "https://api.github.com/users/enagorny/orgs", "repos_url": "https://api.github.com/users/enagorny/repos", "events_url": "https://api.github.com/users/enagorny/events{/privacy}", "received_events_url": "https://api.github.com/users/enagorny/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2012-12-20T10:53:19Z", "updated_at": "2012-12-20T14:03:23Z", "closed_at": "2012-12-20T13:59:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "It worked in 0.14.\nSTR:\nscrapy parse \"http://www.example.com/foobar\" -c parse_item\n\nAnd now it throws exception:\n\n```\nTraceback (most recent call last):\nFile \"/usr/local/bin/scrapy\", line 4, in <module>\n  execute()\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/cmdline.py\", line 131, in execute\n  _run_print_help(parser, _run_command, cmd, args, opts)\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/cmdline.py\", line 76, in _run_print_help\n  func(*a, **kw)\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/cmdline.py\", line 138, in _run_command\n  cmd.run(args, opts)\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/commands/parse.py\", line 194, in run\n  self.set_spider(url, opts)\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/commands/parse.py\", line 128, in set_spider\n  self.spider = create_spider_for_request(self.crawler.spiders, url)\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/utils/spider.py\", line 38, in create_spider_for_request\n  snames = spidermanager.find_by_request(request)\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/spidermanager.py\", line 48, in find_by_request\n  if cls.handles_request(request)]\nFile \"/usr/local/lib/python2.7/dist-packages/scrapy/spider.py\", line 62, in handles_request\n  return url_is_from_spider(request.url, cls)\nAttributeError: 'str' object has no attribute 'url'\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/209/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/209/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/199", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/199/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/199/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/199/events", "html_url": "https://github.com/scrapy/scrapy/issues/199", "id": 8701943, "node_id": "MDU6SXNzdWU4NzAxOTQz", "number": 199, "title": "Exception UnicodeDecodeError in linkextractors", "user": {"login": "dzyao", "id": 239402, "node_id": "MDQ6VXNlcjIzOTQwMg==", "avatar_url": "https://avatars.githubusercontent.com/u/239402?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzyao", "html_url": "https://github.com/dzyao", "followers_url": "https://api.github.com/users/dzyao/followers", "following_url": "https://api.github.com/users/dzyao/following{/other_user}", "gists_url": "https://api.github.com/users/dzyao/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzyao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzyao/subscriptions", "organizations_url": "https://api.github.com/users/dzyao/orgs", "repos_url": "https://api.github.com/users/dzyao/repos", "events_url": "https://api.github.com/users/dzyao/events{/privacy}", "received_events_url": "https://api.github.com/users/dzyao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/2", "html_url": "https://github.com/scrapy/scrapy/milestone/2", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/2/labels", "id": 233782, "node_id": "MDk6TWlsZXN0b25lMjMzNzgy", "number": 2, "title": "Scrapy 0.18", "description": "", "creator": {"login": "pablohoffman", "id": 185212, "node_id": "MDQ6VXNlcjE4NTIxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/185212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pablohoffman", "html_url": "https://github.com/pablohoffman", "followers_url": "https://api.github.com/users/pablohoffman/followers", "following_url": "https://api.github.com/users/pablohoffman/following{/other_user}", "gists_url": "https://api.github.com/users/pablohoffman/gists{/gist_id}", "starred_url": "https://api.github.com/users/pablohoffman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pablohoffman/subscriptions", "organizations_url": "https://api.github.com/users/pablohoffman/orgs", "repos_url": "https://api.github.com/users/pablohoffman/repos", "events_url": "https://api.github.com/users/pablohoffman/events{/privacy}", "received_events_url": "https://api.github.com/users/pablohoffman/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 27, "state": "closed", "created_at": "2012-12-21T19:49:43Z", "updated_at": "2014-11-25T12:56:44Z", "due_on": null, "closed_at": "2014-11-25T12:56:44Z"}, "comments": 3, "created_at": "2012-11-27T01:07:48Z", "updated_at": "2013-01-30T21:55:52Z", "closed_at": "2013-01-29T20:09:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\nFile \"/lib/python2.6/site-packages/Scrapy-0.16.2-py2.6.egg/scrapy/contrib/linkextractors/sgml.py\"\nline 84, in handle_data \nself.current_link.text = self.current_link.text + data.strip()\nexceptions.UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128).\n```\n\nI find other one also have the same issues on this line. My suggestion is to create a Unicode detection code like this.\n\n```\n if isinstance(self.current_link.text, unicode):\n                self.current_link.text = self.current_link.text + data.strip()\nelse:\n                self.current_link.text = self.current_link.text.decode('utf-8') + data.strip()\n#self.current_link.text = self.current_link.text + data.strip()\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/199/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/199/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/163", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/163/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/163/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/163/events", "html_url": "https://github.com/scrapy/scrapy/issues/163", "id": 6034233, "node_id": "MDU6SXNzdWU2MDM0MjMz", "number": 163, "title": "Empty results from SgmlLinkExtractor", "user": {"login": "turian", "id": 65918, "node_id": "MDQ6VXNlcjY1OTE4", "avatar_url": "https://avatars.githubusercontent.com/u/65918?v=4", "gravatar_id": "", "url": "https://api.github.com/users/turian", "html_url": "https://github.com/turian", "followers_url": "https://api.github.com/users/turian/followers", "following_url": "https://api.github.com/users/turian/following{/other_user}", "gists_url": "https://api.github.com/users/turian/gists{/gist_id}", "starred_url": "https://api.github.com/users/turian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/turian/subscriptions", "organizations_url": "https://api.github.com/users/turian/orgs", "repos_url": "https://api.github.com/users/turian/repos", "events_url": "https://api.github.com/users/turian/events{/privacy}", "received_events_url": "https://api.github.com/users/turian/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2012-08-05T02:15:00Z", "updated_at": "2014-07-02T22:29:54Z", "closed_at": "2014-07-02T22:29:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "SgmlLinkExtractor returns no links for http://metaoptimize.com/qa/\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/163/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/163/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/28", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/28/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/28/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/28/events", "html_url": "https://github.com/scrapy/scrapy/issues/28", "id": 1605249, "node_id": "MDU6SXNzdWUxNjA1MjQ5", "number": 28, "title": "SqlitePriorityQueue.pop() return None may crash Poller.poll()", "user": {"login": "shaneaevans", "id": 220454, "node_id": "MDQ6VXNlcjIyMDQ1NA==", "avatar_url": "https://avatars.githubusercontent.com/u/220454?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shaneaevans", "html_url": "https://github.com/shaneaevans", "followers_url": "https://api.github.com/users/shaneaevans/followers", "following_url": "https://api.github.com/users/shaneaevans/following{/other_user}", "gists_url": "https://api.github.com/users/shaneaevans/gists{/gist_id}", "starred_url": "https://api.github.com/users/shaneaevans/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shaneaevans/subscriptions", "organizations_url": "https://api.github.com/users/shaneaevans/orgs", "repos_url": "https://api.github.com/users/shaneaevans/repos", "events_url": "https://api.github.com/users/shaneaevans/events{/privacy}", "received_events_url": "https://api.github.com/users/shaneaevans/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2011-09-09T05:35:33Z", "updated_at": "2014-04-25T22:08:51Z", "closed_at": "2014-04-25T22:08:51Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Previously reported by mrkschan on Trac http://dev.scrapy.org/ticket/313\n\nI have a scrapy project that has several spiders in it. Those spiders are scheduled to execute on an hourly-basis.\n\nThe scrapyd eventually report unhandled error (as shown below). When I dig through the source of scrapy, I suspect the concurrent control of sqlite3 access is not well guarded as the error below is caused by popping from an empty queue.\n\nThe case can simply be explained by the scenario with two spiders A and B (also refer to the source -  http://is.gd/ht4HSs).\n\nSpider A's poller poll() get to line 21 of scrapyd/poller.py.\nMeanwhile, Spider B's poller also get to line 21.\nSpider A's poller poll() get to line 23, the queue in sqlite becomes empty and sqlite3 is locked (according to py doc -  http://is.gd/67PKpn).\nSpider B's poller poll() also get to line 23, wait the lock to be released.\nSpider A commit and release the sqlite lock.\nSpider B pop() from an empty queue. Raise Error.\n\n```\nTraceback (most recent call last):\n  File \"/usr/lib/python2.6/dist-packages/twisted/internet/base.py\", line 778, in runUntilCurrent\n    call.func(*call.args, **call.kw)\n  File \"/usr/lib/python2.6/dist-packages/twisted/internet/task.py\", line 194, in __call__\n    d = defer.maybeDeferred(self.f, *self.a, **self.kw)\n  File \"/usr/lib/python2.6/dist-packages/twisted/internet/defer.py\", line 117, in maybeDeferred\n    result = f(*args, **kw)\n  File \"/usr/lib/python2.6/dist-packages/twisted/internet/defer.py\", line 944, in unwindGenerator\n    return _inlineCallbacks(None, f(*args, **kwargs), Deferred())\n--- <exception caught here> ---\n  File \"/usr/lib/python2.6/dist-packages/twisted/internet/defer.py\", line 823, in _inlineCallbacks\n    result = g.send(result)\n  File \"/usr/lib/pymodules/python2.6/scrapyd/poller.py\", line 24, in poll\n    returnValue(self.dq.put(self._message(msg, p)))\n  File \"/usr/lib/pymodules/python2.6/scrapyd/poller.py\", line 33, in _message\n    d = queue_msg.copy()\nexceptions.AttributeError: 'NoneType' object has no attribute 'copy'\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/28/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/28/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/24", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/24/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/24/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/24/events", "html_url": "https://github.com/scrapy/scrapy/issues/24", "id": 1605232, "node_id": "MDU6SXNzdWUxNjA1MjMy", "number": 24, "title": "SgmlLinkExtractor mangles some url encoding (specifically \"/\" encoded)", "user": {"login": "shaneaevans", "id": 220454, "node_id": "MDQ6VXNlcjIyMDQ1NA==", "avatar_url": "https://avatars.githubusercontent.com/u/220454?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shaneaevans", "html_url": "https://github.com/shaneaevans", "followers_url": "https://api.github.com/users/shaneaevans/followers", "following_url": "https://api.github.com/users/shaneaevans/following{/other_user}", "gists_url": "https://api.github.com/users/shaneaevans/gists{/gist_id}", "starred_url": "https://api.github.com/users/shaneaevans/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shaneaevans/subscriptions", "organizations_url": "https://api.github.com/users/shaneaevans/orgs", "repos_url": "https://api.github.com/users/shaneaevans/repos", "events_url": "https://api.github.com/users/shaneaevans/events{/privacy}", "received_events_url": "https://api.github.com/users/shaneaevans/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/scrapy/milestones/2", "html_url": "https://github.com/scrapy/scrapy/milestone/2", "labels_url": "https://api.github.com/repos/scrapy/scrapy/milestones/2/labels", "id": 233782, "node_id": "MDk6TWlsZXN0b25lMjMzNzgy", "number": 2, "title": "Scrapy 0.18", "description": "", "creator": {"login": "pablohoffman", "id": 185212, "node_id": "MDQ6VXNlcjE4NTIxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/185212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pablohoffman", "html_url": "https://github.com/pablohoffman", "followers_url": "https://api.github.com/users/pablohoffman/followers", "following_url": "https://api.github.com/users/pablohoffman/following{/other_user}", "gists_url": "https://api.github.com/users/pablohoffman/gists{/gist_id}", "starred_url": "https://api.github.com/users/pablohoffman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pablohoffman/subscriptions", "organizations_url": "https://api.github.com/users/pablohoffman/orgs", "repos_url": "https://api.github.com/users/pablohoffman/repos", "events_url": "https://api.github.com/users/pablohoffman/events{/privacy}", "received_events_url": "https://api.github.com/users/pablohoffman/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 27, "state": "closed", "created_at": "2012-12-21T19:49:43Z", "updated_at": "2014-11-25T12:56:44Z", "due_on": null, "closed_at": "2014-11-25T12:56:44Z"}, "comments": 4, "created_at": "2011-09-09T05:31:07Z", "updated_at": "2013-01-30T21:43:17Z", "closed_at": "2013-01-30T18:56:49Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Reported by kurtjx on Trac http://dev.scrapy.org/ticket/316\n\n``` python\nIn [10]: fetch('http://www.last.fm/music/AC%252FDC/+images')\nIn [11]: lx = SgmlLinkExtractor(restrict_xpaths=('//a[@class=\"nextlink\"]'))\n\nIn [12]: lx.extract_links(response)\nOut[12]: [<Link url='http://www.last.fm/music/AC%2FDC/+images?page=2' text=u'Next' >]\n```\n\nthe found link gets mangled to have \"AC%2FDC\" but it should be \"AC%252FDC\"\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/24/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/24/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/scrapy/scrapy/issues/21", "repository_url": "https://api.github.com/repos/scrapy/scrapy", "labels_url": "https://api.github.com/repos/scrapy/scrapy/issues/21/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/scrapy/issues/21/comments", "events_url": "https://api.github.com/repos/scrapy/scrapy/issues/21/events", "html_url": "https://github.com/scrapy/scrapy/issues/21", "id": 1605217, "node_id": "MDU6SXNzdWUxNjA1MjE3", "number": 21, "title": "Defect in FormRequest constructor", "user": {"login": "shaneaevans", "id": 220454, "node_id": "MDQ6VXNlcjIyMDQ1NA==", "avatar_url": "https://avatars.githubusercontent.com/u/220454?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shaneaevans", "html_url": "https://github.com/shaneaevans", "followers_url": "https://api.github.com/users/shaneaevans/followers", "following_url": "https://api.github.com/users/shaneaevans/following{/other_user}", "gists_url": "https://api.github.com/users/shaneaevans/gists{/gist_id}", "starred_url": "https://api.github.com/users/shaneaevans/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shaneaevans/subscriptions", "organizations_url": "https://api.github.com/users/shaneaevans/orgs", "repos_url": "https://api.github.com/users/shaneaevans/repos", "events_url": "https://api.github.com/users/shaneaevans/events{/privacy}", "received_events_url": "https://api.github.com/users/shaneaevans/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 13907246, "node_id": "MDU6TGFiZWwxMzkwNzI0Ng==", "url": "https://api.github.com/repos/scrapy/scrapy/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2011-09-09T05:26:25Z", "updated_at": "2013-01-29T14:43:26Z", "closed_at": "2013-01-29T14:43:26Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Reported by cdeyoung on Trac http://dev.scrapy.org/ticket/323\n\nIn the constructor of the FormRequest? class in scrapy/http/request.form.py -- in the IF statement that handles the \"formdata\" argument -- there is a line that says:\n\n``` python\n    self.method = 'POST'\n```\n\nThat line either shouldn't be there, falling back to the base class's method variable, or it should be handled differently if you want FormRequest? to default to POST rather that GET, as the Response base class does. Currently, you are hard-coding FormRequest? objects to be submitted via POST, and that isn't always valid. You should still allow the developer to specify method='GET' when using a FormRequest? object, I think.\n\nIf you want FormRequest? to default to submitting forms via POST, then I would recommend the following change, or something like it:\n\n``` python\nclass FormRequest(Request):\n    __slots__ = ()\n    def __init__(self, *args, **kwargs):\n        formdata = kwargs.pop('formdata', None)\n        method = kwargs.pop('method', 'POST')\n\n        super(FormRequest, self).__init__(*args, **kwargs)\n\n        if formdata:\n            self.method = method\n            ...\n```\n", "reactions": {"url": "https://api.github.com/repos/scrapy/scrapy/issues/21/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/scrapy/scrapy/issues/21/timeline", "performed_via_github_app": null, "state_reason": "completed"}]