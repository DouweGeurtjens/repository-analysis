[{"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/833", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/833/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/833/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/833/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/833", "id": 325932063, "node_id": "MDU6SXNzdWUzMjU5MzIwNjM=", "number": 833, "title": "Extremely poor performance w/ large embedding matrices (sort of fixed, but plz see inside)", "user": {"login": "cbockman", "id": 4667922, "node_id": "MDQ6VXNlcjQ2Njc5MjI=", "avatar_url": "https://avatars.githubusercontent.com/u/4667922?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cbockman", "html_url": "https://github.com/cbockman", "followers_url": "https://api.github.com/users/cbockman/followers", "following_url": "https://api.github.com/users/cbockman/following{/other_user}", "gists_url": "https://api.github.com/users/cbockman/gists{/gist_id}", "starred_url": "https://api.github.com/users/cbockman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cbockman/subscriptions", "organizations_url": "https://api.github.com/users/cbockman/orgs", "repos_url": "https://api.github.com/users/cbockman/repos", "events_url": "https://api.github.com/users/cbockman/events{/privacy}", "received_events_url": "https://api.github.com/users/cbockman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2018-05-24T01:28:40Z", "updated_at": "2018-08-07T02:36:31Z", "closed_at": "2018-05-24T20:49:43Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\r\n\r\nWe have a t2t fork and recently went to the effort to pull our fork basically up-to-date with core repo master.\r\n\r\nWe then saw the run-time performance of our models plummet from, e.g., 30 steps/s ==> 1 step/s.\r\n\r\nAfter much teeth gnashing, we tracked it down to an unfortunate interaction between a large (word) embedding matrix on the CPU and this update:\r\n\r\n```\r\n  def compute_gradients(self, loss, var_list=None, **kwargs):  # pylint: disable=arguments-differ\r\n    gradients = self._opt.compute_gradients(loss, var_list, **kwargs)\r\n    def cast_grad(g, v):\r\n      if v is None or g is None:\r\n        return (g, v)\r\n      return (tf.cast(g, v.dtype), v)\r\n    gradients = [cast_grad(g, v) for g, v in gradients]\r\n    return gradients\r\n```\r\n\r\nSpecifically, the version we were on was just\r\n\r\n```\r\n  def compute_gradients(self, loss, var_list=None, **kwargs):  # pylint: disable=arguments-differ\r\n    return self._opt.compute_gradients(loss, var_list, **kwargs)\r\n```\r\n\r\nGiven the code in block #1, what is happening makes sense.\r\n\r\nThe queries, then:\r\n\r\n1) What is that new block of code used for?  E.g., is it some support peculiar to TPUs?  Are we safe to just (internally) comment it out and use the \"old\" version?  (Presumably, there is a very good reason this was changed!)\r\n\r\n2) We've run into a couple of small other places that have to be handled very carefully to support word embeddings (at least if pinned on the CPU) (e.g., weight decay needs to be set to zero).\r\n\r\n*If* it is safe to, in some circumstances, revert to the old compute_gradients code, is there any appetite for an internal flag (hparams.support_large_embeddings, or something like that--I'd need to put a little thought into where exactly this should live) that conditions the code paths appropriately?  \r\n\r\nIf this is something of interest, then would happily push a PR, to converge how we apparently need to manage things internally with t2t master.  ", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/833/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/833/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/828", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/828/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/828/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/828/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/828", "id": 325637427, "node_id": "MDU6SXNzdWUzMjU2Mzc0Mjc=", "number": 828, "title": "tensorflow serving with beam_size=1 return empty", "user": {"login": "mudong0419", "id": 24379054, "node_id": "MDQ6VXNlcjI0Mzc5MDU0", "avatar_url": "https://avatars.githubusercontent.com/u/24379054?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mudong0419", "html_url": "https://github.com/mudong0419", "followers_url": "https://api.github.com/users/mudong0419/followers", "following_url": "https://api.github.com/users/mudong0419/following{/other_user}", "gists_url": "https://api.github.com/users/mudong0419/gists{/gist_id}", "starred_url": "https://api.github.com/users/mudong0419/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mudong0419/subscriptions", "organizations_url": "https://api.github.com/users/mudong0419/orgs", "repos_url": "https://api.github.com/users/mudong0419/repos", "events_url": "https://api.github.com/users/mudong0419/events{/privacy}", "received_events_url": "https://api.github.com/users/mudong0419/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-05-23T10:07:49Z", "updated_at": "2018-05-30T09:17:57Z", "closed_at": "2018-05-30T09:17:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\n>I trained an English2Chinese transformer model. In order to speed up decoding, beam_size is set to be 1. It decodes as expected with t2t-decoder, but if I export the model, serving on localhost and then query with t2t-query-server, the output is empty.\r\n\r\n### *TensorFlow* and *tensor2tensor* versions\r\n\r\n> TensorFlow 1.5, 1.6, 1.7, Tensor2Tensor 1.5.4\r\n\r\n### In case of bug report: Steps to reproduce the problem\r\n\r\n> 1. Train a transformer model on translation problem.\r\n>  2. Export checkpoint with \r\n>  --decode_hparams=\"beam_size=1,alpha=0.6\"\r\n>  3. Serving the model\r\n>  serving/bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 -- \r\n>  model_name=my_model --model_base_path=...\r\n> 4. t2t-query-server, test the service\r\n> 5. input source language sentence, the output is empty\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/828/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/828/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/809", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/809/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/809/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/809/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/809", "id": 323709143, "node_id": "MDU6SXNzdWUzMjM3MDkxNDM=", "number": 809, "title": "*bug* checkpoints are incompatible wrt training/learning_rate", "user": {"login": "martinpopel", "id": 724617, "node_id": "MDQ6VXNlcjcyNDYxNw==", "avatar_url": "https://avatars.githubusercontent.com/u/724617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinpopel", "html_url": "https://github.com/martinpopel", "followers_url": "https://api.github.com/users/martinpopel/followers", "following_url": "https://api.github.com/users/martinpopel/following{/other_user}", "gists_url": "https://api.github.com/users/martinpopel/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinpopel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinpopel/subscriptions", "organizations_url": "https://api.github.com/users/martinpopel/orgs", "repos_url": "https://api.github.com/users/martinpopel/repos", "events_url": "https://api.github.com/users/martinpopel/events{/privacy}", "received_events_url": "https://api.github.com/users/martinpopel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-16T17:06:32Z", "updated_at": "2018-06-08T03:08:16Z", "closed_at": "2018-06-08T03:08:16Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "When training with `learning_rate_schedule=constant`, the checkpoints contain a key called `training/learning_rate`.\r\nWhen training with `learning_rate_schedule=rsqrt_decay`, the checkpoints do not contain the key.\r\nThus one cannot continue training with a constant LR with a model pre-trained with rsqrt_decay, we get the `Key training/learning_rate not found in checkpoint` error.\r\n\r\nShould the key be there and why?\r\n\r\ntensor2tensor==1.6.0\r\ntensorflow==1.6.0\r\n", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/809/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/809/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/792", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/792/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/792/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/792/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/792", "id": 322150314, "node_id": "MDU6SXNzdWUzMjIxNTAzMTQ=", "number": 792, "title": "*Help* No model output yielded when running example using Cloud ML Engine", "user": {"login": "sakinaljana", "id": 2888190, "node_id": "MDQ6VXNlcjI4ODgxOTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2888190?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sakinaljana", "html_url": "https://github.com/sakinaljana", "followers_url": "https://api.github.com/users/sakinaljana/followers", "following_url": "https://api.github.com/users/sakinaljana/following{/other_user}", "gists_url": "https://api.github.com/users/sakinaljana/gists{/gist_id}", "starred_url": "https://api.github.com/users/sakinaljana/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sakinaljana/subscriptions", "organizations_url": "https://api.github.com/users/sakinaljana/orgs", "repos_url": "https://api.github.com/users/sakinaljana/repos", "events_url": "https://api.github.com/users/sakinaljana/events{/privacy}", "received_events_url": "https://api.github.com/users/sakinaljana/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-05-11T02:54:57Z", "updated_at": "2018-05-22T04:31:20Z", "closed_at": "2018-05-22T04:31:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi guys,\r\n\r\nI'm just trying to running example from here:\r\nhttps://tensorflow.github.io/tensor2tensor/cloud_mlengine.html\r\n\r\n```\r\n# Note that both the data dir and output dir have to be on GCS\r\nDATA_DIR=gs://my-bucket/data\r\nOUTPUT_DIR=gs://my-bucket/train\r\nt2t-trainer \\\r\n  --problem=translate_ende_wmt32k \\\r\n  --model=transformer \\\r\n  --hparams_set=transformer_base \\\r\n  --data_dir=$DATA_DIR \\\r\n  --output_dir=$OUTPUT_DIR \\\r\n  --cloud_mlengine\r\n```\r\n\r\nturns out the execution is successful but the model files (e.g.: .pbtxt, checkpoint, *.meta, *.index, ckpt, hparams.json) is not written into my $OUTPUT_DIR. I suspect the worker is not running because the logging only throw master instance, not worker instance. This is came conclusion the training is not yet started. Is there any steps that i'm missing to perform this on ML engine?\r\n\r\nThanks\r\n\r\nI'm using latest version of T2T: v1.6.2 and Tensorflow 1.8\r\n\r\nAppendix:\r\n\r\nSample cloud ML logs output:\r\n```\r\nT master-replica-0 gapic-google-cloud-logging-v2 0.91.3 has requirement google-gax<0.16dev,>=0.15.7, but you'll have google-gax 0.12.5 which is incompatible.\r\nmaster-replica-0 Installing collected packages: MarkupSafe, Jinja2, itsdangerous, click, flask, gunicorn, bz2file, pyglet, gym, h5py, greenlet, gevent, tensor2tensor, DummyT2TPackage\r\nmaster-replica-0 The script flask is installed in '/root/.local/bin' which is not on PATH.\r\nmaster-replica-0 Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\r\nmaster-replica-0 The scripts gunicorn and gunicorn_paster are installed in '/root/.local/bin' which is not on PATH.\r\n\r\nI  master-replica-0 Successfully built DummyUsrDirPackage master-replica-0 \r\nE  master-replica-0 gapic-google-cloud-logging-v2 0.91.3 has requirement google-gax<0.16dev,>=0.15.7, but you'll have google-gax 0.12.5 which is incompatible. master-replica-0 \r\nI  master-replica-0 Installing collected packages: DummyUsrDirPackage master-replica-0 \r\nI  master-replica-0   Found existing installation: DummyUsrDirPackage 0.1 master-replica-0 \r\nI  master-replica-0     Uninstalling DummyUsrDirPackage-0.1: master-replica-0 \r\nI  master-replica-0       Successfully uninstalled DummyUsrDirPackage-0.1 master-replica-0 \r\nI  master-replica-0 Successfully installed DummyUsrDirPackage-0.1 master-replica-0 \r\nI  master-replica-0 Running command: python -m tensor2tensor.bin.t2t_trainer --eval_steps 100 --cloud_tpu False --decode_hparams  --sync False --eval_run_autoregressive False --eval_use_test_set False --worker_id 0 --eval_early_stopping_metric_minimize True --worker_replicas 1 --agent_policy_path  --random_seed 1234 --worker_gpu_memory_fraction 0.95 --train_steps 7500 --cloud_tpu_name test-tpu --locally_shard_to_cpu False --iterations_per_loop 100 --registry_help False --worker_gpu 1 --keep_checkpoint_max 20 --save_checkpoints_secs 0 --gpu_order  --master  --generate_data False --intra_op_parallelism_threads 0 --enable_graph_rewriter False --eval_early_stopping_metric loss --autoencoder_path  --output_dir gs://test_t2t/poetry/model --profile False --ps_job /job:ps --tmp_dir /tmp/t2t_datagen --schedule continuous_train_and_eval --inter_op_parallelism_threads 0 --hparams  --use_tpu False --eval_early_stopping_metric_delta 0.1 --ps_gpu 0 --tfdbg False --local_eval_frequency 1000 --data_dir gs://test_t2t/poetry/subset --ps_replicas 0 --export_saved_model False --problem poetry_line_problem --log_device_placement False --hparams_set transformer_poetry --dbgprofile False --timit_paths  --cloud_skip_confirmation False --cloud_delete_on_done False --tpu_num_shards 8 --cloud_vm_name test-vm --parsing_path  --worker_job /job:localhost --model transformer --keep_checkpoint_every_n_hours 10000 --t2t_usr_dir t2t_usr_dir_internal --job-dir gs://test_t2t/poetry/model master-replica-0 \r\nI  master-replica-0 \r\nRegistry contents:\r\n------------------\r\n\r\n  Models:\r\n    aligned:\r\n      * aligned\r\n    attention:\r\n      * attention_lm\r\n      * attention_lm_moe\r\n    autoencoder:\r\n      * autoencoder_autoregressive\r\n      * autoencoder_basic_discrete\r\n      * autoencoder_ordered_discrete\r\n      * autoencoder_residual\r\n      * autoencoder_residual_discrete\r\n      * autoencoder_stacked\r\n    basic:\r\n      * basic_autoencoder\r\n      * basic_conv_gen\r\n      * basic_fc_relu\r\n    byte:\r\n      * byte_net\r\n    cycle:\r\n      * cycle_gan\r\n    diagonal:\r\n      * diagonal_neural_gpu\r\n    distillation:\r\n      * distillation\r\n    gene:\r\n      * gene_expression_conv\r\n    imagetransformer:\r\n      * imagetransformer\r\n    imagetransformer2d:\r\n      * imagetransformer2d\r\n    imagetransformer:\r\n      * imagetransformer_moe\r\n    img2img:\r\n      * img2img_transformer\r\n    lstm:\r\n      * lstm_encoder\r\n      * lstm_seq2seq\r\n      * lstm_seq2seq_attention\r\n      * lstm_seq2seq_attention_bidirectional_encoder\r\n      * lstm_seq2seq_bidirectional_encoder\r\n    multi:\r\n      * multi_model\r\n    neural:\r\n      * neural_gpu\r\n    r:\r\n      * r_transformer\r\n      * r_transformer_encoder\r\n    resnet:\r\n      * resnet\r\n    revnet:\r\n      * revnet\r\n    shake:\r\n      * shake_shake\r\n    slice:\r\n      * slice_net\r\n    super:\r\n      * super_lm\r\n    transformer:\r\n      * transformer\r\n      * transformer_ae\r\n      * transformer_encoder\r\n      * transformer_moe\r\n      * transformer_revnet\r\n      * transformer_scorer\r\n      * transformer_sketch\r\n      * transformer_symshard\r\n    vanilla:\r\n      * vanilla_gan\r\n    xception:\r\n      * xception\r\n\r\n  HParams:\r\n    afx:\r\n      * afx_adafactor\r\n      * afx_adam\r\n      * afx_base\r\n      * afx_clip\r\n      * afx_clip2\r\n      * afx_clip_factored\r\n      * afx_factored\r\n      * afx_fast\r\n      * afx_mimic_adam\r\n      * afx_pow05\r\n      * afx_pow08\r\n      * afx_pow08_clip\r\n      * afx_pow10\r\n      * afx_relative\r\n      * afx_small\r\n      * afx_small_bfloat16\r\n      * afx_small_p10\r\n      * afx_small_p11\r\n      * afx_small_p12\r\n      * afx_small_p16\r\n      * afx_small_p8\r\n      * afx_unscale\r\n      * afx_unscale_relative\r\n    aligned:\r\n      * aligned_8k\r\n      * aligned_8k_grouped\r\n      * aligned_base\r\n      * aligned_grouped\r\n      * aligned_local\r\n      * aligned_local_1k\r\n      * aligned_local_expert\r\n      * aligned_lsh\r\n      * aligned_memory_efficient\r\n      * aligned_moe\r\n      * aligned_no_att\r\n      * aligned_no_timing\r\n      * aligned_pos_emb\r\n      * aligned_pseudolocal\r\n      * aligned_pseudolocal_256\r\n    atari:\r\n      * atari_base\r\n    attention:\r\n      * attention_lm_11k\r\n      * attention_lm_12k\r\n      * attention_lm_16k\r\n      * attention_lm_ae_extended\r\n      * attention_lm_attention_moe_tiny\r\n      * attention_lm_base\r\n      * attention_lm_hybrid_v2\r\n      * attention_lm_moe_24b_diet\r\n      * attention_lm_moe_32b_diet\r\n      * attention_lm_moe_base\r\n      * attention_lm_moe_base_ae\r\n      * attention_lm_moe_base_hybrid\r\n      * attention_lm_moe_base_local\r\n      * attention_lm_moe_base_long_seq\r\n      * attention_lm_moe_base_memeff\r\n      * attention_lm_moe_large\r\n      * attention_lm_moe_large_diet\r\n      * attention_lm_moe_memory_efficient\r\n      * attention_lm_moe_small\r\n      * attention_lm_moe_tiny\r\n      * attention_lm_moe_translation\r\n      * attention_lm_moe_unscramble_base\r\n      * attention_lm_no_moe_small\r\n      * attention_lm_small\r\n      * attention_lm_translation\r\n      * attention_lm_translation_full_attention\r\n      * attention_lm_translation_l12\r\n    autoencoder:\r\n      * autoencoder_autoregressive\r\n      * autoencoder_basic_discrete\r\n      * autoencoder_discrete_pong\r\n      * autoencoder_ordered_discrete\r\n      * autoencoder_residual\r\n      * autoencoder_residual_discrete\r\n      * autoencoder_residual_discrete_big\r\n      * autoencoder_stacked\r\n    basic:\r\n      * basic_1\r\n      * basic_autoencoder\r\n      * basic_conv\r\n      * basic_conv_l1\r\n      * basic_conv_l2\r\n      * basic_conv_small\r\n      * basic_fc_small\r\n    bytenet:\r\n      * bytenet_base\r\n    continuous:\r\n      * continuous_action_base\r\n    cycle:\r\n      * cycle_gan_small\r\n    discrete:\r\n      * discrete_action_base\r\n    distill:\r\n      * distill_resnet_32_to_15_cifar20x5\r\n    gene:\r\n      * gene_expression_conv_base\r\n    image:\r\n      * image_transformer2d_base\r\n      * image_transformer_base\r\n    imagetransformer1d:\r\n      * imagetransformer1d_base_12l_64by64\r\n      * imagetransformer1d_base_8l_64by64\r\n    imagetransformer2d:\r\n      * imagetransformer2d_base\r\n      * imagetransformer2d_base_12l_8_16_big\r\n      * imagetransformer2d_base_12l_8_64_64by64\r\n      * imagetransformer2d_base_14l_8_16_big\r\n      * imagetransformer2d_base_14l_8_16_big_uncond\r\n      * imagetransformer2d_base_8l_8_16\r\n      * imagetransformer2d_base_8l_8_16_big\r\n      * imagetransformer2d_base_8l_8_16_big_16k\r\n      * imagetransformer2d_base_8l_8_16_ls\r\n      * imagetransformer2d_base_8l_8_32_big\r\n      * imagetransformer2d_base_8l_8_64_64by64\r\n      * imagetransformer2d_tiny\r\n    imagetransformer:\r\n      * imagetransformer_ae_cifar\r\n      * imagetransformer_b10l_4h_big_uncond_dr01_tpu\r\n      * imagetransformer_b10l_4h_big_uncond_dr03_lr025_tpu\r\n      * imagetransformer_b10l_4h_big_uncond_dr03_lr05_tpu\r\n      * imagetransformer_b10l_4h_big_uncond_dr03_tpu\r\n      * imagetransformer_b10l_dr03_moe_tpu\r\n      * imagetransformer_b12l_4h_b128_h512_uncond_dr03_im\r\n      * imagetransformer_b12l_4h_b128_h512_uncond_dr03_tpu\r\n      * imagetransformer_b12l_4h_b128_uncond_dr03_tpu\r\n      * imagetransformer_b12l_4h_b256_uncond_dr03_lr025_tpu\r\n      * imagetransformer_b12l_4h_b256_uncond_dr03_tpu\r\n      * imagetransformer_b12l_4h_big_uncond_dr03_lr025_tpu\r\n      * imagetransformer_b12l_4h_big_uncond_dr03_tpu\r\n      * imagetransformer_b12l_4h_small_uncond_dr03_tpu\r\n      * imagetransformer_b12l_8h_b256_uncond_dr03_tpu\r\n      * imagetransformer_bas8l_8h_big_uncond_dr03_imgnet\r\n      * imagetransformer_base\r\n      * imagetransformer_base_10l_16h_big_dr01_imgnet\r\n      * imagetransformer_base_10l_16h_big_dr01_moe_imgnet\r\n      * imagetransformer_base_10l_16h_big_uncond_dr01_imgnet\r\n      * imagetransformer_base_10l_8h_big_cond_dr03_dan\r\n      * imagetransformer_base_10l_8h_big_uncond_dr03_dan\r\n      * imagetransformer_base_10l_8h_big_uncond_dr03_dan_64\r\n      * imagetransformer_base_10l_8h_big_uncond_dr03_dan_64_2d\r\n      * imagetransformer_base_12l_8h_big\r\n      * imagetransformer_base_12l_8h_big_uncond\r\n      * imagetransformer_base_14l_8h_big\r\n      * imagetransformer_base_14l_8h_big_dr01\r\n      * imagetransformer_base_14l_8h_big_uncond\r\n      * imagetransformer_base_14l_8h_big_uncond_dr01\r\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan\r\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_128\r\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated\r\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated_b\r\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated_c\r\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated_d\r\n      * imagetransformer_base_tpu\r\n      * imagetransformer_moe_tiny\r\n      * imagetransformer_sep_channels\r\n      * imagetransformer_sep_channels_10l_8h\r\n      * imagetransformer_sep_channels_12l_16h_imagenet_large\r\n      * imagetransformer_sep_channels_12l_8h\r\n      * imagetransformer_sep_channels_12l_8h_4k\r\n      * imagetransformer_sep_channels_12l_8h_nda\r\n      * imagetransformer_sep_channels_12l_8h_sep_rgb\r\n      * imagetransformer_sep_channels_16l_16h_imgnet_lrg_loc\r\n      * imagetransformer_sep_channels_16l_16h_imgnet_lrg_loc_128\r\n      * imagetransformer_sep_channels_8l\r\n      * imagetransformer_sep_channels_8l_8h\r\n      * imagetransformer_sep_channels_8l_8h_local_and_global_att\r\n      * imagetransformer_sep_channels_8l_glu_ffn\r\n      * imagetransformer_sep_channels_8l_multipos3\r\n      * imagetransformer_sep_channels_8l_self_att_ffn\r\n      * imagetransformer_sep_channels_8l_tpu\r\n      * imagetransformer_sep_output_channels_8l\r\n      * imagetransformer_sep_output_channels_8l_local_and_global_att\r\n      * imagetransformer_tiny\r\n      * imagetransformer_tiny_tpu\r\n    img2img:\r\n      * img2img_transformer2d_base\r\n      * img2img_transformer2d_n103\r\n      * img2img_transformer2d_n24\r\n      * img2img_transformer2d_n3\r\n      * img2img_transformer2d_n31\r\n      * img2img_transformer2d_n44\r\n      * img2img_transformer2d_q1\r\n      * img2img_transformer2d_q2\r\n      * img2img_transformer2d_q3\r\n      * img2img_transformer2d_tiny\r\n      * img2img_transformer_b1\r\n      * img2img_transformer_b2\r\n      * img2img_transformer_b3\r\n      * img2img_transformer_base\r\n      * img2img_transformer_base_tpu\r\n      * img2img_transformer_dilated\r\n      * img2img_transformer_tiny\r\n      * img2img_transformer_tiny_tpu\r\n    lmx:\r\n      * lmx_base\r\n      * lmx_h1k_f4k\r\n      * lmx_h1k_f64k\r\n      * lmx_h2k_f8k\r\n      * lmx_h3k_f12k\r\n      * lmx_h4k_f16k\r\n      * lmx_moe\r\n      * lmx_moe_h1k_f4k_x32\r\n      * lmx_moe_h1k_f8k_x16\r\n      * lmx_relative\r\n      * lmx_relative_nopos\r\n    lstm:\r\n      * lstm_asr_v1\r\n      * lstm_attention\r\n      * lstm_bahdanau_attention\r\n      * lstm_bahdanau_attention_multi\r\n      * lstm_luong_attention\r\n      * lstm_luong_attention_multi\r\n      * lstm_seq2seq\r\n    multimodel:\r\n      * multimodel_base\r\n      * multimodel_tiny\r\n    neural:\r\n      * neural_gpu\r\n    ppo:\r\n      * ppo_base_v1\r\n    r:\r\n      * r_mix_transformer_act_step_position_random_timing_base\r\n      * r_mix_transformer_act_step_position_timing_base\r\n      * r_mix_transformer_base\r\n      * r_transformer_act_accumulated_base\r\n      * r_transformer_act_accumulated_tiny\r\n      * r_transformer_act_base\r\n      * r_transformer_act_base_d03\r\n      * r_transformer_act_base_sb\r\n      * r_transformer_act_big\r\n      * r_transformer_act_big_d03\r\n      * r_transformer_act_global_base\r\n      * r_transformer_act_global_tiny\r\n      * r_transformer_act_large\r\n      * r_transformer_act_position_random_timing_tiny\r\n      * r_transformer_act_position_step_timing_tiny\r\n      * r_transformer_act_position_timing_tiny\r\n      * r_transformer_act_random_base\r\n      * r_transformer_act_random_tiny\r\n      * r_transformer_act_step_position_random_timing_base\r\n      * r_transformer_act_step_position_random_timing_tiny\r\n      * r_transformer_act_step_position_timing_base\r\n      * r_transformer_act_step_position_timing_tiny\r\n      * r_transformer_act_step_sinusoid_position_random_timing_tiny\r\n      * r_transformer_act_step_sinusoid_position_timing_tiny\r\n      * r_transformer_act_step_timing_tiny\r\n      * r_transformer_act_tall\r\n      * r_transformer_act_tall_actlossw0\r\n      * r_transformer_act_tall_actlossw001\r\n      * r_transformer_act_tiny\r\n      * r_transformer_act_tiny_d02\r\n      * r_transformer_act_tiny_d02_sb\r\n      * r_transformer_act_tiny_d05\r\n      * r_transformer_act_tiny_sb\r\n      * r_transformer_base\r\n      * r_transformer_base_dropconnect\r\n      * r_transformer_base_sb\r\n      * r_transformer_big\r\n      * r_transformer_dwa_base\r\n      * r_transformer_dwa_tiny\r\n      * r_transformer_dwa_tiny_test\r\n      * r_transformer_gru_base\r\n      * r_transformer_highway_base\r\n      * r_transformer_highway_tiny\r\n      * r_transformer_lstm_base\r\n      * r_transformer_position_random_timing_base\r\n      * r_transformer_position_random_timing_tiny\r\n      * r_transformer_position_step_timing_tiny\r\n      * r_transformer_position_timing_tiny\r\n      * r_transformer_rnn_base\r\n      * r_transformer_skip_base\r\n      * r_transformer_skip_tiny\r\n      * r_transformer_step_position_random_timing_tiny\r\n      * r_transformer_step_position_timing_base\r\n      * r_transformer_step_position_timing_tiny\r\n      * r_transformer_step_sinusoid_timing_tiny\r\n      * r_transformer_step_timing_tiny\r\n      * r_transformer_teeny\r\n      * r_transformer_tiny\r\n    resnet:\r\n      * resnet_101\r\n      * resnet_152\r\n      * resnet_18\r\n      * resnet_200\r\n      * resnet_34\r\n      * resnet_50\r\n      * resnet_cifar_15\r\n      * resnet_cifar_32\r\n      * resnet_imagenet_102\r\n      * resnet_imagenet_34\r\n    revnet:\r\n      * revnet_104\r\n      * revnet_110_cifar\r\n      * revnet_164_cifar\r\n      * revnet_38_cifar\r\n    shake:\r\n      * shake_shake_quick\r\n    shakeshake:\r\n      * shakeshake_big\r\n      * shakeshake_small\r\n      * shakeshake_tpu\r\n    slicenet:\r\n      * slicenet_1\r\n      * slicenet_1noam\r\n      * slicenet_1tiny\r\n    super:\r\n      * super_lm_b8k\r\n      * super_lm_base\r\n      * super_lm_big\r\n      * super_lm_big_tpu\r\n      * super_lm_conv\r\n      * super_lm_high_mix\r\n      * super_lm_low_mix\r\n      * super_lm_moe\r\n      * super_lm_moe_4b_diet\r\n      * super_lm_moe_h4\r\n      * super_lm_tpu\r\n      * super_lm_tpu_memtest\r\n    transformer:\r\n      * transformer_ae_a3\r\n      * transformer_ae_a6\r\n      * transformer_ae_a8\r\n      * transformer_ae_base\r\n      * transformer_ae_base_tpu\r\n      * transformer_ae_small\r\n      * transformer_base\r\n      * transformer_base_single_gpu\r\n      * transformer_base_sketch\r\n      * transformer_base_v1\r\n      * transformer_base_v2\r\n      * transformer_big\r\n      * transformer_big_dr1\r\n      * transformer_big_dr2\r\n      * transformer_big_enfr\r\n      * transformer_big_enfr_tpu\r\n      * transformer_big_single_gpu\r\n      * transformer_big_tpu\r\n      * transformer_clean\r\n      * transformer_clean_big\r\n      * transformer_clean_big_tpu\r\n      * transformer_dr0\r\n      * transformer_dr2\r\n      * transformer_ff1024\r\n      * transformer_ff4096\r\n      * transformer_h1\r\n      * transformer_h16\r\n      * transformer_h32\r\n      * transformer_h4\r\n      * transformer_hs1024\r\n      * transformer_hs256\r\n      * transformer_k128\r\n      * transformer_k256\r\n      * transformer_l10\r\n      * transformer_l2\r\n      * transformer_l4\r\n      * transformer_l8\r\n      * transformer_librispeech\r\n      * transformer_librispeech_tpu\r\n      * transformer_librispeech_tpu_v1\r\n      * transformer_librispeech_tpu_v2\r\n      * transformer_librispeech_v1\r\n      * transformer_librispeech_v2\r\n      * transformer_lm_tpu_0\r\n      * transformer_lm_tpu_1\r\n      * transformer_ls0\r\n      * transformer_ls2\r\n      * transformer_moe_12k\r\n      * transformer_moe_2k\r\n      * transformer_moe_8k\r\n      * transformer_moe_8k_lm\r\n      * transformer_moe_base\r\n      * transformer_moe_prepend_8k\r\n      * transformer_opt\r\n      * transformer_packed_tpu\r\n      * transformer_parameter_attention_a\r\n      * transformer_parameter_attention_b\r\n      * transformer_parsing_base\r\n      * transformer_parsing_big\r\n      * transformer_parsing_ice\r\n      * transformer_poetry\r\n      * transformer_prepend\r\n      * transformer_prepend_v1\r\n      * transformer_prepend_v2\r\n      * transformer_relative\r\n      * transformer_relative_big\r\n      * transformer_relative_tiny\r\n      * transformer_revnet_base\r\n      * transformer_revnet_big\r\n      * transformer_sketch\r\n      * transformer_sketch_2layer\r\n      * transformer_sketch_4layer\r\n      * transformer_sketch_6layer\r\n      * transformer_small\r\n      * transformer_small_sketch\r\n      * transformer_small_tpu\r\n      * transformer_supervised_attention\r\n      * transformer_symshard_base\r\n      * transformer_symshard_h4\r\n      * transformer_symshard_lm_0\r\n      * transformer_symshard_sh4\r\n      * transformer_teeny\r\n      * transformer_test\r\n      * transformer_tiny\r\n      * transformer_tiny_tpu\r\n      * transformer_tpu\r\n      * transformer_tpu_1b\r\n      * transformer_tpu_bf16_activation\r\n      * transformer_tpu_with_conv\r\n    vanilla:\r\n      * vanilla_gan\r\n    xception:\r\n      * xception_base\r\n      * xception_tiny\r\n      * xception_tiny_tpu\r\n\r\n  RangedHParams:\r\n    basic1:\r\n      * basic1\r\n    revnet:\r\n      * revnet_range\r\n    slicenet1:\r\n      * slicenet1\r\n    transformer:\r\n      * transformer_base_range\r\n      * transformer_poetry_range\r\n      * transformer_sketch_ranged\r\n      * transformer_tiny_tpu_range\r\n      * transformer_tpu_range\r\n\r\n  Modalities:\r\n    audio:audio:\r\n      * audio:audio_spectral_modality\r\n    audio:default:\r\n      * audio:default\r\n    audio:identity:\r\n      * audio:identity\r\n    audio:speech:\r\n      * audio:speech_recognition_modality\r\n    class:\r\n      * class_label:default\r\n      * class_label:identity\r\n      * class_label:sigmoid\r\n      * class_label:sigmoid_max_pooling\r\n    generic:default:\r\n      * generic:default\r\n    image:channel:\r\n      * image:channel_embeddings_bottom\r\n    image:default:\r\n      * image:default\r\n    image:identity:\r\n      * image:identity\r\n    image:image:\r\n      * image:image_channel_compress\r\n    real:default:\r\n      * real:default\r\n    real:identity:\r\n      * real:identity\r\n    real:l2:\r\n      * real:l2_loss\r\n    real:log:\r\n      * real:log_poisson_loss\r\n    symbol:ctc:\r\n      * symbol:ctc\r\n    symbol:default:\r\n      * symbol:default\r\n    symbol:identity:\r\n      * symbol:identity\r\n    video:default:\r\n      * video:default\r\n    video:identity:\r\n      * video:identity\r\n    video:l1:\r\n      * video:l1\r\n    video:l2:\r\n      * video:l2\r\n\r\n  Problems:\r\n    algorithmic:\r\n      * algorithmic_addition_binary40\r\n      * algorithmic_addition_decimal40\r\n      * algorithmic_cipher_shift200\r\n      * algorithmic_cipher_shift5\r\n      * algorithmic_cipher_vigenere200\r\n      * algorithmic_cipher_vigenere5\r\n      * algorithmic_identity_binary40\r\n      * algorithmic_identity_decimal40\r\n      * algorithmic_multiplication_binary40\r\n      * algorithmic_multiplication_decimal40\r\n      * algorithmic_reverse_binary40\r\n      * algorithmic_reverse_binary40_test\r\n      * algorithmic_reverse_decimal40\r\n      * algorithmic_reverse_nlplike32k\r\n      * algorithmic_reverse_nlplike8k\r\n      * algorithmic_shift_decimal40\r\n    audio:\r\n      * audio_timit_characters_tune\r\n      * audio_timit_tokens8k_test\r\n      * audio_timit_tokens8k_tune\r\n    genomics:\r\n      * genomics_expression_cage10\r\n      * genomics_expression_gm12878\r\n      * genomics_expression_l262k\r\n    gym:\r\n      * gym_discrete_problem_with_agent_on_freeway\r\n      * gym_discrete_problem_with_agent_on_pong\r\n      * gym_freeway_random50k\r\n      * gym_freeway_random5k\r\n      * gym_pong_random50k\r\n      * gym_pong_random5k\r\n      * gym_simulated_discrete_problem_with_agent\r\n      * gym_simulated_discrete_problem_with_agent_on_freeway\r\n      * gym_simulated_discrete_problem_with_agent_on_pong\r\n    image:\r\n      * image_celeba\r\n      * image_celeba_multi_resolution\r\n      * image_cifar10\r\n      * image_cifar100\r\n      * image_cifar100_plain\r\n      * image_cifar100_plain8\r\n      * image_cifar100_plain_gen\r\n      * image_cifar100_tune\r\n      * image_cifar10_plain\r\n      * image_cifar10_plain8\r\n      * image_cifar10_plain_gen\r\n      * image_cifar10_tune\r\n      * image_cifar20\r\n      * image_cifar20_plain\r\n      * image_cifar20_plain8\r\n      * image_cifar20_plain_gen\r\n      * image_cifar20_tune\r\n      * image_fashion_mnist\r\n      * image_fsns\r\n      * image_imagenet\r\n      * image_imagenet224\r\n      * image_imagenet32\r\n      * image_imagenet32_small\r\n      * image_imagenet64\r\n      * image_imagenet64_gen\r\n      * image_imagenet_multi_resolution_gen\r\n      * image_mnist\r\n      * image_mnist_tune\r\n      * image_ms_coco_characters\r\n      * image_ms_coco_tokens32k\r\n      * image_text_ms_coco\r\n      * image_text_ms_coco_multi_resolution\r\n    img2img:\r\n      * img2img_celeba\r\n      * img2img_celeba64\r\n      * img2img_cifar10\r\n      * img2img_cifar100\r\n      * img2img_imagenet\r\n    lambada:\r\n      * lambada_lm\r\n      * lambada_lm_control\r\n      * lambada_rc\r\n      * lambada_rc_control\r\n    languagemodel:\r\n      * languagemodel_lm1b32k\r\n      * languagemodel_lm1b32k_packed\r\n      * languagemodel_lm1b8k_packed\r\n      * languagemodel_lm1b_characters\r\n      * languagemodel_lm1b_characters_packed\r\n      * languagemodel_ptb10k\r\n      * languagemodel_ptb_characters\r\n      * languagemodel_wiki_noref_v128k_l1k\r\n      * languagemodel_wiki_noref_v32k_l1k\r\n      * languagemodel_wiki_noref_v8k_l16k\r\n      * languagemodel_wiki_noref_v8k_l1k\r\n      * languagemodel_wiki_scramble_l128\r\n      * languagemodel_wiki_scramble_l1k\r\n      * languagemodel_wiki_xml_v8k_l1k\r\n      * languagemodel_wiki_xml_v8k_l4k\r\n      * languagemodel_wikitext103\r\n      * languagemodel_wikitext103_characters\r\n    librispeech:\r\n      * librispeech\r\n      * librispeech_clean\r\n      * librispeech_clean_small\r\n      * librispeech_noisy\r\n      * librispeech_train_full_test_clean\r\n    multinli:\r\n      * multinli_matched\r\n      * multinli_mismatched\r\n    ocr:\r\n      * ocr_test\r\n    parsing:\r\n      * parsing_english_ptb16k\r\n      * parsing_english_ptb8k\r\n      * parsing_icelandic16k\r\n    poetry:\r\n      * poetry_line_problem\r\n    programming:\r\n      * programming_desc2code_cpp\r\n      * programming_desc2code_py\r\n    sentiment:\r\n      * sentiment_imdb\r\n    squad:\r\n      * squad\r\n      * squad_concat\r\n      * squad_concat_positioned\r\n    summarize:\r\n      * summarize_cnn_dailymail32k\r\n    sva:\r\n      * sva_language_modeling\r\n      * sva_number_prediction\r\n    text2text:\r\n      * text2text_tmpdir\r\n    translate:\r\n      * translate_encs_wmt32k\r\n      * translate_encs_wmt_characters\r\n      * translate_ende_wmt32k\r\n      * translate_ende_wmt32k_packed\r\n      * translate_ende_wmt8k\r\n      * translate_ende_wmt8k_packed\r\n      * translate_ende_wmt_bpe32k\r\n      * translate_ende_wmt_characters\r\n      * translate_enet_wmt32k\r\n      * translate_enet_wmt_characters\r\n      * translate_enfr_wmt32k\r\n      * translate_enfr_wmt32k_packed\r\n      * translate_enfr_wmt8k\r\n      * translate_enfr_wmt_characters\r\n      * translate_enfr_wmt_small32k\r\n      * translate_enfr_wmt_small8k\r\n      * translate_enfr_wmt_small_characters\r\n      * translate_enmk_setimes32k\r\n      * translate_enmk_setimes_characters\r\n      * translate_envi_iwslt32k\r\n      * translate_enzh_wmt32k\r\n      * translate_enzh_wmt8k\r\n    video:\r\n      * video_twentybn\r\n    wikisum:\r\n      * wikisum_commoncrawl\r\n      * wikisum_commoncrawl_lead_section\r\n      * wikisum_web\r\n      * wikisum_web_lead_section\r\n   master-replica-0 \r\nI  master-replica-0 Module completed; cleaning up. master-replica-0 \r\nI  master-replica-0 Clean up finished. master-replica-0 \r\nI  master-replica-0 Task completed successfully. master-replica-0 \r\nI  Job completed successfully. \r\n```", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/792/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/792/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/757", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/757/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/757/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/757/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/757", "id": 318830241, "node_id": "MDU6SXNzdWUzMTg4MzAyNDE=", "number": 757, "title": "Tracking bug for issues in Wikisum", "user": {"login": "f-lng", "id": 26275863, "node_id": "MDQ6VXNlcjI2Mjc1ODYz", "avatar_url": "https://avatars.githubusercontent.com/u/26275863?v=4", "gravatar_id": "", "url": "https://api.github.com/users/f-lng", "html_url": "https://github.com/f-lng", "followers_url": "https://api.github.com/users/f-lng/followers", "following_url": "https://api.github.com/users/f-lng/following{/other_user}", "gists_url": "https://api.github.com/users/f-lng/gists{/gist_id}", "starred_url": "https://api.github.com/users/f-lng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/f-lng/subscriptions", "organizations_url": "https://api.github.com/users/f-lng/orgs", "repos_url": "https://api.github.com/users/f-lng/repos", "events_url": "https://api.github.com/users/f-lng/events{/privacy}", "received_events_url": "https://api.github.com/users/f-lng/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2018-04-30T09:24:06Z", "updated_at": "2018-05-24T20:54:24Z", "closed_at": "2018-05-24T20:54:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nI can currently not sign the Contributor License Agreement, so I will not do a pull request, sorry about this.\r\n\r\nIf you are unable to process any of these patches without a pull-request, I will make one at the end of the week. But for the sake of getting these notes out as soon as possible, for now, this is all I can offer.  \r\n\r\n## Notes on shell commands\r\n(https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/wikisum#commands-to-generate-wikisumweb)\r\n\r\n* Command \"python -m tensor2tensor.data_generators.wikisum.parallel_launch\" needs to go without '.py'\r\n\r\n* --command_prefix can't find the scripts, needs to do a cd first (will break --code_dir feature, but this seems to have no effect on the other commands anyway, as they directly call the python module)\r\n`--command_prefix=\"cd ~/.local/lib/python3.5/site-packages/tensor2tensor/data_generators/ ; python3 -m tensor2tensor.data_generators.wikisum.get_references_web --out_dir={{BUCKET}}/wiki_references --shard_id\"`\r\n\r\n* If \"Cloud Storage JSON API\" is not enabled yet in the gcloud account, it will fail silently on the cloud worker. Should be checked in parallel_launch.py first\r\n\r\n* Vocab-generation on Python3 throws an re exception\r\n>        File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/data_generators/wikisum/wikisum.py\", line 361, in _normalize_text\r\n>         text = re.sub(\"[%s]\" % re.escape(string.punctuation), r\" \\g<0> \", text)\r\n>       File \"/usr/lib/python3.5/re.py\", line 182, in sub\r\n>         return _compile(pattern, flags).sub(repl, string, count)\r\n>     TypeError: cannot use a string pattern on a bytes-like object\r\n\r\n\r\n* Vocab-generation does not work on windows, as it can not access gs:// files, so it should be done in the cloud as well (explitictly using python2 to work around the re exception mentioned above)\r\n```\r\npython2 -m tensor2tensor.data_generators.wikisum.parallel_launch \\\r\n  --num_instances=1 \\\r\n  --cpu=4 --mem=16 \\\r\n  --name=wikisum-vocab-gen \\  \r\n  --setup_command=\"pip install tensor2tensor tensorflow -U -q --user\" \\\r\n  --command_prefix=\"python2 -m tensor2tensor.data_generators.wikisum.generate_vocab  --out_dir=$BUCKET/data  --refs_dir=$BUCKET/wiki_references ; echo Done shard\r\n```\r\n\r\n## Changes for parallel_launch.py\r\n\r\nHere is the full parallel_launch.py file https://pastebin.com/UUDjA9jL \r\n\r\nBelow are the changes I made:\r\n\r\nhttps://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/wikisum/parallel_launch.py#L46 - Cleaning output\r\n\r\n```\r\n#FIX prevent a ton of future warnings from h5py\r\nimport warnings\r\nwarnings.simplefilter(action='ignore', category=FutureWarning)\r\n```\r\n\r\nhttps://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/wikisum/parallel_launch.py#L88 - Some changes to the shell commands\r\n\r\n```\r\n#FIX added username 'wsumuser', otherwise got an error as my windows-username is root\r\nCOPY_CODE = \"gcloud compute scp --recurse {local_dir} wsumuser@{instance_name}:~/\"\r\nSSH = \"gcloud compute ssh wsumuser@{instance_name} --command\"\r\nDEFAULT_ZONE = \"gcloud config get-value compute/zone\"\r\n#FIX use screens logging functionality to get rid of escaping problems for window's popen and to get more log coverage\r\nSCREEN = \"screen -L ~/logs-XXX.txt -dmS test bash -c \\\"{command}\\\"\"\r\n#FIX no need for piping anymore, using screen -L\r\nLOGS = \"; gsutil cp ~/logs-XXX.txt {bucket}logs-{task_id}.txt\"\r\n```\r\n\r\nhttps://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/wikisum/parallel_launch.py#L105 - Find gcloud on windows\r\n\r\n```\r\n     #FIX try to find gcloud on windows\r\n      try:\r\n        return sp.check_call(args)\r\n      except FileNotFoundError:\r\n        if args[0] == \"gcloud\": args[0] = os.getenv('LOCALAPPDATA') + \"/Google/Cloud SDK/google-cloud-sdk/bin/gcloud.cmd\"\r\n        return sp.check_call(args)\r\n```\r\n\r\nhttps://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/wikisum/parallel_launch.py#L115 - Use python instead of netcat to wait for SSH \r\n\r\n```\r\ndef wait_for_ssh(ip):\r\n  \"\"\"Wait for SSH to be available at given IP address.\"\"\"\r\n  # FIX don't use netcat, but python to test for open SSH port\r\n  import socket\r\n  for i in range(12):\r\n    s = socket.socket()\r\n    s.settimeout(2)\r\n\r\n    try:\r\n      s.connect((ip, 22))\r\n      s.close()\r\n      return True\r\n    except:\r\n      s.close()\r\n    time.sleep(10)\r\n  return False\r\n```\r\n\r\nhttps://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/wikisum/parallel_launch.py#L209 - Python3 compatibility\r\n`  vm_names = list(zip(*vm_info))[0] if vm_info else [] #FIX: make a list from zip()-iterator first`\r\n\r\nhttps://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/wikisum/parallel_launch.py#L216 - Log-Dir handling on windows\r\n\r\n```\r\n    #FIX window's \\ leads to an error on the cloud-server afterwards\r\n    log_dir = log_dir.replace(\"\\\\\",\"/\")\r\n\r\n    #FIX on windows there is no gs:// , so give the user the opportunity to create the directories\r\n    from tensorflow.python.framework.errors_impl import UnimplementedError\r\n    try:\r\n      tf.gfile.MakeDirs(log_dir)\r\n    except UnimplementedError:\r\n      input(\"[!] Use http://console.cloud.google.com and manually create '\" + log_dir + \"', then press return.................\")\r\n```\r\n\r\n\r\nhttps://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/wikisum/parallel_launch.py#L251 - Don't fail silently (the zip-exception, for example, was silenced)\r\n```\r\n\r\n    # FIX Don't fail silently\r\n    except Exception as e:  # pylint: disable=bare-except\r\n      failed.append(i)\r\n      tf.logging.error(\"Failed to launch task %d due to exception %s\", i, str(e))\r\n```\r\n\r\n### Changes for cloud_tpu.py\r\n\r\nhttps://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/cloud_tpu.py#L229 - Find gcloud on windows\r\n\r\n```\r\ndef shell_output(cmd_, **kwargs):\r\n  try:\r\n    return text_encoder.to_unicode(sp.check_output(format_cmd(cmd_, **kwargs)))\r\n  except FileNotFoundError:\r\n    return text_encoder.to_unicode(sp.check_output(format_cmd_win(cmd_, **kwargs)))\r\n\r\ndef shell_run(cmd_, **kwargs):\r\n  try:\r\n    return sp.check_call(format_cmd(cmd_, **kwargs))\r\n  except FileNotFoundError:\r\n    return sp.check_call(format_cmd_win(cmd_, **kwargs))\r\n\r\ndef format_cmd_win(cmd_, **kwargs):\r\n  ret = cmd_.format(**kwargs).strip().split()\r\n  if ret[0] == \"gcloud\": ret[0] = os.getenv('LOCALAPPDATA') + \"/Google/Cloud SDK/google-cloud-sdk/bin/gcloud.cmd\"\r\n  elif ret[0] == \"gsutil\": ret[0] = os.getenv('LOCALAPPDATA') + \"/Google/Cloud SDK/google-cloud-sdk/bin/gsutil.cmd\"\r\n  return ret\r\n```\r\n\r\n### *TensorFlow* and *tensor2tensor* versions\r\n\r\ntensor2tensor 1.6.1\r\ntensorflow-gpu 1.7.0\r\n", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/757/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/757/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/726", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/726/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/726/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/726/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/726", "id": 315430826, "node_id": "MDU6SXNzdWUzMTU0MzA4MjY=", "number": 726, "title": "TypeError: a bytes-like object is required, not 'str'", "user": {"login": "onchiptech", "id": 31723717, "node_id": "MDQ6VXNlcjMxNzIzNzE3", "avatar_url": "https://avatars.githubusercontent.com/u/31723717?v=4", "gravatar_id": "", "url": "https://api.github.com/users/onchiptech", "html_url": "https://github.com/onchiptech", "followers_url": "https://api.github.com/users/onchiptech/followers", "following_url": "https://api.github.com/users/onchiptech/following{/other_user}", "gists_url": "https://api.github.com/users/onchiptech/gists{/gist_id}", "starred_url": "https://api.github.com/users/onchiptech/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/onchiptech/subscriptions", "organizations_url": "https://api.github.com/users/onchiptech/orgs", "repos_url": "https://api.github.com/users/onchiptech/repos", "events_url": "https://api.github.com/users/onchiptech/events{/privacy}", "received_events_url": "https://api.github.com/users/onchiptech/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-04-18T10:56:29Z", "updated_at": "2018-05-24T01:10:09Z", "closed_at": "2018-05-24T01:10:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am getting the following error when I run t2t-trainer with --cloud_tpu option  \r\n------------------------------------------\r\nvm_info = list_vm_names_and_ips()\r\n  File \"/home/gmail/anaconda3/lib/python3.6/site-packages/tensor2tensor/utils/cloud_tpu.py\", line 252, in list_vm_n\r\names_and_ips\r\n    lines = [l.split() for l in list_out.split(\"\\n\")[1:-1]]\r\nTypeError: a bytes-like object is required, not 'str'\r\n---------------------------------------------", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/726/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/726/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/688", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/688/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/688/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/688/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/688", "id": 312146604, "node_id": "MDU6SXNzdWUzMTIxNDY2MDQ=", "number": 688, "title": "*bug* Learning rate gets misreported to logging", "user": {"login": "cbockman", "id": 4667922, "node_id": "MDQ6VXNlcjQ2Njc5MjI=", "avatar_url": "https://avatars.githubusercontent.com/u/4667922?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cbockman", "html_url": "https://github.com/cbockman", "followers_url": "https://api.github.com/users/cbockman/followers", "following_url": "https://api.github.com/users/cbockman/following{/other_user}", "gists_url": "https://api.github.com/users/cbockman/gists{/gist_id}", "starred_url": "https://api.github.com/users/cbockman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cbockman/subscriptions", "organizations_url": "https://api.github.com/users/cbockman/orgs", "repos_url": "https://api.github.com/users/cbockman/repos", "events_url": "https://api.github.com/users/cbockman/events{/privacy}", "received_events_url": "https://api.github.com/users/cbockman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-04-06T23:18:14Z", "updated_at": "2018-05-19T02:01:38Z", "closed_at": "2018-05-19T01:23:30Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\nFor non-legacy hparams.learning_rate_schedule, I believe learning rate is reported misleadingly:\r\n\r\nhttps://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/t2t_model.py#L394\r\n\r\nself.hparams.learning_rate is reported, whereas hparams.learning_rate_constant would seem more appropriate:\r\n\r\nhttps://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/learning_rate.py#L30\r\n\r\nEasy fix; happy to issue PR if I haven't misinterpreted things.\r\n\r\n### *TensorFlow* and *tensor2tensor* versions\r\n\r\nt2t master\r\n", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/688/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/688/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/671", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/671/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/671/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/671/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/671", "id": 309598997, "node_id": "MDU6SXNzdWUzMDk1OTg5OTc=", "number": 671, "title": "Incorrect metrics or bad decodding or both?", "user": {"login": "nimasnjb", "id": 24842548, "node_id": "MDQ6VXNlcjI0ODQyNTQ4", "avatar_url": "https://avatars.githubusercontent.com/u/24842548?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nimasnjb", "html_url": "https://github.com/nimasnjb", "followers_url": "https://api.github.com/users/nimasnjb/followers", "following_url": "https://api.github.com/users/nimasnjb/following{/other_user}", "gists_url": "https://api.github.com/users/nimasnjb/gists{/gist_id}", "starred_url": "https://api.github.com/users/nimasnjb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nimasnjb/subscriptions", "organizations_url": "https://api.github.com/users/nimasnjb/orgs", "repos_url": "https://api.github.com/users/nimasnjb/repos", "events_url": "https://api.github.com/users/nimasnjb/events{/privacy}", "received_events_url": "https://api.github.com/users/nimasnjb/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2018-03-29T02:44:43Z", "updated_at": "2018-05-04T02:32:23Z", "closed_at": "2018-05-04T02:32:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- **Note** Please tag your issue with *bug*, *feature request* or *help* -->\r\nIn *text2text problems*:\r\nI have the last versions of tensorflow and tensor2tensor as 28th of March. I had a problem with the previous version like 1.4. I knew there is something wrong with the metrics like *ROUGE*.\r\n\r\nIn *CNN-Dailymail* problem:\r\nI got extraordinary high scores for rouge, like 0.95. Accuracy is above 65% and loss is under 0.35. It must be a master-model. I give it a test-set to decode. The decoded text and the input are almost identical. there might be just 25% difference in lengths. I don't understand why I got those brilliant metrics for this output.\r\nSo far we might say the decoder is generating bad outputs and metrics are correct.\r\n\r\nIn line_poetry_problem:\r\nI used a dataset that contains duplicated instances. The metric for *accuracy_per_sequence* must relatively high, but it is zero! When I remove the duplicates and train the model with the new dataset, the accuracy_per_sequence rise with a good slop to 6%!!\r\n\r\nThese two observations (from poetry problem) suggest that the metrics are incorrect. I don't understand why the quality of decoded outputs is not consistent with the model metrics. The poetry model gives me a long string of a duplicated words as output, while the model shows great metrics in the evaluation.\r\n\r\nHave anyone got good results from CNN-Dailymail problem? \r\n### *TensorFlow* and *tensor2tensor* versions\r\n1.6, 1.5.5", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/671/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/671/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/548", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/548/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/548/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/548/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/548", "id": 292912837, "node_id": "MDU6SXNzdWUyOTI5MTI4Mzc=", "number": 548, "title": "ImportError: cannot import name spaces with python 2.7, TF 1.5", "user": {"login": "dchichkov", "id": 369017, "node_id": "MDQ6VXNlcjM2OTAxNw==", "avatar_url": "https://avatars.githubusercontent.com/u/369017?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dchichkov", "html_url": "https://github.com/dchichkov", "followers_url": "https://api.github.com/users/dchichkov/followers", "following_url": "https://api.github.com/users/dchichkov/following{/other_user}", "gists_url": "https://api.github.com/users/dchichkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dchichkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dchichkov/subscriptions", "organizations_url": "https://api.github.com/users/dchichkov/orgs", "repos_url": "https://api.github.com/users/dchichkov/repos", "events_url": "https://api.github.com/users/dchichkov/events{/privacy}", "received_events_url": "https://api.github.com/users/dchichkov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-30T19:44:16Z", "updated_at": "2018-02-09T00:50:46Z", "closed_at": "2018-02-09T00:50:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "In the https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb  with current pip distribution following code:\r\n\r\n\r\n```\r\n!pip install -q 'tensor2tensor==1.4.1' 'tensorflow==1.5.0rc0'\r\nfrom tensor2tensor import problems\r\n\r\n```\r\n\r\n\r\nProduces:\r\n```\r\nImportErrorTraceback (most recent call last)\r\n<ipython-input-2-03b51d1582cc> in <module>()\r\n      6 \r\n      7 from tensor2tensor import models\r\n----> 8 from tensor2tensor import problems\r\n      9 from tensor2tensor.layers import common_layers\r\n     10 from tensor2tensor.tpu import tpu_trainer_lib\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensor2tensor/problems.py in <module>()\r\n     25 # Dependency imports\r\n     26 \r\n---> 27 from tensor2tensor.data_generators import all_problems  # pylint: disable=unused-import\r\n     28 from tensor2tensor.utils import registry\r\n     29 \r\n\r\n/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/all_problems.py in <module>()\r\n     26 from tensor2tensor.data_generators import cnn_dailymail\r\n     27 from tensor2tensor.data_generators import desc2code\r\n---> 28 from tensor2tensor.data_generators import gym\r\n     29 from tensor2tensor.data_generators import ice_parsing\r\n     30 from tensor2tensor.data_generators import image\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/gym.py in <module>()\r\n     24 # Dependency imports\r\n     25 \r\n---> 26 import gym\r\n     27 \r\n     28 from tensor2tensor.data_generators import generator_utils\r\n\r\n/usr/local/lib/python2.7/dist-packages/gym/__init__.pyc in <module>()\r\n     10 from gym.core import Env, Space, Wrapper, ObservationWrapper, ActionWrapper, RewardWrapper\r\n     11 from gym.envs import make, spec\r\n---> 12 from gym import wrappers, spaces, logger\r\n     13 \r\n     14 def undo_logger_setup():\r\n\r\n/usr/local/lib/python2.7/dist-packages/gym/spaces/__init__.py in <module>()\r\n----> 1 from gym.spaces.box import Box\r\n      2 from gym.spaces.discrete import Discrete\r\n      3 from gym.spaces.multi_discrete import MultiDiscrete\r\n      4 from gym.spaces.multi_binary import MultiBinary\r\n      5 from gym.spaces.prng import seed, np_random\r\n\r\n/usr/local/lib/python2.7/dist-packages/gym/spaces/box.py in <module>()\r\n      1 import numpy as np\r\n----> 2 from gym import Space, spaces, logger\r\n      3 \r\n      4 class Box(Space):\r\n      5     \"\"\"\r\n\r\nImportError: cannot import name spaces\r\n\r\n---------------------------------------------------------------------------\r\nNOTE: If your import is failing due to a missing package, you can\r\nmanually install dependencies using either !pip or !apt.\r\n\r\nTo view examples of installing some common dependencies, click the\r\n\"Open Examples\" button below.\r\n---------------------------------------------------------------------------\r\n\r\n```", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/548/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/548/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/543", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/543/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/543/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/543/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/543", "id": 292113783, "node_id": "MDU6SXNzdWUyOTIxMTM3ODM=", "number": 543, "title": "any examples of GAN?", "user": {"login": "yhg0112", "id": 5001738, "node_id": "MDQ6VXNlcjUwMDE3Mzg=", "avatar_url": "https://avatars.githubusercontent.com/u/5001738?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yhg0112", "html_url": "https://github.com/yhg0112", "followers_url": "https://api.github.com/users/yhg0112/followers", "following_url": "https://api.github.com/users/yhg0112/following{/other_user}", "gists_url": "https://api.github.com/users/yhg0112/gists{/gist_id}", "starred_url": "https://api.github.com/users/yhg0112/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yhg0112/subscriptions", "organizations_url": "https://api.github.com/users/yhg0112/orgs", "repos_url": "https://api.github.com/users/yhg0112/repos", "events_url": "https://api.github.com/users/yhg0112/events{/privacy}", "received_events_url": "https://api.github.com/users/yhg0112/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-27T11:34:55Z", "updated_at": "2018-02-09T01:21:58Z", "closed_at": "2018-02-09T01:21:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "is there any examples using vanilla_gan or cycle_gan? \r\n\r\ni'm trying to do experiments about basic gans with transformer, \r\n\r\nbut code like this keep putting error \r\n\r\n```\r\nPROBLEM=image_mnist\r\nMODEL=vanilla_gan\r\nHPARAMS=vanilla_gan\r\n\r\nUSR_DIR=$PWD\r\nDATA_DIR=/path/to/data/mnist\r\nTMP_DIR=$DATA_DIR\r\nTRAIN_DIR=/path/to/output/model\r\n\r\npython -m pdb ~/anaconda2/bin/t2t-trainer \\\r\n    --t2t_usr_dir=$USR_DIR \\\r\n    --data_dir=$DATA_DIR \\\r\n    --problems=$PROBLEM \\\r\n    --model=$MODEL \\\r\n    --hparams_set=$HPARAMS \\\r\n    --output_dir=$TRAIN_DIR \r\n```\r\n\r\n\r\nthis code above is giving me an error like this \r\n\r\n```\r\nInvalidArgumentError (see above for traceback): Matrix size-incompatible: In[0]: [2,1], In[1]: [784,128]\r\n         [[Node: vanilla_gan/body/model/parallel_0/body/vanilla_gan/d_h1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](vanilla_gan/body/model/parallel_0/body/vanilla_gan/strided_slice_3, Identity_4)]]\r\n         [[Node: training/clip_by_global_norm/mul_1/_251 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1030_training/clip_by_global_norm/mul_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n```\r\n\r\nare there any examples which can help me?", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/543/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/543/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/541", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/541/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/541/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/541/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/541", "id": 291473372, "node_id": "MDU6SXNzdWUyOTE0NzMzNzI=", "number": 541, "title": "Possible bug: rouge_l_fscore function call switches the parameters around.", "user": {"login": "ArjunNair", "id": 1013419, "node_id": "MDQ6VXNlcjEwMTM0MTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1013419?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ArjunNair", "html_url": "https://github.com/ArjunNair", "followers_url": "https://api.github.com/users/ArjunNair/followers", "following_url": "https://api.github.com/users/ArjunNair/following{/other_user}", "gists_url": "https://api.github.com/users/ArjunNair/gists{/gist_id}", "starred_url": "https://api.github.com/users/ArjunNair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ArjunNair/subscriptions", "organizations_url": "https://api.github.com/users/ArjunNair/orgs", "repos_url": "https://api.github.com/users/ArjunNair/repos", "events_url": "https://api.github.com/users/ArjunNair/events{/privacy}", "received_events_url": "https://api.github.com/users/ArjunNair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-25T07:21:13Z", "updated_at": "2018-02-09T00:51:59Z", "closed_at": "2018-02-09T00:51:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "In the function **rouge_l_fscore** (in utils/rouge.py), it makes a call to **rouge_l_sentence_level** like so:\r\n\r\n`rouge_l_f_score = tf.py_func(rouge_l_sentence_level, (labels, outputs),\r\n                               tf.float32)`\r\n\r\nHowever the **rouge_l_sentence_level** function is declared as:\r\n`def rouge_l_sentence_level(eval_sentences, ref_sentences)`\r\n\r\nUnless I'm reading this completely wrong, shouldn't the parameters being passed via tf.py_founc be:\r\n`rouge_l_f_score = tf.py_func(rouge_l_sentence_level, (outputs, labels),\r\n                               tf.float32)`\r\n\r\nwhere the arguments 'outputs' and 'labels' are switched from previous call.", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/541/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/541/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/536", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/536/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/536/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/536/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/536", "id": 290684179, "node_id": "MDU6SXNzdWUyOTA2ODQxNzk=", "number": 536, "title": "decode using attention-lm", "user": {"login": "wachaong", "id": 1356861, "node_id": "MDQ6VXNlcjEzNTY4NjE=", "avatar_url": "https://avatars.githubusercontent.com/u/1356861?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wachaong", "html_url": "https://github.com/wachaong", "followers_url": "https://api.github.com/users/wachaong/followers", "following_url": "https://api.github.com/users/wachaong/following{/other_user}", "gists_url": "https://api.github.com/users/wachaong/gists{/gist_id}", "starred_url": "https://api.github.com/users/wachaong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wachaong/subscriptions", "organizations_url": "https://api.github.com/users/wachaong/orgs", "repos_url": "https://api.github.com/users/wachaong/repos", "events_url": "https://api.github.com/users/wachaong/events{/privacy}", "received_events_url": "https://api.github.com/users/wachaong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-23T02:10:30Z", "updated_at": "2018-02-09T01:22:45Z", "closed_at": "2018-02-09T01:22:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "my script\r\n1 #!/bin/sh\r\n2\r\n3 PROBLEM=languagemodel_ptb10k\r\n4 #MODEL=transformer\r\n5 #HPARAMS=transformer_base\r\n6 MODEL=attention_lm\r\n7 HPARAMS=attention_lm_small\r\n8\r\n9 DATA_DIR=t2t_data\r\n10 TMP_DIR=t2t_datagen_tmp\r\n11 TRAIN_DIR=t2t_train/$PROBLEM/$MODEL-$HPARAMS\r\n12\r\n13 mkdir -p $DATA_DIR $TMP_DIR $TRAIN_DIR\r\n14\r\n15 ## Generate data\r\n16 #t2t-datagen \r\n17 # --data_dir=$DATA_DIR \r\n18 # --tmp_dir=$TMP_DIR \r\n19 # --problem=$PROBLEM\r\n20\r\n21 t2t-trainer \r\n22 --data_dir=$DATA_DIR \r\n23 --problems=$PROBLEM \r\n24 --model=$MODEL \r\n25 --hparams_set=$HPARAMS \r\n26 --output_dir=$TRAIN_DIR \r\n27 --worker_gpu=8 \r\n28 --train_steps=1000 \r\n29 --eval_steps=10\r\n30\r\n31 t2t-decoder \r\n32 --data_dir=$DATA_DIR \r\n33 --problems=$PROBLEM \r\n34 --model=$MODEL \r\n35 --hparams_set=$HPARAMS \r\n36 --output_dir=$TRAIN_DIR \r\n37 --decode_from_file=$TMP_DIR/simple-examples/data/small_test\r\n\r\nmy decode result seems empty:\r\n\r\nINFO:tensorflow:Inference results INPUT: it was the first time in seven years that moscow has n't joined efforts led by\r\nINFO:tensorflow:Inference results OUTPUT:\r\nINFO:tensorflow:Inference results INPUT: for a while\r\nINFO:tensorflow:Inference results OUTPUT:\r\nINFO:tensorflow:Inference results INPUT: we 've been spending a lot of time in los angeles talking to tv production people says mike parks president of call interactive which supplied technology for both abc sports and nbc 's consumer minutes\r\nINFO:tensorflow:Inference results OUTPUT:\r\nINFO:tensorflow:Inference results INPUT: from the fee the local phone company and the long-distance carrier extract their costs to carry the call passing the rest of the money to the\r\nINFO:tensorflow:Inference results OUTPUT:", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/536/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/536/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/523", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/523/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/523/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/523/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/523", "id": 289104179, "node_id": "MDU6SXNzdWUyODkxMDQxNzk=", "number": 523, "title": "Travis log too long", "user": {"login": "martinpopel", "id": 724617, "node_id": "MDQ6VXNlcjcyNDYxNw==", "avatar_url": "https://avatars.githubusercontent.com/u/724617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinpopel", "html_url": "https://github.com/martinpopel", "followers_url": "https://api.github.com/users/martinpopel/followers", "following_url": "https://api.github.com/users/martinpopel/following{/other_user}", "gists_url": "https://api.github.com/users/martinpopel/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinpopel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinpopel/subscriptions", "organizations_url": "https://api.github.com/users/martinpopel/orgs", "repos_url": "https://api.github.com/users/martinpopel/repos", "events_url": "https://api.github.com/users/martinpopel/events{/privacy}", "received_events_url": "https://api.github.com/users/martinpopel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-01-17T00:37:54Z", "updated_at": "2018-01-29T15:07:22Z", "closed_at": "2018-01-29T15:07:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Travis CI has 4MB limit on the log file, but current T2T tests exceed this limit.\r\nAs a result I cannot see the real cause why a [given build](https://travis-ci.org/tensorflow/tensor2tensor/jobs/329572628) failed.\r\nMost of the log (if downloaded as a raw file) is full of download progress bars, e.g.\r\n```\r\n  Downloading mpmath-1.0.0.tar.gz (511kB)\r\n\u001b[?25l\r\n\u001b[K    2% |\u258b                               | 10kB 53.6MB/s eta 0:00:01\r\n\u001b[K    4% |\u2588\u258e                              | 20kB 41.3MB/s eta 0:00:01\r\n\u001b[K    6% |\u2588\u2588                              | 30kB 42.5MB/s eta 0:00:01\r\n\u001b[K    8% |\u2588\u2588\u258b                             | 40kB 41.3MB/s eta 0:00:01\r\n\u001b[K    10% |\u2588\u2588\u2588\u258f                            | 51kB 42.6MB/s eta 0:00:01\r\n```\r\nThis is the first time I see this problem, but it seems that until a new pip version with [--progress-bar off](https://github.com/pypa/pip/pull/4194) option is released, we should use [a workaround](https://github.com/pypa/pip/issues/2756#issuecomment-268773883) `pip install package | cat && exit ${PIPESTATUS[0]}` or `set -o pipefail; pip install package | cat`.", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/523/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/523/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/515", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/515/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/515/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/515/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/515", "id": 288309009, "node_id": "MDU6SXNzdWUyODgzMDkwMDk=", "number": 515, "title": "t2t-insights-server won't start", "user": {"login": "mehmedes", "id": 21199186, "node_id": "MDQ6VXNlcjIxMTk5MTg2", "avatar_url": "https://avatars.githubusercontent.com/u/21199186?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mehmedes", "html_url": "https://github.com/mehmedes", "followers_url": "https://api.github.com/users/mehmedes/followers", "following_url": "https://api.github.com/users/mehmedes/following{/other_user}", "gists_url": "https://api.github.com/users/mehmedes/gists{/gist_id}", "starred_url": "https://api.github.com/users/mehmedes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mehmedes/subscriptions", "organizations_url": "https://api.github.com/users/mehmedes/orgs", "repos_url": "https://api.github.com/users/mehmedes/repos", "events_url": "https://api.github.com/users/mehmedes/events{/privacy}", "received_events_url": "https://api.github.com/users/mehmedes/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-01-13T07:12:41Z", "updated_at": "2018-03-25T17:55:00Z", "closed_at": "2018-03-25T17:55:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "Trying to decode with ```decode_interactive``` or running ```t2t-insights-server``` produces the following errors.\r\n\r\n```decode_interactive```:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/t2t-decoder\", line 16, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/usr/local/bin/t2t-decoder\", line 12, in main\r\n    t2t_decoder.main(argv)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/bin/t2t_decoder.py\", line 105, in main\r\n    decode(estimator, hp, decode_hp)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/bin/t2t_decoder.py\", line 76, in decode\r\n    decoding.decode_interactively(estimator, hparams, decode_hp)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/decoding.py\", line 343, in decode_interactively\r\n    for result in result_iter:\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 409, in predict\r\n    input_fn, model_fn_lib.ModeKeys.PREDICT)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 567, in _get_features_from_input_fn\r\n    result = self._call_input_fn(input_fn, mode)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 663, in _call_input_fn\r\n    return input_fn(**kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/decoding.py\", line 339, in input_fn\r\n    example = _interactive_input_tensor_to_features_dict(example, hparams)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/decoding.py\", line 589, in _interactive_input_tensor_to_features_dict\r\n    input_fn, feature_map[\"problem_choice\"], len(hparams.problems) - 1)\r\nKeyError: 'problem_choice'\r\n```\r\nRunning ```decode_interactive``` as follows:\r\n```\r\nPROBLEM=translate_ende_wmt32k_packed\r\nMODEL=transformer\r\nHPARAMS=transformer_big_lr05_w2k_d999\r\n\r\nDATA_DIR=$HOME/t2t_data\r\nTRAIN_DIR=$HOME/t2t_train/$PROBLEM/$MODEL-$HPARAMS\r\n\r\n\r\nt2t-decoder \\\r\n  --data_dir=$DATA_DIR \\\r\n  --problems=$PROBLEM \\\r\n  --model=$MODEL \\\r\n  --hparams_set=$HPARAMS \\\r\n  --output_dir=$TRAIN_DIR \\\r\n  --decode_interactive\r\n```\r\n\r\n\r\n```t2t-insights-server```:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/t2t-insights-server\", line 16, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/usr/local/bin/t2t-insights-server\", line 12, in main\r\n    server.main(argv)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/insights/server.py\", line 78, in main\r\n    configuration = json.load(configuration_file)\r\n  File \"/usr/lib/python2.7/json/__init__.py\", line 291, in load\r\n    **kw)\r\n  File \"/usr/lib/python2.7/json/__init__.py\", line 339, in loads\r\n    return _default_decoder.decode(s)\r\n  File \"/usr/lib/python2.7/json/decoder.py\", line 364, in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n  File \"/usr/lib/python2.7/json/decoder.py\", line 380, in raw_decode\r\n    obj, end = self.scan_once(s, idx)\r\nValueError: Expecting property name: line 14 column 5 (char 498)\r\n```\r\n\r\nMy config json looks like this:\r\n```\r\n  {\r\n    \"configuration\": [{\r\n      \"source_language\": \"en\",\r\n      \"target_language\": \"de\",\r\n      \"label\": \"translate_ende_wmt32k_packed\",\r\n      \"transformer\": {\r\n        \"model\": \"transformer\",\r\n        \"model_dir\": \"/home/mehmedes/t2t_train/translate_ende_wmt32k_packed/transformer-transformer_big_lr05_w2k_d999\",\r\n        \"data_dir\": \"/home/mehmedes/t2t_data\",\r\n        \"hparams\": \"\",\r\n        \"hparams_set\": \"transformer_big_lr05_w2k_d999\",\r\n        \"problems\": \"translate_ende_wmt32k_packed\"\r\n      },\r\n    }]\r\n    \"language\": [{\r\n      \"code\": \"en\",\r\n      \"name\": \"English\",\r\n    },{\r\n      \"code\": \"de\",\r\n      \"name\": \"German\",\r\n    }]\r\n  }\r\n```\r\n\r\n\r\n\r\nThe model was trained on ```1.4.1```. Continuing training the model with ```1.4.2``` works.\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/515/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/515/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/500", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/500/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/500/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/500/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/500", "id": 285602618, "node_id": "MDU6SXNzdWUyODU2MDI2MTg=", "number": 500, "title": "notebook visualisation does not run due to wrong dimensionality of attention_weights ", "user": {"login": "colmantse", "id": 20071323, "node_id": "MDQ6VXNlcjIwMDcxMzIz", "avatar_url": "https://avatars.githubusercontent.com/u/20071323?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colmantse", "html_url": "https://github.com/colmantse", "followers_url": "https://api.github.com/users/colmantse/followers", "following_url": "https://api.github.com/users/colmantse/following{/other_user}", "gists_url": "https://api.github.com/users/colmantse/gists{/gist_id}", "starred_url": "https://api.github.com/users/colmantse/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colmantse/subscriptions", "organizations_url": "https://api.github.com/users/colmantse/orgs", "repos_url": "https://api.github.com/users/colmantse/repos", "events_url": "https://api.github.com/users/colmantse/events{/privacy}", "received_events_url": "https://api.github.com/users/colmantse/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-01-03T05:35:11Z", "updated_at": "2018-02-09T04:09:41Z", "closed_at": "2018-02-09T04:09:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi all,\r\n\r\nI am playing with the visualisation notebook and after some work, i manage to get everything apart from the last cell running. I find that enc_attn and dec_attn has different shape and therefore in the last cell, during get_attention, they wont concat. It would be great if somebody could take a look and see if i am missing something. \r\n\r\nI have attached the visualisation code here.\r\n[TransformerVisualization.log](https://github.com/tensorflow/tensor2tensor/files/1599469/TransformerVisualization.log)\r\n\r\nwhich is basically the IPYNB file with the ending changed to log. (since github does not support ipynb upload) It recorded also the output at runtime and the stack trace as well.\r\n\r\nThank you very much!\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/500/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/500/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/498", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/498/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/498/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/498/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/498", "id": 285371991, "node_id": "MDU6SXNzdWUyODUzNzE5OTE=", "number": 498, "title": "Training on 1.4.1 hangs", "user": {"login": "vince62s", "id": 15141326, "node_id": "MDQ6VXNlcjE1MTQxMzI2", "avatar_url": "https://avatars.githubusercontent.com/u/15141326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vince62s", "html_url": "https://github.com/vince62s", "followers_url": "https://api.github.com/users/vince62s/followers", "following_url": "https://api.github.com/users/vince62s/following{/other_user}", "gists_url": "https://api.github.com/users/vince62s/gists{/gist_id}", "starred_url": "https://api.github.com/users/vince62s/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vince62s/subscriptions", "organizations_url": "https://api.github.com/users/vince62s/orgs", "repos_url": "https://api.github.com/users/vince62s/repos", "events_url": "https://api.github.com/users/vince62s/events{/privacy}", "received_events_url": "https://api.github.com/users/vince62s/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-01-02T07:53:39Z", "updated_at": "2019-05-07T19:28:31Z", "closed_at": "2018-01-15T16:21:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\r\nSince the upgrade to 1.4 I trained a few runs and each hung after a few hours.\r\nseems to be a comparable issue related here #494 and here #496 \r\n\r\nAnyone with similar problem ?\r\n\r\nJust to be clear, it goes up to freezing the machine need a hard reboot.\r\nI trained without any issue on another toolkit (just to check it was not a hard drive / gpu issue)", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/498/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/498/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/496", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/496/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/496/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/496/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/496", "id": 285183047, "node_id": "MDU6SXNzdWUyODUxODMwNDc=", "number": 496, "title": "Language model decoding problems", "user": {"login": "lnabergall", "id": 15303146, "node_id": "MDQ6VXNlcjE1MzAzMTQ2", "avatar_url": "https://avatars.githubusercontent.com/u/15303146?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lnabergall", "html_url": "https://github.com/lnabergall", "followers_url": "https://api.github.com/users/lnabergall/followers", "following_url": "https://api.github.com/users/lnabergall/following{/other_user}", "gists_url": "https://api.github.com/users/lnabergall/gists{/gist_id}", "starred_url": "https://api.github.com/users/lnabergall/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lnabergall/subscriptions", "organizations_url": "https://api.github.com/users/lnabergall/orgs", "repos_url": "https://api.github.com/users/lnabergall/repos", "events_url": "https://api.github.com/users/lnabergall/events{/privacy}", "received_events_url": "https://api.github.com/users/lnabergall/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-12-30T04:26:37Z", "updated_at": "2018-02-09T01:23:25Z", "closed_at": "2018-02-09T01:23:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "There seem to be problems with decoding from a language model, in particular a (very small) attention_lm and a custom lstm model. When t2t-decoder is run in interactive mode:\r\n\r\n`python t2t-decoder --data_dir=\"C:\\t2t\\t2t_data\\lm1b_baseline\" --tmp_dir=\"C:\\t2t\\t2t_temp\" --t2t_usr_dir=\"C:\\t2t\\multi_lm\" --output_dir=\"C:\\t2t\\t2t_training\\lm1b_baseline\\attention_lm-attention_lm_tiny\" --problem=languagemodel_lm1b8k --model=attention_lm --hparams_set=attention_lm_tiny --decode_interactive`\r\n\r\nit produces the same output every time, regardless of the input:\r\n\r\n> INFO:tensorflow:Restoring parameters from C:\\t2t\\t2t_training\\lm1b_baseline\\attention_lm-attention_lm_tiny\\model.ckpt-108581\r\n> 2017-12-29 23:16:23.449223: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] beam_decode batch_size=[1]\r\n> INFO:tensorflow:\" I 'm not going to be able to make it , \" he said .\r\n> INTERACTIVE MODE  num_samples=1  decode_length=100\r\n>   it=<input_type>     ('text' or 'image' or 'label', default: text)\r\n>   pr=<problem_num>    (set the problem number, default: 0)\r\n>   in=<input_problem>  (set the input problem number)\r\n>   ou=<output_problem> (set the output problem number)\r\n>   ns=<num_samples>    (changes number of samples, default: 1)\r\n>   dl=<decode_length>  (changes decode length, default: 100)\r\n>   <target_prefix>                (decode)\r\n>   q                   (quit)\r\n> \\>What if\r\n> 2017-12-29 23:16:29.480916: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] beam_decode batch_size=[1]\r\n> INFO:tensorflow:\" I 'm not going to be able to make it , \" he said .\r\n> INTERACTIVE MODE  num_samples=1  decode_length=100\r\n>   it=<input_type>     ('text' or 'image' or 'label', default: text)\r\n>   pr=<problem_num>    (set the problem number, default: 0)\r\n>   in=<input_problem>  (set the input problem number)\r\n>   ou=<output_problem> (set the output problem number)\r\n>   ns=<num_samples>    (changes number of samples, default: 1)\r\n>   dl=<decode_length>  (changes decode length, default: 100)\r\n>   <target_prefix>                (decode)\r\n>   q                   (quit)\r\n> \\>Let's try this instead\r\n> 2017-12-29 23:16:49.811394: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] beam_decode batch_size=[1]\r\n> INFO:tensorflow:\" I 'm not going to be able to make it , \" he said .\r\n> INTERACTIVE MODE  num_samples=1  decode_length=100\r\n>   it=<input_type>     ('text' or 'image' or 'label', default: text)\r\n>   pr=<problem_num>    (set the problem number, default: 0)\r\n>   in=<input_problem>  (set the input problem number)\r\n>   ou=<output_problem> (set the output problem number)\r\n>   ns=<num_samples>    (changes number of samples, default: 1)\r\n>   dl=<decode_length>  (changes decode length, default: 100)\r\n>   <target_prefix>                (decode)\r\n>   q                   (quit)\r\n> \\>asdfasfdas\r\n> 2017-12-29 23:16:58.642319: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] beam_decode batch_size=[1]\r\n> INFO:tensorflow:\" I 'm not going to be able to make it , \" he said .\r\n> INTERACTIVE MODE  num_samples=1  decode_length=100\r\n>   it=<input_type>     ('text' or 'image' or 'label', default: text)\r\n>   pr=<problem_num>    (set the problem number, default: 0)\r\n>   in=<input_problem>  (set the input problem number)\r\n>   ou=<output_problem> (set the output problem number)\r\n>   ns=<num_samples>    (changes number of samples, default: 1)\r\n>   dl=<decode_length>  (changes decode length, default: 100)\r\n>   <target_prefix>                (decode)\r\n>   q                   (quit)\r\n> \\>\r\n> \r\n\r\nThis problem also occurs for a LSTM model:\r\n\r\n    @registry.register_model\r\n    class LSTMLm(t2t_model.T2TModel):\r\n        \"\"\"Basic LSTM recurrent neural network.\"\"\"\r\n\r\n        def model_fn_body(self, features):\r\n            if self._hparams.initializer == \"orthogonal\":\r\n                raise ValueError(\"LSTM models fail with orthogonal initializer.\")\r\n            train = self._hparams.mode == tf.estimator.ModeKeys.TRAIN\r\n            with tf.variable_scope(\"lstm_lm\"):\r\n                # Flatten and shift inputs.\r\n                shifted_targets = common_layers.shift_right(features.get(\"targets\"))\r\n                inputs = common_layers.flatten4d3d(shifted_targets)\r\n                outputs, _ = lstm.lstm(inputs, self._hparams, train, \"lstm\")\r\n                return tf.expand_dims(outputs, axis=2)\r\n\r\n`python t2t-decoder --data_dir=\"C:\\t2t\\t2t_data\\lm1b_baseline\" --tmp_dir=\"C:\\t2t\\t2t_temp\" --t2t_usr_dir=\"C:\\t2t\\multi_lm\" --output_dir=\"C:\\t2t\\t2t_training\\lm1b_baseline\\lstm-lstm_tiny\" --problem=languagemodel_lm1b8k --model=lstm_lm --hparams_set=lstm_tiny --decode_interactive`\r\n\r\nNote that both models were trained on the 1 billion word dataset with a vocab size of 8192\r\n\r\n    @registry.register_problem(\"languagemodel_lm1b8k\")\r\n    class LanguagemodelLm1b8k(LanguagemodelLm1b32k):\r\n\r\n        @property\r\n        def targeted_vocab_size(self):\r\n            return 2**13  # 8192\r\n\r\nfor over 100,000 steps and reached decent negative log perplexities, under -4. \r\n\r\nAlthough I have not done a complete review of the source code, this seems to occur for two reasons: (1) the model isn't receiving the input sequence and conditioning the output on it, and (2) there isn't any non-deterministic sampling from the output probabilities. \r\n\r\nIs this correct? And if so, is this the intended behavior or a bug? Both (1) and (2) are a problem for decoding from language models. Others have raised similar issues with decoding, e.g. #439.\r\n\r\nI'm running TensorFlow 1.3.0 and Tensor2Tensor 1.3.0. Any help would be greatly appreciated.\r\n", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/496/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/496/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/495", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/495/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/495/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/495/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/495", "id": 285071220, "node_id": "MDU6SXNzdWUyODUwNzEyMjA=", "number": 495, "title": "Weird changes in version 1.4 [bug]", "user": {"login": "ricsinaruto", "id": 18282017, "node_id": "MDQ6VXNlcjE4MjgyMDE3", "avatar_url": "https://avatars.githubusercontent.com/u/18282017?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ricsinaruto", "html_url": "https://github.com/ricsinaruto", "followers_url": "https://api.github.com/users/ricsinaruto/followers", "following_url": "https://api.github.com/users/ricsinaruto/following{/other_user}", "gists_url": "https://api.github.com/users/ricsinaruto/gists{/gist_id}", "starred_url": "https://api.github.com/users/ricsinaruto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ricsinaruto/subscriptions", "organizations_url": "https://api.github.com/users/ricsinaruto/orgs", "repos_url": "https://api.github.com/users/ricsinaruto/repos", "events_url": "https://api.github.com/users/ricsinaruto/events{/privacy}", "received_events_url": "https://api.github.com/users/ricsinaruto/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2017-12-29T10:37:09Z", "updated_at": "2018-02-06T18:03:07Z", "closed_at": "2018-02-06T18:03:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "There are several weird changes that I have observed by switching from tensor2tensor version 1.3.2 to version 1.4.1. (Tensorflow version is 1.4.1 (gpu) for both)\r\n\r\nRunning exactly the same t2t-trainer command results in vastly different trainings, and I will list all the weird and annoying differences that I have observed here. I have no idea what the problem could be, I don't know whether it is a bug, or I just have to change some parameters to adapt to the new tensor2tensor version.\r\n\r\nThe command that I run:\r\n```\r\nt2t-trainer --t2t_usr_dir=t2t_csaky --generate_data=False --data_dir=data_dir/facebook_ricsibot_character --model=transformer --problems=character_chatbot --hparams_set=transformer_dorka_big_dropout --output_dir=train_dir/trf_big_dropout_facebook_ricsibot_character --train_steps=800000 --keep_checkpoint_max=3 --keep_checkpoint_every_n_hours=1\r\n```\r\n\r\nAs you can see I use my own problem and hparam definitions, however this shouldn't affect anything. In my registration files the code is exactly the same for both tensor2tensor versions. Running the above command results in the following changes from version 1.3.2 to 1.4.1:\r\n* In 1.4.1 I can no longer see any training stats using tensorboard (loss, learning rate, etc.)\r\n  * I can still see eval stats in 1.4.1, but compared to 1.3.2, now there are two eval folders, one named eval, and one named eval_one_pass\r\n* In 1.4.1 in my output_dir I don't get a flags.txt and hparams.json file compared to 1.3.2\r\n* In 1.4.1 the training is run at 2000 steps at a time, and when this is finished the model is reloaded.\r\n  * This results in having 2 checkpoints at each 2000 steps (2001 and 2002 for example)\r\n* In 1.4.1 the evaluation wants to run for 10000 steps compared to 10 steps in 1.3.2\r\n  * After about 70 steps I get a weird error, but the evaluation still prints metrics.\r\n  * In 1.3.2 the evaluation runs for 10 steps and then prints metrics without any errors.\r\n![weird_evaluation](https://user-images.githubusercontent.com/18282017/34435114-d8eb4366-ec93-11e7-8f0f-f20e4975764c.png)\r\n\r\nDespite these differences the actual trainings run the same, so the loss is going down the same way.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/495/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/495/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/494", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/494/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/494/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/494/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/494", "id": 285050539, "node_id": "MDU6SXNzdWUyODUwNTA1Mzk=", "number": 494, "title": "Restoring parameters  hungs", "user": {"login": "zh794390558", "id": 3038472, "node_id": "MDQ6VXNlcjMwMzg0NzI=", "avatar_url": "https://avatars.githubusercontent.com/u/3038472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zh794390558", "html_url": "https://github.com/zh794390558", "followers_url": "https://api.github.com/users/zh794390558/followers", "following_url": "https://api.github.com/users/zh794390558/following{/other_user}", "gists_url": "https://api.github.com/users/zh794390558/gists{/gist_id}", "starred_url": "https://api.github.com/users/zh794390558/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zh794390558/subscriptions", "organizations_url": "https://api.github.com/users/zh794390558/orgs", "repos_url": "https://api.github.com/users/zh794390558/repos", "events_url": "https://api.github.com/users/zh794390558/events{/privacy}", "received_events_url": "https://api.github.com/users/zh794390558/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-12-29T07:58:11Z", "updated_at": "2018-02-09T19:12:15Z", "closed_at": "2018-02-09T19:12:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have the same problem with blstm,\r\nwith --schedule 'train'\r\n\r\n>INFO:tensorflow:Global model_fn finished.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\n2017-12-29 07:38:44.128222: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2017-12-29 07:38:44.851032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:\r\nname: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:05:00.0\r\ntotalMemory: 11.90GiB freeMemory: 11.74GiB\r\n2017-12-29 07:38:44.851088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\n\r\n, --schedule 'evalution'\r\n\r\n>2017-12-29 07:43:23.631197: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2017-12-29 07:43:24.383548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:\r\nname: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:05:00.0\r\ntotalMemory: 11.90GiB freeMemory: 11.74GiB\r\n2017-12-29 07:43:24.383603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\nINFO:tensorflow:Restoring parameters from d/model.ckpt-1\r\n\r\nor '--schedule 'test''\r\n\r\n>INFO:tensorflow:Create CheckpointSaverHook.\r\n2017-12-29 07:52:49.675929: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2017-12-29 07:52:50.477620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:\r\nname: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:05:00.0\r\ntotalMemory: 11.90GiB freeMemory: 11.74GiB\r\n2017-12-29 07:52:50.477673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\nINFO:tensorflow:Restoring parameters from d/model.ckpt-1\r\n\r\n` --schedule 'continuous_train_and_eval'` seems work,\r\n\r\n>totalMemory: 11.90GiB freeMemory: 11.74GiB\r\n2017-12-29 08:15:39.798320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\nINFO:tensorflow:Restoring parameters from d/model.ckpt-1\r\nINFO:tensorflow:Saving checkpoints for 2 into d/model.ckpt.\r\nINFO:tensorflow:loss = 5.00657, step = 2\r\n\r\nbut --schedule 'train_and_evaluate'\r\n\r\nThe problm seems like to https://github.com/tensorflow/tensor2tensor/issues/353, and i use `tf.nn.bidirectional_dynamic_rnn` without  'orthogonal initializer`", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/494/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/494/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/485", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/485/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/485/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/485/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/485", "id": 284117461, "node_id": "MDU6SXNzdWUyODQxMTc0NjE=", "number": 485, "title": "Seed / reproducibility", "user": {"login": "vince62s", "id": 15141326, "node_id": "MDQ6VXNlcjE1MTQxMzI2", "avatar_url": "https://avatars.githubusercontent.com/u/15141326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vince62s", "html_url": "https://github.com/vince62s", "followers_url": "https://api.github.com/users/vince62s/followers", "following_url": "https://api.github.com/users/vince62s/following{/other_user}", "gists_url": "https://api.github.com/users/vince62s/gists{/gist_id}", "starred_url": "https://api.github.com/users/vince62s/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vince62s/subscriptions", "organizations_url": "https://api.github.com/users/vince62s/orgs", "repos_url": "https://api.github.com/users/vince62s/repos", "events_url": "https://api.github.com/users/vince62s/events{/privacy}", "received_events_url": "https://api.github.com/users/vince62s/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-12-22T09:42:08Z", "updated_at": "2018-02-09T01:22:14Z", "closed_at": "2018-02-09T01:22:14Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "\r\neven though this https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/bin/t2t-trainer#L173\r\nwas added in 1.4.0, two runs in ar ow of the same config does not produce the sames results.\r\nJust checked loss and evals afetr 2000 steps, different.", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/485/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/485/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/445", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/445/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/445/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/445/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/445", "id": 277156271, "node_id": "MDU6SXNzdWUyNzcxNTYyNzE=", "number": 445, "title": "`translate_enzh_wmt8k` dev data path error", "user": {"login": "zyshin", "id": 4653774, "node_id": "MDQ6VXNlcjQ2NTM3NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/4653774?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zyshin", "html_url": "https://github.com/zyshin", "followers_url": "https://api.github.com/users/zyshin/followers", "following_url": "https://api.github.com/users/zyshin/following{/other_user}", "gists_url": "https://api.github.com/users/zyshin/gists{/gist_id}", "starred_url": "https://api.github.com/users/zyshin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zyshin/subscriptions", "organizations_url": "https://api.github.com/users/zyshin/orgs", "repos_url": "https://api.github.com/users/zyshin/repos", "events_url": "https://api.github.com/users/zyshin/events{/privacy}", "received_events_url": "https://api.github.com/users/zyshin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-11-27T20:22:42Z", "updated_at": "2017-12-19T01:46:23Z", "closed_at": "2017-12-19T01:46:23Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "```\r\n> t2t-datagen \\\r\n>   --data_dir=$DATA_DIR \\\r\n>   --tmp_dir=$TMP_DIR \\\r\n>   --problem=$PROBLEM\r\nINFO:tensorflow:Generating problems:\r\n    translate:\r\n      * translate_enzh_wmt8k\r\nINFO:tensorflow:Generating data for translate_enzh_wmt8k.\r\nINFO:tensorflow:Found vocab file: /home/translate/t2t_data/vocab.enzh-en.8192\r\nINFO:tensorflow:Found vocab file: /home/translate/t2t_data/vocab.enzh-zh.8192\r\nINFO:tensorflow:Not downloading, file already found: /tmp/t2t_datagen/training-parallel-nc-v12.tgz\r\nINFO:tensorflow:Found vocab file: /home/translate/t2t_data/vocab.enzh-en.8192\r\nINFO:tensorflow:Found vocab file: /home/translate/t2t_data/vocab.enzh-zh.8192\r\nINFO:tensorflow:Not downloading, file already found: /tmp/t2t_datagen/dev.tgz\r\nTraceback (most recent call last):\r\n  File \"/home/translate/env/bin/t2t-datagen\", line 212, in <module>\r\n    tf.app.run()\r\n  File \"/home/translate/env/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/translate/env/bin/t2t-datagen\", line 178, in main\r\n    generate_data_for_registered_problem(problem)\r\n  File \"/home/translate/env/bin/t2t-datagen\", line 208, in generate_data_for_registered_problem\r\n    task_id=task_id)\r\n  File \"/home/translate/env/lib/python3.5/site-packages/tensor2tensor/data_generators/problem.py\", line 638, in generate_data\r\n    self.generator(data_dir, tmp_dir, False), dev_paths)\r\n  File \"/home/translate/env/lib/python3.5/site-packages/tensor2tensor/data_generators/translate_enzh.py\", line 88, in generator\r\n    \"wmt_enzh_tok_%s\" % tag)\r\n  File \"/home/translate/env/lib/python3.5/site-packages/tensor2tensor/data_generators/translate.py\", line 246, in compile_data\r\n    line1, line2 = lang1_file.readline(), lang2_file.readline()\r\n  File \"/home/translate/env/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py\", line 177, in readline\r\n    self._preread_check()\r\n  File \"/home/translate/env/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py\", line 79, in _preread_check\r\n    compat.as_bytes(self.__name), 1024 * 512, status)\r\n  File \"/home/translate/env/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: /tmp/t2t_datagen/dev/newsdev2017-zhen-src.en.sgm; No such file or directory\r\n```\r\n\r\nChanging line 52 of file `data_generators/enzh_wmt8k.py` from\r\n`dev/newsdev2017-zhen-src.en.sgm` and `dev/newsdev2017-zhen-ref.zh.sgm` to\r\n`dev/newsdev2017-enzh-src.en.sgm` and `dev/newsdev2017-enzh-ref.zh.sgm`\r\nwill make it work.", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/445/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/445/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/403", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/403/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/403/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/403/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/403", "id": 271464361, "node_id": "MDU6SXNzdWUyNzE0NjQzNjE=", "number": 403, "title": "Cannot run parsing task", "user": {"login": "sensus-sextus", "id": 14219554, "node_id": "MDQ6VXNlcjE0MjE5NTU0", "avatar_url": "https://avatars.githubusercontent.com/u/14219554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sensus-sextus", "html_url": "https://github.com/sensus-sextus", "followers_url": "https://api.github.com/users/sensus-sextus/followers", "following_url": "https://api.github.com/users/sensus-sextus/following{/other_user}", "gists_url": "https://api.github.com/users/sensus-sextus/gists{/gist_id}", "starred_url": "https://api.github.com/users/sensus-sextus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sensus-sextus/subscriptions", "organizations_url": "https://api.github.com/users/sensus-sextus/orgs", "repos_url": "https://api.github.com/users/sensus-sextus/repos", "events_url": "https://api.github.com/users/sensus-sextus/events{/privacy}", "received_events_url": "https://api.github.com/users/sensus-sextus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-06T12:49:24Z", "updated_at": "2017-11-13T22:29:50Z", "closed_at": "2017-11-13T22:29:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "When trying to launch any of parsing problems, it always crashes\r\nFor example following output when trying to generate data \r\nfor  ptb8k problem\r\n\r\n`\r\n```\r\nINFO:tensorflow:Generating problems:\r\n    parsing:\r\n      * parsing_english_ptb8k\r\n      * parsing_english_ptb8k\r\nINFO:tensorflow:Generating training data for parsing_english_ptb8k.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/t2t-datagen\", line 213, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/usr/local/bin/t2t-datagen\", line 177, in main\r\n    generate_data_for_problem(problem)\r\n  File \"/usr/local/bin/t2t-datagen\", line 190, in generate_data_for_problem\r\n    generator_utils.generate_files(training_gen(), train_output_files,\r\n  File \"/usr/local/bin/t2t-datagen\", line 85, in <lambda>\r\n    lambda: translate.parsing_token_generator(\r\nAttributeError: module 'tensor2tensor.data_generators.translate' has no attribute 'parsing_token_generator'\r\n\r\n```\r\n`\r\nplease help!\r\nThank you", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/403/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/403/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/401", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/401/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/401/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/401/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/401", "id": 271188664, "node_id": "MDU6SXNzdWUyNzExODg2NjQ=", "number": 401, "title": "Crashing -- Memory leak ?", "user": {"login": "smcdufff", "id": 33268991, "node_id": "MDQ6VXNlcjMzMjY4OTkx", "avatar_url": "https://avatars.githubusercontent.com/u/33268991?v=4", "gravatar_id": "", "url": "https://api.github.com/users/smcdufff", "html_url": "https://github.com/smcdufff", "followers_url": "https://api.github.com/users/smcdufff/followers", "following_url": "https://api.github.com/users/smcdufff/following{/other_user}", "gists_url": "https://api.github.com/users/smcdufff/gists{/gist_id}", "starred_url": "https://api.github.com/users/smcdufff/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/smcdufff/subscriptions", "organizations_url": "https://api.github.com/users/smcdufff/orgs", "repos_url": "https://api.github.com/users/smcdufff/repos", "events_url": "https://api.github.com/users/smcdufff/events{/privacy}", "received_events_url": "https://api.github.com/users/smcdufff/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2017-11-04T12:30:47Z", "updated_at": "2017-12-22T17:47:26Z", "closed_at": "2017-12-22T17:47:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "I upgraded to 1.2.6 (tried also 1.2.7) from 1.2.2 and my training is always crashing after 4K steps (system A with 3 GPU)  or 60K (system B with 1 GPU). \r\n\r\nIf I go back to 1.2.2, it works again on both system (500 millions steps).\r\n\r\nHere my configuration\r\n--model=transformer \r\n--hparams_set=transformer_n_da\r\n\r\nHere the stacktrace:\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Ran out of GPU memory when allocating 329294592 bytes for \r\n\t [[Node: symbol_modality_21472_512_2/parallel_0_1/symbol_modality_21472_512/padded_cross_entropy/smoothing_cross_entropy/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](symbol_modality_21472_512_2/parallel_0_1/symbol_modality_21472_512/padded_cross_entropy/smoothing_cross_entropy/Reshape, symbol_modality_21472_512_2/parallel_0_1/symbol_modality_21472_512/padded_cross_entropy/smoothing_cross_entropy/Reshape_1)]]\r\n\t [[Node: total_loss/_5453 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_23728_total_loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op 'symbol_modality_21472_512_2/parallel_0_1/symbol_modality_21472_512/padded_cross_entropy/smoothing_cross_entropy/SoftmaxCrossEntropyWithLogits', defined at:\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\bin\\t2t-trainer\", line 96, in <module>\r\n    tf.app.run()\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\bin\\t2t-trainer\", line 92, in main\r\n    schedule=FLAGS.schedule)\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\utils\\trainer_utils.py\", line 378, in run\r\n    hparams=hparams)\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_runner.py\", line 209, in run\r\n    return _execute_schedule(experiment, schedule)\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_runner.py\", line 46, in _execute_schedule\r\n    return task()\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\experiment.py\", line 502, in train_and_evaluate\r\n    self.train(delay_secs=0)\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\experiment.py\", line 280, in train\r\n    hooks=self._train_monitors + extra_hooks)\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\experiment.py\", line 672, in _call_train\r\n    hooks=hooks)\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 241, in train\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 630, in _train_model\r\n    model_fn_lib.ModeKeys.TRAIN)\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 615, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\utils\\model_builder.py\", line 349, in wrapping_model_fn\r\n    return model_fn(model, features, mode, hparams, **kwargs)\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\utils\\model_builder.py\", line 164, in model_fn\r\n    max_idx=len(hparams.problems) - 1)\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\utils\\input_fn_builder.py\", line 182, in cond_on_index\r\n    return fn(cur_idx)\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\utils\\model_builder.py\", line 132, in nth_model\r\n    features, skip=(skipping_is_on and skip_this_one))\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\utils\\t2t_model.py\", line 598, in model_fn\r\n    sharded_logits, sharded_features[\"targets\"], dp)\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\utils\\modality.py\", line 161, in loss_sharded\r\n    self.loss, sharded_top_out, sharded_targets)\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\utils\\expert_utils.py\", line 222, in __call__\r\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\utils\\modality.py\", line 156, in loss\r\n    weights_fn=weights_fn)\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\layers\\common_layers.py\", line 1473, in padded_cross_entropy\r\n    confidence)\r\n  File \"C:\\Users\\smcdu\\git\\tensor2tensor\\tensor2tensor\\layers\\common_layers.py\", line 1521, in smoothing_cross_entropy\r\n    logits=logits, labels=soft_targets)\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1597, in softmax_cross_entropy_with_logits\r\n    precise_logits, labels, name=name)\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 2385, in _softmax_cross_entropy_with_logits\r\n    features=features, labels=labels, name=name)\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"C:\\Users\\smcdu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nResourceExhaustedError (see above for traceback): Ran out of GPU memory when allocating 329294592 bytes for \r\n\t [[Node: symbol_modality_21472_512_2/parallel_0_1/symbol_modality_21472_512/padded_cross_entropy/smoothing_cross_entropy/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](symbol_modality_21472_512_2/parallel_0_1/symbol_modality_21472_512/padded_cross_entropy/smoothing_cross_entropy/Reshape, symbol_modality_21472_512_2/parallel_0_1/symbol_modality_21472_512/padded_cross_entropy/smoothing_cross_entropy/Reshape_1)]]\r\n\t [[Node: total_loss/_5453 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_23728_total_loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\n2017-11-04 07:22:21.186625: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\event.cc:33] error destroying CUDA event in context 000001E6F21B9320: CUDA_ERROR_ILLEGAL_ADDRESS\r\n", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/401/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/401/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/326", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/326/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/326/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/326/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/326", "id": 261812282, "node_id": "MDU6SXNzdWUyNjE4MTIyODI=", "number": 326, "title": "Decoding did not generate any output", "user": {"login": "flynnwang", "id": 1442332, "node_id": "MDQ6VXNlcjE0NDIzMzI=", "avatar_url": "https://avatars.githubusercontent.com/u/1442332?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flynnwang", "html_url": "https://github.com/flynnwang", "followers_url": "https://api.github.com/users/flynnwang/followers", "following_url": "https://api.github.com/users/flynnwang/following{/other_user}", "gists_url": "https://api.github.com/users/flynnwang/gists{/gist_id}", "starred_url": "https://api.github.com/users/flynnwang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flynnwang/subscriptions", "organizations_url": "https://api.github.com/users/flynnwang/orgs", "repos_url": "https://api.github.com/users/flynnwang/repos", "events_url": "https://api.github.com/users/flynnwang/events{/privacy}", "received_events_url": "https://api.github.com/users/flynnwang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-09-30T02:52:09Z", "updated_at": "2017-12-18T02:17:27Z", "closed_at": "2017-12-18T02:17:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi there,\r\n\r\nI am trying to use transformer model for a text summarization task. the training seems go well, but decoding did not give me any output. \r\n\r\nthe problem definition and Tensorboard results is at [this gist url](https://gist.github.com/flynnwang/7cb2813df8a106cd5b2e77105d114f15).\r\n\r\nand my command for training and decoding:\r\n\r\nfor training:\r\n`\r\nt2t-trainer --generate_data --train_steps=35000 --eval_steps=1000 --save_checkpoints_secs=3600 --keep_checkpoint_max=10 --t2t_usr_dir=~/problem/src --data_dir=~/problem/data --problems=my_problem --model=transformer --hparams_set=transformer_my_problem _hparams_set --output_dir=~/problem/out\r\n`\r\n\r\nfor decoding:\r\n`\r\nt2t-decoder --t2t_usr_dir=~/problem/src --data_dir=~/problem/data --problems=my_problem --model=transformer --hparams_set=transformer_my_problem_hparams_set --output_dir=~/problem/out --decode_hparams=\"beam_size=4,alpha=0.6\" --decode_from_file=/home/flynn/problem/data/dev.src\r\n`\r\n\r\nI'm sure there is not empty target in my training data. So the empty output for all the decoding file is not expected. Please help me if you see anything wrong. Thanks!", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/326/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/326/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/272", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/272/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/272/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/272/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/272", "id": 254685769, "node_id": "MDU6SXNzdWUyNTQ2ODU3Njk=", "number": 272, "title": "ptb10k error", "user": {"login": "vince62s", "id": 15141326, "node_id": "MDQ6VXNlcjE1MTQxMzI2", "avatar_url": "https://avatars.githubusercontent.com/u/15141326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vince62s", "html_url": "https://github.com/vince62s", "followers_url": "https://api.github.com/users/vince62s/followers", "following_url": "https://api.github.com/users/vince62s/following{/other_user}", "gists_url": "https://api.github.com/users/vince62s/gists{/gist_id}", "starred_url": "https://api.github.com/users/vince62s/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vince62s/subscriptions", "organizations_url": "https://api.github.com/users/vince62s/orgs", "repos_url": "https://api.github.com/users/vince62s/repos", "events_url": "https://api.github.com/users/vince62s/events{/privacy}", "received_events_url": "https://api.github.com/users/vince62s/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-09-01T16:06:34Z", "updated_at": "2018-03-08T19:54:35Z", "closed_at": "2017-11-14T00:38:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "From the pip install.\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/t2t-trainer\", line 87, in <module>\r\n    tf.app.run()\r\n  File \"/home/moses/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/usr/local/bin/t2t-trainer\", line 74, in main\r\n    problem.generate_data(data_dir, tmp_dir)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py\", line 419, in generate_data\r\n    self.generator(data_dir, tmp_dir, False), dev_paths)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/generator_utils.py\", line 465, in generate_dataset_and_shuffle\r\n    generate_files(train_gen, train_paths)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/generator_utils.py\", line 143, in generate_files\r\n    for case in generator:\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/ptb.py\", line 155, in _generator\r\n    tok = encoder.encode(line)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/text_encoder.py\", line 199, in encode\r\n    ret = [self._token_to_id[tok] for tok in tokens]\r\nKeyError: '<EOS>'\r\n", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/272/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/272/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/266", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/266/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/266/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/266/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/266", "id": 254168774, "node_id": "MDU6SXNzdWUyNTQxNjg3NzQ=", "number": 266, "title": "Evaluation failed when training with multiple work gpus", "user": {"login": "skyw", "id": 1697840, "node_id": "MDQ6VXNlcjE2OTc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/1697840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skyw", "html_url": "https://github.com/skyw", "followers_url": "https://api.github.com/users/skyw/followers", "following_url": "https://api.github.com/users/skyw/following{/other_user}", "gists_url": "https://api.github.com/users/skyw/gists{/gist_id}", "starred_url": "https://api.github.com/users/skyw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skyw/subscriptions", "organizations_url": "https://api.github.com/users/skyw/orgs", "repos_url": "https://api.github.com/users/skyw/repos", "events_url": "https://api.github.com/users/skyw/events{/privacy}", "received_events_url": "https://api.github.com/users/skyw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 38, "created_at": "2017-08-30T23:53:29Z", "updated_at": "2019-01-26T20:33:17Z", "closed_at": "2017-12-22T16:21:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "I set worker_gpu to 2 and use 2 gpus in the same node. training is completely fine. But evaluation fails with this error\r\n\"\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Number of ways to split should evenly divide the split dimension, but got split_dim 0 (size = 47) and num_split 2\r\n         [[Node: split_2 = Split[T=DT_INT32, num_split=2, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](split_2/split_dim, input_reader/ExpandDims_3/_1823)]]\r\n         [[Node: split_2/_1825 = _HostRecv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:1\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_1113_split_2\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:1\"]()]]\r\n\r\nCaused by op u'split_2', defined at:\r\n  File \"/raid/skyw/venv/tensorflow-pip-py27/bin/t2t-trainer\", line 5, in <module>\r\n    pkg_resources.run_script('tensor2tensor==1.2.1', 't2t-trainer')\r\n\"\r\n\r\nIt wasn't very clear what the error is. But single GPU training/evaluation is fine, the problem comes with 2 worker GPUs.", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/266/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/266/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/121", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/121/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/121/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/121/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/121", "id": 241613353, "node_id": "MDU6SXNzdWUyNDE2MTMzNTM=", "number": 121, "title": "why the results of the evaluation are all zero?", "user": {"login": "ZhenYangIACAS", "id": 13463269, "node_id": "MDQ6VXNlcjEzNDYzMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/13463269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZhenYangIACAS", "html_url": "https://github.com/ZhenYangIACAS", "followers_url": "https://api.github.com/users/ZhenYangIACAS/followers", "following_url": "https://api.github.com/users/ZhenYangIACAS/following{/other_user}", "gists_url": "https://api.github.com/users/ZhenYangIACAS/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZhenYangIACAS/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZhenYangIACAS/subscriptions", "organizations_url": "https://api.github.com/users/ZhenYangIACAS/orgs", "repos_url": "https://api.github.com/users/ZhenYangIACAS/repos", "events_url": "https://api.github.com/users/ZhenYangIACAS/events{/privacy}", "received_events_url": "https://api.github.com/users/ZhenYangIACAS/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 627478123, "node_id": "MDU6TGFiZWw2Mjc0NzgxMjM=", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 25, "created_at": "2017-07-10T06:38:11Z", "updated_at": "2019-10-18T13:12:35Z", "closed_at": "2017-11-14T00:36:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Why the results of the evaluation are all zero?\r\n\r\nINFO:tensorflow:Saving dict for global step 7724: global_step = 7724, loss = 0.0, metrics-wmt_ende_bpe32k/accuracy = 0.0, metrics-wmt_ende_bpe32k/accuracy_per_sequence = 0.0, metrics-wmt_ende_bpe32k/accuracy_top5 = 0.0, metrics-wmt_ende_bpe32k/approx_bleu_score = 0.0, metrics-wmt_ende_bpe32k/neg_log_perplexity = 0.0, metrics/accuracy = 0.0, metrics/accuracy_per_sequence = 0.0, metrics/accuracy_top5 = 0.0, metrics/approx_bleu_score = 0.0, metrics/neg_log_perplexity = 0.0\r\nINFO:tensorflow:Validation (step 8000): loss = 0.0, metrics-wmt_ende_bpe32k/accuracy_per_sequence = 0.0, global_step = 7724, metrics/neg_log_perplexity = 0.0, metrics-wmt_ende_bpe32k/accuracy = 0.0, metrics-wmt_ende_bpe32k/accuracy_top5 = 0.0, metrics-wmt_ende_bpe32k/neg_log_perplexity = 0.0, metrics/accuracy = 0.0, metrics/approx_bleu_score = 0.0, metrics-wmt_ende_bpe32k/approx_bleu_score = 0.0, metrics/accuracy_per_sequence = 0.0, metrics/accuracy_top5 = 0.0\r\n", "reactions": {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/121/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/121/timeline", "performed_via_github_app": null, "state_reason": "completed"}]