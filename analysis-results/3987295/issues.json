[{"url": "https://api.github.com/repos/allenai/allennlp/issues/5732", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5732/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5732/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5732/events", "html_url": "https://github.com/allenai/allennlp/issues/5732", "id": 1449390363, "node_id": "I_kwDOBXH8-M5WY_Eb", "number": 5732, "title": "When 'instances_per_epoch' is set up in the class MultiTaskDataLoader,  the function __len__ in it will return a wrong answer.", "user": {"login": "wsmgh", "id": 38832437, "node_id": "MDQ6VXNlcjM4ODMyNDM3", "avatar_url": "https://avatars.githubusercontent.com/u/38832437?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wsmgh", "html_url": "https://github.com/wsmgh", "followers_url": "https://api.github.com/users/wsmgh/followers", "following_url": "https://api.github.com/users/wsmgh/following{/other_user}", "gists_url": "https://api.github.com/users/wsmgh/gists{/gist_id}", "starred_url": "https://api.github.com/users/wsmgh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wsmgh/subscriptions", "organizations_url": "https://api.github.com/users/wsmgh/orgs", "repos_url": "https://api.github.com/users/wsmgh/repos", "events_url": "https://api.github.com/users/wsmgh/events{/privacy}", "received_events_url": "https://api.github.com/users/wsmgh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-11-15T08:42:13Z", "updated_at": "2022-11-29T16:09:47Z", "closed_at": "2022-11-29T16:09:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ ] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [ ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ ] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nWhen i perform multi-task learning with allennlp, i config the MultiTaskDataLoader as following:\r\n![image](https://user-images.githubusercontent.com/38832437/201865220-dfe9edb0-dc33-4eac-83dc-40c4df9f690b.png)\r\nI set 'instances_per_epoch' to 8000 and 'batch_size' to 16. I expect that there are about 500 steps in an epoch. However, when i run my codes, the process bar shows that there are 3000 steps. But actully, there isn't that much. After 502 steps, the epoch completed.\r\n![image](https://user-images.githubusercontent.com/38832437/201870292-7812ab99-3d1c-4412-852c-5fab9847a4b2.png)\r\n\r\n\r\nAfter checking, i find that the following codes in MultiTaskDataLoader is wrong:\r\n![image](https://user-images.githubusercontent.com/38832437/201864157-6c9b0a68-7c56-499e-b1d6-5f05cf590e49.png)\r\n\r\n\r\nFrom the \\_\\_init\\_\\_ function in MultiTaskDataLoader, we can know that when 'instances_per_epoch' is set, the sampler will also be provided.\r\n![image](https://user-images.githubusercontent.com/38832437/201859654-154b0daa-64cd-4e62-aeea-85069bdc1f4f.png)\r\n\r\nSo, when we count instances for each dataset, we should take into consideration the  proportion of each dataset provided by the sampler. Thus, the aforementioned wrong codes should be replaced by the following codes:\r\n![image](https://user-images.githubusercontent.com/38832437/201863974-827f11a0-d1ed-4891-8361-8d63168c412e.png)\r\n\r\nHere is the codes:\r\n`\r\n\r\n        dataset_proportions = self.sampler.get_task_proportions(self._loaders)\r\n\r\n        proportion_sum = sum(dataset_proportions.values())\r\n\r\n        num_instances_per_dataset = {\r\n\r\n            key: math.floor(proportion * self._instances_per_epoch / proportion_sum)\r\n\r\n            for key, proportion in dataset_proportions.items()\r\n\r\n        }\r\n\r\n\r\n`\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.13\r\nAllennlp version: 2.10.1\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5732/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5732/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5731", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5731/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5731/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5731/events", "html_url": "https://github.com/allenai/allennlp/issues/5731", "id": 1440213713, "node_id": "I_kwDOBXH8-M5V1-rR", "number": 5731, "title": "AutoTokenizer config error when load clipmodel", "user": {"login": "Suluo", "id": 18359714, "node_id": "MDQ6VXNlcjE4MzU5NzE0", "avatar_url": "https://avatars.githubusercontent.com/u/18359714?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Suluo", "html_url": "https://github.com/Suluo", "followers_url": "https://api.github.com/users/Suluo/followers", "following_url": "https://api.github.com/users/Suluo/following{/other_user}", "gists_url": "https://api.github.com/users/Suluo/gists{/gist_id}", "starred_url": "https://api.github.com/users/Suluo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Suluo/subscriptions", "organizations_url": "https://api.github.com/users/Suluo/orgs", "repos_url": "https://api.github.com/users/Suluo/repos", "events_url": "https://api.github.com/users/Suluo/events{/privacy}", "received_events_url": "https://api.github.com/users/Suluo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-11-08T13:32:26Z", "updated_at": "2022-11-23T16:10:27Z", "closed_at": "2022-11-23T16:10:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "Load CLIPModel \uff08openai/clip-vit-base-patch32\uff09\r\n\r\nraise error \r\n  File \"/opt/conda/lib/python3.9/site-packages/allennlp/modules/token_embedders/pretrained_transformer_embedder.py\", line 125, in __init__\r\n    self.output_dim = self.config.hidden_size\r\n  File \"/opt/conda/lib/python3.9/site-packages/transformers/configuration_utils.py\", line 253, in __getattribute__\r\n    return super().__getattribute__(key)\r\nAttributeError: 'CLIPConfig' object has no attribute 'hidden_size'", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5731/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5731/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5723", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5723/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5723/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5723/events", "html_url": "https://github.com/allenai/allennlp/issues/5723", "id": 1416307264, "node_id": "I_kwDOBXH8-M5UayJA", "number": 5723, "title": "Is it possible to load my own quantized model from local", "user": {"login": "pradeepdev-1995", "id": 41164884, "node_id": "MDQ6VXNlcjQxMTY0ODg0", "avatar_url": "https://avatars.githubusercontent.com/u/41164884?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pradeepdev-1995", "html_url": "https://github.com/pradeepdev-1995", "followers_url": "https://api.github.com/users/pradeepdev-1995/followers", "following_url": "https://api.github.com/users/pradeepdev-1995/following{/other_user}", "gists_url": "https://api.github.com/users/pradeepdev-1995/gists{/gist_id}", "starred_url": "https://api.github.com/users/pradeepdev-1995/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pradeepdev-1995/subscriptions", "organizations_url": "https://api.github.com/users/pradeepdev-1995/orgs", "repos_url": "https://api.github.com/users/pradeepdev-1995/repos", "events_url": "https://api.github.com/users/pradeepdev-1995/events{/privacy}", "received_events_url": "https://api.github.com/users/pradeepdev-1995/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2022-10-20T09:45:15Z", "updated_at": "2022-11-04T10:44:52Z", "closed_at": "2022-10-21T00:52:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "Here is the code I tried for the coreference resolution\r\n```\r\nfrom allennlp.predictors.predictor import Predictor\r\nmodel_url = 'https://storage.googleapis.com/pandora-intelligence/models/crosslingual-coreference/minilm/model.tar.gz'\r\npredictor = Predictor.from_path(model_url)  \r\ntext = \"Eva and Martha didn't want their friend Jenny \\\r\n    to feel lonely so they invited her to the party.\"\r\nprediction = predictor.predict(document=text)  \r\nprint(prediction['clusters'])  \r\nprint(predictor.coref_resolved(text))  \r\n```\r\nAnd it worked well I got the output with solved coreference. like below\r\n```\r\nEva and Martha didn't want Eva and Martha's friend Jenny     to feel lonely so Eva and Martha invited their friend Jenny to the party.\r\n```\r\nNow I have quantized the model used here (https://storage.googleapis.com/pandora-intelligence/models/crosslingual-coreference/minilm/model.tar.gz) and the new quantized model is stored in a specific path in my local machine.\r\n\r\nShall I use that customized(quantized) model from my local path in model_url value and use this prediction command like below?\r\n```\r\nmodel_url = <Path to the quantized model in my local machine>\r\npredictor = Predictor.from_path(model_url)  \r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5723/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5723/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5718", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5718/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5718/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5718/events", "html_url": "https://github.com/allenai/allennlp/issues/5718", "id": 1403772329, "node_id": "I_kwDOBXH8-M5Tq92p", "number": 5718, "title": "Can't load models with .zip extension", "user": {"login": "serenalotreck", "id": 41377532, "node_id": "MDQ6VXNlcjQxMzc3NTMy", "avatar_url": "https://avatars.githubusercontent.com/u/41377532?v=4", "gravatar_id": "", "url": "https://api.github.com/users/serenalotreck", "html_url": "https://github.com/serenalotreck", "followers_url": "https://api.github.com/users/serenalotreck/followers", "following_url": "https://api.github.com/users/serenalotreck/following{/other_user}", "gists_url": "https://api.github.com/users/serenalotreck/gists{/gist_id}", "starred_url": "https://api.github.com/users/serenalotreck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/serenalotreck/subscriptions", "organizations_url": "https://api.github.com/users/serenalotreck/orgs", "repos_url": "https://api.github.com/users/serenalotreck/repos", "events_url": "https://api.github.com/users/serenalotreck/events{/privacy}", "received_events_url": "https://api.github.com/users/serenalotreck/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2022-10-10T22:27:29Z", "updated_at": "2022-10-17T21:39:10Z", "closed_at": "2022-10-17T21:39:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [X] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [X] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [X] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [X] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [X] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [X] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [X] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [X] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [X] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [X] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nWhen using the Python API to import a pretrained model that has the extension `.zip`, fails due to \"r:gz\" specified [here](https://github.com/allenai/allennlp/blob/9f879b0964e035db711e018e8099863128b4a46f/allennlp/models/archival.py#L301). Models in question are from the [PURE repository](https://github.com/princeton-nlp/PURE#Pre-trained-Models). \r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n---------------------------------------------------------------------------\r\nOSError                                   Traceback (most recent call last)\r\n~/anaconda3/envs/dygiepp/lib/python3.7/tarfile.py in gzopen(cls, name, mode, fileobj, compresslevel, **kwargs)\r\n   1645         try:\r\n-> 1646             t = cls.taropen(name, mode, fileobj, **kwargs)\r\n   1647         except OSError:\r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/tarfile.py in taropen(cls, name, mode, fileobj, **kwargs)\r\n   1622             raise ValueError(\"mode must be 'r', 'a', 'w' or 'x'\")\r\n-> 1623         return cls(name, mode, fileobj, **kwargs)\r\n   1624 \r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/tarfile.py in __init__(self, name, mode, fileobj, format, tarinfo, dereference, ignore_zeros, encoding, errors, pax_headers, debug, errorlevel, copybufsize)\r\n   1485                 self.firstmember = None\r\n-> 1486                 self.firstmember = self.next()\r\n   1487 \r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/tarfile.py in next(self)\r\n   2288             try:\r\n-> 2289                 tarinfo = self.tarinfo.fromtarfile(self)\r\n   2290             except EOFHeaderError as e:\r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/tarfile.py in fromtarfile(cls, tarfile)\r\n   1093         \"\"\"\r\n-> 1094         buf = tarfile.fileobj.read(BLOCKSIZE)\r\n   1095         obj = cls.frombuf(buf, tarfile.encoding, tarfile.errors)\r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/gzip.py in read(self, size)\r\n    286             raise OSError(errno.EBADF, \"read() on write-only GzipFile object\")\r\n--> 287         return self._buffer.read(size)\r\n    288 \r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/_compression.py in readinto(self, b)\r\n     67         with memoryview(b) as view, view.cast(\"B\") as byte_view:\r\n---> 68             data = self.read(len(byte_view))\r\n     69             byte_view[:len(data)] = data\r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/gzip.py in read(self, size)\r\n    473                 self._init_read()\r\n--> 474                 if not self._read_gzip_header():\r\n    475                     self._size = self._pos\r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/gzip.py in _read_gzip_header(self)\r\n    421         if magic != b'\\037\\213':\r\n--> 422             raise OSError('Not a gzipped file (%r)' % magic)\r\n    423 \r\n\r\nOSError: Not a gzipped file (b'PK')\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nReadError                                 Traceback (most recent call last)\r\n/tmp/local/63761026/ipykernel_27406/2934808558.py in <module>\r\n----> 1 scierc_pure = Model.from_archive('https://nlp.cs.princeton.edu/projects/pure/scierc_models/ent-scib-ctx300.zip')\r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/site-packages/allennlp/models/model.py in from_archive(cls, archive_file, vocab)\r\n    480         from allennlp.models.archival import load_archive  # here to avoid circular imports\r\n    481 \r\n--> 482         model = load_archive(archive_file).model\r\n    483         if vocab:\r\n    484             model.vocab.extend_from_vocab(vocab)\r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/site-packages/allennlp/models/archival.py in load_archive(archive_file, cuda_device, overrides, weights_file)\r\n    218             serialization_dir = resolved_archive_file\r\n    219         else:\r\n--> 220             with extracted_archive(resolved_archive_file, cleanup=False) as tempdir:\r\n    221                 serialization_dir = tempdir\r\n    222 \r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/contextlib.py in __enter__(self)\r\n    110         del self.args, self.kwds, self.func\r\n    111         try:\r\n--> 112             return next(self.gen)\r\n    113         except StopIteration:\r\n    114             raise RuntimeError(\"generator didn't yield\") from None\r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/site-packages/allennlp/models/archival.py in extracted_archive(resolved_archive_file, cleanup)\r\n    299         tempdir = tempfile.mkdtemp()\r\n    300         logger.info(f\"extracting archive file {resolved_archive_file} to temp dir {tempdir}\")\r\n--> 301         with tarfile.open(resolved_archive_file, \"r:gz\") as archive:\r\n    302             archive.extractall(tempdir)\r\n    303         yield tempdir\r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/tarfile.py in open(cls, name, mode, fileobj, bufsize, **kwargs)\r\n   1591             else:\r\n   1592                 raise CompressionError(\"unknown compression type %r\" % comptype)\r\n-> 1593             return func(name, filemode, fileobj, **kwargs)\r\n   1594 \r\n   1595         elif \"|\" in mode:\r\n\r\n~/anaconda3/envs/dygiepp/lib/python3.7/tarfile.py in gzopen(cls, name, mode, fileobj, compresslevel, **kwargs)\r\n   1648             fileobj.close()\r\n   1649             if mode == 'r':\r\n-> 1650                 raise ReadError(\"not a gzip file\")\r\n   1651             raise\r\n   1652         except:\r\n\r\nReadError: not a gzip file\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\nCentOS Linux release 7.9.2009\r\nLinux Kernel 3.10.0-1160.36.2.el7.x86_64\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\nPython 3.6.4\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.5.0\r\nalabaster==0.7.12\r\nalembic==1.7.5\r\nallennlp==1.1.0\r\nallennlp-models==1.1.0\r\nanyio==3.6.1\r\nappdirs==1.4.3\r\nargon2-cffi==21.3.0\r\nargon2-cffi-bindings==21.2.0\r\nartemis==0.1.4\r\nase==3.17.0\r\nasn1crypto==0.24.0\r\nastor==0.7.1\r\natomicwrites==1.3.0\r\nattrs==19.1.0\r\nautopage==0.4.0\r\nawscli==1.18.75\r\nBabel==2.9.1\r\nbackcall==0.1.0\r\nbackports.csv==1.0.7\r\nbcrypt==3.1.4\r\nbeartype==0.3.2\r\nbeautifulsoup4==4.8.1\r\nbiom-format==2.1.7\r\nbiopython==1.72\r\nbitstring==3.1.5\r\nbleach==3.1.4\r\nblessings==1.7\r\nblis==0.4.1\r\nblist==1.3.6\r\nbokeh==2.3.2\r\nBoltzTraP2==20.7.1\r\nboto3==1.20.20\r\nbotocore==1.23.20\r\nbrewer2mpl==1.4.1\r\nBUSCO==3.1.0\r\nbz2file==0.98\r\ncachetools==4.2.2\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi==1.14.3\r\ncftime==1.3.1\r\nchardet==3.0.4\r\ncharset-normalizer==2.0.12\r\nchecksumdir==1.2.0\r\ncli-helpers==0.2.3\r\nclick==7.1.2\r\ncliff==3.10.0\r\ncmaes==0.8.2\r\ncmd2==2.3.3\r\ncolorama==0.4.3\r\ncolored==1.4.2\r\ncolorlog==6.6.0\r\ncommonmark==0.9.1\r\nconfigobj==5.0.6\r\nconllu==4.1\r\ncontextvars==2.4\r\ncryptography==2.1.4\r\ncss-html-js-minify==2.5.5\r\ncupy-cuda100==6.0.0\r\ncutadapt==3.7\r\ncycler==0.10.0\r\ncymem==2.0.3\r\nCython==0.27.3\r\ndataclasses==0.8\r\ndeap==1.2.2\r\ndecorator==4.4.2\r\ndeepTools==3.1.3\r\ndefusedxml==0.6.0\r\ndeprecation==2.1.0\r\ndnaio==0.7.1\r\ndocopt==0.6.2\r\ndocutils==0.14\r\ndoqu==0.28.2\r\necdsa==0.13\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nentrypoints==0.3\r\nenum34==1.1.10\r\nfastrlock==0.4\r\nfilelock==3.0.12\r\nFlask==1.0.3\r\nForthon==0.8.49\r\nfrozenlist==1.2.0\r\nftfy==6.0.3\r\nfuture==0.16.0\r\ngast==0.2.0\r\nghp-import==2.0.2\r\ngit-filter-repo==2.34.0\r\ngitdb==4.0.9\r\nGitPython==3.1.18\r\nglobus-cli==2.1.0\r\nglobus-sdk==2.0.1\r\ngoogle-auth==1.32.1\r\ngpustat==0.5.0\r\ngreenlet==1.1.2\r\nGridDataFormats==0.5.0\r\ngrpcio==1.15.0\r\ngudhi==3.4.1.post1\r\ngurobipy==8.0.1\r\nh5py==2.8.0\r\nHTSeq==0.12.4\r\nhuggingface-hub==0.4.0\r\nhumanize==3.4.1\r\nidna==2.10\r\nidr==2.0.2\r\nimagesize==1.1.0\r\niminuit==2.4.0\r\nimmutables==0.19\r\nimportlib-metadata==4.8.2\r\nimportlib-resources==5.4.0\r\nintervaltree==3.0.2\r\nipykernel==5.2.1\r\nipython==7.2.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\nisal==0.11.1\r\nitsdangerous==1.1.0\r\njedi==0.13.1\r\nJinja2==3.0.3\r\njmespath==0.10.0\r\njoblib==0.17.0\r\njson5==0.9.10\r\njsonnet==0.17.0\r\njsonpickle==2.0.0\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==7.0.6\r\njupyter-console==6.1.0\r\njupyter-core==4.8.1\r\njupyter-server==1.13.1\r\njupyterlab==3.2.9\r\njupyterlab-server==2.10.3\r\nkaleido==0.0.3.post1\r\nkiwisolver==1.0.1\r\nlapels==1.1.1\r\nliac-arff==2.1.1\r\nllvmlite==0.36.0\r\nlxml==4.6.4\r\nMako==1.1.6\r\nmappy==2.20\r\nMarkdown==3.3.6\r\nMarkupSafe==2.0.1\r\nmatlabengineforpython===R2019b\r\nmatplotlib==3.3.2\r\nmatplotlib-venn==0.11.5\r\nmergedeep==1.3.4\r\nMicrobeCensus==1.1.0\r\nmisopy==0.5.4\r\nmistune==0.8.4\r\nmkdocs==1.2.3\r\nmkdocs-git-revision-date-localized-plugin==0.11.1\r\nmkdocs-material==8.1.7\r\nmkdocs-material-extensions==1.0.3\r\nmkdocs-redirects==1.0.4\r\nmmtf-python==1.1.2\r\nmock==2.0.0\r\nmodtools==1.0.2\r\nmore-itertools==6.0.0\r\nmpi4py==3.0.0\r\nmsgpack==1.0.0\r\nmultidict==5.2.0\r\nmurmurhash==1.0.2\r\nNanoComp==1.15.0\r\nNanoFilt==2.7.1\r\nnanoget==1.15.0\r\nNanoLyse==1.2.0\r\nnanomath==1.0.1\r\nnanopack==1.1.0\r\nNanoPlot==1.38.0\r\nnanoQC==0.9.4\r\nNanoStat==1.5.0\r\nnatsort==7.1.1\r\nnbclassic==0.3.5\r\nnbconvert==5.6.1\r\nnbformat==4.4.0\r\nncbi-genome-download==0.2.9\r\nnest-asyncio==1.5.1\r\nnetaddr==0.7.19\r\nnetCDF4==1.5.5.1\r\nnetifaces==0.10.6\r\nnetworkx==2.5\r\nnltk==3.6.5\r\nnmslib==2.0.6\r\nnose==1.3.7\r\nnotebook==6.0.3\r\nnumba==0.53.1\r\nnumpy==1.19.2\r\nnumpydoc==0.8.0\r\nnvidia-ml-py3==7.352.0\r\noauthlib==3.1.1\r\nopencv-python==4.4.0.44\r\noptuna==2.10.0\r\noverrides==3.1.0\r\npackaging==21.3\r\npandas==0.25.2\r\npandocfilters==1.4.2\r\nparamiko==2.4.0\r\nparso==0.3.1\r\npauvre==0.2\r\npaycheck==1.0.2\r\npbr==3.1.1\r\npexpect==4.6.0\r\npickleshare==0.7.5\r\nPillow==7.2.0\r\nplac==1.1.3\r\nplotly==4.10.0\r\npluggy==0.9.0\r\npreshed==3.0.2\r\nprettytable==2.4.0\r\nprometheus-client==0.7.1\r\nprompt-toolkit==2.0.7\r\nprotobuf==3.17.3\r\npsutil==5.6.1\r\nptyprocess==0.6.0\r\npy==1.8.0\r\npy-enigma==0.1\r\npy-rouge==1.1\r\npy2bit==0.3.0\r\npyarrow==1.0.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npybedtools==0.8.0\r\npyBigWig==0.3.12\r\npybind11==2.5.0\r\npycairo==1.19.1\r\npycparser==2.20\r\npycrypto==2.6.1\r\npygist==2.2.0\r\nPygments==2.11.2\r\nPyJWT==1.7.1\r\npymdown-extensions==9.1\r\nPyNaCl==1.2.1\r\npyparsing==2.2.0\r\npyperclip==1.8.2\r\npyrsistent==0.18.0\r\npysam==0.15.1\r\npysbd==0.2.3\r\npytest==4.3.1\r\npython-dateutil==2.8.1\r\nPython-Deprecated==1.1.0\r\npython-igraph==0.8.0\r\npython-Levenshtein==0.12.2\r\npython-magic==0.4.18\r\npytz==2017.3\r\nPyYAML==5.3.1\r\npyyaml_env_tag==0.1\r\npyzmq==19.0.0\r\nqtconsole==4.7.3\r\nQtPy==1.9.0\r\nregex==2021.11.10\r\nrequests==2.25.1\r\nrequests-oauthlib==1.3.0\r\nretrying==1.3.3\r\nrich==9.13.0\r\nrsa==3.4.2\r\ns3cmd==2.1.0\r\ns3transfer==0.5.0\r\nsacremoses==0.0.46\r\nschematics==2.1.0\r\nscikit-learn==0.23.1\r\nscipy==1.5.4\r\nscispacy==0.2.4\r\nscreed==1.0\r\nseaborn==0.10.1\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.96\r\nseqmagick==0.7.0\r\nsix==1.16.0\r\nslurm-gpustat==0.0.7\r\nsmmap==5.0.0\r\nsniffio==1.2.0\r\nsnowballstemmer==1.2.1\r\nsortedcontainers==2.1.0\r\nsoupsieve==2.3.1\r\nsourmash==3.5.0\r\nspacy==2.3.7\r\nspglib==1.16.0\r\nSphinx==1.8.3\r\nsphinxcontrib-websupport==1.1.0\r\nSQLAlchemy==1.4.27\r\nsqlparse==0.2.4\r\nsrsly==1.0.2\r\nstatistics==1.0.3.5\r\nstevedore==3.5.0\r\nsuspenders==0.2.6\r\ntensorboard==1.10.0\r\ntensorboard-plugin-wit==1.8.0\r\ntensorboardX==2.4.1\r\ntensorflow==1.10.1\r\ntermcolor==1.1.0\r\nterminado==0.8.3\r\nterminaltables==3.1.0\r\ntestpath==0.4.4\r\ntexttable==1.6.2\r\nTheano==1.0.3\r\nthinc==7.4.5\r\nthreadpoolctl==2.1.0\r\ntigmint==1.1.2\r\ntinydb==3.13.0\r\ntokenizers==0.8.1rc1\r\ntorch==1.6.0\r\ntorchvision==0.8.2\r\ntornado==6.1\r\ntqdm==4.46.1\r\ntraitlets==4.3.2\r\ntransformers==3.0.2\r\ntrash-cli==0.17.1.14.post0\r\ntyping-extensions==3.7.4.3\r\numi-tools==1.0.0\r\nurllib3==1.26.7\r\nvirtualenv==15.1.0\r\nwasabi==0.6.0\r\nwatchdog==2.1.6\r\nwcwidth==0.1.7\r\nwebencodings==0.5.1\r\nwebsocket-client==1.3.1\r\nWerkzeug==0.14.1\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nxopen==1.4.0\r\nyapf==0.31.0\r\nyarl==1.7.2\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp.models.model import Model\r\nscierc_pure = Model.from_archive('https://nlp.cs.princeton.edu/projects/pure/scierc_models/ent-scib-ctx300.zip')\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5718/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5718/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5717", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5717/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5717/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5717/events", "html_url": "https://github.com/allenai/allennlp/issues/5717", "id": 1401739075, "node_id": "I_kwDOBXH8-M5TjNdD", "number": 5717, "title": "Unclear how to use text2sql model", "user": {"login": "ianbstewart", "id": 1302835, "node_id": "MDQ6VXNlcjEzMDI4MzU=", "avatar_url": "https://avatars.githubusercontent.com/u/1302835?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ianbstewart", "html_url": "https://github.com/ianbstewart", "followers_url": "https://api.github.com/users/ianbstewart/followers", "following_url": "https://api.github.com/users/ianbstewart/following{/other_user}", "gists_url": "https://api.github.com/users/ianbstewart/gists{/gist_id}", "starred_url": "https://api.github.com/users/ianbstewart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ianbstewart/subscriptions", "organizations_url": "https://api.github.com/users/ianbstewart/orgs", "repos_url": "https://api.github.com/users/ianbstewart/repos", "events_url": "https://api.github.com/users/ianbstewart/events{/privacy}", "received_events_url": "https://api.github.com/users/ianbstewart/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2022-10-07T23:19:55Z", "updated_at": "2022-11-23T01:20:28Z", "closed_at": "2022-11-23T01:20:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nI am able to load the text2sql model as follows:\r\n\r\n```\r\nfrom allennlp_models import pretrained\r\nSQL_model_name = 'semparse-text-to-sql'\r\npred_model = pretrained.load_predictor(SQL_model_name)\r\n```\r\n\r\nHowever, the model doesn't appear to allow predictions, since the `predict` method isn't implemented (as compared to other AllenNLP models where `predict` works as expected). Am I using the model incorrectly?\r\n\r\nTraceback:\r\n```\r\n$pred_model.predict('what is the temperature in Berlin?')\r\nAttributeError                            Traceback (most recent call last)\r\n----> 1 pred.predict\r\nAttributeError: 'Predictor' object has no attribute 'predict'\r\n```\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux? (Colab)\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==1.2.0\r\naeppl==0.0.33\r\naesara==2.7.9\r\naiohttp==3.8.3\r\naiosignal==1.2.0\r\nalabaster==0.7.12\r\nalbumentations==1.2.1\r\nallennlp==2.10.0\r\nallennlp-models==2.10.0\r\nallennlp-semparse==0.0.4\r\naltair==4.2.0\r\nappdirs==1.4.4\r\narviz==0.12.1\r\nastor==0.8.1\r\nastropy==4.3.1\r\nastunparse==1.6.3\r\nasync-timeout==4.0.2\r\nasynctest==0.13.0\r\natari-py==0.2.9\r\natomicwrites==1.4.1\r\nattrs==22.1.0\r\naudioread==3.0.0\r\nautograd==1.5\r\nBabel==2.10.3\r\nbackcall==0.2.0\r\nbase58==2.1.1\r\nbeautifulsoup4==4.6.3\r\nbleach==5.0.1\r\nblis==0.7.8\r\nbokeh==2.3.3\r\nboto3==1.24.89\r\nbotocore==1.27.89\r\nbranca==0.5.0\r\nbs4==0.0.1\r\nCacheControl==0.12.11\r\ncached-path==1.1.6\r\ncached-property==1.5.2\r\ncachetools==4.2.4\r\ncatalogue==2.0.8\r\ncertifi==2022.9.24\r\ncffi==1.15.1\r\ncftime==1.6.2\r\nchardet==3.0.4\r\ncharset-normalizer==2.1.1\r\nclick==7.1.2\r\nclikit==0.6.2\r\ncloudpickle==1.5.0\r\ncmake==3.22.6\r\ncmdstanpy==1.0.7\r\ncolorcet==3.0.1\r\ncolorlover==0.3.0\r\ncommonmark==0.9.1\r\ncommunity==1.0.0b1\r\nconfection==0.0.2\r\nconllu==4.4.2\r\ncons==0.4.5\r\ncontextlib2==0.5.5\r\nconvertdate==2.4.0\r\ncrashtest==0.3.1\r\ncrcmod==1.7\r\ncufflinks==0.17.3\r\ncvxopt==1.3.0\r\ncvxpy==1.2.1\r\ncycler==0.11.0\r\ncymem==2.0.6\r\nCython==0.29.32\r\ndaft==0.0.4\r\ndask==2022.2.0\r\ndatascience==0.17.5\r\ndatasets==2.5.2\r\ndebugpy==1.0.0\r\ndecorator==4.4.2\r\ndefusedxml==0.7.1\r\ndescartes==1.1.0\r\ndill==0.3.5.1\r\ndistributed==2022.2.0\r\ndlib==19.24.0\r\ndm-tree==0.1.7\r\ndocker-pycreds==0.4.0\r\ndocutils==0.17.1\r\ndopamine-rl==1.0.5\r\nearthengine-api==0.1.326\r\neasydict==1.10\r\necos==2.0.10\r\neditdistance==0.5.3\r\nen-core-web-lg @ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.0/en_core_web_lg-3.4.0-py3-none-any.whl\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl\r\nentrypoints==0.4\r\nephem==4.1.3\r\net-xmlfile==1.1.0\r\netils==0.8.0\r\netuples==0.3.8\r\nfa2==0.3.5\r\nfairscale==0.4.6\r\nfastai==2.7.9\r\nfastcore==1.5.27\r\nfastdownload==0.0.7\r\nfastdtw==0.3.4\r\nfastjsonschema==2.16.2\r\nfastprogress==1.0.3\r\nfastrlock==0.8\r\nfeather-format==0.4.1\r\nfilelock==3.7.1\r\nfirebase-admin==4.4.0\r\nfix-yahoo-finance==0.0.22\r\nflaky==3.7.0\r\nFlask==1.1.4\r\nflatbuffers==22.9.24\r\nfolium==0.12.1.post1\r\nfrozenlist==1.3.1\r\nfsspec==2022.8.2\r\nftfy==6.1.1\r\nfuture==0.16.0\r\ngast==0.5.3\r\nGDAL==2.2.2\r\ngdown==4.4.0\r\ngensim==3.6.0\r\ngeographiclib==1.52\r\ngeopy==1.17.0\r\ngin-config==0.5.0\r\ngitdb==4.0.9\r\nGitPython==3.1.28\r\nglob2==0.7\r\ngoogle==2.0.3\r\ngoogle-api-core==1.31.6\r\ngoogle-api-python-client==1.12.11\r\ngoogle-auth==1.35.0\r\ngoogle-auth-httplib2==0.0.4\r\ngoogle-auth-oauthlib==0.4.6\r\ngoogle-cloud-bigquery==1.21.0\r\ngoogle-cloud-bigquery-storage==1.1.2\r\ngoogle-cloud-core==2.3.2\r\ngoogle-cloud-datastore==1.8.0\r\ngoogle-cloud-firestore==1.7.0\r\ngoogle-cloud-language==1.2.0\r\ngoogle-cloud-storage==2.5.0\r\ngoogle-cloud-translate==1.5.0\r\ngoogle-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\r\ngoogle-crc32c==1.5.0\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==2.4.0\r\ngoogleapis-common-protos==1.56.4\r\ngoogledrivedownloader==0.4\r\ngraphviz==0.10.1\r\ngreenlet==1.1.3\r\ngrpcio==1.49.1\r\ngspread==3.4.2\r\ngspread-dataframe==3.0.8\r\ngym==0.25.2\r\ngym-notices==0.0.8\r\nh5py==3.7.0\r\nHeapDict==1.0.1\r\nhijri-converter==2.2.4\r\nholidays==0.16\r\nholoviews==1.14.9\r\nhtml5lib==1.0.1\r\nhttpimport==0.5.18\r\nhttplib2==0.17.4\r\nhttplib2shim==0.0.3\r\nhttpstan==4.6.1\r\nhuggingface-hub==0.10.0\r\nhumanize==0.5.1\r\nhyperopt==0.1.2\r\nidna==2.10\r\nimageio==2.9.0\r\nimagesize==1.4.1\r\nimbalanced-learn==0.8.1\r\nimblearn==0.0\r\nimgaug==0.4.0\r\nimportlib-metadata==5.0.0\r\nimportlib-resources==5.9.0\r\nimutils==0.5.4\r\ninflect==2.1.0\r\niniconfig==1.1.1\r\nintel-openmp==2022.2.0\r\nintervaltree==2.1.0\r\nipykernel==5.3.4\r\nipython==7.9.0\r\nipython-genutils==0.2.0\r\nipython-sql==0.3.9\r\nipywidgets==7.7.1\r\nitsdangerous==1.1.0\r\njax==0.3.21\r\njaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.20+cuda11.cudnn805-cp37-cp37m-manylinux2014_x86_64.whl\r\njieba==0.42.1\r\nJinja2==2.11.3\r\njmespath==1.0.1\r\njoblib==1.2.0\r\njpeg4py==0.1.4\r\njsonnet==0.18.0\r\njsonschema==4.3.3\r\njupyter-client==6.1.12\r\njupyter-console==6.1.0\r\njupyter-core==4.11.1\r\njupyterlab-widgets==3.0.3\r\nkaggle==1.5.12\r\nkapre==0.3.7\r\nkeras==2.8.0\r\nKeras-Preprocessing==1.1.2\r\nkeras-vis==0.4.1\r\nkiwisolver==1.4.4\r\nkorean-lunar-calendar==0.3.1\r\nlangcodes==3.3.0\r\nlibclang==14.0.6\r\nlibrosa==0.8.1\r\nlightgbm==2.2.3\r\nllvmlite==0.39.1\r\nlmdb==1.3.0\r\nlocket==1.0.0\r\nlogical-unification==0.4.5\r\nLunarCalendar==0.0.9\r\nlxml==4.9.1\r\nMarkdown==3.4.1\r\nMarkupSafe==2.0.1\r\nmarshmallow==3.18.0\r\nmatplotlib==3.2.2\r\nmatplotlib-venn==0.11.7\r\nminiKanren==1.0.3\r\nmissingno==0.5.1\r\nmistune==0.8.4\r\nmizani==0.7.3\r\nmkl==2019.0\r\nmlxtend==0.14.0\r\nmore-itertools==8.14.0\r\nmoviepy==0.2.3.5\r\nmpmath==1.2.1\r\nmsgpack==1.0.4\r\nmultidict==6.0.2\r\nmultipledispatch==0.6.0\r\nmultiprocess==0.70.13\r\nmultitasking==0.0.11\r\nmurmurhash==1.0.8\r\nmusic21==5.5.0\r\nnatsort==5.5.0\r\nnbconvert==5.6.1\r\nnbformat==5.6.1\r\nnetCDF4==1.6.1\r\nnetworkx==2.6.3\r\nnibabel==3.0.2\r\nnltk==3.7\r\nnotebook==5.3.1\r\nnumba==0.56.2\r\nnumexpr==2.8.3\r\nnumpy==1.21.6\r\noauth2client==4.1.3\r\noauthlib==3.2.1\r\nokgrade==0.4.3\r\nopencv-contrib-python==4.6.0.66\r\nopencv-python==4.6.0.66\r\nopencv-python-headless==4.6.0.66\r\nopenpyxl==3.0.10\r\nopt-einsum==3.3.0\r\nosqp==0.6.2.post0\r\npackaging==21.3\r\npalettable==3.3.0\r\npandas==1.3.5\r\npandas-datareader==0.9.0\r\npandas-gbq==0.13.3\r\npandas-profiling==1.4.1\r\npandocfilters==1.5.0\r\npanel==0.12.1\r\nparam==1.12.2\r\nparsimonious==0.10.0\r\nparso==0.8.3\r\npartd==1.3.0\r\npastel==0.2.1\r\npathlib==1.0.1\r\npathtools==0.1.2\r\npathy==0.6.2\r\npatsy==0.5.2\r\npep517==0.13.0\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.1.2\r\npip-tools==6.2.0\r\nplac==1.1.3\r\nplotly==5.5.0\r\nplotnine==0.8.0\r\npluggy==1.0.0\r\npooch==1.6.0\r\nportpicker==1.3.9\r\nprefetch-generator==1.0.1\r\npreshed==3.0.7\r\nprettytable==3.4.1\r\nprogressbar2==3.38.0\r\npromise==2.3\r\nprompt-toolkit==2.0.10\r\nprophet==1.1.1\r\nprotobuf==3.20.0\r\npsutil==5.4.8\r\npsycopg2==2.9.3\r\nptyprocess==0.7.0\r\npy==1.11.0\r\npy-rouge==1.1\r\npyarrow==6.0.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycocotools==2.0.5\r\npycparser==2.21\r\npyct==0.4.8\r\npydantic==1.8.2\r\npydata-google-auth==1.4.0\r\npydot==1.3.0\r\npydot-ng==2.0.0\r\npydotplus==2.0.2\r\nPyDrive==1.3.1\r\npyemd==0.5.1\r\npyerfa==2.0.0.1\r\nPygments==2.6.1\r\npygobject==3.26.1\r\npylev==1.4.0\r\npymc==4.1.4\r\nPyMeeus==0.5.11\r\npymongo==4.2.0\r\npymystem3==0.2.0\r\nPyOpenGL==3.1.6\r\npyparsing==3.0.9\r\npyrsistent==0.18.1\r\npysimdjson==3.2.0\r\npysndfile==1.3.8\r\nPySocks==1.7.1\r\npystan==3.3.0\r\npytest==7.1.3\r\npython-apt==0.0.0\r\npython-chess==0.23.11\r\npython-dateutil==2.8.2\r\npython-louvain==0.16\r\npython-slugify==6.1.2\r\npython-utils==3.3.3\r\npytz==2022.4\r\npyviz-comms==2.2.1\r\nPyWavelets==1.3.0\r\nPyYAML==6.0\r\npyzmq==23.2.1\r\nqdldl==0.1.5.post2\r\nqudida==0.0.4\r\nregex==2022.6.2\r\nrequests==2.28.1\r\nrequests-oauthlib==1.3.1\r\nresampy==0.4.2\r\nresponses==0.18.0\r\nrich==12.1.0\r\nrpy2==3.4.5\r\nrsa==4.9\r\ns3transfer==0.6.0\r\nsacremoses==0.0.53\r\nscikit-image==0.18.3\r\nscikit-learn==1.0.2\r\nscipy==1.7.3\r\nscreen-resolution-extra==0.0.0\r\nscs==3.2.0\r\nseaborn==0.11.2\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.97\r\nsentry-sdk==1.9.10\r\nsetproctitle==1.3.2\r\nsetuptools-git==1.2\r\nShapely==1.8.4\r\nshortuuid==1.0.9\r\nsix==1.15.0\r\nsklearn-pandas==1.8.0\r\nsmart-open==5.2.1\r\nsmmap==5.0.0\r\nsnowballstemmer==2.2.0\r\nsortedcontainers==2.4.0\r\nsoundfile==0.11.0\r\nspacy==3.4.1\r\nspacy-legacy==3.0.10\r\nspacy-loggers==1.0.3\r\nSphinx==1.8.6\r\nsphinxcontrib-serializinghtml==1.1.5\r\nsphinxcontrib-websupport==1.2.4\r\nSQLAlchemy==1.4.41\r\nsqlparse==0.4.3\r\nsrsly==2.4.4\r\nstatsmodels==0.12.2\r\nsympy==1.7.1\r\ntables==3.7.0\r\ntabulate==0.8.10\r\ntblib==1.7.0\r\ntenacity==8.1.0\r\ntensorboard==2.8.0\r\ntensorboard-data-server==0.6.1\r\ntensorboard-plugin-wit==1.8.1\r\ntensorboardX==2.5.1\r\ntensorflow==2.8.2+zzzcolab20220929150707\r\ntensorflow-datasets==4.6.0\r\ntensorflow-estimator==2.8.0\r\ntensorflow-gcs-config==2.8.0\r\ntensorflow-hub==0.12.0\r\ntensorflow-io-gcs-filesystem==0.27.0\r\ntensorflow-metadata==1.10.0\r\ntensorflow-probability==0.16.0\r\ntermcolor==1.1.0\r\nterminado==0.13.3\r\ntestpath==0.6.0\r\ntext-unidecode==1.3\r\ntextblob==0.15.3\r\nthinc==8.1.3\r\nthreadpoolctl==3.1.0\r\ntifffile==2021.11.2\r\ntokenizers==0.12.1\r\ntoml==0.10.2\r\ntomli==2.0.1\r\ntoolz==0.12.0\r\ntorch==1.11.0\r\ntorchaudio @ https://download.pytorch.org/whl/cu113/torchaudio-0.12.1%2Bcu113-cp37-cp37m-linux_x86_64.whl\r\ntorchsummary==1.5.1\r\ntorchtext==0.13.1\r\ntorchvision==0.12.0\r\ntornado==5.1.1\r\ntqdm==4.64.1\r\ntraitlets==5.4.0\r\ntransformers==4.20.1\r\ntweepy==3.10.0\r\ntypeguard==2.7.1\r\ntyper==0.4.2\r\ntyping-extensions==4.1.1\r\ntzlocal==1.5.1\r\nujson==5.5.0\r\nUnidecode==1.3.6\r\nuritemplate==3.0.1\r\nurllib3==1.26.12\r\nvega-datasets==0.9.0\r\nwandb==0.12.21\r\nwasabi==0.10.1\r\nwcwidth==0.2.5\r\nwebargs==8.2.0\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.6.1\r\nword2number==1.1\r\nwordcloud==1.8.2.2\r\nwrapt==1.14.1\r\nxarray==0.20.2\r\nxarray-einstats==0.2.2\r\nxgboost==0.90\r\nxkit==0.0.0\r\nxlrd==1.1.0\r\nxlwt==1.3.0\r\nxxhash==3.0.0\r\nyarl==1.8.1\r\nyellowbrick==1.5\r\nzict==2.2.0\r\nzipp==3.8.1\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n!pip install torch\r\n!pip install allennlp\r\n!pip install allennlp-models\r\n!pip install allennlp-semparse\r\n```\r\n\r\n```\r\nfrom allennlp_models import pretrained\r\nSQL_model_name = 'semparse-text-to-sql'\r\npred_model = pretrained.load_predictor(SQL_model_name)\r\npred_model.predict('what is the temperature in Berlin?')\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5717/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5717/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5716", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5716/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5716/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5716/events", "html_url": "https://github.com/allenai/allennlp/issues/5716", "id": 1400210700, "node_id": "I_kwDOBXH8-M5TdYUM", "number": 5716, "title": "Incompatibile packages", "user": {"login": "ianbstewart", "id": 1302835, "node_id": "MDQ6VXNlcjEzMDI4MzU=", "avatar_url": "https://avatars.githubusercontent.com/u/1302835?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ianbstewart", "html_url": "https://github.com/ianbstewart", "followers_url": "https://api.github.com/users/ianbstewart/followers", "following_url": "https://api.github.com/users/ianbstewart/following{/other_user}", "gists_url": "https://api.github.com/users/ianbstewart/gists{/gist_id}", "starred_url": "https://api.github.com/users/ianbstewart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ianbstewart/subscriptions", "organizations_url": "https://api.github.com/users/ianbstewart/orgs", "repos_url": "https://api.github.com/users/ianbstewart/repos", "events_url": "https://api.github.com/users/ianbstewart/events{/privacy}", "received_events_url": "https://api.github.com/users/ianbstewart/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2022-10-06T19:42:44Z", "updated_at": "2022-10-26T17:07:40Z", "closed_at": "2022-10-26T17:07:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nTrying to install `allennlp` with `conda` produces many compatibility issues. I have previously installed `allennlp` on other machines but this one has proven difficult. It may have to do with pytorch but not entirely sure.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nCollecting package metadata (current_repodata.json): done\r\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\r\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\r\nSolving environment: \\ \r\nFound conflicts! Looking for incompatible packages.\r\nThis can take several minutes.  Press CTRL-C to abort.\r\nfailed                                                                                                                                                     -  \r\n\r\nUnsatisfiableError: The following specifications were found to be incompatible with a past\r\nexplicit spec that is not an explicit spec in this operation (pytorch):\r\n\r\n  - allennlp -> base58 -> python[version='3.8.*|3.9.*|>=3.10,<3.11.0a0|>=3.10,<3.11.0a0|>=3.5|>=3.6|>=3.7|>=3.7.0|>=3.6.0|>=3.4|>=3.7,<4.0|>=3.6,<4.0|>=2.7',build=*_cpython]\r\n  - allennlp -> fairscale==0.4.6 -> pytorch[version='*|1.10|1.10.*|>=1.10.2,<1.11.0a0|>=1.11.0,<1.12.0a0|1.10.0.*|>=1.8.0|1.10.2',build=cpu*]\r\n  - allennlp -> python[version='>=3.8,<3.9.0a0|>=3.8,<3.9.0a0|>=3.9,<3.10.0a0',build=*_cpython]\r\n  - allennlp -> pytorch[version='>=1.6.0,<1.11.0|>=1.6.0,<1.12.0|>=1.8.0,<1.12.0']\r\n  - allennlp -> torchvision[version='>=0.8.1,<0.12.0|>=0.8.1,<0.13.0']\r\n  - python=3.8\r\n\r\nThe following specifications were found to be incompatible with each other:\r\n\r\nOutput in format: Requested package -> Available versions\r\n\r\nPackage libiconv conflicts for:\r\nlibidn2 -> gettext[version='>=0.19.8.1,<1.0a0'] -> libiconv[version='>=1.16,<2.0.0a0|>=1.17,<2.0a0|>=1.16,<2.0a0']\r\ngnutls -> gettext[version='>=0.19.8.1,<1.0a0'] -> libiconv[version='>=1.16,<2.0.0a0|>=1.17,<2.0a0|>=1.16,<2.0a0']\r\nffmpeg -> libxml2[version='>=2.9.14,<2.11.0a0'] -> libiconv[version='>=1.17,<2.0.0a0']\r\ngettext -> libiconv[version='>=1.16,<2.0.0a0|>=1.17,<2.0a0|>=1.16,<2.0a0']\r\nasttokens -> python[version='>=3.5'] -> libiconv[version='>=1.16,<2.0a0']\r\nlibxml2 -> libiconv[version='>=1.16,<2.0.0a0|>=1.17,<2.0.0a0|>=1.16,<2.0a0']\r\ntraitlets -> python[version='>=3.7'] -> libiconv[version='>=1.16,<2.0a0']\r\nsix -> python -> libiconv[version='>=1.16,<2.0a0']\r\njedi -> python[version='>=3.6'] -> libiconv[version='>=1.16,<2.0a0']\r\nurllib3 -> python[version='<4.0'] -> libiconv[version='>=1.16,<2.0a0']\r\npexpect -> python -> libiconv[version='>=1.16,<2.0a0']\r\ncertifi -> python[version='>=3.7'] -> libiconv[version='>=1.16,<2.0a0']\r\nstack_data -> python[version='>=3.5'] -> libiconv[version='>=1.16,<2.0a0']\r\npytorch -> python[version='>=3.9,<3.10.0a0'] -> libiconv[version='>=1.16,<2.0a0']\r\nexecuting -> python[version='>=2.7'] -> libiconv[version='>=1.16,<2.0a0']\r\npyopenssl -> python[version='>=3.6'] -> libiconv[version='>=1.16,<2.0a0']\r\nnumpy-base -> python[version='>=3.9,<3.10.0a0'] -> libiconv[version='>=1.16,<2.0a0']\r\nwcwidth -> python -> libiconv[version='>=1.16,<2.0a0']\r\ncharset-normalizer -> python[version='>=3.6'] -> libiconv[version='>=1.16,<2.0a0']\r\nnumpy -> python[version='>=3.9,<3.10.0a0'] -> libiconv[version='>=1.16,<2.0a0']\r\nbackcall -> python -> libiconv[version='>=1.16,<2.0a0']\r\npure_eval -> python[version='>=3.5'] -> libiconv[version='>=1.16,<2.0a0']\r\nallennlp -> python[version='>=3.9,<3.10.0a0'] -> libiconv[version='>=1.16,<2.0a0']\r\nwheel -> python[version='!=3.0,!=3.1,!=3.2,!=3.3,!=3.4'] -> libiconv[version='>=1.16,<2.0a0']\r\nipython -> python[version='>=3.8'] -> libiconv[version='>=1.16,<2.0a0']\r\nrequests -> python[version='>=3.7,<4.0'] -> libiconv[version='>=1.16,<2.0a0']\r\nbrotlipy -> python[version='>=3.9,<3.10.0a0'] -> libiconv[version='>=1.16,<2.0a0']\r\npysocks -> python[version='>=3.8'] -> libiconv[version='>=1.16,<2.0a0']\r\nffmpeg -> libiconv[version='>=1.16,<2.0.0a0|>=1.17,<2.0a0|>=1.16,<2.0a0']\r\npip -> python[version='>=3.7'] -> libiconv[version='>=1.16,<2.0a0']\r\nmatplotlib-inline -> python[version='>=3.6'] -> libiconv[version='>=1.16,<2.0a0']\r\npygments -> python[version='>=3.6'] -> libiconv[version='>=1.16,<2.0a0']\r\npycparser -> python[version='2.7.*|>=3.4'] -> libiconv[version='>=1.16,<2.0a0']\r\ncffi -> python[version='>=3.9,<3.10.0a0'] -> libiconv[version='>=1.16,<2.0a0']\r\nsetuptools -> python[version='>=3.7'] -> libiconv[version='>=1.16,<2.0a0']\r\nappnope -> python[version='>=2.7'] -> libiconv[version='>=1.16,<2.0a0']\r\nidna -> python[version='>=3.6'] -> libiconv[version='>=1.16,<2.0a0']\r\ntyping_extensions -> python[version='>=3.7'] -> libiconv[version='>=1.16,<2.0a0']\r\nptyprocess -> python -> libiconv[version='>=1.16,<2.0a0']\r\nparso -> python[version='>=3.6'] -> libiconv[version='>=1.16,<2.0a0']\r\nlibiconv\r\ndecorator -> python[version='>=3.5'] -> libiconv[version='>=1.16,<2.0a0']\r\npickleshare -> python[version='>=3'] -> libiconv[version='>=1.16,<2.0a0']\r\nlame -> libiconv[version='>=1.16,<2.0a0']\r\nprompt-toolkit -> python[version='>=3.6'] -> libiconv[version='>=1.16,<2.0a0']\r\ncryptography -> python[version='>=3.9,<3.10.0a0'] -> libiconv[version='>=1.16,<2.0a0']\r\ntorchvision -> python[version='>=3.9,<3.10.0a0'] -> libiconv[version='>=1.16,<2.0.0a0|>=1.16,<2.0a0|>=1.17,<2.0a0']\r\n\r\n...\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Mac OS Monterey, M1 MacBook Pro\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.13\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nappnope \r\nasttokens \r\nbackcall \r\nbrotlipy==0.7.0\r\ncertifi \r\ncffi \r\ncharset-normalizer \r\ncryptography \r\ndecorator \r\nexecuting \r\nidna \r\nipython \r\njedi \r\nmatplotlib-inline \r\nnumpy \r\nparso \r\npexpect \r\npickleshare \r\nPillow==9.2.0\r\nprompt-toolkit \r\nptyprocess \r\npure-eval \r\npycparser \r\nPygments \r\npyOpenSSL \r\nPySocks \r\nrequests \r\nsix \r\nstack-data \r\ntorch==1.12.1\r\ntorchaudio==0.12.1\r\ntorchvision==0.13.1\r\ntraitlets \r\ntyping_extensions \r\nurllib3 \r\nwcwidth \r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nconda create -n allennlp_env python=3.8\r\nconda activate allennlp_env\r\nconda install pytorch torchvision torchaudio -c pytorch\r\nconda install -c conda-forge python=3.8 allennlp\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5716/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5716/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5715", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5715/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5715/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5715/events", "html_url": "https://github.com/allenai/allennlp/issues/5715", "id": 1394674270, "node_id": "I_kwDOBXH8-M5TIQpe", "number": 5715, "title": "Rich 12.1.0 has been yanked, but has been pinned in `requirements.txt`", "user": {"login": "amitkparekh", "id": 7276308, "node_id": "MDQ6VXNlcjcyNzYzMDg=", "avatar_url": "https://avatars.githubusercontent.com/u/7276308?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amitkparekh", "html_url": "https://github.com/amitkparekh", "followers_url": "https://api.github.com/users/amitkparekh/followers", "following_url": "https://api.github.com/users/amitkparekh/following{/other_user}", "gists_url": "https://api.github.com/users/amitkparekh/gists{/gist_id}", "starred_url": "https://api.github.com/users/amitkparekh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amitkparekh/subscriptions", "organizations_url": "https://api.github.com/users/amitkparekh/orgs", "repos_url": "https://api.github.com/users/amitkparekh/repos", "events_url": "https://api.github.com/users/amitkparekh/events{/privacy}", "received_events_url": "https://api.github.com/users/amitkparekh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-10-03T12:45:31Z", "updated_at": "2022-10-12T21:27:28Z", "closed_at": "2022-10-12T21:27:28Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nWhen installing allennlp (with Poetry), I got this warning.\r\n\r\n```bash\r\nWarning: The locked version 12.1.0 for rich is a yanked version. Reason for being yanked: Broken dependencies. Please upgrade to 12.2.0 or later\r\n```\r\n\r\nI checked pypi and [rich==12.1](https://pypi.org/project/rich/12.1.0/) has been yanked. But this is the only version permitted under the requirements.txt. \r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- https://github.com/allenai/allennlp/pull/5672\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: OS X\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.9.12\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==2.10.0\r\naltair==4.2.0\r\nappnope==0.1.3\r\nastor==0.8.1\r\nasttokens==2.0.8\r\nattrs==22.1.0\r\nbackcall==0.2.0\r\nbandit==1.7.4\r\nbase58==2.1.1\r\nblack==22.8.0\r\nblinker==1.5\r\nblis==0.7.8\r\nboto3==1.24.84\r\nbotocore==1.27.84\r\ncached-path==1.1.6\r\ncachetools==5.2.0\r\ncatalogue==1.0.0\r\ncertifi==2022.6.15\r\ncffi==1.15.1\r\ncfgv==3.3.1\r\ncharset-normalizer==2.1.1\r\nclick==8.1.3\r\ncommonmark==0.9.1\r\nconvert-case==1.1.1\r\ncoverage==6.4.4\r\ncymem==2.0.6\r\ndarglint==1.8.1\r\ndebugpy==1.6.3\r\ndecopatch==1.4.10\r\ndecorator==5.1.1\r\ndill==0.3.5.1\r\ndistlib==0.3.6\r\ndocker-pycreds==0.4.0\r\ndocutils==0.19\r\nentrypoints==0.4\r\neradicate==2.1.0\r\nexecuting==1.0.0\r\nfairscale==0.4.6\r\nfilelock==3.6.0\r\nflake8==4.0.1\r\nflake8-bandit==3.0.0\r\nflake8-broken-line==0.4.0\r\nflake8-bugbear==22.9.23\r\nflake8-commas==2.1.0\r\nflake8-comprehensions==3.10.0\r\nflake8-debugger==4.1.2\r\nflake8-docstrings==1.6.0\r\nflake8-eradicate==1.3.0\r\nflake8-isort==4.2.0\r\nflake8-polyfill==1.0.2\r\nflake8-quotes==3.3.1\r\nflake8-rst-docstrings==0.2.7\r\nflake8-string-format==0.3.0\r\ngitdb==4.0.9\r\nGitPython==3.1.27\r\ngoogle-api-core==2.8.2\r\ngoogle-auth==2.12.0\r\ngoogle-cloud-core==2.3.2\r\ngoogle-cloud-storage==2.5.0\r\ngoogle-crc32c==1.5.0\r\ngoogle-resumable-media==2.4.0\r\ngoogleapis-common-protos==1.56.4\r\nh5py==3.7.0\r\nhuggingface-hub==0.10.0\r\nidentify==2.5.5\r\nidna==3.3\r\nimportlib-metadata==4.12.0\r\niniconfig==1.1.1\r\nipykernel==6.15.2\r\nipython==8.5.0\r\nisort==5.10.1\r\njedi==0.18.1\r\nJinja2==3.1.2\r\njmespath==1.0.1\r\njoblib==1.2.0\r\njsonnet==0.18.0\r\njsonschema==4.16.0\r\njupyter-core==4.11.1\r\njupyter_client==7.3.5\r\nlmdb==1.3.0\r\nmakefun==1.15.0\r\nMarkupSafe==2.1.1\r\nmatplotlib-inline==0.1.6\r\nmccabe==0.6.1\r\nmore-itertools==8.14.0\r\nmurmurhash==1.0.8\r\nmypy==0.971\r\nmypy-extensions==0.4.3\r\nnest-asyncio==1.5.5\r\nnltk==3.7\r\nnodeenv==1.7.0\r\nnumpy==1.23.2\r\norjson==3.8.0\r\noverrides==6.2.0\r\npackaging==21.3\r\npandas==1.4.4\r\nparso==0.8.3\r\npastel==0.2.1\r\npathspec==0.10.1\r\npathtools==0.1.2\r\npbr==5.10.0\r\npep8-naming==0.12.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==9.2.0\r\nplac==1.1.3\r\nplatformdirs==2.5.2\r\nplotly==5.10.0\r\npluggy==1.0.0\r\npoethepoet==0.16.2\r\npre-commit==2.20.0\r\npreshed==3.0.7\r\npromise==2.3\r\nprompt-toolkit==3.0.31\r\nprotobuf==3.20.0\r\npsutil==5.9.2\r\nptyprocess==0.7.0\r\npure-eval==0.2.2\r\npy==1.11.0\r\npyarrow==9.0.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycodestyle==2.8.0\r\npycparser==2.21\r\npydantic==1.10.2\r\npydeck==0.8.0b3\r\npydocstyle==6.1.1\r\npyflakes==2.4.0\r\nPygments==2.13.0\r\nPympler==1.0.1\r\npyparsing==3.0.9\r\npyrsistent==0.18.1\r\npytest==7.1.3\r\npytest-cases==3.6.13\r\npytest-cov==3.0.0\r\npython-dateutil==2.8.2\r\npytz==2022.2.1\r\npytz-deprecation-shim==0.1.0.post0\r\nPyYAML==6.0\r\npyzmq==23.2.1\r\nregex==2022.9.13\r\nrequests==2.28.1\r\nrestructuredtext-lint==1.4.0\r\nrich==12.1.0\r\nrsa==4.9\r\ns3transfer==0.6.0\r\nsacremoses==0.0.53\r\nscikit-learn==1.1.2\r\nscipy==1.9.1\r\nsemver==2.13.0\r\nsentencepiece==0.1.97\r\nsentry-sdk==1.9.9\r\nsetproctitle==1.3.2\r\nshortuuid==1.0.9\r\nsix==1.16.0\r\nsmmap==5.0.0\r\nsnowballstemmer==2.2.0\r\nspacy==2.3.7\r\nsrsly==1.0.5\r\nstack-data==0.5.0\r\nstevedore==4.0.0\r\nstreamlit==1.12.0\r\ntenacity==8.0.1\r\ntensorboardX==2.5.1\r\ntermcolor==1.1.0\r\nthinc==7.4.5\r\nthreadpoolctl==3.1.0\r\ntokenizers==0.12.1\r\ntoml==0.10.2\r\ntomli==2.0.1\r\ntoolz==0.12.0\r\ntorch==1.11.0\r\ntorchvision==0.12.0\r\ntornado==6.2\r\ntqdm==4.64.1\r\ntraitlets==5.3.0\r\ntransformers==4.20.1\r\ntyper==0.6.1\r\ntyping_extensions==4.3.0\r\ntzdata==2022.2\r\ntzlocal==4.2\r\nurllib3==1.26.12\r\nvalidators==0.20.0\r\nvirtualenv==20.16.5\r\nwandb==0.12.21\r\nwasabi==0.10.1\r\nwcwidth==0.2.5\r\nwemake-python-styleguide==0.16.1\r\nzipp==3.8.1\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5715/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5715/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5710", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5710/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5710/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5710/events", "html_url": "https://github.com/allenai/allennlp/issues/5710", "id": 1369837102, "node_id": "I_kwDOBXH8-M5Rpg4u", "number": 5710, "title": "error message occuied \u201czipfile.BadZipFile: File is not a zip file\u201d", "user": {"login": "Hoyyyaard", "id": 80028345, "node_id": "MDQ6VXNlcjgwMDI4MzQ1", "avatar_url": "https://avatars.githubusercontent.com/u/80028345?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hoyyyaard", "html_url": "https://github.com/Hoyyyaard", "followers_url": "https://api.github.com/users/Hoyyyaard/followers", "following_url": "https://api.github.com/users/Hoyyyaard/following{/other_user}", "gists_url": "https://api.github.com/users/Hoyyyaard/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hoyyyaard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hoyyyaard/subscriptions", "organizations_url": "https://api.github.com/users/Hoyyyaard/orgs", "repos_url": "https://api.github.com/users/Hoyyyaard/repos", "events_url": "https://api.github.com/users/Hoyyyaard/events{/privacy}", "received_events_url": "https://api.github.com/users/Hoyyyaard/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-09-12T12:36:27Z", "updated_at": "2022-10-03T16:11:32Z", "closed_at": "2022-10-03T16:11:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n## Description\r\n\r\nerror message occuied \u201czipfile.BadZipFile: File is not a zip file\u201d\r\nWhen applied the code\uff1a\r\n\r\nfrom transformers import PreTrainedTokenizerBase, AutoTokenizer\r\nfrom allennlp.predictors.predictor import Predictor\r\nfrom allennlp.common import Params\r\n\r\n\r\nfrom allennlp.common.model_card import ModelCard\r\nimport tarfile\r\nfrom pathlib import Path\r\nfrom typing import List, Union, Dict, Iterable, Sequence\r\nfrom allennlp.common.plugins import import_plugins\r\npredictor = Predictor.from_path('./elmo-constituency-parser-2020.02.10.tar.gz')\r\n\r\n<details>\r\n\r\nelmo-constituency-parser-2020.02.10.tar.gz has already been downloaded about 678M\r\n\r\n\r\n\r\n\r\n\r\n## Environment\r\n\r\nOS\uff1a Linux \r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8\r\n\r\n\r\n\r\n```\r\nabsl-py                      1.0.0\r\naiohttp                      3.8.1\r\naiosignal                    1.2.0\r\nallennlp                     2.9.1\r\nallennlp-models              2.9.0\r\nargon2-cffi                  21.3.0\r\nargon2-cffi-bindings         21.2.0\r\nasttokens                    2.0.8\r\nastunparse                   1.6.3\r\nasync-timeout                4.0.2\r\nattrs                        22.1.0\r\nautocommand                  2.2.1\r\nbackcall                     0.2.0\r\nbackports.csv                1.0.7\r\nbase58                       2.1.1\r\nbeautifulsoup4               4.11.1\r\nbleach                       5.0.1\r\nblis                         0.7.8\r\nboto3                        1.24.69\r\nbotocore                     1.27.69\r\ncached-path                  1.1.5\r\ncachetools                   5.0.0\r\ncatalogue                    2.0.8\r\ncertifi                      2022.6.15\r\ncffi                         1.15.1\r\ncharset-normalizer           2.1.0\r\nchecklist                    0.0.11\r\ncheroot                      8.6.0\r\nCherryPy                     18.8.0\r\nclick                        8.0.4\r\nclip                         1.0\r\ncommonmark                   0.9.1\r\nconllu                       4.4.1\r\ncryptography                 38.0.1\r\ncycler                       0.11.0\r\ncymem                        2.0.6\r\ndatasets                     1.18.4\r\ndebugpy                      1.6.3\r\ndecorator                    5.1.1\r\ndefusedxml                   0.7.1\r\ndill                         0.3.5.1\r\ndocker-pycreds               0.4.0\r\neasydict                     1.9\r\nEasyProcess                  1.1\r\nentrypoints                  0.4\r\net-xmlfile                   1.1.0\r\nexecuting                    0.10.0\r\nfairscale                    0.4.5\r\nfastjsonschema               2.16.1\r\nfeedparser                   6.0.10\r\nfilelock                     3.6.0\r\nflatbuffers                  2.0\r\nfonttools                    4.34.4\r\nfrozenlist                   1.3.1\r\nfsspec                       2022.8.2\r\nftfy                         6.1.1\r\nfuture                       0.18.2\r\ngitdb                        4.0.9\r\nGitPython                    3.1.27\r\ngoogle-api-core              2.10.0\r\ngoogle-auth                  2.6.5\r\ngoogle-auth-oauthlib         0.4.6\r\ngoogle-cloud-core            2.3.2\r\ngoogle-cloud-storage         2.5.0\r\ngoogle-crc32c                1.5.0\r\ngoogle-pasta                 0.2.0\r\ngoogle-resumable-media       2.3.3\r\ngoogleapis-common-protos     1.56.4\r\ngrpcio                       1.44.0\r\ngym                          0.10.9\r\nh5py                         2.10.0\r\nhuggingface-hub              0.8.1\r\nidna                         3.3\r\nimportlib-metadata           4.11.3\r\nimportlib-resources          5.9.0\r\ninflect                      6.0.0\r\niniconfig                    1.1.1\r\nipykernel                    6.15.1\r\nipython                      8.4.0\r\nipython-genutils             0.2.0\r\nipywidgets                   8.0.2\r\niso-639                      0.4.5\r\njaraco.classes               3.2.2\r\njaraco.collections           3.5.2\r\njaraco.context               4.1.2\r\njaraco.functools             3.5.1\r\njaraco.text                  3.9.1\r\njedi                         0.18.1\r\nJinja2                       3.1.2\r\njmespath                     1.0.1\r\njoblib                       1.1.0\r\njson5                        0.9.10\r\njsonlines                    2.0.0\r\njsonnet                      0.18.0\r\njsonschema                   4.15.0\r\njupyter                      1.0.0\r\njupyter-client               7.3.4\r\njupyter-console              6.4.4\r\njupyter-core                 4.11.1\r\njupyterlab-pygments          0.2.2\r\njupyterlab-widgets           3.0.3\r\nkeras                        2.8.0\r\nKeras-Preprocessing          1.1.2\r\nkiwisolver                   1.4.2\r\nlangcodes                    3.3.0\r\nlibclang                     13.0.0\r\nlmdb                         1.3.0\r\nlxml                         4.9.1\r\nMarkdown                     3.3.6\r\nMarkupSafe                   2.1.1\r\nmatplotlib                   3.5.2\r\nmatplotlib-inline            0.1.6\r\nmistune                      2.0.4\r\nmore-itertools               8.14.0\r\nmultidict                    6.0.2\r\nmultiprocess                 0.70.13\r\nmunch                        2.5.0\r\nmurmurhash                   1.0.8\r\nnbclient                     0.6.7\r\nnbconvert                    7.0.0\r\nnbformat                     5.4.0\r\nnest-asyncio                 1.5.5\r\nnetworkx                     2.5.1\r\nnltk                         3.6.7\r\nnn-builder                   1.0.5\r\nnotebook                     6.4.12\r\nnumpy                        1.20.3\r\noauthlib                     3.2.0\r\nopenai                       0.20.0\r\nopencv-python                4.6.0.66\r\nopenpyxl                     3.0.10\r\nopt-einsum                   3.3.0\r\npackaging                    21.3\r\npandas                       1.4.3\r\npandas-stubs                 1.4.3.220704\r\npandocfilters                1.5.0\r\nparso                        0.8.3\r\npath                         16.4.0\r\npathtools                    0.1.2\r\npathy                        0.6.2\r\npatternfork-nosql            3.6\r\npdfminer.six                 20220524\r\npexpect                      4.8.0\r\npickleshare                  0.7.5\r\nPillow                       9.1.1\r\npip                          21.2.4\r\npkgutil_resolve_name         1.3.10\r\npluggy                       1.0.0\r\nportend                      3.1.0\r\npreshed                      3.0.7\r\nprometheus-client            0.14.1\r\npromise                      2.3\r\nprompt-toolkit               3.0.20\r\nprotobuf                     3.20.1\r\npsutil                       5.9.2\r\nptyprocess                   0.7.0\r\npure-eval                    0.2.2\r\npy                           1.11.0\r\npy-rouge                     1.1\r\npyarrow                      9.0.0\r\npyasn1                       0.4.8\r\npyasn1-modules               0.2.8\r\npycparser                    2.21\r\npydantic                     1.8.2\r\npyglet                       1.5.23\r\nPygments                     2.13.0\r\npyparsing                    3.0.9\r\npyrsistent                   0.18.1\r\npytest                       7.1.3\r\npython-dateutil              2.8.2\r\npython-docx                  0.8.11\r\npytz                         2022.1\r\nPyVirtualDisplay             0.2.1\r\nPyYAML                       6.0\r\npyzmq                        23.2.1\r\nqtconsole                    5.3.2\r\nQtPy                         2.2.0\r\nregex                        2022.6.2\r\nrequests                     2.28.1\r\nrequests-oauthlib            1.3.1\r\nresponses                    0.18.0\r\nrich                         12.5.1\r\nrsa                          4.8\r\ns3transfer                   0.6.0\r\nsacremoses                   0.0.53\r\nscikit-learn                 1.1.2\r\nscipy                        1.8.0\r\nSend2Trash                   1.8.0\r\nsentencepiece                0.1.97\r\nsentry-sdk                   1.9.8\r\nsetproctitle                 1.3.2\r\nsetuptools                   63.4.1\r\nsgmllib3k                    1.0.0\r\nShapely                      1.7.1\r\nshortuuid                    1.0.9\r\nsix                          1.16.0\r\nsmart-open                   5.2.1\r\nsmmap                        5.0.0\r\nsoupsieve                    2.3.2.post1\r\nspacy                        3.2.4\r\nspacy-legacy                 3.0.10\r\nspacy-loggers                1.0.3\r\nsqlitedict                   2.0.0\r\nsrsly                        2.4.4\r\nstack-data                   0.4.0\r\nstanfordcorenlp              3.9.1.1\r\ntempora                      5.0.2\r\ntensorboard                  2.8.0\r\ntensorboard-data-server      0.6.1\r\ntensorboard-plugin-wit       1.8.1\r\ntensorboardX                 2.4.1\r\ntensorflow-io-gcs-filesystem 0.24.0\r\ntermcolor                    1.1.0\r\nterminado                    0.15.0\r\ntf-estimator-nightly         2.8.0.dev2021122109\r\nthinc                        8.0.17\r\nthreadpoolctl                3.1.0\r\ntinycss2                     1.1.1\r\ntokenizers                   0.10.3\r\ntomli                        2.0.1\r\ntorch                        1.8.1+cu101\r\ntorchaudio                   0.8.1\r\ntorchvision                  0.9.1+cu101\r\ntornado                      6.2\r\ntqdm                         4.64.1\r\ntraitlets                    5.3.0\r\ntransformers                 4.12.5\r\ntyper                        0.4.2\r\ntyping_extensions            4.1.1\r\nurllib3                      1.26.12\r\nwandb                        0.12.21\r\nwasabi                       0.10.1\r\nwcwidth                      0.2.5\r\nwebencodings                 0.5.1\r\nWerkzeug                     2.1.1\r\nwheel                        0.37.1\r\nwidgetsnbextension           4.0.3\r\nword2number                  1.1\r\nwrapt                        1.14.0\r\nxxhash                       3.0.0\r\nyarl                         1.8.1\r\nzc.lockfile                  2.0\r\nzipp                         3.8.0\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5710/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5710/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5707", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5707/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5707/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5707/events", "html_url": "https://github.com/allenai/allennlp/issues/5707", "id": 1360772840, "node_id": "I_kwDOBXH8-M5RG77o", "number": 5707, "title": "Incorrect validation in MaxPoolingSpanExtractor", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-09-03T06:24:46Z", "updated_at": "2022-09-19T16:10:01Z", "closed_at": "2022-09-19T16:10:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've been testing the `MaxPoolingSpanExtractor` - I find in my case it does work significantly better than using `EndpointSpanExtractor`, in particular, it significantly reduces the number of false positives but it doesn't change the number of false negatives.\r\n\r\nHowever, in order to make it work, I had to create a fork. The problem is the default padding for span indices is -1 \r\n\r\nhttps://github.com/allenai/allennlp/blob/1caf0dafa3bc8d0bb309a46e2ccb12f714923260/allennlp/data/fields/span_field.py#L61\r\n\r\nyet the `MaxPoolingSpanExtractor`  specifically checks that every span index is between 0 and max sequence length ignoring the mask.\r\n\r\nhttps://github.com/allenai/allennlp/blob/b2eb036e06fbf4e293abb126552aaabc3df91aa1/allennlp/modules/span_extractors/max_pooling_span_extractor.py#L77\r\n\r\nHence for padded sequences this validation always asserts. The correct validation would be to check that only unmasked indices are valid (I just commented it out, I already check in my dataloader) - I would also suggest this should be done in the base class forward rather than one of the implementations.\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5707/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5707/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5696", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5696/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5696/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5696/events", "html_url": "https://github.com/allenai/allennlp/issues/5696", "id": 1323607353, "node_id": "I_kwDOBXH8-M5O5KU5", "number": 5696, "title": "file link error on Google Colaboratory", "user": {"login": "hongyi-li-93", "id": 91433458, "node_id": "MDQ6VXNlcjkxNDMzNDU4", "avatar_url": "https://avatars.githubusercontent.com/u/91433458?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hongyi-li-93", "html_url": "https://github.com/hongyi-li-93", "followers_url": "https://api.github.com/users/hongyi-li-93/followers", "following_url": "https://api.github.com/users/hongyi-li-93/following{/other_user}", "gists_url": "https://api.github.com/users/hongyi-li-93/gists{/gist_id}", "starred_url": "https://api.github.com/users/hongyi-li-93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hongyi-li-93/subscriptions", "organizations_url": "https://api.github.com/users/hongyi-li-93/orgs", "repos_url": "https://api.github.com/users/hongyi-li-93/repos", "events_url": "https://api.github.com/users/hongyi-li-93/events{/privacy}", "received_events_url": "https://api.github.com/users/hongyi-li-93/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-07-31T23:22:37Z", "updated_at": "2022-08-15T16:10:02Z", "closed_at": "2022-08-15T16:10:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nWhen training on Google Colab, hard copying file fails. (I guess adding 38 to line 620 of file_utils.py might help.)\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n[/usr/local/lib/python3.7/dist-packages/allennlp/common/file_utils.py](https://localhost:8080/#) in hardlink_or_copy(source, dest)\r\n    616 def hardlink_or_copy(source: PathOrStr, dest: PathOrStr):\r\n    617     try:\r\n--> 618         os.link(source, dest)\r\n    619     except OSError as e:\r\n    620         if e.errno in {18, 95}:  # Cross-device link and Windows\r\n\r\nOSError: [Errno 38] Function not implemented: 'source.txt' -> 'dest.txt'\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux(Google Colaboratory)\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.13\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==1.2.0\r\naiohttp==3.8.1\r\naiosignal==1.2.0\r\nalabaster==0.7.12\r\nalbumentations==0.1.12\r\nallennlp==2.10.0\r\naltair==4.2.0\r\nappdirs==1.4.4\r\nargon2-cffi==21.3.0\r\nargon2-cffi-bindings==21.2.0\r\narviz==0.12.1\r\nastor==0.8.1\r\nastropy==4.3.1\r\nastunparse==1.6.3\r\nasync-timeout==4.0.2\r\nasynctest==0.13.0\r\natari-py==0.2.9\r\natomicwrites==1.4.1\r\nattrs==21.4.0\r\naudioread==2.1.9\r\nautograd==1.4\r\nBabel==2.10.3\r\nbackcall==0.2.0\r\nbase58==2.1.1\r\nbeautifulsoup4==4.6.3\r\nbleach==5.0.1\r\nblis==0.7.8\r\nbokeh==2.3.3\r\nboto3==1.24.42\r\nbotocore==1.27.42\r\nbranca==0.5.0\r\nbs4==0.0.1\r\nCacheControl==0.12.11\r\ncached-path==1.1.5\r\ncached-property==1.5.2\r\ncachetools==4.2.4\r\ncatalogue==2.0.8\r\ncertifi==2022.6.15\r\ncffi==1.15.1\r\ncftime==1.6.1\r\nchardet==3.0.4\r\ncharset-normalizer==2.1.0\r\nclick==7.1.2\r\nclikit==0.6.2\r\ncloudpickle==1.3.0\r\ncmake==3.22.5\r\ncmdstanpy==1.0.4\r\ncolorcet==3.0.0\r\ncolorlover==0.3.0\r\ncommonmark==0.9.1\r\ncommunity==1.0.0b1\r\ncontextlib2==0.5.5\r\nconvertdate==2.4.0\r\ncoverage==3.7.1\r\ncoveralls==0.5\r\ncrashtest==0.3.1\r\ncrcmod==1.7\r\ncufflinks==0.17.3\r\ncvxopt==1.2.7\r\ncvxpy==1.0.31\r\ncycler==0.11.0\r\ncymem==2.0.6\r\nCython==0.29.30\r\ndaft==0.0.4\r\ndask==2.12.0\r\ndatascience==0.10.6\r\ndebugpy==1.0.0\r\ndecorator==4.4.2\r\ndefusedxml==0.7.1\r\ndeprecat==2.1.1\r\ndescartes==1.1.0\r\ndill==0.3.5.1\r\ndistributed==1.25.3\r\ndlib==19.24.0\r\ndm-tree==0.1.7\r\ndocker-pycreds==0.4.0\r\ndocopt==0.6.2\r\ndocutils==0.17.1\r\ndopamine-rl==1.0.5\r\nearthengine-api==0.1.317\r\neasydict==1.9\r\necos==2.0.10\r\neditdistance==0.5.3\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl\r\nentrypoints==0.4\r\nephem==4.1.3\r\net-xmlfile==1.1.0\r\netils==0.6.0\r\nfa2==0.3.5\r\nfairscale==0.4.6\r\nfastai==2.7.7\r\nfastcore==1.5.10\r\nfastdownload==0.0.7\r\nfastdtw==0.3.4\r\nfastjsonschema==2.16.1\r\nfastprogress==1.0.3\r\nfastrlock==0.8\r\nfeather-format==0.4.1\r\nfilelock==3.7.1\r\nfirebase-admin==4.4.0\r\nfix-yahoo-finance==0.0.22\r\nFlask==1.1.4\r\nflatbuffers==2.0\r\nfolium==0.8.3\r\nfrozenlist==1.3.0\r\nfuture==0.16.0\r\ngast==0.5.3\r\nGDAL==2.2.2\r\ngdown==4.4.0\r\ngensim==3.6.0\r\ngeographiclib==1.52\r\ngeopy==1.17.0\r\ngin-config==0.5.0\r\ngitdb==4.0.9\r\nGitPython==3.1.27\r\nglob2==0.7\r\ngoogle==2.0.3\r\ngoogle-api-core==1.31.6\r\ngoogle-api-python-client==1.12.11\r\ngoogle-auth==1.35.0\r\ngoogle-auth-httplib2==0.0.4\r\ngoogle-auth-oauthlib==0.4.6\r\ngoogle-cloud-bigquery==1.21.0\r\ngoogle-cloud-bigquery-storage==1.1.2\r\ngoogle-cloud-core==2.3.2\r\ngoogle-cloud-datastore==1.8.0\r\ngoogle-cloud-firestore==1.7.0\r\ngoogle-cloud-language==1.2.0\r\ngoogle-cloud-storage==2.4.0\r\ngoogle-cloud-translate==1.5.0\r\ngoogle-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\r\ngoogle-crc32c==1.3.0\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==2.3.3\r\ngoogleapis-common-protos==1.56.4\r\ngoogledrivedownloader==0.4\r\ngraphviz==0.10.1\r\ngreenlet==1.1.2\r\ngrpcio==1.47.0\r\ngspread==3.4.2\r\ngspread-dataframe==3.0.8\r\ngym==0.17.3\r\nh5py==3.7.0\r\nHeapDict==1.0.1\r\nhijri-converter==2.2.4\r\nholidays==0.14.2\r\nholoviews==1.14.9\r\nhtml5lib==1.0.1\r\nhttpimport==0.5.18\r\nhttplib2==0.17.4\r\nhttplib2shim==0.0.3\r\nhttpstan==4.6.1\r\nhuggingface-hub==0.8.1\r\nhumanize==0.5.1\r\nhyperopt==0.1.2\r\nidna==2.10\r\nimageio==2.4.1\r\nimagesize==1.4.1\r\nimbalanced-learn==0.8.1\r\nimblearn==0.0\r\nimgaug==0.2.9\r\nimportlib-metadata==4.12.0\r\nimportlib-resources==5.9.0\r\nimutils==0.5.4\r\ninflect==2.1.0\r\niniconfig==1.1.1\r\nintel-openmp==2022.1.0\r\nintervaltree==2.1.0\r\nipykernel==4.10.1\r\nipython==5.5.0\r\nipython-genutils==0.2.0\r\nipython-sql==0.3.9\r\nipywidgets==7.7.1\r\nitsdangerous==1.1.0\r\njax==0.3.14\r\njaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.14+cuda11.cudnn805-cp37-none-manylinux2014_x86_64.whl\r\njedi==0.18.1\r\njieba==0.42.1\r\nJinja2==2.11.3\r\njmespath==1.0.1\r\njoblib==1.1.0\r\njpeg4py==0.1.4\r\njsonnet==0.18.0\r\njsonschema==4.3.3\r\njupyter==1.0.0\r\njupyter-client==5.3.5\r\njupyter-console==5.2.0\r\njupyter-core==4.11.1\r\njupyterlab-pygments==0.2.2\r\njupyterlab-widgets==1.1.1\r\nkaggle==1.5.12\r\nkapre==0.3.7\r\nkeras==2.8.0\r\nKeras-Preprocessing==1.1.2\r\nkeras-vis==0.4.1\r\nkiwisolver==1.4.4\r\nkorean-lunar-calendar==0.2.1\r\nlangcodes==3.3.0\r\nlibclang==14.0.1\r\nlibrosa==0.8.1\r\nlightgbm==2.2.3\r\nllvmlite==0.34.0\r\nlmdb==1.3.0\r\nLunarCalendar==0.0.9\r\nlxml==4.2.6\r\nMarkdown==3.4.1\r\nMarkupSafe==2.0.1\r\nmarshmallow==3.17.0\r\nmatplotlib==3.2.2\r\nmatplotlib-inline==0.1.3\r\nmatplotlib-venn==0.11.7\r\nmissingno==0.5.1\r\nmistune==0.8.4\r\nmizani==0.6.0\r\nmkl==2019.0\r\nmlxtend==0.14.0\r\nmore-itertools==8.13.0\r\nmoviepy==0.2.3.5\r\nmpmath==1.2.1\r\nmsgpack==1.0.4\r\nmultidict==6.0.2\r\nmultiprocess==0.70.13\r\nmultitasking==0.0.11\r\nmurmurhash==1.0.7\r\nmusic21==5.5.0\r\nnatsort==5.5.0\r\nnbclient==0.6.6\r\nnbconvert==5.6.1\r\nnbformat==5.4.0\r\nnest-asyncio==1.5.5\r\nnetCDF4==1.6.0\r\nnetworkx==2.6.3\r\nnibabel==3.0.2\r\nnltk==3.7\r\nnotebook==5.3.1\r\nnumba==0.51.2\r\nnumexpr==2.8.3\r\nnumpy==1.21.6\r\noauth2client==4.1.3\r\noauthlib==3.2.0\r\nokgrade==0.4.3\r\nopencv-contrib-python==4.6.0.66\r\nopencv-python==4.6.0.66\r\nopenpyxl==3.0.10\r\nopt-einsum==3.3.0\r\nosqp==0.6.2.post0\r\noverrides==6.1.0\r\npackaging==21.3\r\npalettable==3.3.0\r\npandas==1.3.5\r\npandas-datareader==0.9.0\r\npandas-gbq==0.13.3\r\npandas-profiling==1.4.1\r\npandocfilters==1.5.0\r\npanel==0.12.1\r\nparam==1.12.2\r\nparso==0.8.3\r\npastel==0.2.1\r\npathlib==1.0.1\r\npathtools==0.1.2\r\npathy==0.6.2\r\npatsy==0.5.2\r\npep517==0.12.0\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.1.2\r\npip-tools==6.2.0\r\nplotly==5.5.0\r\nplotnine==0.6.0\r\npluggy==1.0.0\r\npooch==1.6.0\r\nportpicker==1.3.9\r\nprefetch-generator==1.0.1\r\npreshed==3.0.6\r\nprettytable==3.3.0\r\nprogressbar2==3.38.0\r\nprometheus-client==0.14.1\r\npromise==2.3\r\nprompt-toolkit==1.0.18\r\nprophet==1.1\r\nprotobuf==3.20.0\r\npsutil==5.4.8\r\npsycopg2==2.7.6.1\r\nptyprocess==0.7.0\r\npy==1.11.0\r\npyarrow==6.0.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycocotools==2.0.4\r\npycparser==2.21\r\npyct==0.4.8\r\npydantic==1.8.2\r\npydata-google-auth==1.4.0\r\npydot==1.3.0\r\npydot-ng==2.0.0\r\npydotplus==2.0.2\r\nPyDrive==1.3.1\r\npyemd==0.5.1\r\npyerfa==2.0.0.1\r\npyglet==1.5.0\r\nPygments==2.6.1\r\npygobject==3.26.1\r\npylev==1.4.0\r\npymc3==3.11.5\r\nPyMeeus==0.5.11\r\npymongo==4.2.0\r\npymystem3==0.2.0\r\nPyOpenGL==3.1.6\r\npyparsing==3.0.9\r\npyrsistent==0.18.1\r\npysimdjson==3.2.0\r\npysndfile==1.3.8\r\nPySocks==1.7.1\r\npystan==3.3.0\r\npytest==7.1.2\r\npython-apt==0.0.0\r\npython-chess==0.23.11\r\npython-dateutil==2.8.2\r\npython-louvain==0.16\r\npython-slugify==6.1.2\r\npython-utils==3.3.3\r\npytorch-pretrained-bert==0.6.2\r\npytorch-transformers==1.2.0\r\npytz==2022.1\r\npyviz-comms==2.2.0\r\nPyWavelets==1.3.0\r\nPyYAML==6.0\r\npyzmq==23.2.0\r\nqdldl==0.1.5.post2\r\nqtconsole==5.3.1\r\nQtPy==2.1.0\r\nregex==2022.6.2\r\nrequests==2.28.1\r\nrequests-oauthlib==1.3.1\r\nresampy==0.3.1\r\nrich==12.1.0\r\nrpy2==3.4.5\r\nrsa==4.9\r\ns3transfer==0.6.0\r\nsacremoses==0.0.53\r\nscikit-image==0.18.3\r\nscikit-learn==1.0.2\r\nscipy==1.7.3\r\nscreen-resolution-extra==0.0.0\r\nscs==3.2.0\r\nseaborn==0.11.2\r\nsemver==2.13.0\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.9.0\r\nsetproctitle==1.3.0\r\nsetuptools-git==1.2\r\nShapely==1.8.2\r\nshortuuid==1.0.9\r\nsimplegeneric==0.8.1\r\nsix==1.15.0\r\nsklearn==0.0\r\nsklearn-pandas==1.8.0\r\nsmart-open==5.2.1\r\nsmmap==5.0.0\r\nsnowballstemmer==2.2.0\r\nsortedcontainers==2.4.0\r\nSoundFile==0.10.3.post1\r\nsoupsieve==2.3.2.post1\r\nspacy==3.3.1\r\nspacy-legacy==3.0.9\r\nspacy-loggers==1.0.3\r\nSphinx==1.8.6\r\nsphinxcontrib-serializinghtml==1.1.5\r\nsphinxcontrib-websupport==1.2.4\r\nSQLAlchemy==1.4.39\r\nsqlparse==0.4.2\r\nsrsly==2.4.4\r\nstatsmodels==0.10.2\r\nsympy==1.7.1\r\ntables==3.7.0\r\ntabulate==0.8.10\r\ntblib==1.7.0\r\ntenacity==8.0.1\r\ntensorboard==2.8.0\r\ntensorboard-data-server==0.6.1\r\ntensorboard-plugin-wit==1.8.1\r\ntensorboardX==2.5.1\r\ntensorflow==2.8.2+zzzcolab20220719082949\r\ntensorflow-datasets==4.0.1\r\ntensorflow-estimator==2.8.0\r\ntensorflow-gcs-config==2.8.0\r\ntensorflow-hub==0.12.0\r\ntensorflow-io-gcs-filesystem==0.26.0\r\ntensorflow-metadata==1.9.0\r\ntensorflow-probability==0.16.0\r\ntermcolor==1.1.0\r\nterminado==0.13.3\r\ntestpath==0.6.0\r\ntext-unidecode==1.3\r\ntextblob==0.15.3\r\nTheano-PyMC==1.1.2\r\nthinc==8.0.17\r\nthreadpoolctl==3.1.0\r\ntifffile==2021.11.2\r\ntinycss2==1.1.1\r\ntokenizers==0.12.1\r\ntomli==2.0.1\r\ntoolz==0.12.0\r\ntorch==1.11.0\r\ntorchaudio @ https://download.pytorch.org/whl/cu113/torchaudio-0.12.0%2Bcu113-cp37-cp37m-linux_x86_64.whl\r\ntorchsummary==1.5.1\r\ntorchtext==0.13.0\r\ntorchvision==0.12.0\r\ntornado==5.1.1\r\ntqdm==4.64.0\r\ntraitlets==5.3.0\r\ntransformers==4.20.1\r\ntweepy==3.10.0\r\ntypeguard==2.7.1\r\ntyper==0.4.2\r\ntyping-extensions==4.1.1\r\ntyping-utils==0.1.0\r\ntzlocal==1.5.1\r\nujson==5.4.0\r\nuritemplate==3.0.1\r\nurllib3==1.26.11\r\nvega-datasets==0.9.0\r\nwandb==0.12.21\r\nwasabi==0.9.1\r\nwcwidth==0.2.5\r\nwebargs==8.2.0\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.6.1\r\nwordcloud==1.5.0\r\nwrapt==1.14.1\r\nxarray==0.20.2\r\nxarray-einstats==0.2.2\r\nxgboost==0.90\r\nxkit==0.0.0\r\nxlrd==1.1.0\r\nxlwt==1.3.0\r\nyarl==1.7.2\r\nyellowbrick==1.4\r\nzict==2.2.0\r\nzipp==3.8.1\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nimport allennlp\r\n\r\ns = 'source.txt'\r\nopen(s,'a+')\r\n\r\nd = 'dest.txt'\r\n\r\nallennlp.common.file_utils.hardlink_or_copy(s, d)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5696/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5696/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5693", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5693/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5693/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5693/events", "html_url": "https://github.com/allenai/allennlp/issues/5693", "id": 1309799830, "node_id": "I_kwDOBXH8-M5OEfWW", "number": 5693, "title": "`MultiTaskDataLoader.__len__` is inaccurate when used with `instances_per_epoch`", "user": {"login": "lgessler", "id": 7650725, "node_id": "MDQ6VXNlcjc2NTA3MjU=", "avatar_url": "https://avatars.githubusercontent.com/u/7650725?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lgessler", "html_url": "https://github.com/lgessler", "followers_url": "https://api.github.com/users/lgessler/followers", "following_url": "https://api.github.com/users/lgessler/following{/other_user}", "gists_url": "https://api.github.com/users/lgessler/gists{/gist_id}", "starred_url": "https://api.github.com/users/lgessler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lgessler/subscriptions", "organizations_url": "https://api.github.com/users/lgessler/orgs", "repos_url": "https://api.github.com/users/lgessler/repos", "events_url": "https://api.github.com/users/lgessler/events{/privacy}", "received_events_url": "https://api.github.com/users/lgessler/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-07-19T16:51:31Z", "updated_at": "2022-08-03T22:54:07Z", "closed_at": "2022-08-03T16:09:54Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Problem\r\nWhen using `MultiTaskDataLoader` with more than one task and the `instances_per_epoch` feature, the number of batches in the epoch is overestimated, showing T*B instead of B, where T is the number of tasks and B is the (actual) number of batches for that epoch. E.g., I see this output with T=2:\r\n\r\n```\r\n# Training ...\r\nmetric_1: ..., metric_2: ..., batch_loss: 2.6009, loss: 6.0547 ||:  50%|#####     | 8/16 [00:00<00:00,  9.60it/s]\r\n2022-07-19 12:46:53,360 - INFO - my.package  - Validating\r\n# ...\r\n```\r\n\r\n## Steps to Reproduce\r\nConfigure an environment that uses `MultiTaskDataLoader` with more than one task and with `instances_per_epoch` set to some integer. \r\n\r\n## Cause\r\n[The branch of `MultiTaskDataLoader.__len__` that is called when `instances_per_epoch is not None`](https://github.com/allenai/allennlp/blob/main/allennlp/data/data_loaders/multitask_data_loader.py#L181L183) assumes that each dataset will have `self._instances_per_epoch` instances for the epoch, estimating a total of `num_tasks * self._instances_per_epoch`. \r\nHowever, [the implementation of `MultiTaskDataLoader._get_instances_for_epoch` guarantees that all instances across all tasks will approximately sum to `self._instances_per_epoch`](https://github.com/allenai/allennlp/blob/main/allennlp/data/data_loaders/multitask_data_loader.py#L231L236\r\n).\r\n\r\n## Suggested Solution\r\nModify `MultiTaskDataLoader.__len__` to use the same logic in `_get_instances_for_epoch` to compute batch numbers. I'm happy to personally open a PR for this.\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5693/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5693/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5683", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5683/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5683/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5683/events", "html_url": "https://github.com/allenai/allennlp/issues/5683", "id": 1295716564, "node_id": "I_kwDOBXH8-M5NOxDU", "number": 5683, "title": "T5 Module Self Attention Overwrites Dropout Configuration", "user": {"login": "MSLars", "id": 13149892, "node_id": "MDQ6VXNlcjEzMTQ5ODky", "avatar_url": "https://avatars.githubusercontent.com/u/13149892?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MSLars", "html_url": "https://github.com/MSLars", "followers_url": "https://api.github.com/users/MSLars/followers", "following_url": "https://api.github.com/users/MSLars/following{/other_user}", "gists_url": "https://api.github.com/users/MSLars/gists{/gist_id}", "starred_url": "https://api.github.com/users/MSLars/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MSLars/subscriptions", "organizations_url": "https://api.github.com/users/MSLars/orgs", "repos_url": "https://api.github.com/users/MSLars/repos", "events_url": "https://api.github.com/users/MSLars/events{/privacy}", "received_events_url": "https://api.github.com/users/MSLars/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-07-06T11:47:54Z", "updated_at": "2022-07-27T16:09:57Z", "closed_at": "2022-07-27T16:09:57Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nWhen I create a T5 Module and configure a custom dropout rate \r\n\r\n```\r\nT5Module.from_pretrained_module(\r\n            model_name,\r\n            beam_search=beam_search,\r\n            ddp_accelerator=self.ddp_accelerator,\r\n            auto_config_kwargs={\"dropout_rate\": 0.0},\r\n            checkpoint_wrapper=checkpoint_wrapper,\r\n            output_attentions=self.interpretation,\r\n            weights_path=weights_path,\r\n            tie_word_embeddings=tie_word_embeddings,\r\n            label_smoothing=label_smoothing,\r\n        )\r\n```\r\nthe value gets replaced with the standard configuration in [T5EncoderStack](https://github.com/allenai/allennlp/blob/main/allennlp/modules/transformer/t5.py#L629). The behavior is similar in the Decoder.\r\n\r\nIt seems not possible to set a value different from 0.1.\r\n\r\nThis\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n## Proposed Solution\r\n\r\nThis can be easily solved by adding the dropout parameter to the `T5Block` call.\r\n\r\n```\r\n  block = T5Block(\r\n      attention=T5LayerSelfAttention(\r\n          self_attention=block_self_attention.construct(\r\n              is_decoder=False, has_relative_attention_bias=(i == 0)\r\n          ),\r\n          dropout=dropout\r\n      ),\r\n```\r\n\r\nIf I am right that this would be the desired behavior, I can prepare a merge request.\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5683/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5683/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5682", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5682/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5682/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5682/events", "html_url": "https://github.com/allenai/allennlp/issues/5682", "id": 1292220251, "node_id": "I_kwDOBXH8-M5NBbdb", "number": 5682, "title": "Training a transformer classifier with DDP", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2022-07-03T06:20:24Z", "updated_at": "2022-07-21T16:09:46Z", "closed_at": "2022-07-21T16:09:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've pre-trained my own Huggingface Roberta transformer and I'm fine-tuning a classifier with it, I'm using the following components\r\n\r\n        embedder: {\r\n            token_embedders: {\r\n                tokens: {\r\n                    type: \"pretrained_transformer\",\r\n                    model_name: MODEL_NAME,\r\n                    transformer_kwargs: {\r\n                        add_pooling_layer: false\r\n                    }\r\n                }\r\n            },\r\n        },\r\n        encoder: {\r\n            type: \"pass_through\",\r\n            input_dim: MODEL_DIM\r\n        },\r\n        pooler: {\r\n            type: \"bert_pooler\",\r\n            pretrained_model: MODEL_NAME\r\n        },\r\n\r\nThis works fine if I train on a single GPU however, it fails when I try to use DDP - I get errors about unused parameters not contributing to the loss. \r\n\r\nLooking through the code, it seems to be related to the pooler. When you load a `RobertaForMaskedLM` using `AutoModel.from_pretrained` it drops the language model head and adds a pooler layer.\r\n\r\nLooking at the `PretrainedTransformerEmbedder` code, it loads the model from the cache (copy=True) including the pooler - however in `forward` the embeddings are extracted before the pooler.\r\n\r\nIn `BertPooler` however, it loads the model from the cache (copy= False) and then deep copies the pooler\r\n\r\nThis means there are two poolers and the first doesn't contribute to gradients if I'm reading things correctly.\r\n\r\nAlso if I pass `transformer_kwargs: { add_pooling_layer: false }` to the embedder there's no pooler at all and the bert_pooler throws an exception.\r\n\r\nIs this not the intended way of using the pooler?\r\n\r\nAs an aside, oddly torch recommends setting `find_unused_parameters=true` which I assumed was diagnosis but it actually seems to fix the problem?\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5682/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5682/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5666", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5666/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5666/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5666/events", "html_url": "https://github.com/allenai/allennlp/issues/5666", "id": 1270741656, "node_id": "I_kwDOBXH8-M5LvfqY", "number": 5666, "title": "AttributeError: module 'cached_path' has no attribute 'file_friendly_logging'", "user": {"login": "lixiepeng", "id": 14953806, "node_id": "MDQ6VXNlcjE0OTUzODA2", "avatar_url": "https://avatars.githubusercontent.com/u/14953806?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lixiepeng", "html_url": "https://github.com/lixiepeng", "followers_url": "https://api.github.com/users/lixiepeng/followers", "following_url": "https://api.github.com/users/lixiepeng/following{/other_user}", "gists_url": "https://api.github.com/users/lixiepeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/lixiepeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lixiepeng/subscriptions", "organizations_url": "https://api.github.com/users/lixiepeng/orgs", "repos_url": "https://api.github.com/users/lixiepeng/repos", "events_url": "https://api.github.com/users/lixiepeng/events{/privacy}", "received_events_url": "https://api.github.com/users/lixiepeng/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-06-14T12:37:03Z", "updated_at": "2022-06-20T20:31:25Z", "closed_at": "2022-06-20T20:31:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\nFile \"/usr/local/lib/python3.8/site-packages/allennlp/predictors/predictor.py\", line 366, in from_path\r\n    load_archive(archive_path, cuda_device=cuda_device, overrides=overrides),\r\n  File \"/usr/local/lib/python3.8/site-packages/allennlp/models/archival.py\", line 206, in load_archive\r\n    resolved_archive_file = cached_path(archive_file)\r\n  File \"/usr/local/lib/python3.8/site-packages/allennlp/common/file_utils.py\", line 135, in cached_path\r\n    _cached_path.file_friendly_logging(common_logging.FILE_FRIENDLY_LOGGING)\r\nAttributeError: module 'cached_path' has no attribute 'file_friendly_logging'\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5666/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5666/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5664", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5664/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5664/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5664/events", "html_url": "https://github.com/allenai/allennlp/issues/5664", "id": 1269247216, "node_id": "I_kwDOBXH8-M5Lpyzw", "number": 5664, "title": "allennlp.common.checks.ConfigurationError", "user": {"login": "swati1504", "id": 83499368, "node_id": "MDQ6VXNlcjgzNDk5MzY4", "avatar_url": "https://avatars.githubusercontent.com/u/83499368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/swati1504", "html_url": "https://github.com/swati1504", "followers_url": "https://api.github.com/users/swati1504/followers", "following_url": "https://api.github.com/users/swati1504/following{/other_user}", "gists_url": "https://api.github.com/users/swati1504/gists{/gist_id}", "starred_url": "https://api.github.com/users/swati1504/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/swati1504/subscriptions", "organizations_url": "https://api.github.com/users/swati1504/orgs", "repos_url": "https://api.github.com/users/swati1504/repos", "events_url": "https://api.github.com/users/swati1504/events{/privacy}", "received_events_url": "https://api.github.com/users/swati1504/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-06-13T10:41:46Z", "updated_at": "2022-06-20T20:37:06Z", "closed_at": "2022-06-20T20:37:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nI am using allennlp 0.8.1 version\r\nOn running the below code:\r\n!allennlp train legal.json -s tmp --include-package mylib \r\nit gives an error: allennlp.common.checks.ConfigurationError: 'Serialization directory (tmp) already exists and is not empty. Specify --recover to recover training from existing output.'\r\n\r\nLooking for help.\r\nThanks in advance.\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:Windows\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Pthon 3.6+\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5664/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5664/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5663", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5663/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5663/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5663/events", "html_url": "https://github.com/allenai/allennlp/issues/5663", "id": 1266660197, "node_id": "I_kwDOBXH8-M5Lf7Nl", "number": 5663, "title": "When training SRL model:\"AssertionError: Found no field that needed padding; we are surprised you got this error, please open an issue on github\"", "user": {"login": "philz0918", "id": 55821420, "node_id": "MDQ6VXNlcjU1ODIxNDIw", "avatar_url": "https://avatars.githubusercontent.com/u/55821420?v=4", "gravatar_id": "", "url": "https://api.github.com/users/philz0918", "html_url": "https://github.com/philz0918", "followers_url": "https://api.github.com/users/philz0918/followers", "following_url": "https://api.github.com/users/philz0918/following{/other_user}", "gists_url": "https://api.github.com/users/philz0918/gists{/gist_id}", "starred_url": "https://api.github.com/users/philz0918/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/philz0918/subscriptions", "organizations_url": "https://api.github.com/users/philz0918/orgs", "repos_url": "https://api.github.com/users/philz0918/repos", "events_url": "https://api.github.com/users/philz0918/events{/privacy}", "received_events_url": "https://api.github.com/users/philz0918/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2022-06-09T21:07:28Z", "updated_at": "2022-10-06T16:10:53Z", "closed_at": "2022-10-06T16:10:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. --> We're attempting to train a SRL model, using the configuration file seen below. \r\nBelow the configuration file, there is a conll formatted data example that we're using.\r\nAs per this, [stackoverflow question](https://stackoverflow.com/questions/69090025/how-to-train-allennlp-srl-on-non-english-languages), the only columns that are needed are words and SRLtags columns. Can you please confirm that this is the case, if so I'm not sure why we're receiving this error, please advise.\r\n\r\n```\r\nlocal bert_model = \"bert-base-uncased\";\r\n\r\n{\r\n    \"dataset_reader\": {\r\n      \"type\": \"srl\",\r\n      \"bert_model_name\": bert_model,\r\n    },\r\n\r\n    \"data_loader\": {\r\n      \"batch_sampler\": {\r\n        \"type\": \"bucket\",\r\n        \"batch_size\" : 32\r\n      }\r\n    },\r\n\r\n    \"train_data_path\": \"path/conll_data/ALLEN_FRENCH_TEST_2_train.conll\",\r\n    \"validation_data_path\":\"path/conll_data/ALLEN_FRENCH_TEST_2_val.conll\",\r\n\r\n    \"model\": {\r\n        \"type\": \"srl_bert\",\r\n        \"embedding_dropout\": 0.1,\r\n        \"bert_model\": bert_model,\r\n    },\r\n\r\n    \"trainer\": {\r\n        \"optimizer\": {\r\n            \"type\": \"huggingface_adamw\",\r\n            \"lr\": 5e-5,\r\n            \"correct_bias\": false,\r\n            \"weight_decay\": 0.01,\r\n            \"parameter_groups\": [\r\n              [[\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\", \"layer_norm.weight\"], {\"weight_decay\": 0.0}],\r\n            ],\r\n        },\r\n\r\n        \"learning_rate_scheduler\": {\r\n            \"type\": \"slanted_triangular\",\r\n        },\r\n        \"checkpointer\": {\r\n            \"keep_most_recent_by_count\": 2,\r\n        },\r\n        \"grad_norm\": 1.0,\r\n        \"num_epochs\": 15,\r\n        \"validation_metric\": \"+f1-measure-overall\",\r\n    },\r\n}\r\n```\r\n\r\n```\r\n_\t_\t0\t@Greguyyyy\tADP\t_\t_\t_\t_\t_\t_\t_\t_\t_\r\n_\t_\t1\t@HalbeardD\tPROPN\t_\t_\t_\t_\t_\t_\t_\t_\t_\r\n_\t_\t2\t@Tlibdij\tPROPN\t_\t_\t_\t_\t_\t_\t_\t_\t_\r\n_\t_\t3\t@JLMelenchon\tNUM\t_\t_\t_\t_\t_\t_\t_\t_\t_\r\n_\t_\t4\t@BurgerKingFR\tPROPN\t_\t_\t_\t_\t_\t_\t_\t_\t_\r\n_\t_\t5\tHonn\u00eatement\tADV\t_\t_\t_\t_\t_\t_\t_\t(ARGM-ADV*)\t_\r\n_\t_\t6\tle\tDET\t_\t_\t_\t_\t_\t_\t_\t_\t_\r\n_\t_\t7\tcapitalisme\tNOUN\t_\t_\t_\t_\t_\t_\t_\t(ARG1*)\t_\r\n_\t_\t8\ta\tAUX\t_\t_\t_\t_\t_\t_\t(V*)\t_\t_\r\n_\t_\t9\t\u00e9t\u00e9\tAUX\t_\t_\t_\t_\t_\t_\t_\t(ARG2*)\t_\r\n_\t_\t10\tg\u00e9nial\tADJ\t_\t_\t_\t_\t_\t_\t_\t_\t_\r\n_\t_\t11\tsur\tADP\t_\t_\t_\t_\t_\t_\t_\t(ARGM-TMP*\t_\r\n_\t_\t12\tcette\tDET\t_\t_\t_\t_\t_\t_\t_\t*\t_\r\n_\t_\t13\tp\u00e9riode\tNOUN\t_\t_\t_\t_\t_\t_\t_\t*)\t_\r\n_\t_\t14\t\u2026\tPROPN\t_\t_\t_\t_\t_\t_\t_\t_\t_\r\n```\r\n\r\n<details>\r\n<summary><b>Python traceback: </b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n2022-06-09 20:21:20,754 - CRITICAL - root - Uncaught exception\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/__main__.py\", line 39, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/__init__.py\", line 120, in main\r\n    args.func(args)\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py\", line 120, in train_model_from_args\r\n    file_friendly_logging=args.file_friendly_logging,\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py\", line 186, in train_model_from_file\r\n    return_model=return_model,\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py\", line 264, in train_model\r\n    file_friendly_logging=file_friendly_logging,\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py\", line 508, in _train_worker\r\n    metrics = train_loop.run()\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py\", line 581, in run\r\n    return self.trainer.train()\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/training/gradient_descent_trainer.py\", line 771, in train\r\n    metrics, epoch = self._try_train()\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/training/gradient_descent_trainer.py\", line 793, in _try_train\r\n    train_metrics = self._train_epoch(epoch)\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/training/gradient_descent_trainer.py\", line 473, in _train_epoch\r\n    for batch_group in batch_group_generator_tqdm:\r\n  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1195, in __iter__\r\n    for obj in iterable:\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/common/util.py\", line 142, in lazy_groups_of\r\n    s = list(islice(iterator, group_size))\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 335, in __iter__\r\n    yield from self._iter_batches()\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 395, in _iter_batches\r\n    for batch in self._instances_to_batches(self.iter_instances(), move_to_device=True):\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 639, in _instances_to_batches\r\n    for batch in batches:\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 636, in <genexpr>\r\n    [instances[i] for i in batch_indices]\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/data/samplers/bucket_batch_sampler.py\", line 117, in get_batch_indices\r\n    indices, _ = self._argsort_by_padding(instances)\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/data/samplers/bucket_batch_sampler.py\", line 92, in _argsort_by_padding\r\n    self._guess_sorting_keys(instances)\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/data/samplers/bucket_batch_sampler.py\", line 159, in _guess_sorting_keys\r\n    \"Found no field that needed padding; we are surprised you got this error, please \"\r\nAssertionError: Found no field that needed padding; we are surprised you got this error, please open an issue on github\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Googlecolab(Linux)\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.7.13\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==1.0.0\r\naiohttp==3.8.1\r\naiosignal==1.2.0\r\nalabaster==0.7.12\r\nalbumentations==0.1.12\r\nallennlp==2.9.3\r\nallennlp-models==2.9.3\r\naltair==4.2.0\r\nappdirs==1.4.4\r\nargon2-cffi==21.3.0\r\nargon2-cffi-bindings==21.2.0\r\narviz==0.12.1\r\nastor==0.8.1\r\nastropy==4.3.1\r\nastunparse==1.6.3\r\nasync-timeout==4.0.2\r\nasynctest==0.13.0\r\natari-py==0.2.9\r\natomicwrites==1.4.0\r\nattrs==21.4.0\r\naudioread==2.1.9\r\nautograd==1.4\r\nBabel==2.10.1\r\nbackcall==0.2.0\r\nbackports.csv==1.0.7\r\nbase58==2.1.1\r\nbeautifulsoup4==4.6.3\r\nbert-score==0.3.11\r\nbleach==5.0.0\r\nblis==0.4.1\r\nbokeh==2.3.3\r\nboto3==1.24.5\r\nbotocore==1.27.5\r\nBottleneck==1.3.4\r\nbranca==0.5.0\r\nbs4==0.0.1\r\nCacheControl==0.12.11\r\ncached-path==1.1.2\r\ncached-property==1.5.2\r\ncachetools==4.2.4\r\ncatalogue==1.0.0\r\ncertifi==2022.5.18.1\r\ncffi==1.15.0\r\ncftime==1.6.0\r\nchardet==3.0.4\r\ncharset-normalizer==2.0.12\r\nchecklist==0.0.11\r\ncheroot==8.6.0\r\nCherryPy==18.6.1\r\nclick==7.1.2\r\ncloudpickle==1.3.0\r\ncmake==3.22.4\r\ncmdstanpy==0.9.5\r\ncolorcet==3.0.0\r\ncolorlover==0.3.0\r\ncommunity==1.0.0b1\r\nconllu==4.4.1\r\ncontextlib2==0.5.5\r\nconvertdate==2.4.0\r\ncoverage==3.7.1\r\ncoveralls==0.5\r\ncrcmod==1.7\r\ncryptography==37.0.2\r\ncufflinks==0.17.3\r\ncvxopt==1.2.7\r\ncvxpy==1.0.31\r\ncycler==0.11.0\r\ncymem==2.0.6\r\nCython==0.29.30\r\ndaft==0.0.4\r\ndask==2.12.0\r\ndatascience==0.10.6\r\ndatasets==2.2.2\r\ndebugpy==1.0.0\r\ndecorator==4.4.2\r\ndefusedxml==0.7.1\r\ndescartes==1.1.0\r\ndill==0.3.4\r\ndistributed==1.25.3\r\ndlib==19.18.0+zzzcolab20220513001918\r\ndm-tree==0.1.7\r\ndocker-pycreds==0.4.0\r\ndocopt==0.6.2\r\ndocutils==0.17.1\r\ndopamine-rl==1.0.5\r\nearthengine-api==0.1.311\r\neasydict==1.9\r\necos==2.0.10\r\neditdistance==0.5.3\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nentrypoints==0.4\r\nephem==4.1.3\r\net-xmlfile==1.1.0\r\nfa2==0.3.5\r\nfairscale==0.4.6\r\nfastai==1.0.61\r\nfastdtw==0.3.4\r\nfastjsonschema==2.15.3\r\nfastprogress==1.0.2\r\nfastrlock==0.8\r\nfbprophet==0.7.1\r\nfeather-format==0.4.1\r\nfeedparser==6.0.10\r\nfilelock==3.4.2\r\nfirebase-admin==4.4.0\r\nfix-yahoo-finance==0.0.22\r\nFlask==1.1.4\r\nflatbuffers==2.0\r\nfolium==0.8.3\r\nfr-core-news-sm @ https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz\r\nfrozenlist==1.3.0\r\nfsspec==2022.5.0\r\nftfy==6.1.1\r\nfuture==0.16.0\r\ngast==0.5.3\r\nGDAL==2.2.2\r\ngdown==4.4.0\r\ngensim==3.6.0\r\ngeographiclib==1.52\r\ngeopy==1.17.0\r\ngin-config==0.5.0\r\ngitdb==4.0.9\r\nGitPython==3.1.27\r\nglob2==0.7\r\ngoogle==2.0.3\r\ngoogle-api-core==1.31.6\r\ngoogle-api-python-client==1.12.11\r\ngoogle-auth==1.35.0\r\ngoogle-auth-httplib2==0.0.4\r\ngoogle-auth-oauthlib==0.4.6\r\ngoogle-cloud-bigquery==1.21.0\r\ngoogle-cloud-bigquery-storage==1.1.1\r\ngoogle-cloud-core==2.3.1\r\ngoogle-cloud-datastore==1.8.0\r\ngoogle-cloud-firestore==1.7.0\r\ngoogle-cloud-language==1.2.0\r\ngoogle-cloud-storage==2.4.0\r\ngoogle-cloud-translate==1.5.0\r\ngoogle-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\r\ngoogle-crc32c==1.3.0\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==2.3.3\r\ngoogleapis-common-protos==1.56.2\r\ngoogledrivedownloader==0.4\r\ngraphviz==0.10.1\r\ngreenlet==1.1.2\r\ngrpcio==1.46.3\r\ngspread==3.4.2\r\ngspread-dataframe==3.0.8\r\ngym==0.17.3\r\nh5py==3.1.0\r\nHeapDict==1.0.1\r\nhijri-converter==2.2.4\r\nholidays==0.10.5.2\r\nholoviews==1.14.9\r\nhtml5lib==1.0.1\r\nhttpimport==0.5.18\r\nhttplib2==0.17.4\r\nhttplib2shim==0.0.3\r\nhuggingface-hub==0.5.1\r\nhumanize==0.5.1\r\nhyperopt==0.1.2\r\nideep4py==2.0.0.post3\r\nidna==2.10\r\nimageio==2.4.1\r\nimagesize==1.3.0\r\nimbalanced-learn==0.8.1\r\nimblearn==0.0\r\nimgaug==0.2.9\r\nimportlib-metadata==4.11.4\r\nimportlib-resources==5.7.1\r\nimutils==0.5.4\r\ninflect==2.1.0\r\niniconfig==1.1.1\r\nintel-openmp==2022.1.0\r\nintervaltree==2.1.0\r\nipykernel==4.10.1\r\nipython==5.5.0\r\nipython-genutils==0.2.0\r\nipython-sql==0.3.9\r\nipywidgets==7.7.0\r\niso-639==0.4.5\r\nitsdangerous==1.1.0\r\njaraco.classes==3.2.1\r\njaraco.collections==3.5.1\r\njaraco.context==4.1.1\r\njaraco.functools==3.5.0\r\njaraco.text==3.8.0\r\njax==0.3.8\r\njaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.7+cuda11.cudnn805-cp37-none-manylinux2014_x86_64.whl\r\njedi==0.18.1\r\njieba==0.42.1\r\nJinja2==2.11.3\r\njmespath==1.0.0\r\njoblib==1.1.0\r\njpeg4py==0.1.4\r\njsonnet==0.18.0\r\njsonpickle==2.2.0\r\njsonschema==4.3.3\r\njupyter==1.0.0\r\njupyter-client==5.3.5\r\njupyter-console==5.2.0\r\njupyter-core==4.10.0\r\njupyterlab-pygments==0.2.2\r\njupyterlab-widgets==1.1.0\r\nkaggle==1.5.12\r\nkapre==0.3.7\r\nkeras==2.8.0\r\nKeras-Preprocessing==1.1.2\r\nkeras-vis==0.4.1\r\nkiwisolver==1.4.2\r\nkorean-lunar-calendar==0.2.1\r\nlibclang==14.0.1\r\nlibrosa==0.8.1\r\nlightgbm==2.2.3\r\nllvmlite==0.34.0\r\nlmdb==0.99\r\nLunarCalendar==0.0.9\r\nlxml==4.2.6\r\nMarkdown==3.3.7\r\nMarkupSafe==2.0.1\r\nmatplotlib==3.2.2\r\nmatplotlib-inline==0.1.3\r\nmatplotlib-venn==0.11.7\r\nmissingno==0.5.1\r\nmistune==0.8.4\r\nmizani==0.6.0\r\nmkl==2019.0\r\nmlxtend==0.14.0\r\nmore-itertools==8.13.0\r\nmoviepy==0.2.3.5\r\nmpmath==1.2.1\r\nmsgpack==1.0.3\r\nmultidict==6.0.2\r\nmultiprocess==0.70.12.2\r\nmultitasking==0.0.10\r\nmunch==2.5.0\r\nmurmurhash==1.0.7\r\nmusic21==5.5.0\r\nnatsort==5.5.0\r\nnbclient==0.6.4\r\nnbconvert==5.6.1\r\nnbformat==5.4.0\r\nnest-asyncio==1.5.5\r\nnetCDF4==1.5.8\r\nnetworkx==2.6.3\r\nnibabel==3.0.2\r\nnltk==3.7\r\nnotebook==5.3.1\r\nnumba==0.51.2\r\nnumexpr==2.8.1\r\nnumpy==1.21.6\r\nnvidia-ml-py3==7.352.0\r\noauth2client==4.1.3\r\noauthlib==3.2.0\r\nokgrade==0.4.3\r\nopencv-contrib-python==4.1.2.30\r\nopencv-python==4.1.2.30\r\nopenpyxl==3.0.10\r\nopt-einsum==3.3.0\r\nosqp==0.6.2.post0\r\noverrides==3.1.0\r\npackaging==21.3\r\npalettable==3.3.0\r\npandas==1.3.5\r\npandas-datareader==0.9.0\r\npandas-gbq==0.13.3\r\npandas-profiling==1.4.1\r\npandocfilters==1.5.0\r\npanel==0.12.1\r\nparam==1.12.1\r\nparso==0.8.3\r\npathlib==1.0.1\r\npathtools==0.1.2\r\npatsy==0.5.2\r\npatternfork-nosql==3.6\r\npdfminer.six==20220524\r\npep517==0.12.0\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.1.2\r\npip-tools==6.2.0\r\nplac==1.1.3\r\nplotly==5.5.0\r\nplotnine==0.6.0\r\npluggy==0.7.1\r\npooch==1.6.0\r\nportend==3.1.0\r\nportpicker==1.3.9\r\nprefetch-generator==1.0.1\r\npreshed==3.0.6\r\nprettytable==3.3.0\r\nprogressbar2==3.38.0\r\nprometheus-client==0.14.1\r\npromise==2.3\r\nprompt-toolkit==1.0.18\r\nprotobuf==3.17.3\r\npsutil==5.4.8\r\npsycopg2==2.7.6.1\r\nptyprocess==0.7.0\r\npy==1.11.0\r\npy-rouge==1.1\r\npyarrow==6.0.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycocotools==2.0.4\r\npyconll==3.1.0\r\npycparser==2.21\r\npyct==0.4.8\r\npydata-google-auth==1.4.0\r\npydot==1.3.0\r\npydot-ng==2.0.0\r\npydotplus==2.0.2\r\nPyDrive==1.3.1\r\npyemd==0.5.1\r\npyerfa==2.0.0.1\r\npyglet==1.5.0\r\nPygments==2.6.1\r\npygobject==3.26.1\r\npymc3==3.11.4\r\nPyMeeus==0.5.11\r\npymongo==4.1.1\r\npymystem3==0.2.0\r\nPyOpenGL==3.1.6\r\npyparsing==3.0.9\r\npyrsistent==0.18.1\r\npysndfile==1.3.8\r\nPySocks==1.7.1\r\npystan==2.19.1.1\r\npytest==3.6.4\r\npython-apt==0.0.0\r\npython-chess==0.23.11\r\npython-dateutil==2.8.2\r\npython-docx==0.8.11\r\npython-louvain==0.16\r\npython-slugify==6.1.2\r\npython-utils==3.2.3\r\npytz==2022.1\r\npyviz-comms==2.2.0\r\nPyWavelets==1.3.0\r\nPyYAML==3.13\r\npyzmq==23.0.0\r\nqdldl==0.1.5.post2\r\nqtconsole==5.3.0\r\nQtPy==2.1.0\r\nregex==2022.6.2\r\nrequests==2.23.0\r\nrequests-oauthlib==1.3.1\r\nresampy==0.2.2\r\nresponses==0.18.0\r\nrpy2==3.4.5\r\nrsa==4.8\r\ns3transfer==0.6.0\r\nsacremoses==0.0.53\r\nscikit-image==0.18.3\r\nscikit-learn==1.0.2\r\nscipy==1.4.1\r\nscreen-resolution-extra==0.0.0\r\nscs==3.2.0\r\nseaborn==0.11.2\r\nsemver==2.13.0\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.5.12\r\nsetproctitle==1.2.3\r\nsetuptools-git==1.2\r\nsgmllib3k==1.0.0\r\nShapely==1.8.2\r\nshortuuid==1.0.9\r\nsimplegeneric==0.8.1\r\nsix==1.15.0\r\nsklearn==0.0\r\nsklearn-pandas==1.8.0\r\nsmart-open==6.0.0\r\nsmmap==5.0.0\r\nsnowballstemmer==2.2.0\r\nsortedcontainers==2.4.0\r\nSoundFile==0.10.3.post1\r\nsoupsieve==2.3.2.post1\r\nspacy==2.2.4\r\nSphinx==1.8.6\r\nsphinxcontrib-serializinghtml==1.1.5\r\nsphinxcontrib-websupport==1.2.4\r\nSQLAlchemy==1.4.36\r\nsqlparse==0.4.2\r\nsrsly==1.0.5\r\nstatsmodels==0.10.2\r\nsympy==1.7.1\r\ntables==3.7.0\r\ntabulate==0.8.9\r\ntblib==1.7.0\r\ntempora==5.0.1\r\ntenacity==8.0.1\r\ntensorboard==2.8.0\r\ntensorboard-data-server==0.6.1\r\ntensorboard-plugin-wit==1.8.1\r\ntensorboardX==2.5.1\r\ntensorflow==2.8.2+zzzcolab20220527125636\r\ntensorflow-datasets==4.0.1\r\ntensorflow-estimator==2.8.0\r\ntensorflow-gcs-config==2.8.0\r\ntensorflow-hub==0.12.0\r\ntensorflow-io-gcs-filesystem==0.26.0\r\ntensorflow-metadata==1.8.0\r\ntensorflow-probability==0.16.0\r\ntermcolor==1.1.0\r\nterminado==0.13.3\r\ntestpath==0.6.0\r\ntext-unidecode==1.3\r\ntextblob==0.15.3\r\nTheano-PyMC==1.1.2\r\nthinc==7.4.0\r\nthreadpoolctl==3.1.0\r\ntifffile==2021.11.2\r\ntinycss2==1.1.1\r\ntokenizers==0.10.3\r\ntomli==2.0.1\r\ntoolz==0.11.2\r\ntorch==1.10.2\r\ntorchaudio @ https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp37-cp37m-linux_x86_64.whl\r\ntorchsummary==1.5.1\r\ntorchtext==0.12.0\r\ntorchvision==0.11.3\r\ntornado==5.1.1\r\ntqdm==4.64.0\r\ntraitlets==5.1.1\r\ntransformers==4.3.3\r\ntweepy==3.10.0\r\ntypeguard==2.7.1\r\ntyper==0.4.1\r\ntyping-extensions==4.2.0\r\ntzlocal==1.5.1\r\nuritemplate==3.0.1\r\nurllib3==1.25.11\r\nvega-datasets==0.9.0\r\nwandb==0.12.18\r\nwasabi==0.9.1\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.6.0\r\nword2number==1.1\r\nwordcloud==1.5.0\r\nwrapt==1.14.1\r\nxarray==0.20.2\r\nxarray-einstats==0.2.2\r\nxgboost==0.90\r\nxkit==0.0.0\r\nxlrd==1.1.0\r\nxlwt==1.3.0\r\nxxhash==3.0.0\r\nyarl==1.7.2\r\nyellowbrick==1.4\r\nzc.lockfile==2.0\r\nzict==2.2.0\r\nzipp==3.8.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\nPopulate a training data file and validation file with the above conll example.\r\nRun the below command using the above configuration file.\r\n```\r\nallennlp train /config_path/srl_train_1.jsonnet -s /model_output\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5663/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5663/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5654", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5654/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5654/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5654/events", "html_url": "https://github.com/allenai/allennlp/issues/5654", "id": 1259543953, "node_id": "I_kwDOBXH8-M5LEx2R", "number": 5654, "title": "python train.py Run issue", "user": {"login": "rahul110228", "id": 4384272, "node_id": "MDQ6VXNlcjQzODQyNzI=", "avatar_url": "https://avatars.githubusercontent.com/u/4384272?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rahul110228", "html_url": "https://github.com/rahul110228", "followers_url": "https://api.github.com/users/rahul110228/followers", "following_url": "https://api.github.com/users/rahul110228/following{/other_user}", "gists_url": "https://api.github.com/users/rahul110228/gists{/gist_id}", "starred_url": "https://api.github.com/users/rahul110228/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rahul110228/subscriptions", "organizations_url": "https://api.github.com/users/rahul110228/orgs", "repos_url": "https://api.github.com/users/rahul110228/repos", "events_url": "https://api.github.com/users/rahul110228/events{/privacy}", "received_events_url": "https://api.github.com/users/rahul110228/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-06-03T07:22:33Z", "updated_at": "2022-09-29T11:43:16Z", "closed_at": "2022-06-17T16:09:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## ISSUE\r\nWhen I'm running this command ( python train.py --config config/ud/multilingual/udify_bert_finetune_multilingual.json --name multilingual) then i found this error \"TypeError(\r\nTypeError: UniversalDependenciesDatasetReader._read: return type None is not a typing.Iterable[allennlp.data.instance.Instance].\"\r\n\r\nTermional:\r\nTraceback (most recent call last):\r\n  File \"/Users/rahuldebmohalder/Giga Tech lLtd/Udify Project/udify-master/train.py\", line 18, in <module>\r\n    from udify import util\r\n  File \"/Users/rahuldebmohalder/Giga Tech lLtd/Udify Project/udify-master/udify/__init__.py\", line 1, in <module>\r\n    from udify.dataset_readers import *\r\n  File \"/Users/rahuldebmohalder/Giga Tech lLtd/Udify Project/udify-master/udify/dataset_readers/__init__.py\", line 1, in <module>\r\n    from udify.dataset_readers.universal_dependencies import UniversalDependenciesDatasetReader\r\n  File \"/Users/rahuldebmohalder/Giga Tech lLtd/Udify Project/udify-master/udify/dataset_readers/universal_dependencies.py\", line 29, in <module>\r\n    class UniversalDependenciesDatasetReader(DatasetReader):\r\n  File \"/Users/rahuldebmohalder/Giga Tech lLtd/Udify Project/udify-master/udify/dataset_readers/universal_dependencies.py\", line 39, in UniversalDependenciesDatasetReader\r\n    def _read(self, file_path: str):\r\n  File \"/Users/rahuldebmohalder/opt/anaconda3/envs/udify/lib/python3.9/site-packages/overrides/overrides.py\", line 88, in overrides\r\n    return _overrides(method, check_signature, check_at_runtime)\r\n  File \"/Users/rahuldebmohalder/opt/anaconda3/envs/udify/lib/python3.9/site-packages/overrides/overrides.py\", line 114, in _overrides\r\n    _validate_method(method, super_class, check_signature)\r\n  File \"/Users/rahuldebmohalder/opt/anaconda3/envs/udify/lib/python3.9/site-packages/overrides/overrides.py\", line 135, in _validate_method\r\n    ensure_signature_is_compatible(super_method, method, is_static)\r\n  File \"/Users/rahuldebmohalder/opt/anaconda3/envs/udify/lib/python3.9/site-packages/overrides/signature.py\", line 86, in ensure_signature_is_compatible\r\n    ensure_return_type_compatibility(super_type_hints, sub_type_hints, method_name)\r\n  File \"/Users/rahuldebmohalder/opt/anaconda3/envs/udify/lib/python3.9/site-packages/overrides/signature.py\", line 269, in ensure_return_type_compatibility\r\n    raise TypeError(\r\nTypeError: UniversalDependenciesDatasetReader._read: return type `None` is not a `typing.Iterable[allennlp.data.instance.Instance]`.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5654/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5654/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5626", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5626/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5626/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5626/events", "html_url": "https://github.com/allenai/allennlp/issues/5626", "id": 1212008724, "node_id": "I_kwDOBXH8-M5IPckU", "number": 5626, "title": "`ExponentialMovingAverage` processes these parameters whose `requires_grad=False`", "user": {"login": "Zessay", "id": 39905704, "node_id": "MDQ6VXNlcjM5OTA1NzA0", "avatar_url": "https://avatars.githubusercontent.com/u/39905704?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zessay", "html_url": "https://github.com/Zessay", "followers_url": "https://api.github.com/users/Zessay/followers", "following_url": "https://api.github.com/users/Zessay/following{/other_user}", "gists_url": "https://api.github.com/users/Zessay/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zessay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zessay/subscriptions", "organizations_url": "https://api.github.com/users/Zessay/orgs", "repos_url": "https://api.github.com/users/Zessay/repos", "events_url": "https://api.github.com/users/Zessay/events{/privacy}", "received_events_url": "https://api.github.com/users/Zessay/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-04-22T08:25:33Z", "updated_at": "2022-05-09T11:21:20Z", "closed_at": "2022-05-06T16:09:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x]  I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nI defined a parameter `field_p` whose `requires_grad` is `False` in my model,  and use `moving_average` in the trainer. Actually, I think the parameter `field_p` doesn't need to moving average in the training procedure, but the `apply` method of `ExponentialMovingAverage` doesn't check the `requires_grad` property and apply to all parameters.\r\n\r\n```python\r\ndef apply(self):\r\n        ....\r\n        if num_updates is not None:\r\n            decay = min(\r\n                self._decay, (self._numerator + num_updates) / (self._denominator + num_updates)\r\n            )\r\n        else:\r\n            decay = self._decay\r\n\r\n        for name, parameter in self._parameters:\r\n            self._shadows[name].mul_(decay).add_((1 - decay) * parameter.data)\r\n```\r\nIf the `dtype` of `field_p` is `torch.long`, this will raise `RuntimeError`.\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nresult type Float can't be cast to the desired output type Long\r\n  File \"[/xxxtests/train_local.py]()\", line 139, in apply\r\n    self._shadows[name].mul_(decay).add_((1 - decay) * parameter.data)\r\n  File \"[/xxx/ctr/trainer.py]()\", line 216, in _train_epoch\r\n    self._moving_average.apply(self._total_batches_completed + 1)\r\n  File \"[/xxx/train_local.py]()\", line 249, in train_pipeline\r\n    trainer.train()\r\n  File \"[/xxx/tests/train_local.py]()\", line 254, in <module>\r\n    train_pipeline()\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.13\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5626/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5626/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5616", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5616/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5616/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5616/events", "html_url": "https://github.com/allenai/allennlp/issues/5616", "id": 1193537900, "node_id": "I_kwDOBXH8-M5HI_Fs", "number": 5616, "title": "Unable to `pip install allennlp-models`. Torch version and blis compile issues.", "user": {"login": "brochington", "id": 3392188, "node_id": "MDQ6VXNlcjMzOTIxODg=", "avatar_url": "https://avatars.githubusercontent.com/u/3392188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brochington", "html_url": "https://github.com/brochington", "followers_url": "https://api.github.com/users/brochington/followers", "following_url": "https://api.github.com/users/brochington/following{/other_user}", "gists_url": "https://api.github.com/users/brochington/gists{/gist_id}", "starred_url": "https://api.github.com/users/brochington/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brochington/subscriptions", "organizations_url": "https://api.github.com/users/brochington/orgs", "repos_url": "https://api.github.com/users/brochington/repos", "events_url": "https://api.github.com/users/brochington/events{/privacy}", "received_events_url": "https://api.github.com/users/brochington/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2022-04-05T18:02:11Z", "updated_at": "2022-04-14T22:50:09Z", "closed_at": "2022-04-14T22:50:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [X] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [X] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [X] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [X] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [X] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [X] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [X] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [X] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [X] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [X] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nAfter installing Pytorch (1.11) and AllenNLP (2.9.2), via pip in a conda env, I am unable to `pip install allennlp-models`.  I get one of two errors, detailed below.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n## Error 1\r\n\r\nERROR: Cannot install allennlp-models==1.2.1, allennlp-models==1.2.2, allennlp-models==1.3.0, allennlp-models==1.4.0, allennlp-models==1.4.1, allennlp-models==1.5.0, allennlp-models==2.0.0, allennlp-models==2.0.1, allennlp-models==2.1.0, allennlp-models==2.2.0, allennlp-models==2.3.0, allennlp-models==2.4.0, allennlp-models==2.5.0, allennlp-models==2.6.0, allennlp-models==2.7.0, allennlp-models==2.8.0 and allennlp-models==2.9.0 because these package versions have conflicting dependencies.\r\n\r\nThe conflict is caused by:\r\n    allennlp-models 2.9.0 depends on torch<1.11.0 and >=1.7.0\r\n    allennlp-models 2.8.0 depends on torch<1.11.0 and >=1.7.0\r\n    allennlp-models 2.7.0 depends on torch<1.10.0 and >=1.7.0\r\n    allennlp-models 2.6.0 depends on torch<1.10.0 and >=1.7.0\r\n    allennlp-models 2.5.0 depends on torch<1.9.0 and >=1.7.0\r\n    allennlp-models 2.4.0 depends on torch<1.9.0 and >=1.7.0\r\n    allennlp-models 2.3.0 depends on torch<1.9.0 and >=1.7.0\r\n    allennlp-models 2.2.0 depends on torch<1.9.0 and >=1.7.0\r\n    allennlp-models 2.1.0 depends on torch<1.8.0 and >=1.7.0\r\n    allennlp-models 2.0.1 depends on torch<1.8.0 and >=1.7.0\r\n    allennlp-models 2.0.0 depends on torch<1.8.0 and >=1.7.0\r\n    allennlp-models 1.5.0 depends on torch<1.8.0 and >=1.7.0\r\n    allennlp-models 1.4.1 depends on torch<1.8.0 and >=1.7.0\r\n    allennlp-models 1.4.0 depends on torch<1.8.0 and >=1.7.0\r\n    allennlp-models 1.3.0 depends on torch<1.8.0 and >=1.7.0\r\n    allennlp-models 1.2.2 depends on torch<1.8.0 and >=1.7.0\r\n    allennlp-models 1.2.1 depends on torch<1.8.0 and >=1.7.0\r\n\r\nTo fix this you could try to:\r\n1. loosen the range of package versions you've specified\r\n2. remove package versions to allow pip attempt to solve the dependency conflict\r\n\r\nERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\r\n\r\n## Error 2\r\n\r\nCompiler gcc\r\n            building 'blis.cy' extension\r\n            creating build/temp.linux-x86_64-3.10\r\n            creating build/temp.linux-x86_64-3.10/blis\r\n            gcc -pthread -B /home/brochstilley/miniforge3/envs/allennlp-api/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/brochstilley/miniforge3/envs/allennlp-api/include -fPIC -O2 -isystem /home/brochstilley/miniforge3/envs/allennlp-api/include -fPIC -I/tmp/pip-install-_etaqpbt/blis_322118b0f1e54b949f5124bb925aef68/include -I/tmp/pip-install-_etaqpbt/blis_322118b0f1e54b949f5124bb925aef68/blis/_src/include/linux-x86_64 -I/home/brochstilley/miniforge3/envs/allennlp-api/include/python3.10 -c blis/cy.c -o build/temp.linux-x86_64-3.10/blis/cy.o -std=c99\r\n            gcc: error: blis/cy.c: No such file or directory\r\n            gcc: fatal error: no input files\r\n            compilation terminated.\r\n            error: command '/usr/bin/gcc' failed with exit code 1\r\n            [end of output]\r\n      \r\n        note: This error originates from a subprocess, and is likely not a problem with pip.\r\n      error: legacy-install-failure\r\n      \r\n      \u00d7 Encountered error while trying to install package.\r\n      \u2570\u2500> blis\r\n      \r\n      note: This is an issue with the package mentioned above, not pip.\r\n      hint: See above for output from the failure.\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n\u00d7 pip subprocess to install build dependencies did not run successfully.\r\n\u2502 exit code: 1\r\n\u2570\u2500> See above for output.\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux (KDE Neon (ubuntu))\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.10.4\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==2.9.2\r\nargon2-cffi==21.3.0\r\nargon2-cffi-bindings==21.2.0\r\nasttokens==2.0.5\r\nattrs==21.4.0\r\nbackcall==0.2.0\r\nbackports.csv==1.0.7\r\nbase58==2.1.1\r\nbeautifulsoup4==4.10.0\r\nbleach==4.1.0\r\nblis==0.7.7\r\nboto3==1.21.33\r\nbotocore==1.24.33\r\ncached-path==1.1.1\r\ncachetools==5.0.0\r\ncatalogue==2.0.7\r\ncertifi==2021.10.8\r\ncffi==1.15.0\r\nchardet==4.0.0\r\ncharset-normalizer==2.0.12\r\nchecklist==0.0.11\r\ncheroot==8.6.0\r\nCherryPy==18.6.1\r\nclick==8.0.4\r\ncryptography==36.0.2\r\ncymem==2.0.6\r\ndebugpy==1.6.0\r\ndecorator==5.1.1\r\ndefusedxml==0.7.1\r\ndill==0.3.4\r\ndocker-pycreds==0.4.0\r\nentrypoints==0.4\r\nexecuting==0.8.3\r\nfairscale==0.4.6\r\nfastjsonschema==2.15.3\r\nfeedparser==6.0.8\r\nfilelock==3.6.0\r\nFlask==2.1.1\r\nfuture==0.18.2\r\ngitdb==4.0.9\r\nGitPython==3.1.27\r\ngoogle-api-core==2.7.1\r\ngoogle-auth==2.6.2\r\ngoogle-cloud-core==2.2.3\r\ngoogle-cloud-storage==2.2.1\r\ngoogle-crc32c==1.3.0\r\ngoogle-resumable-media==2.3.2\r\ngoogleapis-common-protos==1.56.0\r\nh5py==3.6.0\r\nhuggingface-hub==0.4.0\r\nidna==3.3\r\niniconfig==1.1.1\r\nipykernel==6.12.1\r\nipython==8.2.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.7.0\r\niso-639==0.4.5\r\nitsdangerous==2.1.2\r\njaraco.classes==3.2.1\r\njaraco.collections==3.5.1\r\njaraco.context==4.1.1\r\njaraco.functools==3.5.0\r\njaraco.text==3.7.0\r\njedi==0.18.1\r\nJinja2==3.1.1\r\njmespath==1.0.0\r\njoblib==1.1.0\r\njsonnet==0.18.0\r\njsonschema==4.4.0\r\njupyter==1.0.0\r\njupyter-client==7.2.1\r\njupyter-console==6.4.3\r\njupyter-core==4.9.2\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.1.0\r\nlangcodes==3.3.0\r\nlmdb==1.3.0\r\nlxml==4.8.0\r\nMarkupSafe==2.1.1\r\nmatplotlib-inline==0.1.3\r\nmistune==0.8.4\r\nmore-itertools==8.12.0\r\nmunch==2.5.0\r\nmurmurhash==1.0.6\r\nnbclient==0.5.13\r\nnbconvert==6.4.5\r\nnbformat==5.3.0\r\nnest-asyncio==1.5.5\r\nnltk==3.7\r\nnotebook==6.4.10\r\nnumpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1649059883087/work\r\npackaging==21.3\r\npandocfilters==1.5.0\r\nparso==0.8.3\r\npathtools==0.1.2\r\npathy==0.6.1\r\npatternfork-nosql==3.6\r\npdfminer.six==20220319\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow @ file:///home/conda/feedstock_root/build_artifacts/pillow_1648857107578/work\r\npluggy==1.0.0\r\nportend==3.1.0\r\npreshed==3.0.6\r\nprometheus-client==0.13.1\r\npromise==2.3\r\nprompt-toolkit==3.0.29\r\nprotobuf==3.20.0\r\npsutil==5.9.0\r\nptyprocess==0.7.0\r\npure-eval==0.2.2\r\npy==1.11.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.21\r\npydantic==1.8.2\r\nPygments==2.11.2\r\npyparsing==3.0.7\r\npyrsistent==0.18.1\r\npytest==7.1.1\r\npython-dateutil==2.8.2\r\npython-docx==0.8.11\r\npytz==2022.1\r\nPyYAML==6.0\r\npyzmq==22.3.0\r\nqtconsole==5.3.0\r\nQtPy==2.0.1\r\nregex==2022.3.15\r\nrequests==2.27.1\r\nrsa==4.8\r\ns3transfer==0.5.2\r\nsacremoses==0.0.49\r\nscikit-learn==1.0.2\r\nscipy==1.8.0\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.5.8\r\nsetproctitle==1.2.2\r\nsgmllib3k==1.0.0\r\nshortuuid==1.0.8\r\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\r\nsmart-open==5.2.1\r\nsmmap==5.0.0\r\nsoupsieve==2.3.1\r\nspacy==3.2.4\r\nspacy-legacy==3.0.9\r\nspacy-loggers==1.0.2\r\nsrsly==2.4.2\r\nstack-data==0.2.0\r\ntempora==5.0.1\r\ntensorboardX==2.5\r\ntermcolor==1.1.0\r\nterminado==0.13.3\r\ntestpath==0.6.0\r\nthinc==8.0.15\r\nthreadpoolctl==3.1.0\r\ntokenizers==0.11.6\r\ntomli==2.0.1\r\ntorch==1.11.0\r\ntorchaudio==0.11.0\r\ntorchvision==0.12.0\r\ntornado==6.1\r\ntqdm==4.63.2\r\ntraitlets==5.1.1\r\ntransformers==4.17.0\r\ntyper==0.4.1\r\ntyping_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1644850595256/work\r\nurllib3==1.26.9\r\nwandb==0.12.11\r\nwasabi==0.9.1\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nWerkzeug==2.1.1\r\nwidgetsnbextension==3.6.0\r\nyaspin==2.1.0\r\nzc.lockfile==2.0\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\r\npip install allennlp\r\npip install allennlp[all]\r\npip install allennlp-models\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5616/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5616/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5602", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5602/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5602/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5602/events", "html_url": "https://github.com/allenai/allennlp/issues/5602", "id": 1174147401, "node_id": "I_kwDOBXH8-M5F_BFJ", "number": 5602, "title": "Unable to import Predictor from allennlp.predictors.predictor @ Apple Silicon Mac", "user": {"login": "ghostintheshellarise", "id": 9712758, "node_id": "MDQ6VXNlcjk3MTI3NTg=", "avatar_url": "https://avatars.githubusercontent.com/u/9712758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghostintheshellarise", "html_url": "https://github.com/ghostintheshellarise", "followers_url": "https://api.github.com/users/ghostintheshellarise/followers", "following_url": "https://api.github.com/users/ghostintheshellarise/following{/other_user}", "gists_url": "https://api.github.com/users/ghostintheshellarise/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghostintheshellarise/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghostintheshellarise/subscriptions", "organizations_url": "https://api.github.com/users/ghostintheshellarise/orgs", "repos_url": "https://api.github.com/users/ghostintheshellarise/repos", "events_url": "https://api.github.com/users/ghostintheshellarise/events{/privacy}", "received_events_url": "https://api.github.com/users/ghostintheshellarise/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2022-03-19T02:19:25Z", "updated_at": "2022-08-09T15:00:57Z", "closed_at": "2022-03-24T16:52:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [X] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [X] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [X] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [X] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [X] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [X] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [X] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [X] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [X] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [X] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- ImportError: cannot import name 'ProcessGroup' from 'torch.distributed' (/Users/xxxxxxx/miniconda3/envs/allennlp_env/lib/python3.8/site-packages/torch/distributed/__init__.py) -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>----> 7 from allennlp.predictors.predictor import Predictor\r\n      8 import allennlp_models.tagging\r\n     10 predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/ner-elmo.2021-02-12.tar.gz\")\r\n\r\nFile ~/miniconda3/envs/allennlp_env/lib/python3.8/site-packages/allennlp/predictors/__init__.py:9, in <module>\r\n      1 \"\"\"\r\n      2 A `Predictor` is\r\n      3 a wrapper for an AllenNLP `Model`\r\n   (...)\r\n      7 a `Predictor` that wraps it.\r\n      8 \"\"\"\r\n----> 9 from allennlp.predictors.predictor import Predictor\r\n     10 from allennlp.predictors.sentence_tagger import SentenceTaggerPredictor\r\n     11 from allennlp.predictors.text_classifier import TextClassifierPredictor\r\n\r\nFile ~/miniconda3/envs/allennlp_env/lib/python3.8/site-packages/allennlp/predictors/predictor.py:18, in <module>\r\n     16 from allennlp.data import DatasetReader, Instance\r\n     17 from allennlp.data.batch import Batch\r\n---> 18 from allennlp.models import Model\r\n     19 from allennlp.models.archival import Archive, load_archive\r\n     20 from allennlp.nn import util\r\n\r\nFile ~/miniconda3/envs/allennlp_env/lib/python3.8/site-packages/allennlp/models/__init__.py:6, in <module>\r\n      1 \"\"\"\r\n      2 These submodules contain the classes for AllenNLP models,\r\n      3 all of which are subclasses of `Model`.\r\n      4 \"\"\"\r\n----> 6 from allennlp.models.model import Model\r\n      7 from allennlp.models.archival import archive_model, load_archive, Archive\r\n      8 from allennlp.models.basic_classifier import BasicClassifier\r\n\r\nFile ~/miniconda3/envs/allennlp_env/lib/python3.8/site-packages/allennlp/models/model.py:22, in <module>\r\n     20 from allennlp.nn import util\r\n     21 from allennlp.nn.module import Module\r\n---> 22 from allennlp.nn.parallel import DdpAccelerator\r\n     23 from allennlp.nn.regularizers import RegularizerApplicator\r\n     25 logger = logging.getLogger(__name__)\r\n\r\nFile ~/miniconda3/envs/allennlp_env/lib/python3.8/site-packages/allennlp/nn/parallel/__init__.py:7, in <module>\r\n      1 from allennlp.nn.parallel.sharded_module_mixin import ShardedModuleMixin\r\n      2 from allennlp.nn.parallel.ddp_accelerator import (\r\n      3     DdpAccelerator,\r\n      4     DdpWrappedModel,\r\n      5     TorchDdpAccelerator,\r\n      6 )\r\n----> 7 from allennlp.nn.parallel.fairscale_fsdp_accelerator import (\r\n      8     FairScaleFsdpAccelerator,\r\n      9     FairScaleFsdpWrappedModel,\r\n     10 )\r\n\r\nFile ~/miniconda3/envs/allennlp_env/lib/python3.8/site-packages/allennlp/nn/parallel/fairscale_fsdp_accelerator.py:4, in <module>\r\n      1 import os\r\n      2 from typing import Tuple, Union, Optional, TYPE_CHECKING, List, Any, Dict, Sequence\r\n----> 4 from fairscale.nn import FullyShardedDataParallel as FS_FSDP\r\n      5 from fairscale.nn.wrap import enable_wrap, wrap\r\n      6 from fairscale.nn.misc import FlattenParamsWrapper\r\n\r\nFile ~/miniconda3/envs/allennlp_env/lib/python3.8/site-packages/fairscale/__init__.py:12, in <module>\r\n      1 # Copyright (c) Facebook, Inc. and its affiliates. All rights reserved.\r\n      2 #\r\n      3 # This source code is licensed under the BSD license found in the\r\n   (...)\r\n      7 # Import most common subpackages\r\n      8 ################################################################################\r\n     10 from typing import List\r\n---> 12 from . import nn\r\n     13 from .version import __version_tuple__\r\n     15 __version__ = \".\".join([str(x) for x in __version_tuple__])\r\n\r\nFile ~/miniconda3/envs/allennlp_env/lib/python3.8/site-packages/fairscale/nn/__init__.py:9, in <module>\r\n      6 from typing import List\r\n      8 from .checkpoint import checkpoint_wrapper\r\n----> 9 from .data_parallel import FullyShardedDataParallel, ShardedDataParallel\r\n     10 from .misc import FlattenParamsWrapper\r\n     11 from .moe import MOELayer, Top2Gate\r\n\r\nFile ~/miniconda3/envs/allennlp_env/lib/python3.8/site-packages/fairscale/nn/data_parallel/__init__.py:8, in <module>\r\n      1 # Copyright (c) Facebook, Inc. and its affiliates. All rights reserved.\r\n      2 #\r\n      3 # This source code is licensed under the BSD license found in the\r\n      4 # LICENSE file in the root directory of this source tree.\r\n      6 from typing import List\r\n----> 8 from .fully_sharded_data_parallel import FullyShardedDataParallel, OffloadConfig, TrainingState, auto_wrap_bn\r\n      9 from .sharded_ddp import ShardedDataParallel\r\n     11 __all__: List[str] = []\r\n\r\nFile ~/miniconda3/envs/allennlp_env/lib/python3.8/site-packages/fairscale/nn/data_parallel/fully_sharded_data_parallel.py:38, in <module>\r\n     36 from torch.autograd import Variable\r\n     37 import torch.distributed as dist\r\n---> 38 from torch.distributed import ProcessGroup\r\n     39 import torch.nn as nn\r\n     40 import torch.nn.functional as F\r\n\r\nImportError: cannot import name 'ProcessGroup' from 'torch.distributed' (/Users/simontse/miniconda3/envs/allennlp_env/lib/python3.8/site-packages/torch/distributed/__init__.py)\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: macOS Monterey ver12.3\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.12\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp @ file:///Users/runner/miniforge3/conda-bld/aiohttp_1637087375815/work\r\naiosignal @ file:///home/conda/feedstock_root/build_artifacts/aiosignal_1636093929600/work\r\nalembic @ file:///home/conda/feedstock_root/build_artifacts/alembic_1647367721563/work\r\nallennlp @ file:///Users/runner/miniforge3/conda-bld/allennlp_1644183594868/work\r\nallennlp-models @ file:///Users/runner/miniforge3/conda-bld/allennlp-models_1644193900256/work\r\nallennlp-optuna @ file:///home/conda/feedstock_root/build_artifacts/allennlp-optuna_1637742042512/work\r\nallennlp-semparse @ file:///Users/runner/miniforge3/conda-bld/allennlp-semparse_1644289991832/work\r\nallennlp-server @ file:///Users/runner/miniforge3/conda-bld/allennlp-server_1644211316665/work\r\nappnope @ file:///Users/runner/miniforge3/conda-bld/appnope_1635819899231/work\r\nargon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1640817743617/work\r\nargon2-cffi-bindings @ file:///Users/runner/miniforge3/conda-bld/argon2-cffi-bindings_1640885719931/work\r\nasttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1618968359944/work\r\nasync-timeout @ file:///home/conda/feedstock_root/build_artifacts/async-timeout_1640026696943/work\r\nattrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1640799537051/work\r\nautopage @ file:///home/conda/feedstock_root/build_artifacts/autopage_1642834347039/work\r\nbackcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\r\nbackports.csv==1.0.7\r\nbackports.functools-lru-cache @ file:///home/conda/feedstock_root/build_artifacts/backports.functools_lru_cache_1618230623929/work\r\nbase58 @ file:///home/conda/feedstock_root/build_artifacts/base58_1635724186165/work\r\nbeautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1631087867185/work\r\nbleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1629908509068/work\r\nblis @ file:///Users/runner/miniforge3/conda-bld/cython-blis_1645002545531/work\r\nboto3 @ file:///home/conda/feedstock_root/build_artifacts/boto3_1647500875427/work\r\nbotocore @ file:///home/conda/feedstock_root/build_artifacts/botocore_1647478405006/work\r\nbrotlipy @ file:///Users/runner/miniforge3/conda-bld/brotlipy_1636012322014/work\r\ncached-path @ file:///Users/runner/miniforge3/conda-bld/cached_path_1646363831472/work\r\ncached-property @ file:///home/conda/feedstock_root/build_artifacts/cached_property_1615209429212/work\r\ncachetools @ file:///home/conda/feedstock_root/build_artifacts/cachetools_1640686991047/work\r\ncatalogue @ file:///Users/runner/miniforge3/conda-bld/catalogue_1638867620917/work\r\ncertifi==2021.10.8\r\ncffi @ file:///Users/runner/miniforge3/conda-bld/cffi_1636046166270/work\r\nchardet @ file:///Users/runner/miniforge3/conda-bld/chardet_1635814976389/work\r\ncharset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1644853463426/work\r\nchecklist @ file:///home/conda/feedstock_root/build_artifacts/checklist_1626355406222/work\r\ncheroot @ file:///home/conda/feedstock_root/build_artifacts/cheroot_1641335003286/work\r\nCherryPy @ file:///Users/runner/miniforge3/conda-bld/cherrypy_1643789202126/work\r\nclick==7.1.2\r\ncliff @ file:///home/conda/feedstock_root/build_artifacts/cliff_1645470499396/work\r\ncmaes @ file:///home/conda/feedstock_root/build_artifacts/cmaes_1613785714721/work\r\ncmd2 @ file:///Users/runner/miniforge3/conda-bld/cmd2_1644164388812/work\r\ncolorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1602866480661/work\r\ncolorlog==6.6.0\r\nconfigparser @ file:///home/conda/feedstock_root/build_artifacts/configparser_1638573090458/work\r\nconllu @ file:///home/conda/feedstock_root/build_artifacts/conllu_1629103029427/work\r\ncryptography @ file:///Users/runner/miniforge3/conda-bld/cryptography_1639699343700/work\r\ncycler @ file:///home/conda/feedstock_root/build_artifacts/cycler_1635519461629/work\r\ncymem @ file:///Users/runner/miniforge3/conda-bld/cymem_1636053450611/work\r\ndataclasses @ file:///home/conda/feedstock_root/build_artifacts/dataclasses_1628958434797/work\r\ndatasets @ file:///home/conda/feedstock_root/build_artifacts/datasets_1647378244171/work\r\ndebugpy @ file:///Users/runner/miniforge3/conda-bld/debugpy_1636043378262/work\r\ndecorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\r\ndefusedxml @ file:///home/conda/feedstock_root/build_artifacts/defusedxml_1615232257335/work\r\ndill @ file:///home/conda/feedstock_root/build_artifacts/dill_1623610058511/work\r\ndocker-pycreds==0.4.0\r\neditdistance @ file:///Users/runner/miniforge3/conda-bld/editdistance_1636224171992/work\r\nentrypoints @ file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\r\nexecuting @ file:///home/conda/feedstock_root/build_artifacts/executing_1646044401614/work\r\nfairscale @ file:///Users/runner/miniforge3/conda-bld/fairscale_1644056098310/work\r\nfeedparser @ file:///home/conda/feedstock_root/build_artifacts/feedparser_1624371037925/work\r\nfilelock @ file:///home/conda/feedstock_root/build_artifacts/filelock_1641470428964/work\r\nFlask @ file:///home/conda/feedstock_root/build_artifacts/flask_1644887820294/work\r\nFlask-Cors @ file:///home/conda/feedstock_root/build_artifacts/flask-cors_1622383494577/work\r\nflit_core @ file:///home/conda/feedstock_root/build_artifacts/flit-core_1645629044586/work/source/flit_core\r\nfonttools @ file:///Users/runner/miniforge3/conda-bld/fonttools_1646922287558/work\r\nfrozenlist @ file:///Users/runner/miniforge3/conda-bld/frozenlist_1643222648494/work\r\nfsspec @ file:///home/conda/feedstock_root/build_artifacts/fsspec_1645566723803/work\r\nftfy @ file:///home/conda/feedstock_root/build_artifacts/ftfy_1647200718722/work\r\nfuture @ file:///Users/runner/miniforge3/conda-bld/future_1635819654955/work\r\ngevent @ file:///Users/runner/miniforge3/conda-bld/gevent_1639267879746/work\r\ngitdb @ file:///home/conda/feedstock_root/build_artifacts/gitdb_1635085722655/work\r\nGitPython @ file:///home/conda/feedstock_root/build_artifacts/gitpython_1645531658201/work\r\ngoogle-api-core @ file:///home/conda/feedstock_root/build_artifacts/google-api-core-split_1644877687275/work\r\ngoogle-auth @ file:///home/conda/feedstock_root/build_artifacts/google-auth_1644503159426/work\r\ngoogle-cloud-core @ file:///home/conda/feedstock_root/build_artifacts/google-cloud-core_1642607638110/work\r\ngoogle-cloud-storage @ file:///home/conda/feedstock_root/build_artifacts/google-cloud-storage_1644876711050/work\r\ngoogle-crc32c @ file:///Users/runner/miniforge3/conda-bld/google-crc32c_1636020985630/work\r\ngoogle-resumable-media @ file:///home/conda/feedstock_root/build_artifacts/google-resumable-media_1635195007097/work\r\ngoogleapis-common-protos @ file:///Users/runner/miniforge3/conda-bld/googleapis-common-protos-feedstock_1647557644942/work\r\ngreenlet @ file:///Users/runner/miniforge3/conda-bld/greenlet_1635837112391/work\r\ngrpcio @ file:///Users/runner/miniforge3/conda-bld/grpcio_1645230394268/work\r\nh5py @ file:///Users/runner/miniforge3/conda-bld/h5py_1637964070496/work\r\nhuggingface-hub @ file:///home/conda/feedstock_root/build_artifacts/huggingface_hub_1641988520462/work\r\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1642433548627/work\r\nimportlib-metadata @ file:///Users/runner/miniforge3/conda-bld/importlib-metadata_1647210434605/work\r\nimportlib-resources @ file:///home/conda/feedstock_root/build_artifacts/importlib_resources_1635615662634/work\r\nipykernel @ file:///Users/runner/miniforge3/conda-bld/ipykernel_1647271194783/work/dist/ipykernel-6.9.2-py3-none-any.whl\r\nipython @ file:///Users/runner/miniforge3/conda-bld/ipython_1646324756182/work\r\nipython-genutils==0.2.0\r\nipywidgets @ file:///home/conda/feedstock_root/build_artifacts/ipywidgets_1647456365981/work\r\niso-639 @ file:///home/conda/feedstock_root/build_artifacts/iso-639_1626355260505/work\r\nitsdangerous @ file:///home/conda/feedstock_root/build_artifacts/itsdangerous_1646849180040/work\r\njaraco.classes @ file:///home/conda/feedstock_root/build_artifacts/jaraco.classes_1619298134024/work\r\njaraco.collections @ file:///home/conda/feedstock_root/build_artifacts/jaraco.collections_1641469018844/work\r\njaraco.context @ file:///home/conda/feedstock_root/build_artifacts/jaraco.context_1646657544740/work\r\njaraco.functools @ file:///home/conda/feedstock_root/build_artifacts/jaraco.functools_1641071972629/work\r\njaraco.text @ file:///Users/runner/miniforge3/conda-bld/jaraco.text_1646672054767/work\r\njedi @ file:///Users/runner/miniforge3/conda-bld/jedi_1637175378067/work\r\nJinja2 @ file:///home/conda/feedstock_root/build_artifacts/jinja2_1636510082894/work\r\njmespath @ file:///home/conda/feedstock_root/build_artifacts/jmespath_1647416812516/work\r\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1633637554808/work\r\njsonnet @ file:///Users/runner/miniforge3/conda-bld/jsonnet_1644086886800/work\r\njsonschema @ file:///home/conda/feedstock_root/build_artifacts/jsonschema-meta_1642000296051/work\r\njupyter @ file:///Users/runner/miniforge3/conda-bld/jupyter_1637233406932/work\r\njupyter-client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1642858610849/work\r\njupyter-console @ file:///home/conda/feedstock_root/build_artifacts/jupyter_console_1646669715337/work\r\njupyter-core @ file:///Users/runner/miniforge3/conda-bld/jupyter_core_1645024702831/work\r\njupyterlab-pygments @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_pygments_1601375948261/work\r\njupyterlab-widgets @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_widgets_1647446862951/work\r\nkiwisolver @ file:///Users/runner/miniforge3/conda-bld/kiwisolver_1647351843120/work\r\nlangcodes @ file:///home/conda/feedstock_root/build_artifacts/langcodes_1636741340529/work\r\nlmdb @ file:///Users/runner/miniforge3/conda-bld/python-lmdb_1644189524859/work\r\nlxml @ file:///Users/runner/miniforge3/conda-bld/lxml_1645124877356/work\r\nMako @ file:///home/conda/feedstock_root/build_artifacts/mako_1646959760357/work\r\nMarkupSafe @ file:///Users/runner/miniforge3/conda-bld/markupsafe_1647364592705/work\r\nmatplotlib @ file:///Users/runner/miniforge3/conda-bld/matplotlib-suite_1639359034653/work\r\nmatplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1631080358261/work\r\nmistune @ file:///Users/runner/miniforge3/conda-bld/mistune_1635845001896/work\r\nmore-itertools @ file:///home/conda/feedstock_root/build_artifacts/more-itertools_1637732846337/work\r\nmultidict @ file:///Users/runner/miniforge3/conda-bld/multidict_1643055408799/work\r\nmultiprocess @ file:///Users/runner/miniforge3/conda-bld/multiprocess_1635876223414/work\r\nmunch==2.5.0\r\nmunkres==1.1.4\r\nmurmurhash @ file:///Users/runner/miniforge3/conda-bld/murmurhash_1636019736584/work\r\nmysqlclient @ file:///Users/runner/miniforge3/conda-bld/mysqlclient_1639024612770/work\r\nnbclient @ file:///home/conda/feedstock_root/build_artifacts/nbclient_1646999386773/work\r\nnbconvert @ file:///Users/runner/miniforge3/conda-bld/nbconvert_1647040578847/work\r\nnbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1646951096007/work\r\nnest-asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1638419302549/work\r\nnetworkx @ file:///home/conda/feedstock_root/build_artifacts/networkx_1646497321764/work\r\nnltk @ file:///home/conda/feedstock_root/build_artifacts/nltk_1633955089856/work\r\nnotebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1647377876077/work\r\nnumpy @ file:///Users/runner/miniforge3/conda-bld/numpy_1646717493174/work\r\noptuna @ file:///home/conda/feedstock_root/build_artifacts/optuna_1633337702246/work\r\npackaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1637239678211/work\r\npandas==1.4.1\r\npandocfilters @ file:///home/conda/feedstock_root/build_artifacts/pandocfilters_1631603243851/work\r\nparsimonious==0.8.1\r\nparso @ file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work\r\npathtools==0.1.2\r\npathy @ file:///home/conda/feedstock_root/build_artifacts/pathy_1635227809952/work\r\nPattern @ file:///home/conda/feedstock_root/build_artifacts/pattern_1588682046427/work\r\npbr @ file:///home/conda/feedstock_root/build_artifacts/pbr_1644225887826/work\r\npdfminer.six @ file:///home/conda/feedstock_root/build_artifacts/pdfminer.six_1634369700996/work\r\npexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1602535608087/work\r\npickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\r\nPillow @ file:///Users/runner/miniforge3/conda-bld/pillow_1645323199912/work\r\nportend @ file:///home/conda/feedstock_root/build_artifacts/portend_1614149298816/work\r\npreshed @ file:///Users/runner/miniforge3/conda-bld/preshed_1636077826592/work\r\nprettytable @ file:///home/conda/feedstock_root/build_artifacts/prettytable_1646674402880/work\r\nprometheus-client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1643395600215/work\r\npromise @ file:///Users/runner/miniforge3/conda-bld/promise_1644078593510/work\r\nprompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1644497866770/work\r\nprotobuf==3.19.4\r\npsutil @ file:///Users/runner/miniforge3/conda-bld/psutil_1640887165910/work\r\nptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\r\npy-rouge @ file:///home/conda/feedstock_root/build_artifacts/py-rouge_1611141518214/work\r\npyarrow==7.0.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.7\r\npycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work\r\npydantic @ file:///Users/runner/miniforge3/conda-bld/pydantic_1636021450594/work\r\nPygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1641580240686/work\r\npyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1643496850550/work\r\npyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1642753572664/work\r\npyperclip @ file:///home/conda/feedstock_root/build_artifacts/pyperclip_1622337600177/work\r\npyrsistent @ file:///Users/runner/miniforge3/conda-bld/pyrsistent_1642534457653/work\r\nPySocks @ file:///Users/runner/miniforge3/conda-bld/pysocks_1635862741516/work\r\npython-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\r\npython-docx @ file:///home/conda/feedstock_root/build_artifacts/python-docx_1622121039670/work\r\npytz @ file:///home/conda/feedstock_root/build_artifacts/pytz_1633452062248/work\r\npyu2f @ file:///home/conda/feedstock_root/build_artifacts/pyu2f_1604248910016/work\r\nPyYAML @ file:///Users/runner/miniforge3/conda-bld/pyyaml_1636139931219/work\r\npyzmq @ file:///Users/runner/miniforge3/conda-bld/pyzmq_1635877710701/work\r\nregex @ file:///Users/runner/miniforge3/conda-bld/regex_1647399893594/work\r\nrepoze.lru==0.7\r\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1641580202195/work\r\nresponses @ file:///home/conda/feedstock_root/build_artifacts/responses_1643839609465/work\r\nRoutes @ file:///home/conda/feedstock_root/build_artifacts/routes_1604230639459/work\r\nrsa @ file:///home/conda/feedstock_root/build_artifacts/rsa_1637781155505/work\r\ns3transfer @ file:///home/conda/feedstock_root/build_artifacts/s3transfer_1645745825648/work\r\nsacremoses @ file:///home/conda/feedstock_root/build_artifacts/sacremoses_1647361442468/work\r\nscikit-learn @ file:///Users/runner/miniforge3/conda-bld/scikit-learn_1640464197451/work\r\nscipy @ file:///Users/runner/miniforge3/conda-bld/scipy_1644357749526/work\r\nSend2Trash @ file:///home/conda/feedstock_root/build_artifacts/send2trash_1628511208346/work\r\nsentencepiece==0.1.96\r\nsentry-sdk @ file:///home/conda/feedstock_root/build_artifacts/sentry-sdk_1646753508615/work\r\nsetproctitle @ file:///Users/runner/miniforge3/conda-bld/setproctitle_1635864315706/work\r\nsgmllib3k @ file:///home/conda/feedstock_root/build_artifacts/sgmllib3k_1600021450347/work\r\nshellingham @ file:///home/conda/feedstock_root/build_artifacts/shellingham_1612179560728/work\r\nshortuuid @ file:///Users/runner/miniforge3/conda-bld/shortuuid_1644056369207/work\r\nsimplejson @ file:///Users/runner/miniforge3/conda-bld/simplejson_1637177164728/work\r\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\r\nsmart-open @ file:///home/conda/feedstock_root/build_artifacts/smart_open_1630238320325/work\r\nsmmap @ file:///home/conda/feedstock_root/build_artifacts/smmap_1611376390914/work\r\nsoupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1638550740809/work\r\nspacy @ file:///Users/runner/miniforge3/conda-bld/spacy_1644658008331/work\r\nspacy-legacy @ file:///home/conda/feedstock_root/build_artifacts/spacy-legacy_1645713043381/work\r\nspacy-loggers @ file:///home/conda/feedstock_root/build_artifacts/spacy-loggers_1634809367310/work\r\nSQLAlchemy @ file:///Users/runner/miniforge3/conda-bld/sqlalchemy_1646615332152/work\r\nsqlparse @ file:///home/conda/feedstock_root/build_artifacts/sqlparse_1631317292236/work\r\nsrsly @ file:///Users/runner/miniforge3/conda-bld/srsly_1638879679486/work\r\nstack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1644872665635/work\r\nstevedore @ file:///Users/runner/miniforge3/conda-bld/stevedore_1639542690056/work\r\ntempora @ file:///home/conda/feedstock_root/build_artifacts/tempora_1643789373873/work\r\ntensorboardX @ file:///home/conda/feedstock_root/build_artifacts/tensorboardx_1645578792360/work\r\ntermcolor==1.1.0\r\nterminado @ file:///Users/runner/miniforge3/conda-bld/terminado_1646684761186/work\r\ntestpath @ file:///home/conda/feedstock_root/build_artifacts/testpath_1645693042223/work\r\nthinc @ file:///Users/runner/miniforge3/conda-bld/thinc_1647363132934/work\r\nthinc-apple-ops==0.0.5\r\nthreadpoolctl @ file:///home/conda/feedstock_root/build_artifacts/threadpoolctl_1643647933166/work\r\ntokenizers @ file:///Users/runner/miniforge3/conda-bld/tokenizers_1632285718817/work\r\ntorch @ file:///Users/runner/miniforge3/conda-bld/pytorch-recipe_1643987637853/work\r\ntorchvision @ file:///Users/runner/miniforge3/conda-bld/torchvision-split_1644148546672/work\r\ntornado @ file:///Users/runner/miniforge3/conda-bld/tornado_1635819723809/work\r\ntqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1646031859244/work\r\ntraitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1635260543454/work\r\ntransformers @ file:///home/conda/feedstock_root/build_artifacts/transformers_1640232623006/work\r\ntyper @ file:///home/conda/feedstock_root/build_artifacts/typer_1630326630489/work\r\ntyping_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1644850595256/work\r\nunicodedata2 @ file:///Users/runner/miniforge3/conda-bld/unicodedata2_1640031423081/work\r\nUnidecode @ file:///home/conda/feedstock_root/build_artifacts/unidecode_1646918762405/work\r\nurllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1647489083693/work\r\nwandb @ file:///home/conda/feedstock_root/build_artifacts/wandb_1646271144123/work\r\nwasabi @ file:///home/conda/feedstock_root/build_artifacts/wasabi_1638865582891/work\r\nwcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1600965781394/work\r\nwebencodings==0.5.1\r\nWerkzeug @ file:///home/conda/feedstock_root/build_artifacts/werkzeug_1644332431572/work\r\nwidgetsnbextension @ file:///Users/runner/miniforge3/conda-bld/widgetsnbextension_1647446968519/work\r\nword2number==1.1\r\nxxhash @ file:///Users/runner/miniforge3/conda-bld/python-xxhash_1646085210894/work\r\nyarl @ file:///Users/runner/miniforge3/conda-bld/yarl_1636047129772/work\r\nyaspin @ file:///home/conda/feedstock_root/build_artifacts/yaspin_1630004424954/work\r\nzc.lockfile==2.0\r\nzipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1643828507773/work\r\nzope.event @ file:///home/conda/feedstock_root/build_artifacts/zope.event_1600479883063/work\r\nzope.interface @ file:///Users/runner/miniforge3/conda-bld/zope.interface_1635859682970/work\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n1. Create a separate env for using:  conda install -c conda-forge python=3.8 allennlp\r\n2. Install additional libraries accordingly: conda install -c conda-forge allennlp-models allennlp-semparse allennlp-server allennlp-optuna  \r\n3. Then I also install thing for apple silicon: pip install thinc-apple-ops\r\n\r\n<details>\r\n<summary><b>\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.tagging\r\n\r\npredictor = **Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/ner-elmo.2021-02-12.tar.gz\")</b</summary>**\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n`from allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.tagging\r\n\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/ner-elmo.2021-02-12.tar.gz\")`\r\n</p>\r\n</details>\r\n[allennlp.pdf](https://github.com/allenai/allennlp/files/8308431/allennlp.pdf)\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5602/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5602/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5600", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5600/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5600/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5600/events", "html_url": "https://github.com/allenai/allennlp/issues/5600", "id": 1170635701, "node_id": "I_kwDOBXH8-M5Fxnu1", "number": 5600, "title": "allennlp.common.checks.ConfigurationError: key \"optimizer\" is required at location \"trainer.learning_rate_scheduler.\"", "user": {"login": "dangne", "id": 36122564, "node_id": "MDQ6VXNlcjM2MTIyNTY0", "avatar_url": "https://avatars.githubusercontent.com/u/36122564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangne", "html_url": "https://github.com/dangne", "followers_url": "https://api.github.com/users/dangne/followers", "following_url": "https://api.github.com/users/dangne/following{/other_user}", "gists_url": "https://api.github.com/users/dangne/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangne/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangne/subscriptions", "organizations_url": "https://api.github.com/users/dangne/orgs", "repos_url": "https://api.github.com/users/dangne/repos", "events_url": "https://api.github.com/users/dangne/events{/privacy}", "received_events_url": "https://api.github.com/users/dangne/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2022-03-16T07:20:38Z", "updated_at": "2022-03-24T16:53:19Z", "closed_at": "2022-03-24T16:53:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nI'm using `allennlp train` with the following config\r\n<details>\r\n<summary><b>JSON config:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nlocal args = {\r\n    // dataset_reader args\r\n    dataset_reader_name :: \"seq2labels_datareader\",\r\n    pretrained_transformer_name :: \"roberta-base\",\r\n    max_length :: 512,\r\n    delimeters :: {\r\n        \"tokens\": \" \",\r\n        \"labels\": \"SEPL|||SEPR\",\r\n        \"operations\": \"SEPL__SEPR\",\r\n    },\r\n    skip_correct :: true,\r\n    skip_complex :: 0,\r\n    max_len :: 50,\r\n    test_mode :: false,\r\n    tag_strategy :: \"keep_one\",\r\n    tn_prob :: 0,\r\n    tp_prob :: 1,\r\n    broken_dot_strategy :: \"keep\",\r\n\r\n    // data path args\r\n    train_data_path :: \"data/processed/train/errorified_data_0/train_0.txt\",\r\n    validation_data_path :: \"data/processed/val/errorified_data_0/val_0.txt\",\r\n\r\n    // vocab args\r\n    max_vocab_size :: {\r\n        \"tokens\": 30000, \r\n        \"labels\": 5000, \r\n        \"d_tags\": 2,\r\n    },\r\n    vocab_path :: \"vocabulary\",\r\n    tokens_to_add :: {\r\n        \"labels\": [\r\n            \"@@UNKNOWN@@\",\r\n            \"@@PADDING@@\",\r\n        ],\r\n        \"d_tags\": [\r\n            \"@@UNKNOWN@@\",\r\n            \"@@PADDING@@\",\r\n        ],\r\n    },\r\n\r\n    // model args\r\n    model_name :: \"seq2labels\",\r\n    predictor_dropout :: 0.0,\r\n    label_smoothing :: 0.0,\r\n\r\n    // data_loader args\r\n    batch_size :: 64,\r\n    num_workers :: 4,\r\n    max_instances_in_memory :: 64 * 4 * 3,\r\n\r\n    // trainer args\r\n    trainer_name :: \"gec_trainer\",\r\n    lr :: 1e-5,\r\n    patience :: 3,\r\n    num_epochs :: 20,\r\n    model_dir :: \"models/demo_train_from_configs\",\r\n    factor :: 0.1,\r\n    accumulation_size :: 2,\r\n    cold_step_count :: 4,\r\n    cold_lr :: 1e-3,\r\n};\r\n\r\nlocal from_instances_vocab = {\r\n    \"type\": \"from_instances\",\r\n    \"max_vocab_size\": args.max_vocab_size,\r\n    \"tokens_to_add\": args.tokens_to_add,\r\n};\r\n\r\nlocal from_files_vocab = {\r\n    \"type\": \"from_files\",\r\n    \"directory\": args.vocab_path,\r\n};\r\n\r\n{\r\n    \"dataset_reader\": {\r\n        \"type\": args.dataset_reader_name,\r\n        \"token_indexers\": {\r\n            \"tokens\": {\r\n                \"type\": \"pretrained_transformer\",\r\n                \"model_name\": args.pretrained_transformer_name,\r\n                \"max_length\": args.max_length,\r\n            },\r\n        },\r\n        \"delimeters\": args.delimeters,\r\n        \"skip_correct\": args.skip_correct,\r\n        \"skip_complex\": args.skip_complex,\r\n        \"max_len\": args.max_len,\r\n        \"test_mode\": args.test_mode,\r\n        \"tag_strategy\": args.tag_strategy,\r\n        \"tn_prob\": args.tn_prob,\r\n        \"tp_prob\": args.tp_prob,\r\n        \"broken_dot_strategy\": args.broken_dot_strategy,\r\n    },\r\n    \"train_data_path\": args.train_data_path,\r\n    \"validation_data_path\": args.validation_data_path,\r\n    \"vocabulary\": from_files_vocab,\r\n    \"model\": {\r\n        \"type\": args.model_name,\r\n        \"text_field_embedder\": {\r\n            \"token_embedders\": {\r\n                \"tokens\": {\r\n                    \"type\": \"pretrained_transformer\",\r\n                    \"model_name\": args.pretrained_transformer_name,\r\n                },\r\n            },\r\n        },\r\n        \"predictor_dropout\": args.predictor_dropout,\r\n        \"label_smoothing\": args.label_smoothing,\r\n    },\r\n    \"data_loader\": {\r\n        \"batch_sampler\": {\r\n            \"type\": \"bucket\",\r\n            \"batch_size\": args.batch_size,\r\n        },\r\n        \"num_workers\": args.num_workers,\r\n        \"max_instances_in_memory\": args.max_instances_in_memory,\r\n\r\n    },\r\n    \"trainer\": {\r\n        \"type\": args.trainer_name,\r\n        \"optimizer\": {\r\n            \"type\": \"adam\",\r\n            \"lr\": args.lr,\r\n        },\r\n        \"learning_rate_scheduler\": {\r\n            \"type\": \"reduce_on_plateau\",\r\n            \"factor\": args.factor,\r\n            \"patience\": args.patience,\r\n        },\r\n        \"patience\": args.patience,\r\n        \"num_epochs\": args.num_epochs,\r\n        \"num_gradient_accumulation_steps\": args.accumulation_size,\r\n        \"cold_step_count\": args.cold_step_count,\r\n        \"cold_lr\": args.cold_lr,\r\n    },\r\n    \"distributed\": {\r\n        \"cuda_devices\": [0, 1]\r\n    }\r\n}\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nIn `\"trainer\"` I specified the `optimizer` and `learning_rate_scheduler`. However, once I run `allennlp train`, it raise the following error:\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback 1:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n-- Process 1 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/params.py\", line 211, in pop\r\n    value = self.params.pop(key)\r\nKeyError: 'optimizer'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 59, in _wrap\r\n    fn(i, *args)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/commands/train.py\", line 494, in _train_worker\r\n    train_loop = TrainModel.from_params(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 604, in from_params\r\n    return retyped_subclass.from_params(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 638, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/commands/train.py\", line 786, in from_partial_objects\r\n    trainer_ = trainer.construct(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/lazy.py\", line 82, in construct\r\n    return self.constructor(**contructor_kwargs)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/lazy.py\", line 66, in constructor_to_use\r\n    return self._constructor.from_params(  # type: ignore[union-attr]\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 604, in from_params\r\n    return retyped_subclass.from_params(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 636, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 206, in create_kwargs\r\n    constructed_arg = pop_and_construct_arg(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 314, in pop_and_construct_arg\r\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 348, in construct_arg\r\n    result = annotation.from_params(params=popped_params, **subextras)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 604, in from_params\r\n    return retyped_subclass.from_params(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 636, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 206, in create_kwargs\r\n    constructed_arg = pop_and_construct_arg(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 310, in pop_and_construct_arg\r\n    popped_params = params.pop(name, default) if default != _NO_DEFAULT else params.pop(name)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/params.py\", line 216, in pop\r\n    raise ConfigurationError(msg)\r\nallennlp.common.checks.ConfigurationError: key \"optimizer\" is required at location \"trainer.learning_rate_scheduler.\"\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nBut the doc states that I do not need to pass an optimizer key to the learning rate scheduler.\r\n\r\nI also did try to pass the `optimizer` inside `learning_rate_scheduler` as follows:\r\n```\r\n\"trainer\": {\r\n        \"type\": args.trainer_name,\r\n        \"optimizer\": {\r\n            \"type\": \"adam\",\r\n            \"lr\": args.lr,\r\n        },\r\n        \"learning_rate_scheduler\": {\r\n            \"type\": \"reduce_on_plateau\",\r\n            \"optimizer\": {\r\n                \"type\": \"adam\",\r\n                \"lr\": args.lr,\r\n            },\r\n            \"factor\": args.factor,\r\n            \"patience\": args.patience,\r\n        },\r\n        ...\r\n}\r\n```\r\nbut then it raises an error for missing \"model_parameters\" key in `learning_rate_scheduler` (see the traceback below).\r\n\r\n<details>\r\n<summary><b>Python traceback 2:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n-- Process 1 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/params.py\", line 211, in pop\r\n    value = self.params.pop(key)\r\nKeyError: 'model_parameters'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 59, in _wrap\r\n    fn(i, *args)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/commands/train.py\", line 494, in _train_worker\r\n    train_loop = TrainModel.from_params(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 604, in from_params\r\n    return retyped_subclass.from_params(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 638, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/commands/train.py\", line 786, in from_partial_objects\r\n    trainer_ = trainer.construct(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/lazy.py\", line 82, in construct\r\n    return self.constructor(**contructor_kwargs)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/lazy.py\", line 66, in constructor_to_use\r\n    return self._constructor.from_params(  # type: ignore[union-attr]\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 604, in from_params\r\n    return retyped_subclass.from_params(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 636, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 206, in create_kwargs\r\n    constructed_arg = pop_and_construct_arg(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 314, in pop_and_construct_arg\r\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 348, in construct_arg\r\n    result = annotation.from_params(params=popped_params, **subextras)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 604, in from_params\r\n    return retyped_subclass.from_params(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 636, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 206, in create_kwargs\r\n    constructed_arg = pop_and_construct_arg(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 314, in pop_and_construct_arg\r\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 348, in construct_arg\r\n    result = annotation.from_params(params=popped_params, **subextras)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 604, in from_params\r\n    return retyped_subclass.from_params(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 636, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 206, in create_kwargs\r\n    constructed_arg = pop_and_construct_arg(\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 310, in pop_and_construct_arg\r\n    popped_params = params.pop(name, default) if default != _NO_DEFAULT else params.pop(name)\r\n  File \"/root/miniconda3/envs/arp/lib/python3.8/site-packages/allennlp/common/params.py\", line 216, in pop\r\n    raise ConfigurationError(msg)\r\nallennlp.common.checks.ConfigurationError: key \"model_parameters\" is required at location \"trainer.learning_rate_scheduler.optimizer.\"\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 18.04.4 LTS\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.12\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==1.0.0\r\naiohttp==3.8.1\r\naiosignal==1.2.0\r\nalabaster==0.7.12\r\nallennlp==2.9.0\r\nargon2-cffi==21.3.0\r\nargon2-cffi-bindings==21.2.0\r\nasttokens==2.0.5\r\nasync-timeout==4.0.2\r\nattrs==21.4.0\r\nawscli==1.22.67\r\nBabel==2.9.1\r\nbackcall==0.2.0\r\nbackports.csv==1.0.7\r\nbase58==2.1.1\r\nbeautifulsoup4==4.10.0\r\nblack==22.1.0\r\nbleach==4.1.0\r\nblis==0.7.6\r\nboto3==1.21.12\r\nbotocore==1.24.12\r\ncached-path==1.1.0\r\ncachetools==5.0.0\r\ncatalogue==2.0.6\r\ncertifi==2021.10.8\r\ncffi==1.15.0\r\nchardet==4.0.0\r\ncharset-normalizer==2.0.12\r\nchecklist==0.0.11\r\ncheroot==8.6.0\r\nCherryPy==18.6.1\r\nclick==8.0.4\r\ncolorama==0.4.3\r\nconllu==0.11\r\ncryptography==36.0.1\r\ncycler==0.11.0\r\ncymem==2.0.6\r\ndebugpy==1.5.1\r\ndecorator==5.1.1\r\ndefusedxml==0.7.1\r\ndill==0.3.4\r\ndocker-pycreds==0.4.0\r\ndocutils==0.15.2\r\neditdistance==0.6.0\r\nentrypoints==0.4\r\nexecuting==0.8.3\r\nfairscale==0.4.5\r\nfeedparser==6.0.8\r\nfilelock==3.4.2\r\nflaky==3.7.0\r\nFlask==2.0.3\r\nFlask-Cors==3.0.10\r\nfonttools==4.29.1\r\nfrozenlist==1.3.0\r\nfsspec==2022.2.0\r\nftfy==6.1.1\r\nfuture==0.18.2\r\ngevent==21.12.0\r\ngitdb==4.0.9\r\nGitPython==3.1.27\r\ngoogle-api-core==2.6.0\r\ngoogle-auth==2.6.0\r\ngoogle-auth-oauthlib==0.4.6\r\ngoogle-cloud-core==2.2.2\r\ngoogle-cloud-storage==1.44.0\r\ngoogle-crc32c==1.3.0\r\ngoogle-resumable-media==2.3.1\r\ngoogleapis-common-protos==1.55.0\r\ngreenlet==1.1.2\r\ngrpcio==1.44.0\r\nh5py==3.6.0\r\nhuggingface-hub==0.2.1\r\nidna==3.3\r\nimagesize==1.3.0\r\nimportlib-metadata==4.11.2\r\nimportlib-resources==5.4.0\r\niniconfig==1.1.1\r\nipykernel==6.9.1\r\nipython==8.1.1\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.5\r\niso-639==0.4.5\r\nitsdangerous==2.1.0\r\njaraco.classes==3.2.1\r\njaraco.collections==3.5.1\r\njaraco.context==4.1.1\r\njaraco.functools==3.5.0\r\njaraco.text==3.7.0\r\njedi==0.18.1\r\nJinja2==3.0.3\r\njmespath==0.10.0\r\njoblib==1.1.0\r\njsonnet==0.18.0\r\njsonpickle==2.1.0\r\njsonschema==4.4.0\r\njupyter==1.0.0\r\njupyter-client==7.1.2\r\njupyter-console==6.4.0\r\njupyter-core==4.9.2\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.2\r\nkiwisolver==1.3.2\r\nlangcodes==3.3.0\r\nlmdb==1.3.0\r\nlxml==4.8.0\r\nMarkdown==3.3.6\r\nMarkupSafe==2.1.0\r\nmatplotlib==3.5.1\r\nmatplotlib-inline==0.1.3\r\nmistune==0.8.4\r\nmore-itertools==8.12.0\r\nmultidict==6.0.2\r\nmunch==2.5.0\r\nmurmurhash==1.0.6\r\nmypy-extensions==0.4.3\r\nnbclient==0.5.11\r\nnbconvert==6.4.2\r\nnbformat==5.1.3\r\nnest-asyncio==1.5.4\r\nnltk==3.6.5\r\nnotebook==6.4.8\r\nnumpy==1.22.2\r\nnumpydoc==1.2\r\noauthlib==3.2.0\r\noverrides==3.1.0\r\npackaging==21.3\r\npandocfilters==1.5.0\r\nparsimonious==0.8.1\r\nparso==0.8.3\r\npathspec==0.9.0\r\npathtools==0.1.2\r\npathy==0.6.1\r\npatternfork-nosql==3.6\r\npdfminer.six==20211012\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==9.0.1\r\nplac==0.9.6\r\nplatformdirs==2.5.1\r\npluggy==1.0.0\r\nportend==3.1.0\r\npreshed==3.0.6\r\nprometheus-client==0.13.1\r\npromise==2.3\r\nprompt-toolkit==3.0.28\r\nprotobuf==3.19.4\r\npsutil==5.9.0\r\nptyprocess==0.7.0\r\npure-eval==0.2.2\r\npy==1.11.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.21\r\npydantic==1.8.2\r\npyDeprecate==0.3.1\r\nPygments==2.11.2\r\npyparsing==3.0.7\r\npyrsistent==0.18.1\r\npytest==7.0.1\r\npython-dateutil==2.8.2\r\npython-docx==0.8.11\r\npython-Levenshtein==0.12.1\r\npytorch-lightning==1.5.10\r\npytorch-pretrained-bert==0.6.2\r\npytz==2021.3\r\nPyYAML==5.4.1\r\npyzmq==22.3.0\r\nqtconsole==5.2.2\r\nQtPy==2.0.1\r\nregex==2022.3.2\r\nrequests==2.27.1\r\nrequests-oauthlib==1.3.1\r\nresponses==0.18.0\r\nrsa==4.7.2\r\ns3transfer==0.5.2\r\nsacremoses==0.0.47\r\nscikit-learn==1.0.2\r\nscipy==1.8.0\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.5.6\r\nsetproctitle==1.2.2\r\nsgmllib3k==1.0.0\r\nshortuuid==1.0.8\r\nsix==1.16.0\r\nsmart-open==5.2.1\r\nsmmap==5.0.0\r\nsnowballstemmer==2.2.0\r\nsoupsieve==2.3.1\r\nspacy==3.2.3\r\nspacy-legacy==3.0.9\r\nspacy-loggers==1.0.1\r\nSphinx==4.4.0\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==2.0.0\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.5\r\nsqlparse==0.4.2\r\nsrsly==2.4.2\r\nstack-data==0.2.0\r\ntempora==5.0.1\r\ntensorboard==2.8.0\r\ntensorboard-data-server==0.6.1\r\ntensorboard-plugin-wit==1.8.1\r\ntensorboardX==2.5\r\ntermcolor==1.1.0\r\nterminado==0.13.2\r\ntestpath==0.6.0\r\nthinc==8.0.13\r\nthreadpoolctl==3.1.0\r\ntokenizers==0.11.6\r\ntomli==2.0.1\r\ntorch==1.10.2\r\ntorchmetrics==0.7.2\r\ntorchvision==0.11.3\r\ntornado==6.1\r\ntqdm==4.62.3\r\ntraitlets==5.1.1\r\ntransformers==4.17.0\r\ntyper==0.4.0\r\ntyping-utils==0.1.0\r\ntyping_extensions==4.1.1\r\nUnidecode==1.3.3\r\nurllib3==1.26.8\r\nwandb==0.12.11\r\nwasabi==0.9.0\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nWerkzeug==2.0.3\r\nwidgetsnbextension==3.5.2\r\nword2number==1.1\r\nyarl==1.7.2\r\nyaspin==2.1.0\r\nzc.lockfile==2.0\r\nzipp==3.7.0\r\nzope.event==4.5.0\r\nzope.interface==5.4.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5600/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5600/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5588", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5588/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5588/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5588/events", "html_url": "https://github.com/allenai/allennlp/issues/5588", "id": 1164626091, "node_id": "I_kwDOBXH8-M5Fasir", "number": 5588, "title": "`allennlp test-install` broken without `checklist`", "user": {"login": "h-vetinari", "id": 33685575, "node_id": "MDQ6VXNlcjMzNjg1NTc1", "avatar_url": "https://avatars.githubusercontent.com/u/33685575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/h-vetinari", "html_url": "https://github.com/h-vetinari", "followers_url": "https://api.github.com/users/h-vetinari/followers", "following_url": "https://api.github.com/users/h-vetinari/following{/other_user}", "gists_url": "https://api.github.com/users/h-vetinari/gists{/gist_id}", "starred_url": "https://api.github.com/users/h-vetinari/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/h-vetinari/subscriptions", "organizations_url": "https://api.github.com/users/h-vetinari/orgs", "repos_url": "https://api.github.com/users/h-vetinari/repos", "events_url": "https://api.github.com/users/h-vetinari/events{/privacy}", "received_events_url": "https://api.github.com/users/h-vetinari/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-03-10T01:14:04Z", "updated_at": "2022-03-21T19:37:52Z", "closed_at": "2022-03-21T19:37:52Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "This is a bit of fall-out from #5507; encountered in https://github.com/conda-forge/allennlp-feedstock/pull/35\r\n\r\n```\r\n+ allennlp test-install\r\n[...]/lib/python3.9/site-packages/allennlp/confidence_checks/task_checklists/__init__.py:15: UserWarning: To use the checklist integration you should install ``allennlp`` with the \"checklist\" extra (e.g. ``pip install allennlp[checklist]``) or just install checklist after the fact.\r\n  warnings.warn(\r\nTraceback (most recent call last):\r\n  File \"[...]/bin/allennlp\", line 11, in <module>\r\n    sys.exit(run())\r\n  File \"[...]/lib/python3.9/site-packages/allennlp/__main__.py\", line 39, in run\r\n    main(prog=\"allennlp\")\r\n  File \"[...]/lib/python3.9/site-packages/allennlp/commands/__init__.py\", line 121, in main\r\n    parser, args = parse_args(prog)\r\n  File \"[...]/lib/python3.9/site-packages/allennlp/commands/__init__.py\", line 109, in parse_args\r\n    import_plugins()\r\n  File \"[...]/lib/python3.9/site-packages/allennlp/common/plugins.py\", line 79, in import_plugins\r\n    import_module_and_submodules(\r\n  File \"[...]/lib/python3.9/site-packages/allennlp/common/util.py\", line 362, in import_module_and_submodules\r\n    import_module_and_submodules(subpackage, exclude=exclude)\r\n  File \"[...]/lib/python3.9/site-packages/allennlp/common/util.py\", line 362, in import_module_and_submodules\r\n    import_module_and_submodules(subpackage, exclude=exclude)\r\n  File \"[...]/lib/python3.9/site-packages/allennlp/common/util.py\", line 351, in import_module_and_submodules\r\n    module = importlib.import_module(package_name)\r\n  File \"[...]/lib/python3.9/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n    from allennlp.confidence_checks.task_checklists.task_suite import TaskSuite\r\n  File \"[...]/lib/python3.9/site-packages/allennlp/confidence_checks/task_checklists/task_suite.py\", line 6, in <module>\r\n    from checklist.test_suite import TestSuite\r\nModuleNotFoundError: No module named 'checklist'\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5588/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5588/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5585", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5585/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5585/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5585/events", "html_url": "https://github.com/allenai/allennlp/issues/5585", "id": 1161642940, "node_id": "I_kwDOBXH8-M5FPUO8", "number": 5585, "title": "unable to load predictor using from_path with cached_path version 1.1.0", "user": {"login": "ksteimel", "id": 25189520, "node_id": "MDQ6VXNlcjI1MTg5NTIw", "avatar_url": "https://avatars.githubusercontent.com/u/25189520?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ksteimel", "html_url": "https://github.com/ksteimel", "followers_url": "https://api.github.com/users/ksteimel/followers", "following_url": "https://api.github.com/users/ksteimel/following{/other_user}", "gists_url": "https://api.github.com/users/ksteimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ksteimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ksteimel/subscriptions", "organizations_url": "https://api.github.com/users/ksteimel/orgs", "repos_url": "https://api.github.com/users/ksteimel/repos", "events_url": "https://api.github.com/users/ksteimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ksteimel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-03-07T16:27:26Z", "updated_at": "2022-03-09T18:28:41Z", "closed_at": "2022-03-09T18:28:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nWith cached_path version 1.1.0 released 4 days ago, [the return value of cached_path was changed from str to Path](https://github.com/allenai/cached_path/releases/tag/v1.1.0). This causes issues when the json file is loaded since the json library is only compatible with string path representations. I can submit a PR to fix this shortly.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nn [2]: Predictor.from_path(\"test_fixtures/simple_tagger/serialization/model.tar.gz\")\r\n2022-03-07 11:18:33,618 - INFO - allennlp.models.archival - loading archive file test_fixtures/simple_tagger/serialization/model.tar.gz from cache at test_fixtures/simple_tagger/serialization/model.tar.gz\r\n2022-03-07 11:18:33,618 - INFO - allennlp.models.archival - extracting archive file test_fixtures/simple_tagger/serialization/model.tar.gz to temp dir /tmp/tmpefwxrma7\r\n2022-03-07 11:18:33,619 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpefwxrma7\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nInput In [2], in <cell line: 1>()\r\n----> 1 Predictor.from_path(\"test_fixtures/simple_tagger/serialization/model.tar.gz\")\r\n\r\nFile ~/allennlp_for_test/allennlp/predictors/predictor.py:366, in Predictor.from_path(cls, archive_path, predictor_name, cuda_device, dataset_reader_to_load, frozen, import_plugins, overrides, **kwargs)\r\n    363 if import_plugins:\r\n    364     plugins.import_plugins()\r\n    365 return Predictor.from_archive(\r\n--> 366     load_archive(archive_path, cuda_device=cuda_device, overrides=overrides),\r\n    367     predictor_name,\r\n    368     dataset_reader_to_load=dataset_reader_to_load,\r\n    369     frozen=frozen,\r\n    370     extra_args=kwargs,\r\n    371 )\r\n\r\nFile ~/allennlp_for_test/allennlp/models/archival.py:229, in load_archive(archive_file, cuda_device, overrides, weights_file)\r\n    226     weights_path = get_weights_path(serialization_dir)\r\n    228 # Load config\r\n--> 229 config = Params.from_file(os.path.join(serialization_dir, CONFIG_NAME), overrides)\r\n    231 # Instantiate model and dataset readers. Use a duplicate of the config, as it will get consumed.\r\n    232 dataset_reader, validation_dataset_reader = _load_dataset_readers(\r\n    233     config.duplicate(), serialization_dir\r\n    234 )\r\n\r\nFile ~/allennlp_for_test/allennlp/common/params.py:462, in Params.from_file(cls, params_file, params_overrides, ext_vars)\r\n    459 params_file = cached_path(params_file)\r\n    460 ext_vars = {**_environment_variables(), **ext_vars}\r\n--> 462 file_dict = json.loads(evaluate_file(params_file, ext_vars=ext_vars))\r\n    464 if isinstance(params_overrides, dict):\r\n    465     params_overrides = json.dumps(params_overrides)\r\n\r\nTypeError: argument 1 must be str, not PosixPath\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.12\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp @ file:///home/conda/feedstock_root/build_artifacts/aiohttp_1637087019853/work\r\naiosignal @ file:///home/conda/feedstock_root/build_artifacts/aiosignal_1636093929600/work\r\n-e git+https://github.com/allenai/allennlp.git@99c93439fce9473fb0b1677bd1014fbe79e4f347#egg=allennlp\r\nargon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1640817743617/work\r\nargon2-cffi-bindings @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi-bindings_1640855148858/work\r\nasttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1618968359944/work\r\nasync-timeout @ file:///home/conda/feedstock_root/build_artifacts/async-timeout_1640026696943/work\r\nattrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1640799537051/work\r\nbackcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\r\nbackports.csv==1.0.7\r\nbackports.functools-lru-cache @ file:///home/conda/feedstock_root/build_artifacts/backports.functools_lru_cache_1618230623929/work\r\nbase58 @ file:///home/conda/feedstock_root/build_artifacts/base58_1635724186165/work\r\nbeautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1631087867185/work\r\nbleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1629908509068/work\r\nblis @ file:///home/conda/feedstock_root/build_artifacts/cython-blis_1645002514022/work\r\nboto3 @ file:///home/conda/feedstock_root/build_artifacts/boto3_1646447578967/work\r\nbotocore @ file:///home/conda/feedstock_root/build_artifacts/botocore_1646438083893/work\r\nbrotlipy @ file:///home/conda/feedstock_root/build_artifacts/brotlipy_1636012188166/work\r\ncached-path @ file:///home/conda/feedstock_root/build_artifacts/cached_path_1646363586912/work\r\ncached-property @ file:///home/conda/feedstock_root/build_artifacts/cached_property_1615209429212/work\r\ncachetools @ file:///home/conda/feedstock_root/build_artifacts/cachetools_1640686991047/work\r\ncatalogue @ file:///home/conda/feedstock_root/build_artifacts/catalogue_1638867392804/work\r\ncertifi==2021.10.8\r\ncffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1636046063618/work\r\nchardet @ file:///home/conda/feedstock_root/build_artifacts/chardet_1635814844635/work\r\ncharset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1644853463426/work\r\nchecklist @ file:///home/conda/feedstock_root/build_artifacts/checklist_1626355406222/work\r\ncheroot @ file:///home/conda/feedstock_root/build_artifacts/cheroot_1641335003286/work\r\nCherryPy @ file:///home/conda/feedstock_root/build_artifacts/cherrypy_1636828596465/work\r\nclick==7.1.2\r\ncolorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1602866480661/work\r\nconfigparser @ file:///home/conda/feedstock_root/build_artifacts/configparser_1638573090458/work\r\ncryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography_1639699280509/work\r\ncymem @ file:///home/conda/feedstock_root/build_artifacts/cymem_1636053152744/work\r\ndataclasses @ file:///home/conda/feedstock_root/build_artifacts/dataclasses_1628958434797/work\r\ndatasets==1.18.4\r\ndebugpy @ file:///home/conda/feedstock_root/build_artifacts/debugpy_1636043259437/work\r\ndecorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\r\ndefusedxml @ file:///home/conda/feedstock_root/build_artifacts/defusedxml_1615232257335/work\r\ndill @ file:///home/conda/feedstock_root/build_artifacts/dill_1623610058511/work\r\ndocker-pycreds==0.4.0\r\nentrypoints @ file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\r\nexecuting @ file:///home/conda/feedstock_root/build_artifacts/executing_1646044401614/work\r\nfairscale @ file:///home/conda/feedstock_root/build_artifacts/fairscale_1642208909799/work\r\nfeedparser @ file:///home/conda/feedstock_root/build_artifacts/feedparser_1624371037925/work\r\nfilelock @ file:///home/conda/feedstock_root/build_artifacts/filelock_1641470428964/work\r\nflit_core @ file:///home/conda/feedstock_root/build_artifacts/flit-core_1645629044586/work/source/flit_core\r\nfrozenlist @ file:///home/conda/feedstock_root/build_artifacts/frozenlist_1643222566706/work\r\nfsspec==2022.2.0\r\nfuture @ file:///home/conda/feedstock_root/build_artifacts/future_1635819504071/work\r\ngitdb @ file:///home/conda/feedstock_root/build_artifacts/gitdb_1635085722655/work\r\nGitPython @ file:///home/conda/feedstock_root/build_artifacts/gitpython_1645531658201/work\r\ngoogle-api-core @ file:///home/conda/feedstock_root/build_artifacts/google-api-core-split_1644877687275/work\r\ngoogle-auth @ file:///home/conda/feedstock_root/build_artifacts/google-auth_1644503159426/work\r\ngoogle-cloud-core @ file:///home/conda/feedstock_root/build_artifacts/google-cloud-core_1642607638110/work\r\ngoogle-cloud-storage @ file:///home/conda/feedstock_root/build_artifacts/google-cloud-storage_1644876711050/work\r\ngoogle-crc32c @ file:///home/conda/feedstock_root/build_artifacts/google-crc32c_1636020895323/work\r\ngoogle-resumable-media @ file:///home/conda/feedstock_root/build_artifacts/google-resumable-media_1635195007097/work\r\ngoogleapis-common-protos @ file:///home/conda/feedstock_root/build_artifacts/googleapis-common-protos-feedstock_1641396325888/work\r\ngrpcio @ file:///home/conda/feedstock_root/build_artifacts/grpcio_1645230339993/work\r\nh5py @ file:///home/conda/feedstock_root/build_artifacts/h5py_1637963921863/work\r\nhuggingface-hub @ file:///home/conda/feedstock_root/build_artifacts/huggingface_hub_1641988520462/work\r\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1642433548627/work\r\nimportlib-metadata @ file:///home/conda/feedstock_root/build_artifacts/importlib-metadata_1646003237683/work\r\nimportlib-resources @ file:///home/conda/feedstock_root/build_artifacts/importlib_resources_1635615662634/work\r\niniconfig @ file:///home/conda/feedstock_root/build_artifacts/iniconfig_1603384189793/work\r\nipykernel @ file:///home/conda/feedstock_root/build_artifacts/ipykernel_1644979757530/work/dist/ipykernel-6.9.1-py3-none-any.whl\r\nipython @ file:///home/conda/feedstock_root/build_artifacts/ipython_1646324678335/work\r\nipython-genutils==0.2.0\r\nipywidgets @ file:///home/conda/feedstock_root/build_artifacts/ipywidgets_1631590360471/work\r\niso-639 @ file:///home/conda/feedstock_root/build_artifacts/iso-639_1626355260505/work\r\njaraco.classes @ file:///home/conda/feedstock_root/build_artifacts/jaraco.classes_1619298134024/work\r\njaraco.collections @ file:///home/conda/feedstock_root/build_artifacts/jaraco.collections_1641469018844/work\r\njaraco.functools @ file:///home/conda/feedstock_root/build_artifacts/jaraco.functools_1641071972629/work\r\njaraco.text @ file:///home/conda/feedstock_root/build_artifacts/jaraco.text_1636408436868/work\r\njedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1637175084646/work\r\nJinja2 @ file:///home/conda/feedstock_root/build_artifacts/jinja2_1636510082894/work\r\njmespath @ file:///home/conda/feedstock_root/build_artifacts/jmespath_1589369830981/work\r\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1633637554808/work\r\njsonnet @ file:///home/conda/feedstock_root/build_artifacts/jsonnet_1636234864125/work\r\njsonschema @ file:///home/conda/feedstock_root/build_artifacts/jsonschema-meta_1642000296051/work\r\njupyter-client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1642858610849/work\r\njupyter-core @ file:///home/conda/feedstock_root/build_artifacts/jupyter_core_1645024265313/work\r\njupyterlab-pygments @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_pygments_1601375948261/work\r\njupyterlab-widgets @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_widgets_1631590465624/work\r\nlangcodes @ file:///home/conda/feedstock_root/build_artifacts/langcodes_1636741340529/work\r\nlmdb @ file:///home/conda/feedstock_root/build_artifacts/python-lmdb_1644189490626/work\r\nlxml @ file:///home/conda/feedstock_root/build_artifacts/lxml_1645124851601/work\r\nMarkupSafe @ file:///home/conda/feedstock_root/build_artifacts/markupsafe_1646594593472/work\r\nmatplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1631080358261/work\r\nmistune @ file:///home/conda/feedstock_root/build_artifacts/mistune_1635844675081/work\r\nmore-itertools @ file:///home/conda/feedstock_root/build_artifacts/more-itertools_1637732846337/work\r\nmultidict @ file:///home/conda/feedstock_root/build_artifacts/multidict_1643055351442/work\r\nmultiprocess==0.70.12.2\r\nmunch==2.5.0\r\nmurmurhash @ file:///home/conda/feedstock_root/build_artifacts/murmurhash_1636019583024/work\r\nmysqlclient @ file:///home/conda/feedstock_root/build_artifacts/mysqlclient_1639024663458/work\r\nnbclient @ file:///home/conda/feedstock_root/build_artifacts/nbclient_1646594625097/work\r\nnbconvert @ file:///home/conda/feedstock_root/build_artifacts/nbconvert_1644591289215/work\r\nnbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1617383142101/work\r\nnest-asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1638419302549/work\r\nnltk @ file:///home/conda/feedstock_root/build_artifacts/nltk_1633955089856/work\r\nnotebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1643149609895/work\r\nnumpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1643958805350/work\r\npackaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1637239678211/work\r\npandas==1.4.1\r\npandocfilters @ file:///home/conda/feedstock_root/build_artifacts/pandocfilters_1631603243851/work\r\nparso @ file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work\r\npathtools==0.1.2\r\npathy @ file:///home/conda/feedstock_root/build_artifacts/pathy_1635227809952/work\r\nPattern @ file:///home/conda/feedstock_root/build_artifacts/pattern_1588682046427/work\r\npdfminer.six @ file:///home/conda/feedstock_root/build_artifacts/pdfminer.six_1634369700996/work\r\npexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1602535608087/work\r\npickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\r\nPillow @ file:///home/conda/feedstock_root/build_artifacts/pillow_1645323150784/work\r\npluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1635832818738/work\r\nportend @ file:///home/conda/feedstock_root/build_artifacts/portend_1614149298816/work\r\npreshed @ file:///home/conda/feedstock_root/build_artifacts/preshed_1636077712344/work\r\nprometheus-client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1643395600215/work\r\npromise @ file:///home/conda/feedstock_root/build_artifacts/promise_1636078143998/work\r\nprompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1644497866770/work\r\nprotobuf==3.19.4\r\npsutil @ file:///home/conda/feedstock_root/build_artifacts/psutil_1640887117172/work\r\nptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\r\npy @ file:///home/conda/feedstock_root/build_artifacts/py_1636301881863/work\r\npyarrow==7.0.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.7\r\npycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work\r\npydantic @ file:///home/conda/feedstock_root/build_artifacts/pydantic_1636021149719/work\r\nPygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1641580240686/work\r\npyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1643496850550/work\r\npyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1642753572664/work\r\npyrsistent @ file:///home/conda/feedstock_root/build_artifacts/pyrsistent_1642534367111/work\r\nPySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1635862404924/work\r\npytest==7.0.1\r\npython-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\r\npython-docx @ file:///home/conda/feedstock_root/build_artifacts/python-docx_1622121039670/work\r\npytz @ file:///home/conda/feedstock_root/build_artifacts/pytz_1633452062248/work\r\npyu2f @ file:///home/conda/feedstock_root/build_artifacts/pyu2f_1604248910016/work\r\nPyYAML @ file:///home/conda/feedstock_root/build_artifacts/pyyaml_1636139793187/work\r\npyzmq @ file:///home/conda/feedstock_root/build_artifacts/pyzmq_1635877406326/work\r\nregex @ file:///home/conda/feedstock_root/build_artifacts/regex_1646209958833/work\r\nrepoze.lru==0.7\r\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1641580202195/work\r\nresponses==0.18.0\r\nRoutes @ file:///home/conda/feedstock_root/build_artifacts/routes_1604230639459/work\r\nrsa @ file:///home/conda/feedstock_root/build_artifacts/rsa_1637781155505/work\r\ns3transfer @ file:///home/conda/feedstock_root/build_artifacts/s3transfer_1645745825648/work\r\nsacremoses @ file:///home/conda/feedstock_root/build_artifacts/sacremoses_1636276757411/work\r\nscikit-learn @ file:///home/conda/feedstock_root/build_artifacts/scikit-learn_1640464148960/work\r\nscipy @ file:///home/conda/feedstock_root/build_artifacts/scipy_1644357257999/work\r\nSend2Trash @ file:///home/conda/feedstock_root/build_artifacts/send2trash_1628511208346/work\r\nsentencepiece==0.1.96\r\nsentry-sdk @ file:///home/conda/feedstock_root/build_artifacts/sentry-sdk_1645545793808/work\r\nsetproctitle @ file:///home/conda/feedstock_root/build_artifacts/setproctitle_1635864195956/work\r\nsgmllib3k @ file:///home/conda/feedstock_root/build_artifacts/sgmllib3k_1600021450347/work\r\nshellingham @ file:///home/conda/feedstock_root/build_artifacts/shellingham_1612179560728/work\r\nshortuuid @ file:///home/conda/feedstock_root/build_artifacts/shortuuid_1636643755121/work\r\nsimplejson @ file:///home/conda/feedstock_root/build_artifacts/simplejson_1637176768658/work\r\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\r\nsmart-open @ file:///home/conda/feedstock_root/build_artifacts/smart_open_1630238320325/work\r\nsmmap @ file:///home/conda/feedstock_root/build_artifacts/smmap_1611376390914/work\r\nsoupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1638550740809/work\r\nspacy @ file:///home/conda/feedstock_root/build_artifacts/spacy_1644657943105/work\r\nspacy-legacy @ file:///home/conda/feedstock_root/build_artifacts/spacy-legacy_1645713043381/work\r\nspacy-loggers @ file:///home/conda/feedstock_root/build_artifacts/spacy-loggers_1634809367310/work\r\nsqlitedict==2.0.0\r\nsrsly @ file:///home/conda/feedstock_root/build_artifacts/srsly_1638879568141/work\r\nstack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1644872665635/work\r\ntempora @ file:///home/conda/feedstock_root/build_artifacts/tempora_1643789373873/work\r\ntensorboardX @ file:///home/conda/feedstock_root/build_artifacts/tensorboardx_1645578792360/work\r\ntermcolor==1.1.0\r\nterminado @ file:///home/conda/feedstock_root/build_artifacts/terminado_1646324387640/work\r\ntestpath @ file:///home/conda/feedstock_root/build_artifacts/testpath_1645693042223/work\r\nthinc @ file:///home/conda/feedstock_root/build_artifacts/thinc_1638980259098/work\r\nthreadpoolctl @ file:///home/conda/feedstock_root/build_artifacts/threadpoolctl_1643647933166/work\r\ntokenizers @ file:///home/conda/feedstock_root/build_artifacts/tokenizers_1632285665555/work\r\ntomli @ file:///home/conda/feedstock_root/build_artifacts/tomli_1644342247877/work\r\ntorch @ file:///home/conda/feedstock_root/build_artifacts/pytorch-recipe_1643349930968/work\r\ntorchvision==0.11.3\r\ntornado @ file:///home/conda/feedstock_root/build_artifacts/tornado_1635819587273/work\r\ntqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1646031859244/work\r\ntraitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1635260543454/work\r\ntransformers @ file:///home/conda/feedstock_root/build_artifacts/transformers_1640232623006/work\r\ntyper @ file:///home/conda/feedstock_root/build_artifacts/typer_1630326630489/work\r\ntyping_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1644850595256/work\r\nurllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1641584929973/work\r\nwandb @ file:///home/conda/feedstock_root/build_artifacts/wandb_1646271144123/work\r\nwasabi @ file:///home/conda/feedstock_root/build_artifacts/wasabi_1638865582891/work\r\nwcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1600965781394/work\r\nwebencodings==0.5.1\r\nwidgetsnbextension @ file:///home/conda/feedstock_root/build_artifacts/widgetsnbextension_1637174139311/work\r\nxxhash==3.0.0\r\nyarl @ file:///home/conda/feedstock_root/build_artifacts/yarl_1636046814972/work\r\nyaspin @ file:///home/conda/feedstock_root/build_artifacts/yaspin_1630004424954/work\r\nzc.lockfile==2.0\r\nzipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1643828507773/work\r\n```\r\n\r\n\r\n\r\n\r\n</p>\r\n</details>\r\n\r\n<details>\r\n<summary><b>Output of <code>conda env export</code>:</b></summary>\r\n<p>\r\n\r\n```\r\nname: allennlp_test\r\nchannels:\r\n  - pytorch\r\n  - conda-forge\r\n  - huggingface\r\ndependencies:\r\n  - _libgcc_mutex=0.1=conda_forge\r\n  - _openmp_mutex=4.5=1_llvm\r\n  - aiohttp=3.8.1=py38h497a2fe_0\r\n  - aiosignal=1.2.0=pyhd8ed1ab_0\r\n  - argon2-cffi=21.3.0=pyhd8ed1ab_0\r\n  - argon2-cffi-bindings=21.2.0=py38h497a2fe_1\r\n  - asttokens=2.0.5=pyhd8ed1ab_0\r\n  - async-timeout=4.0.2=pyhd8ed1ab_0\r\n  - attrs=21.4.0=pyhd8ed1ab_0\r\n  - backcall=0.2.0=pyh9f0ad1d_0\r\n  - backports=1.0=py_2\r\n  - backports.csv=1.0.7=py_0\r\n  - backports.functools_lru_cache=1.6.4=pyhd8ed1ab_0\r\n  - base58=2.1.1=pyhd8ed1ab_0\r\n  - beautifulsoup4=4.10.0=pyha770c72_0\r\n  - bleach=4.1.0=pyhd8ed1ab_0\r\n  - boto3=1.21.13=pyhd8ed1ab_0\r\n  - botocore=1.24.13=pyhd8ed1ab_0\r\n  - brotlipy=0.7.0=py38h497a2fe_1003\r\n  - bzip2=1.0.8=h7f98852_4\r\n  - c-ares=1.18.1=h7f98852_0\r\n  - ca-certificates=2021.10.8=ha878542_0\r\n  - cached-property=1.5.2=hd8ed1ab_1\r\n  - cached_path=1.1.0=py38h578d9bd_0\r\n  - cached_property=1.5.2=pyha770c72_1\r\n  - cachetools=5.0.0=pyhd8ed1ab_0\r\n  - catalogue=2.0.6=py38h578d9bd_1\r\n  - certifi=2021.10.8=py38h578d9bd_1\r\n  - cffi=1.15.0=py38h3931269_0\r\n  - chardet=4.0.0=py38h578d9bd_2\r\n  - charset-normalizer=2.0.12=pyhd8ed1ab_0\r\n  - checklist=0.0.11=pyhd8ed1ab_0\r\n  - cheroot=8.6.0=pyhd8ed1ab_0\r\n  - cherrypy=18.6.1=py38h578d9bd_2\r\n  - click=7.1.2=pyh9f0ad1d_0\r\n  - colorama=0.4.4=pyh9f0ad1d_0\r\n  - configparser=5.2.0=pyhd8ed1ab_0\r\n  - cryptography=36.0.1=py38h3e25421_0\r\n  - cudatoolkit=11.3.1=ha36c431_10\r\n  - cudnn=8.2.1.32=h86fa8c9_0\r\n  - cymem=2.0.6=py38h709712a_2\r\n  - cython-blis=0.7.6=py38h6c62de6_0\r\n  - dataclasses=0.8=pyhc8e2a94_3\r\n  - debugpy=1.5.1=py38h709712a_0\r\n  - decorator=5.1.1=pyhd8ed1ab_0\r\n  - defusedxml=0.7.1=pyhd8ed1ab_0\r\n  - dill=0.3.4=pyhd8ed1ab_0\r\n  - docker-pycreds=0.4.0=py_0\r\n  - entrypoints=0.4=pyhd8ed1ab_0\r\n  - executing=0.8.3=pyhd8ed1ab_0\r\n  - fairscale=0.4.5=cuda112py38h881568f_0\r\n  - feedparser=6.0.8=pyhd8ed1ab_0\r\n  - ffmpeg=4.3=hf484d3e_0\r\n  - filelock=3.4.2=pyhd8ed1ab_1\r\n  - flit-core=3.7.1=pyhd8ed1ab_0\r\n  - freetype=2.10.4=h0708190_1\r\n  - frozenlist=1.3.0=py38h497a2fe_0\r\n  - future=0.18.2=py38h578d9bd_4\r\n  - giflib=5.2.1=h36c2ea0_2\r\n  - gitdb=4.0.9=pyhd8ed1ab_0\r\n  - gitpython=3.1.27=pyhd8ed1ab_0\r\n  - gmp=6.2.1=h58526e2_0\r\n  - gnutls=3.6.13=h85f3911_1\r\n  - google-api-core=2.5.0=pyhd8ed1ab_0\r\n  - google-auth=2.6.0=pyh6c4a22f_1\r\n  - google-cloud-core=2.2.2=pyh6c4a22f_0\r\n  - google-cloud-storage=2.1.0=pyh6c4a22f_0\r\n  - google-crc32c=1.1.2=py38h8838a9a_2\r\n  - google-resumable-media=2.1.0=pyh6c4a22f_0\r\n  - googleapis-common-protos=1.54.0=py38h578d9bd_0\r\n  - grpcio=1.44.0=py38hdd6454d_0\r\n  - h5py=3.6.0=nompi_py38hfbb2109_100\r\n  - hdf5=1.12.1=nompi_h2386368_104\r\n  - huggingface_hub=0.4.0=pyhd8ed1ab_0\r\n  - icu=69.1=h9c3ff4c_0\r\n  - idna=3.3=pyhd8ed1ab_0\r\n  - importlib-metadata=4.11.2=py38h578d9bd_0\r\n  - importlib_metadata=4.11.2=hd8ed1ab_0\r\n  - importlib_resources=5.4.0=pyhd8ed1ab_0\r\n  - iniconfig=1.1.1=pyh9f0ad1d_0\r\n  - ipykernel=6.9.1=py38he5a9106_0\r\n  - ipython=8.1.1=py38h578d9bd_0\r\n  - ipython_genutils=0.2.0=py_1\r\n  - ipywidgets=7.6.5=pyhd8ed1ab_0\r\n  - iso-639=0.4.5=pyhd8ed1ab_0\r\n  - jaraco.classes=3.2.1=pyhd8ed1ab_1\r\n  - jaraco.collections=3.5.1=pyhd8ed1ab_0\r\n  - jaraco.functools=3.5.0=pyhd8ed1ab_0\r\n  - jaraco.text=3.6.0=py38h578d9bd_0\r\n  - jbig=2.1=h7f98852_2003\r\n  - jedi=0.18.1=py38h578d9bd_0\r\n  - jinja2=3.0.3=pyhd8ed1ab_0\r\n  - jmespath=0.10.0=pyh9f0ad1d_0\r\n  - joblib=1.1.0=pyhd8ed1ab_0\r\n  - jpeg=9e=h7f98852_0\r\n  - jsonnet=0.17.0=py38h709712a_2\r\n  - jsonschema=4.4.0=pyhd8ed1ab_0\r\n  - jupyter_client=7.1.2=pyhd8ed1ab_0\r\n  - jupyter_core=4.9.2=py38h578d9bd_0\r\n  - jupyterlab_pygments=0.1.2=pyh9f0ad1d_0\r\n  - jupyterlab_widgets=1.0.2=pyhd8ed1ab_0\r\n  - keyutils=1.6.1=h166bdaf_0\r\n  - krb5=1.19.2=h3790be6_4\r\n  - lame=3.100=h7f98852_1001\r\n  - langcodes=3.3.0=pyhd8ed1ab_0\r\n  - lcms2=2.12=hddcbb42_0\r\n  - ld_impl_linux-64=2.36.1=hea4e1c9_2\r\n  - lerc=3.0=h9c3ff4c_0\r\n  - libblas=3.9.0=13_linux64_mkl\r\n  - libcblas=3.9.0=13_linux64_mkl\r\n  - libcrc32c=1.1.2=h9c3ff4c_0\r\n  - libcurl=7.81.0=h2574ce0_0\r\n  - libdeflate=1.10=h7f98852_0\r\n  - libedit=3.1.20191231=he28a2e2_2\r\n  - libev=4.33=h516909a_1\r\n  - libffi=3.4.2=h7f98852_5\r\n  - libgcc-ng=11.2.0=h1d223b6_13\r\n  - libgfortran-ng=11.2.0=h69a702a_13\r\n  - libgfortran5=11.2.0=h5c6108e_13\r\n  - libiconv=1.16=h516909a_0\r\n  - liblapack=3.9.0=13_linux64_mkl\r\n  - libnghttp2=1.47.0=h727a467_0\r\n  - libnsl=2.0.0=h7f98852_0\r\n  - libpng=1.6.37=h21135ba_2\r\n  - libprotobuf=3.19.4=h780b84a_0\r\n  - libsodium=1.0.18=h36c2ea0_1\r\n  - libssh2=1.10.0=ha56f1ee_2\r\n  - libstdcxx-ng=11.2.0=he4da1e4_13\r\n  - libsvm=325=h9c3ff4c_0\r\n  - libtiff=4.3.0=h542a066_3\r\n  - libwebp=1.2.2=h3452ae3_0\r\n  - libwebp-base=1.2.2=h7f98852_1\r\n  - libxcb=1.13=h7f98852_1004\r\n  - libxml2=2.9.12=h885dcf4_1\r\n  - libxslt=1.1.33=h0ef7038_3\r\n  - libzlib=1.2.11=h36c2ea0_1013\r\n  - llvm-openmp=13.0.1=he0ac6c6_1\r\n  - lxml=4.8.0=py38hf1fe3a4_0\r\n  - lz4-c=1.9.3=h9c3ff4c_1\r\n  - magma=2.5.4=h6103c52_2\r\n  - markupsafe=2.1.0=py38h0a891b7_1\r\n  - matplotlib-inline=0.1.3=pyhd8ed1ab_0\r\n  - mistune=0.8.4=py38h497a2fe_1005\r\n  - mkl=2022.0.1=h8d4b97c_803\r\n  - more-itertools=8.12.0=pyhd8ed1ab_0\r\n  - multidict=6.0.2=py38h497a2fe_0\r\n  - munch=2.5.0=py_0\r\n  - murmurhash=1.0.6=py38h709712a_2\r\n  - mysql-common=8.0.28=ha770c72_0\r\n  - mysql-libs=8.0.28=hfa10184_0\r\n  - mysqlclient=2.0.3=py38h709712a_2\r\n  - nbclient=0.5.12=pyhd8ed1ab_0\r\n  - nbconvert=6.4.2=py38h578d9bd_0\r\n  - nbformat=5.1.3=pyhd8ed1ab_0\r\n  - nccl=2.11.4.1=h5c60f85_2\r\n  - ncurses=6.3=h9c3ff4c_0\r\n  - nest-asyncio=1.5.4=pyhd8ed1ab_0\r\n  - nettle=3.6=he412f7d_0\r\n  - ninja=1.10.2=h4bd325d_1\r\n  - nltk=3.6.5=pyhd8ed1ab_0\r\n  - notebook=6.4.8=pyha770c72_0\r\n  - numpy=1.22.2=py38h6ae9a64_0\r\n  - openh264=2.1.1=h780b84a_0\r\n  - openjpeg=2.4.0=hb52868f_1\r\n  - openssl=1.1.1l=h7f98852_0\r\n  - packaging=21.3=pyhd8ed1ab_0\r\n  - pandoc=2.17.1.1=ha770c72_0\r\n  - pandocfilters=1.5.0=pyhd8ed1ab_0\r\n  - parso=0.8.3=pyhd8ed1ab_0\r\n  - pathtools=0.1.2=py_1\r\n  - pathy=0.6.1=pyhd8ed1ab_0\r\n  - pattern=3.6.0=pyh9f0ad1d_1\r\n  - pdfminer.six=20211012=pyhd8ed1ab_0\r\n  - pexpect=4.8.0=pyh9f0ad1d_2\r\n  - pickleshare=0.7.5=py_1003\r\n  - pillow=9.0.1=py38h0ee0e06_2\r\n  - pip=22.0.4=pyhd8ed1ab_0\r\n  - pluggy=1.0.0=py38h578d9bd_2\r\n  - portend=2.7.1=pyhd8ed1ab_0\r\n  - preshed=3.0.6=py38h709712a_1\r\n  - prometheus_client=0.13.1=pyhd8ed1ab_0\r\n  - promise=2.3=py38h578d9bd_5\r\n  - prompt-toolkit=3.0.27=pyha770c72_0\r\n  - protobuf=3.19.4=py38h709712a_0\r\n  - psutil=5.9.0=py38h497a2fe_0\r\n  - pthread-stubs=0.4=h36c2ea0_1001\r\n  - ptyprocess=0.7.0=pyhd3deb0d_0\r\n  - pure_eval=0.2.2=pyhd8ed1ab_0\r\n  - py=1.11.0=pyh6c4a22f_0\r\n  - pyasn1=0.4.8=py_0\r\n  - pyasn1-modules=0.2.7=py_0\r\n  - pycparser=2.21=pyhd8ed1ab_0\r\n  - pydantic=1.8.2=py38h497a2fe_2\r\n  - pygments=2.11.2=pyhd8ed1ab_0\r\n  - pyopenssl=22.0.0=pyhd8ed1ab_0\r\n  - pyparsing=3.0.7=pyhd8ed1ab_0\r\n  - pyrsistent=0.18.1=py38h497a2fe_0\r\n  - pysocks=1.7.1=py38h578d9bd_4\r\n  - pytest=7.0.1=py38h578d9bd_0\r\n  - python=3.8.12=ha38a3c6_3_cpython\r\n  - python-dateutil=2.8.2=pyhd8ed1ab_0\r\n  - python-docx=0.8.11=pyhd8ed1ab_0\r\n  - python-lmdb=1.3.0=py38h709712a_0\r\n  - python_abi=3.8=2_cp38\r\n  - pytorch=1.10.2=cuda112py38h6425f36_0\r\n  - pytorch-gpu=1.10.2=cuda112py38h0bbbad9_0\r\n  - pytz=2021.3=pyhd8ed1ab_0\r\n  - pyu2f=0.1.5=pyhd8ed1ab_0\r\n  - pyyaml=6.0=py38h497a2fe_3\r\n  - pyzmq=22.3.0=py38h2035c66_1\r\n  - readline=8.1=h46c0cb4_0\r\n  - regex=2022.3.2=py38h0a891b7_0\r\n  - repoze.lru=0.7=py_0\r\n  - requests=2.27.1=pyhd8ed1ab_0\r\n  - routes=2.5.1=pyhd8ed1ab_0\r\n  - rsa=4.8=pyhd8ed1ab_0\r\n  - s3transfer=0.5.2=pyhd8ed1ab_0\r\n  - sacremoses=0.0.46=pyhd8ed1ab_0\r\n  - scikit-learn=1.0.2=py38h1561384_0\r\n  - scipy=1.8.0=py38h56a6a73_1\r\n  - send2trash=1.8.0=pyhd8ed1ab_0\r\n  - sentencepiece=0.1.96=py38h1fd1430_0\r\n  - sentry-sdk=1.5.6=pyhd8ed1ab_0\r\n  - setproctitle=1.2.2=py38h497a2fe_1\r\n  - setuptools=60.9.3=py38h578d9bd_0\r\n  - sgmllib3k=1.0.0=pyh9f0ad1d_0\r\n  - shellingham=1.4.0=pyh44b312d_0\r\n  - shortuuid=1.0.8=py38h578d9bd_0\r\n  - simplejson=3.17.6=py38h497a2fe_0\r\n  - six=1.16.0=pyh6c4a22f_0\r\n  - sleef=3.5.1=h9b69904_2\r\n  - smart_open=5.2.1=pyhd8ed1ab_0\r\n  - smmap=3.0.5=pyh44b312d_0\r\n  - soupsieve=2.3.1=pyhd8ed1ab_0\r\n  - spacy=3.2.2=py38h2b96118_0\r\n  - spacy-legacy=3.0.9=pyhd8ed1ab_0\r\n  - spacy-loggers=1.0.1=pyhd8ed1ab_0\r\n  - sqlite=3.37.0=h9cd32fc_0\r\n  - srsly=2.4.2=py38h709712a_1\r\n  - stack_data=0.2.0=pyhd8ed1ab_0\r\n  - tbb=2021.5.0=h4bd325d_0\r\n  - tempora=5.0.1=pyhd8ed1ab_0\r\n  - tensorboardx=2.5=pyhd8ed1ab_0\r\n  - termcolor=1.1.0=py_2\r\n  - terminado=0.13.2=py38h578d9bd_0\r\n  - testpath=0.6.0=pyhd8ed1ab_0\r\n  - thinc=8.0.13=py38h2b96118_0\r\n  - threadpoolctl=3.1.0=pyh8a188c0_0\r\n  - tk=8.6.12=h27826a3_0\r\n  - tokenizers=0.10.3=py38hb63a372_1\r\n  - tomli=2.0.1=pyhd8ed1ab_0\r\n  - torchvision=0.11.3=py38_cu113\r\n  - tornado=6.1=py38h497a2fe_2\r\n  - tqdm=4.63.0=pyhd8ed1ab_0\r\n  - traitlets=5.1.1=pyhd8ed1ab_0\r\n  - transformers=4.15.0=pyhd8ed1ab_0\r\n  - typer=0.4.0=pyhd8ed1ab_0\r\n  - typing-extensions=4.1.1=hd8ed1ab_0\r\n  - typing_extensions=4.1.1=pyha770c72_0\r\n  - urllib3=1.26.8=pyhd8ed1ab_1\r\n  - wandb=0.12.11=pyhd8ed1ab_0\r\n  - wasabi=0.9.0=pyhd8ed1ab_0\r\n  - wcwidth=0.2.5=pyh9f0ad1d_2\r\n  - webencodings=0.5.1=py_1\r\n  - wheel=0.37.1=pyhd8ed1ab_0\r\n  - widgetsnbextension=3.5.2=py38h578d9bd_1\r\n  - xorg-libxau=1.0.9=h7f98852_0\r\n  - xorg-libxdmcp=1.1.3=h7f98852_0\r\n  - xz=5.2.5=h516909a_1\r\n  - yaml=0.2.5=h7f98852_2\r\n  - yarl=1.7.2=py38h497a2fe_1\r\n  - yaspin=2.1.0=pyhd8ed1ab_0\r\n  - zc.lockfile=2.0=py_0\r\n  - zeromq=4.3.4=h9c3ff4c_1\r\n  - zipp=3.7.0=pyhd8ed1ab_1\r\n  - zlib=1.2.11=h36c2ea0_1013\r\n  - zstd=1.5.2=ha95c52a_0\r\n  - pip:\r\n    - datasets==1.18.4\r\n    - fsspec==2022.2.0\r\n    - multiprocess==0.70.12.2\r\n    - pandas==1.4.1\r\n    - pyarrow==7.0.0\r\n    - responses==0.18.0\r\n    - sqlitedict==2.0.0\r\n    - xxhash==3.0.0\r\nprefix: /opt/mambaforge/envs/allennlp_test\r\n```\r\n</details>\r\n</p>\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp.predictors import Predictor\r\nPredictor.from_path(\"test_fixtures/simple_tagger/serialization/model.tar.gz\")\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5585/reactions", "total_count": 3, "+1": 3, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5585/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5582", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5582/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5582/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5582/events", "html_url": "https://github.com/allenai/allennlp/issues/5582", "id": 1154641111, "node_id": "I_kwDOBXH8-M5E0mzX", "number": 5582, "title": "Loading a HuggingFace model into AllenNLP gives different predictions", "user": {"login": "santiagxf", "id": 32112894, "node_id": "MDQ6VXNlcjMyMTEyODk0", "avatar_url": "https://avatars.githubusercontent.com/u/32112894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/santiagxf", "html_url": "https://github.com/santiagxf", "followers_url": "https://api.github.com/users/santiagxf/followers", "following_url": "https://api.github.com/users/santiagxf/following{/other_user}", "gists_url": "https://api.github.com/users/santiagxf/gists{/gist_id}", "starred_url": "https://api.github.com/users/santiagxf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/santiagxf/subscriptions", "organizations_url": "https://api.github.com/users/santiagxf/orgs", "repos_url": "https://api.github.com/users/santiagxf/repos", "events_url": "https://api.github.com/users/santiagxf/events{/privacy}", "received_events_url": "https://api.github.com/users/santiagxf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2022-02-28T22:59:13Z", "updated_at": "2022-06-11T18:29:05Z", "closed_at": "2022-03-12T00:16:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nWhen loading a model created with HuggingFace (transformer library) into AllenNLP, the models works but predictions are different from what I get if running the model with transformers. Both model are running on evaluation mode.\r\n\r\n\r\n### Details\r\nI have a custom classification model trained using transformers library based on a BERT model. The model classifies text into 7 different categories. It is persisted in a directory using:\r\n\r\n```python\r\ntrainer.save_model(model_name)\r\ntokenizer.save_pretrained(model_name)\r\n```\r\n\r\nI'm trying to load such persisted model using the `allennlp` library for further analysis. However, when running the model inside the `allennlp` framework, the model tends to predict very different from the predictions I get when I run it using `transformers`, which lead me think some part of the loading was not done correctly. There are no errors during the inference, it is just that the predictions don't match.\r\n\r\nThere is little documentation about how to load an existing model (persisted in a path for instance), so I'm wondering if someone faced the same situation before. There is just one example of how to do QA classification with ROBERTA, but couldn't extrapolate to what I'm looking for. This is how I'm loading the trained model:\r\n\r\n```python\r\ntransformer_vocab = Vocabulary.from_pretrained_transformer(model_name)\r\ntransformer_tokenizer = PretrainedTransformerTokenizer(model_name)\r\ntransformer_encoder = BertPooler(model_name)\r\n\r\nparams = Params(\r\n    {\r\n     \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer\",\r\n          \"model_name\": model_name,\r\n        }\r\n      }\r\n    }\r\n)\r\ntoken_embedder = BasicTextFieldEmbedder.from_params(vocab=vocab, params=params)\r\ntoken_indexer = PretrainedTransformerIndexer(model_name)\r\n\r\ntransformer_model = BasicClassifier(vocab=transformer_vocab,\r\n                                    text_field_embedder=token_embedder, \r\n                                    seq2vec_encoder=transformer_encoder, \r\n                                    dropout=0.1, \r\n                                    num_labels=7)\r\n\r\ntransformer_model.eval()\r\n```\r\n\r\nI also had to implement my own DatasetReader as follows:\r\n\r\n```python\r\nclass ClassificationTransformerReader(DatasetReader):\r\n    def __init__(\r\n        self,\r\n        tokenizer: Tokenizer,\r\n        token_indexer: TokenIndexer,\r\n        max_tokens: int,\r\n        **kwargs\r\n    ):\r\n        super().__init__(**kwargs)\r\n        self.tokenizer = tokenizer\r\n        self.token_indexers: Dict[str, TokenIndexer] = { \"tokens\": token_indexer }\r\n        self.max_tokens = max_tokens\r\n        self.vocab = vocab\r\n\r\n    def text_to_instance(self, text: str, label: str = None) -> Instance:\r\n        tokens = self.tokenizer.tokenize(text)\r\n        if self.max_tokens:\r\n            tokens = tokens[: self.max_tokens]\r\n        \r\n        inputs = TextField(tokens, self.token_indexers)\r\n        fields: Dict[str, Field] = { \"tokens\": inputs }\r\n            \r\n        if label:\r\n            fields[\"label\"] = LabelField(label)\r\n            \r\n        return Instance(fields)\r\n```\r\n\r\nIt is instantiated as follows:\r\n\r\n```python\r\ndataset_reader = ClassificationTransformerReader(tokenizer=transformer_tokenizer,\r\n                                                 token_indexer=token_indexer,\r\n                                                 max_tokens=400)\r\n```\r\n\r\nTo run the model and test out if it works I'm doing the following:\r\n\r\n```python\r\ninstance = dataset_reader.text_to_instance(\"some sample text here\")\r\ndataset = Batch([instance])\r\ndataset.index_instances(transformer_vocab)\r\nmodel_input = util.move_to_device(dataset.as_tensor_dict(), \r\n                                  transformer_model._get_prediction_device())\r\n\r\noutputs = transformer_model.make_output_human_readable(transformer_model(**model_input))\r\n```\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\nOS: `Ubuntu 20.04 LTS`\r\n\r\nPython version: `3.8`\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==1.0.0\r\nalabaster==0.7.12\r\nalbumentations==0.1.12\r\nallennlp==2.9.0\r\naltair==4.2.0\r\nappdirs==1.4.4\r\nargon2-cffi==21.3.0\r\nargon2-cffi-bindings==21.2.0\r\narviz==0.11.4\r\nastor==0.8.1\r\nastropy==4.3.1\r\nastunparse==1.6.3\r\natari-py==0.2.9\r\natomicwrites==1.4.0\r\nattrs==21.4.0\r\naudioread==2.1.9\r\nautograd==1.3\r\nBabel==2.9.1\r\nbackcall==0.2.0\r\nbackports.csv==1.0.7\r\nbase58==2.1.1\r\nbeautifulsoup4==4.6.3\r\nbleach==4.1.0\r\nblis==0.4.1\r\nbokeh==2.3.3\r\nboto3==1.21.9\r\nbotocore==1.24.9\r\nBottleneck==1.3.2\r\nbranca==0.4.2\r\nbs4==0.0.1\r\nCacheControl==0.12.10\r\ncached-path==1.0.2\r\ncached-property==1.5.2\r\ncachetools==4.2.4\r\ncatalogue==1.0.0\r\ncertifi==2021.10.8\r\ncffi==1.15.0\r\ncftime==1.5.2\r\nchardet==3.0.4\r\ncharset-normalizer==2.0.12\r\nchecklist==0.0.11\r\ncheroot==8.6.0\r\nCherryPy==18.6.1\r\nclick==7.1.2\r\ncloudpickle==1.3.0\r\ncmake==3.12.0\r\ncmdstanpy==0.9.5\r\ncolorcet==3.0.0\r\ncolorlover==0.3.0\r\ncommunity==1.0.0b1\r\ncontextlib2==0.5.5\r\nconvertdate==2.4.0\r\ncoverage==3.7.1\r\ncoveralls==0.5\r\ncrcmod==1.7\r\ncryptography==36.0.1\r\ncufflinks==0.17.3\r\ncupy-cuda111==9.4.0\r\ncvxopt==1.2.7\r\ncvxpy==1.0.31\r\ncycler==0.11.0\r\ncymem==2.0.6\r\nCython==0.29.28\r\ndaft==0.0.4\r\ndask==2.12.0\r\ndatascience==0.10.6\r\ndebugpy==1.0.0\r\ndecorator==4.4.2\r\ndefusedxml==0.7.1\r\ndescartes==1.1.0\r\ndill==0.3.4\r\ndistributed==1.25.3\r\ndlib @ file:///dlib-19.18.0-cp37-cp37m-linux_x86_64.whl\r\ndm-tree==0.1.6\r\ndocker-pycreds==0.4.0\r\ndocopt==0.6.2\r\ndocutils==0.17.1\r\ndopamine-rl==1.0.5\r\nearthengine-api==0.1.299\r\neasydict==1.9\r\necos==2.0.10\r\neditdistance==0.5.3\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nentrypoints==0.4\r\nephem==4.1.3\r\net-xmlfile==1.1.0\r\nfa2==0.3.5\r\nfairscale==0.4.5\r\nfastai==1.0.61\r\nfastdtw==0.3.4\r\nfastprogress==1.0.2\r\nfastrlock==0.8\r\nfbprophet==0.7.1\r\nfeather-format==0.4.1\r\nfeedparser==6.0.8\r\nfilelock==3.4.2\r\nfirebase-admin==4.4.0\r\nfix-yahoo-finance==0.0.22\r\nFlask==1.1.4\r\nflatbuffers==2.0\r\nfolium==0.8.3\r\nfuture==0.16.0\r\ngast==0.5.3\r\nGDAL==2.2.2\r\ngdown==4.2.1\r\ngensim==3.6.0\r\ngeographiclib==1.52\r\ngeopy==1.17.0\r\ngin-config==0.5.0\r\ngitdb==4.0.9\r\nGitPython==3.1.27\r\nglob2==0.7\r\ngoogle==2.0.3\r\ngoogle-api-core==1.26.3\r\ngoogle-api-python-client==1.12.10\r\ngoogle-auth==1.35.0\r\ngoogle-auth-httplib2==0.0.4\r\ngoogle-auth-oauthlib==0.4.6\r\ngoogle-cloud-bigquery==1.21.0\r\ngoogle-cloud-bigquery-storage==1.1.0\r\ngoogle-cloud-core==1.7.2\r\ngoogle-cloud-datastore==1.8.0\r\ngoogle-cloud-firestore==1.7.0\r\ngoogle-cloud-language==1.2.0\r\ngoogle-cloud-storage==1.40.0\r\ngoogle-cloud-translate==1.5.0\r\ngoogle-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\r\ngoogle-crc32c==1.3.0\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==1.3.3\r\ngoogleapis-common-protos==1.54.0\r\ngoogledrivedownloader==0.4\r\ngraphviz==0.10.1\r\ngreenlet==1.1.2\r\ngrpcio==1.44.0\r\ngspread==3.4.2\r\ngspread-dataframe==3.0.8\r\ngym==0.17.3\r\nh5py==3.1.0\r\nHeapDict==1.0.1\r\nhijri-converter==2.2.3\r\nholidays==0.10.5.2\r\nholoviews==1.14.8\r\nhtml5lib==1.0.1\r\nhttpimport==0.5.18\r\nhttplib2==0.17.4\r\nhttplib2shim==0.0.3\r\nhuggingface-hub==0.2.1\r\nhumanize==0.5.1\r\nhyperopt==0.1.2\r\nideep4py==2.0.0.post3\r\nidna==2.10\r\nimageio==2.4.1\r\nimagesize==1.3.0\r\nimbalanced-learn==0.8.1\r\nimblearn==0.0\r\nimgaug==0.2.9\r\nimportlib-metadata==4.11.1\r\nimportlib-resources==5.4.0\r\nimutils==0.5.4\r\ninflect==2.1.0\r\niniconfig==1.1.1\r\nintel-openmp==2022.0.2\r\nintervaltree==2.1.0\r\nipykernel==4.10.1\r\nipython==5.5.0\r\nipython-genutils==0.2.0\r\nipython-sql==0.3.9\r\nipywidgets==7.6.5\r\niso-639==0.4.5\r\nitsdangerous==1.1.0\r\njaraco.classes==3.2.1\r\njaraco.collections==3.5.1\r\njaraco.context==4.1.1\r\njaraco.functools==3.5.0\r\njaraco.text==3.7.0\r\njax==0.3.1\r\njaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.0+cuda11.cudnn805-cp37-none-manylinux2010_x86_64.whl\r\njedi==0.18.1\r\njieba==0.42.1\r\nJinja2==2.11.3\r\njmespath==0.10.0\r\njoblib==1.1.0\r\njpeg4py==0.1.4\r\njsonnet==0.18.0\r\njsonschema==4.3.3\r\njupyter==1.0.0\r\njupyter-client==5.3.5\r\njupyter-console==5.2.0\r\njupyter-core==4.9.2\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.2\r\nkaggle==1.5.12\r\nkapre==0.3.7\r\nkeras==2.8.0\r\nKeras-Preprocessing==1.1.2\r\nkeras-vis==0.4.1\r\nkiwisolver==1.3.2\r\nkorean-lunar-calendar==0.2.1\r\nlibclang==13.0.0\r\nlibrosa==0.8.1\r\nlightgbm==2.2.3\r\nllvmlite==0.34.0\r\nlmdb==0.99\r\nLunarCalendar==0.0.9\r\nlxml==4.2.6\r\nMarkdown==3.3.6\r\nMarkupSafe==2.0.1\r\nmatplotlib==3.2.2\r\nmatplotlib-inline==0.1.3\r\nmatplotlib-venn==0.11.6\r\nmissingno==0.5.0\r\nmistune==0.8.4\r\nmizani==0.6.0\r\nmkl==2019.0\r\nmlxtend==0.14.0\r\nmore-itertools==8.12.0\r\nmoviepy==0.2.3.5\r\nmpmath==1.2.1\r\nmsgpack==1.0.3\r\nmultiprocess==0.70.12.2\r\nmultitasking==0.0.10\r\nmunch==2.5.0\r\nmurmurhash==1.0.6\r\nmusic21==5.5.0\r\nnatsort==5.5.0\r\nnbclient==0.5.11\r\nnbconvert==5.6.1\r\nnbformat==5.1.3\r\nnest-asyncio==1.5.4\r\nnetCDF4==1.5.8\r\nnetworkx==2.6.3\r\nnibabel==3.0.2\r\nnltk==3.2.5\r\nnotebook==5.3.1\r\nnumba==0.51.2\r\nnumexpr==2.8.1\r\nnumpy==1.21.5\r\nnvidia-ml-py3==7.352.0\r\noauth2client==4.1.3\r\noauthlib==3.2.0\r\nokgrade==0.4.3\r\nopencv-contrib-python==4.1.2.30\r\nopencv-python==4.1.2.30\r\nopenpyxl==3.0.9\r\nopt-einsum==3.3.0\r\nosqp==0.6.2.post0\r\npackaging==21.3\r\npalettable==3.3.0\r\npandas==1.3.5\r\npandas-datareader==0.9.0\r\npandas-gbq==0.13.3\r\npandas-profiling==1.4.1\r\npandocfilters==1.5.0\r\npanel==0.12.1\r\nparam==1.12.0\r\nparso==0.8.3\r\npathlib==1.0.1\r\npathtools==0.1.2\r\npatsy==0.5.2\r\npatternfork-nosql==3.6\r\npdfminer.six==20211012\r\npep517==0.12.0\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.1.2\r\npip-tools==6.2.0\r\nplac==1.1.3\r\nplotly==5.5.0\r\nplotnine==0.6.0\r\npluggy==0.7.1\r\npooch==1.6.0\r\nportend==3.1.0\r\nportpicker==1.3.9\r\nprefetch-generator==1.0.1\r\npreshed==3.0.6\r\nprettytable==3.1.1\r\nprogressbar2==3.38.0\r\nprometheus-client==0.13.1\r\npromise==2.3\r\nprompt-toolkit==1.0.18\r\nprotobuf==3.17.3\r\npsutil==5.4.8\r\npsycopg2==2.7.6.1\r\nptyprocess==0.7.0\r\npy==1.11.0\r\npyarrow==6.0.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycocotools==2.0.4\r\npycparser==2.21\r\npyct==0.4.8\r\npydata-google-auth==1.3.0\r\npydot==1.3.0\r\npydot-ng==2.0.0\r\npydotplus==2.0.2\r\nPyDrive==1.3.1\r\npyemd==0.5.1\r\npyerfa==2.0.0.1\r\npyglet==1.5.0\r\nPygments==2.6.1\r\npygobject==3.26.1\r\npymc3==3.11.4\r\nPyMeeus==0.5.11\r\npymongo==4.0.1\r\npymystem3==0.2.0\r\nPyOpenGL==3.1.5\r\npyparsing==3.0.7\r\npyrsistent==0.18.1\r\npysndfile==1.3.8\r\nPySocks==1.7.1\r\npystan==2.19.1.1\r\npytest==3.6.4\r\npython-apt==0.0.0\r\npython-chess==0.23.11\r\npython-dateutil==2.8.2\r\npython-docx==0.8.11\r\npython-louvain==0.16\r\npython-slugify==6.0.1\r\npython-utils==3.1.0\r\npytz==2018.9\r\npyviz-comms==2.1.0\r\nPyWavelets==1.2.0\r\nPyYAML==6.0\r\npyzmq==22.3.0\r\nqdldl==0.1.5.post0\r\nqtconsole==5.2.2\r\nQtPy==2.0.1\r\nregex==2019.12.20\r\nrequests==2.23.0\r\nrequests-oauthlib==1.3.1\r\nresampy==0.2.2\r\nrpy2==3.4.5\r\nrsa==4.8\r\ns3transfer==0.5.2\r\nsacremoses==0.0.47\r\nscikit-image==0.18.3\r\nscikit-learn==1.0.2\r\nscipy==1.4.1\r\nscreen-resolution-extra==0.0.0\r\nscs==3.1.0\r\nseaborn==0.11.2\r\nsemver==2.13.0\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.5.6\r\nsetuptools-git==1.2\r\nsgmllib3k==1.0.0\r\nShapely==1.8.1.post1\r\nshortuuid==1.0.8\r\nsimplegeneric==0.8.1\r\nsix==1.15.0\r\nsklearn==0.0\r\nsklearn-pandas==1.8.0\r\nsmart-open==5.2.1\r\nsmmap==5.0.0\r\nsnowballstemmer==2.2.0\r\nsortedcontainers==2.4.0\r\nSoundFile==0.10.3.post1\r\nspacy==2.2.4\r\nSphinx==1.8.6\r\nsphinxcontrib-serializinghtml==1.1.5\r\nsphinxcontrib-websupport==1.2.4\r\nSQLAlchemy==1.4.31\r\nsqlparse==0.4.2\r\nsrsly==1.0.5\r\nstatsmodels==0.10.2\r\nsympy==1.7.1\r\ntables==3.7.0\r\ntabulate==0.8.9\r\ntblib==1.7.0\r\ntempora==5.0.1\r\ntenacity==8.0.1\r\ntensorboard==2.8.0\r\ntensorboard-data-server==0.6.1\r\ntensorboard-plugin-wit==1.8.1\r\ntensorboardX==2.5\r\ntensorflow @ file:///tensorflow-2.8.0-cp37-cp37m-linux_x86_64.whl\r\ntensorflow-datasets==4.0.1\r\ntensorflow-estimator==2.8.0\r\ntensorflow-gcs-config==2.8.0\r\ntensorflow-hub==0.12.0\r\ntensorflow-io-gcs-filesystem==0.24.0\r\ntensorflow-metadata==1.6.0\r\ntensorflow-probability==0.16.0\r\ntermcolor==1.1.0\r\nterminado==0.13.1\r\ntestpath==0.5.0\r\ntext-unidecode==1.3\r\ntextblob==0.15.3\r\nTheano-PyMC==1.1.2\r\nthinc==7.4.0\r\nthreadpoolctl==3.1.0\r\ntifffile==2021.11.2\r\ntokenizers==0.10.3\r\ntomli==2.0.1\r\ntoolz==0.11.2\r\ntorch==1.9.0\r\ntorchaudio @ https://download.pytorch.org/whl/cu111/torchaudio-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\r\ntorchsummary==1.5.1\r\ntorchtext==0.11.0\r\ntorchvision==0.10.0\r\ntornado==5.1.1\r\ntqdm==4.62.3\r\ntraitlets==5.1.1\r\ntransformers==4.12.3\r\ntweepy==3.10.0\r\ntypeguard==2.7.1\r\ntyping-extensions==3.10.0.2\r\ntzlocal==1.5.1\r\nuritemplate==3.0.1\r\nurllib3==1.25.11\r\nvega-datasets==0.9.0\r\nwandb==0.12.10\r\nwasabi==0.9.0\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.5.2\r\nwordcloud==1.5.0\r\nwrapt==1.13.3\r\nxarray==0.18.2\r\nxgboost==0.90\r\nxkit==0.0.0\r\nxlrd==1.1.0\r\nxlwt==1.3.0\r\nyaspin==2.1.0\r\nzc.lockfile==2.0\r\nzict==2.0.0\r\nzipp==3.7.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nFollow the description of the isssue.\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n## Provided above.\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5582/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5582/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5577", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5577/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5577/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5577/events", "html_url": "https://github.com/allenai/allennlp/issues/5577", "id": 1148091234, "node_id": "I_kwDOBXH8-M5Ebnti", "number": 5577, "title": "How to save models that maintain optimal performance across multiple datasets on multitask?", "user": {"login": "ICanFlyGFC", "id": 50896307, "node_id": "MDQ6VXNlcjUwODk2MzA3", "avatar_url": "https://avatars.githubusercontent.com/u/50896307?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ICanFlyGFC", "html_url": "https://github.com/ICanFlyGFC", "followers_url": "https://api.github.com/users/ICanFlyGFC/followers", "following_url": "https://api.github.com/users/ICanFlyGFC/following{/other_user}", "gists_url": "https://api.github.com/users/ICanFlyGFC/gists{/gist_id}", "starred_url": "https://api.github.com/users/ICanFlyGFC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ICanFlyGFC/subscriptions", "organizations_url": "https://api.github.com/users/ICanFlyGFC/orgs", "repos_url": "https://api.github.com/users/ICanFlyGFC/repos", "events_url": "https://api.github.com/users/ICanFlyGFC/events{/privacy}", "received_events_url": "https://api.github.com/users/ICanFlyGFC/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2022-02-23T13:23:18Z", "updated_at": "2022-03-17T17:49:50Z", "closed_at": "2022-03-17T17:49:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "I built a multitask model. The best-performing model by training is automatically saved in the single-task case.\r\nBut for multitasking, the model just saves the best performance of the model on one of the datasets.\r\nHow do I get the training process to choose a better model performance measure for multiple datasets?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5577/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5577/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5573", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5573/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5573/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5573/events", "html_url": "https://github.com/allenai/allennlp/issues/5573", "id": 1143045464, "node_id": "I_kwDOBXH8-M5EIX1Y", "number": 5573, "title": "Unclear error when Perl is not found in path when training AllenNLP Semantic Role Labeling model", "user": {"login": "Denbergvanthijs", "id": 43202049, "node_id": "MDQ6VXNlcjQzMjAyMDQ5", "avatar_url": "https://avatars.githubusercontent.com/u/43202049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Denbergvanthijs", "html_url": "https://github.com/Denbergvanthijs", "followers_url": "https://api.github.com/users/Denbergvanthijs/followers", "following_url": "https://api.github.com/users/Denbergvanthijs/following{/other_user}", "gists_url": "https://api.github.com/users/Denbergvanthijs/gists{/gist_id}", "starred_url": "https://api.github.com/users/Denbergvanthijs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Denbergvanthijs/subscriptions", "organizations_url": "https://api.github.com/users/Denbergvanthijs/orgs", "repos_url": "https://api.github.com/users/Denbergvanthijs/repos", "events_url": "https://api.github.com/users/Denbergvanthijs/events{/privacy}", "received_events_url": "https://api.github.com/users/Denbergvanthijs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2022-02-18T13:14:59Z", "updated_at": "2022-03-01T07:32:04Z", "closed_at": "2022-03-01T07:32:04Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n  0%|          | 0/1546 [00:00<?, ?it/s]2022-02-17 13:06:23,003 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one\r\n2022-02-17 13:06:23,003 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys\r\n  0%|          | 0/1546 [00:00<?, ?it/s]\r\n2022-02-17 13:06:23,262 - CRITICAL - root - Uncaught exception\r\n\r\n(...)\r\n\r\n  File \"C:\\Users\\[REDACTED]\\Anaconda3\\envs\\[REDACTED]\\lib\\site-packages\\allennlp_models\\structured_prediction\\metrics\\srl_eval_scorer.py\", line 107, in __call__\r\n    completed_process = subprocess.run(\r\n  File \"C:\\Users\\[REDACTED]\\Anaconda3\\envs\\[REDACTED]\\lib\\subprocess.py\", line 505, in run\r\n    with Popen(*popenargs, **kwargs) as process:\r\n  File \"C:\\Users\\[REDACTED]\\Anaconda3\\envs\\[REDACTED]\\lib\\subprocess.py\", line 951, in __init__\r\n    self._execute_child(args, executable, preexec_fn, close_fds,\r\n  File \"C:\\Users\\[REDACTED]\\Anaconda3\\envs\\[REDACTED]\\lib\\subprocess.py\", line 1420, in _execute_child\r\n    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\r\nFileNotFoundError: [WinError 2] The system cannot find the file specified\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nWhen running the `allennlp train` command for a Semantic Role Labeling model, the script will crash when Perl is not installed/found in path. The `FileNotFoundError` can be unclear to some users. In my opinion, a better error message would be to explicitly mention that Perl is not found.\r\n\r\nThe relevant lines are:\r\n\r\nhttps://github.com/allenai/allennlp-models/blob/1e89d5e51cb45f3e77a48d4983bf980088334fac/allennlp_models/structured_prediction/metrics/srl_eval_scorer.py#L106-L109\r\n\r\nI wouldn't mind implementing something to check if Perl is installed! Please let me know if you would be interested in a PR!\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Windows 10\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.9.9\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==1.0.0\r\naiofiles==0.8.0\r\naiohttp==3.8.1\r\naiosignal==1.2.0\r\nallennlp==2.9.0\r\nallennlp-models==2.9.0\r\nanyio==3.4.0\r\nargon2-cffi==21.1.0\r\nastunparse==1.6.3\r\nasync-timeout==4.0.2\r\natomicwrites==1.4.0\r\nattrs==21.2.0\r\nautopep8==1.6.0\r\nBabel==2.9.1\r\nbackcall==0.2.0\r\nbackports.csv==1.0.7\r\nbase58==2.1.1\r\nbcrypt==3.2.0\r\nbeautifulsoup4==4.10.0\r\nblack==22.1.0\r\nbleach==4.1.0\r\nblis==0.7.5\r\nboto3==1.20.46\r\nbotocore==1.23.46\r\ncached-path==1.0.2\r\ncachetools==4.2.4\r\ncatalogue==2.0.6\r\ncertifi==2021.10.8\r\ncffi==1.15.0\r\nchardet==4.0.0\r\ncharset-normalizer==2.0.7\r\ncheroot==8.6.0\r\nCherryPy==18.6.1\r\nclick==8.0.3\r\ncolorama==0.4.4\r\nconfigparser==5.1.0\r\nconllu==4.4.1\r\ncoverage==6.2\r\ncryptography==36.0.0\r\ncycler==0.11.0\r\ncymem==2.0.6\r\nCython==0.29.24\r\ndatasets==1.18.2\r\ndebugpy==1.5.1\r\ndecorator==5.1.0\r\ndefusedxml==0.7.1\r\ndgl==0.6.1\r\ndill==0.3.4\r\ndocker-pycreds==0.4.0\r\nemoji==1.6.3\r\nen-core-web-lg @ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.2.0/en_core_web_lg-3.2.0-py3-none-any.whl\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl\r\nentrypoints==0.3\r\nexecnet==1.9.0\r\nfairscale==0.4.5\r\nfastapi==0.68.2\r\nfasttext==0.9.2\r\nfeedparser==6.0.8\r\nfilelock==3.4.2\r\nflake8==4.0.1\r\nflatbuffers==2.0\r\nfonttools==4.28.1\r\nfrozenlist==1.3.0\r\nfsspec==2022.1.0\r\nftfy==6.0.3\r\nfuture==0.18.2\r\ngast==0.4.0\r\ngitdb==4.0.9\r\nGitPython==3.1.24\r\ngoogle-api-core==2.4.0\r\ngoogle-auth==2.3.3\r\ngoogle-auth-oauthlib==0.4.6\r\ngoogle-cloud-core==2.2.2\r\ngoogle-cloud-storage==1.44.0\r\ngoogle-crc32c==1.3.0\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==2.1.0\r\ngoogleapis-common-protos==1.54.0\r\ngraphviz==0.19.1\r\ngrpcio==1.42.0\r\nh11==0.13.0\r\nh5py==3.6.0\r\nhuggingface-hub==0.2.1\r\nidna==3.3\r\nimageio==2.16.0\r\nimportlib-metadata==4.8.2\r\niniconfig==1.1.1\r\nipykernel==6.5.1\r\nipython==7.29.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.5\r\niso-639==0.4.5\r\njaraco.classes==3.2.1\r\njaraco.collections==3.5.1\r\njaraco.context==4.1.1\r\njaraco.functools==3.5.0\r\njaraco.text==3.7.0\r\njedi==0.18.1\r\nJinja2==3.0.3\r\njmespath==0.10.0\r\njoblib==1.1.0\r\njson5==0.9.6\r\njsonschema==4.2.1\r\njupyter==1.0.0\r\njupyter-client==7.0.6\r\njupyter-console==6.4.0\r\njupyter-core==4.9.1\r\njupyter-server==1.12.1\r\njupyterlab==3.2.4\r\njupyterlab-pygments==0.1.2\r\njupyterlab-server==2.8.2\r\njupyterlab-widgets==1.0.2\r\nKafNafParserPy==1.896\r\nkeras==2.7.0\r\nKeras-Preprocessing==1.1.2\r\nkiwisolver==1.3.2\r\nlangcodes==3.3.0\r\nlibclang==12.0.0\r\nlmdb==1.3.0\r\nlxml==4.7.1\r\nMarkdown==3.3.6\r\nMarkupSafe==2.0.1\r\nmatplotlib==3.5.0\r\nmatplotlib-inline==0.1.3\r\nmccabe==0.6.1\r\nmistune==0.8.4\r\nmore-itertools==8.12.0\r\nmultidict==6.0.2\r\nmultiprocess==0.70.12.2\r\nmunch==2.5.0\r\nmurmurhash==1.0.6\r\nmypy==0.931\r\nmypy-extensions==0.4.3\r\nnbclassic==0.3.4\r\nnbclient==0.5.9\r\nnbconvert==6.3.0\r\nnbformat==5.1.3\r\nnest-asyncio==1.5.1\r\nnetworkx==2.6.3\r\nnl-core-news-lg @ https://github.com/explosion/spacy-models/releases/download/nl_core_news_lg-3.2.0/nl_core_news_lg-3.2.0-py3-none-any.whl\r\nnl-core-news-sm @ https://github.com/explosion/spacy-models/releases/download/nl_core_news_sm-3.2.0/nl_core_news_sm-3.2.0-py3-none-any.whl\r\nnltk==3.6.5\r\nnotebook==6.4.6\r\nnumpy==1.21.4\r\noauthlib==3.1.1\r\nopencv-contrib-python==4.5.4.58\r\nopencv-python==4.5.4.58\r\nopt-einsum==3.3.0\r\npackaging==21.3\r\npandas==1.3.4\r\npandocfilters==1.5.0\r\nparamiko==2.8.0\r\nparso==0.8.2\r\npathspec==0.9.0\r\npathtools==0.1.2\r\npathy==0.6.1\r\npatsy==0.5.2\r\npatternfork-nosql==3.6\r\npdfminer.six==20211012\r\npeewee==3.14.8\r\npickleshare==0.7.5\r\nPillow==8.4.0\r\nplac==1.1.3\r\nplatformdirs==2.5.0\r\npluggy==1.0.0\r\nportend==3.1.0\r\npreshed==3.0.6\r\nprettyprint==0.1.5\r\nprogress==1.6\r\nprometheus-client==0.12.0\r\npromise==2.3\r\nprompt-toolkit==3.0.22\r\nprotobuf==3.19.1\r\npsutil==5.8.0\r\npy==1.11.0\r\npy-rouge==1.1\r\npyarrow==6.0.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npybind11==2.9.1\r\npycocotools==2.0.3\r\npycodestyle==2.8.0\r\npycparser==2.21\r\npydantic==1.8.2\r\npyflakes==2.4.0\r\nPygments==2.10.0\r\nPyJWT==2.3.0\r\nPyNaCl==1.4.0\r\npynput==1.7.5\r\npyparsing==3.0.6\r\nPyQt5==5.15.6\r\nPyQt5-Qt5==5.15.2\r\nPyQt5-sip==12.9.0\r\npyrsistent==0.18.0\r\npytest==6.2.5\r\npytest-cov==3.0.0\r\npytest-forked==1.3.0\r\npytest-xdist==2.4.0\r\npython-dateutil==2.8.2\r\npython-docx==0.8.11\r\npytz==2021.3\r\npywin32==302\r\npywinpty==1.1.6\r\nPyYAML==6.0\r\npyzmq==22.3.0\r\nqtconsole==5.2.2\r\nQtPy==2.0.0\r\nregex==2022.1.18\r\nrequests==2.26.0\r\nrequests-oauthlib==1.3.0\r\nrsa==4.7.2\r\ns3transfer==0.5.0\r\nsacremoses==0.0.47\r\nscikit-learn==1.0.1\r\nscipy==1.7.2\r\nscp==0.14.1\r\nseaborn @ file:///D:/projects/seaborn\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.5.0\r\nsetuptools-scm==6.3.2\r\nsgmllib3k==1.0.0\r\nshortuuid==1.0.8\r\nsix==1.16.0\r\nsklearn==0.0\r\nsmart-open==5.2.1\r\nsmmap==5.0.0\r\nsniffio==1.2.0\r\nsoupsieve==2.3.1\r\nspacy==3.2.1\r\nspacy-legacy==3.0.8\r\nspacy-loggers==1.0.1\r\nsrsly==2.4.2\r\nstanza==1.2\r\nstarlette==0.14.2\r\nstatsmodels==0.13.1\r\nsubprocess32==3.5.4\r\ntempora==5.0.0\r\ntensorboard==2.7.0\r\ntensorboard-data-server==0.6.1\r\ntensorboard-plugin-wit==1.8.0\r\ntensorboardX==2.4.1\r\ntensorflow==2.7.0\r\ntensorflow-estimator==2.7.0\r\ntensorflow-io-gcs-filesystem==0.22.0\r\ntermcolor==1.1.0\r\nterminado==0.12.1\r\ntestpath==0.5.0\r\nthinc==8.0.13\r\nthop==0.0.31.post2005241907\r\nthreadpoolctl==3.0.0\r\ntokenizers==0.10.3\r\ntoml==0.10.2\r\ntomli==1.2.2\r\ntoolz==0.11.2\r\ntorch==1.8.2+cu102\r\ntorchaudio==0.8.2\r\ntorchvision==0.9.2+cu102\r\ntornado==6.1\r\ntqdm==4.62.3\r\ntraitlets==5.1.1\r\ntransformers==4.15.0\r\ntyper==0.4.0\r\ntyping_extensions==4.0.0\r\nurllib3==1.26.7\r\nuvicorn==0.13.4\r\nwandb==0.12.7\r\nwasabi==0.9.0\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nwebsocket-client==1.2.1\r\nWerkzeug==2.0.2\r\nwidgetsnbextension==3.5.2\r\nword2number==1.1\r\nwrapt==1.13.3\r\nxxhash==2.0.2\r\nyarl==1.7.2\r\nyaspin==2.1.0\r\nzc.lockfile==2.0\r\nzipp==3.6.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n1. Make sure Perl is not in path\r\n2. Run the following command:\r\n\r\n```bash\r\nallennlp train https://raw.githubusercontent.com/allenai/allennlp-models/main/training_config/structured_prediction/bert_base_srl.jsonnet -s /path/to/output\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5573/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5573/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5564", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5564/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5564/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5564/events", "html_url": "https://github.com/allenai/allennlp/issues/5564", "id": 1131304765, "node_id": "I_kwDOBXH8-M5Dblc9", "number": 5564, "title": "Confusing `Vocabulary` docstring", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2022-02-11T00:13:10Z", "updated_at": "2022-03-04T02:27:44Z", "closed_at": "2022-03-04T02:27:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to build a model using pre-trained gensim word2vec vectors. I think I have it working now but it was quite confusing, in particular, the docstring for the `Vocabulary`  `only_include_pretrained_words`. It states:\r\n\r\n    only_include_pretrained_words : `bool`, optional (default=`False`)\r\n        This defines the strategy for using any pretrained embedding files which may have been\r\n        specified in `pretrained_files`. If False, an inclusive strategy is used: and words\r\n        which are in the `counter` and in the pretrained file are added to the `Vocabulary`,\r\n        regardless of whether their count exceeds `min_count` or not. If True, we use an\r\n        exclusive strategy: words are only included in the Vocabulary if they are in the pretrained\r\n        embedding file (their count must still be at least `min_count`).\r\n\r\nWhat this implies to me is that you either get the intersection of the pre-trained vocab and the tokens discovered from the instances OR you get just the pre-trained vocabulary. However, there's what an undocumented and confusing (IMO) interaction with the `min_pretrained_embeddings` parameter, the docstring being:\r\n\r\n    min_pretrained_embeddings : `Dict[str, int]`, optional\r\n        If provided, specifies for each namespace a minimum number of lines (typically the\r\n        most common words) to keep from pretrained embedding files, even for words not\r\n        appearing in the data.\r\n\r\nGiven that it's optional, my expectation is that if you set `only_include_pretrained_words=True` and don't set `min_pretrained_embeddings` the resulting vocabulary should be 100% of the tokens from the pre-trained file.\r\n\r\nThis isn't the case from what I gather, it appears you must set `only_include_pretrained_words=True` and pass the number of tokens in the pre-trained files anmespace to `min_pretrained_embeddings` due to this line :\r\n\r\nhttps://github.com/allenai/allennlp/blob/1caf0dafa3bc8d0bb309a46e2ccb12f714923260/allennlp/data/vocabulary.py#L669\r\n\r\nIt coalesces 'min_pretrained_embeddings' to rather than the length of pretrained_list, so you always only get the vocab from instances. Perhaps it should be:\r\n\r\n                pretrained_list = _read_pretrained_tokens(pretrained_files[namespace])\r\n                min_embeddings = min_pretrained_embeddings.get(namespace, len(pretrained_list))\r\n\r\nAlthough I'm not sure if that also works in the case where `only_include_pretrained_words=False` (or at least I'm not sure it's consistent with the docstring)\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5564/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5564/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5559", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5559/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5559/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5559/events", "html_url": "https://github.com/allenai/allennlp/issues/5559", "id": 1124873173, "node_id": "I_kwDOBXH8-M5DDDPV", "number": 5559, "title": "Remove upper bound for nltk", "user": {"login": "h-vetinari", "id": 33685575, "node_id": "MDQ6VXNlcjMzNjg1NTc1", "avatar_url": "https://avatars.githubusercontent.com/u/33685575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/h-vetinari", "html_url": "https://github.com/h-vetinari", "followers_url": "https://api.github.com/users/h-vetinari/followers", "following_url": "https://api.github.com/users/h-vetinari/following{/other_user}", "gists_url": "https://api.github.com/users/h-vetinari/gists{/gist_id}", "starred_url": "https://api.github.com/users/h-vetinari/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/h-vetinari/subscriptions", "organizations_url": "https://api.github.com/users/h-vetinari/orgs", "repos_url": "https://api.github.com/users/h-vetinari/repos", "events_url": "https://api.github.com/users/h-vetinari/events{/privacy}", "received_events_url": "https://api.github.com/users/h-vetinari/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-02-05T08:41:58Z", "updated_at": "2022-02-10T23:16:02Z", "closed_at": "2022-02-10T23:16:02Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Currently, allennlp 2.9.0 [requires](https://github.com/allenai/allennlp/blame/v2.9.0/setup.py#L58)\r\n```\r\nnltk <3.6.6\r\n```\r\nwhile allennlp-models 2.9.0 [requires](https://github.com/allenai/allennlp-models/blame/v2.9.0/requirements.txt#L11)\r\n```\r\nnltk >=3.6.5\r\n```\r\n\r\nThis is the slimmest possible margin, and for anyone using allennlp-models, this is effectively an exact pin to `3.6.5`, and will strain (or in the worst case: break) the package solvers of either conda or pip.\r\n\r\nFor context: the change that introduced the cap here was #5540 in response to #5521 - that's completely fine as a stop-gap, but latest in the medium term this cap should be removed again.\r\n\r\nCC @dirkgr @epwalsh \r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5559/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5559/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5556", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5556/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5556/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5556/events", "html_url": "https://github.com/allenai/allennlp/issues/5556", "id": 1122608791, "node_id": "I_kwDOBXH8-M5C6aaX", "number": 5556, "title": "Cannot construct BidirectionalLanguageModelTokenEmbedder", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-02-03T03:17:12Z", "updated_at": "2022-02-21T16:09:42Z", "closed_at": "2022-02-21T16:09:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've been adapting the model described by Louis Qin [PyTorch ELMo, trained from scratch](https://towardsdatascience.com/pytorch-elmo-844d2391a0b2) but I'n having issues creating a `BidirectionalLanguageModelTokenEmbedder` from the pretrained model. ie.\r\n\r\n```\r\nembedder = BidirectionalLanguageModelTokenEmbedder(\r\n    archive_file=archive_file,\r\n    bos_eos_tokens=(\"<s>\", \"</s>\")\r\n)\r\n```\r\n\r\nfails, it complains that Embeddings require either a size or a vocabulary. I traced it to the way the `BidirectionalLanguageModelTokenEmbedder` attempts to construct a new TextFieldEmbedder from the model params without a vocabulary\r\n\r\n```\r\narchive = load_archive(archive_file)\r\n\r\nconfig = archive.config\r\ndict_config = config.as_dict(quiet=True)\r\n\r\ntext_field_embedder = dict_config[\"model\"][\"text_field_embedder\"]\r\ntext_field_embedder = TextFieldEmbedder.from_params(Params(text_field_embedder))\r\n```\r\n\r\nI think the last line should be\r\n\r\n```\r\ntext_field_embedder = TextFieldEmbedder.from_params(vocab=self._lm.vocab,  params=Params(text_field_embedder))\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5556/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5556/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5547", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5547/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5547/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5547/events", "html_url": "https://github.com/allenai/allennlp/issues/5547", "id": 1107634686, "node_id": "I_kwDOBXH8-M5CBSn-", "number": 5547, "title": "Training longformer fails with error", "user": {"login": "kingafy", "id": 15839412, "node_id": "MDQ6VXNlcjE1ODM5NDEy", "avatar_url": "https://avatars.githubusercontent.com/u/15839412?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kingafy", "html_url": "https://github.com/kingafy", "followers_url": "https://api.github.com/users/kingafy/followers", "following_url": "https://api.github.com/users/kingafy/following{/other_user}", "gists_url": "https://api.github.com/users/kingafy/gists{/gist_id}", "starred_url": "https://api.github.com/users/kingafy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kingafy/subscriptions", "organizations_url": "https://api.github.com/users/kingafy/orgs", "repos_url": "https://api.github.com/users/kingafy/repos", "events_url": "https://api.github.com/users/kingafy/events{/privacy}", "received_events_url": "https://api.github.com/users/kingafy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-01-19T04:36:56Z", "updated_at": "2022-02-05T01:58:00Z", "closed_at": "2022-02-04T16:09:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am using allennlp trainer to train longformer (allenai/longformer-base-4096) model but unfortunately its failing with message \r\n File \"/usr/local/lib/python3.7/dist-packages/allennlp/modules/seq2vec_encoders/boe_encoder.py\", line 43, in forward\r\n    tokens = tokens * mask.unsqueeze(-1)\r\nRuntimeError: The size of tensor a (512) must match the size of tensor b (503) at non-singleton dimension 1\r\n\r\nIs there a limitation to train long sequence models in Allennlp or are there any specific parameters to be passed to train models in allen nlp to handle longer sequence based models such a longformer.\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5547/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5547/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5544", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5544/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5544/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5544/events", "html_url": "https://github.com/allenai/allennlp/issues/5544", "id": 1105672433, "node_id": "I_kwDOBXH8-M5B5zjx", "number": 5544, "title": "Broken Link in MultiProcessDataLoader Docs", "user": {"login": "MSLars", "id": 13149892, "node_id": "MDQ6VXNlcjEzMTQ5ODky", "avatar_url": "https://avatars.githubusercontent.com/u/13149892?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MSLars", "html_url": "https://github.com/MSLars", "followers_url": "https://api.github.com/users/MSLars/followers", "following_url": "https://api.github.com/users/MSLars/following{/other_user}", "gists_url": "https://api.github.com/users/MSLars/gists{/gist_id}", "starred_url": "https://api.github.com/users/MSLars/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MSLars/subscriptions", "organizations_url": "https://api.github.com/users/MSLars/orgs", "repos_url": "https://api.github.com/users/MSLars/repos", "events_url": "https://api.github.com/users/MSLars/events{/privacy}", "received_events_url": "https://api.github.com/users/MSLars/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-01-17T10:29:45Z", "updated_at": "2022-01-31T16:09:35Z", "closed_at": "2022-01-31T16:09:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nThe documentation for `MultiProcessDataLoader` contains a broken link.\r\n\r\nhttps://docs.allennlp.org/main/api/data/data_loaders/multiprocess_data_loader/#multiprocessdataloader links to https://docs.allennlp.org/api/data/dataset_readers/dataset_reader/#datasetreader.using_your_reader_with_multi-process_or_distributed_data_loading which leads to an `404` error. \r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5544/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5544/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5537", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5537/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5537/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5537/events", "html_url": "https://github.com/allenai/allennlp/issues/5537", "id": 1095916004, "node_id": "I_kwDOBXH8-M5BUlnk", "number": 5537, "title": "Using evaluate command for multi-task model", "user": {"login": "ICanFlyGFC", "id": 50896307, "node_id": "MDQ6VXNlcjUwODk2MzA3", "avatar_url": "https://avatars.githubusercontent.com/u/50896307?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ICanFlyGFC", "html_url": "https://github.com/ICanFlyGFC", "followers_url": "https://api.github.com/users/ICanFlyGFC/followers", "following_url": "https://api.github.com/users/ICanFlyGFC/following{/other_user}", "gists_url": "https://api.github.com/users/ICanFlyGFC/gists{/gist_id}", "starred_url": "https://api.github.com/users/ICanFlyGFC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ICanFlyGFC/subscriptions", "organizations_url": "https://api.github.com/users/ICanFlyGFC/orgs", "repos_url": "https://api.github.com/users/ICanFlyGFC/repos", "events_url": "https://api.github.com/users/ICanFlyGFC/events{/privacy}", "received_events_url": "https://api.github.com/users/ICanFlyGFC/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2022-01-07T02:16:46Z", "updated_at": "2022-02-28T21:42:05Z", "closed_at": "2022-02-28T21:42:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nevaluate command can not support multitask that input_file only takes the file name as input.\r\nBut multi-task reader needs Dic.\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n\r\n(allennlp2_8) D:\\WorkSpace\\GeoQA-with-UniT -2_8>allennlp evaluate save/test test_data_path --include-package NGS_Aux --cuda-device 0\r\n2022-01-07 09:38:22,837 - INFO - allennlp.models.archival - loading archive file save/test\r\n2022-01-07 09:38:23,469 - INFO - allennlp.data.vocabulary - Loading token dictionary from save/test\\vocabulary.\r\n##### Checkpoint Loaded! #####\r\n2022-01-07 09:38:28,271 - INFO - allennlp.modules.token_embedders.embedding - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you wan\r\nt to extend the vocabulary.\r\n2022-01-07 09:38:29,051 - INFO - allennlp.common.checks - Pytorch version: 1.10.0+cu113\r\n2022-01-07 09:38:29,053 - INFO - allennlp.commands.evaluate - Reading evaluation data from test_data_path\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda\\envs\\allennlp2_8\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"D:\\Anaconda\\envs\\allennlp2_8\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"D:\\Anaconda\\envs\\allennlp2_8\\Scripts\\allennlp.exe\\__main__.py\", line 7, in <module>\r\n  File \"D:\\Anaconda\\envs\\allennlp2_8\\lib\\site-packages\\allennlp\\__main__.py\", line 46, in run\r\n    main(prog=\"allennlp\")\r\n  File \"D:\\Anaconda\\envs\\allennlp2_8\\lib\\site-packages\\allennlp\\commands\\__init__.py\", line 123, in main\r\n    args.func(args)\r\n  File \"D:\\Anaconda\\envs\\allennlp2_8\\lib\\site-packages\\allennlp\\commands\\evaluate.py\", line 189, in evaluate_from_args\r\n    params=data_loader_params, reader=dataset_reader, data_path=evaluation_data_path\r\n  File \"D:\\Anaconda\\envs\\allennlp2_8\\lib\\site-packages\\allennlp\\common\\from_params.py\", line 656, in from_params\r\n    **extras,\r\n  File \"D:\\Anaconda\\envs\\allennlp2_8\\lib\\site-packages\\allennlp\\common\\from_params.py\", line 686, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"D:\\Anaconda\\envs\\allennlp2_8\\lib\\site-packages\\allennlp\\data\\data_loaders\\multitask_data_loader.py\", line 143, in __init__\r\n    if self.readers.keys() != self.data_paths.keys():\r\nAttributeError: 'str' object has no attribute 'keys'\r\n\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nWindows:\r\naiohttp                  3.8.0\r\naiosignal                1.2.0\r\nallennlp                 2.8.0\r\nargcomplete              1.12.3\r\nargon2-cffi              21.1.0\r\nasync-timeout            4.0.0\r\nasynctest                0.13.0\r\natomicwrites             1.4.0\r\nattrs                    21.2.0\r\nbackcall                 0.2.0\r\nbackports.csv            1.0.7\r\nbase58                   2.1.1\r\nbeautifulsoup4           4.10.0\r\nbleach                   4.1.0\r\nblis                     0.7.5\r\nboto3                    1.19.12\r\nbotocore                 1.22.12\r\ncached-path              0.3.2\r\ncached-property          1.5.2\r\ncachetools               4.2.4\r\ncatalogue                1.0.0\r\ncertifi                  2021.10.8\r\ncffi                     1.15.0\r\nchardet                  4.0.0\r\ncharset-normalizer       2.0.7\r\nchecklist                0.0.11\r\ncheroot                  8.5.2\r\nCherryPy                 18.6.1\r\nclick                    8.0.3\r\ncolorama                 0.4.4\r\nconfigparser             5.1.0\r\ncryptography             35.0.0\r\ncymem                    2.0.6\r\nCython                   0.29.23\r\ndatasets                 1.15.1\r\ndebugpy                  1.5.1\r\ndecorator                5.1.0\r\ndefusedxml               0.7.1\r\ndill                     0.3.4\r\ndocker-pycreds           0.4.0\r\nen-core-web-sm           2.3.0\r\nentrypoints              0.3\r\nfairscale                0.4.0\r\nfeedparser               6.0.8\r\nfilelock                 3.3.2\r\nfrozenlist               1.2.0\r\nfsspec                   2021.11.0\r\nfuture                   0.18.2\r\ngensim                   4.1.2\r\ngitdb                    4.0.9\r\nGitPython                3.1.24\r\ngoogle-api-core          2.2.2\r\ngoogle-auth              2.3.3\r\ngoogle-cloud-core        2.1.0\r\ngoogle-cloud-storage     1.42.3\r\ngoogle-crc32c            1.3.0\r\ngoogle-resumable-media   2.1.0\r\ngoogleapis-common-protos 1.53.0\r\nh5py                     3.5.0\r\nhuggingface-hub          0.1.1\r\nidna                     3.3\r\nimportlib-metadata       4.8.1\r\nimportlib-resources      5.4.0\r\niniconfig                1.1.1\r\nipykernel                6.5.0\r\nipython                  7.29.0\r\nipython-genutils         0.2.0\r\nipywidgets               7.6.5\r\niso-639                  0.4.5\r\njaraco.classes           3.2.1\r\njaraco.collections       3.4.0\r\njaraco.functools         3.4.0\r\njaraco.text              3.6.0\r\njedi                     0.18.0\r\njieba                    0.42.1\r\nJinja2                   3.0.2\r\njmespath                 0.10.0\r\njoblib                   1.1.0\r\njsonschema               4.2.1\r\njupyter                  1.0.0\r\njupyter-client           7.0.6\r\njupyter-console          6.4.0\r\njupyter-core             4.9.1\r\njupyterlab-pygments      0.1.2\r\njupyterlab-widgets       1.0.2\r\nlmdb                     1.2.1\r\nlxml                     4.6.4\r\nMarkupSafe               2.0.1\r\nmatplotlib-inline        0.1.3\r\nmistune                  0.8.4\r\nmore-itertools           8.10.0\r\nmultidict                5.2.0\r\nmultiprocess             0.70.12.2\r\nmunch                    2.5.0\r\nmurmurhash               1.0.6\r\nnbclient                 0.5.4\r\nnbconvert                6.2.0\r\nnbformat                 5.1.3\r\nnest-asyncio             1.5.1\r\nnltk                     3.6.5\r\nnotebook                 6.4.5\r\nnumpy                    1.21.4\r\nopencv-python            4.5.4.58\r\noverrides                3.1.0\r\npackaging                21.2\r\npandas                   1.3.4\r\npandocfilters            1.5.0\r\nparso                    0.8.2\r\npathtools                0.1.2\r\npathy                    0.6.1\r\npatternfork-nosql        3.6\r\npdfminer.six             20211012\r\npickleshare              0.7.5\r\nPillow                   8.4.0\r\npip                      21.2.4\r\nplac                     1.1.3\r\npluggy                   1.0.0\r\nportend                  3.0.0\r\npreshed                  3.0.6\r\nprometheus-client        0.12.0\r\npromise                  2.3\r\nprompt-toolkit           3.0.22\r\nprotobuf                 3.19.1\r\npsutil                   5.8.0\r\npy                       1.11.0\r\npyarrow                  6.0.0\r\npyasn1                   0.4.8\r\npyasn1-modules           0.2.8\r\npycparser                2.21\r\npydantic                 1.8.2\r\nPygments                 2.10.0\r\npyparsing                2.4.7\r\npyrsistent               0.18.0\r\npytest                   6.2.5\r\npython-dateutil          2.8.2\r\npython-docx              0.8.11\r\npytz                     2021.3\r\npywin32                  302\r\npywinpty                 1.1.5\r\nPyYAML                   6.0\r\npyzmq                    22.3.0\r\nqtconsole                5.1.1\r\nQtPy                     1.11.2\r\nregex                    2021.11.2\r\nrequests                 2.26.0\r\nrsa                      4.7.2\r\ns3transfer               0.5.0\r\nsacremoses               0.0.46\r\nscikit-learn             1.0.1\r\nscipy                    1.7.2\r\nSend2Trash               1.8.0\r\nsentencepiece            0.1.96\r\nsentry-sdk               1.4.3\r\nsetuptools               58.0.4\r\nsgmllib3k                1.0.0\r\nshortuuid                1.0.1\r\nsix                      1.16.0\r\nsmart-open               5.2.1\r\nsmmap                    5.0.0\r\nsoupsieve                2.3\r\nspacy                    2.3.7\r\nspacy-legacy             3.0.8\r\nsqlitedict               1.7.0\r\nsrsly                    1.0.5\r\nsubprocess32             3.5.4\r\ntempora                  4.1.2\r\ntensorboardX             2.4\r\ntermcolor                1.1.0\r\nterminado                0.12.1\r\ntestpath                 0.5.0\r\nthinc                    7.4.5\r\nthreadpoolctl            3.0.0\r\ntokenizers               0.10.3\r\ntoml                     0.10.2\r\ntorch                    1.10.0+cu113\r\ntorchaudio               0.10.0+cu113\r\ntorchvision              0.11.1+cu113\r\ntornado                  6.1\r\ntqdm                     4.62.3\r\ntraitlets                5.1.1\r\ntransformers             4.12.3\r\ntyper                    0.4.0\r\ntyping-extensions        3.10.0.2\r\nurllib3                  1.26.7\r\nwandb                    0.12.6\r\nwasabi                   0.8.2\r\nwcwidth                  0.2.5\r\nwebencodings             0.5.1\r\nwheel                    0.37.0\r\nwidgetsnbextension       3.5.2\r\nwincertstore             0.2\r\nxxhash                   2.0.2\r\nyarl                     1.7.2\r\nyaspin                   2.1.0\r\nzc.lockfile              2.0\r\nzipp                     3.6.0\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n3.7\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5537/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5537/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5532", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5532/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5532/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5532/events", "html_url": "https://github.com/allenai/allennlp/issues/5532", "id": 1091045450, "node_id": "I_kwDOBXH8-M5BCAhK", "number": 5532, "title": "Error: 'zipimporter' object has no attribute 'path'", "user": {"login": "rajesh-channashetty", "id": 33393718, "node_id": "MDQ6VXNlcjMzMzkzNzE4", "avatar_url": "https://avatars.githubusercontent.com/u/33393718?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rajesh-channashetty", "html_url": "https://github.com/rajesh-channashetty", "followers_url": "https://api.github.com/users/rajesh-channashetty/followers", "following_url": "https://api.github.com/users/rajesh-channashetty/following{/other_user}", "gists_url": "https://api.github.com/users/rajesh-channashetty/gists{/gist_id}", "starred_url": "https://api.github.com/users/rajesh-channashetty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rajesh-channashetty/subscriptions", "organizations_url": "https://api.github.com/users/rajesh-channashetty/orgs", "repos_url": "https://api.github.com/users/rajesh-channashetty/repos", "events_url": "https://api.github.com/users/rajesh-channashetty/events{/privacy}", "received_events_url": "https://api.github.com/users/rajesh-channashetty/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2021-12-30T11:27:26Z", "updated_at": "2022-02-23T02:24:09Z", "closed_at": "2022-02-23T02:24:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [ x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [ x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!--Getting the error ''zipimporter' object has no attribute 'path'' while importing a model. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<command-1817538804636320> in <module>\r\n      2 \r\n      3 model_url = 'https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz'\r\n----> 4 predictor = Predictor.from_path(model_url)  # load the model\r\n\r\n/databricks/python/lib/python3.8/site-packages/allennlp/predictors/predictor.py in from_path(cls, archive_path, predictor_name, cuda_device, dataset_reader_to_load, frozen, import_plugins, overrides)\r\n    357         \"\"\"\r\n    358         if import_plugins:\r\n--> 359             plugins.import_plugins()\r\n    360         return Predictor.from_archive(\r\n    361             load_archive(archive_path, cuda_device=cuda_device, overrides=overrides),\r\n\r\n/databricks/python/lib/python3.8/site-packages/allennlp/common/plugins.py in import_plugins()\r\n     85         try:\r\n     86             # For default plugins we recursively import everything.\r\n---> 87             import_module_and_submodules(module_name)\r\n     88             logger.info(\"Plugin %s available\", module_name)\r\n     89         except ModuleNotFoundError as e:\r\n\r\n/databricks/python/lib/python3.8/site-packages/allennlp/common/util.py in import_module_and_submodules(package_name)\r\n    354                 continue\r\n    355             subpackage = f\"{package_name}.{name}\"\r\n--> 356             import_module_and_submodules(subpackage)\r\n    357 \r\n    358 \r\n\r\n/databricks/python/lib/python3.8/site-packages/allennlp/common/util.py in import_module_and_submodules(package_name)\r\n    351             # Sometimes when you import third-party libraries that are on your path,\r\n    352             # `pkgutil.walk_packages` returns those too, so we need to skip them.\r\n--> 353             if path_string and module_finder.path != path_string:  # type: ignore[union-attr]\r\n    354                 continue\r\n    355             subpackage = f\"{package_name}.{name}\"\r\n\r\nAttributeError: 'zipimporter' object has no attribute 'path'\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- I am using Azure Databricks. The code works just fine when I use a single VM. But when I try to install the same model on a cluster, I get this error.\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:Azure Databricks, possibly Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:3.7.1\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp.predictors.predictor import Predictor\r\n\r\nmodel_url = 'https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz'\r\npredictor = Predictor.from_path(model_url)  # load the model\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5532/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5532/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5523", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5523/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5523/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5523/events", "html_url": "https://github.com/allenai/allennlp/issues/5523", "id": 1086411282, "node_id": "I_kwDOBXH8-M5AwVIS", "number": 5523, "title": "run test suites occur errors", "user": {"login": "idiomaticrefactoring", "id": 29055749, "node_id": "MDQ6VXNlcjI5MDU1NzQ5", "avatar_url": "https://avatars.githubusercontent.com/u/29055749?v=4", "gravatar_id": "", "url": "https://api.github.com/users/idiomaticrefactoring", "html_url": "https://github.com/idiomaticrefactoring", "followers_url": "https://api.github.com/users/idiomaticrefactoring/followers", "following_url": "https://api.github.com/users/idiomaticrefactoring/following{/other_user}", "gists_url": "https://api.github.com/users/idiomaticrefactoring/gists{/gist_id}", "starred_url": "https://api.github.com/users/idiomaticrefactoring/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/idiomaticrefactoring/subscriptions", "organizations_url": "https://api.github.com/users/idiomaticrefactoring/orgs", "repos_url": "https://api.github.com/users/idiomaticrefactoring/repos", "events_url": "https://api.github.com/users/idiomaticrefactoring/events{/privacy}", "received_events_url": "https://api.github.com/users/idiomaticrefactoring/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-12-22T03:22:00Z", "updated_at": "2021-12-23T21:51:16Z", "closed_at": "2021-12-23T21:51:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n**Hello, I want run existing test suites, so I run command as following:\r\npip3 install -e .\r\npip install -r dev-requirements.txt\r\npython3.7 -m pytest -v tests/nn/chu_liu_edmonds_test.py \r\n\r\nHowever, it seems the test case occur errors .**\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n==================================================================================== test session starts =====================================================================================\r\nplatform linux -- Python 3.7.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- /mnt/zejun/smp/data/python_star_2000repo/allennlp/venv_test_7/bin/python3.7\r\ncachedir: .pytest_cache\r\nrootdir: /mnt/zejun/smp/data/python_star_2000repo/allennlp, configfile: pytest.ini\r\nplugins: cov-3.0.0, mock-3.6.1\r\ncollected 0 items / 1 error                                                                                                                                                                  \r\n\r\n=========================================================================================== ERRORS ===========================================================================================\r\n_____________________________________________________________________ ERROR collecting tests/nn/chu_liu_edmonds_test.py ______________________________________________________________________\r\nvenv_test_7/lib/python3.7/site-packages/nltk/corpus/util.py:84: in __load\r\n    root = nltk.data.find(f\"{self.subdir}/{zip_name}\")\r\nvenv_test_7/lib/python3.7/site-packages/nltk/data.py:583: in find\r\n    raise LookupError(resource_not_found)\r\nE   LookupError: \r\nE   **********************************************************************\r\nE     Resource omw-1.4 not found.\r\nE     Please use the NLTK Downloader to obtain the resource:\r\nE   \r\nE     >>> import nltk\r\nE     >>> nltk.download('omw-1.4')\r\nE     \r\nE     For more information see: https://www.nltk.org/data.html\r\nE   \r\nE     Attempted to load corpora/omw-1.4.zip/omw-1.4/\r\nE   \r\nE     Searched in:\r\nE       - '/home/zejun/nltk_data'\r\nE       - '/mnt/zejun/smp/data/python_star_2000repo/allennlp/venv_test_7/nltk_data'\r\nE       - '/mnt/zejun/smp/data/python_star_2000repo/allennlp/venv_test_7/share/nltk_data'\r\nE       - '/mnt/zejun/smp/data/python_star_2000repo/allennlp/venv_test_7/lib/nltk_data'\r\nE       - '/usr/share/nltk_data'\r\nE       - '/usr/local/share/nltk_data'\r\nE       - '/usr/lib/nltk_data'\r\nE       - '/usr/local/lib/nltk_data'\r\nE   **********************************************************************\r\n\r\nDuring handling of the above exception, another exception occurred:\r\ntests/nn/chu_liu_edmonds_test.py:5: in <module>\r\n    from allennlp.common.testing import AllenNlpTestCase\r\nallennlp/common/testing/__init__.py:10: in <module>\r\n    from allennlp.common.testing.model_test_case import ModelTestCase\r\nallennlp/common/testing/model_test_case.py:11: in <module>\r\n    from allennlp.commands.train import train_model_from_file\r\nallennlp/commands/__init__.py:24: in <module>\r\n    from allennlp.commands.checklist import CheckList\r\nallennlp/commands/checklist.py:18: in <module>\r\n    from allennlp.confidence_checks.task_checklists.task_suite import TaskSuite\r\nallennlp/confidence_checks/task_checklists/__init__.py:1: in <module>\r\n    from allennlp.confidence_checks.task_checklists.task_suite import TaskSuite\r\nallennlp/confidence_checks/task_checklists/task_suite.py:9: in <module>\r\n    from checklist.perturb import Perturb\r\nvenv_test_7/lib/python3.7/site-packages/checklist/perturb.py:7: in <module>\r\n    from pattern.en import tenses\r\nvenv_test_7/lib/python3.7/site-packages/pattern/text/en/__init__.py:61: in <module>\r\n    from pattern.text.en.inflect import (\r\nvenv_test_7/lib/python3.7/site-packages/pattern/text/en/__init__.py:80: in <module>\r\n    from pattern.text.en import wordnet\r\nvenv_test_7/lib/python3.7/site-packages/pattern/text/en/wordnet/__init__.py:74: in <module>\r\n    VERSION = wn.get_version() or \"3.0\"\r\nvenv_test_7/lib/python3.7/site-packages/nltk/corpus/util.py:121: in __getattr__\r\n    self.__load()\r\nvenv_test_7/lib/python3.7/site-packages/nltk/corpus/util.py:89: in __load\r\n    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\r\nvenv_test_7/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py:1176: in __init__\r\n    self.provenances = self.omw_prov()\r\nvenv_test_7/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py:1285: in omw_prov\r\n    fileids = self._omw_reader.fileids()\r\nvenv_test_7/lib/python3.7/site-packages/nltk/corpus/util.py:121: in __getattr__\r\n    self.__load()\r\nvenv_test_7/lib/python3.7/site-packages/nltk/corpus/util.py:86: in __load\r\n    raise e\r\nvenv_test_7/lib/python3.7/site-packages/nltk/corpus/util.py:81: in __load\r\n    root = nltk.data.find(f\"{self.subdir}/{self.__name}\")\r\nvenv_test_7/lib/python3.7/site-packages/nltk/data.py:583: in find\r\n    raise LookupError(resource_not_found)\r\nE   LookupError: \r\nE   **********************************************************************\r\nE     Resource omw-1.4 not found.\r\nE     Please use the NLTK Downloader to obtain the resource:\r\nE   \r\nE     >>> import nltk\r\nE     >>> nltk.download('omw-1.4')\r\nE     \r\nE     For more information see: https://www.nltk.org/data.html\r\nE   \r\nE     Attempted to load corpora/omw-1.4\r\nE   \r\nE     Searched in:\r\nE       - '/home/zejun/nltk_data'\r\nE       - '/mnt/zejun/smp/data/python_star_2000repo/allennlp/venv_test_7/nltk_data'\r\nE       - '/mnt/zejun/smp/data/python_star_2000repo/allennlp/venv_test_7/share/nltk_data'\r\nE       - '/mnt/zejun/smp/data/python_star_2000repo/allennlp/venv_test_7/lib/nltk_data'\r\nE       - '/usr/share/nltk_data'\r\nE       - '/usr/local/share/nltk_data'\r\nE       - '/usr/lib/nltk_data'\r\nE       - '/usr/local/lib/nltk_data'\r\nE   **********************************************************************\r\n================================================================================== short test summary info ===================================================================================\r\nERROR tests/nn/chu_liu_edmonds_test.py - LookupError: \r\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\r\n====================================================================================== 1 error in 8.57s ======================================================================================\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\npip3 install -e .\r\npip install -r dev-requirements.txt\r\npython3.7 -m pytest -v tests/nn/chu_liu_edmonds_test.py \r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5523/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5523/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5521", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5521/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5521/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5521/events", "html_url": "https://github.com/allenai/allennlp/issues/5521", "id": 1085754783, "node_id": "I_kwDOBXH8-M5At02f", "number": 5521, "title": "Error occurs when importing checklist stuff with the latest `nltk`", "user": {"login": "himkt", "id": 5164000, "node_id": "MDQ6VXNlcjUxNjQwMDA=", "avatar_url": "https://avatars.githubusercontent.com/u/5164000?v=4", "gravatar_id": "", "url": "https://api.github.com/users/himkt", "html_url": "https://github.com/himkt", "followers_url": "https://api.github.com/users/himkt/followers", "following_url": "https://api.github.com/users/himkt/following{/other_user}", "gists_url": "https://api.github.com/users/himkt/gists{/gist_id}", "starred_url": "https://api.github.com/users/himkt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/himkt/subscriptions", "organizations_url": "https://api.github.com/users/himkt/orgs", "repos_url": "https://api.github.com/users/himkt/repos", "events_url": "https://api.github.com/users/himkt/events{/privacy}", "received_events_url": "https://api.github.com/users/himkt/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "02b8d1", "default": false, "description": ""}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2021-12-21T11:55:49Z", "updated_at": "2022-01-13T18:11:17Z", "closed_at": "2022-01-13T18:11:17Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "`import allennlp.commands` raises an error that fails to load `omw-1.4`.\r\nAfter executing `python -m nltk.downloader omw-1.4`, the problem does not happen anymore.\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n  - ~I checked it by running `pip install git+https://github.com/allenai/allennlp.git`~\r\n  - I'm sorry, the error doesn't occurs when running `git clone` and `pip install .`\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n/tmp/test-allennlp/venv/lib/python3.9/site-packages/allennlp/tango/__init__.py:17: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\r\n  warnings.warn(\r\nTraceback (most recent call last):\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/util.py\", line 84, in __load\r\n    root = nltk.data.find(f\"{self.subdir}/{zip_name}\")\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/data.py\", line 583, in find\r\n    raise LookupError(resource_not_found)\r\nLookupError:\r\n**********************************************************************\r\n  Resource omw-1.4 not found.\r\n  Please use the NLTK Downloader to obtain the resource:\r\n\r\n  >>> import nltk\r\n  >>> nltk.download('omw-1.4')\r\n\r\n  For more information see: https://www.nltk.org/data.html\r\n\r\n  Attempted to load corpora/omw-1.4.zip/omw-1.4/\r\n\r\n  Searched in:\r\n    - '/home/himkt/nltk_data'\r\n    - '/tmp/test-allennlp/venv/nltk_data'\r\n    - '/tmp/test-allennlp/venv/share/nltk_data'\r\n    - '/tmp/test-allennlp/venv/lib/nltk_data'\r\n    - '/usr/share/nltk_data'\r\n    - '/usr/local/share/nltk_data'\r\n    - '/usr/lib/nltk_data'\r\n    - '/usr/local/lib/nltk_data'\r\n**********************************************************************\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/allennlp/commands/__init__.py\", line 24, in <module>\r\n    from allennlp.commands.checklist import CheckList\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/allennlp/commands/checklist.py\", line 18, in <module>\r\n    from allennlp.confidence_checks.task_checklists.task_suite import TaskSuite\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/allennlp/confidence_checks/task_checklists/__init__.py\", line 1, in <module>\r\n    from allennlp.confidence_checks.task_checklists.task_suite import TaskSuite\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/allennlp/confidence_checks/task_checklists/task_suite.py\", line 9, in <module>\r\n    from checklist.perturb import Perturb\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/checklist/perturb.py\", line 7, in <module>\r\n    from pattern.en import tenses\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/pattern/text/en/__init__.py\", line 61, in <module>\r\n    from pattern.text.en.inflect import (\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/pattern/text/en/__init__.py\", line 80, in <module>\r\n    from pattern.text.en import wordnet\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/pattern/text/en/wordnet/__init__.py\", line 74, in <module>\r\n    VERSION = wn.get_version() or \"3.0\"\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/util.py\", line 121, in __getattr__\r\n    self.__load()\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/util.py\", line 89, in __load\r\n    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py\", line 1176, in __init__\r\n    self.provenances = self.omw_prov()\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py\", line 1285, in omw_prov\r\n    fileids = self._omw_reader.fileids()\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/util.py\", line 121, in __getattr__\r\n    self.__load()\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/util.py\", line 86, in __load\r\n    raise e\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/util.py\", line 81, in __load\r\n    root = nltk.data.find(f\"{self.subdir}/{self.__name}\")\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/data.py\", line 583, in find\r\n    raise LookupError(resource_not_found)\r\nLookupError:\r\n**********************************************************************\r\n  Resource omw-1.4 not found.\r\n  Please use the NLTK Downloader to obtain the resource:\r\n\r\n  >>> import nltk\r\n  >>> nltk.download('omw-1.4')\r\n\r\n  For more information see: https://www.nltk.org/data.html\r\n\r\n  Attempted to load corpora/omw-1.4\r\n\r\n  Searched in:\r\n    - '/home/himkt/nltk_data'\r\n    - '/tmp/test-allennlp/venv/nltk_data'\r\n    - '/tmp/test-allennlp/venv/share/nltk_data'\r\n    - '/tmp/test-allennlp/venv/lib/nltk_data'\r\n    - '/usr/share/nltk_data'\r\n    - '/usr/local/share/nltk_data'\r\n    - '/usr/lib/nltk_data'\r\n    - '/usr/local/lib/nltk_data'\r\n**********************************************************************\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n```\r\n> lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID: Ubuntu\r\nDescription:    Ubuntu 20.04.3 LTS\r\nRelease:        20.04\r\nCodename:       focal\r\n```\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.9.9\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp==3.8.1\r\naiosignal==1.2.0\r\nallennlp==2.8.0\r\nargon2-cffi==21.3.0\r\nargon2-cffi-bindings==21.2.0\r\nasync-timeout==4.0.2\r\nattrs==21.2.0\r\nbackcall==0.2.0\r\nbackports.csv==1.0.7\r\nbase58==2.1.1\r\nbeautifulsoup4==4.10.0\r\nbleach==4.1.0\r\nblis==0.7.5\r\nboto3==1.20.25\r\nbotocore==1.23.25\r\ncached-path==0.3.2\r\ncachetools==4.2.4\r\ncatalogue==2.0.6\r\ncertifi==2021.10.8\r\ncffi==1.15.0\r\nchardet==4.0.0\r\ncharset-normalizer==2.0.9\r\nchecklist==0.0.11\r\ncheroot==8.5.2\r\nCherryPy==18.6.1\r\nclick==8.0.3\r\nconfigparser==5.2.0\r\ncryptography==36.0.1\r\ncymem==2.0.6\r\ndatasets==1.16.1\r\ndebugpy==1.5.1\r\ndecorator==5.1.0\r\ndefusedxml==0.7.1\r\ndill==0.3.4\r\ndocker-pycreds==0.4.0\r\nentrypoints==0.3\r\nfairscale==0.4.0\r\nfeedparser==6.0.8\r\nfilelock==3.3.2\r\nfrozenlist==1.2.0\r\nfsspec==2021.11.1\r\nfuture==0.18.2\r\ngitdb==4.0.9\r\nGitPython==3.1.24\r\ngoogle-api-core==2.3.2\r\ngoogle-auth==2.3.3\r\ngoogle-cloud-core==2.2.1\r\ngoogle-cloud-storage==1.43.0\r\ngoogle-crc32c==1.3.0\r\ngoogle-resumable-media==2.1.0\r\ngoogleapis-common-protos==1.54.0\r\nh5py==3.6.0\r\nhuggingface-hub==0.1.2\r\nidna==3.3\r\niniconfig==1.1.1\r\nipykernel==6.6.0\r\nipython==7.30.1\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.5\r\niso-639==0.4.5\r\njaraco.classes==3.2.1\r\njaraco.collections==3.4.0\r\njaraco.functools==3.5.0\r\njaraco.text==3.6.0\r\njedi==0.18.1\r\nJinja2==3.0.3\r\njmespath==0.10.0\r\njoblib==1.1.0\r\njsonnet==0.17.0\r\njsonschema==4.3.2\r\njupyter==1.0.0\r\njupyter-client==7.1.0\r\njupyter-console==6.4.0\r\njupyter-core==4.9.1\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.2\r\nlmdb==1.2.1\r\nlxml==4.7.1\r\nMarkupSafe==2.0.1\r\nmatplotlib-inline==0.1.3\r\nmistune==0.8.4\r\nmore-itertools==8.12.0\r\nmultidict==5.2.0\r\nmultiprocess==0.70.12.2\r\nmunch==2.5.0\r\nmurmurhash==1.0.6\r\nnbclient==0.5.9\r\nnbconvert==6.3.0\r\nnbformat==5.1.3\r\nnest-asyncio==1.5.4\r\nnltk==3.6.6\r\nnotebook==6.4.6\r\nnumpy==1.21.5\r\noverrides==3.1.0\r\npackaging==21.3\r\npandas==1.3.5\r\npandocfilters==1.5.0\r\nparso==0.8.3\r\npathtools==0.1.2\r\npathy==0.6.1\r\npatternfork-nosql==3.6\r\npdfminer.six==20211012\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==8.4.0\r\npluggy==1.0.0\r\nportend==3.1.0\r\npreshed==3.0.6\r\nprometheus-client==0.12.0\r\npromise==2.3\r\nprompt-toolkit==3.0.24\r\nprotobuf==3.19.1\r\npsutil==5.8.0\r\nptyprocess==0.7.0\r\npy==1.11.0\r\npyarrow==6.0.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.21\r\npydantic==1.8.2\r\nPygments==2.10.0\r\npyparsing==3.0.6\r\npyrsistent==0.18.0\r\npytest==6.2.5\r\npython-dateutil==2.8.2\r\npython-docx==0.8.11\r\npytz==2021.3\r\nPyYAML==6.0\r\npyzmq==22.3.0\r\nqtconsole==5.2.2\r\nQtPy==1.11.3\r\nregex==2021.11.10\r\nrequests==2.26.0\r\nrsa==4.8\r\ns3transfer==0.5.0\r\nsacremoses==0.0.46\r\nscikit-learn==1.0.1\r\nscipy==1.7.3\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.5.1\r\nsgmllib3k==1.0.0\r\nshortuuid==1.0.8\r\nsix==1.16.0\r\nsmart-open==5.2.1\r\nsmmap==5.0.0\r\nsoupsieve==2.3.1\r\nspacy==3.1.4\r\nspacy-legacy==3.0.8\r\nsqlitedict==1.7.0\r\nsrsly==2.4.2\r\nsubprocess32==3.5.4\r\ntempora==4.1.2\r\ntensorboardX==2.4.1\r\ntermcolor==1.1.0\r\nterminado==0.12.1\r\ntestpath==0.5.0\r\nthinc==8.0.13\r\nthreadpoolctl==3.0.0\r\ntokenizers==0.10.3\r\ntoml==0.10.2\r\ntorch==1.10.1\r\ntorchvision==0.11.2\r\ntornado==6.1\r\ntqdm==4.62.3\r\ntraitlets==5.1.1\r\ntransformers==4.12.5\r\ntyper==0.4.0\r\ntyping_extensions==4.0.1\r\nurllib3==1.26.7\r\nwandb==0.12.9\r\nwasabi==0.9.0\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nwidgetsnbextension==3.5.2\r\nxxhash==2.0.2\r\nyarl==1.7.2\r\nyaspin==2.1.0\r\nzc.lockfile==2.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n> python3 --version\r\nPython 3.9.9\r\n2021-12-21 20:36:49 [/tmp/test-allennlp]\r\n> python3 -m venv venv\r\n2021-12-21 20:36:55 [/tmp/test-allennlp]\r\n> . venv/bin/activate\r\n(venv) 2021-12-21 20:36:56 [/tmp/test-allennlp]\r\n> pip install allennlp --quiet\r\n(venv) 2021-12-21 20:38:55 [/tmp/test-allennlp]\r\n> pip list | grep allennlp\r\nallennlp                 2.8.0\r\n(venv) 2021-12-21 20:40:47 [/tmp/test-allennlp]\r\n> pip list | grep nltk\r\nnltk                     3.6.6\r\n(venv) 2021-12-21 20:40:50 [/tmp/test-allennlp]\r\n> python -c 'import allennlp.commands'\r\n/tmp/test-allennlp/venv/lib/python3.9/site-packages/allennlp/tango/__init__.py:17: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\r\n  warnings.warn(\r\nTraceback (most recent call last):\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/util.py\", line 84, in __load\r\n    root = nltk.data.find(f\"{self.subdir}/{zip_name}\")\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/data.py\", line 583, in find\r\n    raise LookupError(resource_not_found)\r\nLookupError:\r\n**********************************************************************\r\n  Resource omw-1.4 not found.\r\n  Please use the NLTK Downloader to obtain the resource:\r\n\r\n  >>> import nltk\r\n  >>> nltk.download('omw-1.4')\r\n\r\n  For more information see: https://www.nltk.org/data.html\r\n\r\n  Attempted to load corpora/omw-1.4.zip/omw-1.4/\r\n\r\n  Searched in:\r\n    - '/home/himkt/nltk_data'\r\n    - '/tmp/test-allennlp/venv/nltk_data'\r\n    - '/tmp/test-allennlp/venv/share/nltk_data'\r\n    - '/tmp/test-allennlp/venv/lib/nltk_data'\r\n    - '/usr/share/nltk_data'\r\n    - '/usr/local/share/nltk_data'\r\n    - '/usr/lib/nltk_data'\r\n    - '/usr/local/lib/nltk_data'\r\n**********************************************************************\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/allennlp/commands/__init__.py\", line 24, in <module>\r\n    from allennlp.commands.checklist import CheckList\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/allennlp/commands/checklist.py\", line 18, in <module>\r\n    from allennlp.confidence_checks.task_checklists.task_suite import TaskSuite\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/allennlp/confidence_checks/task_checklists/__init__.py\", line 1, in <module>\r\n    from allennlp.confidence_checks.task_checklists.task_suite import TaskSuite\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/allennlp/confidence_checks/task_checklists/task_suite.py\", line 9, in <module>\r\n    from checklist.perturb import Perturb\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/checklist/perturb.py\", line 7, in <module>\r\n    from pattern.en import tenses\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/pattern/text/en/__init__.py\", line 61, in <module>\r\n    from pattern.text.en.inflect import (\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/pattern/text/en/__init__.py\", line 80, in <module>\r\n    from pattern.text.en import wordnet\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/pattern/text/en/wordnet/__init__.py\", line 74, in <module>\r\n    VERSION = wn.get_version() or \"3.0\"\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/util.py\", line 121, in __getattr__\r\n    self.__load()\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/util.py\", line 89, in __load\r\n    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py\", line 1176, in __init__\r\n    self.provenances = self.omw_prov()\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py\", line 1285, in omw_prov\r\n    fileids = self._omw_reader.fileids()\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/util.py\", line 121, in __getattr__\r\n    self.__load()\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/util.py\", line 86, in __load\r\n    raise e\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/corpus/util.py\", line 81, in __load\r\n    root = nltk.data.find(f\"{self.subdir}/{self.__name}\")\r\n  File \"/tmp/test-allennlp/venv/lib/python3.9/site-packages/nltk/data.py\", line 583, in find\r\n    raise LookupError(resource_not_found)\r\nLookupError:\r\n**********************************************************************\r\n  Resource omw-1.4 not found.\r\n  Please use the NLTK Downloader to obtain the resource:\r\n\r\n  >>> import nltk\r\n  >>> nltk.download('omw-1.4')\r\n\r\n  For more information see: https://www.nltk.org/data.html\r\n\r\n  Attempted to load corpora/omw-1.4\r\n\r\n  Searched in:\r\n    - '/home/himkt/nltk_data'\r\n    - '/tmp/test-allennlp/venv/nltk_data'\r\n    - '/tmp/test-allennlp/venv/share/nltk_data'\r\n    - '/tmp/test-allennlp/venv/lib/nltk_data'\r\n    - '/usr/share/nltk_data'\r\n    - '/usr/local/share/nltk_data'\r\n    - '/usr/lib/nltk_data'\r\n    - '/usr/local/lib/nltk_data'\r\n**********************************************************************\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5521/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5521/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5511", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5511/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5511/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5511/events", "html_url": "https://github.com/allenai/allennlp/issues/5511", "id": 1079132121, "node_id": "I_kwDOBXH8-M5AUj_Z", "number": 5511, "title": "CUDA Out of memory error after training has stopped", "user": {"login": "vikigenius", "id": 12724810, "node_id": "MDQ6VXNlcjEyNzI0ODEw", "avatar_url": "https://avatars.githubusercontent.com/u/12724810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vikigenius", "html_url": "https://github.com/vikigenius", "followers_url": "https://api.github.com/users/vikigenius/followers", "following_url": "https://api.github.com/users/vikigenius/following{/other_user}", "gists_url": "https://api.github.com/users/vikigenius/gists{/gist_id}", "starred_url": "https://api.github.com/users/vikigenius/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vikigenius/subscriptions", "organizations_url": "https://api.github.com/users/vikigenius/orgs", "repos_url": "https://api.github.com/users/vikigenius/repos", "events_url": "https://api.github.com/users/vikigenius/events{/privacy}", "received_events_url": "https://api.github.com/users/vikigenius/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2021-12-13T23:19:58Z", "updated_at": "2021-12-20T22:25:33Z", "closed_at": "2021-12-20T22:25:33Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nAdditional GPU memory is used even after training stops. This issue does not happen when the last epoch is also the best model so far.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n-- Process 3 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 59, in _wrap\r\n    fn(i, *args)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/allennlp/commands/train.py\", line 504, in _train_worker\r\n    metrics = train_loop.run()\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/allennlp/commands/train.py\", line 577, in run\r\n    return self.trainer.train()\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/allennlp/training/gradient_descent_trainer.py\", line 769, in train\r\n    metrics, epoch = self._try_train()\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/allennlp/training/gradient_descent_trainer.py\", line 956, in _try_train\r\n    self._load_model_state(self._best_model_filename)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/allennlp/training/gradient_descent_trainer.py\", line 968, in _load_model_state\r\n    self._ddp_wrapped_model.load_state_dict(torch.load(path))\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/torch/serialization.py\", line 607, in load\r\n    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/torch/serialization.py\", line 882, in _load\r\n    result = unpickler.load()\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/torch/serialization.py\", line 857, in persistent_load\r\n    load_tensor(data_type, size, key, _maybe_decode_ascii(location))\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/torch/serialization.py\", line 846, in load_tensor\r\n    loaded_storages[key] = restore_location(storage, location)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/torch/serialization.py\", line 175, in default_restore_location\r\n    result = fn(storage, location)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/torch/serialization.py\", line 157, in _cuda_deserialize\r\n    return obj.cuda(device)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/torch/_utils.py\", line 79, in _cuda\r\n    return new_type(self.size()).copy_(self, non_blocking)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.9/site-packages/torch/cuda/__init__.py\", line 606, in _lazy_new\r\n    return super(_CudaBase, cls).__new__(cls, *args, **kwargs)\r\nRuntimeError: CUDA error: out of memory\r\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\r\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.9.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp @ file:///home/void/.cache/pypoetry/artifacts/c3/d1/97/85daa5493c9bf3eb25c509bc3eb629985f82b89336bfcb5adcb76b78fe/aiohttp-3.8.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\naiosignal @ file:///home/void/.cache/pypoetry/artifacts/d3/d7/92/f7aa28b137b4b00e62270f58330cedde299917a71a3c00ee64913aa3c2/aiosignal-1.2.0-py3-none-any.whl\r\nalabaster @ file:///home/void/.cache/pypoetry/artifacts/48/57/b7/0e44080d4c6f80ece83e427f90368b376fdec42759b60c2c37a04da23b/alabaster-0.7.12-py2.py3-none-any.whl\r\nalembic @ file:///home/void/.cache/pypoetry/artifacts/a9/7f/76/cc692e51f952a683bbb802478dbcc64da55ae1365d161446cca6ce0809/alembic-1.7.5-py3-none-any.whl\r\nallennlp @ file:///home/void/.cache/pypoetry/artifacts/5f/bc/2c/31dfa2e9194c9081a89d19148cac449d570f5f104d71adce4b92505e29/allennlp-2.8.0-py3-none-any.whl\r\nallennlp-optuna @ file:///home/void/.cache/pypoetry/artifacts/5b/51/0e/8776f8115f6e5dd56c3b1a005c81c38696b961a98e5db932ee4ef8cb6f/allennlp_optuna-0.1.7-py3-none-any.whl\r\narger @ file:///home/void/.cache/pypoetry/artifacts/be/a9/97/92eedbef45f7661c903a6a82517d2d19b7b808717bee4ca85c941531b0/arger-1.4.2-py3-none-any.whl\r\nargon2-cffi @ file:///home/void/.cache/pypoetry/artifacts/e5/36/34/bf219434f7144f39ec847b03dc7626b6d79dd2ce22f0dd27be6a6f2656/argon2_cffi-21.3.0-py3-none-any.whl\r\nargon2-cffi-bindings @ file:///home/void/.cache/pypoetry/artifacts/dc/7d/af/6367bb3a6693241419d236ecccbc664f4efa6b8bdebb6a5594e1508633/argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nastor @ file:///home/void/.cache/pypoetry/artifacts/1f/03/36/982d1222edac5e8cb8ac6e0464249747fa800d4fb04728a99153ecfe4d/astor-0.8.1-py2.py3-none-any.whl\r\nasync-timeout @ file:///home/void/.cache/pypoetry/artifacts/4a/a8/7d/ffb2ac78e2c6ac4cbf6bbf5d29a0afb3cf7a1b3f18ffbb3a0adfe89d5d/async_timeout-4.0.1-py3-none-any.whl\r\nattrs @ file:///home/void/.cache/pypoetry/artifacts/6f/a9/ee/569c37f69a8c365ee41d2340aeac0214ee8c0086b8d8db43a21545204b/attrs-21.2.0-py2.py3-none-any.whl\r\nautopage @ file:///home/void/.cache/pypoetry/artifacts/73/11/fb/97c1c7b5e56a1b4a358f24e359119a21f7e5a2165ad9fc37738091d3ba/autopage-0.4.0-py3-none-any.whl\r\nautorepr @ file:///home/void/.cache/pypoetry/artifacts/79/b0/2c/559adfad5f45b74ef658fdab7bff52f955339a62d1aeae798f390f88d9/autorepr-0.3.0-py2.py3-none-any.whl\r\nBabel @ file:///home/void/.cache/pypoetry/artifacts/1e/28/b6/110e8fc8ccc0dafe21bbc521139d0d0674574f7daa6f6f90137bdb4759/Babel-2.9.1-py2.py3-none-any.whl\r\nbackcall @ file:///home/void/.cache/pypoetry/artifacts/43/8e/e8/4e598704edf6fb4a53d552ea511c04e9958dcf850897760e5387878b99/backcall-0.2.0-py2.py3-none-any.whl\r\nbackports.csv @ file:///home/void/.cache/pypoetry/artifacts/30/84/1a/81a42cff31ce7f0b7a86ab54e2cbcb610d96fa8b735d63bdb7251e91cb/backports.csv-1.0.7-py2.py3-none-any.whl\r\nbandit @ file:///home/void/.cache/pypoetry/artifacts/5a/52/5e/30a779fa19fdd8ac741622674d12f76ad48c8f76074fe83dfc2ea2d0af/bandit-1.7.1-py3-none-any.whl\r\nbase58 @ file:///home/void/.cache/pypoetry/artifacts/2e/53/33/a15f42f485704caf86395e9701bb3440206ec9bffc062d7a597f43518e/base58-2.1.1-py3-none-any.whl\r\nbeautifulsoup4 @ file:///home/void/.cache/pypoetry/artifacts/d4/3e/b2/b4df19cca3023c21eb4a289b88c132ac71a9517bddef2055fd38eadd39/beautifulsoup4-4.10.0-py3-none-any.whl\r\nbleach @ file:///home/void/.cache/pypoetry/artifacts/db/42/1e/1062d618eece64f515d716a5cb98eace54768d5af54a9273b1f554eaec/bleach-4.1.0-py2.py3-none-any.whl\r\nblis @ file:///home/void/.cache/pypoetry/artifacts/ed/19/db/9c4d35a6ae4d8bafd131c6e29638af4528680f853c54cbd074ec874162/blis-0.7.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nboto3 @ file:///home/void/.cache/pypoetry/artifacts/0a/57/02/42339b65f77c54b1c0d1f35c3d3c6c7a084c961afce3c50c56e080ab14/boto3-1.20.23-py3-none-any.whl\r\nbotocore @ file:///home/void/.cache/pypoetry/artifacts/b3/3d/aa/30d9a04e5a70bef8c817f173dc388ed4116621b0611b24df8026ffe0f8/botocore-1.23.23-py3-none-any.whl\r\ncached-path @ file:///home/void/.cache/pypoetry/artifacts/94/57/de/0f18078c0fcdba822b1236767fb6b51db6aac0d047b39fe790dfe94540/cached_path-0.3.2-py3-none-any.whl\r\ncachetools @ file:///home/void/.cache/pypoetry/artifacts/ab/92/05/de1deda089a4f18230cef3edfa7da0739da7e4482a5727422e9a5db078/cachetools-4.2.4-py3-none-any.whl\r\ncachy @ file:///home/void/.cache/pypoetry/artifacts/c0/ce/2b/be65c61ed593659749cff39804b346369e358f14f09151abe591f0c5ab/cachy-0.3.0-py2.py3-none-any.whl\r\ncatalogue @ file:///home/void/.cache/pypoetry/artifacts/7c/6a/8a/f666a0e711d9153f80a844329970fcf567da43df07fef3127356219777/catalogue-2.0.6-py3-none-any.whl\r\ncertifi==2021.10.8\r\ncffi @ file:///home/void/.cache/pypoetry/artifacts/0b/b7/48/30ff76ec327f0041e809dd9c35b741a68d6d8566a123e6dabda722536a/cffi-1.15.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\nchardet @ file:///home/void/.cache/pypoetry/artifacts/11/63/f9/797eda27963177a6b75a340f62aa194d462ea69e6b0dbb77a651fa2b62/chardet-4.0.0-py2.py3-none-any.whl\r\ncharset-normalizer @ file:///home/void/.cache/pypoetry/artifacts/9e/1a/c0/f7635922644ab43cdae873172296c99b00796f2e281669e0fb7516bf88/charset_normalizer-2.0.9-py3-none-any.whl\r\nchecklist @ file:///home/void/.cache/pypoetry/artifacts/04/84/f3/1324eec13577715f52121b3073ab37792c08483aae7faa7d22b7dd5e1d/checklist-0.0.11.tar.gz\r\ncheroot @ file:///home/void/.cache/pypoetry/artifacts/3c/cf/87/c9bb0e3b0d4c43affeb8f9714d5791b61c97750bc3a2ee35d276d425b5/cheroot-8.5.2-py2.py3-none-any.whl\r\nCherryPy @ file:///home/void/.cache/pypoetry/artifacts/dd/d5/0c/5289a45f52e9aa001f7b8c2b9c792377e79ad572bc759f1a692d160818/CherryPy-18.6.1-py2.py3-none-any.whl\r\nclick @ file:///home/void/.cache/pypoetry/artifacts/34/4d/5b/2e936191a48c61e37319c157af7e3c0dbdde9b80ccdd04b7940f99c5db/click-8.0.3-py3-none-any.whl\r\ncliff @ file:///home/void/.cache/pypoetry/artifacts/b8/19/16/acf36d1f3ec0fb46cde9e3700a44f14796366bd39542c9adedeefebbca/cliff-3.10.0-py3-none-any.whl\r\ncmaes @ file:///home/void/.cache/pypoetry/artifacts/25/75/d0/dd27383149a81e2f7be6fc9ac708fa8b06ea14d96b18d645f8f3cf85c5/cmaes-0.8.2-py3-none-any.whl\r\ncmd2 @ file:///home/void/.cache/pypoetry/artifacts/7a/79/21/3ecc24e0d01c3e69c8d67262be1acf2db7425452f0f84972f9044802e8/cmd2-2.3.3-py3-none-any.whl\r\ncolorlog @ file:///home/void/.cache/pypoetry/artifacts/44/b1/86/5279793ca939562b56cd91947a520f212e585ad0c4252cb01c0ec59dd8/colorlog-6.6.0-py2.py3-none-any.whl\r\nconfigparser @ file:///home/void/.cache/pypoetry/artifacts/5d/f4/e0/46a13abe32ddb24eefbec544131a7050f0951e8023028eefa49aa1e17b/configparser-5.2.0-py3-none-any.whl\r\nConfigUpdater @ file:///home/void/.cache/pypoetry/artifacts/ac/04/8d/bed8325152ace634ebb44caa22d0eece05748e6a11d69c5ca90bd23bc4/ConfigUpdater-3.0.1-py2.py3-none-any.whl\r\ncoverage @ file:///home/void/.cache/pypoetry/artifacts/80/36/13/bcbeede3f084e1a60abc76b394f326ef569436d4ed68aa0f8ccf5505b2/coverage-6.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\ncryptography @ file:///home/void/.cache/pypoetry/artifacts/3c/18/cb/9631c1afaf817699720296a54b598cba8e50ddba8b42e89c91f593f416/cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl\r\ncymem @ file:///home/void/.cache/pypoetry/artifacts/f1/e5/0d/418ca076950a2a7841dd4199fe239ce71934f6eed6448b117560c8b594/cymem-2.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\ndarglint @ file:///home/void/.cache/pypoetry/artifacts/2d/47/f9/e4df12fe8185cdb64f2f77c23d349693941e09d8d5374c68454fb12e4f/darglint-1.8.1-py3-none-any.whl\r\ndatasets @ file:///home/void/.cache/pypoetry/artifacts/34/03/25/6bfe1bccb74e348f99c4ec6ecd4c7d26bc49685ccf029f9f57a32e8367/datasets-1.16.1-py3-none-any.whl\r\ndebugpy @ file:///home/void/.cache/pypoetry/artifacts/7b/52/41/857f16c34fdc6e0393b19a8ceed45255a606010a8753e9c594132e53f2/debugpy-1.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\ndecorator @ file:///home/void/.cache/pypoetry/artifacts/c5/6b/f9/35190d429d462647b42d2847ab554759b98334d6479bc354c719947ce6/decorator-5.1.0-py3-none-any.whl\r\ndefusedxml @ file:///home/void/.cache/pypoetry/artifacts/2b/69/07/7b13f7eaf3a4d7af737dcebe24d3d17b1c2a2f457fbddf746f5642bc43/defusedxml-0.7.1-py2.py3-none-any.whl\r\ndictdiffer @ file:///home/void/.cache/pypoetry/artifacts/bc/85/a4/4043bd24ee0498bfa674ee88c3b151fb29f0946a2b17b0f3e5f02c906b/dictdiffer-0.9.0-py2.py3-none-any.whl\r\ndill @ file:///home/void/.cache/pypoetry/artifacts/26/56/9e/73963d2285e6c700801f185e8c1d28f1f971c09aaa411cec9b799a5fca/dill-0.3.4-py2.py3-none-any.whl\r\ndoc8 @ file:///home/void/.cache/pypoetry/artifacts/02/8c/ea/ee72e46c18bb92524f64422cb67e575cca213c43a4c48411b1bac48dd3/doc8-0.10.1-py3-none-any.whl\r\ndocker-pycreds @ file:///home/void/.cache/pypoetry/artifacts/9b/0b/be/891931da9caf5e55102337a635d3a7eeeb92c93b4bd39c24d0810f1f25/docker_pycreds-0.4.0-py2.py3-none-any.whl\r\ndocutils @ file:///home/void/.cache/pypoetry/artifacts/43/28/92/79000933ad30371dc938d9b368a9000e20ac0bb467a716c19ef1fbd3c7/docutils-0.17.1-py2.py3-none-any.whl\r\ndparse @ file:///home/void/.cache/pypoetry/artifacts/0e/d3/3f/27b08502c8c8da888ca1b2701c4f1d91b6777be03197cc2566b65eb3dd/dparse-0.5.1-py3-none-any.whl\r\nentrypoints @ file:///home/void/.cache/pypoetry/artifacts/63/c1/af/bbfdd91bcb544e62ac8f1567ef23c243cb188d1a9cb933532999c9bbb0/entrypoints-0.3-py2.py3-none-any.whl\r\neradicate @ file:///home/void/.cache/pypoetry/artifacts/12/ce/ac/197035fe6d51568abb7ea160f5ad416d2164a2010005e8356b8229e550/eradicate-2.0.0.tar.gz\r\nfairscale @ file:///home/void/.cache/pypoetry/artifacts/af/4f/57/87d33c2f59c3d0bbc847cb9880c3b1504f03ced8353fd70924a1ebb6c4/fairscale-0.4.0.tar.gz\r\nfeedparser @ file:///home/void/.cache/pypoetry/artifacts/d1/81/87/0f3c1c0b02176b2bf05af85261d8ce7522e4d241e5d9f7b3f0ec4f2a10/feedparser-6.0.8-py3-none-any.whl\r\nfilelock @ file:///home/void/.cache/pypoetry/artifacts/2b/5e/92/0d4f081b9ca0f6e1a3a88db44eb2e55c0c3d723288fe74e32c41235525/filelock-3.3.2-py3-none-any.whl\r\nflake8 @ file:///home/void/.cache/pypoetry/artifacts/3f/57/d5/11722093c13092cc3bfc3dd7c88aef6f8e4d5ac97cfe5fd054d5aba412/flake8-3.9.2-py2.py3-none-any.whl\r\nflake8-bandit @ file:///home/void/.cache/pypoetry/artifacts/7e/e4/46/e15782d941f9cde39b64ca5b636180f47573f2b2c9315be56b55152f17/flake8_bandit-2.1.2.tar.gz\r\nflake8-broken-line @ file:///home/void/.cache/pypoetry/artifacts/51/ea/87/37348b281b73d7df44fc46b09c0430e2984e991df11998e2e9bb459fce/flake8_broken_line-0.3.0-py3-none-any.whl\r\nflake8-bugbear @ file:///home/void/.cache/pypoetry/artifacts/93/54/65/c5a4be2d8c60c8f88ee3122e7798d259db9f00c76b0ae20626b2fc8388/flake8_bugbear-21.11.29-py36.py37.py38-none-any.whl\r\nflake8-commas @ file:///home/void/.cache/pypoetry/artifacts/32/06/3d/62f07a797bd4a6d9f15ead0b6306a47bd0650ca9b3e20aa08d4ee2c23d/flake8_commas-2.1.0-py2.py3-none-any.whl\r\nflake8-comprehensions @ file:///home/void/.cache/pypoetry/artifacts/69/82/2b/b41b89274a557fa065257c074e1bff9ddb1bf7e97ca7831345247be00a/flake8_comprehensions-3.7.0-py3-none-any.whl\r\nflake8-debugger @ file:///home/void/.cache/pypoetry/artifacts/66/04/47/7bef98a8d237eb17cbfbcb803343be1c79e2c0674ceba163717b6c8e1b/flake8_debugger-4.0.0-py3-none-any.whl\r\nflake8-docstrings @ file:///home/void/.cache/pypoetry/artifacts/e0/85/e9/6b482a11d48cf26e1170d9f5bf0b044a5a6c9b816ffe70945e90fc3e56/flake8_docstrings-1.6.0-py2.py3-none-any.whl\r\nflake8-eradicate @ file:///home/void/.cache/pypoetry/artifacts/94/a4/1b/56cd39944d5d4d2639e80929837e7fc3b2ff432e095fd7a4d528c56090/flake8_eradicate-1.2.0-py3-none-any.whl\r\nflake8-isort @ file:///home/void/.cache/pypoetry/artifacts/73/53/0f/7e71fed3a8631dfabd048e16a84f9fb8e15c8c9a381bda2a444bf42961/flake8_isort-4.1.1-py3-none-any.whl\r\nflake8-plugin-utils @ file:///home/void/.cache/pypoetry/artifacts/d1/c5/cd/002f81a0e6fe87b5dc718a0f7381e43f0814e72acccd04d84899cb342b/flake8_plugin_utils-1.3.2-py3-none-any.whl\r\nflake8-polyfill @ file:///home/void/.cache/pypoetry/artifacts/28/17/cc/952c11cd5ffb2608137557f928dc4f9365b4dbe1e2a6015eeea78583ac/flake8_polyfill-1.0.2-py2.py3-none-any.whl\r\nflake8-pytest-style @ file:///home/void/.cache/pypoetry/artifacts/06/f5/ba/9e9e06bdcc5972b1eb2a190e39d1607b314ef79bae22e26e243725f37b/flake8_pytest_style-1.5.1-py3-none-any.whl\r\nflake8-quotes @ file:///home/void/.cache/pypoetry/artifacts/76/04/0d/e3326c63986618bbd2e54c3211274f66a0bfae21c700e3e67ed14640cd/flake8-quotes-3.3.1.tar.gz\r\nflake8-rst-docstrings @ file:///home/void/.cache/pypoetry/artifacts/07/75/20/16ffb132e46114df2fbe48fe2f50254b3f8ea6016371f04addc6738f41/flake8_rst_docstrings-0.2.5-py3-none-any.whl\r\nflake8-string-format @ file:///home/void/.cache/pypoetry/artifacts/24/89/bb/7ce8e216f8c7289aa8a2ad4c44f30f87af6c7cdaf5d510110d566d66ec/flake8_string_format-0.3.0-py2.py3-none-any.whl\r\nfrozenlist @ file:///home/void/.cache/pypoetry/artifacts/16/82/59/e9de178960fa722dabaa376316661aeedaca1bce820657f3c841fc51ae/frozenlist-1.2.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\nfsspec @ file:///home/void/.cache/pypoetry/artifacts/21/c5/18/c49ba5010477a09fddd7a039e5d6496310652a5637ced473b5b1e7331d/fsspec-2021.11.1-py3-none-any.whl\r\nfuture @ file:///home/void/.cache/pypoetry/artifacts/f8/58/55/86be1f567b212fdd98854d12815964a49db8fb1bcff725018e5f95c61d/future-0.18.2.tar.gz\r\ngitdb @ file:///home/void/.cache/pypoetry/artifacts/90/22/b2/13e35fcefe45f6779d7507377070865acf263775bda5c08fff422c1a4d/gitdb-4.0.9-py3-none-any.whl\r\nGitPython @ file:///home/void/.cache/pypoetry/artifacts/a5/0c/54/252d7dfe30f738045d07a47072bf784c68b68cce6d4600869cf335c1b2/GitPython-3.1.24-py3-none-any.whl\r\ngoogle-api-core @ file:///home/void/.cache/pypoetry/artifacts/2c/84/57/bd52ce51ad2bacdcef1c0308c0b64c38cc33219fa8f5342003c9594e40/google_api_core-2.3.0-py2.py3-none-any.whl\r\ngoogle-auth @ file:///home/void/.cache/pypoetry/artifacts/b3/ff/ed/2b0fd60d6a2ca3cd399676776f0c09264d0e94f1667269ecd96d136ff8/google_auth-2.3.3-py2.py3-none-any.whl\r\ngoogle-cloud-core @ file:///home/void/.cache/pypoetry/artifacts/77/e4/3d/ce8ea415961c50b94280469610815b8d70c8ba17f6bbacb65dbf84ebee/google_cloud_core-2.2.1-py2.py3-none-any.whl\r\ngoogle-cloud-storage @ file:///home/void/.cache/pypoetry/artifacts/b8/b9/58/eafb345088c65da05e0224b0186ad9a2a543023de0ab7e775b901ffe04/google_cloud_storage-1.43.0-py2.py3-none-any.whl\r\ngoogle-crc32c @ file:///home/void/.cache/pypoetry/artifacts/dc/73/5d/3e90ed7e68039176e9833fa7936e473a5542d1c38f19a3d63e42ef3e0a/google_crc32c-1.3.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\ngoogle-resumable-media @ file:///home/void/.cache/pypoetry/artifacts/ee/56/cd/4225643d5f5931b0f867ee44e7dccdd99315ce4c372ba315f3387c51a6/google_resumable_media-2.1.0-py2.py3-none-any.whl\r\ngoogleapis-common-protos @ file:///home/void/.cache/pypoetry/artifacts/77/7b/91/7cb1de6c5653a728a51c1d6c251dc38468c5b2e597067a35eed2285043/googleapis_common_protos-1.54.0-py2.py3-none-any.whl\r\ngreenlet @ file:///home/void/.cache/pypoetry/artifacts/50/37/3a/8b9fdf0fe03f0f52d1bb7c3505cdec8e2b0d72b9fedf093b84332bf97c/greenlet-1.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nh5py @ file:///home/void/.cache/pypoetry/artifacts/f1/de/3b/b6b056d985b3b06bfcbb42eaa59871c2c47aae1687e406be20e01d1541/h5py-3.6.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\nhuggingface-hub @ file:///home/void/.cache/pypoetry/artifacts/9e/bf/cf/655508ef1a6ac197efc182642122d99d0bbd6b68f63278cfff0bda75f7/huggingface_hub-0.1.2-py3-none-any.whl\r\nidentify @ file:///home/void/.cache/pypoetry/artifacts/ae/f6/e7/902cc86fc3e112d585e0fecc9cf81d49590a3d0cfaa0f46f382f8ad93b/identify-2.4.0-py2.py3-none-any.whl\r\nidna @ file:///home/void/.cache/pypoetry/artifacts/d5/04/80/9c17fd3240a37d12ff2ef042b0306aeb1abd2d8b95f150fd60be938352/idna-3.3-py3-none-any.whl\r\nimagesize @ file:///home/void/.cache/pypoetry/artifacts/96/5c/68/c505397f41dd445fe3305ed42a0c203fe0f36fee2cbb522ef564d90d71/imagesize-1.3.0-py2.py3-none-any.whl\r\nimportlib-metadata @ file:///home/void/.cache/pypoetry/artifacts/53/7a/9a/4d94d104305a079e224206038434d261e1d9cc1beb771d02a0715d5e65/importlib_metadata-4.8.2-py3-none-any.whl\r\niniconfig @ file:///home/void/.cache/pypoetry/artifacts/fa/b0/c6/10cfac68c9e6de9d2a1678366ca89fd9292b362c1760dbe758e41691cb/iniconfig-1.1.1-py2.py3-none-any.whl\r\nipykernel @ file:///home/void/.cache/pypoetry/artifacts/89/23/5d/c45e6bbf8fe53de475787afcf084ce795f90b515764c40736e0f7ad352/ipykernel-6.6.0-py3-none-any.whl\r\nipython @ file:///home/void/.cache/pypoetry/artifacts/e0/59/72/4d9bd2e1728ce74ef79b7a4d42048fa75076bb9e276ff9f0378a2d4e3c/ipython-7.30.1-py3-none-any.whl\r\nipython-genutils @ file:///home/void/.cache/pypoetry/artifacts/b4/31/01/6f96480580d1674cab0b5e26dc9fca7bbdf7a2fd5811a7807a92436268/ipython_genutils-0.2.0-py2.py3-none-any.whl\r\nipywidgets @ file:///home/void/.cache/pypoetry/artifacts/fc/29/4b/f750c0f70ce7f9529dc7dcae670c7a69248e56cec4a62e16cdf4febd70/ipywidgets-7.6.5-py2.py3-none-any.whl\r\niso-639 @ file:///home/void/.cache/pypoetry/artifacts/f0/a6/d6/17ede193e09cf4ac45d787cbef2e1c78ff7dff5a58775728212204bbd0/iso-639-0.4.5.tar.gz\r\nisort @ file:///home/void/.cache/pypoetry/artifacts/9d/c0/d5/617ee6ec6b065b9a3c8c3f7a0b06604f1a47738904535923554e135a7d/isort-5.10.1-py3-none-any.whl\r\njaraco.classes @ file:///home/void/.cache/pypoetry/artifacts/d0/3c/d2/f157bfb781b294c3d68a29e898ab39327bc2397eea1b42cf8afdfda14b/jaraco.classes-3.2.1-py3-none-any.whl\r\njaraco.collections @ file:///home/void/.cache/pypoetry/artifacts/b5/37/dc/9c36b359f5ee40235f16be580710ca07f20d5f03be3d28a10df354e707/jaraco.collections-3.4.0-py3-none-any.whl\r\njaraco.functools @ file:///home/void/.cache/pypoetry/artifacts/77/50/ae/8893dee5640d369f64a95c45a9e7d2b70892e34051958e9bb44a0cd881/jaraco.functools-3.4.0-py3-none-any.whl\r\njaraco.text @ file:///home/void/.cache/pypoetry/artifacts/3b/b4/df/e40175a7b285d6abc4be0e5301cbcd2f73a40decd507c3b2f0d8a236c7/jaraco.text-3.6.0-py3-none-any.whl\r\njedi @ file:///home/void/.cache/pypoetry/artifacts/c0/16/7b/b208472f00204d5aaeb0895fcde8e681c56c250bdf8d106fa76cdf7b30/jedi-0.18.1-py2.py3-none-any.whl\r\nJinja2 @ file:///home/void/.cache/pypoetry/artifacts/3b/12/80/ed05a8559d6ad1e85324dbcebfe790670d339c674fb15c419b29aae138/Jinja2-3.0.3-py3-none-any.whl\r\njmespath @ file:///home/void/.cache/pypoetry/artifacts/2c/f0/52/b0ba93d941bd49c8719dee7ca27d2096bf96e17948667388c3ee2ac8f8/jmespath-0.10.0-py2.py3-none-any.whl\r\njoblib @ file:///home/void/.cache/pypoetry/artifacts/a6/ca/34/f3a58b34616787c399095242ae8633fc32e061f8f76debd987dcecb325/joblib-1.1.0-py2.py3-none-any.whl\r\njsonnet @ file:///home/void/.cache/pypoetry/artifacts/60/4e/2d/acde747a02049d38e6dbda9dc3fbf64f03bf2e14c8e9ad04f07edcc66b/jsonnet-0.17.0.tar.gz\r\njsonschema @ file:///home/void/.cache/pypoetry/artifacts/ac/85/79/ccb562dde487c36a54f9c9e0872b5991960e317d7286c714723b7d399d/jsonschema-4.2.1-py3-none-any.whl\r\njupyter @ file:///home/void/.cache/pypoetry/artifacts/bb/e8/12/09df1332820a1126a780ab09cec78d2f50457f79bcd0cb2fbb07b19ef4/jupyter-1.0.0-py2.py3-none-any.whl\r\njupyter-client @ file:///home/void/.cache/pypoetry/artifacts/27/6c/bc/333a7cf743ca6eaba129fbc32cbd844b16a60d1a00d4837ea6a83d953c/jupyter_client-7.1.0-py3-none-any.whl\r\njupyter-console @ file:///home/void/.cache/pypoetry/artifacts/4b/2f/b8/119f975fb811a5e911beacc7a1bb8f8e1154254fb33204e753131e7aca/jupyter_console-6.4.0-py3-none-any.whl\r\njupyter-core @ file:///home/void/.cache/pypoetry/artifacts/94/16/ab/109e77a494c40a8da71a914e4c4fced4f49ccdc3ba8dc603c10c12d01b/jupyter_core-4.9.1-py3-none-any.whl\r\njupyterlab-pygments @ file:///home/void/.cache/pypoetry/artifacts/de/ef/fc/5883436de4b7865f082f7cba0e0e0ff5fbf229fe55d6e7d5431a6080f4/jupyterlab_pygments-0.1.2-py2.py3-none-any.whl\r\njupyterlab-widgets @ file:///home/void/.cache/pypoetry/artifacts/b0/2b/0f/f7f65b7f0839db0577f58ba1135a0b2592c80c8c44cfe0feade7ffea95/jupyterlab_widgets-1.0.2-py3-none-any.whl\r\nlmdb @ file:///home/void/.cache/pypoetry/artifacts/8c/76/54/b721202dccac74078c06fb8bb746bc85c679ef6ed6488ff62e97f597c5/lmdb-1.2.1-cp39-cp39-manylinux2010_x86_64.whl\r\nloguru @ file:///home/void/.cache/pypoetry/artifacts/86/46/fb/57abc2a88da92cb957a6f2c96bd3e58662eede7ebc1adce938a5ea46c4/loguru-0.5.3-py3-none-any.whl\r\nlxml @ file:///home/void/.cache/pypoetry/artifacts/71/9f/af/bb6db64668ef6754d242c72616cbd050d11016729520a8de21ecf6b12b/lxml-4.6.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl\r\nm2r2 @ file:///home/void/.cache/pypoetry/artifacts/13/22/0c/6840c0a42d0edbca824d90ebfdf23e3514d686ab1df51c393580ff1ca2/m2r2-0.3.2-py3-none-any.whl\r\nMako @ file:///home/void/.cache/pypoetry/artifacts/f5/35/12/a1a9bd3bdefed47c1b61fb976364f50a2fb431b0d8cc52001a44920780/Mako-1.1.6-py2.py3-none-any.whl\r\nMarkupSafe @ file:///home/void/.cache/pypoetry/artifacts/8b/03/f1/977f12728ea53158567728db9f624a06196c1eadef033ecd621df81b47/MarkupSafe-2.0.1-cp39-cp39-manylinux2010_x86_64.whl\r\nmarshmallow @ file:///home/void/.cache/pypoetry/artifacts/7e/41/f1/81d9a89f25ac2e4c2bf3c19eb031d7f3294c006480818b5d32bd3e9c17/marshmallow-3.14.1-py3-none-any.whl\r\nmarshmallow-polyfield @ file:///home/void/.cache/pypoetry/artifacts/15/54/1a/bf7b323a7e9bef7044335503b044f792374a95673e74fcf13d80690a10/marshmallow_polyfield-5.10-py3-none-any.whl\r\nmatplotlib-inline @ file:///home/void/.cache/pypoetry/artifacts/b5/de/c6/6384d0999287fcdc9e88d38f7951106dcb7ffac7c4e8c0d0c665e12cac/matplotlib_inline-0.1.3-py3-none-any.whl\r\nmccabe @ file:///home/void/.cache/pypoetry/artifacts/96/5e/5f/21ae5296697ca7f94de4da6e21d4936d74029c352a35202e4c339a4253/mccabe-0.6.1-py2.py3-none-any.whl\r\nmistune @ file:///home/void/.cache/pypoetry/artifacts/33/31/4c/2d69dc65d06d1c8f8b00b8e995e24bae97fce2e1f8ec5d8d2d98e852da/mistune-0.8.4-py2.py3-none-any.whl\r\nmkl-fft==1.3.1\r\nmkl-random @ file:///tmp/build/80754af9/mkl_random_1626186066731/work\r\nmkl-service==2.4.0\r\nmore-itertools @ file:///home/void/.cache/pypoetry/artifacts/a6/67/cb/fbf4fb4bbfedae39080e351b12ca64287d47c839769eeaf91434f3274c/more_itertools-8.12.0-py3-none-any.whl\r\nmultidict @ file:///home/void/.cache/pypoetry/artifacts/22/0a/79/83ddc41690ddab080e4124552f4a06bef7689df7f71ff8d022fd183a3c/multidict-5.2.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\nmultiprocess @ file:///home/void/.cache/pypoetry/artifacts/5d/fb/ce/029cafd015834319024c43f708d975b006d115de466309cb8f4d8c1353/multiprocess-0.70.12.2-py39-none-any.whl\r\nmunch @ file:///home/void/.cache/pypoetry/artifacts/c3/f9/98/c46b861b1fe10f4d4fecd0ed8752a968be33d2c7e698b70589015aa0b2/munch-2.5.0-py2.py3-none-any.whl\r\nmurmurhash @ file:///home/void/.cache/pypoetry/artifacts/c5/62/3e/e9b9045eda9a62bac496552aaab7dca42fa7ed5eb8ad1e2e47334f2e7b/murmurhash-1.0.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nmypy @ file:///home/void/.cache/pypoetry/artifacts/36/49/09/f6ff69bf72a43d56fd882450780491cf84523aa3cb39b1d0e3f2c6c9a4/mypy-0.910-cp39-cp39-manylinux2010_x86_64.whl\r\nmypy-extensions @ file:///home/void/.cache/pypoetry/artifacts/92/45/bf/1807ce854ff668d92602207a37bfa9316def2a3f257bd03c4c5be4bc9b/mypy_extensions-0.4.3-py2.py3-none-any.whl\r\nnbclient @ file:///home/void/.cache/pypoetry/artifacts/4f/7f/d9/a2258a0ec621b96205a9c5d1522d2c1a16f1e08360af4938d6af875ccb/nbclient-0.5.9-py3-none-any.whl\r\nnbconvert @ file:///home/void/.cache/pypoetry/artifacts/0c/6a/ef/958991527ceb81a24b5211a099566d3ff16370b77496246e48525635a4/nbconvert-6.3.0-py3-none-any.whl\r\nnbformat @ file:///home/void/.cache/pypoetry/artifacts/36/a7/e7/e1a0c1c54f6151e23afd51bc71e3f6e0b24a96dd1e693b92dd9a4e4ab3/nbformat-5.1.3-py3-none-any.whl\r\nnest-asyncio @ file:///home/void/.cache/pypoetry/artifacts/b3/29/3c/b5aaddd006ebba37d2ae62d54ebf0e5a536b927e00b2e3a7b034b82e4a/nest_asyncio-1.5.4-py3-none-any.whl\r\nnitpick @ file:///home/void/.cache/pypoetry/artifacts/d1/78/f1/f1b50c86f3a30423aa445ff3b36353427817a99ce9c4c005f96ab3e2e7/nitpick-0.29.0-py3-none-any.whl\r\nnltk @ file:///home/void/.cache/pypoetry/artifacts/da/4b/7c/7cdcd55f26e3f858a1fa5f755b799911525ed98ca5cae6385001dfa07c/nltk-3.6.5-py3-none-any.whl\r\nnotebook @ file:///home/void/.cache/pypoetry/artifacts/1a/6a/22/3e21fed164be61b5708342540da0b106f4e490683849fe458a5632d50d/notebook-6.4.6-py3-none-any.whl\r\nnumpy @ file:///home/void/.cache/pypoetry/artifacts/35/1c/d2/841d67d0d5cb5184003bb5c34e40a0bcf166dda67c86bef5528cfa003a/numpy-1.21.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\nolefile @ file:///Users/ktietz/demo/mc3/conda-bld/olefile_1629805411829/work\r\noptuna @ file:///home/void/.cache/pypoetry/artifacts/a5/9a/c9/62c0937c6a185daa56f35d881db7ee99d097ee07c462a4b536d689759b/optuna-2.10.0-py3-none-any.whl\r\noverrides @ file:///home/void/.cache/pypoetry/artifacts/24/45/16/62e842b5cdff34f5106ee676232cbcc7d7a1333e4900d111bca737b13a/overrides-3.1.0.tar.gz\r\npackaging @ file:///home/void/.cache/pypoetry/artifacts/47/3f/ce/b240169f7d8bef1ff24a0269b709721ce86543c2ec25e0b6adb2c2d7ac/packaging-21.3-py3-none-any.whl\r\npandas @ file:///home/void/.cache/pypoetry/artifacts/09/8b/ad/dea1bcb23c34aa56f16ddbf322155f5e0a2cb73a12e4ab0a51cdc35711/pandas-1.3.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\npandocfilters @ file:///home/void/.cache/pypoetry/artifacts/31/93/b3/c3f289a2e857d460f34581e351cfe3ac509300d47c487f135c96e39349/pandocfilters-1.5.0-py2.py3-none-any.whl\r\nparso @ file:///home/void/.cache/pypoetry/artifacts/4e/d3/c5/d91e200388f1ce44b74484eb39fbfd0797eb236741d3672a7d728668b2/parso-0.8.3-py2.py3-none-any.whl\r\npastel @ file:///home/void/.cache/pypoetry/artifacts/da/84/f3/3e4d8b15eabeba62960ed9d3ccc1e30b7ae5f1b93e6c28d291c67eaf93/pastel-0.2.1-py2.py3-none-any.whl\r\npathtools @ file:///home/void/.cache/pypoetry/artifacts/ce/ff/c7/31da76336d55d51d979a50868616c867c7b2ea6f2d2084b8c744726ae7/pathtools-0.1.2.tar.gz\r\npathy @ file:///home/void/.cache/pypoetry/artifacts/50/12/78/e6a2a43271455193874ba977034f2eb9ce0c4993ce86418a8903962049/pathy-0.6.1-py3-none-any.whl\r\npatternfork-nosql @ file:///home/void/.cache/pypoetry/artifacts/fa/53/d7/a04c2b1cd20312460da3f82ca634ac259fc581089956ed73763c0757cc/patternfork_nosql-3.6.tar.gz\r\npbr @ file:///home/void/.cache/pypoetry/artifacts/ae/21/53/3fee9e8edcd01b131a623fffcfef07c401beb748a2bd52a8e3fd7d12eb/pbr-5.8.0-py2.py3-none-any.whl\r\npdfminer.six @ file:///home/void/.cache/pypoetry/artifacts/cb/48/9a/333cadec1385a8846110abec74e0e0d3a75e5fc706ec6c9746bc1cbf0a/pdfminer.six-20211012-py3-none-any.whl\r\npep8-naming @ file:///home/void/.cache/pypoetry/artifacts/a4/93/c7/a3b9b8b4aef682b4caa67015d897aff3d064860a460124ad8a23b6f45f/pep8_naming-0.11.1-py2.py3-none-any.whl\r\npexpect @ file:///home/void/.cache/pypoetry/artifacts/5c/c2/43/b54fe59cab7e831df35401c8e6840162bf4a2ae5862604e7bc22db3000/pexpect-4.8.0-py2.py3-none-any.whl\r\npickleshare @ file:///home/void/.cache/pypoetry/artifacts/b5/48/a1/d2b823337003d531d87cf0d503ef28bb579703a74d14ad24a88863d616/pickleshare-0.7.5-py2.py3-none-any.whl\r\nPillow==8.4.0\r\npluggy @ file:///home/void/.cache/pypoetry/artifacts/81/78/ca/13f743a3628faf5a0b7f021efb45f2193acba3a13663d498f6b34bf02e/pluggy-1.0.0-py2.py3-none-any.whl\r\npoethepoet @ file:///home/void/.cache/pypoetry/artifacts/26/05/ba/93c09ab34cd65fa679517a054858388ea3d6872a2d2c935968ac69d41a/poethepoet-0.11.0-py3-none-any.whl\r\nportend @ file:///home/void/.cache/pypoetry/artifacts/b3/f1/c9/2742382df341b37e926f70577d5e6e1941593daa76f445b011b5760ba3/portend-3.1.0-py3-none-any.whl\r\npreshed @ file:///home/void/.cache/pypoetry/artifacts/32/18/f6/d3ef3856138e839656c9506ee150937257b0be46dcefb42b33572b9a01/preshed-3.0.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nprettytable @ file:///home/void/.cache/pypoetry/artifacts/41/92/33/a7b29c9b27ef82b89fcc84a93098e457b165dc0afa43255c01ddb8c35a/prettytable-2.4.0-py3-none-any.whl\r\nprometheus-client @ file:///home/void/.cache/pypoetry/artifacts/e5/94/14/4c38534d91e7278ccdf17c9e95312bb7dc0616281412eb11d863b4f6b4/prometheus_client-0.12.0-py2.py3-none-any.whl\r\npromise @ file:///home/void/.cache/pypoetry/artifacts/d6/c6/43/95f1e737b1dd79d3a5ac6cfb264a889716bab4cd9d28a9bc8c69591d53/promise-2.3.tar.gz\r\nprompt-toolkit @ file:///home/void/.cache/pypoetry/artifacts/ec/2a/77/5024fe40d375fe25a5d638cb593ec62b68f66f18670ea6eb8be5e0d414/prompt_toolkit-3.0.24-py3-none-any.whl\r\nprotobuf @ file:///home/void/.cache/pypoetry/artifacts/67/3c/11/7ad8ef245e4143fa80e62004142d61b5f9bd8179e65185b45479a09fee/protobuf-3.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\npsutil @ file:///home/void/.cache/pypoetry/artifacts/06/3a/4a/5e88d8f14e18b10c222f81667132086849930f068d68d064ceb8a87834/psutil-5.8.0-cp39-cp39-manylinux2010_x86_64.whl\r\nptyprocess @ file:///home/void/.cache/pypoetry/artifacts/2a/29/5d/0cdc5ec916431d60f03d2f725c54edbfa9fe53700b75fdfee209a3291e/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npy @ file:///home/void/.cache/pypoetry/artifacts/b3/5c/47/ba5a596e01a2b61fa2daa6a438252483ad8c04e6c99e5dc22eaf8a489a/py-1.11.0-py2.py3-none-any.whl\r\npyarrow @ file:///home/void/.cache/pypoetry/artifacts/28/3c/3e/fe875ac36b574da1e98180fa8d5230599b1af79bf6a6c6004470215308/pyarrow-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\npyasn1 @ file:///home/void/.cache/pypoetry/artifacts/7b/3a/54/42ce43b579bda01b9d79022fb733811594441e7a32e9f9a5a98f672bdc/pyasn1-0.4.8-py2.py3-none-any.whl\r\npyasn1-modules @ file:///home/void/.cache/pypoetry/artifacts/dd/b8/4f/b56433e0354274a31074995e01b8671751e9f0ed0001f5254e5b03a54f/pyasn1_modules-0.2.8-py2.py3-none-any.whl\r\npycodestyle @ file:///home/void/.cache/pypoetry/artifacts/4c/30/97/026c283ef67eb248e5b7e6fad1f8ffb99dae50c11fd93eb939fd7c1f46/pycodestyle-2.7.0-py2.py3-none-any.whl\r\npycparser @ file:///home/void/.cache/pypoetry/artifacts/fb/06/dd/b5671b47dd0597663bc05d60d324bb315a8cef56f3179b8f9067f88e50/pycparser-2.21-py2.py3-none-any.whl\r\npydantic @ file:///home/void/.cache/pypoetry/artifacts/e1/bf/c1/7cdd43a1b6ea4e9cfd1e0e9e5b3276ad83c6b57194b4449da3e64fe6cf/pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl\r\npydocstyle @ file:///home/void/.cache/pypoetry/artifacts/75/e7/e5/1acad15a51efd39cf39259c7888c205fd787a92efea28f7afc5a9e315c/pydocstyle-6.1.1-py3-none-any.whl\r\npyflakes @ file:///home/void/.cache/pypoetry/artifacts/eb/c4/2c/47fcc1b3f387b1f7033e85b3ac6ee7772338461a8de8ac3977c6a7dcc1/pyflakes-2.3.1-py2.py3-none-any.whl\r\nPygments @ file:///home/void/.cache/pypoetry/artifacts/d0/e9/f0/fe2df77eaa1b942fb9b6c52c8c433da9ce654580696e74423c9a9ad814/Pygments-2.10.0-py3-none-any.whl\r\npyparsing @ file:///home/void/.cache/pypoetry/artifacts/61/f1/da/6428e68d48dbbc9e9b942cf2dfb6b5a7faa052423078aae46465c3c8e0/pyparsing-3.0.6-py3-none-any.whl\r\npyperclip @ file:///home/void/.cache/pypoetry/artifacts/35/fc/1a/52ce52d3f2894189c10f68a583aa30936be8b3f2ae63ed12a58c2ab370/pyperclip-1.8.2.tar.gz\r\npyrsistent @ file:///home/void/.cache/pypoetry/artifacts/78/42/af/83d41626a30713ec48d568b27fc65ea9a098dd76da0e034fa6fa37c127/pyrsistent-0.18.0-cp39-cp39-manylinux1_x86_64.whl\r\npytest @ file:///home/void/.cache/pypoetry/artifacts/28/be/f1/ce8fa22c989106fc7c1ee7fa31d55d7f31aee1c58c63b2a43670601b79/pytest-6.2.5-py3-none-any.whl\r\npytest-cov @ file:///home/void/.cache/pypoetry/artifacts/50/df/c5/4bd35027c6247daac4ba547aff90d97ccdc7daf4aa62e110d69cfd39de/pytest_cov-3.0.0-py3-none-any.whl\r\npytest-randomly @ file:///home/void/.cache/pypoetry/artifacts/d0/be/d5/ab32188862bfab68e4fe043037f5c29f4b1657fa9b11ee6215bbbce29e/pytest_randomly-3.10.3-py3-none-any.whl\r\npython-dateutil @ file:///home/void/.cache/pypoetry/artifacts/53/f8/2a/7d63ce15df7386e9536e83413453f8aa845b47fb425f05c4ca2fb231c3/python_dateutil-2.8.2-py2.py3-none-any.whl\r\npython-docx @ file:///home/void/.cache/pypoetry/artifacts/7f/3f/b0/ca05b61dd6a8beb8bc8317700154416271ddda4db5425c92e9d780cba7/python-docx-0.8.11.tar.gz\r\npython-lsp-jsonrpc @ file:///home/void/.cache/pypoetry/artifacts/e6/0e/80/b725147ba93341249a4ba1659a62c1e5fdff33d830389c548e06f75065/python_lsp_jsonrpc-1.0.0-py3-none-any.whl\r\npython-lsp-server @ file:///home/void/.cache/pypoetry/artifacts/5d/f5/2f/a6a8117edeecd8d8bfc62f5737a05bb40fe86cd4e4647510868bffd40a/python_lsp_server-1.3.2-py3-none-any.whl\r\npython-slugify @ file:///home/void/.cache/pypoetry/artifacts/55/30/64/5d47f177ea315b707abbd2c99158590fbcb2e16d64954fd6866264b6b1/python_slugify-5.0.2-py2.py3-none-any.whl\r\npytz @ file:///home/void/.cache/pypoetry/artifacts/3e/f3/dd/6629bf5ed0a970a128e0a015f2af3b67280e749a56fdaabdaa06d5fc6b/pytz-2021.3-py2.py3-none-any.whl\r\nPyYAML @ file:///home/void/.cache/pypoetry/artifacts/4e/12/e6/32a4a77023f06c3061d2fc6d4692aa531b8530e211b24ff1f77a39e6ee/PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\npyzmq @ file:///home/void/.cache/pypoetry/artifacts/55/34/c8/5202023ce699a94ec8e3208751b3199ff36dda321909e46071ac56ff99/pyzmq-22.3.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\nqtconsole @ file:///home/void/.cache/pypoetry/artifacts/c6/8e/42/23f9ca96f920c5a6d025e320f260cd6cfa562ad4ac8c8630fdfd4719e9/qtconsole-5.2.1-py3-none-any.whl\r\nQtPy @ file:///home/void/.cache/pypoetry/artifacts/bd/e8/2d/4e139a4203207e267a82367a23f300bb4ea3aa19cc84b79e08dcee10ee/QtPy-1.11.3-py2.py3-none-any.whl\r\nregex @ file:///home/void/.cache/pypoetry/artifacts/69/3f/17/3188c9bca1e4732b00fb9bfcb2517add6231b3912ff2fc88e163377c06/regex-2021.11.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nrequests @ file:///home/void/.cache/pypoetry/artifacts/13/00/3d/5574756561eed6b522f5b13d5a2c05c2920860b05b1e687c3792495ba0/requests-2.26.0-py2.py3-none-any.whl\r\nrestructuredtext-lint @ file:///home/void/.cache/pypoetry/artifacts/b6/09/80/91d176f17ba9a28291203e41600b294aa26214e185082bcb0cc3543588/restructuredtext_lint-1.3.2.tar.gz\r\nrsa @ file:///home/void/.cache/pypoetry/artifacts/29/ba/41/0ee0fcca877c94f32799d12775b513c1314a9712a5c2833dc5bacff2ab/rsa-4.8-py3-none-any.whl\r\nruamel.yaml @ file:///home/void/.cache/pypoetry/artifacts/74/59/e5/d0f5b8a5babb30e50b50ebbc49f00d4567db12f4f93dee4d256ad2045a/ruamel.yaml-0.17.17-py3-none-any.whl\r\nruamel.yaml.clib @ file:///home/void/.cache/pypoetry/artifacts/52/95/75/d1a001b469ea6ed66dd6f4194c9f7eb370223816cf6292be2a8213e9a4/ruamel.yaml.clib-0.2.6-cp39-cp39-manylinux1_x86_64.whl\r\ns3transfer @ file:///home/void/.cache/pypoetry/artifacts/24/03/95/68c447d2eda2cc1924350cd0fdc25702e449ec27e9ac07b9106d57ee0b/s3transfer-0.5.0-py3-none-any.whl\r\nsacremoses @ file:///home/void/.cache/pypoetry/artifacts/65/e4/32/31727975bdcbad897dad7897d4dd2f2cc417567cb8cdb062a33ff203dd/sacremoses-0.0.46-py3-none-any.whl\r\nsafety @ file:///home/void/.cache/pypoetry/artifacts/8f/cc/5a/1dc0196c65cdb3f015bad143c000d159aca6f838a21d7d10872b092b83/safety-1.10.3-py2.py3-none-any.whl\r\nscikit-learn @ file:///home/void/.cache/pypoetry/artifacts/7e/53/6a/d82bb17e553455e6e77c903e8f9073d80cb89be3001094e1bc6b61c2da/scikit_learn-1.0.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\nscipy @ file:///home/void/.cache/pypoetry/artifacts/f6/a9/24/5707b4b4771bb5870386d5f9a054a34c61d719c835eb5411d6f9c2172d/scipy-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nSend2Trash @ file:///home/void/.cache/pypoetry/artifacts/63/2c/10/d48818ab0722d2d6ac42f70c8b9b6567ff3a7936bdc06dedddda4398b8/Send2Trash-1.8.0-py3-none-any.whl\r\nsentencepiece @ file:///home/void/.cache/pypoetry/artifacts/82/c3/b5/7dcf4928f5159deaba8f451549bd8b063b13e500873857524fc8f893c9/sentencepiece-0.1.96-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nsentry-sdk @ file:///home/void/.cache/pypoetry/artifacts/30/32/20/e1a1ec2d14fe92277fe6de796bd2788aa637b4453fae25dccfb91cf181/sentry_sdk-1.5.0-py2.py3-none-any.whl\r\nsgmllib3k @ file:///home/void/.cache/pypoetry/artifacts/48/41/c1/47c574e94f31057312eab350c2a7e7b75d1105eb5b673a14efe485c128/sgmllib3k-1.0.0.tar.gz\r\nshortuuid @ file:///home/void/.cache/pypoetry/artifacts/1b/c2/26/0a03ab3637895180121fd749a44e5005e71b8300cdd863c20ddbf0d318/shortuuid-1.0.8-py3-none-any.whl\r\nsiamenc==0.1.0\r\nsix @ file:///tmp/build/80754af9/six_1623709665295/work\r\nsmart-open @ file:///home/void/.cache/pypoetry/artifacts/90/9d/8f/b3121f6940407c06e50f8f81646a84f4551ec214bb239013488c3492e8/smart_open-5.2.1-py3-none-any.whl\r\nsmmap @ file:///home/void/.cache/pypoetry/artifacts/76/3f/89/377e56f6e08e5b1fa88da762382b4c9c817c6dd24eae2e0e190898511d/smmap-5.0.0-py3-none-any.whl\r\nsnowballstemmer @ file:///home/void/.cache/pypoetry/artifacts/a4/95/b0/c0f70d4b9bb0bac123e716da53ba9b012071cedf7c99bcf030757530f4/snowballstemmer-2.2.0-py2.py3-none-any.whl\r\nsortedcontainers @ file:///home/void/.cache/pypoetry/artifacts/b9/80/e1/4bdfa349488797fd308ecbe48f4fad57a3245777fb47c8741730583262/sortedcontainers-2.4.0-py2.py3-none-any.whl\r\nsoupsieve @ file:///home/void/.cache/pypoetry/artifacts/d6/e3/46/df82bc73fb10e31f7b04a84f47a5779830a07eeb6a6fa547e6d39ba88f/soupsieve-2.3.1-py3-none-any.whl\r\nspacy @ file:///home/void/.cache/pypoetry/artifacts/d7/0d/95/78417ba0b0e2e9fad4c3a79d8ffa424452dda63eda7e7928268b3f9e6e/spacy-3.1.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nspacy-legacy @ file:///home/void/.cache/pypoetry/artifacts/3a/2e/7c/ea1cd14cc8de699a5021f6aeb2d53e5951af637177cc9cbab44e17b4b2/spacy_legacy-3.0.8-py2.py3-none-any.whl\r\nSphinx @ file:///home/void/.cache/pypoetry/artifacts/8c/bb/4c/0ee38eab2be2a2d2f4623c9931920764ce590096adac2d693793344e12/Sphinx-4.3.1-py3-none-any.whl\r\nsphinx-autodoc-typehints @ file:///home/void/.cache/pypoetry/artifacts/e1/00/00/fde2ece43111d9fa6d415ed6fc4b0ef02b562fd106f3b6d636c3290d69/sphinx_autodoc_typehints-1.12.0-py3-none-any.whl\r\nsphinxcontrib-applehelp @ file:///home/void/.cache/pypoetry/artifacts/8d/eb/86/eec708bb3ff50c9780e78f36a9cb82cd9ff8030a90bd23b9a6f20aecca/sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl\r\nsphinxcontrib-devhelp @ file:///home/void/.cache/pypoetry/artifacts/56/a5/74/11ccaa7737f06a10422027e0595b24d243af7a7a1dc4982dec22044c28/sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl\r\nsphinxcontrib-htmlhelp @ file:///home/void/.cache/pypoetry/artifacts/66/d0/cb/7228297c74d9280e7246b52187704724b0b0881e2762cdef34e04be778/sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl\r\nsphinxcontrib-jsmath @ file:///home/void/.cache/pypoetry/artifacts/d2/22/96/2076357e64b369910aa24a20d5b719beb24a1487146e4742476ee1e2d8/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\r\nsphinxcontrib-qthelp @ file:///home/void/.cache/pypoetry/artifacts/32/fc/a9/112a82396d53ec629c1450253a6ded4d94d7ffffd63acd49879543ece9/sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl\r\nsphinxcontrib-serializinghtml @ file:///home/void/.cache/pypoetry/artifacts/e6/9a/17/830e357f3aee36549c613a2d660b5cf38d70c27ecb7c218d15c7bfffe1/sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl\r\nSQLAlchemy @ file:///home/void/.cache/pypoetry/artifacts/25/53/55/c917b4ef4af377fda67fa5112c8e9f7d76d6a01ac079e6117731103750/SQLAlchemy-1.4.28-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nsqlitedict @ file:///home/void/.cache/pypoetry/artifacts/30/da/52/503d8c476c0ad677cb6bcf1714381aa53b2500752bacc499aa0a5f4283/sqlitedict-1.7.0.tar.gz\r\nsrsly @ file:///home/void/.cache/pypoetry/artifacts/89/a3/39/8c42cc259a1c485abc0d750eab45ade4628e27862bbc13e1b55e08fdcc/srsly-2.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nstevedore @ file:///home/void/.cache/pypoetry/artifacts/42/17/61/45c6b9d8b0d45dd19994d1f96aa784b4e9792c968eb24e21b0816a258b/stevedore-3.5.0-py3-none-any.whl\r\nsubprocess32 @ file:///home/void/.cache/pypoetry/artifacts/b9/91/2e/cc8d3ccbf05fa27ee73859de9d02ef1a7eba84ed701970db1063a1848d/subprocess32-3.5.4.tar.gz\r\ntempora @ file:///home/void/.cache/pypoetry/artifacts/cb/55/38/93541362ca01d0ad882d583b2ede1e85283b618443fe69c3c3ed766f42/tempora-4.1.2-py3-none-any.whl\r\ntensorboardX @ file:///home/void/.cache/pypoetry/artifacts/94/c5/ae/2f09a78d1accfca59ec6e4a2abba0672b6d5d4186a88aae7c52abcb8ae/tensorboardX-2.4.1-py2.py3-none-any.whl\r\ntermcolor @ file:///home/void/.cache/pypoetry/artifacts/a2/5d/c7/e4ccb3b3bb8d3e3aff995fb6ffb12cfc78bbc8affa283907ee5eb5a5a5/termcolor-1.1.0.tar.gz\r\nterminado @ file:///home/void/.cache/pypoetry/artifacts/02/75/b5/4e735b6c2cb848bfe48f9fdbdff83761cb24fb4d7efabc73f87129bfc7/terminado-0.12.1-py3-none-any.whl\r\ntestfixtures @ file:///home/void/.cache/pypoetry/artifacts/f1/d5/a7/c4faba6a07aaf55807b3ccd90e164452bdf933dba1d25f66e8f71c451f/testfixtures-6.18.3-py2.py3-none-any.whl\r\ntestpath @ file:///home/void/.cache/pypoetry/artifacts/1e/2d/08/76691a9e7e429930fb378dd96f760de96f2686841c47da2b35a04c5aad/testpath-0.5.0-py3-none-any.whl\r\ntext-unidecode @ file:///home/void/.cache/pypoetry/artifacts/34/f9/c2/484c44b08bab89d472229bbd257fcc1d1c6273ee027f01cb08c4e3c309/text_unidecode-1.3-py2.py3-none-any.whl\r\nthinc @ file:///home/void/.cache/pypoetry/artifacts/0b/d9/75/057cbfbcba5d08f7a45fc2007dc0bf6960c2deaabf14dc9a84d94ca162/thinc-8.0.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nthreadpoolctl @ file:///home/void/.cache/pypoetry/artifacts/c6/32/f8/3fa7f1449c7563f03c74b00ea430b78691e4fec87a7b0098c82d4e65ab/threadpoolctl-3.0.0-py3-none-any.whl\r\ntokenizers @ file:///home/void/.cache/pypoetry/artifacts/b8/c9/5c/4f70bb6fca31833a346653e969bb4f5d7261302f6b828e918709a81ec3/tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\ntoml @ file:///home/void/.cache/pypoetry/artifacts/6b/6a/c9/53b19f7870a77d855e8b05ecdc98193944e5d246dafe11bbcad850ecba/toml-0.10.2-py2.py3-none-any.whl\r\ntomli @ file:///home/void/.cache/pypoetry/artifacts/04/b1/42/66b120badb2e2c588323f2066e27e85314a70d09e9bd0d571ea28b888b/tomli-1.2.2-py3-none-any.whl\r\ntomlkit @ file:///home/void/.cache/pypoetry/artifacts/fd/06/32/b79e75623225a9b5af79899482b9c2933c2fa2c6fb0eff80fcec10ae48/tomlkit-0.7.2-py2.py3-none-any.whl\r\ntorch==1.10.0\r\ntorchvision==0.11.1\r\ntornado @ file:///home/void/.cache/pypoetry/artifacts/32/ff/76/0fc7d26eab2180c92fa57552212f38defaf212ceb7ddc9432bd84d646c/tornado-6.1-cp39-cp39-manylinux2010_x86_64.whl\r\ntqdm @ file:///home/void/.cache/pypoetry/artifacts/c1/d2/95/984649137d2c9fac6d0f7a883c2007c07e7bbac3b692cad1004d495455/tqdm-4.62.3-py2.py3-none-any.whl\r\ntraitlets @ file:///home/void/.cache/pypoetry/artifacts/ee/01/57/93229f3393af5b0814aff282450fcac279f4d7f32188b49db882ebf459/traitlets-5.1.1-py3-none-any.whl\r\ntransformers @ file:///home/void/.cache/pypoetry/artifacts/2f/44/2e/3d86a39afc1169ee45cd28d73172f9d258f429a3993931ca6103e3a6ac/transformers-4.12.5-py3-none-any.whl\r\ntyper @ file:///home/void/.cache/pypoetry/artifacts/45/11/e9/0fd368a9452c62570ff1775b64e1fee58dc51e24327652495876625be0/typer-0.4.0-py3-none-any.whl\r\ntypes-toml @ file:///home/void/.cache/pypoetry/artifacts/e1/31/59/1539e56caa1c8887484812d0d9a0384ba535b41664b6ccfbb6670a25fd/types_toml-0.10.1-py3-none-any.whl\r\ntyping-extensions @ file:///tmp/build/80754af9/typing_extensions_1631814937681/work\r\nujson @ file:///home/void/.cache/pypoetry/artifacts/e1/c6/4f/d6e2db8bf28a838a8458e3099d839390ef47f0f913b111365f4de539d0/ujson-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nurllib3 @ file:///home/void/.cache/pypoetry/artifacts/55/46/d1/1acba0600879bfaada54191116fbaea89a464f437b3f949bc9c2a220e7/urllib3-1.26.7-py2.py3-none-any.whl\r\nwandb @ file:///home/void/.cache/pypoetry/artifacts/4a/87/ae/59e6cb93ad9fa66e2a38a2ab1823ce7acbd4f407416559707b9adc56f8/wandb-0.12.7-py2.py3-none-any.whl\r\nwasabi @ file:///home/void/.cache/pypoetry/artifacts/38/0b/ad/70a82d637fbe35102583fb03600f76fcbaf3928d6e074bd295e50bbd5c/wasabi-0.9.0-py3-none-any.whl\r\nwcwidth @ file:///home/void/.cache/pypoetry/artifacts/7d/f4/60/0737157bb9711fec72c70dff523aa54491eef317e0d586cf5388ff0908/wcwidth-0.2.5-py2.py3-none-any.whl\r\nwebencodings @ file:///home/void/.cache/pypoetry/artifacts/ed/d4/da/61384706cfac042ba3bd148746d66e50695463993be117c7c8dadeef7a/webencodings-0.5.1-py2.py3-none-any.whl\r\nwemake-python-styleguide @ file:///home/void/.cache/pypoetry/artifacts/b2/30/6d/aff16dd6cc6e7169bd34e8f2e8feff71a3cc593d6ebb617acc9cf7e927/wemake_python_styleguide-0.15.3-py3-none-any.whl\r\nwidgetsnbextension @ file:///home/void/.cache/pypoetry/artifacts/1e/8c/72/6bea2521eb3293d1d676d0bd992472ac2749ffc9159df93c30cb550027/widgetsnbextension-3.5.2-py2.py3-none-any.whl\r\nxxhash @ file:///home/void/.cache/pypoetry/artifacts/10/96/f5/ba104c6099c04fc1a07a01edd26d0c96519e713dadecd057566e8ce1f7/xxhash-2.0.2-cp39-cp39-manylinux2010_x86_64.whl\r\nyarl @ file:///home/void/.cache/pypoetry/artifacts/a3/6b/bb/af40f3ac1dfb8650848efd34d43176c01039c7203c8f8f615543baf9d2/yarl-1.7.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\nyaspin @ file:///home/void/.cache/pypoetry/artifacts/08/96/72/a995df36daf20ca713ef9c496ef7cc2595253341a2ed64056cb8ddb82c/yaspin-2.1.0-py3-none-any.whl\r\nzc.lockfile @ file:///home/void/.cache/pypoetry/artifacts/b5/a8/c8/e94e98335e585be92e35e5d07dd8a75e5c2e7774c8bd24410160f9cfe0/zc.lockfile-2.0-py2.py3-none-any.whl\r\nzipp @ file:///home/void/.cache/pypoetry/artifacts/84/c4/6a/f8c4d0deac7fc967e69e2e3b99eead4735005380e0c47b335bebf943f4/zipp-3.6.0-py3-none-any.whl\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\nThis is hard to reproduce in a minimal example because it depends on GPU memory. But I can reproduce it by training my model with batch size large enough to take up all the GPU space. \r\n\r\n1. In first run tweak number of epochs so that the last epoch also ends up being the best epoch. In this scenario the error does not happen.\r\n\r\n2. In 2nd run increase the number of epochs or change metric such that the last epoch is no longer the best epoch, can reliably do this by making the model run out of patience. This will produce an out of memory error after the training has finished.\r\n\r\nFrom looking I think this is the potential problem:\r\nhttps://github.com/allenai/allennlp/blob/38436d89f4d1d08959d7db8d1e6c339fff9720e2/allennlp/training/gradient_descent_trainer.py#L953-L957\r\n\r\nThe else condition where the model state dict is loaded again is causing the issue maybe?\r\n\r\n**Edit**\r\n\r\nHere is the worker 3 logs that confirm it has finished it's entire training and validation and has ran out of patience.\r\n[out_worker3.log](https://github.com/allenai/allennlp/files/7707558/out_worker3.log)\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5511/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5511/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5508", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5508/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5508/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5508/events", "html_url": "https://github.com/allenai/allennlp/issues/5508", "id": 1077358029, "node_id": "I_kwDOBXH8-M5ANy3N", "number": 5508, "title": "`conda install allennlp==2.8.0 -c conda-forge` hangs forever", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2021-12-11T02:07:18Z", "updated_at": "2022-06-01T22:14:55Z", "closed_at": "2021-12-27T16:09:44Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "When I run `conda install allennlp==2.8.0 -c conda-forge` in an environment with Python 3.8, it hangs forever.\r\n\r\n@h-vetinari, do you know anything about that?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5508/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5508/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5492", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5492/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5492/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5492/events", "html_url": "https://github.com/allenai/allennlp/issues/5492", "id": 1067774557, "node_id": "I_kwDOBXH8-M4_pPJd", "number": 5492, "title": "Path.unlink(missing_ok=True) not supported on python 3.7 but used unconditionally", "user": {"login": "h-vetinari", "id": 33685575, "node_id": "MDQ6VXNlcjMzNjg1NTc1", "avatar_url": "https://avatars.githubusercontent.com/u/33685575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/h-vetinari", "html_url": "https://github.com/h-vetinari", "followers_url": "https://api.github.com/users/h-vetinari/followers", "following_url": "https://api.github.com/users/h-vetinari/following{/other_user}", "gists_url": "https://api.github.com/users/h-vetinari/gists{/gist_id}", "starred_url": "https://api.github.com/users/h-vetinari/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/h-vetinari/subscriptions", "organizations_url": "https://api.github.com/users/h-vetinari/orgs", "repos_url": "https://api.github.com/users/h-vetinari/repos", "events_url": "https://api.github.com/users/h-vetinari/events{/privacy}", "received_events_url": "https://api.github.com/users/h-vetinari/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2021-11-30T23:29:24Z", "updated_at": "2021-12-01T01:59:33Z", "closed_at": "2021-12-01T01:59:30Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The keyword-argument `missing_ok` to `Path.unlink` was only [added](https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink) in python 3.8, but is used unconditionally in the code base. This leads to test errors on the allennlp-feedstock for conda-forge for the python 3.7 builds ([1](https://github.com/conda-forge/allennlp-feedstock/pull/30), [2](https://github.com/conda-forge/allennlp-feedstock/pull/31)).\r\n\r\n<details>\r\n\r\n```\r\n=================================== FAILURES ===================================\r\n__________________ TestTangoCommand.test_tango[train_tagger] ___________________\r\n\r\nself = <tests.commands.tango_test.TestTangoCommand object at 0x7f76b8044190>\r\nconfig = 'train_tagger'\r\n\r\n    @pytest.mark.parametrize(\"config\", [\"train_tagger\", \"train_tagger_complicated\"])\r\n    def test_tango(self, config: str):\r\n        output_path = self.TEST_DIR / f\"tango_{config}\"\r\n        sys.argv = [\r\n            \"allennlp\",\r\n            \"tango\",\r\n            str(self.FIXTURES_ROOT / \"tango\" / f\"{config}.jsonnet\"),\r\n            \"-s\",\r\n            str(output_path),\r\n        ]\r\n\r\n        assert not os.path.exists(output_path)\r\n\r\n        start = time.time()\r\n>       main()\r\n\r\ntests/commands/tango_test.py:29:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n[...]/lib/python3.7/site-packages/allennlp/commands/__init__.py:122: in main\r\n    args.func(args)\r\n[...]/lib/python3.7/site-packages/allennlp/commands/tango.py:83: in run_tango_from_args\r\n    file_friendly_logging=args.file_friendly_logging,\r\n[...]/lib/python3.7/site-packages/allennlp/commands/tango.py:101: in run_tango_from_file\r\n    file_friendly_logging=file_friendly_logging,\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nparams = <allennlp.common.params.Params object at 0x7f779a0b4b90>\r\nserialization_dir = PosixPath('/tmp/allennlp_testsa0wn1j1m/tango_train_tagger')\r\ninclude_package = [], dry_run = False, file_friendly_logging = False\r\n\r\n    def run_tango(\r\n        params: Params,\r\n        serialization_dir: Union[str, PathLike],\r\n        include_package: Optional[List[str]] = None,\r\n        dry_run: bool = False,\r\n        file_friendly_logging: bool = False,\r\n    ):\r\n        common_logging.FILE_FRIENDLY_LOGGING = file_friendly_logging\r\n\r\n        if include_package is not None:\r\n            for package_name in include_package:\r\n                common_util.import_module_and_submodules(package_name)\r\n\r\n        common_util.prepare_environment(params)\r\n\r\n        step_graph = step_graph_from_params(params.pop(\"steps\"))\r\n\r\n        serialization_dir = Path(serialization_dir)\r\n        serialization_dir.mkdir(parents=True, exist_ok=True)\r\n        step_cache = DirectoryStepCache(serialization_dir / \"step_cache\")\r\n\r\n        if dry_run:\r\n            for step, cached in tango_dry_run(\r\n                (s for s in step_graph.values() if not s.only_if_needed), step_cache\r\n            ):\r\n                if cached:\r\n                    print(f\"Getting {step.name} from cache\")\r\n                else:\r\n                    print(f\"Computing {step.name}\")\r\n        else:\r\n            # remove symlinks to old results\r\n            for filename in serialization_dir.glob(\"*\"):\r\n                if filename.is_symlink():\r\n                    relative_target = os.readlink(filename)\r\n                    if not relative_target.startswith(\"step_cache/\"):\r\n                        continue\r\n                    logger.info(\r\n                        f\"Removing symlink '{filename.name}' to previous result {relative_target}\"\r\n                    )\r\n                    filename.unlink()\r\n\r\n            # produce results\r\n            for name, step in step_graph.items():\r\n                if not step.only_if_needed:\r\n                    step.ensure_result(step_cache)\r\n\r\n            # symlink everything that has been computed\r\n            for name, step in step_graph.items():\r\n                if step in step_cache:\r\n                    step_link = serialization_dir / name\r\n>                   step_link.unlink(missing_ok=True)\r\nE                   TypeError: unlink() got an unexpected keyword argument 'missing_ok'\r\n```\r\n\r\n</details>", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5492/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5492/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5480", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5480/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5480/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5480/events", "html_url": "https://github.com/allenai/allennlp/issues/5480", "id": 1061351247, "node_id": "I_kwDOBXH8-M4_Qu9P", "number": 5480, "title": "EncoderBase pack padded sequence error", "user": {"login": "nickmagginas", "id": 16196224, "node_id": "MDQ6VXNlcjE2MTk2MjI0", "avatar_url": "https://avatars.githubusercontent.com/u/16196224?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nickmagginas", "html_url": "https://github.com/nickmagginas", "followers_url": "https://api.github.com/users/nickmagginas/followers", "following_url": "https://api.github.com/users/nickmagginas/following{/other_user}", "gists_url": "https://api.github.com/users/nickmagginas/gists{/gist_id}", "starred_url": "https://api.github.com/users/nickmagginas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nickmagginas/subscriptions", "organizations_url": "https://api.github.com/users/nickmagginas/orgs", "repos_url": "https://api.github.com/users/nickmagginas/repos", "events_url": "https://api.github.com/users/nickmagginas/events{/privacy}", "received_events_url": "https://api.github.com/users/nickmagginas/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-11-23T14:28:10Z", "updated_at": "2021-12-13T16:09:40Z", "closed_at": "2021-12-13T16:09:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ x ] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [ x ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ x ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ x ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ x ] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [ x ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ x ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ x ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ x ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ x ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nThe ```sort_and_run_forward``` method of ```_EncoderBase``` in ```modules/encoder_base.py``` determines if a sample in a batch is valid in line 99: \r\n\r\n```python\r\nnum_valid = torch.sum(mask[:, 0]).int().item()\r\n```\r\nThe mask is of shape B x S where B is batch size and S is sequence length. If the first item in the sequence of a sample is a pad token then the sample is deemed non valid. However, when we wish to mask sequences and observe the outputs of the model as for example in Lime replacing token_ids with 0 (pad token_id) will cause a traceback if all sequences in a batch start with zero. A batch for example containing ```[[\"[PAD]\", \"good\", \"[PAD]\"], [\"[PAD]\", \"bad\", \"flick\"]]``` will fail. \r\n\r\nIdeally the batch above would be valid to pass through the model.   \r\n \r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/nick/dev/magnex/src/evaluation/captum_interface/captum_interface.py\", line 190, in <module>\r\n    intepret_predictions(\r\n  File \"/home/nick/dev/magnex/src/evaluation/captum_interface/captum_interface.py\", line 173, in intepret_predictions\r\n    next(method_attributions)\r\n  File \"/home/nick/dev/magnex/src/evaluation/captum_interface/captum_interface.py\", line 113, in explain_instances\r\n    batch_attributions = initialized_interpeter.attribute(\r\n  File \"/home/nick/.miniconda/envs/magnex/lib/python3.9/site-packages/captum/log/__init__.py\", line 35, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/nick/.miniconda/envs/magnex/lib/python3.9/site-packages/captum/attr/_core/lime.py\", line 1053, in attribute\r\n    return self._attribute_kwargs(\r\n  File \"/home/nick/.miniconda/envs/magnex/lib/python3.9/site-packages/captum/attr/_core/lime.py\", line 1164, in _attribute_kwargs\r\n    coefs = super().attribute.__wrapped__(\r\n  File \"/home/nick/.miniconda/envs/magnex/lib/python3.9/site-packages/captum/attr/_core/lime.py\", line 479, in attribute\r\n    model_out = self._evaluate_batch(\r\n  File \"/home/nick/.miniconda/envs/magnex/lib/python3.9/site-packages/captum/attr/_core/lime.py\", line 535, in _evaluate_batch\r\n    model_out = _run_forward(\r\n  File \"/home/nick/.miniconda/envs/magnex/lib/python3.9/site-packages/captum/_utils/common.py\", line 456, in _run_forward\r\n    output = forward_func(\r\n  File \"/home/nick/dev/magnex/src/evaluation/captum_interface/captum_interface.py\", line 105, in _forward_func\r\n    model_output = model.forward(**complete_model_input)\r\n  File \"/home/nick/.miniconda/envs/magnex/lib/python3.9/site-packages/allennlp/models/basic_classifier.py\", line 128, in forward\r\n    embedded_text = self._seq2vec_encoder(embedded_text, mask=mask)\r\n  File \"/home/nick/.miniconda/envs/magnex/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/nick/.miniconda/envs/magnex/lib/python3.9/site-packages/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py\", line 80, in forward\r\n    ) = self.sort_and_run_forward(self._module, inputs, mask, hidden_state)\r\n  File \"/home/nick/.miniconda/envs/magnex/lib/python3.9/site-packages/allennlp/modules/encoder_base.py\", line 110, in sort_and_run_forward\r\n    packed_sequence_input = pack_padded_sequence(\r\n  File \"/home/nick/.miniconda/envs/magnex/lib/python3.9/site-packages/torch/nn/utils/rnn.py\", line 249, in pack_padded_sequence\r\n    _VF._pack_padded_sequence(input, lengths, batch_first)\r\nRuntimeError: Cannot pack empty tensors.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux ( Arch Linux x86_64  kernel: 5.14.15-arch1-1)\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.9.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp==3.8.0\r\naiosignal==1.2.0\r\nallennlp==2.8.0\r\nallennlp-models==2.8.0\r\nappdirs==1.4.4\r\nargon2-cffi==21.1.0\r\nasync-timeout==4.0.1\r\nattrs @ file:///tmp/build/80754af9/attrs_1620827162558/work\r\nbackcall==0.2.0\r\nbackports.csv==1.0.7\r\nbase58==2.1.1\r\nbeautifulsoup4 @ file:///tmp/build/80754af9/beautifulsoup4_1631874778482/work\r\nblack==19.10b0\r\nbleach==4.1.0\r\nblis==0.7.5\r\nboto3==1.20.3\r\nbotocore==1.23.3\r\nbrotlipy==0.7.0\r\ncached-path==0.3.2\r\ncachetools==4.2.4\r\ncaptum==0.4.1\r\ncatalogue==2.0.6\r\ncertifi==2021.10.8\r\ncffi==1.15.0\r\nchardet @ file:///tmp/build/80754af9/chardet_1607706775000/work\r\ncharset-normalizer==2.0.7\r\nchecklist==0.0.11\r\ncheroot==8.5.2\r\nCherryPy==18.6.1\r\nclick==8.0.3\r\nconda==4.10.3\r\nconda-build==3.21.6\r\nconda-package-handling @ file:///tmp/build/80754af9/conda-package-handling_1618262147379/work\r\nconfigparser==5.1.0\r\nconllu==4.4.1\r\ncryptography @ file:///tmp/build/80754af9/cryptography_1635366129652/work\r\ncycler==0.11.0\r\ncymem==2.0.6\r\ndatasets==1.15.1\r\ndebugpy==1.5.1\r\ndecorator==5.1.0\r\ndefusedxml==0.7.1\r\ndill==0.3.4\r\ndocker-pycreds==0.4.0\r\nentrypoints==0.3\r\nfairscale==0.4.0\r\nfeedparser==6.0.8\r\nfilelock==3.3.2\r\nfonttools==4.28.1\r\nfrozenlist==1.2.0\r\nfsspec==2021.11.0\r\nftfy==6.0.3\r\nfuture==0.18.2\r\ngitdb==4.0.9\r\nGitPython==3.1.24\r\nglob2 @ file:///home/linux1/recipes/ci/glob2_1610991677669/work\r\ngoogle-api-core==2.2.2\r\ngoogle-auth==2.3.3\r\ngoogle-cloud-core==2.2.1\r\ngoogle-cloud-storage==1.42.3\r\ngoogle-crc32c==1.3.0\r\ngoogle-resumable-media==2.1.0\r\ngoogleapis-common-protos==1.53.0\r\nh5py==3.5.0\r\nhuggingface-hub==0.1.2\r\nidna==3.3\r\niniconfig==1.1.1\r\nipykernel==6.5.0\r\nipython==7.29.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.5\r\niso-639==0.4.5\r\njaraco.classes==3.2.1\r\njaraco.collections==3.4.0\r\njaraco.functools==3.4.0\r\njaraco.text==3.6.0\r\njedi==0.18.0\r\nJinja2==3.0.3\r\njmespath==0.10.0\r\njoblib==1.1.0\r\njsonnet==0.17.0\r\njsonschema==4.2.1\r\njupyter==1.0.0\r\njupyter-client==7.0.6\r\njupyter-console==6.4.0\r\njupyter-core==4.9.1\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.2\r\nkiwisolver==1.3.2\r\nlibarchive-c @ file:///tmp/build/80754af9/python-libarchive-c_1617780486945/work\r\nlmdb==1.2.1\r\nlxml==4.6.4\r\nMarkupSafe @ file:///tmp/build/80754af9/markupsafe_1621523467000/work\r\nmatplotlib==3.5.0\r\nmatplotlib-inline==0.1.3\r\nmistune==0.8.4\r\nmore-itertools==8.11.0\r\nmultidict==5.2.0\r\nmultiprocess==0.70.12.2\r\nmunch==2.5.0\r\nmurmurhash==1.0.6\r\nmypy==0.910\r\nmypy-extensions==0.4.3\r\nnbclient==0.5.5\r\nnbconvert==6.2.0\r\nnbformat==5.1.3\r\nnest-asyncio==1.5.1\r\nnltk==3.6.3\r\nnotebook==6.4.5\r\nnumpy==1.21.4\r\noverrides==3.1.0\r\npackaging==21.2\r\npandas==1.3.4\r\npandocfilters==1.5.0\r\nparso==0.8.2\r\npathspec==0.7.0\r\npathtools==0.1.2\r\npathy==0.6.1\r\npatternfork-nosql==3.6\r\npdfminer.six==20211012\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==8.4.0\r\npkginfo==1.7.1\r\npluggy==1.0.0\r\nportend==3.0.0\r\npreshed==3.0.6\r\nprometheus-client==0.12.0\r\npromise==2.3\r\nprompt-toolkit==3.0.22\r\nprotobuf==3.19.1\r\npsutil @ file:///tmp/build/80754af9/psutil_1612297992929/work\r\nptyprocess==0.7.0\r\npy==1.11.0\r\npy-rouge==1.1\r\npyarrow==6.0.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycosat==0.6.3\r\npycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\r\npydantic==1.8.2\r\nPygments==2.10.0\r\npyOpenSSL @ file:///tmp/build/80754af9/pyopenssl_1635333100036/work\r\npyparsing==2.4.7\r\npyrsistent==0.18.0\r\nPySocks @ file:///tmp/build/80754af9/pysocks_1605305812635/work\r\npytest==6.2.5\r\npython-dateutil==2.8.2\r\npython-docx==0.8.11\r\npytz==2021.3\r\nPyYAML==6.0\r\npyzmq==22.3.0\r\nqtconsole==5.2.0\r\nQtPy==1.11.2\r\nregex==2021.11.10\r\nrequests @ file:///tmp/build/80754af9/requests_1629994808627/work\r\nrsa==4.7.2\r\nruamel-yaml-conda @ file:///tmp/build/80754af9/ruamel_yaml_1616016711199/work\r\ns3transfer==0.5.0\r\nsacremoses==0.0.46\r\nscikit-learn==1.0.1\r\nscipy==1.7.2\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.4.3\r\nsetuptools-scm==6.3.2\r\nsgmllib3k==1.0.0\r\nshortuuid==1.0.8\r\nsix @ file:///tmp/build/80754af9/six_1623709665295/work\r\nsmart-open==5.2.1\r\nsmmap==5.0.0\r\nsoupsieve @ file:///tmp/build/80754af9/soupsieve_1636706018808/work\r\nspacy==3.1.4\r\nspacy-legacy==3.0.8\r\nsqlitedict==1.7.0\r\nsrsly==2.4.2\r\nsubprocess32==3.5.4\r\ntempora==4.1.2\r\ntensorboardX==2.4\r\ntermcolor==1.1.0\r\nterminado==0.12.1\r\ntestpath==0.5.0\r\nthinc==8.0.13\r\nthreadpoolctl==3.0.0\r\ntokenizers==0.10.3\r\ntoml @ file:///tmp/build/80754af9/toml_1616166611790/work\r\ntomli==1.2.2\r\ntorch==1.10.0\r\ntorchvision==0.11.1\r\ntornado==6.1\r\ntqdm @ file:///tmp/build/80754af9/tqdm_1635330843403/work\r\ntraitlets==5.1.1\r\ntransformers==4.12.3\r\ntyped-ast @ file:///tmp/build/80754af9/typed-ast_1624953673314/work\r\ntyper==0.4.0\r\ntyping-extensions @ file:///tmp/build/80754af9/typing_extensions_1631814937681/work\r\nurllib3==1.26.7\r\nwandb==0.12.6\r\nwasabi==0.8.2\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nwidgetsnbextension==3.5.2\r\nword2number==1.1\r\nxxhash==2.0.2\r\nyarl==1.7.2\r\nyaspin==2.1.0\r\nzc.lockfile==2.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```python\r\nfrom allennlp.data.fields.text_field import TextFieldTensors\r\nfrom allennlp.models.archival import load_archive\r\nfrom allennlp.data.batch import Batch\r\nfrom allennlp.common.util import import_module_and_submodules\r\nimport torch\r\n\r\nimport_module_and_submodules(\"allennlp_models\")\r\n\r\narchive = load_archive(\r\n    \"https://storage.googleapis.com/allennlp-public-models/basic_stanford_sentiment_treebank-2020.06.09.tar.gz\"\r\n)\r\n\r\ninstances = archive.dataset_reader.read(\r\n    \"https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\"\r\n)\r\n\r\nsample_instance = next(instances)\r\n\r\ndummy_batch = Batch([sample_instance])\r\n\r\narchive.dataset_reader.apply_token_indexers(sample_instance)\r\ndummy_batch.index_instances(archive.model.vocab)\r\n\r\ntensor_dict = dummy_batch.as_tensor_dict()\r\n\r\nworking_mask = torch.Tensor([[1, 0]])\r\nnon_working_mask = torch.Tensor([[0, 1]])\r\n\r\n\r\ndef mask_tokens(\r\n    text_field_tensors: TextFieldTensors, mask: torch.Tensor\r\n) -> TextFieldTensors:\r\n\r\n    \"\"\"Mask some token ids based on mask\"\"\"\r\n    return {\r\n        key: {\r\n            _key: torch.where(mask == 1, _value, torch.zeros_like(_value))\r\n            for _key, _value in value.items()\r\n        }\r\n        for key, value in text_field_tensors.items()\r\n    }\r\n\r\n\r\nworking_masked_input = mask_tokens(tensor_dict[\"tokens\"], working_mask)  # type: ignore\r\nworking_model_output = archive.model.forward(**{\"tokens\": working_masked_input})\r\n\r\nnon_working_masked_input = mask_tokens(tensor_dict[\"tokens\"], non_working_mask)  # type: ignore\r\nnon_working_model_output = archive.model.forward(**{\"tokens\": non_working_masked_input})\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5480/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5480/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5472", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5472/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5472/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5472/events", "html_url": "https://github.com/allenai/allennlp/issues/5472", "id": 1056802496, "node_id": "I_kwDOBXH8-M4-_YbA", "number": 5472, "title": "FBetaMultiLabelMeasure confusing docstring", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2021-11-18T00:54:31Z", "updated_at": "2021-11-23T00:36:13Z", "closed_at": "2021-11-23T00:36:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "The docstring for the `threshold` parameter for `FBetaMultiLabelMeasure` states\r\n\r\n    threshold: `float`, optional (default = `0.5`)\r\n        Logits over this threshold will be considered predictions for the corresponding class.\r\n\r\nThis is slightly confusing, usually, you'd test if logits are greater than 0.0 or probabilities are greater than 0.5\r\n\r\nThe docstring implies that we should pass `logits` as `predictions`, but the default for threshold implies `probabilities` are expected. \r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5472/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5472/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5466", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5466/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5466/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5466/events", "html_url": "https://github.com/allenai/allennlp/issues/5466", "id": 1054961065, "node_id": "I_kwDOBXH8-M4-4W2p", "number": 5466, "title": "Error when trying to install from source on Windows 10 using conda environment", "user": {"login": "AlanQuille", "id": 33432976, "node_id": "MDQ6VXNlcjMzNDMyOTc2", "avatar_url": "https://avatars.githubusercontent.com/u/33432976?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AlanQuille", "html_url": "https://github.com/AlanQuille", "followers_url": "https://api.github.com/users/AlanQuille/followers", "following_url": "https://api.github.com/users/AlanQuille/following{/other_user}", "gists_url": "https://api.github.com/users/AlanQuille/gists{/gist_id}", "starred_url": "https://api.github.com/users/AlanQuille/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AlanQuille/subscriptions", "organizations_url": "https://api.github.com/users/AlanQuille/orgs", "repos_url": "https://api.github.com/users/AlanQuille/repos", "events_url": "https://api.github.com/users/AlanQuille/events{/privacy}", "received_events_url": "https://api.github.com/users/AlanQuille/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2021-11-16T14:41:33Z", "updated_at": "2021-12-01T01:54:31Z", "closed_at": "2021-12-01T01:54:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nI am installing AllenNLP from source. I have successfully run this command in a fresh Python 3.7 anaconda environment:\r\n\r\npip install -U pip setuptools wheel\r\n\r\nHowever, when I run the following command:\r\n\r\npip install --editable .\r\n\r\nI get the the following error:\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n(allen_source) \u03bb pip install --editable .\r\nObtaining file:///C:/Users/Alan/Desktop/Internship/allen_train/allennlp\r\n  Installing build dependencies ... done\r\n  Checking if build backend supports build_editable ... done\r\n  Getting requirements to build wheel ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: 'C:\\ProgramData\\Anaconda3\\envs\\allen_source\\python.exe' 'C:\\ProgramData\\Anaconda3\\envs\\allen_source\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\Alan\\AppData\\Local\\Temp\\tmp2tirtgi3'\r\n       cwd: C:\\Users\\Alan\\Desktop\\Internship\\allen_train\\allennlp\r\n  Complete output (18 lines):\r\n  Traceback (most recent call last):\r\n    File \"C:\\ProgramData\\Anaconda3\\envs\\allen_source\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 363, in <module>\r\n      main()\r\n    File \"C:\\ProgramData\\Anaconda3\\envs\\allen_source\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 345, in main\r\n      json_out['return_val'] = hook(**hook_input['kwargs'])\r\n    File \"C:\\ProgramData\\Anaconda3\\envs\\allen_source\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 130, in get_requires_for_build_wheel\r\n      return hook(config_settings)\r\n    File \"C:\\Users\\Alan\\AppData\\Local\\Temp\\pip-build-env-ilzm346c\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 163, in get_requires_for_build_wheel\r\n      config_settings, requirements=['wheel'])\r\n    File \"C:\\Users\\Alan\\AppData\\Local\\Temp\\pip-build-env-ilzm346c\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 143, in _get_build_requires\r\n      self.run_setup()\r\n    File \"C:\\Users\\Alan\\AppData\\Local\\Temp\\pip-build-env-ilzm346c\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 158, in run_setup\r\n      exec(compile(code, __file__, 'exec'), locals())\r\n    File \"setup.py\", line 26, in <module>\r\n      long_description=open(\"README.md\").read(),\r\n    File \"C:\\ProgramData\\Anaconda3\\envs\\allen_source\\lib\\encodings\\cp1252.py\", line 23, in decode\r\n      return codecs.charmap_decode(input,self.errors,decoding_table)[0]\r\n  UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 1210: character maps to <undefined>\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Windows 10 Pro\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.7.0\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\ncertifi==2021.10.8\r\nwincertstore==0.2\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nconda create -n allen_source python==3.7\r\nconda activate allen_source\r\ngit clone https://github.com/allenai/allennlp.git\r\ncd allennlp/\r\npip install -U pip setuptools wheel\r\npip install --editable .\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5466/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5466/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5457", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5457/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5457/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5457/events", "html_url": "https://github.com/allenai/allennlp/issues/5457", "id": 1043875830, "node_id": "I_kwDOBXH8-M4-OEf2", "number": 5457, "title": "AllenNLP Models 2.8", "user": {"login": "pvcastro", "id": 12713359, "node_id": "MDQ6VXNlcjEyNzEzMzU5", "avatar_url": "https://avatars.githubusercontent.com/u/12713359?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pvcastro", "html_url": "https://github.com/pvcastro", "followers_url": "https://api.github.com/users/pvcastro/followers", "following_url": "https://api.github.com/users/pvcastro/following{/other_user}", "gists_url": "https://api.github.com/users/pvcastro/gists{/gist_id}", "starred_url": "https://api.github.com/users/pvcastro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pvcastro/subscriptions", "organizations_url": "https://api.github.com/users/pvcastro/orgs", "repos_url": "https://api.github.com/users/pvcastro/repos", "events_url": "https://api.github.com/users/pvcastro/events{/privacy}", "received_events_url": "https://api.github.com/users/pvcastro/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2021-11-03T17:27:24Z", "updated_at": "2021-11-06T00:59:00Z", "closed_at": "2021-11-06T00:59:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I'm trying to upgrade AllenNLP to 2.8.0, but since AllenNLP models wasn't upgraded accordingly, I can't keep the new version. Isn't the models project going to get released to 2.8.0 too?\r\n\r\nThanks!", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5457/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5457/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5451", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5451/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5451/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5451/events", "html_url": "https://github.com/allenai/allennlp/issues/5451", "id": 1038853974, "node_id": "I_kwDOBXH8-M4966dW", "number": 5451, "title": "Check for bad start or end symbol in Seq2SeqDatasetReader considers only source tokenizer", "user": {"login": "JohnGiorgi", "id": 8917831, "node_id": "MDQ6VXNlcjg5MTc4MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/8917831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JohnGiorgi", "html_url": "https://github.com/JohnGiorgi", "followers_url": "https://api.github.com/users/JohnGiorgi/followers", "following_url": "https://api.github.com/users/JohnGiorgi/following{/other_user}", "gists_url": "https://api.github.com/users/JohnGiorgi/gists{/gist_id}", "starred_url": "https://api.github.com/users/JohnGiorgi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JohnGiorgi/subscriptions", "organizations_url": "https://api.github.com/users/JohnGiorgi/orgs", "repos_url": "https://api.github.com/users/JohnGiorgi/repos", "events_url": "https://api.github.com/users/JohnGiorgi/events{/privacy}", "received_events_url": "https://api.github.com/users/JohnGiorgi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-10-28T18:54:55Z", "updated_at": "2021-11-01T23:06:01Z", "closed_at": "2021-11-01T23:06:01Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nIn [`Seq2SeqDatasetReader`](https://github.com/allenai/allennlp-models/blob/d1b81c3637f875f9be95314945deb48d40d32ae2/allennlp_models/generation/dataset_readers/seq2seq.py#L108-L121), there is a check for the validity of the `start_symbol` and `end_symbol` (copy pasted below)\r\n\r\n```python\r\n        if (\r\n            source_add_start_token\r\n            or source_add_end_token\r\n            or target_add_start_token\r\n            or target_add_end_token\r\n        ):\r\n            # Check that the tokenizer correctly appends the start and end tokens to\r\n            # the sequence without splitting them.\r\n            tokens = self._source_tokenizer.tokenize(start_symbol + \" \" + end_symbol)\r\n            err_msg = (\r\n                f\"Bad start or end symbol ('{start_symbol}', '{end_symbol}') \"\r\n                f\"for tokenizer {self._source_tokenizer}\"\r\n            )\r\n            try:\r\n                start_token, end_token = tokens[0], tokens[-1]\r\n            except IndexError:\r\n                raise ValueError(err_msg)\r\n            if start_token.text != start_symbol or end_token.text != end_symbol:\r\n                raise ValueError(err_msg)\r\n\r\n            self._start_token = start_token\r\n            self._end_token = end_token\r\n```\r\n\r\nI think the `if` statement considering only the `source_tokenizer` is a bug, as it will raise an error for any `source_tokenizer` that 1) Adds its own special tokens to the beginning or end of a sequence and/or 2) Uses subword tokenization and splits up `start_symbol` or `end_symbol`. This error is raised even if you properly set up your `target_tokenizer`, and set `source_add_start_token=False`, `source_add_end_token=False`.\r\n\r\n```python\r\nfrom allennlp.data.tokenizers import PretrainedTransformerTokenizer\r\nfrom allennlp_models.generation import Seq2SeqDatasetReader\r\nfrom allennlp.common.util import START_SYMBOL, END_SYMBOL\r\n\r\nsource_tokenizer = PretrainedTransformerTokenizer(\"bert-base-uncased\", add_special_tokens=True)\r\n\r\n# Set up a target tokenizer so it is compatible with `start_symbol` and `end_symbol`\r\ntokenizer_kwargs = {\"additional_special_tokens\": [START_SYMBOL, END_SYMBOL]}\r\ntarget_tokenizer = PretrainedTransformerTokenizer(\"bert-base-uncased\", add_special_tokens=False, tokenizer_kwargs=tokenizer_kwargs)\r\n\r\n# Raises ValueError\r\nreader = Seq2SeqDatasetReader(\r\n    source_tokenizer=source_tokenizer,\r\n    target_tokenizer=target_tokenizer,\r\n    source_add_start_token=False,\r\n    source_add_end_token=False,\r\n    start_symbol=START_SYMBOL,\r\n    end_symbol=END_SYMBOL\r\n)\r\n```\r\n\r\nI think the fix is to break the `if` statement up into two checks, one for the `source_tokenizer` and one for the `target_tokenizer`. I'd be happy to do that in a PR if the maintainers agree.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```bash\r\n~/Library/Caches/pypoetry/virtualenvs/seq2rel-KdBYT5RF-py3.8/lib/python3.8/site-packages/allennlp_models/generation/dataset_readers/seq2seq.py in __init__(self, source_tokenizer, target_tokenizer, source_token_indexers, target_token_indexers, source_add_start_token, source_add_end_token, target_add_start_token, target_add_end_token, start_symbol, end_symbol, delimiter, source_max_tokens, target_max_tokens, quoting, **kwargs)\r\n    116                 raise ValueError(err_msg)\r\n    117             if start_token.text != start_symbol or end_token.text != end_symbol:\r\n--> 118                 raise ValueError(err_msg)\r\n    119 \r\n    120             self._start_token = start_token\r\n\r\nValueError: Bad start or end symbol ('@start@', '@end@') for tokenizer <allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer object at 0x7fdd22b84550>\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: MacOS, Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/1e/2e/7a/374792df594d4558e7849f4a367e0ddb5f5213e6d4776f883323432364/aiohttp-3.7.4.post0-cp38-cp38-macosx_10_14_x86_64.whl\r\nallennlp @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/d1/0e/28/6187f1a8cf1e88c909d1894c3f99fbe1a396202e4e83c12c2c17158e50/allennlp-2.7.0-py3-none-any.whl\r\nallennlp-models @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/d3/de/4b/afa5ee582d4a14ab6a4b6fd7c245717963fbe5d7c02f39508b42d592e1/allennlp_models-2.7.0-py3-none-any.whl\r\nanyio==3.3.1\r\nappnope @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/db/10/31/24b2c5bc1fc158d51095265fd31ede89b3ac384a8a2307ffc7ec8d87bb/appnope-0.1.2-py2.py3-none-any.whl\r\nargon2-cffi @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/cc/73/82/88105415573a251b1cfc3374c63f06527c2f0b56215fdf697b8bb7e92d/argon2_cffi-21.1.0-cp35-abi3-macosx_10_14_x86_64.whl\r\nasync-timeout @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/0d/5d/3e/630122e534c1b25e36c3142597c4b0b2e9d3f2e0a9cea9f10ac219f9a7/async_timeout-3.0.1-py3-none-any.whl\r\nattrs @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/1a/aa/39/10d6d07084f186f8cf6963cb033440402ad5088bb94d712239170f2ef6/attrs-21.2.0-py2.py3-none-any.whl\r\nBabel==2.9.1\r\nbackcall @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/62/2c/f2/bf9c43ca0bcfca41150901227b0d023dc854851b710f82a72f5beaa09b/backcall-0.2.0-py2.py3-none-any.whl\r\nbackports.csv @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/62/f6/b5/1fc08ffc7d061d06727f3d82267fa2e6a2ba386b0d45b781011a9e8e76/backports.csv-1.0.7-py2.py3-none-any.whl\r\nbackports.entry-points-selectable==1.1.0\r\nbase58 @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/3b/99/5b/f0cba442306d941d06e57b14367dd39889e6045b046248b683ef55f449/base58-2.1.0-py3-none-any.whl\r\nbeautifulsoup4 @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/6b/d1/6b/d0b3c51ce4f18fb1bd802534ae47547c8cac66e8dd8e35ec5dfa25ec74/beautifulsoup4-4.10.0-py3-none-any.whl\r\nblack @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/98/73/04/994acfc78d741658bc3b00f289e2d6ddf3d1afa901301102bbea18b1a7/black-21.9b0-py3-none-any.whl\r\nbleach @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/c2/d4/65/1df2e21979f2ef4b2f78653a465a302f5138c7f42c9b2f816d0a5167f4/bleach-4.1.0-py2.py3-none-any.whl\r\nblis @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f1/f7/65/c23408461bd53cfeb5b8e761ce18ff00479dd028bbb6a4d8369ec565de/blis-0.7.4-cp38-cp38-macosx_10_9_x86_64.whl\r\nboto3 @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/a8/bb/a3/f0b0ff64f04dd919065a8484ad6b61d9aba2e49a0d0af6787dacecf32d/boto3-1.18.63-py3-none-any.whl\r\nbotocore @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/23/f5/07/0891b039af91379e2e15d8501de8bd8056423ee805ad859ae578162e1d/botocore-1.21.63-py3-none-any.whl\r\ncachetools @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/ca/68/fb/a94522dd8c8d081803f16d6ec74ce9a678a827247431e2a8339f25506f/cachetools-4.2.4-py3-none-any.whl\r\ncatalogue @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/0b/b7/5d/989fb530709f23308e5e3078336a2b25616e48483321f5d40d43227a3e/catalogue-2.0.6-py3-none-any.whl\r\ncertifi @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/77/74/3e/daf57610ff13227e3b3f50a78487055f6ac94cc9363abd2463be34c5e9/certifi-2021.10.8-py2.py3-none-any.whl\r\ncffi @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/e6/3a/ed/211634ffd1f9ed0a6957a6981ef59f3af9934e62dc2ee15819d9623196/cffi-1.15.0-cp38-cp38-macosx_10_9_x86_64.whl\r\nchardet @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/47/b7/82/19c2b887f87f3adbaf4e34c55189388e5132c78f6929d7001a78b0209b/chardet-4.0.0-py2.py3-none-any.whl\r\ncharset-normalizer @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/23/43/96/9c5bffd9765f723eb96925cec608e36125667e8f31b6b3152f0b51716f/charset_normalizer-2.0.7-py3-none-any.whl\r\nchecklist @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/7f/33/3a/65d35388a6f64f3588edd653207d54bc2a6df87d12dbbd091a60691030/checklist-0.0.11.tar.gz\r\ncheroot @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/c7/ed/3f/4d422858bbc847c271a76ff4f9f74fa52cef8e3b343137c8dd3ee20c74/cheroot-8.5.2-py2.py3-none-any.whl\r\nCherryPy @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/73/28/88/5a7eb306865e78d39e014c1a5817d8982dbb3bdd86c3d2d24d6e4a3c59/CherryPy-18.6.1-py2.py3-none-any.whl\r\nclick @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/3c/f6/a3/2262df8f5a6f3de5bbc78cc13803c60524c8384dce76661fdfe3df975f/click-8.0.3-py3-none-any.whl\r\ncodecov @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/29/78/32/d6897550a321cf7a72f75d517bdd629791fb6d77a845d22f38ae663b98/codecov-2.1.12-py2.py3-none-any.whl\r\ncolorama @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/b0/f3/a3/cf94f06cbe1d286a25116cfe54d5a75cb1c4b54d15b2b1b4fc03a7f657/colorama-0.4.4-py2.py3-none-any.whl\r\nconfigparser @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f7/52/b3/2a0e73f491afdef69d3a59b416ca8c10b4e43a9eee55e95065f5f145e8/configparser-5.0.2-py3-none-any.whl\r\nconllu @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/8e/76/29/59f80fa3e3e5231b9674ebc6d9823c24ca79e647c82407a704f7c6522f/conllu-4.4.1-py2.py3-none-any.whl\r\ncoverage @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/7d/97/ed/264891013579a2b2e008cef6ad91712d255bfcdf01af6d130383d8270b/coverage-6.0.2-cp38-cp38-macosx_10_9_x86_64.whl\r\ncryptography @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/16/18/fd/53f7bd4088758821f0edf9ef9f345668e11a1f1894f1b4dc3f7252a801/cryptography-35.0.0-cp36-abi3-macosx_10_10_x86_64.whl\r\ncycler==0.10.0\r\ncymem @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f8/37/7b/9022833f73b73d3b67107a0aa0567e2d8bf526e43b6c211ca8e2d714e5/cymem-2.0.5-cp38-cp38-macosx_10_9_x86_64.whl\r\ndatasets @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/1a/f3/4e/f4d95860411c32ad68b41e571d677d898efd8f8862c1904bdf54678aa2/datasets-1.13.3-py3-none-any.whl\r\ndebugpy @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/57/26/42/875e0a918207d1e49c1619f784d21d1d4bfa1650b39282eea154cd8398/debugpy-1.5.0-cp38-cp38-macosx_10_15_x86_64.whl\r\ndecorator @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/34/17/0e/2b47ba09c969bda1d9eaefda2d9ccee318289f9e57d361761be4f3ab90/decorator-5.1.0-py3-none-any.whl\r\ndefusedxml @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/15/b0/94/888992ee7b1de9fbc975b6afd17d34f441df6e96172df8d4eba95c9432/defusedxml-0.7.1-py2.py3-none-any.whl\r\ndill @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/28/60/d3/32828bed02c4d7c32349419de5acbc87826c39d627804affa9a357ca4b/dill-0.3.4-py2.py3-none-any.whl\r\ndocker-pycreds @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/d8/39/1e/e7e74a2508ba56c50439f59cedea0b0b83433255ecfa7626aae74aef70/docker_pycreds-0.4.0-py2.py3-none-any.whl\r\nentrypoints @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/27/67/42/5ca7438658f76c8700ff6c44ea1cf9dc128cf0862adb7de53d3a35266c/entrypoints-0.3-py2.py3-none-any.whl\r\nfairscale @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/fa/92/f4/a8ff4216b2ef616172ef3ae34a26b8ac2b138172f68bd8512ca98b880a/fairscale-0.4.0.tar.gz\r\nfeedparser @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/aa/52/0a/5826fdb32a49126bc4790a960987feaadceb6d923f41500a4de5ef2c07/feedparser-6.0.8-py3-none-any.whl\r\nfilelock @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f4/78/c1/69555c3867649a2a5dac43f12a078830700480a49be273fb2de82be2ab/filelock-3.0.12-py3-none-any.whl\r\nflake8 @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/93/78/ae/ee75d1b46827f8892defc2a710979cc71803d2da75a049bdabd3adad70/flake8-3.9.2-py2.py3-none-any.whl\r\nfsspec @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/34/60/72/3b024eeebe678be8f6a267950b5b0fb1e649e1d087162576f3dd6c2b6c/fsspec-2021.10.1-py3-none-any.whl\r\nftfy @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f6/d1/2c/db46cdd19a4799ff0bc2fb1cfcd8912d7be819f91ae38cccbcd7885cca/ftfy-6.0.3.tar.gz\r\nfuture @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/d9/62/dc/809bb3ddfe360ddc60ebb287ad6b0eaf71aef98937f0ea0c466d44aa19/future-0.18.2.tar.gz\r\ngitdb @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/04/0e/cf/315c241493e86260bce0499c9a41b201c16d4c408d14259d1fb78f2dba/gitdb-4.0.7-py3-none-any.whl\r\nGitPython @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/65/50/fc/efadf2a96d18ae3443681e0d98d082d735e62ebb53f1f46312a4e6ca57/GitPython-3.1.24-py3-none-any.whl\r\ngoogle-api-core @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/df/19/49/576fc9447a455a79e3a9a57cba6435b47f9a146b9429c73b57dbf80faf/google_api_core-2.1.1-py2.py3-none-any.whl\r\ngoogle-auth @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/13/4d/3e/c4dc56fe3580ddc0be70ad157f7b63f7bd4184270d3dcc741a3e7032c6/google_auth-2.3.0-py2.py3-none-any.whl\r\ngoogle-cloud-core @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/35/2e/bd/b38f62629276e20104e18e7d27e93d6673f68e9c3d27d48c6b470c9321/google_cloud_core-2.1.0-py2.py3-none-any.whl\r\ngoogle-cloud-storage @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/55/a3/4b/c0107363aa1a1b566b15d06baf5ccd9eb820229d58aa247d6f5e2b79b3/google_cloud_storage-1.42.3-py2.py3-none-any.whl\r\ngoogle-crc32c @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/37/48/05/a1631635edda209ce80b9ecb6e0678262bf3a0f30fde8674fc1bd3245e/google_crc32c-1.3.0-cp38-cp38-macosx_10_9_x86_64.whl\r\ngoogle-resumable-media @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/2d/c8/79/2f89c7a2afafab389d62c8e123c9c083e982e078a5a05d04e7967b5e6e/google_resumable_media-2.0.3-py2.py3-none-any.whl\r\ngoogleapis-common-protos @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/8c/2e/ad/efdce99c62dbe56fda156dd62f807ea79a43f83dea45bd9f9ff4bc6240/googleapis_common_protos-1.53.0-py2.py3-none-any.whl\r\nh5py @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/be/59/fa/8583e2f8bb9d66efdfe56f10669c984c3531e4ebce40eb474d2a52754a/h5py-3.4.0-cp38-cp38-macosx_10_9_x86_64.whl\r\nhuggingface-hub @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/53/9e/4d/9ef09205045d9886788cd70f1f7cf516e41da3691ab8000f381da616dc/huggingface_hub-0.0.19-py3-none-any.whl\r\nhypothesis @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/17/1d/e1/a12fe47a0ba064f8e62294e4b29cf5e7d32164b0186cf6092f8a7eabb9/hypothesis-6.23.3-py3-none-any.whl\r\nidna @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f7/09/c9/8e80952436ff87855ddff4891a35ecf913b2b5dc97911f02a070ff2b1f/idna-3.3-py3-none-any.whl\r\niniconfig @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/ac/f9/da/e990ffcd9ec361a68676a5916e391286e1ea5d1b8907ae887e141a71f5/iniconfig-1.1.1-py2.py3-none-any.whl\r\nipykernel @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f4/a2/97/0b967c5d149ef3cbde87b844ad05b0391783a9af93b1eb947f872ae38d/ipykernel-6.4.1-py3-none-any.whl\r\nipython @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f7/92/5e/e887b7585d67c295cb815d828bc8892c281feb8826447b699fac96d520/ipython-7.28.0-py3-none-any.whl\r\nipython-genutils @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/e6/8e/a3/8f37e14310c0072b3fcc4240490bcb42630aa695d069aee89953ebd9f8/ipython_genutils-0.2.0-py2.py3-none-any.whl\r\nipywidgets @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/13/b5/43/b938f79239314b91a8160cdd8ff1644168cad0aef195945834a185c620/ipywidgets-7.6.5-py2.py3-none-any.whl\r\niso-639 @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/df/a4/b2/6573e801cd5b1443ea8f62ef82096a6a7cb706ff16c480e7811f9f95a9/iso-639-0.4.5.tar.gz\r\njaraco.classes @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/06/2a/9b/c3f7f1dc3409472aac3fa75571ec4f9c5fdf9724ba95aa0d3857e993fd/jaraco.classes-3.2.1-py3-none-any.whl\r\njaraco.collections @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/10/78/fb/1453da786fa6ee3c9d9c620a49cd022239dded61be2c6b5a727260dfad/jaraco.collections-3.4.0-py3-none-any.whl\r\njaraco.functools @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/5e/70/c8/fd61c1b3830aae625b240e7420442742de5b64790eba20ce95be9b2b36/jaraco.functools-3.3.0-py3-none-any.whl\r\njaraco.text @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/51/e4/2a/f0fbc9f217e7c8574db5bca1abf0398d6cfbb62a0ed6c4377a2366d435/jaraco.text-3.5.1-py3-none-any.whl\r\njedi @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/42/26/07/496d2180e241dbf58cf832e0c7a617d8fcbdd6f3f93937056d106545fc/jedi-0.18.0-py2.py3-none-any.whl\r\nJinja2 @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/bc/7e/94/a305d7942db6684c4e372c6d8c89d1df206e8c88517a7b5b0dffbbf29e/Jinja2-3.0.2-py3-none-any.whl\r\njmespath @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/43/d5/a2/f83573231324de7f5b61f5c607fbbe82ca535359a452de4852d2e25e8d/jmespath-0.10.0-py2.py3-none-any.whl\r\njoblib @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/9b/a3/77/11a58dff170042277b83b2abf4a83664b0ef3c048f0cccee2b204ed842/joblib-1.1.0-py2.py3-none-any.whl\r\njson5==0.9.6\r\njsonnet @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/23/ba/91/41be2f00e06a18e8c220311460dc643bb9975fe5bbf08a3e0017e887fb/jsonnet-0.17.0.tar.gz\r\njsonpickle @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/a3/43/36/9eb7c32fbeffd93e855d2090f208d1bb0660f56aa2e6d0a7234c3faae2/jsonpickle-2.0.0-py2.py3-none-any.whl\r\njsonschema @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/33/bd/57/7f6d7f5f991bc085a9fddc45d80bad9314919b6ae7f0da38dea4f739e3/jsonschema-4.1.0-py3-none-any.whl\r\njupyter @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/2e/44/a0/764f7d3907f220eb94db0e2bce1f8f3e50dcb48aca15a625dd210cb114/jupyter-1.0.0-py2.py3-none-any.whl\r\njupyter-client @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/cd/1f/33/dafe8bc6a70871d969c9f5c4539659af33f71e0067aef55315b491caa8/jupyter_client-7.0.6-py3-none-any.whl\r\njupyter-console @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/a4/52/39/18f8e5a28b25875a9251e900d0d749e9c28310b3ce786ba4ecd67c2e45/jupyter_console-6.4.0-py3-none-any.whl\r\njupyter-core @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/21/d9/04/1f31168a9142ce3d567d44960411c87f47a2fdcebc083307f80d6e151b/jupyter_core-4.8.1-py3-none-any.whl\r\njupyter-server==1.11.0\r\njupyterlab==3.1.13\r\njupyterlab-pygments @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/c8/b0/10/ad75ecf240424057a12f5b4320da2c9f380541cdf830a39e7e8437c2c0/jupyterlab_pygments-0.1.2-py2.py3-none-any.whl\r\njupyterlab-server==2.8.1\r\njupyterlab-widgets @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/4b/3f/13/7f7e8014e6ea67fab4a942882d870d27a15971f08b0b2660b4cdbcd03f/jupyterlab_widgets-1.0.2-py3-none-any.whl\r\nkiwisolver==1.3.2\r\nlmdb @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/ab/59/27/94188b63ed5f8e062d4671d2bcde446c8cf73ac892dbdcbe4db746ba79/lmdb-1.2.1-cp38-cp38-macosx_10_14_x86_64.whl\r\nlxml @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/b0/c3/1f/bde91e88c462e522b16a3b38fab74d4d32aea11d19262a02ea3cbdadd5/lxml-4.6.3-cp38-cp38-macosx_10_9_x86_64.whl\r\nMarkupSafe @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/cd/11/54/fd481eec49cddc06876e526483e7ee8675d0910fed2aa7668a9fc88e62/MarkupSafe-2.0.1-cp38-cp38-macosx_10_9_x86_64.whl\r\nmatplotlib==3.4.3\r\nmatplotlib-inline @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/99/9e/a7/697624e74ebe7195097dbec4fe8bff67cf73c04390b69235ab5d6433b3/matplotlib_inline-0.1.3-py3-none-any.whl\r\nmccabe @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/37/6e/69/4a33a4d6c80c775b1ee205face2c6e07b762c8602bb0f0d236ebe790c5/mccabe-0.6.1-py2.py3-none-any.whl\r\nmistune @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/d9/d8/5c/8eac14aaa95c3aa81409d56b7423ff6dd88eb398f551c1bf0b8c05b916/mistune-0.8.4-py2.py3-none-any.whl\r\nmore-itertools @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/e5/d6/53/7e4b7c402487c7aa47865c0155ca95057fd385fcf3d331fb0535f7bf38/more_itertools-8.10.0-py3-none-any.whl\r\nmultidict @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/ce/07/97/96c8c0778bcefb790a0e0509f8f3114fc02f75a074477cac59c5174797/multidict-5.2.0-cp38-cp38-macosx_10_9_x86_64.whl\r\nmultiprocess @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/ca/0c/50/4fa4087501423c3e6a0e07cf9e4293cb262c98689b0a5da0bcc0ee4148/multiprocess-0.70.12.2-py38-none-any.whl\r\nmunch @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/8a/51/90/b6d8e8acd78aee2f686f94d1d64b52cc649a194f0b71c3e083bc2c4abf/munch-2.5.0-py2.py3-none-any.whl\r\nmurmurhash @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/e4/76/e6/55d7b3ff6a76e1d5a66a445a5a76d831adecb7840c89ffa3c847a6f17d/murmurhash-1.0.5-cp38-cp38-macosx_10_9_x86_64.whl\r\nmypy @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/ab/cc/97/d2bf236a86ad0c9b4134b069009b132ec469a131579fe22d5d52e43974/mypy-0.910-cp38-cp38-macosx_10_9_x86_64.whl\r\nmypy-extensions @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/b6/a0/b0/a5dc9acd6fd12aba308634f21bb7cf0571448f20848797d7ecb327aa12/mypy_extensions-0.4.3-py2.py3-none-any.whl\r\nnbclassic==0.3.2\r\nnbclient @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/4a/28/12/0bec26bfe28eff423fdd8b3e3f361ef308eb3a1b77b95c30c126350672/nbclient-0.5.4-py3-none-any.whl\r\nnbconvert @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/3d/9f/ac/586455af84e0714a231e09a125e6a20029577b22c8b9d5ae3bf2378c95/nbconvert-6.2.0-py3-none-any.whl\r\nnbformat @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/50/21/dd/ed31613a2f0fda01bcb038557b711726da40cbe5b483cf13719918d6b0/nbformat-5.1.3-py3-none-any.whl\r\nnest-asyncio @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f5/d1/32/8bc78b4ee2a2d3a377491872fe5aa705448a863af0bb0968676a0e2d3b/nest_asyncio-1.5.1-py3-none-any.whl\r\nnetworkx @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/fa/4f/d3/e7fe0bef76afda6c21516d0f99c5a4f7c81b8aea2c884477bcb331d2f4/networkx-2.6.3-py3-none-any.whl\r\nnltk @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/eb/6c/95/719c7a3727a2f3caacddac4c5b5db9e76ff0fc027e56fe4520292c74fd/nltk-3.6.5-py3-none-any.whl\r\nnotebook @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/98/21/17/b4e544779a6e1a6e8c202d4c60a8382d869181d958754ad37c69ad82f2/notebook-6.4.4-py3-none-any.whl\r\nnumpy @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/da/3c/db/6f799cf4a5e87e3d4e53ac7a1b5a9f6638f4b6cc5122ccf3286d2ac802/numpy-1.21.1-cp38-cp38-macosx_10_9_x86_64.whl\r\noverrides @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/2e/a1/58/bef997b290151ed8dc40c8873f5a581732643e73c41da963ab65b75838/overrides-3.1.0.tar.gz\r\npackaging @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/6e/de/e5/e3e7e60b359c616435089a1dd11b101dc553fae21fca74bbe98d0c323e/packaging-21.0-py3-none-any.whl\r\npandas @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/01/67/d5/6fde19dd1d9f25e899b24eb3acfecaf25a53aa9c8e76ec8f58595bddfc/pandas-1.3.4-cp38-cp38-macosx_10_9_x86_64.whl\r\npandocfilters @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/a0/1a/aa/08b056cf02efdac22abd6440fea5dbb93be4fe8c9c1f33c6d6f8795de7/pandocfilters-1.5.0-py2.py3-none-any.whl\r\nparso @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/22/e1/fb/1f6342ec76fc3368aca0b5266c38f9a44c03e1003f904397fd31c0df0c/parso-0.8.2-py2.py3-none-any.whl\r\npathspec @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/04/91/14/294ed2ee6c852b0d466bdd15d393127eff4168b35ae81cedf5a03fe348/pathspec-0.9.0-py2.py3-none-any.whl\r\npathtools @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/db/27/0c/42fa00f22356328dc3bd6da21aae59384ad7f36690fe5ca5495586560f/pathtools-0.1.2.tar.gz\r\npathy @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/9e/df/8b/1b7de6047d48d9b82dcf31e899ef9d07e2bf97241956d3acdb62af271c/pathy-0.6.0-py3-none-any.whl\r\npatternfork-nosql @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/2a/8a/10/3ffc35b9958e7c2fe26d577c221508d170be8768aa92eb9212d7c8d061/patternfork_nosql-3.6.tar.gz\r\npdfminer.six @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/c0/ec/8d/6d1984532bf0bef70e3e34b224a230e18acfa90d8d85068e3f4bf49027/pdfminer.six-20211012-py3-none-any.whl\r\npexpect @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/c0/05/08/f23ddb8e3d5b19e7cf01eb434220310be2aaf69226bdec78bc53589024/pexpect-4.8.0-py2.py3-none-any.whl\r\npickleshare @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/27/b2/0a/93a92c700a1993b2923519262ddf76a629bd459a0597c0ae28bf80c7a6/pickleshare-0.7.5-py2.py3-none-any.whl\r\nPillow @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/c9/53/2f/e945b6916e89751d135bc88d397e10fd6e5adb24f0cd89e037fa67e8ae/Pillow-8.4.0-cp38-cp38-macosx_10_10_x86_64.whl\r\nplatformdirs @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/c2/ba/64/b6513f98bf6524a0ec2316e6f9326829bf25522e915b9965b0e55b969b/platformdirs-2.4.0-py3-none-any.whl\r\npluggy @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/38/05/d7/70e2b0d553c780097b692ed658b0f553a28f16028d848a98174b1a2249/pluggy-1.0.0-py2.py3-none-any.whl\r\nportend @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/bc/af/52/69884c4cd721d7775dcc7593f513479170204e31ab750643b8fe80f7fd/portend-3.0.0-py3-none-any.whl\r\npreshed @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/87/8c/8d/a9fcfd95b2ab9272af32f4480cbc7c58f297d5ea2df53367579e0a57b4/preshed-3.0.5-cp38-cp38-macosx_10_9_x86_64.whl\r\nprometheus-client @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/00/18/42/94cd084834c473ccb4fc3413137856974fb5a4423d3cfe615faf442dd0/prometheus_client-0.11.0-py2.py3-none-any.whl\r\npromise @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/0f/4f/91/54827555a9ce3597aca6d8a5ca3066e4cbdeb55dfc09e7dd69e113cec7/promise-2.3.tar.gz\r\nprompt-toolkit @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/49/72/f2/5d1b0ad43dfb0689c7ae8a457baa705bacdaec338077a13f807686fefd/prompt_toolkit-3.0.20-py3-none-any.whl\r\nprotobuf @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/ac/85/1a/e8ab87755d8a0d6589f086e98d5dcb1b65995476c00ab95b92fa124c9c/protobuf-3.18.1-cp38-cp38-macosx_10_9_x86_64.whl\r\npsutil @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/84/fa/d1/12147def50aecb1f1a65f19fac48db25f0edc692fafb01a6809daf4995/psutil-5.8.0-cp38-cp38-macosx_10_9_x86_64.whl\r\nptyprocess @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/b5/84/64/9519e6926ac101cbc8d93423b8165f4abac4f8a8e3e099f74d3c7e0e67/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npy @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/6b/b2/2b/e6686e7d0183dbd36bd66921efa3e77ce26260a3671524cd86614290e0/py-1.10.0-py2.py3-none-any.whl\r\npy-rouge @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/8c/da/8b/765cd7f7641eb25264c1d00e40e19d69d198c3f838160614aa34ff2fc7/py_rouge-1.1-py3-none-any.whl\r\npyarrow @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/60/9d/e0/55d4f2f56315901aeeed8bedad29454ebbcc11937b1586b0183bbb8a70/pyarrow-5.0.0-cp38-cp38-macosx_10_13_x86_64.whl\r\npyasn1 @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/a6/f7/5e/59a43ec23ade0888631b3f24244da7f5d5a0b6b40849c86b8c6b4c54d1/pyasn1-0.4.8-py2.py3-none-any.whl\r\npyasn1-modules @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/09/f6/56/0e33158234b3e9b9e5d8eb01e7a96670a99ab43b3dbe89b0f129477a59/pyasn1_modules-0.2.8-py2.py3-none-any.whl\r\npycodestyle @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/ea/27/4a/ce8e18f033aae28e47dc2895901dce76e10e7c9efc48bcd95ab4443c47/pycodestyle-2.7.0-py2.py3-none-any.whl\r\npycparser @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f1/03/25/40eb46f7bede64f78ba073e2141b8216e611cbcde72e3117c326560101/pycparser-2.20-py2.py3-none-any.whl\r\npydantic @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/d2/99/3c/bffa7ba1ed68effa728f5766fd9b626a4ecf01b7635d3e3ff1c09c6ed8/pydantic-1.8.2-cp38-cp38-macosx_10_9_x86_64.whl\r\npyflakes @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/b0/73/41/34d4d02987e40ffa6ee0292425303a75b4178476bf134ceaf0585a9faf/pyflakes-2.3.1-py2.py3-none-any.whl\r\nPygments @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/0f/4e/ff/68a1ec60d16d43c7f126ec7a6834ec8300bf293c7fa5ab34831a7f2211/Pygments-2.10.0-py3-none-any.whl\r\npyparsing @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/da/e7/3d/1780282f558e5fd157bf708b28b8ba0d08323ef6bc5b6396139ce38a0b/pyparsing-2.4.7-py2.py3-none-any.whl\r\npyrsistent @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/72/05/80/43e73cc485a2fd76c8e9ba4d5e41b31ef57e6f90bf82079ad3a49fa0b8/pyrsistent-0.18.0-cp38-cp38-macosx_10_9_x86_64.whl\r\npytest @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/90/e1/d5/985c1b371486cf5749ce1ec1beac04524dacb0642a52d916fd1aa82671/pytest-6.2.5-py3-none-any.whl\r\npytest-cov @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/ce/cd/a2/2d987485d9ccd39e0e4c99f44afb2031232743eb1ec04c4ccf1c3d3b44/pytest_cov-3.0.0-py3-none-any.whl\r\npython-dateutil @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/0f/f1/e2/e1d3399cea26388e2ed5b93ea3e7c137d2b4027c5ba14c64ab839294ed/python_dateutil-2.8.2-py2.py3-none-any.whl\r\npython-docx @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/a6/64/06/a932c2eb8f96e71ce6b90c535a1971c0dfa110ee1cc554f3f6f38eb0b0/python-docx-0.8.11.tar.gz\r\npytz @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/07/c1/43/6f22a533e7bc5e277f10b4c6033e936ff7bbeb6464e5f27dbfb6c641d7/pytz-2021.3-py2.py3-none-any.whl\r\npyvis @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f2/11/9b/2a8f163989cf6da31959f8055ae0914f2a4da74425170f2a8af79d5061/pyvis-0.1.9-py3-none-any.whl\r\nPyYAML @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f0/ae/ac/3d7d408acba599bb6f26145f4ccfa63e42769a71f67bc8d5b643946261/PyYAML-6.0-cp38-cp38-macosx_10_9_x86_64.whl\r\npyzmq @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/d4/18/cd/4b50de2fe36cddc0a2c570dea01dc7a2322ad65edb2340dd2c503656d4/pyzmq-22.3.0-cp38-cp38-macosx_10_9_x86_64.whl\r\nqtconsole @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/a4/47/34/7fe2401249a490f591453e6116bfe86c553175b2148660b88324f7e994/qtconsole-5.1.1-py3-none-any.whl\r\nQtPy @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/bd/f0/f0/53d1c1d12ddbebbe885aa7066c4d551b514f25fa970c1ff6c853dd23bd/QtPy-1.11.2-py2.py3-none-any.whl\r\nregex @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/82/f8/be/afa0d92da049895e643ec6adaad8030302f076f3a9231e5bd2b38cb67f/regex-2021.10.8-cp38-cp38-macosx_10_9_x86_64.whl\r\nrequests @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/97/12/e1/3c2e2b7f315a912e2da1b1465a23c3f14d51a3bd4696e14e0f2796adde/requests-2.26.0-py2.py3-none-any.whl\r\nrequests-unixsocket==0.2.0\r\nrsa @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/3a/ab/43/a67c8d818350593872a5713ca125b95f465d62eee5ba7895de1194add1/rsa-4.7.2-py3-none-any.whl\r\ns3transfer @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/c4/3d/ac/f736ad58b798b0dccee9e9ba7ed0493385c74f952b5f04c10dfb563877/s3transfer-0.5.0-py3-none-any.whl\r\nsacremoses @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/35/e8/a7/c74242481a266a99136f3fa39a5210170ba5c33052b750843b794f1a60/sacremoses-0.0.46-py3-none-any.whl\r\nscikit-learn @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/09/ca/db/46fdde8f503c9a1bd55bdf588b8f18dd36b2eded7d0532f83527ce74f4/scikit_learn-1.0-cp38-cp38-macosx_10_13_x86_64.whl\r\nscipy @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/98/e6/9a/ec37b4d476e93b73a6ac9e134ac65839185bd9428c87e4913a614f1f80/scipy-1.6.1-cp38-cp38-macosx_10_9_x86_64.whl\r\nSend2Trash @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/04/75/07/732af573e27a23b54c8ecd612eadc3725f0ce6428aee277184a4d0c780/Send2Trash-1.8.0-py3-none-any.whl\r\nsentencepiece @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/c2/54/b6/bdf5712fbf6c8df51afce96a9ef8954dd601ebfce81ea653375a13292f/sentencepiece-0.1.96-cp38-cp38-macosx_10_6_x86_64.whl\r\nsentry-sdk @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/aa/f9/f5/e3e2f5afb33f1f7c4f81e0d5a3320138b5da41db1d61659a614dc8da78/sentry_sdk-1.4.3-py2.py3-none-any.whl\r\nseq2rel==0.1.0\r\nsgmllib3k @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/7f/ff/47/daedf070ffb84ea157ae769afcd95b6085d6bb88fa9d54b93011cf5f6b/sgmllib3k-1.0.0.tar.gz\r\nshellingham @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/4b/83/6d/e35ec68166f5c637275dcae5c8411bbc624f69306d927f7e46b2a3e278/shellingham-1.4.0-py2.py3-none-any.whl\r\nshortuuid @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/d1/e0/1d/1f9cb7b3ab6fabb17fe7420dd453db16d7ba50a15deb1b234eb320b2b4/shortuuid-1.0.1-py3-none-any.whl\r\nsix @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/48/e6/04/8118155ae3ec3a16dd2a213bbf7a7d8a62c596b2e90f73a22c896269f1/six-1.16.0-py2.py3-none-any.whl\r\nsmart-open @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/26/81/76/40a70723fc34dccdf893387d11e40c3dd3a59c46fb6b461944136fbe4b/smart_open-5.2.1-py3-none-any.whl\r\nsmmap @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/1e/d8/13/34940d459f5ed772e4b4e7b376b8b694f793d766785e9e8700188a8d5f/smmap-4.0.0-py2.py3-none-any.whl\r\nsniffio==1.2.0\r\nsortedcontainers @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/8f/31/be/2d0a228ecadbc21e65b90453a4055bb3a48b0b098ed3e0ca8cafa85629/sortedcontainers-2.4.0-py2.py3-none-any.whl\r\nsoupsieve @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/b8/a8/7f/9e40f555a1f9d45c0bee1c0968b363dd999d2beb5b111eec78c11e9203/soupsieve-2.2.1-py3-none-any.whl\r\nspacy @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/75/15/af/dbec3d052bdbf4584feef13bb6960fb62e72568826b9b6df1f847dc209/spacy-3.1.3-cp38-cp38-macosx_10_9_x86_64.whl\r\nspacy-legacy @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/c0/27/a2/5a30c4f2acd541e62cba27834a6f07bbe740c8b29f0677e7843ce81ce0/spacy_legacy-3.0.8-py2.py3-none-any.whl\r\nsqlitedict @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/cd/26/1c/f4f445a24f194f21b8c96459eaf76398dc434a978d7f07fbd6e3bac1d2/sqlitedict-1.7.0.tar.gz\r\nsrsly @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/6a/56/a1/06cc4a4e9f2a83dca3c26267804a8d489500fc7778aeb1627d8fee90ae/srsly-2.4.1-cp38-cp38-macosx_10_9_x86_64.whl\r\nsubprocess32 @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/ba/61/77/20064e3312c309728c4824cb725c398e0044f1e1afaa2be5482ea8e0fe/subprocess32-3.5.4.tar.gz\r\ntempora @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/4a/7f/bd/9999aec83cbafd80ca0e96379ddf30ede9aeeccce7511279425993092b/tempora-4.1.2-py3-none-any.whl\r\ntensorboardX @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/68/eb/3c/1605a551971ad0cea75ef1dcec3eea7add47711fe7a2cb25d38604a46d/tensorboardX-2.4-py2.py3-none-any.whl\r\ntermcolor @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/33/6b/61/45ca85fe93f3295319a6eb1d6a8d2d449b6fa6d17c2ed2ec1810196a4a/termcolor-1.1.0.tar.gz\r\nterminado @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/99/c0/03/31feee159a5291c183f98d53f6b00d169c3e4a21feb6a570ea1b34b066/terminado-0.12.1-py3-none-any.whl\r\ntestpath @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/99/c6/0c/2256a0fa1dbfdfee5595aa75497e3967a6a234852e7e76050fe51d18ed/testpath-0.5.0-py3-none-any.whl\r\nthinc @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/61/0f/1e/29a881f14c47a32cd52823be48b2347e9c236322664988aacc818b5950/thinc-8.0.10-cp38-cp38-macosx_10_9_x86_64.whl\r\nthreadpoolctl @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/20/bc/46/3ea1d0f54ff5ea38f5af47728f2dc93c2bd79a4ab3fb58f74cec723c35/threadpoolctl-3.0.0-py3-none-any.whl\r\ntokenize-rt==4.1.0\r\ntokenizers @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/9b/b5/e5/a3cea2a9e667e964792e0961f23412fcce905661a6f90a4136d2c07637/tokenizers-0.10.3-cp38-cp38-macosx_10_11_x86_64.whl\r\ntoml @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/9f/8c/c3/7b4f6778d60f3c9fa11f8fd0e48243bbad25a04975e0a01006b6350594/toml-0.10.2-py2.py3-none-any.whl\r\ntomli @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/66/79/ff/273065eae5d047b67af1ec99ed8abcb1769f67f1d7ca537d0a07beac40/tomli-1.2.1-py3-none-any.whl\r\ntorch @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/3d/3a/9b/1511a1faddd2fd32bfbb5e99faff69a1679e0c29098ec6a856666990b3/torch-1.9.1-cp38-none-macosx_10_9_x86_64.whl\r\ntorchvision @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/0a/f4/97/d909a6605c2d653a4b11c0c0dd4189b55c7d654d65c6788332ef9c07d3/torchvision-0.10.1-cp38-cp38-macosx_10_9_x86_64.whl\r\ntornado @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f8/e3/41/917f42a91e332f48e4150ee97f1c569a747bb58d2db08b1aa8a794fe06/tornado-6.1-cp38-cp38-macosx_10_9_x86_64.whl\r\ntqdm @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/cc/00/d6/11a230005951f04ebcf5e304ef217666e8e0f5fed12661971a4988bb2d/tqdm-4.62.3-py2.py3-none-any.whl\r\ntraitlets @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/b6/cc/f0/bf72aeacb5d520e3c0e1cb45914bc5799a08f52788d89a62014f8bf35d/traitlets-5.1.0-py3-none-any.whl\r\ntransformers @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/e4/9f/e9/b54bc81ee849bd9317d3327485aed385538f982612b48e692d6ad733af/transformers-4.5.1-py3-none-any.whl\r\ntyper @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/50/84/0e/12de0984fa7c3b0360303fd4df9b8f70ef49467ebc690e78371c7b4681/typer-0.4.0-py3-none-any.whl\r\ntyping-extensions @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/63/00/66/294e7d75d34398c27c7ed9b154822f99422b0f11548b11c569c188eb2b/typing_extensions-3.10.0.2-py3-none-any.whl\r\nurllib3 @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/d8/12/e2/1b499db5e41e88fd0f31d0e056a4dc7b53824f63f027fffc1702969c57/urllib3-1.26.7-py2.py3-none-any.whl\r\nvalidators @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/9b/76/01/4344dc10a31836ed299d8699acd5da84d5bf170de6953be4e58cce86c8/validators-0.18.2-py3-none-any.whl\r\nwandb @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/e4/26/83/dc36e5102ad1991ce452baedf1c8103fbbeb2e044b55ee206f6fe4741c/wandb-0.12.4-py2.py3-none-any.whl\r\nwasabi @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/42/4a/9d/f75bd98be0123c02fb2a2dbb95d920914b644aced2fc781e2e4111685d/wasabi-0.8.2-py3-none-any.whl\r\nwcwidth @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/36/68/e2/7232f431072d5e8aeec124120b9a1d095d45da10311d271fac10982473/wcwidth-0.2.5-py2.py3-none-any.whl\r\nwebencodings @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/60/1e/b4/eff9915b6506bb01a5ad61dfae3fa4f0302be9e2ad45eaccc833925b95/webencodings-0.5.1-py2.py3-none-any.whl\r\nwebsocket-client==1.2.1\r\nwidgetsnbextension @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/4f/c4/8c/95c9c932a9649e98240304b336a4c725419ee2fd517897c94b817722d6/widgetsnbextension-3.5.1-py2.py3-none-any.whl\r\nword2number @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/f1/a2/d9/65e48a223ce6054ccc45f9ba049ee4ce8b8000656ddebb233642b52225/word2number-1.1.zip\r\nxxhash @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/dc/56/52/d7f0d297596fcfd5794d8b7bc54962a27cedd0b9467ec2b24b83a18230/xxhash-2.0.2-cp38-cp38-macosx_10_9_x86_64.whl\r\nyarl @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/44/09/c8/d10accf5175f19f5916c186ccd3f809722d6cc0459e7d47f2dd56c9cce/yarl-1.7.0-cp38-cp38-macosx_10_9_x86_64.whl\r\nyaspin @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/c9/f9/85/a7745419a7b786e5bd6b91a6b9bdae7a4612671ecd52c2cd2703ff061b/yaspin-2.1.0-py3-none-any.whl\r\nzc.lockfile @ file:///Users/johngiorgi/Library/Caches/pypoetry/artifacts/8a/7d/4d/87319be2a2e6f3fc33151575541b353af4ba6a4ac928bb1d3c1f5d64e1/zc.lockfile-2.0-py2.py3-none-any.whl\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```python\r\nfrom allennlp.data.tokenizers import PretrainedTransformerTokenizer\r\nfrom allennlp_models.generation import Seq2SeqDatasetReader\r\nfrom allennlp.common.util import START_SYMBOL, END_SYMBOL\r\n\r\nsource_tokenizer = PretrainedTransformerTokenizer(\"bert-base-uncased\", add_special_tokens=True)\r\n\r\n# Set up a target tokenizer so it is compatible with `start_symbol` and `end_symbol`\r\ntokenizer_kwargs = {\"additional_special_tokens\": [START_SYMBOL, END_SYMBOL]}\r\ntarget_tokenizer = PretrainedTransformerTokenizer(\"bert-base-uncased\", add_special_tokens=False, tokenizer_kwargs=tokenizer_kwargs)\r\n\r\n# Raises ValueError\r\nreader = Seq2SeqDatasetReader(\r\n    source_tokenizer=source_tokenizer,\r\n    target_tokenizer=target_tokenizer,\r\n    source_add_start_token=False,\r\n    source_add_end_token=False,\r\n    start_symbol=START_SYMBOL,\r\n    end_symbol=END_SYMBOL\r\n)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5451/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5451/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5444", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5444/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5444/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5444/events", "html_url": "https://github.com/allenai/allennlp/issues/5444", "id": 1033708646, "node_id": "I_kwDOBXH8-M49nSRm", "number": 5444, "title": "Assertion error when keep_most_recent_by_count = 0 and moving_average = None", "user": {"login": "ksteimel", "id": 25189520, "node_id": "MDQ6VXNlcjI1MTg5NTIw", "avatar_url": "https://avatars.githubusercontent.com/u/25189520?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ksteimel", "html_url": "https://github.com/ksteimel", "followers_url": "https://api.github.com/users/ksteimel/followers", "following_url": "https://api.github.com/users/ksteimel/following{/other_user}", "gists_url": "https://api.github.com/users/ksteimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ksteimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ksteimel/subscriptions", "organizations_url": "https://api.github.com/users/ksteimel/orgs", "repos_url": "https://api.github.com/users/ksteimel/repos", "events_url": "https://api.github.com/users/ksteimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ksteimel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2021-10-22T15:32:15Z", "updated_at": "2021-11-26T16:09:40Z", "closed_at": "2021-11-26T16:09:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nWhen training a model using a config with `keep_most_recent_by_count` set to `0` and `moving_average` set to `None`, the `GradientDescentTrainer` throws an assertion error just before trying to copy the model state checkpoint. This worked on allennlp version 2.4 (when the parameter was `num_serialized_models_to_keep`). However on 2.7 and main this error is thrown. Changing either of these (e.g. using a moving average or setting `keep_most_recent_by_count` to a non-zero value), prevents this error from being raised.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\naccuracy: 0.7500, accuracy3: 1.0000, batch_loss: 0.6267, loss: 0.6267 ||: 100%|##########| 1/1 [00:00<00:00, 332.56it/s]\r\n2021-10-22 11:13:32,397 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation\r\n2021-10-22 11:13:32,397 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.750  |     0.750\r\n2021-10-22 11:13:32,397 - INFO - allennlp.training.callbacks.console_logger - accuracy3          |     1.000  |     1.000\r\n2021-10-22 11:13:32,397 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.627  |     0.627\r\n2021-10-22 11:13:32,397 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |   432.031  |       N/A\r\n2021-10-22 11:13:32,401 - CRITICAL - root - Uncaught exception\r\nTraceback (most recent call last):\r\n  File \"/usr/local/homebrew/Caskroom/miniconda/base/envs/ets_nlp_allennlp_models/bin/allennlp\", line 33, in <module>\r\n    sys.exit(load_entry_point('allennlp', 'console_scripts', 'allennlp')())\r\n  File \"/Users/ksteimel/Documents/Projects/allennlp/allennlp/__main__.py\", line 46, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/Users/ksteimel/Documents/Projects/allennlp/allennlp/commands/__init__.py\", line 123, in main\r\n    args.func(args)\r\n  File \"/Users/ksteimel/Documents/Projects/allennlp/allennlp/commands/train.py\", line 112, in train_model_from_args\r\n    train_model_from_file(\r\n  File \"/Users/ksteimel/Documents/Projects/allennlp/allennlp/commands/train.py\", line 178, in train_model_from_file\r\n    return train_model(\r\n  File \"/Users/ksteimel/Documents/Projects/allennlp/allennlp/commands/train.py\", line 254, in train_model\r\n    model = _train_worker(\r\n  File \"/Users/ksteimel/Documents/Projects/allennlp/allennlp/commands/train.py\", line 504, in _train_worker\r\n    metrics = train_loop.run()\r\n  File \"/Users/ksteimel/Documents/Projects/allennlp/allennlp/commands/train.py\", line 577, in run\r\n    return self.trainer.train()\r\n  File \"/Users/ksteimel/Documents/Projects/allennlp/allennlp/training/gradient_descent_trainer.py\", line 769, in train\r\n    metrics, epoch = self._try_train()\r\n  File \"/Users/ksteimel/Documents/Projects/allennlp/allennlp/training/gradient_descent_trainer.py\", line 912, in _try_train\r\n    assert last_checkpoint is not None\r\nAssertionError\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: MacOS 11\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.12\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nappnope==0.1.2\r\nargon2-cffi==21.1.0\r\nasync-timeout==3.0.1\r\nattrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1620387926260/work\r\nbackcall==0.2.0\r\nbackports.csv==1.0.7\r\nbase58==2.1.0\r\nbeautifulsoup4==4.10.0\r\nbleach==4.1.0\r\nblis==0.7.4\r\nboto3 @ file:///home/conda/feedstock_root/build_artifacts/boto3_1634782393307/work\r\nbotocore @ file:///home/conda/feedstock_root/build_artifacts/botocore_1634773831616/work\r\nbrotlipy==0.7.0\r\ncached-property @ file:///home/conda/feedstock_root/build_artifacts/cached_property_1615209429212/work\r\ncachetools==4.2.4\r\ncatalogue==2.0.6\r\ncertifi==2021.10.8\r\ncffi @ file:///Users/runner/miniforge3/conda-bld/cffi_1631636289798/work\r\nchardet @ file:///Users/runner/miniforge3/conda-bld/chardet_1610093477312/work\r\ncharset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1626371162869/work\r\nchecklist==0.0.11\r\ncheroot==8.5.2\r\nCherryPy==18.6.1\r\nclick==7.1.2\r\ncolorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1602866480661/work\r\nconfigparser==5.0.2\r\ncoverage @ file:///Users/runner/miniforge3/conda-bld/coverage_1634003959650/work\r\ncryptography @ file:///Users/runner/miniforge3/conda-bld/cryptography_1634230528229/work\r\ncymem==2.0.5\r\ndataclasses==0.6\r\ndatasets==1.14.0\r\ndebugpy==1.5.1\r\ndecorator==5.1.0\r\ndefusedxml==0.7.1\r\ndill==0.3.4\r\ndocker-pycreds==0.4.0\r\nen-core-web-sm @ file:///home/conda/feedstock_root/build_artifacts/spacy-model-en_core_web_1626140665752/work/sm\r\nentrypoints==0.3\r\nfairscale==0.4.0\r\nfeedparser==6.0.8\r\nfilelock @ file:///home/conda/feedstock_root/build_artifacts/filelock_1589994591731/work\r\nfsspec==2021.10.1\r\nfuture==0.18.2\r\ngitdb==4.0.7\r\nGitPython==3.1.24\r\ngoogle-api-core==2.1.1\r\ngoogle-auth==2.3.0\r\ngoogle-cloud-core==2.1.0\r\ngoogle-cloud-storage==1.42.3\r\ngoogle-crc32c==1.3.0\r\ngoogle-resumable-media==2.0.3\r\ngoogleapis-common-protos==1.53.0\r\nh5py @ file:///Users/runner/miniforge3/conda-bld/h5py_1631559921610/work\r\nhuggingface-hub==0.0.19\r\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1609836280497/work\r\nimportlib-metadata @ file:///Users/runner/miniforge3/conda-bld/importlib-metadata_1630267509190/work\r\niniconfig @ file:///home/conda/feedstock_root/build_artifacts/iniconfig_1603384189793/work\r\nipykernel==6.4.2\r\nipython==7.28.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.5\r\niso-639==0.4.5\r\njaraco.classes==3.2.1\r\njaraco.collections==3.4.0\r\njaraco.functools==3.3.0\r\njaraco.text==3.5.1\r\njedi==0.18.0\r\nJinja2==3.0.2\r\njmespath @ file:///home/conda/feedstock_root/build_artifacts/jmespath_1589369830981/work\r\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1633637554808/work\r\njsonnet @ file:///Users/runner/miniforge3/conda-bld/jsonnet_1606064694325/work\r\njsonpickle @ file:///home/conda/feedstock_root/build_artifacts/jsonpickle_1618250231429/work\r\njsonschema==4.1.2\r\njupyter==1.0.0\r\njupyter-client==7.0.6\r\njupyter-console==6.4.0\r\njupyter-core==4.8.1\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.2\r\nlmdb @ file:///Users/runner/miniforge3/conda-bld/python-lmdb_1615637368298/work\r\nloguru @ file:///Users/runner/miniforge3/conda-bld/loguru_1618589874299/work\r\nlxml @ file:///Users/runner/miniforge3/conda-bld/lxml_1616532325069/work\r\nMarkupSafe==2.0.1\r\nmatplotlib-inline==0.1.3\r\nmistune==0.8.4\r\nmore-itertools @ file:///home/conda/feedstock_root/build_artifacts/more-itertools_1631893103191/work\r\nmultidict==5.2.0\r\nmultiprocess==0.70.12.2\r\nmunch==2.5.0\r\nmurmurhash==1.0.5\r\nmypy @ file:///Users/runner/miniforge3/conda-bld/mypy_1624396887604/work\r\nmypy-extensions @ file:///Users/runner/miniforge3/conda-bld/mypy_extensions_1610127398887/work\r\nnbclient==0.5.4\r\nnbconvert==6.2.0\r\nnbformat==5.1.3\r\nnest-asyncio==1.5.1\r\nnltk @ file:///home/conda/feedstock_root/build_artifacts/nltk_1633955089856/work\r\nnotebook==6.4.5\r\nnumpy @ file:///Users/runner/miniforge3/conda-bld/numpy_1634853074130/work\r\nolefile @ file:///home/conda/feedstock_root/build_artifacts/olefile_1602866521163/work\r\noverrides @ file:///home/conda/feedstock_root/build_artifacts/overrides_1592431494961/work\r\npackaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1625323647219/work\r\npandas==1.3.4\r\npandocfilters==1.5.0\r\nparso==0.8.2\r\npathtools==0.1.2\r\npathy==0.6.0\r\npatternfork-nosql==3.6\r\npdfminer.six==20211012\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow @ file:///Users/runner/miniforge3/conda-bld/pillow_1630696729270/work\r\nplac==1.1.3\r\npluggy @ file:///Users/runner/miniforge3/conda-bld/pluggy_1631522705346/work\r\nportend==3.0.0\r\npreshed==3.0.5\r\nprometheus-client==0.11.0\r\npromise==2.3\r\nprompt-toolkit==3.0.21\r\nprotobuf==3.18.1\r\npsutil @ file:///Users/runner/miniforge3/conda-bld/psutil_1618863837648/work\r\nptyprocess==0.7.0\r\npy @ file:///home/conda/feedstock_root/build_artifacts/py_1607783655754/work\r\npyarrow==5.0.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1593275161868/work\r\npydantic==1.8.2\r\nPygments==2.10.0\r\npyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1633192417276/work\r\npyparsing==2.4.7\r\npyrsistent==0.18.0\r\nPySocks @ file:///Users/runner/miniforge3/conda-bld/pysocks_1610291493748/work\r\npytest==6.2.5\r\npytest-cov @ file:///home/conda/feedstock_root/build_artifacts/pytest-cov_1633356845954/work\r\npython-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\r\npython-docx==0.8.11\r\npytz @ file:///home/conda/feedstock_root/build_artifacts/pytz_1633452062248/work\r\nPyYAML==6.0\r\npyzmq==22.3.0\r\nqtconsole==5.1.1\r\nQtPy==1.11.2\r\nregex @ file:///Users/runner/miniforge3/conda-bld/regex_1634800923165/work\r\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1626393743643/work\r\nrsa==4.7.2\r\ns3transfer @ file:///home/conda/feedstock_root/build_artifacts/s3transfer_1626384238958/work\r\nsacremoses @ file:///home/conda/feedstock_root/build_artifacts/sacremoses_1588857588528/work\r\nscikit-learn @ file:///Users/runner/miniforge3/conda-bld/scikit-learn_1632611439190/work\r\nscipy @ file:///Users/runner/miniforge3/conda-bld/scipy_1628206458939/work\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.4.3\r\nsgmllib3k==1.0.0\r\nshortuuid==1.0.1\r\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\r\nsmart-open==5.2.1\r\nsmmap==4.0.0\r\nsoupsieve==2.2.1\r\nspacy==3.1.0\r\nspacy-legacy==3.0.8\r\nsqlitedict==1.7.0\r\nsrsly==2.4.2\r\nsubprocess32==3.5.4\r\ntempora==4.1.2\r\ntensorboardX @ file:///home/conda/feedstock_root/build_artifacts/tensorboardx_1628560643999/work\r\ntermcolor==1.1.0\r\nterminado==0.12.1\r\ntestpath==0.5.0\r\nthinc==8.0.11\r\nthreadpoolctl @ file:///home/conda/feedstock_root/build_artifacts/threadpoolctl_1633102299089/work\r\ntokenizers==0.10.3\r\ntoml @ file:///home/conda/feedstock_root/build_artifacts/toml_1604308577558/work\r\ntomli @ file:///home/conda/feedstock_root/build_artifacts/tomli_1628264172148/work\r\ntorch==1.7.0\r\ntorchvision==0.8.1\r\ntornado==6.1\r\ntqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1632160078689/work\r\ntraitlets==5.1.0\r\ntransformers==4.11.3\r\ntyper==0.3.2\r\ntyping-extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1632313171031/work\r\nurllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1632350318291/work\r\nwandb==0.12.5\r\nwasabi==0.8.2\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nwidgetsnbextension==3.5.1\r\nxxhash==2.0.2\r\nyarl==1.7.0\r\nyaspin==2.1.0\r\nzc.lockfile==2.0\r\nzipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1633302054558/work\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\nThis is a modified version of [simple_tagger/experiment.json](https://github.com/allenai/allennlp/blob/main/test_fixtures/simple_tagger/experiment.json) that causes this error.\r\n```\r\n{\r\n  \"dataset_reader\":{\"type\":\"sequence_tagging\"},\r\n  \"train_data_path\": \"test_fixtures/data/sequence_tagging.tsv\",\r\n  \"validation_data_path\": \"test_fixtures/data/sequence_tagging.tsv\",\r\n  \"model\": {\r\n    \"type\": \"simple_tagger\",\r\n    \"text_field_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n            \"type\": \"embedding\",\r\n            \"projection_dim\": 2,\r\n            \"pretrained_file\": \"test_fixtures/embeddings/glove.6B.100d.sample.txt.gz\",\r\n            \"embedding_dim\": 100,\r\n            \"trainable\": true\r\n        }\r\n      }\r\n    },\r\n    \"encoder\": {\r\n      \"type\": \"lstm\",\r\n      \"input_size\": 2,\r\n      \"hidden_size\": 4,\r\n      \"num_layers\": 1\r\n    }\r\n  },\r\n  \"data_loader\": {\r\n      \"batch_sampler\": {\r\n        \"type\": \"bucket\",\r\n        \"sorting_keys\": [\"tokens\"],\r\n        \"padding_noise\": 0.0,\r\n        \"batch_size\" : 80\r\n    }\r\n},\r\n  \"trainer\": {\r\n    \"num_epochs\": 1,\r\n    \"grad_norm\": 1.0,\r\n    \"patience\": 500,\r\n    \"cuda_device\": -1,\r\n    \"checkpointer\": {\r\n        \"keep_most_recent_by_count\": 0\r\n    },\r\n    \"moving_average\": null,\r\n    \"optimizer\": {\r\n      \"type\": \"adadelta\",\r\n      \"lr\": 0.000001,\r\n      \"rho\": 0.95\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5444/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5444/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5439", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5439/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5439/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5439/events", "html_url": "https://github.com/allenai/allennlp/issues/5439", "id": 1030750424, "node_id": "I_kwDOBXH8-M49cADY", "number": 5439, "title": "Load elmo-constituency-parser from archive failed", "user": {"login": "hoperiver", "id": 53037904, "node_id": "MDQ6VXNlcjUzMDM3OTA0", "avatar_url": "https://avatars.githubusercontent.com/u/53037904?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hoperiver", "html_url": "https://github.com/hoperiver", "followers_url": "https://api.github.com/users/hoperiver/followers", "following_url": "https://api.github.com/users/hoperiver/following{/other_user}", "gists_url": "https://api.github.com/users/hoperiver/gists{/gist_id}", "starred_url": "https://api.github.com/users/hoperiver/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hoperiver/subscriptions", "organizations_url": "https://api.github.com/users/hoperiver/orgs", "repos_url": "https://api.github.com/users/hoperiver/repos", "events_url": "https://api.github.com/users/hoperiver/events{/privacy}", "received_events_url": "https://api.github.com/users/hoperiver/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-10-19T21:14:30Z", "updated_at": "2021-10-26T02:20:40Z", "closed_at": "2021-10-22T06:24:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ ] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [ ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ ] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n    archive = load_archive(\r\n        \"elmo-constituency-parser-2018.03.14.tar.gz\"\r\n    )\r\n    predictor = Predictor.from_archive(archive, 'constituency-parser')\r\n\r\n    predictor.predict_json({\"sentence\": \"This is a sentence to be predicted!\"})\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"E:\\Chuan\\Documents\\GitHub\\allennlp\\allennlp\\models\\archival.py\", line 232, in load_archive\r\n    dataset_reader, validation_dataset_reader = _load_dataset_readers(\r\n  File \"E:\\Chuan\\Documents\\GitHub\\allennlp\\allennlp\\models\\archival.py\", line 268, in _load_dataset_readers\r\n    dataset_reader = DatasetReader.from_params(\r\n  File \"E:\\Chuan\\Documents\\GitHub\\allennlp\\allennlp\\common\\from_params.py\", line 638, in from_params\r\n    subclass, constructor_name = as_registrable.resolve_class_name(choice)\r\n  File \"E:\\Chuan\\Documents\\GitHub\\allennlp\\allennlp\\common\\registrable.py\", line 207, in resolve_class_name\r\n    raise ConfigurationError(\r\nallennlp.common.checks.ConfigurationError: 'ptb_trees' is not a registered name for 'DatasetReader'. If your registered class comes from custom code, you'll need to import the corresponding modules. If you're using AllenNLP from the command-line, this is done by using the '--include-package' flag, or by specifying your imports in a '.allennlp_plugins' file. Alternatively, you can specify your choices using fully-qualified paths, e.g. {\"model\": \"my_module.models.MyModel\"} in which case they will be automatically imported correctly.\r\npython-BaseException\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Windows 10\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.9.5\r\nallennlp 2.4.0\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5439/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5439/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5431", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5431/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5431/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5431/events", "html_url": "https://github.com/allenai/allennlp/issues/5431", "id": 1016338302, "node_id": "I_kwDOBXH8-M48lBd-", "number": 5431, "title": "`from_files_and_instances` is not registered in vocabulary.py", "user": {"login": "guopeiming", "id": 39085859, "node_id": "MDQ6VXNlcjM5MDg1ODU5", "avatar_url": "https://avatars.githubusercontent.com/u/39085859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guopeiming", "html_url": "https://github.com/guopeiming", "followers_url": "https://api.github.com/users/guopeiming/followers", "following_url": "https://api.github.com/users/guopeiming/following{/other_user}", "gists_url": "https://api.github.com/users/guopeiming/gists{/gist_id}", "starred_url": "https://api.github.com/users/guopeiming/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guopeiming/subscriptions", "organizations_url": "https://api.github.com/users/guopeiming/orgs", "repos_url": "https://api.github.com/users/guopeiming/repos", "events_url": "https://api.github.com/users/guopeiming/events{/privacy}", "received_events_url": "https://api.github.com/users/guopeiming/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-10-05T13:33:32Z", "updated_at": "2021-10-10T21:22:55Z", "closed_at": "2021-10-10T21:22:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n`from_files_and_instances` is a `@classmethod` constructor in class of `Vocabulary`, but it is not registered.\r\nWhen I want to init the vocabulary by this method from model archive file, allennlp raises the exceptions below.\r\nIt should be registered like the other classmethods of `from_instances`, `from_files`, `from_pretrained_transformer`, etc in [`vocabulary.py`](https://github.com/allenai/allennlp/blob/main/allennlp/data/vocabulary.py).\r\n\r\nSo I think there is a line of code missing at the end of `vocabulary.py`:\r\n`Vocabulary.register(\"from_files_and_instances\", constructor=\"from_files_and_instances\")(Vocabulary)`\r\n\r\nThis is a small bug and it is easy to fix it. And we just need to add this line of code to the file.\r\nIf you agree with my modification, it is my honor to make a PR to add this line of code.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/admin/miniconda3/envs/allen/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/__main__.py\", line 46, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/commands/__init__.py\", line 122, in main\r\n    args.func(args)\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/commands/train.py\", line 112, in train_model_from_args\r\n    train_model_from_file(\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/commands/train.py\", line 178, in train_model_from_file\r\n    return train_model(\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/commands/train.py\", line 254, in train_model\r\n    model = _train_worker(\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/commands/train.py\", line 490, in _train_worker\r\n    train_loop = TrainModel.from_params(\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 652, in from_params\r\n    return retyped_subclass.from_params(\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 686, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/commands/train.py\", line 764, in from_partial_objects\r\n    vocabulary_ = vocabulary.construct(instances=instance_generator)\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/common/lazy.py\", line 82, in construct\r\n    return self.constructor(**contructor_kwargs)\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/common/lazy.py\", line 66, in constructor_to_use\r\n    return self._constructor.from_params(  # type: ignore[union-attr]\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 633, in from_params\r\n    choice = params.pop_choice(\r\n  File \"/home/admin/miniconda3/envs/allen/lib/python3.8/site-packages/allennlp/common/params.py\", line 352, in pop_choice\r\n    raise ConfigurationError(message)\r\nallennlp.common.checks.ConfigurationError: from_files_and_instances not in acceptable choices for vocabulary.type: ['from_instances', 'from_pretrained_transformer', 'from_pretrained_transformer_and_instances', 'from_files', 'extend', 'empty']. You should either use the --include-package flag to make sure the correct module is loaded, or use a fully qualified class name in your config file like {\"model\": \"my_module.models.MyModel\"} to have it imported automatically.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux ubuntu 18.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.11\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp==3.7.4.post0\r\nallennlp==2.7.0\r\nallennlp-models==2.7.0\r\nargon2-cffi==21.1.0\r\nasync-timeout==3.0.1\r\nattrs==21.2.0\r\nbackcall==0.2.0\r\nbackports.csv==1.0.7\r\nbase58==2.1.0\r\nbeautifulsoup4==4.10.0\r\nbleach==4.1.0\r\nblessings==1.7\r\nblis==0.7.4\r\nboto3==1.18.47\r\nbotocore==1.21.48\r\ncachetools==4.2.2\r\ncatalogue==2.0.6\r\ncertifi==2021.5.30\r\ncffi==1.14.6\r\nchardet==4.0.0\r\ncharset-normalizer==2.0.6\r\nchecklist==0.0.11\r\ncheroot==8.5.2\r\nCherryPy==18.6.1\r\nclick==8.0.1\r\nconfigparser==5.0.2\r\nconllu==4.4.1\r\ncryptography==3.4.8\r\ncymem==2.0.5\r\ndatasets==1.12.1\r\ndebugpy==1.4.3\r\ndecorator==5.1.0\r\ndefusedxml==0.7.1\r\ndill==0.3.4\r\ndocker-pycreds==0.4.0\r\nentrypoints==0.3\r\nfairscale==0.4.0\r\nfeedparser==6.0.8\r\nfilelock==3.0.12\r\nflake8==3.9.2\r\nfsspec==2021.9.0\r\nftfy==6.0.3\r\nfuture==0.18.2\r\ngitdb==4.0.7\r\nGitPython==3.1.24\r\ngoogle-api-core==2.0.1\r\ngoogle-auth==2.1.0\r\ngoogle-cloud-core==2.0.0\r\ngoogle-cloud-storage==1.42.2\r\ngoogle-crc32c==1.2.0\r\ngoogle-resumable-media==2.0.3\r\ngoogleapis-common-protos==1.53.0\r\ngpustat==0.6.0\r\nh5py==3.4.0\r\nhuggingface-hub==0.0.17\r\nidna==3.2\r\niniconfig==1.1.1\r\nipykernel==6.4.1\r\nipython==7.27.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.5\r\niso-639==0.4.5\r\njaraco.classes==3.2.1\r\njaraco.collections==3.4.0\r\njaraco.functools==3.3.0\r\njaraco.text==3.5.1\r\njedi==0.18.0\r\nJinja2==3.0.1\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonnet==0.17.0\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==7.0.3\r\njupyter-console==6.4.0\r\njupyter-core==4.8.1\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.2\r\nlmdb==1.2.1\r\nlxml==4.6.3\r\nMarkupSafe==2.0.1\r\nmatplotlib-inline==0.1.3\r\nmccabe==0.6.1\r\nmistune==0.8.4\r\nmore-itertools==8.10.0\r\nmultidict==5.1.0\r\nmultiprocess==0.70.12.2\r\nmunch==2.5.0\r\nmurmurhash==1.0.5\r\nnbclient==0.5.4\r\nnbconvert==6.2.0\r\nnbformat==5.1.3\r\nnest-asyncio==1.5.1\r\nnltk==3.6.3\r\nnotebook==6.4.4\r\nnumpy==1.21.2\r\nnvidia-ml-py3==7.352.0\r\nopustools==1.2.1\r\noverrides==3.1.0\r\npackaging==21.0\r\npandas==1.3.3\r\npandocfilters==1.5.0\r\nparso==0.8.2\r\npathtools==0.1.2\r\npathy==0.6.0\r\npatternfork-nosql==3.6\r\npdfminer.six==20201018\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==8.3.2\r\npluggy==1.0.0\r\nportend==2.7.1\r\npreshed==3.0.5\r\nprometheus-client==0.11.0\r\npromise==2.3\r\nprompt-toolkit==3.0.20\r\nprotobuf==3.18.0\r\npsutil==5.8.0\r\nptyprocess==0.7.0\r\npy==1.10.0\r\npy-rouge==1.1\r\npyarrow==5.0.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycodestyle==2.7.0\r\npycparser==2.20\r\npydantic==1.8.2\r\npyflakes==2.3.1\r\nPygments==2.10.0\r\npyparsing==2.4.7\r\npyrsistent==0.18.0\r\npytest==6.2.5\r\npython-dateutil==2.8.2\r\npython-docx==0.8.11\r\npytz==2021.1\r\nPyYAML==5.4.1\r\npyzmq==22.3.0\r\nqtconsole==5.1.1\r\nQtPy==1.11.2\r\nregex==2021.8.28\r\nrequests==2.26.0\r\nrsa==4.7.2\r\ns3transfer==0.5.0\r\nsacremoses==0.0.45\r\nscikit-learn==1.0\r\nscipy==1.7.1\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.4.1\r\nsgmllib3k==1.0.0\r\nshortuuid==1.0.1\r\nsix==1.16.0\r\nsmart-open==5.2.1\r\nsmmap==4.0.0\r\nsortedcontainers==2.4.0\r\nsoupsieve==2.2.1\r\nspacy==3.1.3\r\nspacy-legacy==3.0.8\r\nsqlitedict==1.7.0\r\nsrsly==2.4.1\r\nsubprocess32==3.5.4\r\ntempora==4.1.1\r\ntensorboardX==2.4\r\ntermcolor==1.1.0\r\nterminado==0.12.1\r\ntestpath==0.5.0\r\nthinc==8.0.10\r\nthreadpoolctl==2.2.0\r\ntokenizers==0.10.3\r\ntoml==0.10.2\r\ntorch==1.9.1\r\ntorchvision==0.10.1\r\ntornado==6.1\r\ntqdm==4.62.3\r\ntraitlets==5.1.0\r\ntransformers==4.5.1\r\ntyper==0.4.0\r\ntyping-extensions==3.10.0.2\r\nurllib3==1.26.7\r\nwandb==0.12.2\r\nwasabi==0.8.2\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nxxhash==2.0.2\r\nyarl==1.6.3\r\nyaspin==2.1.0\r\nzc.lockfile==2.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nYou can reproduce the bug by adding the code below to any train configuration files.\r\nAddition, `directory` is the path of `Vocabulary` file that was serialized either using `save_to_files` or inside a model archive file.\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n\"vocabulary\": {\r\n    \"type\": \"from_files_and_instances\",\r\n    \"directory\": /path/to/serialized/vocabulary/file,\r\n},\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5431/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5431/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5430", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5430/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5430/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5430/events", "html_url": "https://github.com/allenai/allennlp/issues/5430", "id": 1015869469, "node_id": "I_kwDOBXH8-M48jPAd", "number": 5430, "title": "MultiLabelField not being indexed correctly with pre-trained transformer", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-10-05T04:22:16Z", "updated_at": "2021-10-15T04:13:00Z", "closed_at": "2021-10-15T04:13:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "This is probably a user error but I cannot find a jsonl vocab constructor which works correctly with a MultiLabelField (i.e. a multi-label classifier).\r\n\r\nI need to set the vocabs `unk` and `pad` token as I'm using a huggingface transformer, and of course, I need to index the labels.\r\n\r\nWhen I use `from_pretrained_transformer` to construct my vocabulary there are two issues, first, when `MultiLabelField.index` is called, the vocab only contains a tokens namespace, no labels. This causes 'index' to crash - oddly `vocab.get_token_index(label, self._label_namespace)` returns 1 (one) for every label despite the namespace not existing, should it not return an error?\r\n\r\n    vocabulary: {\r\n        type: \"from_pretrained_transformer\",\r\n        model_name: \"models/transformer\",\r\n    }\r\n\r\nAlso inspecting the vocab object I'm seeing\r\n\r\n_oov_token:'\\<unk\\>'\r\n_padding_token:'@@PADDING@@'\r\n\r\nSo it's failed to infer the padding token. From what I can see the from_pretrained_transformer has no `padding_token` argument?\r\n\r\nIf I use 'from_instances' it indexes the labels correctly but afaik it's reindexing the original vocab but it's out of alignment.\r\n\r\nMy model is\r\n\r\n    vocabulary: {\r\n        type: \"from_pretrained_transformer\",\r\n        model_name: \"models/transformer\",\r\n    },\r\n    dataset_reader: {\r\n        type: \"multi_label\",\r\n        tokenizer: {\r\n          type: \"pretrained_transformer\",\r\n          model_name: \"models/transformer\"\r\n        },\r\n        token_indexers: {\r\n            tokens: {\r\n                type: \"pretrained_transformer\",\r\n                model_name: \"models/transformer\",\r\n                namespace: \"tokens\" \r\n            },\r\n        },\r\n    },\r\n    model: {\r\n        type: \"multi_label\",\r\n        text_field_embedder: {\r\n            token_embedders: {\r\n                tokens: {\r\n                    type: \"pretrained_transformer\",\r\n                    model_name: \"models/transformer\"\r\n                }\r\n            },\r\n        },\r\n        seq2vec_encoder: {\r\n            type: \"bert_pooler\",\r\n            pretrained_model: \"models/transformer\",\r\n            dropout: 0.1,\r\n        },\r\n    },\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5430/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5430/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5417", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5417/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5417/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5417/events", "html_url": "https://github.com/allenai/allennlp/issues/5417", "id": 1003694393, "node_id": "I_kwDOBXH8-M470yk5", "number": 5417, "title": "from ._check_build import check_build # noqa ImportError: dlopen: cannot load any more object with static TLS", "user": {"login": "cyilu", "id": 27624311, "node_id": "MDQ6VXNlcjI3NjI0MzEx", "avatar_url": "https://avatars.githubusercontent.com/u/27624311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cyilu", "html_url": "https://github.com/cyilu", "followers_url": "https://api.github.com/users/cyilu/followers", "following_url": "https://api.github.com/users/cyilu/following{/other_user}", "gists_url": "https://api.github.com/users/cyilu/gists{/gist_id}", "starred_url": "https://api.github.com/users/cyilu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cyilu/subscriptions", "organizations_url": "https://api.github.com/users/cyilu/orgs", "repos_url": "https://api.github.com/users/cyilu/repos", "events_url": "https://api.github.com/users/cyilu/events{/privacy}", "received_events_url": "https://api.github.com/users/cyilu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-09-22T02:45:01Z", "updated_at": "2021-10-06T16:09:27Z", "closed_at": "2021-10-06T16:09:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nAfter I finish `pip install allennlp`, then run `allennlp test-install` or `from allennlp.commands.elmo import ElmoEmbedder`, I meet this problem.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n>>> from allennlp.commands.elmo import ElmoEmbedder\r\nTraceback (most recent call last):\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/sklearn/__check_build/__init__.py\", line 44, in <module>\r\n    from ._check_build import check_build  # noqa\r\nImportError: dlopen: cannot load any more object with static TLS\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/allennlp/commands/__init__.py\", line 9, in <module>\r\n    from allennlp.commands.build_vocab import BuildVocab\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/allennlp/commands/build_vocab.py\", line 17, in <module>\r\n    from allennlp.training.util import make_vocab_from_params\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/allennlp/training/__init__.py\", line 2, in <module>\r\n    from allennlp.training.no_op_trainer import NoOpTrainer\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/allennlp/training/no_op_trainer.py\", line 6, in <module>\r\n    from allennlp.models import Model\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/allennlp/models/__init__.py\", line 6, in <module>\r\n    from allennlp.models.model import Model\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/allennlp/models/model.py\", line 18, in <module>\r\n    from allennlp.data import Instance, Vocabulary\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/allennlp/data/__init__.py\", line 1, in <module>\r\n    from allennlp.data.data_loaders import (\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/allennlp/data/data_loaders/__init__.py\", line 2, in <module>\r\n    from allennlp.data.data_loaders.multiprocess_data_loader import MultiProcessDataLoader, WorkerError\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 19, in <module>\r\n    from allennlp.data.data_loaders.data_collator import DataCollator, DefaultDataCollator\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/allennlp/data/data_loaders/data_collator.py\", line 3, in <module>\r\n    from transformers.data.data_collator import DataCollatorForLanguageModeling\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/transformers/data/__init__.py\", line 19, in <module>\r\n    from .metrics import glue_compute_metrics, xnli_compute_metrics\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/transformers/data/metrics/__init__.py\", line 22, in <module>\r\n    if is_sklearn_available():\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/transformers/file_utils.py\", line 307, in is_sklearn_available\r\n    return importlib.util.find_spec(\"sklearn.metrics\") and importlib.util.find_spec(\"scipy.stats\")\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/importlib/util.py\", line 94, in find_spec\r\n    parent = __import__(parent_name, fromlist=['__path__'])\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/sklearn/__init__.py\", line 81, in <module>\r\n    from . import __check_build  # noqa: F401\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/sklearn/__check_build/__init__.py\", line 46, in <module>\r\n    raise_build_error(e)\r\n  File \"/home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/sklearn/__check_build/__init__.py\", line 31, in raise_build_error\r\n    raise ImportError(\"\"\"%s\r\nImportError: dlopen: cannot load any more object with static TLS\r\n___________________________________________________________________________\r\nContents of /home/nls3/anaconda2/envs/allennlp38_tmp/lib/python3.8/site-packages/sklearn/__check_build:\r\nsetup.py                  _check_build.cpython-38-x86_64-linux-gnu.so__init__.py\r\n__pycache__\r\n___________________________________________________________________________\r\nIt seems that scikit-learn has not been built correctly.\r\n\r\nIf you have installed scikit-learn from source, please do not forget\r\nto build the package before using it: run `python setup.py install` or\r\n`make` in the source directory.\r\n\r\nIf you have used an installer, please check that it is suited for your\r\nPython version, your operating system and your platform.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- https://github.com/allenai/allennlp/issues/285\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux GPU1 4.2.0-27-generic #32~14.04.1-Ubuntu SMP Fri Jan 22 15:32:26 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.11\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp==3.7.4.post0\r\nallennlp==2.7.0\r\nargon2-cffi==21.1.0\r\nasync-timeout==3.0.1\r\nattrs==21.2.0\r\nbackcall==0.2.0\r\nbackports.csv==1.0.7\r\nbase58==2.1.0\r\nbeautifulsoup4==4.10.0\r\nbleach==4.1.0\r\nblis==0.7.4\r\nboto3==1.18.45\r\nbotocore==1.21.45\r\ncachetools==4.2.2\r\ncatalogue==2.0.6\r\ncertifi==2021.5.30\r\ncffi==1.14.6\r\nchardet==4.0.0\r\ncharset-normalizer==2.0.6\r\nchecklist==0.0.11\r\ncheroot==8.5.2\r\nCherryPy==18.6.1\r\nclick==8.0.1\r\nconfigparser==5.0.2\r\ncryptography==3.4.8\r\ncymem==2.0.5\r\ndatasets==1.12.1\r\ndebugpy==1.4.3\r\ndecorator==5.1.0\r\ndefusedxml==0.7.1\r\ndill==0.3.4\r\ndocker-pycreds==0.4.0\r\nentrypoints==0.3\r\nfairscale==0.4.0\r\nfeedparser==6.0.8\r\nfilelock==3.0.12\r\nfsspec==2021.8.1\r\nfuture==0.18.2\r\ngitdb==4.0.7\r\nGitPython==3.1.24\r\ngoogle-api-core==2.0.1\r\ngoogle-auth==2.1.0\r\ngoogle-cloud-core==2.0.0\r\ngoogle-cloud-storage==1.42.2\r\ngoogle-crc32c==1.2.0\r\ngoogle-resumable-media==2.0.3\r\ngoogleapis-common-protos==1.53.0\r\nh5py==3.4.0\r\nhuggingface-hub==0.0.17\r\nidna==3.2\r\niniconfig==1.1.1\r\nipykernel==6.4.1\r\nipython==7.27.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.5\r\niso-639==0.4.5\r\njaraco.classes==3.2.1\r\njaraco.collections==3.4.0\r\njaraco.functools==3.3.0\r\njaraco.text==3.5.1\r\njedi==0.18.0\r\nJinja2==3.0.1\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonnet==0.17.0\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==7.0.3\r\njupyter-console==6.4.0\r\njupyter-core==4.8.1\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.2\r\nlmdb==1.2.1\r\nlxml==4.6.3\r\nMarkupSafe==2.0.1\r\nmatplotlib-inline==0.1.3\r\nmistune==0.8.4\r\nmore-itertools==8.10.0\r\nmultidict==5.1.0\r\nmultiprocess==0.70.12.2\r\nmunch==2.5.0\r\nmurmurhash==1.0.5\r\nnbclient==0.5.4\r\nnbconvert==6.1.0\r\nnbformat==5.1.3\r\nnest-asyncio==1.5.1\r\nnltk==3.6.3\r\nnotebook==6.4.4\r\nnumpy==1.21.2\r\noverrides==3.1.0\r\npackaging==21.0\r\npandas==1.3.3\r\npandocfilters==1.5.0\r\nparso==0.8.2\r\npathtools==0.1.2\r\npathy==0.6.0\r\npatternfork-nosql==3.6\r\npdfminer.six==20201018\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==8.3.2\r\npluggy==1.0.0\r\nportend==2.7.1\r\npreshed==3.0.5\r\nprometheus-client==0.11.0\r\npromise==2.3\r\nprompt-toolkit==3.0.20\r\nprotobuf==3.18.0\r\npsutil==5.8.0\r\nptyprocess==0.7.0\r\npy==1.10.0\r\npyarrow==5.0.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\npydantic==1.8.2\r\nPygments==2.10.0\r\npyparsing==2.4.7\r\npyrsistent==0.18.0\r\npytest==6.2.5\r\npython-dateutil==2.8.2\r\npython-docx==0.8.11\r\npytz==2021.1\r\nPyYAML==5.4.1\r\npyzmq==22.3.0\r\nqtconsole==5.1.1\r\nQtPy==1.11.1\r\nregex==2021.8.28\r\nrequests==2.26.0\r\nrsa==4.7.2\r\ns3transfer==0.5.0\r\nsacremoses==0.0.45\r\nscikit-learn==0.24.2\r\nscipy==1.7.1\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.4.0\r\nsgmllib3k==1.0.0\r\nshortuuid==1.0.1\r\nsix==1.16.0\r\nsmart-open==5.2.1\r\nsmmap==4.0.0\r\nsortedcontainers==2.4.0\r\nsoupsieve==2.2.1\r\nspacy==3.1.3\r\nspacy-legacy==3.0.8\r\nsqlitedict==1.7.0\r\nsrsly==2.4.1\r\nsubprocess32==3.5.4\r\ntempora==4.1.1\r\ntensorboardX==2.4\r\ntermcolor==1.1.0\r\nterminado==0.12.1\r\ntestpath==0.5.0\r\nthinc==8.0.10\r\nthreadpoolctl==2.2.0\r\ntokenizers==0.10.3\r\ntoml==0.10.2\r\ntorch==1.9.1\r\ntorchvision==0.10.1\r\ntornado==6.1\r\ntqdm==4.62.3\r\ntraitlets==5.1.0\r\ntransformers==4.5.1\r\ntyper==0.4.0\r\ntyping-extensions==3.10.0.2\r\nurllib3==1.26.6\r\nwandb==0.12.2\r\nwasabi==0.8.2\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nwidgetsnbextension==3.5.1\r\nxxhash==2.0.2\r\nyarl==1.6.3\r\nyaspin==2.1.0\r\nzc.lockfile==2.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\nAfter finishing `pip install allennlp`, then run  `allennlp test-install` or `from allennlp.commands.elmo import ElmoEmbedder`.\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5417/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5417/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5413", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5413/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5413/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5413/events", "html_url": "https://github.com/allenai/allennlp/issues/5413", "id": 1000511373, "node_id": "I_kwDOBXH8-M47opeN", "number": 5413, "title": "Concern about the implementation of gradient_clipping during fp16 training ", "user": {"login": "YKX-A", "id": 38134733, "node_id": "MDQ6VXNlcjM4MTM0NzMz", "avatar_url": "https://avatars.githubusercontent.com/u/38134733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YKX-A", "html_url": "https://github.com/YKX-A", "followers_url": "https://api.github.com/users/YKX-A/followers", "following_url": "https://api.github.com/users/YKX-A/following{/other_user}", "gists_url": "https://api.github.com/users/YKX-A/gists{/gist_id}", "starred_url": "https://api.github.com/users/YKX-A/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YKX-A/subscriptions", "organizations_url": "https://api.github.com/users/YKX-A/orgs", "repos_url": "https://api.github.com/users/YKX-A/repos", "events_url": "https://api.github.com/users/YKX-A/events{/privacy}", "received_events_url": "https://api.github.com/users/YKX-A/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2021-09-20T02:15:42Z", "updated_at": "2021-10-14T16:45:30Z", "closed_at": "2021-10-14T16:45:30Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [ x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nI have a question about the implementation of `grad_clipping ` in gradient_descent_trainer([here](https://github.com/allenai/allennlp/blob/main/allennlp/training/gradient_descent_trainer.py#L231)), when opening up `use_amp` option.\r\nThe current implementation is to register a hook, which clips gradient immediately. ([here](https://github.com/allenai/allennlp/blob/main/allennlp/training/gradient_descent_trainer.py#L759))\r\nHowever, I think this specific implementation of gradient clipping has a problem when combined with mixed-precision training.\r\n\r\n**EXAMPLE**:\r\n  (SETTING: gradient_clipping=2.0)\r\n1. Supposing the gradient of param `P` is 1.0.\r\n2. Note that fp16 training needs to scale the loss larger before Back Propagation, say `factor = 16`, but during Back Propagation, the hook would immediately clip the gradient of param `P` from 1 * 16 = 16.0 to 2.0.\r\n3. At last, we unscale the fp32 gradient of param `P` 2.0/16 = 0.125 (But it should be 1.0, right?)\r\n\r\n**Solution**\r\nIn short, it might be more proper to use `torch.nn.utils.clip_grad_value_` instead of reristering a `hook` (where to clip gradient? I think it could follow the `clip_grad_norm` in  `Trainer`, in a similar fashion and position, after `self._scaler.unscale_(self.optimizer)`).\r\nPytorch officially has an advice about gradient clipping in fp16 training, see [here](https://pytorch.org/docs/stable/notes/amp_examples.html#gradient-clipping) (though the example is in fact about clip gradient norm). \r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5413/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5413/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5412", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5412/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5412/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5412/events", "html_url": "https://github.com/allenai/allennlp/issues/5412", "id": 997188055, "node_id": "I_kwDOBXH8-M47b-HX", "number": 5412, "title": "cannot import name 'OrderedDict' from 'typing'", "user": {"login": "rattlesnakey", "id": 57869572, "node_id": "MDQ6VXNlcjU3ODY5NTcy", "avatar_url": "https://avatars.githubusercontent.com/u/57869572?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rattlesnakey", "html_url": "https://github.com/rattlesnakey", "followers_url": "https://api.github.com/users/rattlesnakey/followers", "following_url": "https://api.github.com/users/rattlesnakey/following{/other_user}", "gists_url": "https://api.github.com/users/rattlesnakey/gists{/gist_id}", "starred_url": "https://api.github.com/users/rattlesnakey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rattlesnakey/subscriptions", "organizations_url": "https://api.github.com/users/rattlesnakey/orgs", "repos_url": "https://api.github.com/users/rattlesnakey/repos", "events_url": "https://api.github.com/users/rattlesnakey/events{/privacy}", "received_events_url": "https://api.github.com/users/rattlesnakey/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2021-09-15T14:59:05Z", "updated_at": "2021-10-04T16:09:39Z", "closed_at": "2021-10-04T16:09:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [ ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ ] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:cannot import name 'OrderedDict' from 'typing'</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:3.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==2.7.0\r\nargcomplete @ file:///tmp/build/80754af9/argcomplete_1618920853202/work\r\nargon2-cffi==21.1.0\r\nattrs @ file:///tmp/build/80754af9/attrs_1620827162558/work\r\nbackcall @ file:///home/ktietz/src/ci/backcall_1611930011877/work\r\nbackports.csv==1.0.7\r\nbase58==2.1.0\r\nbeautifulsoup4==4.10.0\r\nbleach==4.1.0\r\nblis==0.7.4\r\nboto3==1.18.42\r\nbotocore==1.21.42\r\ncached-property==1.5.2\r\ncachetools==4.2.2\r\ncatalogue==2.0.6\r\ncertifi==2021.5.30\r\ncffi==1.14.6\r\nchardet==4.0.0\r\ncharset-normalizer==2.0.4\r\nchecklist==0.0.11\r\ncheroot==8.5.2\r\nCherryPy==18.6.1\r\nclick==7.1.2\r\nconfigparser==5.0.2\r\ncryptography==3.4.8\r\ncycler==0.10.0\r\ncymem==2.0.5\r\ndatasets==1.6.2\r\ndebugpy==1.4.3\r\ndecorator==5.1.0\r\ndefusedxml @ file:///tmp/build/80754af9/defusedxml_1615228127516/work\r\ndill==0.3.4\r\ndocker-pycreds==0.4.0\r\nentrypoints==0.3\r\nfairscale==0.4.0\r\nfeedparser==6.0.8\r\nfilelock==3.0.12\r\nfsspec==2021.8.1\r\nfuture==0.18.2\r\ngitdb==4.0.7\r\nGitPython==3.1.23\r\ngoogle-api-core==2.0.1\r\ngoogle-auth==2.1.0\r\ngoogle-cloud-core==2.0.0\r\ngoogle-cloud-storage==1.42.1\r\ngoogle-crc32c==1.1.2\r\ngoogle-resumable-media==2.0.2\r\ngoogleapis-common-protos==1.53.0\r\nh5py==3.4.0\r\nhuggingface-hub==0.0.16\r\nidna==3.2\r\nimportlib-metadata==4.8.1\r\niniconfig==1.1.1\r\nipykernel==6.4.1\r\nipython==7.27.0\r\nipython-genutils @ file:///tmp/build/80754af9/ipython_genutils_1606773439826/work\r\nipywidgets==7.6.4\r\niso-639==0.4.5\r\njaraco.classes==3.2.1\r\njaraco.collections==3.4.0\r\njaraco.functools==3.3.0\r\njaraco.text==3.5.1\r\njedi @ file:///tmp/build/80754af9/jedi_1611333758854/work\r\nJinja2 @ file:///tmp/build/80754af9/jinja2_1624781299557/work\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonnet==0.17.0\r\njsonschema @ file:///Users/ktietz/demo/mc3/conda-bld/jsonschema_1630511932244/work\r\njupyter==1.0.0\r\njupyter-client==7.0.2\r\njupyter-console==6.4.0\r\njupyter-core @ file:///tmp/build/80754af9/jupyter_core_1612213308260/work\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.1\r\nkiwisolver==1.3.2\r\nlmdb==1.2.1\r\nlxml==4.6.3\r\nMarkupSafe @ file:///tmp/build/80754af9/markupsafe_1621528142364/work\r\nmatplotlib==3.4.3\r\nmatplotlib-inline==0.1.3\r\nmistune @ file:///tmp/build/80754af9/mistune_1594373098390/work\r\nmore-itertools==8.9.0\r\nmultiprocess==0.70.12.2\r\nmunch==2.5.0\r\nmurmurhash==1.0.5\r\nnb-conda==2.2.1\r\nnb-conda-kernels @ file:///tmp/build/80754af9/nb_conda_kernels_1606775986548/work\r\nnbclient==0.5.4\r\nnbconvert==6.1.0\r\nnbformat @ file:///tmp/build/80754af9/nbformat_1617383369282/work\r\nnest-asyncio @ file:///tmp/build/80754af9/nest-asyncio_1613680548246/work\r\nnltk==3.6.2\r\nnotebook==6.4.3\r\nnumpy==1.21.2\r\noverrides==3.1.0\r\npackaging @ file:///tmp/build/80754af9/packaging_1625611678980/work\r\npandas==1.1.5\r\npandocfilters @ file:///tmp/build/80754af9/pandocfilters_1605120451932/work\r\nparso @ file:///tmp/build/80754af9/parso_1617223946239/work\r\npathtools==0.1.2\r\npathy==0.6.0\r\npatternfork-nosql==3.6\r\npdfminer.six==20201018\r\npexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work\r\npickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work\r\nPillow==8.3.2\r\npluggy==1.0.0\r\nportend==2.7.1\r\npreshed==3.0.5\r\nprometheus-client @ file:///tmp/build/80754af9/prometheus_client_1623189609245/work\r\npromise==2.3\r\nprompt-toolkit==3.0.20\r\nprotobuf==3.17.3\r\npsutil==5.8.0\r\nptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npy==1.10.0\r\npyarrow==5.0.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\npydantic==1.8.2\r\nPygments @ file:///tmp/build/80754af9/pygments_1629234116488/work\r\npyparsing @ file:///home/linux1/recipes/ci/pyparsing_1610983426697/work\r\npyrsistent==0.18.0\r\npytest==6.2.5\r\npython-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\r\npython-docx==0.8.11\r\npytz==2021.1\r\nPyYAML==5.4.1\r\npyzmq @ file:///tmp/build/80754af9/pyzmq_1628267913491/work\r\nqtconsole==5.1.1\r\nQtPy==1.11.0\r\nregex==2021.8.28\r\nrequests==2.26.0\r\nrsa==4.7.2\r\ns3transfer==0.5.0\r\nsacremoses==0.0.45\r\nscikit-learn==0.24.2\r\nscipy==1.7.1\r\nseaborn==0.11.2\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.3.1\r\nsgmllib3k==1.0.0\r\nshortuuid==1.0.1\r\nsix @ file:///tmp/build/80754af9/six_1623709665295/work\r\nsklearn==0.0\r\nsmart-open==5.2.1\r\nsmmap==4.0.0\r\nsortedcontainers==2.4.0\r\nsoupsieve==2.2.1\r\nspacy==3.1.2\r\nspacy-legacy==3.0.8\r\nsqlitedict==1.7.0\r\nsrsly==2.4.1\r\nsubprocess32==3.5.4\r\ntempora==4.1.1\r\ntensorboardX==2.4\r\ntermcolor==1.1.0\r\nterminado==0.12.1\r\ntestpath @ file:///tmp/build/80754af9/testpath_1624638946665/work\r\nthinc==8.0.10\r\nthreadpoolctl==2.2.0\r\ntokenizers==0.10.3\r\ntoml==0.10.2\r\ntorch==1.9.0\r\ntorchtext==0.10.0\r\ntorchvision==0.10.0\r\ntornado @ file:///tmp/build/80754af9/tornado_1606942283357/work\r\ntqdm==4.49.0\r\ntraitlets==5.1.0\r\ntransformers==4.4.2\r\ntyper==0.3.2\r\ntyping==3.7.4.3\r\ntyping-extensions==3.10.0.2\r\nurllib3==1.26.6\r\nwandb==0.12.1\r\nwasabi==0.8.2\r\nwcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work\r\nwebencodings==0.5.1\r\nwidgetsnbextension==3.5.1\r\nxxhash==2.0.2\r\nzc.lockfile==2.0\r\nzipp @ file:///tmp/build/80754af9/zipp_1625570634446/work\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5412/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5412/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5406", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5406/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5406/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5406/events", "html_url": "https://github.com/allenai/allennlp/issues/5406", "id": 994683907, "node_id": "MDU6SXNzdWU5OTQ2ODM5MDc=", "number": 5406, "title": "2.7.0 breaks multi-task multiprocess data loading on CUDA", "user": {"login": "amitkparekh", "id": 7276308, "node_id": "MDQ6VXNlcjcyNzYzMDg=", "avatar_url": "https://avatars.githubusercontent.com/u/7276308?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amitkparekh", "html_url": "https://github.com/amitkparekh", "followers_url": "https://api.github.com/users/amitkparekh/followers", "following_url": "https://api.github.com/users/amitkparekh/following{/other_user}", "gists_url": "https://api.github.com/users/amitkparekh/gists{/gist_id}", "starred_url": "https://api.github.com/users/amitkparekh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amitkparekh/subscriptions", "organizations_url": "https://api.github.com/users/amitkparekh/orgs", "repos_url": "https://api.github.com/users/amitkparekh/repos", "events_url": "https://api.github.com/users/amitkparekh/events{/privacy}", "received_events_url": "https://api.github.com/users/amitkparekh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-09-13T09:51:39Z", "updated_at": "2021-10-08T16:09:42Z", "closed_at": "2021-10-08T16:09:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nThis has been a tricky one to isolate. With 2.7.0, the changes with how the MultiprocessDataLoader handles queues has broken multi-task data loading when training more than one tasks with more than one GPU. \r\n\r\nThe [nightly version from 26th Aug 2021](https://pypi.org/project/allennlp/2.7.0.dev20210826/) is the last one that is working without erroring out.  \r\n\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n\r\n```\r\nProcess ForkProcess-21:11:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nloading instances: 896it [00:01, 736.64it/s]\r\nProcess ForkProcess-21:12:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-21:13:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-21:14:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-21:15:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-21:16:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-21:17:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-21:18:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-21:19:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nloading instances: 987it [00:02, 472.66it/s]\r\nProcess ForkProcess-21:20::00, ?it/s]\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-22:11:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-22:12:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-22:13:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-22:14:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-22:15:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-22:16:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-22:17:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-22:18:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\nProcess ForkProcess-22:19:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n                                     Process ForkProcess-22:20:\r\nTraceback (most recent call last):/s]\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 556, in _instance_worker\r\n    if self._safe_queue_put(worker_id, (instance, None), queue, rx):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 562, in _instance_worker\r\n    if not self._safe_queue_put(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 518, in _safe_queue_put\r\n    fds, _, _ = select.select([rx.fileno()], [], [], 0)\r\nValueError: filedescriptor out of range in select()\r\n^CTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/bin/allennlp\", line 8, in <module>\r\nloading instances: 0it [00:06, ?it/s]\r\n\r\n    sys.exit(run())\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/__main__.py\", line 46, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/commands/__init__.py\", line 122, in main\r\n    args.func(args)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/commands/train.py\", line 112, in train_model_from_args\r\n    train_model_from_file(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/commands/train.py\", line 178, in train_model_from_file\r\n    return train_model(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/commands/train.py\", line 321, in train_model\r\n0it [00:10, ?it/s]    mp.spawn(\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 230, in spawn\r\n\r\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 188, in start_processes\r\n    while not context.join():\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 99, in join\r\n    ready = multiprocessing.connection.wait(\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\r\n    ready = selector.select(timeout)\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/selectors.py\", line 416, in select\r\n    fd_event_list = self._selector.poll(timeout)\r\nKeyboardInterrupt\r\nloading instances: 1025it [00:09, 105.05it/s]\r\nException ignored in: <generator object MultiProcessDataLoader.iter_instances at 0x7f024460f970>\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 392, in iter_instances\r\n    self._join_workers(workers, queue, txs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 483, in _join_workers\r\n    tx.send(\"stop\")\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/connection.py\", line 211, in send\r\n    self._send_bytes(_ForkingPickler.dumps(obj))\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\r\n    self._send(header + buf)\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\r\n    n = write(self._handle, buf)\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nloading instances: 1025it [00:10, 100.96it/s]\r\nException ignored in: <generator object MultiProcessDataLoader.iter_instances at 0x7fa8340c0c80>\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 392, in iter_instances\r\n    self._join_workers(workers, queue, txs)\r\n  File \"/home/ap41/develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 483, in _join_workers\r\n    tx.send(\"stop\")\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/connection.py\", line 211, in send\r\n    self._send_bytes(_ForkingPickler.dumps(obj))\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\r\n    self._send(header + buf)\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\r\n    n = write(self._handle, buf)\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n^CError in atexit._run_exitfuncs:\r\nTraceback (most recent call last):\r\n  File \"/home/ap41/.zinit/plugins/pyenv---pyenv/versions/3.9.6/lib/python3.9/multiprocessing/popen_fork.py\", line 27, in poll\r\n    pid, sts = os.waitpid(self.pid, flag)\r\nKeyboardInterrupt\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.9.6\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp @ file:///home/ap41/.cache/pypoetry/artifacts/6d/b9/d1/bd4137b29ef435eb8c0f07e7821b37e90ea3b2dd9f2eae99c6f72d6534/allennlp-2.7.0-py3-none-any.whl\r\nargon2-cffi @ file:///home/ap41/.cache/pypoetry/artifacts/c0/c3/f7/82597d8293535347329974ab242671376ff92ffe41cc534ea192e561b6/argon2_cffi-21.1.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.whl\r\nastor @ file:///home/ap41/.cache/pypoetry/artifacts/1f/03/36/982d1222edac5e8cb8ac6e0464249747fa800d4fb04728a99153ecfe4d/astor-0.8.1-py2.py3-none-any.whl\r\nattrs @ file:///home/ap41/.cache/pypoetry/artifacts/6f/a9/ee/569c37f69a8c365ee41d2340aeac0214ee8c0086b8d8db43a21545204b/attrs-21.2.0-py2.py3-none-any.whl\r\nbackcall @ file:///home/ap41/.cache/pypoetry/artifacts/43/8e/e8/4e598704edf6fb4a53d552ea511c04e9958dcf850897760e5387878b99/backcall-0.2.0-py2.py3-none-any.whl\r\nbackports.csv @ file:///home/ap41/.cache/pypoetry/artifacts/30/84/1a/81a42cff31ce7f0b7a86ab54e2cbcb610d96fa8b735d63bdb7251e91cb/backports.csv-1.0.7-py2.py3-none-any.whl\r\nbackports.entry-points-selectable @ file:///home/ap41/.cache/pypoetry/artifacts/28/b3/f9/3290d966259d25f13a39a46617b9a9b5591282ff22871cf30f7d35ed9f/backports.entry_points_selectable-1.1.0-py2.py3-none-any.whl\r\nbandit @ file:///home/ap41/.cache/pypoetry/artifacts/6a/05/4f/98680ab175e4b595c2d1b775974c208b6b20c05448a52944374c2db4b0/bandit-1.7.0-py3-none-any.whl\r\nbase58 @ file:///home/ap41/.cache/pypoetry/artifacts/b0/55/9d/0110497446d4e322216740a417f1fb7c3e81b63b2000ecc0216abc70a7/base58-2.1.0-py3-none-any.whl\r\nbeautifulsoup4 @ file:///home/ap41/.cache/pypoetry/artifacts/d4/3e/b2/b4df19cca3023c21eb4a289b88c132ac71a9517bddef2055fd38eadd39/beautifulsoup4-4.10.0-py3-none-any.whl\r\nblack @ file:///home/ap41/.cache/pypoetry/artifacts/03/0e/f9/f10727f8b0ba7665a77feb04560102e8367927f9148882a69f195f2c3f/black-21.8b0-py3-none-any.whl\r\nbleach @ file:///home/ap41/.cache/pypoetry/artifacts/db/42/1e/1062d618eece64f515d716a5cb98eace54768d5af54a9273b1f554eaec/bleach-4.1.0-py2.py3-none-any.whl\r\nblis @ file:///home/ap41/.cache/pypoetry/artifacts/9d/16/b7/619f57a1e88e83c9ba80d0f5b058c151436346ea659ea6ec326962c900/blis-0.7.4-cp39-cp39-manylinux2014_x86_64.whl\r\nboto3 @ file:///home/ap41/.cache/pypoetry/artifacts/45/69/5f/280025a4cbc1c3b1bd1f8fe462f350ef24be65a0819495cfcb20793651/boto3-1.18.40-py3-none-any.whl\r\nbotocore @ file:///home/ap41/.cache/pypoetry/artifacts/10/9b/f6/d52255c9ea22d64926607a891167bb9f4293534c1271c023f79b58087f/botocore-1.21.40-py3-none-any.whl\r\ncachetools @ file:///home/ap41/.cache/pypoetry/artifacts/04/ca/d7/8af05dc8ccae1212d4151afd99960369c2415b26bc13ed3bbb288c4f5a/cachetools-4.2.2-py3-none-any.whl\r\ncatalogue @ file:///home/ap41/.cache/pypoetry/artifacts/7c/6a/8a/f666a0e711d9153f80a844329970fcf567da43df07fef3127356219777/catalogue-2.0.6-py3-none-any.whl\r\ncertifi @ file:///home/ap41/.cache/pypoetry/artifacts/cd/2c/dc/e5bfda594e18f3f1e9af9f11e13581014d821425f325f3220b3ed2c337/certifi-2021.5.30-py2.py3-none-any.whl\r\ncffi @ file:///home/ap41/.cache/pypoetry/artifacts/07/bd/6a/4c069e59508f3c9940783b3c741c9a9fb04f57156488db39ad6b33c9d4/cffi-1.14.6-cp39-cp39-manylinux1_x86_64.whl\r\ncfgv @ file:///home/ap41/.cache/pypoetry/artifacts/01/82/9f/3671a8d16261a6ab135899476dc3724864519a2461d2f62545c113637a/cfgv-3.3.1-py2.py3-none-any.whl\r\nchardet @ file:///home/ap41/.cache/pypoetry/artifacts/11/63/f9/797eda27963177a6b75a340f62aa194d462ea69e6b0dbb77a651fa2b62/chardet-4.0.0-py2.py3-none-any.whl\r\ncharset-normalizer @ file:///home/ap41/.cache/pypoetry/artifacts/e0/69/bc/9f03bea1c18fddcbfc52ed595f99fdbc68f8a5c0d479e589bca308ac21/charset_normalizer-2.0.4-py3-none-any.whl\r\nchecklist @ file:///home/ap41/.cache/pypoetry/artifacts/04/84/f3/1324eec13577715f52121b3073ab37792c08483aae7faa7d22b7dd5e1d/checklist-0.0.11.tar.gz\r\ncheroot @ file:///home/ap41/.cache/pypoetry/artifacts/3c/cf/87/c9bb0e3b0d4c43affeb8f9714d5791b61c97750bc3a2ee35d276d425b5/cheroot-8.5.2-py2.py3-none-any.whl\r\nCherryPy @ file:///home/ap41/.cache/pypoetry/artifacts/dd/d5/0c/5289a45f52e9aa001f7b8c2b9c792377e79ad572bc759f1a692d160818/CherryPy-18.6.1-py2.py3-none-any.whl\r\nclick @ file:///home/ap41/.cache/pypoetry/artifacts/e2/79/34/a23e9d2f683ed66be11ec3bd760dec3a2fe228cfdedf2071bcf0531b06/click-7.1.2-py2.py3-none-any.whl\r\ncolorama @ file:///home/ap41/.cache/pypoetry/artifacts/9e/b3/11/7d87ac44fdb2d557301f1f4086a37c080d1482a98751abe7cdbabbad26/colorama-0.4.4-py2.py3-none-any.whl\r\ncommonmark @ file:///home/ap41/.cache/pypoetry/artifacts/11/56/f6/d054064b623fab5c7e4420f60d931f49fea2dacdebe1dc991201010c84/commonmark-0.9.1-py2.py3-none-any.whl\r\nconfigparser @ file:///home/ap41/.cache/pypoetry/artifacts/4e/17/fd/30c9e84dc4b951f3587a4d5eb2894e20105120991793ff3e9f3a60d787/configparser-5.0.2-py3-none-any.whl\r\ncoverage @ file:///home/ap41/.cache/pypoetry/artifacts/2b/40/c4/6d4f333f20c8fe59c1248df160e1a76224b652ed2e41a842b6a22579a1/coverage-5.5-cp39-cp39-manylinux2010_x86_64.whl\r\ncryptography @ file:///home/ap41/.cache/pypoetry/artifacts/59/33/cb/852d2d43e37b510e0fb27b54b534c9a83c6cff64ad695db5537420bc3a/cryptography-3.4.8-cp36-abi3-manylinux_2_24_x86_64.whl\r\ncymem @ file:///home/ap41/.cache/pypoetry/artifacts/df/fa/b7/3c93ddfdcef16e7b4a0cf43f520d95d8cac38aad3fc8e392371f858712/cymem-2.0.5-cp39-cp39-manylinux2014_x86_64.whl\r\ndarglint @ file:///home/ap41/.cache/pypoetry/artifacts/bb/64/25/6fa28703f05a524eef407d4425af6290f242eb131574704386e677624b/darglint-1.8.0-py3-none-any.whl\r\ndatasets @ file:///home/ap41/.cache/pypoetry/artifacts/2e/2b/c8/bb7daa7d94bb2424ad40e2f1ca47e1a55ff0d0e0605e5dfd2305dd77e1/datasets-1.11.0-py3-none-any.whl\r\ndecorator @ file:///home/ap41/.cache/pypoetry/artifacts/c5/6b/f9/35190d429d462647b42d2847ab554759b98334d6479bc354c719947ce6/decorator-5.1.0-py3-none-any.whl\r\ndefusedxml @ file:///home/ap41/.cache/pypoetry/artifacts/2b/69/07/7b13f7eaf3a4d7af737dcebe24d3d17b1c2a2f457fbddf746f5642bc43/defusedxml-0.7.1-py2.py3-none-any.whl\r\ndill @ file:///home/ap41/.cache/pypoetry/artifacts/26/56/9e/73963d2285e6c700801f185e8c1d28f1f971c09aaa411cec9b799a5fca/dill-0.3.4-py2.py3-none-any.whl\r\ndistlib @ file:///home/ap41/.cache/pypoetry/artifacts/6f/35/97/6a255392aaa7200818a8cd0f4b014ef2e0a086bab49dd568780f367ef5/distlib-0.3.2-py2.py3-none-any.whl\r\ndocker-pycreds @ file:///home/ap41/.cache/pypoetry/artifacts/9b/0b/be/891931da9caf5e55102337a635d3a7eeeb92c93b4bd39c24d0810f1f25/docker_pycreds-0.4.0-py2.py3-none-any.whl\r\ndocutils @ file:///home/ap41/.cache/pypoetry/artifacts/43/28/92/79000933ad30371dc938d9b368a9000e20ac0bb467a716c19ef1fbd3c7/docutils-0.17.1-py2.py3-none-any.whl\r\nentrypoints @ file:///home/ap41/.cache/pypoetry/artifacts/63/c1/af/bbfdd91bcb544e62ac8f1567ef23c243cb188d1a9cb933532999c9bbb0/entrypoints-0.3-py2.py3-none-any.whl\r\neradicate @ file:///home/ap41/.cache/pypoetry/artifacts/12/ce/ac/197035fe6d51568abb7ea160f5ad416d2164a2010005e8356b8229e550/eradicate-2.0.0.tar.gz\r\nfairscale @ file:///home/ap41/.cache/pypoetry/artifacts/af/4f/57/87d33c2f59c3d0bbc847cb9880c3b1504f03ced8353fd70924a1ebb6c4/fairscale-0.4.0.tar.gz\r\nfeedparser @ file:///home/ap41/.cache/pypoetry/artifacts/d1/81/87/0f3c1c0b02176b2bf05af85261d8ce7522e4d241e5d9f7b3f0ec4f2a10/feedparser-6.0.8-py3-none-any.whl\r\nfilelock @ file:///home/ap41/.cache/pypoetry/artifacts/7e/c4/97/2cfbeab3cc292d0b4290cb7cab0b969b3002dc24f6dd5944cbe340e684/filelock-3.0.12-py3-none-any.whl\r\nflake8 @ file:///home/ap41/.cache/pypoetry/artifacts/3f/57/d5/11722093c13092cc3bfc3dd7c88aef6f8e4d5ac97cfe5fd054d5aba412/flake8-3.9.2-py2.py3-none-any.whl\r\nflake8-bandit @ file:///home/ap41/.cache/pypoetry/artifacts/7e/e4/46/e15782d941f9cde39b64ca5b636180f47573f2b2c9315be56b55152f17/flake8_bandit-2.1.2.tar.gz\r\nflake8-broken-line @ file:///home/ap41/.cache/pypoetry/artifacts/51/ea/87/37348b281b73d7df44fc46b09c0430e2984e991df11998e2e9bb459fce/flake8_broken_line-0.3.0-py3-none-any.whl\r\nflake8-bugbear @ file:///home/ap41/.cache/pypoetry/artifacts/40/9a/89/4ddf0245d6ca6c67f61f49325b250ce9416c1869531587a96019bbf75e/flake8_bugbear-21.9.1-py36.py37.py38-none-any.whl\r\nflake8-commas @ file:///home/ap41/.cache/pypoetry/artifacts/c3/47/1d/7f7fac0c58b2bd2bf7361bcba0bceba1c81c365cab5e1de352fa7fac68/flake8_commas-2.0.0-py2.py3-none-any.whl\r\nflake8-comprehensions @ file:///home/ap41/.cache/pypoetry/artifacts/07/8d/7f/546da917af8e1293c81462d92f623ec18c22e7137b8487cced290b59ad/flake8_comprehensions-3.6.1-py3-none-any.whl\r\nflake8-debugger @ file:///home/ap41/.cache/pypoetry/artifacts/66/04/47/7bef98a8d237eb17cbfbcb803343be1c79e2c0674ceba163717b6c8e1b/flake8_debugger-4.0.0-py3-none-any.whl\r\nflake8-docstrings @ file:///home/ap41/.cache/pypoetry/artifacts/e0/85/e9/6b482a11d48cf26e1170d9f5bf0b044a5a6c9b816ffe70945e90fc3e56/flake8_docstrings-1.6.0-py2.py3-none-any.whl\r\nflake8-eradicate @ file:///home/ap41/.cache/pypoetry/artifacts/fc/3d/a0/58427b14b0a6d33587f3d6896e695615272c37c3ff2c89d6155b5155f6/flake8_eradicate-1.1.0-py3-none-any.whl\r\nflake8-isort @ file:///home/ap41/.cache/pypoetry/artifacts/11/37/1c/68fb64c6704b9c2468f711b83090590abc2c8295eeafbac9a167f32e0a/flake8_isort-4.0.0-py2.py3-none-any.whl\r\nflake8-polyfill @ file:///home/ap41/.cache/pypoetry/artifacts/28/17/cc/952c11cd5ffb2608137557f928dc4f9365b4dbe1e2a6015eeea78583ac/flake8_polyfill-1.0.2-py2.py3-none-any.whl\r\nflake8-quotes @ file:///home/ap41/.cache/pypoetry/artifacts/04/4a/79/ed230ab7b27297cc42d0bfa3565aa93895adad49e66f4ad39b8a69a6c3/flake8-quotes-3.3.0.tar.gz\r\nflake8-rst-docstrings @ file:///home/ap41/.cache/pypoetry/artifacts/69/c4/19/62afcee08756b2cc746fb4d585d02dd819556e0b0d30a6cc7acb6a101a/flake8_rst_docstrings-0.2.3-py3-none-any.whl\r\nflake8-string-format @ file:///home/ap41/.cache/pypoetry/artifacts/24/89/bb/7ce8e216f8c7289aa8a2ad4c44f30f87af6c7cdaf5d510110d566d66ec/flake8_string_format-0.3.0-py2.py3-none-any.whl\r\nfsspec @ file:///home/ap41/.cache/pypoetry/artifacts/6a/83/93/ff0422a7ea9ad9e3b66586905979d8bf7f91183c0e7bc79ce5d8f17009/fsspec-2021.8.1-py3-none-any.whl\r\nfuture @ file:///home/ap41/.cache/pypoetry/artifacts/f8/58/55/86be1f567b212fdd98854d12815964a49db8fb1bcff725018e5f95c61d/future-0.18.2.tar.gz\r\ngitdb @ file:///home/ap41/.cache/pypoetry/artifacts/82/af/0d/fc5992ac7ef8a227e6b9705aa6de550211814dd0318b857530d3306d02/gitdb-4.0.7-py3-none-any.whl\r\nGitPython @ file:///home/ap41/.cache/pypoetry/artifacts/8f/69/eb/66f0e8ec0d4726b57021796421ed05236c4e795e92914c495dec3f2cd2/GitPython-3.1.23-py3-none-any.whl\r\ngoogle-api-core @ file:///home/ap41/.cache/pypoetry/artifacts/f6/4d/ab/517f837b07d681a71e3bc323330335942f2e941cae8f4a51117c177d6b/google_api_core-2.0.1-py2.py3-none-any.whl\r\ngoogle-auth @ file:///home/ap41/.cache/pypoetry/artifacts/8c/8f/89/d02b4dcfa146c747105bc6815997a1c5f5b6b578149aa54de0f4f76f77/google_auth-2.0.2-py2.py3-none-any.whl\r\ngoogle-cloud-core @ file:///home/ap41/.cache/pypoetry/artifacts/82/7f/12/2011f0d6380fa130617c8e768921ff7a3e3a17728239b21b9c18410811/google_cloud_core-2.0.0-py2.py3-none-any.whl\r\ngoogle-cloud-storage @ file:///home/ap41/.cache/pypoetry/artifacts/e7/83/7e/f47006ece6f48d0129ba367b3a052d2260844da1d36279e05bdf117d68/google_cloud_storage-1.42.1-py2.py3-none-any.whl\r\ngoogle-crc32c @ file:///home/ap41/.cache/pypoetry/artifacts/48/50/6a/6a545cb1fd1c4bd2afa9fb0644c1db495faccf6288ee9ef9d61850739f/google_crc32c-1.1.2-cp39-cp39-manylinux2014_x86_64.whl\r\ngoogle-resumable-media @ file:///home/ap41/.cache/pypoetry/artifacts/a0/b5/23/0569c4fe4e88725ff464ef300d489f1e90e3d24a79183ab1c1eb687e84/google_resumable_media-2.0.2-py2.py3-none-any.whl\r\ngoogleapis-common-protos @ file:///home/ap41/.cache/pypoetry/artifacts/8d/40/1f/21e71977c3d547b27842caaafc2e420c9a6dd40a745cce4b61673e3be3/googleapis_common_protos-1.53.0-py2.py3-none-any.whl\r\nh5py @ file:///home/ap41/.cache/pypoetry/artifacts/07/81/5b/f6b44991f8b7580f7168014b60cd4ab4e62515d0b6d3db24044023960c/h5py-3.4.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\nhuggingface-hub @ file:///home/ap41/.cache/pypoetry/artifacts/4f/0b/2c/51fc8021723d71e255ac256565eb65ffd942e23c5bc5c0d67b400af174/huggingface_hub-0.0.16-py3-none-any.whl\r\nhypothesis @ file:///home/ap41/.cache/pypoetry/artifacts/14/63/80/66976895919a22442b583d3f22094c953efd38448811e32ed143125962/hypothesis-6.21.0-py3-none-any.whl\r\nidentify @ file:///home/ap41/.cache/pypoetry/artifacts/59/5c/29/b6524bdbbe18efeee10d6c86b348747e7da84a1013d300716aeaeb3c8f/identify-2.2.14-py2.py3-none-any.whl\r\nidna @ file:///home/ap41/.cache/pypoetry/artifacts/ff/0d/80/b45ae1ddba13a20e406682fd42ce6c201d9bedc5f592bee00cf799a1fb/idna-3.2-py3-none-any.whl\r\niniconfig @ file:///home/ap41/.cache/pypoetry/artifacts/fa/b0/c6/10cfac68c9e6de9d2a1678366ca89fd9292b362c1760dbe758e41691cb/iniconfig-1.1.1-py2.py3-none-any.whl\r\nipykernel @ file:///home/ap41/.cache/pypoetry/artifacts/30/98/d5/b01a5306b6404f2c2862d298a4f8649f5c2579c0f5973f59838fe3fc2b/ipykernel-5.5.5-py3-none-any.whl\r\nipython @ file:///home/ap41/.cache/pypoetry/artifacts/b2/94/a0/acc44143d8707af8057ced65be3758e02b0e4c815d6dd06f2ba3968a06/ipython-7.27.0-py3-none-any.whl\r\nipython-genutils @ file:///home/ap41/.cache/pypoetry/artifacts/b4/31/01/6f96480580d1674cab0b5e26dc9fca7bbdf7a2fd5811a7807a92436268/ipython_genutils-0.2.0-py2.py3-none-any.whl\r\nipywidgets @ file:///home/ap41/.cache/pypoetry/artifacts/7e/39/23/4cbff8897284ce8d7f24d4faf23acf579ec0e9daa6ef0b1268c4e1be98/ipywidgets-7.6.4-py2.py3-none-any.whl\r\niso-639 @ file:///home/ap41/.cache/pypoetry/artifacts/f0/a6/d6/17ede193e09cf4ac45d787cbef2e1c78ff7dff5a58775728212204bbd0/iso-639-0.4.5.tar.gz\r\nisort @ file:///home/ap41/.cache/pypoetry/artifacts/bc/d9/39/a45ef37c64d06afcb2b384592ccd87f10eb578c31e4d4895c7557cca93/isort-5.9.3-py3-none-any.whl\r\njaraco.classes @ file:///home/ap41/.cache/pypoetry/artifacts/d0/3c/d2/f157bfb781b294c3d68a29e898ab39327bc2397eea1b42cf8afdfda14b/jaraco.classes-3.2.1-py3-none-any.whl\r\njaraco.collections @ file:///home/ap41/.cache/pypoetry/artifacts/b5/37/dc/9c36b359f5ee40235f16be580710ca07f20d5f03be3d28a10df354e707/jaraco.collections-3.4.0-py3-none-any.whl\r\njaraco.functools @ file:///home/ap41/.cache/pypoetry/artifacts/4e/9d/9f/96376949fa50b18fc96d90f93d24360b467689922c512daa6beee4d08b/jaraco.functools-3.3.0-py3-none-any.whl\r\njaraco.text @ file:///home/ap41/.cache/pypoetry/artifacts/de/53/c4/272dc0bf286ebe8e5aeefcc1be1156c5be2f95a73dd15033e30f8e24dc/jaraco.text-3.5.1-py3-none-any.whl\r\njedi @ file:///home/ap41/.cache/pypoetry/artifacts/2a/5b/d6/62e1f4e7b392c3e7f8258bbe3159dff695814a46e65547cd547ca0fedb/jedi-0.18.0-py2.py3-none-any.whl\r\nJinja2 @ file:///home/ap41/.cache/pypoetry/artifacts/21/2e/46/0a76ea6f6a15e594c9828a85a781f1cee8ed5a1b77e361305645f9e1f4/Jinja2-3.0.1-py3-none-any.whl\r\njmespath @ file:///home/ap41/.cache/pypoetry/artifacts/2c/f0/52/b0ba93d941bd49c8719dee7ca27d2096bf96e17948667388c3ee2ac8f8/jmespath-0.10.0-py2.py3-none-any.whl\r\njoblib @ file:///home/ap41/.cache/pypoetry/artifacts/28/41/26/7ed6532cff9d56b8d2878f93bc289c075f338c12aa7d630862aae39d45/joblib-1.0.1-py3-none-any.whl\r\njsonnet @ file:///home/ap41/.cache/pypoetry/artifacts/60/4e/2d/acde747a02049d38e6dbda9dc3fbf64f03bf2e14c8e9ad04f07edcc66b/jsonnet-0.17.0.tar.gz\r\njsonschema @ file:///home/ap41/.cache/pypoetry/artifacts/db/1d/66/ad84fa70cc987bd4aad68be808562321cdab3cb03f4d5d7714a0e0571c/jsonschema-3.2.0-py2.py3-none-any.whl\r\njupyter @ file:///home/ap41/.cache/pypoetry/artifacts/bb/e8/12/09df1332820a1126a780ab09cec78d2f50457f79bcd0cb2fbb07b19ef4/jupyter-1.0.0-py2.py3-none-any.whl\r\njupyter-client @ file:///home/ap41/.cache/pypoetry/artifacts/51/81/06/fe1de398c604b0e8163f4feb5223ede9bf60fdf1901b260d39ea6a57c9/jupyter_client-7.0.2-py3-none-any.whl\r\njupyter-console @ file:///home/ap41/.cache/pypoetry/artifacts/4b/2f/b8/119f975fb811a5e911beacc7a1bb8f8e1154254fb33204e753131e7aca/jupyter_console-6.4.0-py3-none-any.whl\r\njupyter-core @ file:///home/ap41/.cache/pypoetry/artifacts/91/8f/22/1377f102bb4478eb073c741714348b7cbb6518d221da9c232cfc5242b3/jupyter_core-4.7.1-py3-none-any.whl\r\njupyterlab-pygments @ file:///home/ap41/.cache/pypoetry/artifacts/de/ef/fc/5883436de4b7865f082f7cba0e0e0ff5fbf229fe55d6e7d5431a6080f4/jupyterlab_pygments-0.1.2-py2.py3-none-any.whl\r\njupyterlab-widgets @ file:///home/ap41/.cache/pypoetry/artifacts/51/fe/e1/e18d3ce55cfe05c4658647de3b3ba811c2e72dee7b2c66aea9ec018e75/jupyterlab_widgets-1.0.1-py3-none-any.whl\r\nlmdb @ file:///home/ap41/.cache/pypoetry/artifacts/8c/76/54/b721202dccac74078c06fb8bb746bc85c679ef6ed6488ff62e97f597c5/lmdb-1.2.1-cp39-cp39-manylinux2010_x86_64.whl\r\nlxml @ file:///home/ap41/.cache/pypoetry/artifacts/22/b6/df/404ec1fd9c34f71c3f09c1ae47b6dada296cbec9a676226de0416702b7/lxml-4.6.3-cp39-cp39-manylinux2014_x86_64.whl\r\nMarkupSafe @ file:///home/ap41/.cache/pypoetry/artifacts/ec/52/15/121903cbf3e26335764efabbe86a236389d359c3c9e9d060c2d90c5f01/MarkupSafe-2.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\nmatplotlib-inline @ file:///home/ap41/.cache/pypoetry/artifacts/b5/de/c6/6384d0999287fcdc9e88d38f7951106dcb7ffac7c4e8c0d0c665e12cac/matplotlib_inline-0.1.3-py3-none-any.whl\r\nmccabe @ file:///home/ap41/.cache/pypoetry/artifacts/96/5e/5f/21ae5296697ca7f94de4da6e21d4936d74029c352a35202e4c339a4253/mccabe-0.6.1-py2.py3-none-any.whl\r\nmistune @ file:///home/ap41/.cache/pypoetry/artifacts/33/31/4c/2d69dc65d06d1c8f8b00b8e995e24bae97fce2e1f8ec5d8d2d98e852da/mistune-0.8.4-py2.py3-none-any.whl\r\nmore-itertools @ file:///home/ap41/.cache/pypoetry/artifacts/70/54/d1/37276698396d4d90cefd85f4e10e01c991850a346ca5a548d1a5033215/more_itertools-8.9.0-py3-none-any.whl\r\nmultiprocess @ file:///home/ap41/.cache/pypoetry/artifacts/5d/fb/ce/029cafd015834319024c43f708d975b006d115de466309cb8f4d8c1353/multiprocess-0.70.12.2-py39-none-any.whl\r\nmunch @ file:///home/ap41/.cache/pypoetry/artifacts/c3/f9/98/c46b861b1fe10f4d4fecd0ed8752a968be33d2c7e698b70589015aa0b2/munch-2.5.0-py2.py3-none-any.whl\r\nmurmurhash @ file:///home/ap41/.cache/pypoetry/artifacts/82/47/8a/2188632aa4756a4fe634fc8529f6a318baeac1db0460408ecc0e2eb84b/murmurhash-1.0.5-cp39-cp39-manylinux2014_x86_64.whl\r\nmypy @ file:///home/ap41/.cache/pypoetry/artifacts/40/9b/f3/725ed0f2a5116fd7ef7dcef5595483bbb50ef25f5e7a6334f6a74a41e6/mypy-0.901-cp39-cp39-manylinux2010_x86_64.whl\r\nmypy-extensions @ file:///home/ap41/.cache/pypoetry/artifacts/92/45/bf/1807ce854ff668d92602207a37bfa9316def2a3f257bd03c4c5be4bc9b/mypy_extensions-0.4.3-py2.py3-none-any.whl\r\nnbclient @ file:///home/ap41/.cache/pypoetry/artifacts/cf/79/fc/887dc9becedf0234a9a66c10093c17b1784cac9e43deeac59686ec5c39/nbclient-0.5.4-py3-none-any.whl\r\nnbconvert @ file:///home/ap41/.cache/pypoetry/artifacts/cd/57/5f/0aebcf8edff99a9ea65795c24b549346cdb70b238cf2c200de0bf86f0f/nbconvert-6.1.0-py3-none-any.whl\r\nnbformat @ file:///home/ap41/.cache/pypoetry/artifacts/36/a7/e7/e1a0c1c54f6151e23afd51bc71e3f6e0b24a96dd1e693b92dd9a4e4ab3/nbformat-5.1.3-py3-none-any.whl\r\nnest-asyncio @ file:///home/ap41/.cache/pypoetry/artifacts/51/1a/ee/4f904dc67e6f59f0c8b75ef59d0111e4fb57dd4a884ad19d289ab31a77/nest_asyncio-1.5.1-py3-none-any.whl\r\nnltk @ file:///home/ap41/.cache/pypoetry/artifacts/18/6d/ee/ffa73af7527056102cff0b73ffa10fc5a7ffa898f9214d546e6ec70b57/nltk-3.6.2-py3-none-any.whl\r\nnodeenv @ file:///home/ap41/.cache/pypoetry/artifacts/54/f0/a1/53d1e469f8e160bad013c23411375fd63d4ea70cda0fc649fcb244ca7e/nodeenv-1.6.0-py2.py3-none-any.whl\r\nnotebook @ file:///home/ap41/.cache/pypoetry/artifacts/22/b8/5b/538cf10e491d06190097a64f723df9addcff70567c73f0801eece8ee0c/notebook-6.4.3-py3-none-any.whl\r\nnumpy @ file:///home/ap41/.cache/pypoetry/artifacts/09/41/2d/f87d4931dbeb5c1c9969044e87c1fb20a7729758872458fa5ea668b6d7/numpy-1.21.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\norjson @ file:///home/ap41/.cache/pypoetry/artifacts/d2/6d/39/e2fe4c24801df0bbf72d4bb8e95a6ebdbd63e7150b924360515cbeda22/orjson-3.6.3-cp39-cp39-manylinux_2_24_x86_64.whl\r\noverrides @ file:///home/ap41/.cache/pypoetry/artifacts/24/45/16/62e842b5cdff34f5106ee676232cbcc7d7a1333e4900d111bca737b13a/overrides-3.1.0.tar.gz\r\npackaging @ file:///home/ap41/.cache/pypoetry/artifacts/f9/4f/09/c91a145b26102e014fd6e33bd8c7b87306c8e1d4a771158f34dd13210e/packaging-21.0-py3-none-any.whl\r\npandas @ file:///home/ap41/.cache/pypoetry/artifacts/a1/2c/77/bdc2cb032a1b71994364748b6afd485b8726c4bfea3caf175531952f85/pandas-1.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\npandocfilters @ file:///home/ap41/.cache/pypoetry/artifacts/2b/8b/2b/6cd1e4385f3f7f98a25f05764a4ea3f2f20d1db00612ef79e25bb90fe9/pandocfilters-1.4.3.tar.gz\r\nparso @ file:///home/ap41/.cache/pypoetry/artifacts/36/cd/ab/a8c3a5df337bc6f34a10f3f385417b62cdfebe2873ac2fec38206af0db/parso-0.8.2-py2.py3-none-any.whl\r\npastel @ file:///home/ap41/.cache/pypoetry/artifacts/da/84/f3/3e4d8b15eabeba62960ed9d3ccc1e30b7ae5f1b93e6c28d291c67eaf93/pastel-0.2.1-py2.py3-none-any.whl\r\npathspec @ file:///home/ap41/.cache/pypoetry/artifacts/0a/67/21/620031f7f2938bad77b057a68a4c2a334542a7402a3214ed48690caf8c/pathspec-0.9.0-py2.py3-none-any.whl\r\npathtools @ file:///home/ap41/.cache/pypoetry/artifacts/ce/ff/c7/31da76336d55d51d979a50868616c867c7b2ea6f2d2084b8c744726ae7/pathtools-0.1.2.tar.gz\r\npathy @ file:///home/ap41/.cache/pypoetry/artifacts/8b/32/7d/6ebde3e12379c8b7b21d79a425ab583dd22bc29dea747ca556c4263aa6/pathy-0.6.0-py3-none-any.whl\r\npatternfork-nosql @ file:///home/ap41/.cache/pypoetry/artifacts/fa/53/d7/a04c2b1cd20312460da3f82ca634ac259fc581089956ed73763c0757cc/patternfork_nosql-3.6.tar.gz\r\npbr @ file:///home/ap41/.cache/pypoetry/artifacts/c7/6a/db/482c805b950fd5a0ece81e7a9a063cb1aa99169ca73fba511759c9db30/pbr-5.6.0-py2.py3-none-any.whl\r\npdfminer.six @ file:///home/ap41/.cache/pypoetry/artifacts/21/c6/47/9aded02cbdd666be599af42cbfc0c6cf4ad847f177acf882ee11ff2f19/pdfminer.six-20201018-py3-none-any.whl\r\npep8-naming @ file:///home/ap41/.cache/pypoetry/artifacts/a4/93/c7/a3b9b8b4aef682b4caa67015d897aff3d064860a460124ad8a23b6f45f/pep8_naming-0.11.1-py2.py3-none-any.whl\r\npexpect @ file:///home/ap41/.cache/pypoetry/artifacts/5c/c2/43/b54fe59cab7e831df35401c8e6840162bf4a2ae5862604e7bc22db3000/pexpect-4.8.0-py2.py3-none-any.whl\r\npickleshare @ file:///home/ap41/.cache/pypoetry/artifacts/b5/48/a1/d2b823337003d531d87cf0d503ef28bb579703a74d14ad24a88863d616/pickleshare-0.7.5-py2.py3-none-any.whl\r\nPillow @ file:///home/ap41/.cache/pypoetry/artifacts/e2/63/33/450f579e8ec594e5faa794106364a01da86e2dd6e1825f228f7a2971d6/Pillow-8.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nplatformdirs @ file:///home/ap41/.cache/pypoetry/artifacts/b5/1c/75/af1b48d59847e9602d4314e30b5eda42b3adb4d3efd767a4eefa54076d/platformdirs-2.3.0-py3-none-any.whl\r\npluggy @ file:///home/ap41/.cache/pypoetry/artifacts/81/78/ca/13f743a3628faf5a0b7f021efb45f2193acba3a13663d498f6b34bf02e/pluggy-1.0.0-py2.py3-none-any.whl\r\npoethepoet @ file:///home/ap41/.cache/pypoetry/artifacts/36/42/75/cc7c77f4b9ac69fd8470c7524490be4f0c722f6f7b98d14da11fc2774e/poethepoet-0.10.0-py3-none-any.whl\r\npokerface==0.1.0\r\nportend @ file:///home/ap41/.cache/pypoetry/artifacts/9e/0a/b1/aab32a1b4dbdac42ada198c9c4378651e9a6fba9698662d1e1838a7100/portend-2.7.1-py3-none-any.whl\r\npre-commit @ file:///home/ap41/.cache/pypoetry/artifacts/42/0e/fe/db8bccf878698a112f0d0e7df6b321c152250ee983f26ecdeea683ab9d/pre_commit-2.15.0-py2.py3-none-any.whl\r\npreshed @ file:///home/ap41/.cache/pypoetry/artifacts/14/6e/76/733ae947d0289c8da1f104facf08fc4a27be8633c64fd2e5038d702403/preshed-3.0.5-cp39-cp39-manylinux2014_x86_64.whl\r\nprometheus-client @ file:///home/ap41/.cache/pypoetry/artifacts/ce/fa/c7/255d5bc58b6e1a7cc1e9d4eb3c5a993bea6af1aa016b5008147ab8beb7/prometheus_client-0.11.0-py2.py3-none-any.whl\r\npromise @ file:///home/ap41/.cache/pypoetry/artifacts/d6/c6/43/95f1e737b1dd79d3a5ac6cfb264a889716bab4cd9d28a9bc8c69591d53/promise-2.3.tar.gz\r\nprompt-toolkit @ file:///home/ap41/.cache/pypoetry/artifacts/fa/d8/d6/49b01a255d533bbed8278b7fc50a6075bfb54aa7aace829b71e99c1a0a/prompt_toolkit-3.0.20-py3-none-any.whl\r\nprotobuf @ file:///home/ap41/.cache/pypoetry/artifacts/ff/aa/28/b7696139ebbc85c393673e1124c9ab1b1a9c701f542a86bcc3a1de3f92/protobuf-3.17.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl\r\npsutil @ file:///home/ap41/.cache/pypoetry/artifacts/06/3a/4a/5e88d8f14e18b10c222f81667132086849930f068d68d064ceb8a87834/psutil-5.8.0-cp39-cp39-manylinux2010_x86_64.whl\r\nptyprocess @ file:///home/ap41/.cache/pypoetry/artifacts/2a/29/5d/0cdc5ec916431d60f03d2f725c54edbfa9fe53700b75fdfee209a3291e/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npy @ file:///home/ap41/.cache/pypoetry/artifacts/60/79/0b/c48bd9c2a989aa8b1eb7a67cd02b053c10734f2e4e5665f7995f09999c/py-1.10.0-py2.py3-none-any.whl\r\npy-spy @ file:///home/ap41/.cache/pypoetry/artifacts/0c/b5/0a/19e9976e436e91e1f20dd1e7ae27bb7bce30d4a00685bce155e9c4cd12/py_spy-0.3.9-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl\r\npyarrow @ file:///home/ap41/.cache/pypoetry/artifacts/0f/56/ab/103a674728cd742d9b8ff0de742def887ac9a73f25c492d13420d794d4/pyarrow-5.0.0-cp39-cp39-manylinux2014_x86_64.whl\r\npyasn1 @ file:///home/ap41/.cache/pypoetry/artifacts/7b/3a/54/42ce43b579bda01b9d79022fb733811594441e7a32e9f9a5a98f672bdc/pyasn1-0.4.8-py2.py3-none-any.whl\r\npyasn1-modules @ file:///home/ap41/.cache/pypoetry/artifacts/dd/b8/4f/b56433e0354274a31074995e01b8671751e9f0ed0001f5254e5b03a54f/pyasn1_modules-0.2.8-py2.py3-none-any.whl\r\npycodestyle @ file:///home/ap41/.cache/pypoetry/artifacts/4c/30/97/026c283ef67eb248e5b7e6fad1f8ffb99dae50c11fd93eb939fd7c1f46/pycodestyle-2.7.0-py2.py3-none-any.whl\r\npycparser @ file:///home/ap41/.cache/pypoetry/artifacts/37/8e/5a/0ea4f84bc7f11e0e3468110efa2c7783241ea7eaa63a92a751de06f78f/pycparser-2.20-py2.py3-none-any.whl\r\npydantic @ file:///home/ap41/.cache/pypoetry/artifacts/e1/bf/c1/7cdd43a1b6ea4e9cfd1e0e9e5b3276ad83c6b57194b4449da3e64fe6cf/pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl\r\npydocstyle @ file:///home/ap41/.cache/pypoetry/artifacts/75/e7/e5/1acad15a51efd39cf39259c7888c205fd787a92efea28f7afc5a9e315c/pydocstyle-6.1.1-py3-none-any.whl\r\npyflakes @ file:///home/ap41/.cache/pypoetry/artifacts/eb/c4/2c/47fcc1b3f387b1f7033e85b3ac6ee7772338461a8de8ac3977c6a7dcc1/pyflakes-2.3.1-py2.py3-none-any.whl\r\nPygments @ file:///home/ap41/.cache/pypoetry/artifacts/d0/e9/f0/fe2df77eaa1b942fb9b6c52c8c433da9ce654580696e74423c9a9ad814/Pygments-2.10.0-py3-none-any.whl\r\npyparsing @ file:///home/ap41/.cache/pypoetry/artifacts/92/0f/cf/effdcd5d76a6186df0969f85b3b030284ff8058936d5016540b5258ea3/pyparsing-2.4.7-py2.py3-none-any.whl\r\npyrsistent @ file:///home/ap41/.cache/pypoetry/artifacts/78/42/af/83d41626a30713ec48d568b27fc65ea9a098dd76da0e034fa6fa37c127/pyrsistent-0.18.0-cp39-cp39-manylinux1_x86_64.whl\r\npytest @ file:///home/ap41/.cache/pypoetry/artifacts/28/be/f1/ce8fa22c989106fc7c1ee7fa31d55d7f31aee1c58c63b2a43670601b79/pytest-6.2.5-py3-none-any.whl\r\npytest-cov @ file:///home/ap41/.cache/pypoetry/artifacts/f4/fe/91/424be7c04bf2c12dfadf29fb063c284c2f6d91d11d81d7d6f9ba135061/pytest_cov-2.12.1-py2.py3-none-any.whl\r\npython-dateutil @ file:///home/ap41/.cache/pypoetry/artifacts/53/f8/2a/7d63ce15df7386e9536e83413453f8aa845b47fb425f05c4ca2fb231c3/python_dateutil-2.8.2-py2.py3-none-any.whl\r\npython-docx @ file:///home/ap41/.cache/pypoetry/artifacts/7f/3f/b0/ca05b61dd6a8beb8bc8317700154416271ddda4db5425c92e9d780cba7/python-docx-0.8.11.tar.gz\r\npython-dotenv @ file:///home/ap41/.cache/pypoetry/artifacts/a6/61/71/a8300bb6be27750f8810f5d2a0c070e220ebc1a416f0837d4bbc283391/python_dotenv-0.17.1-py2.py3-none-any.whl\r\npytz @ file:///home/ap41/.cache/pypoetry/artifacts/b0/a7/8d/54de3ab4d1ff29abbbca1e9ccbaefdc2a1b290138311b84f73bee16de1/pytz-2021.1-py2.py3-none-any.whl\r\nPyYAML @ file:///home/ap41/.cache/pypoetry/artifacts/dd/d9/3d/cbc42de28fcde705eb305497d2f3e5679ca7890234c51348b33c0f428f/PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl\r\npyzmq @ file:///home/ap41/.cache/pypoetry/artifacts/d2/e6/be/490a2142b628943a01558865df111aed7479c5fd50d2a068d26ff5f763/pyzmq-22.2.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\nqtconsole @ file:///home/ap41/.cache/pypoetry/artifacts/88/04/9d/bfea17c2892fc9d54fe273876b3c28dc50389a75af0a43c4e5db123bbd/qtconsole-5.1.1-py3-none-any.whl\r\nQtPy @ file:///home/ap41/.cache/pypoetry/artifacts/9e/4e/6f/38489f203281c50c4eb9d75d6cd75fcc5dec3bbea76fcf3b1f78c8587f/QtPy-1.11.0-py2.py3-none-any.whl\r\nregex @ file:///home/ap41/.cache/pypoetry/artifacts/16/b3/ea/efd13886af7a8e3ee046540e32b31240a3abfce1aa3ce8ddc0dca670d5/regex-2021.8.28-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nrequests @ file:///home/ap41/.cache/pypoetry/artifacts/13/00/3d/5574756561eed6b522f5b13d5a2c05c2920860b05b1e687c3792495ba0/requests-2.26.0-py2.py3-none-any.whl\r\nrestructuredtext-lint @ file:///home/ap41/.cache/pypoetry/artifacts/b6/09/80/91d176f17ba9a28291203e41600b294aa26214e185082bcb0cc3543588/restructuredtext_lint-1.3.2.tar.gz\r\nrich @ file:///home/ap41/.cache/pypoetry/artifacts/f1/f3/9e/565a9b68733e7ed3da92213233b62811d81d05667f3793be833f6dc35d/rich-10.9.0-py3-none-any.whl\r\nrsa @ file:///home/ap41/.cache/pypoetry/artifacts/27/21/1f/fea99b1c1766c11c2c47dd961d7773ebab5c6acbf730200bd2e021b836/rsa-4.7.2-py3-none-any.whl\r\ns3transfer @ file:///home/ap41/.cache/pypoetry/artifacts/24/03/95/68c447d2eda2cc1924350cd0fdc25702e449ec27e9ac07b9106d57ee0b/s3transfer-0.5.0-py3-none-any.whl\r\nsacremoses @ file:///home/ap41/.cache/pypoetry/artifacts/96/d8/48/cdb78bf884395d731e5af8316b4de4517cd3b3b2b7bd28ede180216c83/sacremoses-0.0.45-py3-none-any.whl\r\nscikit-learn @ file:///home/ap41/.cache/pypoetry/artifacts/4e/32/a2/6a520fca3c92e78f32f10d9d2939b09734b91505db293fcdadcd94fca7/scikit_learn-0.24.2-cp39-cp39-manylinux2010_x86_64.whl\r\nscipy @ file:///home/ap41/.cache/pypoetry/artifacts/cf/54/79/6934fe0ee0382e865908197894c6ef46b1339d7fbe28cb76be7eba060c/scipy-1.6.1-cp39-cp39-manylinux1_x86_64.whl\r\nSend2Trash @ file:///home/ap41/.cache/pypoetry/artifacts/63/2c/10/d48818ab0722d2d6ac42f70c8b9b6567ff3a7936bdc06dedddda4398b8/Send2Trash-1.8.0-py3-none-any.whl\r\nsentencepiece @ file:///home/ap41/.cache/pypoetry/artifacts/82/c3/b5/7dcf4928f5159deaba8f451549bd8b063b13e500873857524fc8f893c9/sentencepiece-0.1.96-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nsentry-sdk @ file:///home/ap41/.cache/pypoetry/artifacts/6f/88/58/10475a7d13394eb04280b02d41705e3143669a6304a5651ace36ef24c0/sentry_sdk-1.3.1-py2.py3-none-any.whl\r\nsgmllib3k @ file:///home/ap41/.cache/pypoetry/artifacts/48/41/c1/47c574e94f31057312eab350c2a7e7b75d1105eb5b673a14efe485c128/sgmllib3k-1.0.0.tar.gz\r\nshortuuid @ file:///home/ap41/.cache/pypoetry/artifacts/80/85/8d/5bdb9fbab8b4fc7bd9599a4982cac0ae2498f4c863d13869d4e1e7b722/shortuuid-1.0.1-py3-none-any.whl\r\nsix @ file:///home/ap41/.cache/pypoetry/artifacts/08/9f/47/c16ae03035fc69eaf100ea39657a49baaeef714e25a52575710c34cd48/six-1.16.0-py2.py3-none-any.whl\r\nsmart-open @ file:///home/ap41/.cache/pypoetry/artifacts/90/9d/8f/b3121f6940407c06e50f8f81646a84f4551ec214bb239013488c3492e8/smart_open-5.2.1-py3-none-any.whl\r\nsmmap @ file:///home/ap41/.cache/pypoetry/artifacts/fb/95/d9/27c304575d15e0faf1b64e46ec12611c0a683b4d9d6aa459850d5a77df/smmap-4.0.0-py2.py3-none-any.whl\r\nsnowballstemmer @ file:///home/ap41/.cache/pypoetry/artifacts/c7/56/66/7613028d4906686fd240574f9e4ec773d99d60753a515f163d21b44935/snowballstemmer-2.1.0-py2.py3-none-any.whl\r\nsortedcontainers @ file:///home/ap41/.cache/pypoetry/artifacts/b9/80/e1/4bdfa349488797fd308ecbe48f4fad57a3245777fb47c8741730583262/sortedcontainers-2.4.0-py2.py3-none-any.whl\r\nsoupsieve @ file:///home/ap41/.cache/pypoetry/artifacts/20/16/55/4a9893b172bb2a7815f46f6a947ff3506dd241ea679377ffdc0b2c811e/soupsieve-2.2.1-py3-none-any.whl\r\nspacy @ file:///home/ap41/.cache/pypoetry/artifacts/7a/3a/a5/b6e02e9e2af5ed707f9d2e99872cb0a87dcab686c77328eb850b92426d/spacy-3.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nspacy-legacy @ file:///home/ap41/.cache/pypoetry/artifacts/3a/2e/7c/ea1cd14cc8de699a5021f6aeb2d53e5951af637177cc9cbab44e17b4b2/spacy_legacy-3.0.8-py2.py3-none-any.whl\r\nsqlitedict @ file:///home/ap41/.cache/pypoetry/artifacts/30/da/52/503d8c476c0ad677cb6bcf1714381aa53b2500752bacc499aa0a5f4283/sqlitedict-1.7.0.tar.gz\r\nsrsly @ file:///home/ap41/.cache/pypoetry/artifacts/71/8f/16/02ad7416777f6738e24aee7e68ecd02cb9b117c14faae69bd0146efc75/srsly-2.4.1-cp39-cp39-manylinux2014_x86_64.whl\r\nstevedore @ file:///home/ap41/.cache/pypoetry/artifacts/2d/57/41/1742e18c670f3badfa0cd168955cec13d17de17364cb8825471c43dad6/stevedore-3.4.0-py3-none-any.whl\r\nsubprocess32 @ file:///home/ap41/.cache/pypoetry/artifacts/b9/91/2e/cc8d3ccbf05fa27ee73859de9d02ef1a7eba84ed701970db1063a1848d/subprocess32-3.5.4.tar.gz\r\ntempora @ file:///home/ap41/.cache/pypoetry/artifacts/b9/f8/26/4304b7c3157148ded2a9f388c0c3e6b1c0016147ff5995928d8db2ce8b/tempora-4.1.1-py3-none-any.whl\r\ntensorboardX @ file:///home/ap41/.cache/pypoetry/artifacts/f6/18/d3/c562b4cfa8f42a7172c29cfea8ded406d87b3e79e6bcc0032dc3eace99/tensorboardX-2.4-py2.py3-none-any.whl\r\ntermcolor @ file:///home/ap41/.cache/pypoetry/artifacts/a2/5d/c7/e4ccb3b3bb8d3e3aff995fb6ffb12cfc78bbc8affa283907ee5eb5a5a5/termcolor-1.1.0.tar.gz\r\nterminado @ file:///home/ap41/.cache/pypoetry/artifacts/02/75/b5/4e735b6c2cb848bfe48f9fdbdff83761cb24fb4d7efabc73f87129bfc7/terminado-0.12.1-py3-none-any.whl\r\ntestfixtures @ file:///home/ap41/.cache/pypoetry/artifacts/97/46/04/2c778330a519ea14b9405bec43ecfea036e8e64d349f2110ffaef1d24a/testfixtures-6.18.1-py2.py3-none-any.whl\r\ntestpath @ file:///home/ap41/.cache/pypoetry/artifacts/1e/2d/08/76691a9e7e429930fb378dd96f760de96f2686841c47da2b35a04c5aad/testpath-0.5.0-py3-none-any.whl\r\nthinc @ file:///home/ap41/.cache/pypoetry/artifacts/42/3e/f5/6b127fdabf19884080b8edcdca4a34da0e1887efae513c30141273315e/thinc-8.0.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nthreadpoolctl @ file:///home/ap41/.cache/pypoetry/artifacts/7b/b5/49/550b4953bb841e92404d74b7c7671139fd8bbdcec26c2e89c1843fcb76/threadpoolctl-2.2.0-py3-none-any.whl\r\ntokenizers @ file:///home/ap41/.cache/pypoetry/artifacts/b8/c9/5c/4f70bb6fca31833a346653e969bb4f5d7261302f6b828e918709a81ec3/tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\ntoml @ file:///home/ap41/.cache/pypoetry/artifacts/6b/6a/c9/53b19f7870a77d855e8b05ecdc98193944e5d246dafe11bbcad850ecba/toml-0.10.2-py2.py3-none-any.whl\r\ntomli @ file:///home/ap41/.cache/pypoetry/artifacts/7b/a4/22/559325a4271b73ba93b936f2b2953235fba10bd955a50a9c0323354809/tomli-1.2.1-py3-none-any.whl\r\ntomlkit @ file:///home/ap41/.cache/pypoetry/artifacts/fd/06/32/b79e75623225a9b5af79899482b9c2933c2fa2c6fb0eff80fcec10ae48/tomlkit-0.7.2-py2.py3-none-any.whl\r\ntorch==1.9.0+cu111\r\ntorchvision==0.10.0+cu111\r\ntornado @ file:///home/ap41/.cache/pypoetry/artifacts/32/ff/76/0fc7d26eab2180c92fa57552212f38defaf212ceb7ddc9432bd84d646c/tornado-6.1-cp39-cp39-manylinux2010_x86_64.whl\r\ntqdm @ file:///home/ap41/.cache/pypoetry/artifacts/6e/fb/04/58cb1bba772d44b28d0658eb41dd273c3b7d5facedc626e406485e97f3/tqdm-4.62.2-py2.py3-none-any.whl\r\ntraitlets @ file:///home/ap41/.cache/pypoetry/artifacts/b9/61/8a/586c9b50f38b4b6269d83b427e6b29994f7db4a343f72e6f29325e4c84/traitlets-5.1.0-py3-none-any.whl\r\ntransformers @ file:///home/ap41/.cache/pypoetry/artifacts/ae/3e/26/9a99e73cfd7d44463aad270e850034478e6258f45900175d268a0cd976/transformers-4.5.1-py3-none-any.whl\r\ntyper @ file:///home/ap41/.cache/pypoetry/artifacts/99/69/d1/c0eaba65c56fdb620594a0da4f551abb366ecf588fdf0d31113e232047/typer-0.3.2-py3-none-any.whl\r\ntypes-orjson @ file:///home/ap41/.cache/pypoetry/artifacts/e3/ac/f5/782a3257b6f17101317a753b694ce3dffc227c7eee054f8633cbb18700/types_orjson-0.1.1-py2.py3-none-any.whl\r\ntyping-extensions @ file:///home/ap41/.cache/pypoetry/artifacts/4e/df/c9/f8b546ab8ea4b39e1c4f91a8360f6091cc3497ef3f9eb8fa65c0375b03/typing_extensions-3.10.0.2-py3-none-any.whl\r\nurllib3 @ file:///home/ap41/.cache/pypoetry/artifacts/d8/4b/3f/9e8027e7f15b2f99244ad505328c3cf87912ad87446c1c8e89efacf731/urllib3-1.25.11-py2.py3-none-any.whl\r\nvirtualenv @ file:///home/ap41/.cache/pypoetry/artifacts/ca/20/86/ae517c4eb7811edea2107d0aa1e933fd41d3e71f9b8224b534920d8237/virtualenv-20.7.2-py2.py3-none-any.whl\r\nwandb @ file:///home/ap41/.cache/pypoetry/artifacts/49/f4/c8/324b20beeceb351e72c821219d999d460442c4b4ff903122f29979ab5e/wandb-0.10.33-py2.py3-none-any.whl\r\nwasabi @ file:///home/ap41/.cache/pypoetry/artifacts/d5/9d/af/58d834e926bfc5371fb8208596bdec3d5824083600c5681f98ce0790d7/wasabi-0.8.2-py3-none-any.whl\r\nwcwidth @ file:///home/ap41/.cache/pypoetry/artifacts/7d/f4/60/0737157bb9711fec72c70dff523aa54491eef317e0d586cf5388ff0908/wcwidth-0.2.5-py2.py3-none-any.whl\r\nwebencodings @ file:///home/ap41/.cache/pypoetry/artifacts/ed/d4/da/61384706cfac042ba3bd148746d66e50695463993be117c7c8dadeef7a/webencodings-0.5.1-py2.py3-none-any.whl\r\nwemake-python-styleguide @ file:///home/ap41/.cache/pypoetry/artifacts/b2/30/6d/aff16dd6cc6e7169bd34e8f2e8feff71a3cc593d6ebb617acc9cf7e927/wemake_python_styleguide-0.15.3-py3-none-any.whl\r\nwidgetsnbextension @ file:///home/ap41/.cache/pypoetry/artifacts/eb/b0/c5/e9e106309ddf8d2cbebcd3c9f2c2be8c7c7346f58d8ff7ace4196371d8/widgetsnbextension-3.5.1-py2.py3-none-any.whl\r\nxxhash @ file:///home/ap41/.cache/pypoetry/artifacts/10/96/f5/ba104c6099c04fc1a07a01edd26d0c96519e713dadecd057566e8ce1f7/xxhash-2.0.2-cp39-cp39-manylinux2010_x86_64.whl\r\nzc.lockfile @ file:///home/ap41/.cache/pypoetry/artifacts/b5/a8/c8/e94e98335e585be92e35e5d07dd8a75e5c2e7774c8bd24410160f9cfe0/zc.lockfile-2.0-py2.py3-none-any.whl\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n1. Use at least 2 GPUs\r\n2. Set `num_workers` to at least 2\r\n3. Set `max_instances_in_memory` to something \u2014 currently unconfirmed\r\n3. Train a model with at least 2 tasks using the `multi-task` data loader\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5406/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5406/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5404", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5404/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5404/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5404/events", "html_url": "https://github.com/allenai/allennlp/issues/5404", "id": 993413305, "node_id": "MDU6SXNzdWU5OTM0MTMzMDU=", "number": 5404, "title": "Coreference Resolution training is failing with CUDA out of memory error", "user": {"login": "ranjita-naik", "id": 32549868, "node_id": "MDQ6VXNlcjMyNTQ5ODY4", "avatar_url": "https://avatars.githubusercontent.com/u/32549868?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ranjita-naik", "html_url": "https://github.com/ranjita-naik", "followers_url": "https://api.github.com/users/ranjita-naik/followers", "following_url": "https://api.github.com/users/ranjita-naik/following{/other_user}", "gists_url": "https://api.github.com/users/ranjita-naik/gists{/gist_id}", "starred_url": "https://api.github.com/users/ranjita-naik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ranjita-naik/subscriptions", "organizations_url": "https://api.github.com/users/ranjita-naik/orgs", "repos_url": "https://api.github.com/users/ranjita-naik/repos", "events_url": "https://api.github.com/users/ranjita-naik/events{/privacy}", "received_events_url": "https://api.github.com/users/ranjita-naik/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-09-10T16:51:02Z", "updated_at": "2021-09-14T08:28:34Z", "closed_at": "2021-09-14T08:28:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n\r\n```\r\n```\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\nNAME=\"Ubuntu\"\r\nVERSION=\"18.04.2 LTS (Bionic Beaver)\"\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\nPython 3.7.11\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n$conda create -n allennlp python=3.7\r\n$source activate allennlp\r\n\r\n$pip install allennlp\r\n$pip install allennlp-models\r\n$pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu111/torch_nightly.html -U\r\n\r\n$allennlp train coref_spanbert_large.jsonnet -s output_dir\r\ncoref_precision: 0.2097, coref_recall: 0.0115, coref_f1: 0.0217, mention_recall: 0.1283, batch_loss: 30.2774, loss: 26.6453 ||:  52%|#####2    | 1467/2802 [04:04<03:58,\r\ncoref_precision: 0.2100, coref_recall: 0.0115, coref_f1: 0.0218, mention_recall: 0.1285, batch_loss: 31.8822, loss: 26.6488 ||:  52%|#####2    | 1468/2802 [04:04<03:31,\r\ncoref_precision: 0.2109, coref_recall: 0.0116, coref_f1: 0.0219, mention_recall: 0.1289, batch_loss: 112.6335, loss: 26.7074 ||:  52%|#####2    | 1469/2802 [04:08<30:40\r\ncoref_precision: 0.2110, coref_recall: 0.0116, coref_f1: 0.0219, mention_recall: 0.1291, batch_loss: 79.8499, loss: 26.7435 ||:  52%|#####2    | 1470/2802 [04:08<22:46,\r\ncoref_precision: 0.2110, coref_recall: 0.0116, coref_f1: 0.0219, mention_recall: 0.1291, batch_loss: 79.8499, loss: 26.7435 ||:  52%|#####2    | 1470/2802 [04:09<03:45,  5.90it/s]\r\n2021-09-10 16:20:58,437 - CRITICAL - root - Uncaught exception\r\n\r\nRuntimeError: CUDA out of memory. Tried to allocate 1.75 GiB (GPU 0; 39.59 GiB total capacity; 32.47 GiB already allocated; 1.52 GiB free; 36.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\r\n\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5404/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5404/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5398", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5398/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5398/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5398/events", "html_url": "https://github.com/allenai/allennlp/issues/5398", "id": 989089704, "node_id": "MDU6SXNzdWU5ODkwODk3MDQ=", "number": 5398, "title": "`OrderedDict` typing breaks compatibility with Python 3.6", "user": {"login": "guhur", "id": 12297742, "node_id": "MDQ6VXNlcjEyMjk3NzQy", "avatar_url": "https://avatars.githubusercontent.com/u/12297742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guhur", "html_url": "https://github.com/guhur", "followers_url": "https://api.github.com/users/guhur/followers", "following_url": "https://api.github.com/users/guhur/following{/other_user}", "gists_url": "https://api.github.com/users/guhur/gists{/gist_id}", "starred_url": "https://api.github.com/users/guhur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guhur/subscriptions", "organizations_url": "https://api.github.com/users/guhur/orgs", "repos_url": "https://api.github.com/users/guhur/repos", "events_url": "https://api.github.com/users/guhur/events{/privacy}", "received_events_url": "https://api.github.com/users/guhur/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-09-06T11:49:49Z", "updated_at": "2021-09-08T21:03:40Z", "closed_at": "2021-09-08T21:03:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "The typing of `OrderedDict` is introduced in Python 3.7.2 and is not back-ported to 3.6.\r\nI tested with latest versions of typing ( typing_extensions. I am using Python 3.6.12.\r\n\r\nA recent update from July is introducing a typing checking of `OrderedDict`:  \r\nhttps://github.com/allenai/allennlp/blob/ca656fc6bac7be66e566e8f1ba3131f3aa3d7729/allennlp/nn/parallel/ddp_accelerator.py\r\n\r\nAs a consequence, `allennlp` is not compatible anymore with 3.6, which is contradictory with your README. \r\n\r\nAt first sights, it seems to affect `allennlp==2.7.0`, but not `2.6.0`. \r\n\r\nPreviously, the typing of `OrderedDict` was managed with quotes: https://github.com/allenai/allennlp/blob/f877fdc30d18178b88c335fbd92722fb77c42d93/allennlp/modules/vision/grid_embedder.py\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5398/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5398/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5395", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5395/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5395/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5395/events", "html_url": "https://github.com/allenai/allennlp/issues/5395", "id": 987796547, "node_id": "MDU6SXNzdWU5ODc3OTY1NDc=", "number": 5395, "title": "PairedPCABiasDirection should not center difference vectors", "user": {"login": "ozzypossie", "id": 22890566, "node_id": "MDQ6VXNlcjIyODkwNTY2", "avatar_url": "https://avatars.githubusercontent.com/u/22890566?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ozzypossie", "html_url": "https://github.com/ozzypossie", "followers_url": "https://api.github.com/users/ozzypossie/followers", "following_url": "https://api.github.com/users/ozzypossie/following{/other_user}", "gists_url": "https://api.github.com/users/ozzypossie/gists{/gist_id}", "starred_url": "https://api.github.com/users/ozzypossie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ozzypossie/subscriptions", "organizations_url": "https://api.github.com/users/ozzypossie/orgs", "repos_url": "https://api.github.com/users/ozzypossie/repos", "events_url": "https://api.github.com/users/ozzypossie/events{/privacy}", "received_events_url": "https://api.github.com/users/ozzypossie/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-09-03T13:55:42Z", "updated_at": "2021-09-17T16:09:40Z", "closed_at": "2021-09-17T16:09:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [X] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [X] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [X] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [X] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [X] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [X] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [X] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nWhen trying out the `PairedPCABiasDirection` from the fairness module on a Dutch word2vec[1], I noticed very bad results compared to the original implementation from Bolukbasi et al. (2016) [2] and my own. For example, when using the word pairs (man,vrouw) and (hij,zij) to signify gender, I would get the following bias scores that does not separate the two genders:\r\n\r\n```\r\nzij (she) \t-5.243651\r\nman (man) \t4.102735\r\nvrouw (woman) \t6.039383\r\nhij (he) \t8.196733\r\n```\r\n\r\nI realized that `PairedPCABiasDirection` does not work as intended, because the PCA centres the difference vectors. This should not happen, as is also noted by Rathore et al. (2021) [2]: \"because these vectors are the result of differences, we do not need to \u201ccenter\u201d them (remove their mean) first as when PCA is used on word vectors.\" The original paper (Bolukbasi et al., 2016) [3] and their code [4] also make clear that these vectors should not be centred.\r\n\r\nSo technically, we need SVD (`torch.svd`) instead of PCA, but another simple fix in the AllenNLP implementation would be to add `center=False` to the `torch.pca_lowrank` function. With the latter solution, I would get the expected division that is closer to Bolukbasi's implementation:\r\n\r\n```\r\nzij \t-7.313303\r\nvrouw \t0.071725\r\nman \t3.963416\r\nhij \t8.571440\r\n```\r\n\r\n[1] https://github.com/coosto/dutch-word-embeddings\r\n[2] https://arxiv.org/pdf/2104.02797.pdf\r\n[3] page 6 of https://papers.neurips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf\r\n[4] https://github.com/tolga-b/debiaswe/blob/10277b23e187ee4bd2b6872b507163ef4198686b/debiaswe/we.py#L235\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: \r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5395/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5395/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5385", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5385/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5385/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5385/events", "html_url": "https://github.com/allenai/allennlp/issues/5385", "id": 981960831, "node_id": "MDU6SXNzdWU5ODE5NjA4MzE=", "number": 5385, "title": "PytorchSeq2VecWrapper documentation", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-08-29T00:41:20Z", "updated_at": "2021-09-13T16:09:50Z", "closed_at": "2021-09-13T16:09:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "The docuemntation for PytorchSeq2VecWrapper states:\r\n\r\n    Note that we *require* you to pass sequence lengths when you call this module, to avoid subtle\r\n    bugs around masking.  If you already have a `PackedSequence` you can pass `None` as the\r\n    second parameter.\r\n\r\nhttps://github.com/allenai/allennlp/blob/28950215344900e5e04fa5c8a27e5753d4e8837e/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py#L38\r\n\r\nYet the second parameter of forward is `mask` rather than `length` so this doesn't appear to be the case, perhaps it was changed at some point?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5385/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5385/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5384", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5384/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5384/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5384/events", "html_url": "https://github.com/allenai/allennlp/issues/5384", "id": 981760715, "node_id": "MDU6SXNzdWU5ODE3NjA3MTU=", "number": 5384, "title": "Runtime error with convolution classifier", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-08-28T07:19:01Z", "updated_at": "2021-10-11T03:19:06Z", "closed_at": "2021-09-20T16:09:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've created a text classifier based on the `cnn-highway` encoder. It more or less works, but sometimes it crashes either during training or evaluation, the problem being that sometimes the input text isn't long enough for the CNN window size. It's mostly a problem during evaluation where I've been evaluating single strings, during training the batching tends to add enough padding to mask the issue.\r\n\r\nThe error is:\r\n\r\n> RuntimeError: Calculated padded input size per channel: (3). Kernel size: (4). Kernel size can't be greater than actual input size\r\n\r\n\r\nThe model is below, how do you pad each input sequence to a minimum length so the model doesn't occasionally fail?\r\n\r\n```\r\n{\r\n    vocabulary: {\r\n        type: \"from_instances\",\r\n        non_padded_namespaces: [],\r\n    },\r\n    train_data_path: TRAIN_PATH,\r\n    validation_data_path: DEV_PATH,\r\n    dataset_reader: {\r\n        type: \"text_classification_json\",\r\n        tokenizer: {\r\n          type: \"character\",\r\n          lowercase_characters: false\r\n        },\r\n        token_indexers: {\r\n            tokens: {\r\n                type: \"single_id\",\r\n            },\r\n        }\r\n    },\r\n    model: {\r\n        type: \"basic_classifier\",\r\n        text_field_embedder: {\r\n            token_embedders: {\r\n                tokens: {\r\n                    type: \"embedding\",\r\n                    embedding_dim: EMBEDDING_DIM,\r\n                },\r\n            }\r\n        },\r\n        seq2vec_encoder: {\r\n            # https://arxiv.org/pdf/1508.06615.pdf (Small)\r\n            type: \"cnn-highway\",\r\n            embedding_dim: EMBEDDING_DIM,\r\n            filters: [[1,25],[2,50],[3,125],[4,150],[5,175],[6,200]],\r\n            num_highway: 1,\r\n            projection_dim: 200\r\n        }\r\n    },\r\n    data_loader: {\r\n        batch_size: BATCH_SIZE,\r\n        shuffle: true\r\n    },\r\n    trainer: {\r\n      cuda_device: CUDA_DEVICE,\r\n      num_epochs: NUM_EPOCHS,\r\n      optimizer: {\r\n         lr: LEARNING_RATE,\r\n         type: \"adam\"\r\n      },\r\n      patience: 1,\r\n      validation_metric: \"+accuracy\"\r\n   }\r\n}\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5384/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5384/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5379", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5379/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5379/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5379/events", "html_url": "https://github.com/allenai/allennlp/issues/5379", "id": 979942609, "node_id": "MDU6SXNzdWU5Nzk5NDI2MDk=", "number": 5379, "title": "Cannot import name 'GradientDescentTrainer' from 'allennlp.training.trainer'", "user": {"login": "blackbirt-5", "id": 82014275, "node_id": "MDQ6VXNlcjgyMDE0Mjc1", "avatar_url": "https://avatars.githubusercontent.com/u/82014275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/blackbirt-5", "html_url": "https://github.com/blackbirt-5", "followers_url": "https://api.github.com/users/blackbirt-5/followers", "following_url": "https://api.github.com/users/blackbirt-5/following{/other_user}", "gists_url": "https://api.github.com/users/blackbirt-5/gists{/gist_id}", "starred_url": "https://api.github.com/users/blackbirt-5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/blackbirt-5/subscriptions", "organizations_url": "https://api.github.com/users/blackbirt-5/orgs", "repos_url": "https://api.github.com/users/blackbirt-5/repos", "events_url": "https://api.github.com/users/blackbirt-5/events{/privacy}", "received_events_url": "https://api.github.com/users/blackbirt-5/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-08-26T07:49:22Z", "updated_at": "2021-08-26T08:22:58Z", "closed_at": "2021-08-26T08:22:58Z", "author_association": "NONE", "active_lock_reason": null, "body": null, "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5379/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5379/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5375", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5375/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5375/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5375/events", "html_url": "https://github.com/allenai/allennlp/issues/5375", "id": 976928303, "node_id": "MDU6SXNzdWU5NzY5MjgzMDM=", "number": 5375, "title": "AllenNLP installation issue - No matching distribution found for torchvision<0.9.0,>=0.8.1", "user": {"login": "sandeepbhutani304", "id": 4421756, "node_id": "MDQ6VXNlcjQ0MjE3NTY=", "avatar_url": "https://avatars.githubusercontent.com/u/4421756?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sandeepbhutani304", "html_url": "https://github.com/sandeepbhutani304", "followers_url": "https://api.github.com/users/sandeepbhutani304/followers", "following_url": "https://api.github.com/users/sandeepbhutani304/following{/other_user}", "gists_url": "https://api.github.com/users/sandeepbhutani304/gists{/gist_id}", "starred_url": "https://api.github.com/users/sandeepbhutani304/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sandeepbhutani304/subscriptions", "organizations_url": "https://api.github.com/users/sandeepbhutani304/orgs", "repos_url": "https://api.github.com/users/sandeepbhutani304/repos", "events_url": "https://api.github.com/users/sandeepbhutani304/events{/privacy}", "received_events_url": "https://api.github.com/users/sandeepbhutani304/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-08-23T11:27:08Z", "updated_at": "2021-09-06T16:09:36Z", "closed_at": "2021-09-06T16:09:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "As per demos, we are expected to install AllenNLP using following command:\r\n`pip install allennlp==2.1.0 allennlp-models==2.1.0\r\n`\r\nBut it always throws error:\r\n```\r\n  ERROR: Could not find a version that satisfies the requirement torchvision<0.9.0,>=0.8.1 (from allennlp==2.1.0) (from versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.3.0, 0.4.1, 0.5.0, 0.9.0, 0.9.1, 0.10.0)\r\nERROR: No matching distribution found for torchvision<0.9.0,>=0.8.1 (from allennlp==2.1.0)\r\n```\r\n\r\nHave tried installing torchvision separately but the version demanded by AllenNLP is not available at all. As can be seen in error above the torchvision<0.9.0,>=0.8.1 is demanded, but the available versions are ... 0.5.0, 0.9.0 ...    \r\nWhat am I missing ?\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5375/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5375/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5369", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5369/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5369/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5369/events", "html_url": "https://github.com/allenai/allennlp/issues/5369", "id": 975074251, "node_id": "MDU6SXNzdWU5NzUwNzQyNTE=", "number": 5369, "title": "Possibility of a memory leak on gpu when using multi-process dataloader and executing `allennlp train` in a subprocess.", "user": {"login": "dhruvdcoder", "id": 4356534, "node_id": "MDQ6VXNlcjQzNTY1MzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/4356534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dhruvdcoder", "html_url": "https://github.com/dhruvdcoder", "followers_url": "https://api.github.com/users/dhruvdcoder/followers", "following_url": "https://api.github.com/users/dhruvdcoder/following{/other_user}", "gists_url": "https://api.github.com/users/dhruvdcoder/gists{/gist_id}", "starred_url": "https://api.github.com/users/dhruvdcoder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dhruvdcoder/subscriptions", "organizations_url": "https://api.github.com/users/dhruvdcoder/orgs", "repos_url": "https://api.github.com/users/dhruvdcoder/repos", "events_url": "https://api.github.com/users/dhruvdcoder/events{/privacy}", "received_events_url": "https://api.github.com/users/dhruvdcoder/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2395308352, "node_id": "MDU6TGFiZWwyMzk1MzA4MzUy", "url": "https://api.github.com/repos/allenai/allennlp/labels/question", "name": "question", "color": "1d76db", "default": true, "description": ""}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2021-08-19T21:45:22Z", "updated_at": "2021-08-28T03:49:17Z", "closed_at": "2021-08-28T03:49:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "I post this as a question because I am not sure if something like this can happen. However, if you deem that something like this can, I can come up with a minimal reproducible example.\r\n\r\n## Context\r\n\r\nI use [wandb sweeps](https://docs.wandb.ai/guides/sweeps/quickstart) to tune the parameters of my model. The wandb client creates a sweep \"agent\" which communicates with the wandb server and receives hyperparameters which are then used to execute `allennlp train` with parameter overrides. The sweep agent executes `allennlp train` in a subprocess. Lets call one such execution as a 'run'. Different hyperparameter settings are tried serially by the agent by executing runs serially. Sometimes, the wandb server asks the sweep agent to end an ongoing run. The sweep agent does so by calling `.terminate()` on the `allennlp train` subprocess. Note that the `finally` blocks in the multiprocess dataloader will not be executed when `allennlp train` receives a SIGTERM ([ref](https://stackoverflow.com/questions/49262379/does-finally-always-execute-in-python)).\r\n\r\n## Problem\r\n\r\nAs I understand the 'multiprocess' dataloader is the default now. For smaller datasets, I do not set the `num_workers` and hence, the dataloader does not spawn any children processes. In this scenario, a single sweep agent runs hundreds of runs without any issue.\r\n\r\nHowever, with larger datasets, when I set `num_workers=5`, all the runs after the first runs started by an agent fail due to CUDA memory exhaustion. On closer inspection, I observed that when an agent stops a run and starts the next run, the gpu memory of the first run is not released and the second run only has the leftover memory to use and hence fails. Moreover, I also see that the number of processes related to sweep agent increase with time--meaning that the termination of runs might be leaving zombie processes. \r\n\r\nDo you think that this could be a valid explanation of my issue with using multiprocess dataloader with wandb sweep? If so what further information would I need to fix this issue? One thing, I can think of is adding a signal handler for SIGTERM and have it generate a `KeyboardInterrupt` as that will ensure that all the `finally` blocks are executed.\r\n\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5369/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5369/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5364", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5364/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5364/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5364/events", "html_url": "https://github.com/allenai/allennlp/issues/5364", "id": 973488693, "node_id": "MDU6SXNzdWU5NzM0ODg2OTM=", "number": 5364, "title": "gpu_memory_mb", "user": {"login": "ICanFlyGFC", "id": 50896307, "node_id": "MDQ6VXNlcjUwODk2MzA3", "avatar_url": "https://avatars.githubusercontent.com/u/50896307?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ICanFlyGFC", "html_url": "https://github.com/ICanFlyGFC", "followers_url": "https://api.github.com/users/ICanFlyGFC/followers", "following_url": "https://api.github.com/users/ICanFlyGFC/following{/other_user}", "gists_url": "https://api.github.com/users/ICanFlyGFC/gists{/gist_id}", "starred_url": "https://api.github.com/users/ICanFlyGFC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ICanFlyGFC/subscriptions", "organizations_url": "https://api.github.com/users/ICanFlyGFC/orgs", "repos_url": "https://api.github.com/users/ICanFlyGFC/repos", "events_url": "https://api.github.com/users/ICanFlyGFC/events{/privacy}", "received_events_url": "https://api.github.com/users/ICanFlyGFC/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2021-08-18T09:56:57Z", "updated_at": "2021-09-01T16:12:52Z", "closed_at": "2021-09-01T16:12:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\nI use allennlp 0.9.0 and run my code without GPU.\r\nI also use \"cuda_device\": -1\r\nbut:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/allennlp/common/util.py\", line 378, in gpu_memory_mb\r\n    encoding='utf-8')\r\n  File \"/usr/lib/python3.7/subprocess.py\", line 411, in check_output\r\n    **kwargs).stdout\r\n  File \"/usr/lib/python3.7/subprocess.py\", line 512, in run\r\n    output=stdout, stderr=stderr)\r\nsubprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\r\n2021-08-18 09:42:41,987 - INFO - allennlp.training.trainer - Training\r\n  0%|          | 0/110 [00:00<?, ?it/s]^C\r\n\r\nthanks\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5364/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5364/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5359", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5359/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5359/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5359/events", "html_url": "https://github.com/allenai/allennlp/issues/5359", "id": 971492033, "node_id": "MDU6SXNzdWU5NzE0OTIwMzM=", "number": 5359, "title": "Unable to open file", "user": {"login": "lenyabloko", "id": 55606, "node_id": "MDQ6VXNlcjU1NjA2", "avatar_url": "https://avatars.githubusercontent.com/u/55606?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lenyabloko", "html_url": "https://github.com/lenyabloko", "followers_url": "https://api.github.com/users/lenyabloko/followers", "following_url": "https://api.github.com/users/lenyabloko/following{/other_user}", "gists_url": "https://api.github.com/users/lenyabloko/gists{/gist_id}", "starred_url": "https://api.github.com/users/lenyabloko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lenyabloko/subscriptions", "organizations_url": "https://api.github.com/users/lenyabloko/orgs", "repos_url": "https://api.github.com/users/lenyabloko/repos", "events_url": "https://api.github.com/users/lenyabloko/events{/privacy}", "received_events_url": "https://api.github.com/users/lenyabloko/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2021-08-16T08:25:33Z", "updated_at": "2021-08-30T05:16:55Z", "closed_at": "2021-08-30T05:16:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x ] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [ x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nOSError                                   Traceback (most recent call last)\r\n<ipython-input-9-6a908f3e6a4e> in <module>()\r\n      1 from allennlp.predictors.predictor import Predictor\r\n      2 import allennlp_models.structured_prediction\r\n----> 3 predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/elmo-constituency-parser-2020.02.10.tar.gz\")\r\n\r\n25 frames\r\n/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py in make_fid(name, mode, userblock_size, fapl, fcpl, swmr)\r\n    188         if swmr and swmr_support:\r\n    189             flags |= h5f.ACC_SWMR_READ\r\n--> 190         fid = h5f.open(name, flags, fapl=fapl)\r\n    191     elif mode == 'r+':\r\n    192         fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)\r\n\r\nh5py/_objects.pyx in h5py._objects.with_phil.wrapper()\r\n\r\nh5py/_objects.pyx in h5py._objects.with_phil.wrapper()\r\n\r\nh5py/h5f.pyx in h5py.h5f.open()\r\n\r\nOSError: Unable to open file (truncated file: eof = 335544320, sblock->base_addr = 0, stored_eof = 374434792)\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Google Colab\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.12.0\r\nalabaster==0.7.12\r\nalbumentations==0.1.12\r\nallennlp==2.6.0\r\nallennlp-models==2.6.0\r\naltair==4.1.0\r\nappdirs==1.4.4\r\nargcomplete==1.12.3\r\nargon2-cffi==20.1.0\r\narviz==0.11.2\r\nastor==0.8.1\r\nastropy==4.3.1\r\nastunparse==1.6.3\r\nasync-generator==1.10\r\natari-py==0.2.9\r\natomicwrites==1.4.0\r\nattrs==21.2.0\r\naudioread==2.1.9\r\nautograd==1.3\r\nBabel==2.9.1\r\nbackcall==0.2.0\r\nbackports.csv==1.0.7\r\nbeautifulsoup4==4.6.3\r\nbleach==4.0.0\r\nblis==0.4.1\r\nbokeh==2.3.3\r\nboto3==1.18.21\r\nbotocore==1.21.21\r\nBottleneck==1.3.2\r\nbranca==0.4.2\r\nbs4==0.0.1\r\nCacheControl==0.12.6\r\ncached-property==1.5.2\r\ncachetools==4.2.2\r\ncatalogue==1.0.0\r\ncertifi==2021.5.30\r\ncffi==1.14.6\r\ncftime==1.5.0\r\nchardet==3.0.4\r\ncharset-normalizer==2.0.4\r\nchecklist==0.0.11\r\ncheroot==8.5.2\r\nCherryPy==18.6.1\r\nclick==7.1.2\r\ncloudpickle==1.3.0\r\ncmake==3.12.0\r\ncmdstanpy==0.9.5\r\ncolorcet==2.0.6\r\ncolorlover==0.3.0\r\ncommunity==1.0.0b1\r\nconfigparser==5.0.2\r\nconllu==4.4\r\ncontextlib2==0.5.5\r\nconvertdate==2.3.2\r\ncoverage==3.7.1\r\ncoveralls==0.5\r\ncrcmod==1.7\r\ncryptography==3.4.7\r\ncufflinks==0.17.3\r\ncupy-cuda101==9.1.0\r\ncvxopt==1.2.6\r\ncvxpy==1.0.31\r\ncycler==0.10.0\r\ncymem==2.0.5\r\nCython==0.29.24\r\ndaft==0.0.4\r\ndask==2.12.0\r\ndatascience==0.10.6\r\ndebugpy==1.0.0\r\ndecorator==4.4.2\r\ndefusedxml==0.7.1\r\ndescartes==1.1.0\r\ndill==0.3.4\r\ndistributed==1.25.3\r\ndlib @ file:///dlib-19.18.0-cp37-cp37m-linux_x86_64.whl\r\ndm-tree==0.1.6\r\ndocker-pycreds==0.4.0\r\ndocopt==0.6.2\r\ndocutils==0.17.1\r\ndopamine-rl==1.0.5\r\nearthengine-api==0.1.277\r\neasydict==1.9\r\necos==2.0.7.post1\r\neditdistance==0.5.3\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nentrypoints==0.3\r\nephem==4.0.0.2\r\net-xmlfile==1.1.0\r\nfa2==0.3.5\r\nfastai==1.0.61\r\nfastdtw==0.3.4\r\nfastprogress==1.0.0\r\nfastrlock==0.6\r\nfbprophet==0.7.1\r\nfeather-format==0.4.1\r\nfeedparser==6.0.8\r\nfilelock==3.0.12\r\nfirebase-admin==4.4.0\r\nfix-yahoo-finance==0.0.22\r\nFlask==1.1.4\r\nflatbuffers==1.12\r\nfolium==0.8.3\r\nftfy==6.0.3\r\nfuture==0.16.0\r\ngast==0.4.0\r\nGDAL==2.2.2\r\ngdown==3.6.4\r\ngensim==3.6.0\r\ngeographiclib==1.52\r\ngeopy==1.17.0\r\ngin-config==0.4.0\r\ngitdb==4.0.7\r\nGitPython==3.1.18\r\nglob2==0.7\r\ngoogle==2.0.3\r\ngoogle-api-core==1.26.3\r\ngoogle-api-python-client==1.12.8\r\ngoogle-auth==1.34.0\r\ngoogle-auth-httplib2==0.0.4\r\ngoogle-auth-oauthlib==0.4.5\r\ngoogle-cloud-bigquery==1.21.0\r\ngoogle-cloud-bigquery-storage==1.1.0\r\ngoogle-cloud-core==1.7.2\r\ngoogle-cloud-datastore==1.8.0\r\ngoogle-cloud-firestore==1.7.0\r\ngoogle-cloud-language==1.2.0\r\ngoogle-cloud-storage==1.41.1\r\ngoogle-cloud-translate==1.5.0\r\ngoogle-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\r\ngoogle-crc32c==1.1.2\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==1.3.3\r\ngoogleapis-common-protos==1.53.0\r\ngoogledrivedownloader==0.4\r\ngraphql-core==3.1.5\r\ngraphviz==0.10.1\r\ngreenlet==1.1.1\r\ngrpcio==1.34.1\r\ngspread==3.0.1\r\ngspread-dataframe==3.0.8\r\ngym==0.17.3\r\nh5py==3.1.0\r\nHeapDict==1.0.1\r\nhijri-converter==2.1.3\r\nholidays==0.10.5.2\r\nholoviews==1.14.5\r\nhtml5lib==1.0.1\r\nhttpimport==0.5.18\r\nhttplib2==0.17.4\r\nhttplib2shim==0.0.3\r\nhuggingface-hub==0.0.12\r\nhumanize==0.5.1\r\nhyperopt==0.1.2\r\nideep4py==2.0.0.post3\r\nidna==2.10\r\nimageio==2.4.1\r\nimagesize==1.2.0\r\nimbalanced-learn==0.4.3\r\nimblearn==0.0\r\nimgaug==0.2.9\r\nimportlib-metadata==4.6.3\r\nimportlib-resources==5.2.2\r\nimutils==0.5.4\r\ninflect==2.1.0\r\niniconfig==1.1.1\r\ninstall==1.3.4\r\nintel-openmp==2021.3.0\r\nintervaltree==2.1.0\r\nipykernel==4.10.1\r\nipython==5.5.0\r\nipython-genutils==0.2.0\r\nipython-sql==0.3.9\r\nipywidgets==7.6.3\r\niso-639==0.4.5\r\nitsdangerous==1.1.0\r\njaraco.classes==3.2.1\r\njaraco.collections==3.4.0\r\njaraco.functools==3.3.0\r\njaraco.text==3.5.1\r\njax==0.2.17\r\njaxlib @ https://storage.googleapis.com/jax-releases/cuda110/jaxlib-0.1.69+cuda110-cp37-none-manylinux2010_x86_64.whl\r\njdcal==1.4.1\r\njedi==0.18.0\r\njieba==0.42.1\r\nJinja2==2.11.3\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njpeg4py==0.1.4\r\njsonnet==0.17.0\r\njsonschema==2.6.0\r\njupyter==1.0.0\r\njupyter-client==5.3.5\r\njupyter-console==5.2.0\r\njupyter-core==4.7.1\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.0\r\nkaggle==1.5.12\r\nkapre==0.3.5\r\nKeras==2.4.3\r\nkeras-nightly==2.5.0.dev2021032900\r\nKeras-Preprocessing==1.1.2\r\nkeras-vis==0.4.1\r\nkiwisolver==1.3.1\r\nkorean-lunar-calendar==0.2.1\r\nlibrosa==0.8.1\r\nlightgbm==2.2.3\r\nllvmlite==0.34.0\r\nlmdb==0.99\r\nLunarCalendar==0.0.9\r\nlxml==4.2.6\r\nMarkdown==3.3.4\r\nMarkupSafe==2.0.1\r\nmatplotlib==3.2.2\r\nmatplotlib-inline==0.1.2\r\nmatplotlib-venn==0.11.6\r\nmissingno==0.5.0\r\nmistune==0.8.4\r\nmizani==0.6.0\r\nmkl==2019.0\r\nmlxtend==0.14.0\r\nmore-itertools==8.8.0\r\nmoviepy==0.2.3.5\r\nmpmath==1.2.1\r\nmsgpack==1.0.2\r\nmultiprocess==0.70.12.2\r\nmultitasking==0.0.9\r\nmunch==2.5.0\r\nmurmurhash==1.0.5\r\nmusic21==5.5.0\r\nnatsort==5.5.0\r\nnbclient==0.5.3\r\nnbconvert==5.6.1\r\nnbformat==5.1.3\r\nnest-asyncio==1.5.1\r\nnetCDF4==1.5.7\r\nnetworkx==2.6.2\r\nnibabel==3.0.2\r\nnltk==3.2.5\r\nnotebook==5.3.1\r\nnumba==0.51.2\r\nnumexpr==2.7.3\r\nnumpy==1.19.5\r\nnvidia-ml-py3==7.352.0\r\noauth2client==4.1.3\r\noauthlib==3.1.1\r\nokgrade==0.4.3\r\nopencv-contrib-python==4.1.2.30\r\nopencv-python==4.1.2.30\r\nopenpyxl==2.5.9\r\nopt-einsum==3.3.0\r\nosqp==0.6.2.post0\r\noverrides==3.1.0\r\npackaging==21.0\r\npalettable==3.3.0\r\npandas==1.1.5\r\npandas-datareader==0.9.0\r\npandas-gbq==0.13.3\r\npandas-profiling==1.4.1\r\npandocfilters==1.4.3\r\npanel==0.12.1\r\nparam==1.11.1\r\nparso==0.8.2\r\npathlib==1.0.1\r\npathtools==0.1.2\r\npatsy==0.5.1\r\npatternfork-nosql==3.6\r\npdfminer.six==20201018\r\npep517==0.11.0\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.1.2\r\npip-tools==6.2.0\r\nplac==1.1.3\r\nplotly==4.4.1\r\nplotnine==0.6.0\r\npluggy==0.7.1\r\npooch==1.4.0\r\nportend==2.7.1\r\nportpicker==1.3.9\r\nprefetch-generator==1.0.1\r\npreshed==3.0.5\r\nprettytable==2.1.0\r\nprogressbar2==3.38.0\r\nprometheus-client==0.11.0\r\npromise==2.3\r\nprompt-toolkit==1.0.18\r\nprotobuf==3.17.3\r\npsutil==5.4.8\r\npsycopg2==2.7.6.1\r\nptyprocess==0.7.0\r\npy==1.10.0\r\npy-rouge==1.1\r\npyarrow==3.0.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycocotools==2.0.2\r\npycparser==2.20\r\npyct==0.4.8\r\npydata-google-auth==1.2.0\r\npydot==1.3.0\r\npydot-ng==2.0.0\r\npydotplus==2.0.2\r\nPyDrive==1.3.1\r\npyemd==0.5.1\r\npyerfa==2.0.0\r\npyglet==1.5.0\r\nPygments==2.6.1\r\npygobject==3.26.1\r\npymc3==3.11.2\r\nPyMeeus==0.5.11\r\npymongo==3.12.0\r\npymystem3==0.2.0\r\nPyOpenGL==3.1.5\r\npyparsing==2.4.7\r\npyrsistent==0.18.0\r\npysndfile==1.3.8\r\nPySocks==1.7.1\r\npystan==2.19.1.1\r\npytest==3.6.4\r\npython-apt==0.0.0\r\npython-chess==0.23.11\r\npython-dateutil==2.8.2\r\npython-docx==0.8.11\r\npython-louvain==0.15\r\npython-slugify==5.0.2\r\npython-utils==2.5.6\r\npytz==2018.9\r\npyviz-comms==2.1.0\r\nPyWavelets==1.1.1\r\nPyYAML==3.13\r\npyzmq==22.2.1\r\nqdldl==0.1.5.post0\r\nqtconsole==5.1.1\r\nQtPy==1.9.0\r\nregex==2019.12.20\r\nrequests==2.23.0\r\nrequests-oauthlib==1.3.0\r\nresampy==0.2.2\r\nretrying==1.3.3\r\nrpy2==3.4.5\r\nrsa==4.7.2\r\ns3transfer==0.5.0\r\nsacremoses==0.0.45\r\nscikit-image==0.16.2\r\nscikit-learn==0.22.2.post1\r\nscipy==1.4.1\r\nscreen-resolution-extra==0.0.0\r\nscs==2.1.4\r\nseaborn==0.11.1\r\nsemver==2.13.0\r\nSend2Trash==1.8.0\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.3.1\r\nsetuptools-git==1.2\r\nsgmllib3k==1.0.0\r\nShapely==1.7.1\r\nshortuuid==1.0.1\r\nsimplegeneric==0.8.1\r\nsix==1.15.0\r\nsklearn==0.0\r\nsklearn-pandas==1.8.0\r\nsmart-open==5.1.0\r\nsmmap==4.0.0\r\nsnowballstemmer==2.1.0\r\nsortedcontainers==2.4.0\r\nSoundFile==0.10.3.post1\r\nspacy==2.2.4\r\nSphinx==1.8.5\r\nsphinxcontrib-serializinghtml==1.1.5\r\nsphinxcontrib-websupport==1.2.4\r\nSQLAlchemy==1.4.22\r\nsqlparse==0.4.1\r\nsrsly==1.0.5\r\nstatsmodels==0.10.2\r\nsympy==1.7.1\r\ntables==3.4.4\r\ntabulate==0.8.9\r\ntblib==1.7.0\r\ntempora==4.1.1\r\ntensorboard==2.5.0\r\ntensorboard-data-server==0.6.1\r\ntensorboard-plugin-wit==1.8.0\r\ntensorboardX==2.4\r\ntensorflow @ file:///tensorflow-2.5.0-cp37-cp37m-linux_x86_64.whl\r\ntensorflow-datasets==4.0.1\r\ntensorflow-estimator==2.5.0\r\ntensorflow-gcs-config==2.5.0\r\ntensorflow-hub==0.12.0\r\ntensorflow-metadata==1.2.0\r\ntensorflow-probability==0.13.0\r\ntermcolor==1.1.0\r\nterminado==0.10.1\r\ntestpath==0.5.0\r\ntext-unidecode==1.3\r\ntextblob==0.15.3\r\nTheano-PyMC==1.1.2\r\nthinc==7.4.0\r\ntifffile==2021.8.8\r\ntokenizers==0.10.3\r\ntoml==0.10.2\r\ntomli==1.2.1\r\ntoolz==0.11.1\r\ntorch @ https://download.pytorch.org/whl/cu102/torch-1.9.0%2Bcu102-cp37-cp37m-linux_x86_64.whl\r\ntorchsummary==1.5.1\r\ntorchtext==0.10.0\r\ntorchvision @ https://download.pytorch.org/whl/cu102/torchvision-0.10.0%2Bcu102-cp37-cp37m-linux_x86_64.whl\r\ntornado==5.1.1\r\ntqdm==4.62.0\r\ntraitlets==5.0.5\r\ntransformers==4.8.2\r\ntweepy==3.10.0\r\ntypeguard==2.7.1\r\ntyping-extensions==3.7.4.3\r\ntzlocal==1.5.1\r\nuritemplate==3.0.1\r\nurllib3==1.25.11\r\nvega-datasets==0.9.0\r\nwandb==0.11.1\r\nwasabi==0.8.2\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nwordcloud==1.5.0\r\nwrapt==1.12.1\r\nxarray==0.18.2\r\nxgboost==0.90\r\nxkit==0.0.0\r\nxlrd==1.1.0\r\nxlwt==1.3.0\r\nyellowbrick==0.9.1\r\nzc.lockfile==2.0\r\nzict==2.0.0\r\nzipp==3.5.0\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n!pip install allennlp allennlp-models\r\n\r\n!pip install nltk\r\n!pip install tqdm\r\n!pip install spacy \r\n!python -m spacy download en_core_web_sm\r\n\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.structured_prediction\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/elmo-constituency-parser-2020.02.10.tar.gz\")\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5359/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5359/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5354", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5354/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5354/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5354/events", "html_url": "https://github.com/allenai/allennlp/issues/5354", "id": 965797568, "node_id": "MDU6SXNzdWU5NjU3OTc1Njg=", "number": 5354, "title": "the last decoding step miscalculated in the forward_loss of CopyNet?", "user": {"login": "GregoryZeng", "id": 8487378, "node_id": "MDQ6VXNlcjg0ODczNzg=", "avatar_url": "https://avatars.githubusercontent.com/u/8487378?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GregoryZeng", "html_url": "https://github.com/GregoryZeng", "followers_url": "https://api.github.com/users/GregoryZeng/followers", "following_url": "https://api.github.com/users/GregoryZeng/following{/other_user}", "gists_url": "https://api.github.com/users/GregoryZeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/GregoryZeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GregoryZeng/subscriptions", "organizations_url": "https://api.github.com/users/GregoryZeng/orgs", "repos_url": "https://api.github.com/users/GregoryZeng/repos", "events_url": "https://api.github.com/users/GregoryZeng/events{/privacy}", "received_events_url": "https://api.github.com/users/GregoryZeng/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2021-08-11T03:17:29Z", "updated_at": "2021-08-19T18:10:08Z", "closed_at": "2021-08-19T18:10:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nHi, I was recently reading through the implementation of [CopyNet](https://github.com/allenai/allennlp-models/blob/main/allennlp_models/generation/models/copynet_seq2seq.py), which is rather delicate :)\r\n\r\nIn the forward_loss of CopyNet, I find a conditional statement that determines if the target of the current step is the END token (See Line [526)](https://github.com/allenai/allennlp-models/blob/31649f5776522ae60661499c595f73e1c019d72c/allennlp_models/generation/models/copynet_seq2seq.py#L526). \r\n```python\r\n            # If the previous target token was copied, we use the special copy token.\r\n            # But the end target token will always be THE end token, so we know\r\n            # it was not copied.\r\n            if timestep < num_decoding_steps - 1:\r\n                # Get mask tensor indicating which instances were copied.\r\n                # shape: (batch_size,)\r\n                copied = (\r\n                    (input_choices == self._oov_index) & (target_to_source.sum(-1) > 0)\r\n                ).long()\r\n                # shape: (batch_size,)\r\n                input_choices = input_choices * (1 - copied) + copy_input_choices * copied\r\n                # shape: (batch_size, source_sequence_length)\r\n                target_to_source = state[\"source_token_ids\"] == target_token_ids[\r\n                    :, timestep + 1\r\n                ].unsqueeze(-1)\r\n```\r\n\r\nHowever, Line [497](https://github.com/allenai/allennlp-models/blob/31649f5776522ae60661499c595f73e1c019d72c/allennlp_models/generation/models/copynet_seq2seq.py#L497) has already excluded the potential END token. Therefore I am confused if the if-statement is correct in Line 526.\r\n\r\n```python\r\n        # The last input from the target is either padding or the end symbol.\r\n        # Either way, we don't have to process it.\r\n        num_decoding_steps = target_sequence_length - 1\r\n```\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5354/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5351", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5351/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5351/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5351/events", "html_url": "https://github.com/allenai/allennlp/issues/5351", "id": 964556378, "node_id": "MDU6SXNzdWU5NjQ1NTYzNzg=", "number": 5351, "title": "LogWriter log_batch missing metrics?", "user": {"login": "teffland", "id": 5906031, "node_id": "MDQ6VXNlcjU5MDYwMzE=", "avatar_url": "https://avatars.githubusercontent.com/u/5906031?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teffland", "html_url": "https://github.com/teffland", "followers_url": "https://api.github.com/users/teffland/followers", "following_url": "https://api.github.com/users/teffland/following{/other_user}", "gists_url": "https://api.github.com/users/teffland/gists{/gist_id}", "starred_url": "https://api.github.com/users/teffland/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teffland/subscriptions", "organizations_url": "https://api.github.com/users/teffland/orgs", "repos_url": "https://api.github.com/users/teffland/repos", "events_url": "https://api.github.com/users/teffland/events{/privacy}", "received_events_url": "https://api.github.com/users/teffland/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2021-08-10T03:18:34Z", "updated_at": "2021-08-19T18:32:37Z", "closed_at": "2021-08-19T18:32:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nJust updated from v0.9 to v2.6, switched to using callbacks and noticed that my metrics were not logging to tensorboard or wandb at the batch level anymore (used to be under `epoch_metrics/*`, now they're only per epoch.\r\n\r\nLooking at the source code for [`LogWriterCallback`](https://github.com/allenai/allennlp/blob/main/allennlp/training/callbacks/log_writer.py#L229-240) I see that in `log_batch` the method takes the `metrics` but doesn't use them, instead only using `(\"batch_loss\", \"batch_reg_loss\")` in `metrics_to_log`.\r\n\r\nShouldn't `metrics_to_log` also contain the entries from the input `metrics` dict?  Or perhaps I'm missing some other configuration option to control this?\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux ubuntu 18.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.1\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5351/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5351/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5346", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5346/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5346/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5346/events", "html_url": "https://github.com/allenai/allennlp/issues/5346", "id": 963553420, "node_id": "MDU6SXNzdWU5NjM1NTM0MjA=", "number": 5346, "title": "'optional' multitask scheduler is not optional", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2021-08-09T00:38:59Z", "updated_at": "2021-08-12T09:06:29Z", "closed_at": "2021-08-12T09:06:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "The docstring for the `MultiTaskDataLoader` indicates the `scheduler` argument is optional\r\n\r\nhttps://github.com/allenai/allennlp/blob/311f1104bf4762b7b5c1172eb874276343d562c9/allennlp/data/data_loaders/multitask_data_loader.py#L54\r\n\r\nHowever, it's declared as a required positional argument \r\n\r\nhttps://github.com/allenai/allennlp/blob/311f1104bf4762b7b5c1172eb874276343d562c9/allennlp/data/data_loaders/multitask_data_loader.py#L106\r\n\r\nAnd I don't see any indication that if not supplied it's set to `HomogeneousRoundRobinScheduler`", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5346/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5346/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5345", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5345/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5345/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5345/events", "html_url": "https://github.com/allenai/allennlp/issues/5345", "id": 963438219, "node_id": "MDU6SXNzdWU5NjM0MzgyMTk=", "number": 5345, "title": "Scaled Dot Product Attention matmul error", "user": {"login": "gabeorlanski", "id": 18234433, "node_id": "MDQ6VXNlcjE4MjM0NDMz", "avatar_url": "https://avatars.githubusercontent.com/u/18234433?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gabeorlanski", "html_url": "https://github.com/gabeorlanski", "followers_url": "https://api.github.com/users/gabeorlanski/followers", "following_url": "https://api.github.com/users/gabeorlanski/following{/other_user}", "gists_url": "https://api.github.com/users/gabeorlanski/gists{/gist_id}", "starred_url": "https://api.github.com/users/gabeorlanski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gabeorlanski/subscriptions", "organizations_url": "https://api.github.com/users/gabeorlanski/orgs", "repos_url": "https://api.github.com/users/gabeorlanski/repos", "events_url": "https://api.github.com/users/gabeorlanski/events{/privacy}", "received_events_url": "https://api.github.com/users/gabeorlanski/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2021-08-08T13:55:35Z", "updated_at": "2021-08-17T23:51:51Z", "closed_at": "2021-08-17T23:51:51Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Checklist\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nWhen trying to use the [`ScaledDotProductAttention`](https://github.com/allenai/allennlp/blob/main/allennlp/modules/attention/scaled_dot_product_attention.py) with the [`AutoRegressiveSeqDecoder`](https://github.com/allenai/allennlp-models/blob/main/allennlp_models/generation/modules/seq_decoders/auto_regressive.py) from [`allennlp-models`](https://github.com/allenai/allennlp-models), a mat mul error is raised stating that the dimensions do not align. \r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\click\\core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\click\\core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"C:/Coding/merlin_labs/nn-semparse/debug_scripts/debug_train.py\", line 51, in debug_train\r\n    disable_tracking=disable_tracking\r\n  File \"C:\\Coding\\merlin_labs\\nn-semparse\\src\\commands\\train_extended.py\", line 359, in train_model\r\n    file_friendly_logging=file_friendly_logging,\r\n  File \"C:\\Coding\\merlin_labs\\nn-semparse\\src\\commands\\train_extended.py\", line 586, in _train_worker\r\n    metrics = train_loop.run()\r\n  File \"C:\\Coding\\merlin_labs\\nn-semparse\\src\\commands\\train_extended.py\", line 658, in run\r\n    return self.trainer.train()\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\allennlp\\training\\gradient_descent_trainer.py\", line 706, in train\r\n    metrics, epoch = self._try_train()\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\allennlp\\training\\gradient_descent_trainer.py\", line 727, in _try_train\r\n    train_metrics = self._train_epoch(epoch)\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\allennlp\\training\\gradient_descent_trainer.py\", line 458, in _train_epoch\r\n    batch_outputs = self.batch_outputs(batch, for_training=True)\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\allennlp\\training\\gradient_descent_trainer.py\", line 351, in batch_outputs\r\n    output_dict = self._pytorch_model(**batch)\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"C:\\Coding\\merlin_labs\\nn-semparse\\src\\models\\simple_seq2seq.py\", line 126, in forward\r\n    outputs = self._decoder(state, target_tokens)\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"C:\\Coding\\merlin_labs\\nn-semparse\\src\\models\\modules\\extendable_auto_regressive.py\", line 451, in forward\r\n    output_dict = self._forward_loss(state_forward_loss, target_tokens)\r\n  File \"C:\\Coding\\merlin_labs\\nn-semparse\\src\\models\\modules\\extendable_auto_regressive.py\", line 245, in _forward_loss\r\n    effective_last_prediction, state)\r\n  File \"C:\\Coding\\merlin_labs\\nn-semparse\\src\\models\\modules\\extendable_auto_regressive.py\", line 321, in _prepare_output_projections\r\n    previous_steps_predictions=previous_steps_predictions,\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\allennlp_models\\generation\\modules\\decoder_nets\\lstm_cell.py\", line 118, in forward\r\n    decoder_hidden, encoder_outputs, source_mask\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\allennlp_models\\generation\\modules\\decoder_nets\\lstm_cell.py\", line 71, in _prepare_attended_input\r\n    input_weights = self._attention(decoder_hidden_state, encoder_outputs, encoder_outputs_mask)\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\allennlp\\modules\\attention\\attention.py\", line 45, in forward\r\n    similarities = self._forward_internal(vector, matrix)\r\n  File \"C:\\ProgramData\\Miniconda3\\envs\\nn-semparse\\lib\\site-packages\\allennlp\\modules\\attention\\scaled_dot_product_attention.py\", line 31, in _forward_internal\r\n    scores = torch.matmul(vector, matrix)\r\nRuntimeError: mat1 dim 1 must match mat2 dim 0\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nUpon looking into the code for [`ScaledDotProductAttention`](https://github.com/allenai/allennlp/blob/main/allennlp/modules/attention/scaled_dot_product_attention.py), I noticed that it is missing the transpose from the equation 1 in the [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf). This appears to be fixed with [this PR](https://github.com/allenai/allennlp/pull/4901) but it was closed without merging. That issue is addressed by using `matrix.bmm(vector.unsqueeze(-1)).squeeze(-1)` instead of the `torch.matmul(vector, matrix)` that is currently present. It is worth noting that the normal [`DotProductAttention`](https://github.com/allenai/allennlp/blob/main/allennlp/modules/attention/dot_product_attention.py) uses `matrix.bmm(vector.unsqueeze(-1)).squeeze(-1)` instead of `torch.matmul(vector, matrix)`. \r\n\r\nI can open a PR with the fix from the original pull request, but I am not sure it would be easier than just reopening the original PR and merging.\r\n\r\n## Related issues or possible duplicates\r\n\r\n- [Scaled Dot Product Attention Pull Request](https://github.com/allenai/allennlp/pull/4901)\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Windows\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.10\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==2.5.0\r\nallennlp-models==2.5.0\r\nargon2-cffi==20.1.0\r\nasync-generator==1.10\r\natomicwrites==1.4.0\r\nattrs==21.2.0\r\nbackcall==0.2.0\r\nbackports.csv==1.0.7\r\nbeautifulsoup4==4.9.3\r\nbleach==3.3.0\r\nblis==0.7.4\r\nboto3==1.17.101\r\nbotocore==1.20.101\r\ncached-property==1.5.2\r\ncachetools==4.2.2\r\ncatalogue==2.0.4\r\ncertifi==2021.5.30\r\ncffi==1.14.5\r\nchardet==4.0.0\r\nchecklist==0.0.11\r\ncheroot==8.5.2\r\nCherryPy==18.6.0\r\nclick==7.1.2\r\ncolorama==0.4.4\r\nconfigparser==5.0.2\r\nconllu==4.4\r\ncoverage @ file:///C:/ci/coverage_1614614910274/work\r\ncryptography==3.4.7\r\ncymem==2.0.5\r\ndecorator==5.0.9\r\ndefusedxml==0.7.1\r\ndill==0.3.4\r\ndocker-pycreds==0.4.0\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl\r\nentrypoints==0.3\r\nfeedparser==6.0.8\r\nfilelock==3.0.12\r\nftfy==6.0.3\r\nfuture==0.18.2\r\ngitdb==4.0.7\r\nGitPython==3.1.18\r\ngoogle-api-core==1.30.0\r\ngoogle-auth==1.32.0\r\ngoogle-cloud-core==1.7.1\r\ngoogle-cloud-storage==1.38.0\r\ngoogle-crc32c==1.1.2\r\ngoogle-resumable-media==1.3.1\r\ngoogleapis-common-protos==1.53.0\r\nh5py==3.3.0\r\nhuggingface-hub==0.0.8\r\nidna==2.10\r\nimportlib-metadata==4.6.0\r\niniconfig==1.1.1\r\nipykernel==5.5.5\r\nipython==7.25.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.3\r\niso-639==0.4.5\r\njaraco.classes==3.2.1\r\njaraco.collections==3.3.0\r\njaraco.functools==3.3.0\r\njaraco.text==3.5.0\r\njedi==0.18.0\r\nJinja2==3.0.1\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==6.1.12\r\njupyter-console==6.4.0\r\njupyter-core==4.7.1\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.0\r\nlmdb==1.2.1\r\nlxml==4.6.3\r\nMarkupSafe==2.0.1\r\nmatplotlib-inline==0.1.2\r\nmistune==0.8.4\r\nmore-itertools==8.8.0\r\nmunch==2.5.0\r\nmurmurhash==1.0.5\r\nnbclient==0.5.3\r\nnbconvert==6.1.0\r\nnbformat==5.1.3\r\nnest-asyncio==1.5.1\r\nnltk==3.6.2\r\nnotebook==6.4.0\r\nnumpy==1.21.0\r\noverrides==3.1.0\r\npackaging==20.9\r\npandocfilters==1.4.3\r\nparso==0.8.2\r\npathtools==0.1.2\r\npathy==0.6.0\r\npatternfork-nosql==3.6\r\npdfminer.six==20201018\r\npickleshare==0.7.5\r\nPillow==8.2.0\r\npluggy==0.13.1\r\nportalocker==2.0.0\r\nportend==2.7.1\r\npreshed==3.0.5\r\nprometheus-client==0.11.0\r\npromise==2.3\r\nprompt-toolkit==3.0.19\r\nprotobuf==3.17.3\r\npsutil==5.8.0\r\npy==1.10.0\r\npy-rouge==1.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\npydantic==1.7.4\r\nPygments==2.9.0\r\npyparsing==2.4.7\r\npyrsistent==0.17.3\r\npytest==6.2.4\r\npython-dateutil==2.8.1\r\npython-docx==0.8.11\r\npytz==2021.1\r\npywin32==301\r\npywinpty==1.1.3\r\nPyYAML==5.4.1\r\npyzmq==22.1.0\r\nqtconsole==5.1.0\r\nQtPy==1.9.0\r\nregex==2021.4.4\r\nrequests==2.25.1\r\nrsa==4.7.2\r\ns3transfer==0.4.2\r\nsacrebleu==1.5.1\r\nsacremoses==0.0.45\r\nscikit-learn==0.24.2\r\nscipy==1.7.0\r\nSend2Trash==1.7.1\r\nsentencepiece==0.1.96\r\nsentry-sdk==1.1.0\r\nsgmllib3k==1.0.0\r\nshortuuid==1.0.1\r\nsix==1.16.0\r\nsklearn==0.0\r\nsmart-open==5.1.0\r\nsmmap==4.0.0\r\nsortedcontainers==2.4.0\r\nsoupsieve==2.2.1\r\nspacy==3.0.6\r\nspacy-legacy==3.0.6\r\nsrsly==2.4.1\r\nsubprocess32==3.5.4\r\ntempora==4.1.1\r\ntensorboardX==2.3\r\ntermcolor==1.1.0\r\nterminado==0.10.1\r\ntestpath==0.5.0\r\nthinc==8.0.6\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.10.3\r\ntoml==0.10.2\r\ntorch==1.8.1+cu102\r\ntorchaudio==0.8.1\r\ntorchvision==0.9.1+cu102\r\ntornado==6.1\r\ntqdm==4.61.1\r\ntraitlets==5.0.5\r\ntransformers==4.6.1\r\ntyper==0.3.2\r\ntyping-extensions==3.10.0.0\r\nurllib3==1.25.11\r\nwandb==0.10.33\r\nwasabi==0.8.2\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nwidgetsnbextension==3.5.1\r\nwincertstore==0.2\r\nword2number==1.1\r\nyapf==0.31.0\r\nzc.lockfile==2.0\r\nzipp==3.4.1\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nTo reproduce, use the same setup as the [semantic parsing section in Part 3 of the guide](https://guide.allennlp.org/semantic-parsing-seq2seq) but make a small modification to the training config such that it uses the scaled dot product attention.\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n{\r\n  \"dataset_reader\": {\r\n    \"type\": \"seq2seq\",\r\n    \"source_tokenizer\": {\r\n      \"type\": \"whitespace\"\r\n    },\r\n    \"target_tokenizer\": {\r\n      \"type\": \"whitespace\"\r\n    },\r\n    \"source_token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"single_id\",\r\n        \"namespace\": \"source_tokens\"\r\n      }\r\n    },\r\n    \"target_token_indexers\": {\r\n      \"tokens\": {\r\n        \"namespace\": \"target_tokens\"\r\n      }\r\n    }\r\n  },\r\n  \"train_data_path\": \"data/nla_with_meaning_rep_train.tsv\",\r\n  \"validation_data_path\": \"data/nla_with_meaning_rep_dev.tsv\",\r\n  \"model\": {\r\n    \"type\": \"composed_seq2seq\",\r\n    \"source_text_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"embedding\",\r\n          \"vocab_namespace\": \"source_tokens\",\r\n          \"embedding_dim\": 100,\r\n          \"trainable\": true\r\n        }\r\n      }\r\n    },\r\n    \"encoder\": {\r\n      \"type\": \"lstm\",\r\n      \"input_size\": 100,\r\n      \"hidden_size\": 50,\r\n      \"num_layers\": 1\r\n    },\r\n    \"decoder\": {\r\n      \"decoder_net\": {\r\n         \"type\": \"lstm_cell\",\r\n         \"decoding_dim\": 50,\r\n         \"target_embedding_dim\": 50,\r\n         \"attention\": {\r\n                    \"type\": \"scaled_dot_product\",\r\n                    \"scaling_factor\": 3\r\n         },\r\n      },\r\n      \"max_decoding_steps\": 50,\r\n      \"target_namespace\": \"target_tokens\",\r\n      \"target_embedder\": {\r\n        \"vocab_namespace\": \"target_tokens\",\r\n        \"embedding_dim\": 50\r\n      },\r\n      \"scheduled_sampling_ratio\": 0.5,\r\n      \"beam_size\": 10,\r\n      \"token_based_metric\": \"nla_metric\"\r\n    }\r\n  },\r\n  \"data_loader\": {\r\n    \"batch_sampler\": {\r\n        \"type\": \"bucket\",\r\n        \"batch_size\": 10,\r\n        \"padding_noise\": 0.0\r\n    }\r\n},\r\n  \"trainer\": {\r\n    \"num_epochs\": 20,\r\n    \"patience\": 10,\r\n    \"validation_metric\": \"+sequence_accuracy\",\r\n    \"cuda_device\": -1,\r\n    \"optimizer\": {\r\n      \"type\": \"adam\",\r\n      \"lr\": 0.01\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5345/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5345/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5342", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5342/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5342/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5342/events", "html_url": "https://github.com/allenai/allennlp/issues/5342", "id": 959801979, "node_id": "MDU6SXNzdWU5NTk4MDE5Nzk=", "number": 5342, "title": "T5 mask bug when calculate loss.", "user": {"login": "wlhgtc", "id": 16603773, "node_id": "MDQ6VXNlcjE2NjAzNzcz", "avatar_url": "https://avatars.githubusercontent.com/u/16603773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wlhgtc", "html_url": "https://github.com/wlhgtc", "followers_url": "https://api.github.com/users/wlhgtc/followers", "following_url": "https://api.github.com/users/wlhgtc/following{/other_user}", "gists_url": "https://api.github.com/users/wlhgtc/gists{/gist_id}", "starred_url": "https://api.github.com/users/wlhgtc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wlhgtc/subscriptions", "organizations_url": "https://api.github.com/users/wlhgtc/orgs", "repos_url": "https://api.github.com/users/wlhgtc/repos", "events_url": "https://api.github.com/users/wlhgtc/events{/privacy}", "received_events_url": "https://api.github.com/users/wlhgtc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2021-08-04T02:32:45Z", "updated_at": "2021-10-25T16:09:39Z", "closed_at": "2021-10-25T16:09:39Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The CrossEntropy loss used in T5 model would ignore pos where `idx = -100`.\r\n\r\nAccording to the [code](https://github.com/huggingface/transformers/blob/master/src/transformers/data/data_collator.py#L277-L284) in transformers, they set all padding tokens to -100. \r\nIn our code we miss this operation, so we calculate these loss which is unnecessary and would lead a little bit drop(at least in my own task).\r\n\r\nSuch code should be added:\r\n```python\r\nlabels.masked_fill_(labels == 0, -100)\r\n```\r\nAdd it in  [allennlp](https://github.com/allenai/allennlp/blob/main/allennlp/modules/transformer/t5.py#L930) or [allennlp-models](https://github.com/allenai/allennlp-models/blob/main/allennlp_models/generation/models/t5.py#L101) ?\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5342/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5342/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5318", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5318/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5318/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5318/events", "html_url": "https://github.com/allenai/allennlp/issues/5318", "id": 947014535, "node_id": "MDU6SXNzdWU5NDcwMTQ1MzU=", "number": 5318, "title": "ConfigurationError exception is not deserializable", "user": {"login": "ojomio", "id": 6757091, "node_id": "MDQ6VXNlcjY3NTcwOTE=", "avatar_url": "https://avatars.githubusercontent.com/u/6757091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ojomio", "html_url": "https://github.com/ojomio", "followers_url": "https://api.github.com/users/ojomio/followers", "following_url": "https://api.github.com/users/ojomio/following{/other_user}", "gists_url": "https://api.github.com/users/ojomio/gists{/gist_id}", "starred_url": "https://api.github.com/users/ojomio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ojomio/subscriptions", "organizations_url": "https://api.github.com/users/ojomio/orgs", "repos_url": "https://api.github.com/users/ojomio/repos", "events_url": "https://api.github.com/users/ojomio/events{/privacy}", "received_events_url": "https://api.github.com/users/ojomio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2021-07-18T11:39:39Z", "updated_at": "2021-07-23T18:06:20Z", "closed_at": "2021-07-23T18:06:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nConfigurationError exception is not unserializable, which leads to obscure Celery tracebacks\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nMaybeEncodingError: Error sending result: ''(1, <ExceptionInfo: ConfigurationError()>, None)''. Reason: ''PicklingError(\"Can\\'t pickle <class \\'allennlp.common.checks.ConfigurationError\\'>: it\\'s not the same object as allenai_common.checks.ConfigurationError\")''.\r\n  File \"billiard/pool.py\", line 366, in workloop\r\n    put((READY, (job, i, result, inqW_fd)))\r\n  File \"billiard/queues.py\", line 366, in put\r\n    self.send_payload(ForkingPickler.dumps(obj))\r\n  File \"billiard/reduction.py\", line 56, in dumps\r\n    cls(buf, protocol).dump(obj)\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: \"Ubuntu 20.04.2 LTS\"\r\n\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.10\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py @ file:///home/ypaykov/.cache/pypoetry/artifacts/f9/fd/bf/a7ed1ad72a860cdbb48506ddeac935fafb56792ba98a9f5f1050244526/absl_py-0.13.0-py3-none-any.whl\r\naiobotocore @ file:///home/ypaykov/.cache/pypoetry/artifacts/bf/6b/ba/05d1397cf9eb59634fa802ce3239e8ab023ece7990bb2d461256dec2fa/aiobotocore-1.3.0.tar.gz\r\naiohttp @ file:///home/ypaykov/.cache/pypoetry/artifacts/b7/45/ac/27b8d241df8a69268b48e211310c2c86764adacde4f338f154c71df87d/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl\r\naioitertools @ file:///home/ypaykov/.cache/pypoetry/artifacts/bc/d5/17/68a9db6a3ec5d8ee0dce68a3afc8b23c64ae6311bca19076529d5cb7a1/aioitertools-0.7.1-py3-none-any.whl\r\nalembic @ file:///home/ypaykov/.cache/pypoetry/artifacts/46/41/3b/d5dd8b55ce8a20360bccf49605839fe5b45058e003853afb102f143d3c/alembic-1.6.5-py2.py3-none-any.whl\r\nallenai-common @ file:///home/ypaykov/.cache/pypoetry/artifacts/fe/69/5f/0c29a0b5377f6f127de25122e25476b244b451bf796336ac3295af3290/allenai_common-1.1.2-py3-none-any.whl\r\nallennlp @ file:///home/ypaykov/.cache/pypoetry/artifacts/42/4e/f5/2e480468630c78b89315a4b0dd9525fbb246490dff76a34ac72df9b9ee/allennlp-1.5.0-py3-none-any.whl\r\namqp @ file:///home/ypaykov/.cache/pypoetry/artifacts/5c/98/c9/c43d6521a9a8c80e8c562a857520df9f3cf38eecedc5a64c34986ad280/amqp-5.0.6-py3-none-any.whl\r\nanybadge @ file:///home/ypaykov/.cache/pypoetry/artifacts/c4/06/1c/15092d53636218eec7b1db4b970c5ddd1d06522a34b47b859e202e004a/anybadge-1.7.0-py2.py3-none-any.whl\r\nappdirs @ file:///home/ypaykov/.cache/pypoetry/artifacts/e0/bb/d7/ce7b80180d65db4c913e7498d9673e279f5b64306a78a85fbf8542514c/appdirs-1.4.4-py2.py3-none-any.whl\r\nastroid @ file:///home/ypaykov/.cache/pypoetry/artifacts/a4/72/92/0ac7e669883c15b870355d6a18a9b8aa73591ca9e5b268805cb888096f/astroid-2.6.2-py3-none-any.whl\r\nastunparse @ file:///home/ypaykov/.cache/pypoetry/artifacts/4d/37/04/0488d1b7f5eabad9747e58af0908f63ff60e5a9ead5a2f9f58569c287e/astunparse-1.6.3-py2.py3-none-any.whl\r\nasync-timeout @ file:///home/ypaykov/.cache/pypoetry/artifacts/b8/f8/e8/6ef0687a026ad6b419ded4eab2d5e536af9f2d3ba41009fcccee431102/async_timeout-3.0.1-py3-none-any.whl\r\natpublic @ file:///home/ypaykov/.cache/pypoetry/artifacts/84/fe/34/42d475acad15cb37d14dbac367bae59f0b53a371f20ad761d9eab4d1b2/atpublic-2.3.tar.gz\r\nattrs @ file:///home/ypaykov/.cache/pypoetry/artifacts/f1/fe/0c/dbbd6d435effbb75ce7bceb36d7a1a80b1989854c0d0c83ebd46b1c886/attrs-21.2.0-py2.py3-none-any.whl\r\nbackcall==0.2.0\r\nbert-for-tf2 @ file:///home/ypaykov/.cache/pypoetry/artifacts/2a/bc/8b/3f864502da2938343c1c19ae63d667220dd099ecd9f0f5ddcf7228f696/bert-for-tf2-0.14.9.tar.gz\r\nbilliard @ file:///home/ypaykov/.cache/pypoetry/artifacts/aa/12/d7/07c1a6ab037134665f3d5ffd2e0c820e5d48d0363c9f81827795445ad9/billiard-3.6.4.0-py3-none-any.whl\r\nblack @ file:///home/ypaykov/.cache/pypoetry/artifacts/4e/56/38/010557c33344e062aa9bb9018e457353dcf933640abfac2ff882d995fa/black-21.6b0-py3-none-any.whl\r\nblis @ file:///home/ypaykov/.cache/pypoetry/artifacts/8f/75/09/53dd821976ed9723b9f9a1cc788f233ffc8102055d1138585c36eec471/blis-0.7.4-cp37-cp37m-manylinux2014_x86_64.whl\r\nboto3 @ file:///home/ypaykov/.cache/pypoetry/artifacts/4e/79/48/c51d8cc18af0775b1b2f8e20989c7ea171f61ba57f3819fd6c20ca3cc6/boto3-1.17.105-py2.py3-none-any.whl\r\nboto3-type-annotations-with-docs @ file:///home/ypaykov/.cache/pypoetry/artifacts/9b/19/3e/31e8b335f63558f4c057ec02cf39807cb3141a0f3d304ac3bbec088b5b/boto3_type_annotations_with_docs-0.3.1-py3-none-any.whl\r\nbotocore @ file:///home/ypaykov/.cache/pypoetry/artifacts/b8/2e/c3/a49982ffd5b6881f5792299f711b99ed159e88c61cb920eb020aac4002/botocore-1.20.105-py2.py3-none-any.whl\r\ncached-property @ file:///home/ypaykov/.cache/pypoetry/artifacts/bc/dd/dd/24a32952b48aa05a20e3181bc7566e2cdfbfe939caaf147a08f61c8511/cached_property-1.5.2-py2.py3-none-any.whl\r\ncachetools @ file:///home/ypaykov/.cache/pypoetry/artifacts/56/be/ee/37f0408a2f154720a2d27cc2597917dd221bed300ffd89f05c07db91c3/cachetools-4.2.2-py3-none-any.whl\r\ncatalogue @ file:///home/ypaykov/.cache/pypoetry/artifacts/e5/fe/c7/e36fd75bfe7a0caa3a75533e2fa26c1435c3a51063df714b4424d6b213/catalogue-1.0.0-py2.py3-none-any.whl\r\ncelery @ file:///home/ypaykov/.cache/pypoetry/artifacts/7d/ff/72/3ab5e1b7086cf51b71e27decc77d3f27edf049e3905193709e905a1812/celery-5.1.2-py3-none-any.whl\r\ncertifi @ file:///home/ypaykov/.cache/pypoetry/artifacts/a9/06/ae/b63d1f30e96f047d5c2d3c260fc572406c1372a5018728c35fa34c35af/certifi-2021.5.30-py2.py3-none-any.whl\r\ncffi @ file:///home/ypaykov/.cache/pypoetry/artifacts/92/da/90/9b8ed036b2ed4b2dd9e4fefe8faace1d97140766716b84dd4359916cd6/cffi-1.14.5-cp37-cp37m-manylinux1_x86_64.whl\r\nchardet @ file:///home/ypaykov/.cache/pypoetry/artifacts/61/c4/55/412a9bcb2bf3bb856163fb1c835679bc40ba1635934306dc9caba0392f/chardet-4.0.0-py2.py3-none-any.whl\r\nclick @ file:///home/ypaykov/.cache/pypoetry/artifacts/bd/aa/aa/8b6e6c3fb32dc7bb451bb1a776910ea5b320c95af2e3876342c1d1c551/click-7.1.2-py2.py3-none-any.whl\r\nclick-didyoumean @ file:///home/ypaykov/.cache/pypoetry/artifacts/76/66/2b/f91e57545a12ae47779576b464f520521bc6a5f5f823ee2e776c867463/click-didyoumean-0.0.3.tar.gz\r\nclick-plugins @ file:///home/ypaykov/.cache/pypoetry/artifacts/a2/39/f1/c222a5763c1ac4a476fd4a1a735d0aa6a4e80beb8196218858a5016c47/click_plugins-1.1.1-py2.py3-none-any.whl\r\nclick-repl @ file:///home/ypaykov/.cache/pypoetry/artifacts/b2/84/8a/9d2a6b111335b8a93df49c7b0c41ff9afe23cbfe6f88e68a56557f7027/click_repl-0.2.0-py3-none-any.whl\r\ncliff @ file:///home/ypaykov/.cache/pypoetry/artifacts/4e/07/fa/8eea8d9b6571ac032dcdbc47d9c607badd3c4056ad20f6957ef3217d76/cliff-3.8.0-py3-none-any.whl\r\ncmaes @ file:///home/ypaykov/.cache/pypoetry/artifacts/0c/83/0d/438c19ffbd0ed9fd0adf1e1ef603e1a12ca5b415fa8f8e36e42a1e6773/cmaes-0.8.2-py3-none-any.whl\r\ncmd2 @ file:///home/ypaykov/.cache/pypoetry/artifacts/6a/3b/19/a1d687f797e0eda4c556a07c9ec5f0ab57ae27deed4068d41b40608710/cmd2-2.1.2-py3-none-any.whl\r\ncolorama @ file:///home/ypaykov/.cache/pypoetry/artifacts/6c/b8/35/d0bd6a231786315fbd792bf6c580c683bca6f8b380a8587a24e8baaa14/colorama-0.4.4-py2.py3-none-any.whl\r\ncolorlog @ file:///home/ypaykov/.cache/pypoetry/artifacts/9d/76/8b/a14ee1a782d327329a5dd0775ebc0fa1d6efe2b4782528e53e452e382b/colorlog-5.0.1-py2.py3-none-any.whl\r\ncommonmark @ file:///home/ypaykov/.cache/pypoetry/artifacts/56/74/5f/066a8c0e8891ee09a0c280f10a892ba8290f096493df32c7a246decf21/commonmark-0.9.1-py2.py3-none-any.whl\r\nconfigobj @ file:///home/ypaykov/.cache/pypoetry/artifacts/80/0e/7a/79e99a3c49b79c3fc96bf6868f012260824924122859e4a6c5f0d61ad6/configobj-5.0.6.tar.gz\r\nconfigparser @ file:///home/ypaykov/.cache/pypoetry/artifacts/28/63/83/4270532418ad0ae29f5377dbb9ce6ee6961b3d57d0c6b6d82591e5d6e6/configparser-5.0.2-py3-none-any.whl\r\ncoverage @ file:///home/ypaykov/.cache/pypoetry/artifacts/f9/24/a5/49f4dbdf017542bb391a9bf62e5aa2a246afd75a1c3d3a17781b51df8e/coverage-5.5-cp37-cp37m-manylinux2010_x86_64.whl\r\ncycler @ file:///home/ypaykov/.cache/pypoetry/artifacts/4a/18/48/773efed6d4ec2096a532523a4b8c7543bfc7cad5f10f8869cddef7e0e4/cycler-0.10.0-py2.py3-none-any.whl\r\ncymem @ file:///home/ypaykov/.cache/pypoetry/artifacts/21/e0/f9/1002198b33523028edf279bb606aec120d5d73e782cdd10b443acb2dff/cymem-2.0.5-cp37-cp37m-manylinux2014_x86_64.whl\r\nCython @ file:///home/ypaykov/.cache/pypoetry/artifacts/ee/60/b1/94561c16aefad63f755857bab5127c6da286f1b01decc12821a0c7184e/Cython-0.29.23-cp37-cp37m-manylinux1_x86_64.whl\r\ndatautils @ file:///home/ypaykov/.cache/pypoetry/artifacts/5f/91/15/92a0c0c0238226e72803d30ea02d0c1ebf3dbb515f7591bfa317e0a7a7/datautils-2019.14.0-py3-none-any.whl\r\nDAWG @ file:///home/ypaykov/.cache/pypoetry/artifacts/a9/50/09/5933406e82403fbaeb525d8658350e6f7219dfa523ee4b2804b303730d/DAWG-0.8.0.tar.gz\r\nDAWG-Python @ file:///home/ypaykov/.cache/pypoetry/artifacts/cf/e5/66/c76b159fd216aa54d2ac6614fcc1f19583bfea9371dca8fc2800e2bef0/DAWG_Python-0.7.2-py2.py3-none-any.whl\r\ndecorator @ file:///home/ypaykov/.cache/pypoetry/artifacts/15/41/0b/75497277885f23a6664b31d304d31d64c2ed1f473c64f76a17d2d078c3/decorator-4.4.2-py2.py3-none-any.whl\r\nDeprecated @ file:///home/ypaykov/.cache/pypoetry/artifacts/99/18/01/f007341dced85c59bc09e835ce552edab7a6b2f2952b5888ec4043ae31/Deprecated-1.2.12-py2.py3-none-any.whl\r\ndictdiffer @ file:///home/ypaykov/.cache/pypoetry/artifacts/b0/1b/be/03bffc89b165f9adb4463ae5e186d22dcffe5e343ed51d2f937f770405/dictdiffer-0.8.1-py2.py3-none-any.whl\r\ndill @ file:///home/ypaykov/.cache/pypoetry/artifacts/ba/a1/15/cc1afa33ac3104c433559021ea33e95b19a7dcfc914943af84a38e3e7b/dill-0.2.9.tar.gz\r\ndiskcache @ file:///home/ypaykov/.cache/pypoetry/artifacts/aa/ad/19/f880f9af28f21c897091e4b0cf3f39a5579cee53890806c0d61cda1a85/diskcache-5.2.1-py3-none-any.whl\r\ndistro @ file:///home/ypaykov/.cache/pypoetry/artifacts/47/dc/9b/b0058c8e186e807d72d33e2f2a830c09cac28c0e7a226666bdc11f5eae/distro-1.5.0-py2.py3-none-any.whl\r\ndocker-pycreds @ file:///home/ypaykov/.cache/pypoetry/artifacts/f7/1b/9d/96b91507fe4a3dad063b2469d228415afbf2b380cd5aa584b0a7f9ff10/docker_pycreds-0.4.0-py2.py3-none-any.whl\r\ndocopt @ file:///home/ypaykov/.cache/pypoetry/artifacts/7b/9b/05/f50fd5dd792dcb97c8c5e2d633ae05d7785ac53183ccc10e049fe234f3/docopt-0.6.2.tar.gz\r\ndpath @ file:///home/ypaykov/.cache/pypoetry/artifacts/36/78/fa/d90669287e3cf9b956b2aedba3dd3ce0ea86cd3a426c21c235d5f5524c/dpath-2.0.1.tar.gz\r\ndulwich @ file:///home/ypaykov/.cache/pypoetry/artifacts/db/84/c8/2ed6bb57999764acb05d38635cae631806e58e7fd0e7fb220aa1ae17db/dulwich-0.20.23-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\ndvc @ file:///home/ypaykov/.cache/pypoetry/artifacts/46/c9/59/a3e496e18e59824e2f242f877ab7248cc319503775908ea763d9a3da79/dvc-2.3.0-py2.py3-none-any.whl\r\neditdistance @ file:///home/ypaykov/.cache/pypoetry/artifacts/0a/ce/ba/d8ad406351274684b7ce2d000a2aa2cedff18c1187fd71075cebf84485/editdistance-0.5.3-cp37-cp37m-manylinux1_x86_64.whl\r\neli5 @ file:///home/ypaykov/.cache/pypoetry/artifacts/54/3f/f2/08e1ebebfaa19e7d43300bb5e79bfd41a00f2d84ed6808c4b5e749cade/eli5-0.11.0-py2.py3-none-any.whl\r\neradicate @ file:///home/ypaykov/.cache/pypoetry/artifacts/20/8f/e6/7c8f6ae47c64a5dbfbac1493a807726f39c9233abadbd47213e5a39bac/eradicate-2.0.0.tar.gz\r\net-xmlfile @ file:///home/ypaykov/.cache/pypoetry/artifacts/ae/81/34/f705711ca666881f684c836b30ff853d2680c47e0bea33db0da4c7910d/et_xmlfile-1.1.0-py3-none-any.whl\r\nfakeredis @ file:///home/ypaykov/.cache/pypoetry/artifacts/8d/6f/04/34a66252930fa9d7846b088d5fce6e178044a77c948f693b42c97a72b1/fakeredis-1.5.2-py3-none-any.whl\r\nfastapi @ file:///home/ypaykov/.cache/pypoetry/artifacts/61/e2/57/9cf8c63524b0237da5572e2f56e171db815fb895e13a365bb691a6bad3/fastapi-0.61.2-py3-none-any.whl\r\nfilelock @ file:///home/ypaykov/.cache/pypoetry/artifacts/5c/9c/f3/4dab5814885a4100c4765346bf6a8b6953ca7197a67e94a95b83180261/filelock-3.0.12-py3-none-any.whl\r\nflake8 @ file:///home/ypaykov/.cache/pypoetry/artifacts/58/17/80/8e1aaee055c3b33888b018cccee2ada9120dcd201055fddbdb5e3ff965/flake8-3.9.2-py2.py3-none-any.whl\r\nflake8-awesome @ file:///home/ypaykov/.cache/pypoetry/artifacts/5c/15/f5/bd256434da6f1b7fd4b9d9972929300dcdf03ac81fdda88072c829f3d8/flake8_awesome-1.2.1-py3-none-any.whl\r\nflake8-breakpoint @ file:///home/ypaykov/.cache/pypoetry/artifacts/84/9a/14/758f48270b8c0bc5d9c292d35cd2e0d9135401ca5379b35907bfbe6b4f/flake8_breakpoint-1.1.0-py3-none-any.whl\r\nflake8-builtins @ file:///home/ypaykov/.cache/pypoetry/artifacts/7f/59/d1/dd70dff80bae956a8777fa22e871ad315048f70230a4a6de9486e2fabd/flake8_builtins-1.5.3-py2.py3-none-any.whl\r\nflake8-comprehensions @ file:///home/ypaykov/.cache/pypoetry/artifacts/52/41/11/927c870de435802aaa2e5eed65cbb188be3dcfb2479c19af4ab4b8c104/flake8_comprehensions-3.5.0-py3-none-any.whl\r\nflake8-debugger @ file:///home/ypaykov/.cache/pypoetry/artifacts/df/c6/e4/bd567eeaadf568e0ac0dcab2745699584488e093c66c39aa9179f89b38/flake8_debugger-4.0.0-py3-none-any.whl\r\nflake8-eradicate @ file:///home/ypaykov/.cache/pypoetry/artifacts/cd/26/81/56188f83cba70dfc9acf3386f697bc92120ee274026c9224d2ade6c29a/flake8_eradicate-1.1.0-py3-none-any.whl\r\nflake8-gl-codeclimate @ file:///home/ypaykov/.cache/pypoetry/artifacts/ed/5e/74/2c03eb7d08f343cf99d7b08bfe31227463940b6489f764167834d05234/flake8-gl-codeclimate-0.1.4.tar.gz\r\nflake8-if-expr @ file:///home/ypaykov/.cache/pypoetry/artifacts/e5/8d/9f/c540d8ad2e7b8fbe9e3c4766dc561312fae0ea66d3531123abf78e6a2c/flake8_if_expr-1.0.4-py3-none-any.whl\r\nflake8-isort @ file:///home/ypaykov/.cache/pypoetry/artifacts/82/7b/81/3bfef03d940fdf49020cde237b57498da8833a20965a6fad283a5158e0/flake8_isort-4.0.0-py2.py3-none-any.whl\r\nflake8-logging-format @ file:///home/ypaykov/.cache/pypoetry/artifacts/bd/67/35/1c2d8e878c02161a006e3a76b44dec887c5bdf53c1ec64bb5a6bb0bf58/flake8-logging-format-0.6.0.tar.gz\r\nflake8-plugin-utils @ file:///home/ypaykov/.cache/pypoetry/artifacts/d5/15/5a/be4206665bcb9f163047d504d146b0818002e97cc3b4ee8f1cff296e4d/flake8_plugin_utils-1.3.2-py3-none-any.whl\r\nflake8-polyfill @ file:///home/ypaykov/.cache/pypoetry/artifacts/c7/8c/e3/dbb3b03008d18c7a68e45afc39651eae6445f99640ba0733391804cd0f/flake8_polyfill-1.0.2-py2.py3-none-any.whl\r\nflake8-print @ file:///home/ypaykov/.cache/pypoetry/artifacts/9d/e0/be/2a63ddaf3cf56592ecdce88b8dc8429135f825542895d3bf42d0b9d816/flake8_print-4.0.0-py3-none-any.whl\r\nflake8-pytest @ file:///home/ypaykov/.cache/pypoetry/artifacts/59/7b/ac/2e5a2ddaba9e04de2eb88f14c23b98d6e1937c98e56c19f647511efe0c/flake8_pytest-1.3-py2.py3-none-any.whl\r\nflake8-pytest-style @ file:///home/ypaykov/.cache/pypoetry/artifacts/26/ed/be/b43b851c543531097dff87a6567d8d41b903552f947c31a1360b6043cb/flake8_pytest_style-1.5.0-py3-none-any.whl\r\nflake8-return @ file:///home/ypaykov/.cache/pypoetry/artifacts/75/da/e5/31ca971f0b0ec3d308c48d87022e3a2bb7b8879001b272205acfab6e7b/flake8_return-1.1.3-py3-none-any.whl\r\nflatbuffers @ file:///home/ypaykov/.cache/pypoetry/artifacts/25/51/ad/a80757396dcab1368aca8c70858726109f71f9bc3c2447486d77e7c2de/flatbuffers-1.12-py2.py3-none-any.whl\r\nflatten-dict @ file:///home/ypaykov/.cache/pypoetry/artifacts/39/ed/6b/aed9c6d28db1b9f410ef7ceaa6b2751619f3f7e08cfc8aa2c019e863bf/flatten_dict-0.4.0-py2.py3-none-any.whl\r\nflufl.lock @ file:///home/ypaykov/.cache/pypoetry/artifacts/a3/44/51/7849651af4a96b16d18e50d2a91d2f4e68dc8bdd56c55e5914b465bbd2/flufl.lock-3.2.tar.gz\r\nfreezegun @ file:///home/ypaykov/.cache/pypoetry/artifacts/ff/9c/2c/e31bc23bd07e76cfbc03d9c214f2d2d57f52944c0afc0e21f4258370f0/freezegun-1.1.0-py2.py3-none-any.whl\r\nfsspec @ file:///home/ypaykov/.cache/pypoetry/artifacts/c3/c9/19/10f21635b5b869283327f8e628c694b8ea0f68833e91b0eec6d610784e/fsspec-2021.5.0-py3-none-any.whl\r\nftfy @ file:///home/ypaykov/.cache/pypoetry/artifacts/db/60/a1/7fde707686a5a9d48bd0b98027e5a2fbabf696eb6bba96b2782424eaf8/ftfy-6.0.3.tar.gz\r\nfuncy @ file:///home/ypaykov/.cache/pypoetry/artifacts/f0/87/f8/3fb64b9c3cf9e38f2ebf4d1adaed33e3585d6c66e6eca63cefa9c408d9/funcy-1.16-py2.py3-none-any.whl\r\nfuture @ file:///home/ypaykov/.cache/pypoetry/artifacts/6a/31/20/582c43acd5302c78f6846c9da5627bc50bed2190d25c6355c6c28354c5/future-0.18.2.tar.gz\r\ngast @ file:///home/ypaykov/.cache/pypoetry/artifacts/c7/9e/2f/92fd087319a93926a07f2984cad2eaad3f2b9d41c7a7ac04879c16e68d/gast-0.3.3-py2.py3-none-any.whl\r\ngitdb @ file:///home/ypaykov/.cache/pypoetry/artifacts/dd/85/83/d333f8e91e00f55ba92f8e55a921e540432ecbb20724ab1503662b0ebc/gitdb-4.0.7-py3-none-any.whl\r\nGitPython @ file:///home/ypaykov/.cache/pypoetry/artifacts/6d/da/a0/9ed28f70fb5658d220369c3255e402630c9690f1286aff73ba794cbb82/GitPython-3.1.18-py3-none-any.whl\r\ngoogle-auth @ file:///home/ypaykov/.cache/pypoetry/artifacts/ff/98/45/e34be1f8da1504a128376a873b29703c0869e36816c8960d0d6c345741/google_auth-1.32.1-py2.py3-none-any.whl\r\ngoogle-auth-oauthlib @ file:///home/ypaykov/.cache/pypoetry/artifacts/59/6d/0f/24308e80458b87ab70fad0d0da509995d120a515f40e44d61ed67985ef/google_auth_oauthlib-0.4.4-py2.py3-none-any.whl\r\ngoogle-pasta @ file:///home/ypaykov/.cache/pypoetry/artifacts/56/77/ee/eb44004f4bd40f3d594865ec903d952239be5f46bd490d99a5f300aabc/google_pasta-0.2.0-py3-none-any.whl\r\ngrandalf @ file:///home/ypaykov/.cache/pypoetry/artifacts/09/6e/c9/634cd454aee019a0fa1ddd3e6097bdf7c55d6693d274cfe6b0e1111cc0/grandalf-0.6-py3-none-any.whl\r\ngraphviz @ file:///home/ypaykov/.cache/pypoetry/artifacts/d9/03/f8/8d6f539515a032a2757d3ca6b6a15eb1148ff1cc42dfbb8134e8efdfb9/graphviz-0.16-py2.py3-none-any.whl\r\ngreenlet @ file:///home/ypaykov/.cache/pypoetry/artifacts/65/0a/c2/35d3097df694b6b7e9b65f712cdd5843fd9cab8d42f88d44b5397fbac2/greenlet-1.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\ngrpcio @ file:///home/ypaykov/.cache/pypoetry/artifacts/38/71/59/dfab530252b4b9b0946f8974288a9b5aec0ccf6dc06f8be291a90c47c9/grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl\r\ngunicorn @ file:///home/ypaykov/.cache/pypoetry/artifacts/eb/e5/71/80554fae9df242efcd9a687024542d582c508a2b35c54e9fe4f231db98/gunicorn-19.9.0-py2.py3-none-any.whl\r\nh11 @ file:///home/ypaykov/.cache/pypoetry/artifacts/41/dd/2f/0decbf81b1e9639f5925dcd736545b60701c1580cd2e8c47ad21ba8613/h11-0.8.1-py2.py3-none-any.whl\r\nh5py @ file:///home/ypaykov/.cache/pypoetry/artifacts/ff/b8/f2/68d415ac80fe3e2a7dfebc412182ba291973255e2971de854566a1350d/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl\r\nhdbscan @ file:///home/ypaykov/.cache/pypoetry/virtualenvs/clusters-p3buAsje-py3.7/src/hdbscan\r\nhttptools @ file:///home/ypaykov/.cache/pypoetry/artifacts/a1/58/9b/31acaa91e1f278921b767bbf841643d2f5870f3c47ba5697da98f70769/httptools-0.0.13.tar.gz\r\nhumanize @ file:///home/ypaykov/.cache/pypoetry/artifacts/2c/65/d7/ef62f63dbaabee55b81bb5a721a4afdde97439b0e1d8301763be762f97/humanize-3.10.0-py3-none-any.whl\r\nidna @ file:///home/ypaykov/.cache/pypoetry/artifacts/16/9f/af/2de9e531a53d586b99001a6050f8d4abc416c54e34a92ad5d7631430c4/idna-2.10-py2.py3-none-any.whl\r\nimportlib-metadata @ file:///home/ypaykov/.cache/pypoetry/artifacts/84/73/35/bb3461857ad366d6dab322d0523e9dd8a9ea16d506ce228695c70408d0/importlib_metadata-4.6.1-py3-none-any.whl\r\niniconfig @ file:///home/ypaykov/.cache/pypoetry/artifacts/9e/d1/e5/14b6b2ab8e9ff53ce57f2c1918f96d0e415a25f66adf35a5c9f014325a/iniconfig-1.1.1-py2.py3-none-any.whl\r\nipython==7.24.1\r\nipython-genutils==0.2.0\r\nisort @ file:///home/ypaykov/.cache/pypoetry/artifacts/b2/95/25/8988c918d49a5a93b19e1f990f75803b16c4da0ce4a9b682b088dcff26/isort-5.9.1-py3-none-any.whl\r\njedi==0.18.0\r\nJinja2 @ file:///home/ypaykov/.cache/pypoetry/artifacts/62/b7/47/09284a75211ed6435373bdc8c4411dc8eb56c808519c93186a2b712c47/Jinja2-3.0.1-py3-none-any.whl\r\njmespath @ file:///home/ypaykov/.cache/pypoetry/artifacts/88/a5/6c/06c399ebe1b1a2e94e3c437b9062ee5144c31739a3ee6efb7ae55d974c/jmespath-0.10.0-py2.py3-none-any.whl\r\njoblib @ file:///home/ypaykov/.cache/pypoetry/artifacts/b2/08/7a/b84d88f5005eb4a240928d7868a358fc28f58a97cbe176d15306f79bbc/joblib-1.0.1-py3-none-any.whl\r\njsonlines @ file:///home/ypaykov/.cache/pypoetry/artifacts/48/95/f9/69f3b41beeedc705cc77d5b7faba8c33808670168bd0568ce7718fac0d/jsonlines-1.2.0-py2.py3-none-any.whl\r\njsonnet @ file:///home/ypaykov/.cache/pypoetry/artifacts/9f/07/4e/0035147ad131b147efb900c9933f858e5d11cb215dd59d44e63827a8f7/jsonnet-0.17.0.tar.gz\r\njsonpath-ng @ file:///home/ypaykov/.cache/pypoetry/artifacts/1c/5d/a3/ae1a99509c71959b57351cc3e8cf1314ea4ff3e006b24e674827782987/jsonpath_ng-1.5.2-py3-none-any.whl\r\njsonpickle @ file:///home/ypaykov/.cache/pypoetry/artifacts/78/c0/aa/c51c412f877e58e0b5b5243692d162964110dd407a43327a5600fa5fe5/jsonpickle-2.0.0-py2.py3-none-any.whl\r\nKeras @ file:///home/ypaykov/.cache/pypoetry/artifacts/75/2b/45/90c5b49103785ae5e8d921e17f2857a562eb07b6721aabd957fdef2b52/Keras-2.3.1-py2.py3-none-any.whl\r\nKeras-Applications @ file:///home/ypaykov/.cache/pypoetry/artifacts/c7/54/87/6663c7f89ef90615ca20f72ca0b5dca3d3e1a63035b3e0f4daeab8ce8a/Keras_Applications-1.0.8-py3-none-any.whl\r\nkeras-nightly @ file:///home/ypaykov/.cache/pypoetry/artifacts/de/0a/55/e5e2be81135024a549b0c5e914b98b277d84b615c0a4669e53f619c793/keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl\r\nKeras-Preprocessing @ file:///home/ypaykov/.cache/pypoetry/artifacts/c0/65/af/38baf9b0f613b24bf54698cd8c8c052ad617091ed53cb5d7066a971676/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\r\nkiwisolver @ file:///home/ypaykov/.cache/pypoetry/artifacts/ba/13/29/02511f4939084b6e0fe1dd0d3871276f4ec475e4155c4cefc5e1a5824f/kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl\r\nkombu @ file:///home/ypaykov/.cache/pypoetry/artifacts/ce/93/46/ca8ce6e939c343ba71663828f6fd8aa7c80408e189e65f6dd2e5ffd1a0/kombu-5.1.0-py3-none-any.whl\r\nlaserembeddings @ file:///home/ypaykov/.cache/pypoetry/artifacts/b2/b0/a7/110dc0ef602541b6e14d65f918786bdde4900ea2d0855a47349a1dac31/laserembeddings-1.1.1-py3-none-any.whl\r\nlazy @ file:///home/ypaykov/.cache/pypoetry/artifacts/d8/1f/2a/300738f98c3b129310e133e269d547790c3151f133062587031fed34d4/lazy-1.4-py2.py3-none-any.whl\r\nlazy-object-proxy @ file:///home/ypaykov/.cache/pypoetry/artifacts/23/cd/9c/f7326b83ad8ebd09cba7de349de27525311667bdd1b70a89db2f255734/lazy_object_proxy-1.6.0-cp37-cp37m-manylinux1_x86_64.whl\r\nlru-dict @ file:///home/ypaykov/.cache/pypoetry/artifacts/71/2f/eb/282291fe1771a09b0f2de6953b01110193e0cec337b95ec48bf998d53f/lru-dict-1.1.7.tar.gz\r\nlupa @ file:///home/ypaykov/.cache/pypoetry/artifacts/c2/2c/7f/c9ec1135afb0236645d8693376ab17495ec0be1c3e25b7592a0cf18d95/lupa-1.9-cp37-cp37m-manylinux1_x86_64.whl\r\nmailchecker @ file:///home/ypaykov/.cache/pypoetry/artifacts/c9/ca/d4/087ba856e757c246173e640a498cc9f40f147ed34bedca040fc566d84f/mailchecker-4.0.8.tar.gz\r\nMako @ file:///home/ypaykov/.cache/pypoetry/artifacts/c5/12/6c/620ed3f0afc8badaab5913be96962271177aa90d4d6786f3efd97c2628/Mako-1.1.4-py2.py3-none-any.whl\r\nMarkdown @ file:///home/ypaykov/.cache/pypoetry/artifacts/2a/b2/b7/45d4877cf6d6f264520c8d6174229e0950411ab78e9b18aa768b83bcb3/Markdown-3.3.4-py3-none-any.whl\r\nMarkupSafe @ file:///home/ypaykov/.cache/pypoetry/artifacts/24/5d/fd/77120f1716ebf4b1251fc9438535198191dab24dee5a39aa72bc8ea407/MarkupSafe-2.0.1-cp37-cp37m-manylinux2010_x86_64.whl\r\nmaru @ file:///home/ypaykov/.cache/pypoetry/artifacts/9c/75/9a/0b6d62a4a5f76f1f63be82e46c6daae50a32da1ab495e03b9ca02d20c9/maru-0.2.0-py3-none-any.whl\r\nmatplotlib @ file:///home/ypaykov/.cache/pypoetry/artifacts/6f/02/74/8a2efa7db442221fa65b4956f6355fc89a296e25f95ad1bc785c24b650/matplotlib-3.4.2-cp37-cp37m-manylinux1_x86_64.whl\r\nmatplotlib-inline==0.1.2\r\nmccabe @ file:///home/ypaykov/.cache/pypoetry/artifacts/1e/a5/64/a1f4410464fdc020cb4d8808b82d807b9f98d8abc85e56acff25ee797e/mccabe-0.6.1-py2.py3-none-any.whl\r\nmlkit @ file:///home/ypaykov/.cache/pypoetry/artifacts/96/73/57/7b01d5b16b918b5567313831f259205156f5097eb99a8372d5081734dc/mlkit-2.1.4-py3-none-any.whl\r\nmultidict @ file:///home/ypaykov/.cache/pypoetry/artifacts/c9/b3/6e/3b16eb20d40f7e63e784f51f05251eb5cad213333fd4e9bd1cd41ffc4f/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl\r\nmurmurhash @ file:///home/ypaykov/.cache/pypoetry/artifacts/f4/3d/9e/b109a2b34a9e2e8ade6e012d25d9220074194d2b0480d18240cd4c9354/murmurhash-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl\r\nmypy @ file:///home/ypaykov/.cache/pypoetry/artifacts/bc/3e/5a/34d2f61d3e31aea39dae743ac9e8ffa85a130130b2843f21304fba04f0/mypy-0.910-cp37-cp37m-manylinux2010_x86_64.whl\r\nmypy-extensions @ file:///home/ypaykov/.cache/pypoetry/artifacts/bf/b4/62/e583c259631d6cdbc5fe4febf019e99216d8ec3b43a302d4f793d2dc9d/mypy_extensions-0.4.3-py2.py3-none-any.whl\r\nnanotime @ file:///home/ypaykov/.cache/pypoetry/artifacts/6d/b1/26/9c7d213244f3caf39f4707d309a3502e7057169ca8336ba4410858de36/nanotime-0.5.2.tar.gz\r\nnetworkx @ file:///home/ypaykov/.cache/pypoetry/artifacts/44/fd/31/c20fc829c3be9182657d04c6101114d764e724898223ac827510b11229/networkx-2.5.1-py3-none-any.whl\r\nnltk @ file:///home/ypaykov/.cache/pypoetry/artifacts/2a/9a/de/0acf4cc2ac836e4f088edc9acac329cafd56939c591efdf341597e91c4/nltk-3.6.2-py3-none-any.whl\r\nnmslib @ file:///home/ypaykov/.cache/pypoetry/artifacts/59/bc/04/7927dbc81fbff024e19bd9bf86b53604bffa1c15eefa96b363c294950e/nmslib-2.1.1-cp37-cp37m-manylinux2010_x86_64.whl\r\nnumpy @ file:///home/ypaykov/.cache/pypoetry/artifacts/f4/c3/98/ceeb60899b2ef223a6ce2a9d54b9a33cee3d74879fe5143796ee2095d0/numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl\r\noauthlib @ file:///home/ypaykov/.cache/pypoetry/artifacts/b3/ee/90/9877929a26608346e479db2d682c007d96f8617db63e70e5d5798f7336/oauthlib-3.1.1-py2.py3-none-any.whl\r\nopenpyxl @ file:///home/ypaykov/.cache/pypoetry/artifacts/22/b6/62/3d36a75f52ba3dc33815855601acf8bdc5ac0700e84c40b81d30bbbd96/openpyxl-3.0.7-py2.py3-none-any.whl\r\nopt-einsum @ file:///home/ypaykov/.cache/pypoetry/artifacts/a2/dd/5a/aa8a2e33f77e81426e4e25da7b39a754866e03f47eba405f7af7bba60f/opt_einsum-3.3.0-py3-none-any.whl\r\noptuna @ file:///home/ypaykov/.cache/pypoetry/artifacts/40/c4/74/18524c8eed51792e7c171054679a2557fdb87ebb424597f97b2cac71fb/optuna-2.8.0-py3-none-any.whl\r\noverrides @ file:///home/ypaykov/.cache/pypoetry/artifacts/39/a5/1a/558c012bad6e41e8f9153ef5cb83c3b4a8d5f604c852771d273d6d8d10/overrides-3.1.0.tar.gz\r\npackaging @ file:///home/ypaykov/.cache/pypoetry/artifacts/b3/b1/89/c2f786996ca1576f9f08a744b1e1f062091dae1240367903d0653c63b7/packaging-21.0-py3-none-any.whl\r\npandas @ file:///home/ypaykov/.cache/pypoetry/artifacts/33/81/79/fb1b81742d9f634c874c4a3f23c36bbfded6156bad206e029e77b4806e/pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl\r\nparams-flow @ file:///home/ypaykov/.cache/pypoetry/artifacts/4f/24/99/a2bf061949eb53d1e4acc9061b19eb6aa5392686fb7e6a0971736601fa/params-flow-0.8.2.tar.gz\r\nparso==0.8.2\r\npathspec @ file:///home/ypaykov/.cache/pypoetry/artifacts/6a/8a/0f/492ce3e8af186e53038f16fe300ef0156780436696da258bc81624b8e6/pathspec-0.8.1-py2.py3-none-any.whl\r\npathtools @ file:///home/ypaykov/.cache/pypoetry/artifacts/98/86/a8/56d3423b88b356d2b86f6803be761974d268770812ca415071130ef6ef/pathtools-0.1.2.tar.gz\r\npbr @ file:///home/ypaykov/.cache/pypoetry/artifacts/9b/b6/44/60a7ef0af0dd8fa5e668ec9131047d384bc2d239af5ef8cca52665e15e/pbr-5.6.0-py2.py3-none-any.whl\r\npep8-naming @ file:///home/ypaykov/.cache/pypoetry/artifacts/39/39/52/48b5100f6c16dbc2f9668e4cd58fdbe7d36ece0c200bed91145d9fe9b6/pep8_naming-0.11.1-py2.py3-none-any.whl\r\npexpect==4.8.0\r\nphonenumbers @ file:///home/ypaykov/.cache/pypoetry/artifacts/a7/0d/82/d8afd3d15627ff180e47ca8c50e5bcb1644a7c55b5e29abd30e9a7dd6f/phonenumbers-8.12.26-py2.py3-none-any.whl\r\npickleshare==0.7.5\r\nPillow @ file:///home/ypaykov/.cache/pypoetry/artifacts/24/51/1e/c8a3660365f684b5f041142ce3edb1953d1e3f4f847036fca65ed90b8e/Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl\r\nplac @ file:///home/ypaykov/.cache/pypoetry/artifacts/f6/82/f5/14e97321affb4ac27f18ddf4ffa9a3f350265cdcdeddfcd3558e1ca50f/plac-1.1.3-py2.py3-none-any.whl\r\npluggy @ file:///home/ypaykov/.cache/pypoetry/artifacts/03/70/1b/0161002058384cc8a621750b9e6ca6ec27c934ccfb029e7041dac03bbc/pluggy-0.13.1-py2.py3-none-any.whl\r\nply @ file:///home/ypaykov/.cache/pypoetry/artifacts/38/e2/83/dec1b319aec24541211c740bd0409a9c8a9a1cd9af32426e2de5ec4258/ply-3.11-py2.py3-none-any.whl\r\npreprocessor @ file:///home/ypaykov/.cache/pypoetry/artifacts/26/3b/c1/a9a2359651f47f90f5c880ed36fdc25a8a44e8b2da87ce95cb0ab6e5c4/preprocessor-0.1.2-py3-none-any.whl\r\npreshed @ file:///home/ypaykov/.cache/pypoetry/artifacts/19/3d/75/ff7e5cfc4c0d62febcc10e0f17345f2e149cb89889f38e6f968e46d111/preshed-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl\r\nprettytable @ file:///home/ypaykov/.cache/pypoetry/artifacts/82/56/69/5a0f21904615f8c1f7d3b726a118c52f23766a6811a5568df6ce4d9a4e/prettytable-2.1.0-py3-none-any.whl\r\nprogressbar2 @ file:///home/ypaykov/.cache/pypoetry/artifacts/b8/14/a1/c0188225816c6bf960cee2a3a3822bd5293cb7a039c0756dbbc75c5867/progressbar2-3.53.1-py2.py3-none-any.whl\r\npromise @ file:///home/ypaykov/.cache/pypoetry/artifacts/25/32/f4/dff77ee6616168fce4d1e3dfaf20f93c7d751b0cb574e8447b048a108e/promise-2.3.tar.gz\r\nprompt-toolkit @ file:///home/ypaykov/.cache/pypoetry/artifacts/7e/80/fd/f8d17973ef42d2a6219044c2937ae90f62973eb9d8c6ec2cd22ec13475/prompt_toolkit-3.0.19-py3-none-any.whl\r\nprotobuf @ file:///home/ypaykov/.cache/pypoetry/artifacts/0a/6f/cd/aff925e751a3988ac3244b6c66a816b5b3f3a3de7444bf2ecf06f8d6c7/protobuf-3.17.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\r\npsutil @ file:///home/ypaykov/.cache/pypoetry/artifacts/a2/43/14/1b699f8e5eea56b33e6da9e28eb96e32bacd3e397096e00b019d801a40/psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl\r\nptyprocess==0.7.0\r\npy @ file:///home/ypaykov/.cache/pypoetry/artifacts/20/a0/83/d8b0192779e622d8b508670de445f63eebf17b175cfb086458a3923832/py-1.10.0-py2.py3-none-any.whl\r\npy-params @ file:///home/ypaykov/.cache/pypoetry/artifacts/12/d1/90/b1f734dca73d3e14021166b552d502c7f0c6882406619a4ea5aa56ea49/py-params-0.10.2.tar.gz\r\npyahocorasick @ file:///home/ypaykov/.cache/pypoetry/artifacts/f3/1c/52/8c46a365f106d5200eedb2b31bee5d8d3e3cf83cb6731b66365354d6ae/pyahocorasick-1.4.2.tar.gz\r\npyasn1 @ file:///home/ypaykov/.cache/pypoetry/artifacts/12/28/20/42ea93add896bb1f360d752e8a8a84d44983c44f9dc778f536423736e5/pyasn1-0.4.8-py2.py3-none-any.whl\r\npyasn1-modules @ file:///home/ypaykov/.cache/pypoetry/artifacts/dd/32/0d/0466cfccc2338a61d333a13596c0551bf8f76832df09f4e52587f36199/pyasn1_modules-0.2.8-py2.py3-none-any.whl\r\npybind11 @ file:///home/ypaykov/.cache/pypoetry/artifacts/d2/b3/c6/69ec8c05021f2c442f795cd31bd05c05d781b2bf937ba6e41f1395d962/pybind11-2.6.1-py2.py3-none-any.whl\r\npycodestyle @ file:///home/ypaykov/.cache/pypoetry/artifacts/9b/c8/2d/364488224e7f8db3aa1f1c1a4db4603be7e7f42fbd90b66c91c1a7936e/pycodestyle-2.7.0-py2.py3-none-any.whl\r\npycparser @ file:///home/ypaykov/.cache/pypoetry/artifacts/87/23/1e/a70df1ef5ef1b561427577c728c16778dfdec362d600847546d64bf5c1/pycparser-2.20-py2.py3-none-any.whl\r\npydantic @ file:///home/ypaykov/.cache/pypoetry/artifacts/72/d5/ce/84f3dda882078f20e226fcc9363bec8ebc90e97030d9a9729dd7a3b52c/pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl\r\npydot @ file:///home/ypaykov/.cache/pypoetry/artifacts/a1/f4/24/0355ea4160bbae0a3e75b2e7bcd5d62a0d481d30423653ca9ab8b5fa15/pydot-1.4.2-py2.py3-none-any.whl\r\npyflakes @ file:///home/ypaykov/.cache/pypoetry/artifacts/81/23/37/5e65256a90e680bb3fe3664a060ef09110ba5a680dc901a546a812597c/pyflakes-2.3.1-py2.py3-none-any.whl\r\npygit2 @ file:///home/ypaykov/.cache/pypoetry/artifacts/50/45/f3/fd286131dedfaae56a14b4ec2a1ca87350f681914520f70e8e46971977/pygit2-1.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nPygments==2.9.0\r\npygtrie @ file:///home/ypaykov/.cache/pypoetry/artifacts/de/cb/bc/3cc8cafac87fb55d8f99aaff7121ed4ed75b4c49b3398b244f751b29fa/pygtrie-2.3.2.tar.gz\r\npylint @ file:///home/ypaykov/.cache/pypoetry/artifacts/13/7f/4f/d3539c95a22db22be539fc35b2955e2d685af83cb49597fbb29b876dde/pylint-2.9.3-py3-none-any.whl\r\npylint-gitlab @ file:///home/ypaykov/.cache/pypoetry/artifacts/37/83/ed/923283cf4a7f4b5b31e3b55252262ecda18c0a249485339170ae5d09a0/pylint_gitlab-0.3.0-py3-none-any.whl\r\npylint-pytest @ file:///home/ypaykov/.cache/pypoetry/artifacts/bb/c4/2b/b43b8742c689407a208f47b518886ff9d3694961b03a5c7ffa839bcfd8/pylint_pytest-0.3.0-py2.py3-none-any.whl\r\npymorphy2 @ file:///home/ypaykov/.cache/pypoetry/artifacts/05/96/8e/a229e6dc376a01b05c2673b450f07bff2dd993fd7e33f3ccbd5bdf1af0/pymorphy2-0.8-py2.py3-none-any.whl\r\npymorphy2-dicts @ file:///home/ypaykov/.cache/pypoetry/artifacts/1b/0b/26/924f500636d62e2262ca563e7155b4651aec71faf9c43faee8d9a51b7e/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl\r\npymorphy2-dicts-ru @ file:///home/ypaykov/.cache/pypoetry/artifacts/90/11/28/b40efca33ca06db85caf09a37048e304e9a06fb0892551df92f037d4b6/pymorphy2_dicts_ru-2.4.393658.3725883-py2.py3-none-any.whl\r\npymorphy2-dicts-uk @ file:///home/ypaykov/.cache/pypoetry/artifacts/cf/28/fc/816c34ed8417ac384b2e60ea20fd0a83d1abfef093a0490322fc81b0c6/pymorphy2_dicts_uk-2.4.1.1.1460299261-py2.py3-none-any.whl\r\npymystem3 @ file:///home/ypaykov/.cache/pypoetry/artifacts/30/ed/07/b488ffa7f90694095c24d071d5722c83feedcf41f54c4588f99df8c869/pymystem3-0.2.0-py3-none-any.whl\r\npyparsing @ file:///home/ypaykov/.cache/pypoetry/artifacts/4a/72/b8/b1ea43dff7c2d14425311efe6de93622ca32401a6b20e73fc81884acdb/pyparsing-2.4.7-py2.py3-none-any.whl\r\npyperclip @ file:///home/ypaykov/.cache/pypoetry/artifacts/79/f0/56/f8ca0351b58404a818ad2097a1456729602eea2acd5e78b18f88f8b180/pyperclip-1.8.2.tar.gz\r\npytest @ file:///home/ypaykov/.cache/pypoetry/artifacts/af/64/67/25b66519b4e3f49e3f1e7176a1f409386ec994d0fbc531d694353bf476/pytest-6.2.4-py3-none-any.whl\r\npytest-cov @ file:///home/ypaykov/.cache/pypoetry/artifacts/fb/30/60/9465a09324b6c700f570964bec46c9c108b75701ae95148d1ecdd39311/pytest_cov-2.11.1-py2.py3-none-any.whl\r\npytest-custom-exit-code @ file:///home/ypaykov/.cache/pypoetry/artifacts/60/20/5d/950f590820a6ddb52f0dec9d79c3fdf1c816f19e9f3fe41b8c712bebbf/pytest_custom_exit_code-0.3.0-py3-none-any.whl\r\npytest-freezegun @ file:///home/ypaykov/.cache/pypoetry/artifacts/44/fb/5e/eddd087fb8ceca6c25fa019087e404aad44595d03b3712095f2de5dae1/pytest_freezegun-0.4.2-py2.py3-none-any.whl\r\npytest-lazy-fixture @ file:///home/ypaykov/.cache/pypoetry/artifacts/ee/87/f7/6a6cd79423f70ab67f78066f2b5d535ae76d15e4d40b2056ac28b46957/pytest_lazy_fixture-0.6.3-py3-none-any.whl\r\npytest-mock @ file:///home/ypaykov/.cache/pypoetry/artifacts/21/0f/20/6f7cc87eb21a1a5da6cc63759efc8ac8b5212c589e79042d90a8445b98/pytest_mock-3.6.1-py3-none-any.whl\r\npython-benedict @ file:///home/ypaykov/.cache/pypoetry/artifacts/35/95/00/7114daeaeea1c7df3adeb2449496f0c007f490cfe761ada30d44c7f576/python_benedict-0.24.0-py3-none-any.whl\r\npython-crfsuite @ file:///home/ypaykov/.cache/pypoetry/artifacts/de/51/4a/d0b420f61de89d055aac692a367e5457d98fdddea34a8e41873d1b5037/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl\r\npython-dateutil @ file:///home/ypaykov/.cache/pypoetry/artifacts/91/f8/4f/b00762a4dbb64f3476a057542484343676acef163e42963d298c6fe216/python_dateutil-2.8.1-py2.py3-none-any.whl\r\npython-dotenv @ file:///home/ypaykov/.cache/pypoetry/artifacts/e3/d2/f6/1326ba2fc5e6b7a86b349af13f4be7b242e35b48fe13bc4536fe1769cd/python_dotenv-0.17.1-py2.py3-none-any.whl\r\npython-editor @ file:///home/ypaykov/.cache/pypoetry/artifacts/3f/9c/bd/6d156b34401db06dc35840127c99b027258b8d3656673b5c1313810855/python_editor-1.0.4-py3-none-any.whl\r\npython-fsutil @ file:///home/ypaykov/.cache/pypoetry/artifacts/95/68/89/5cedff56038827900d6658d45d4a4f82d0271dc7c46c8d8a535678395a/python_fsutil-0.5.0-py3-none-any.whl\r\npython-Levenshtein @ file:///home/ypaykov/.cache/pypoetry/artifacts/b5/6d/d7/79b772ff9dd8c2214b34cea2127300ea8c4881ce0f93b5afee968350ec/python-Levenshtein-0.12.2.tar.gz\r\npython-slugify @ file:///home/ypaykov/.cache/pypoetry/artifacts/7a/49/d7/e73e646767a915f4bc7ad5d2abaa8de0e220983569b33f262209e2babe/python_slugify-5.0.2-py2.py3-none-any.whl\r\npython-utils @ file:///home/ypaykov/.cache/pypoetry/artifacts/29/05/a7/11a728fb457669b18fd6743f5e6462208b793df409ccd50a7856dbe232/python_utils-2.5.6-py2.py3-none-any.whl\r\npytz @ file:///home/ypaykov/.cache/pypoetry/artifacts/97/24/da/655a858c81aa71ff89c15bcecd0462856275643c1e9584ec109420c19c/pytz-2021.1-py2.py3-none-any.whl\r\nPyYAML @ file:///home/ypaykov/.cache/pypoetry/artifacts/dc/dc/d5/5e50ec775b30045a52d98dd12d77509e3c5ac3e3dcee9005fe7d6d44aa/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl\r\nrazdel @ file:///home/ypaykov/.cache/pypoetry/artifacts/eb/25/42/c576c132b2718c2ec3640b07f15a28d216ec3b9e8988a6836a38e35b3c/razdel-0.5.0-py3-none-any.whl\r\nredis @ file:///home/ypaykov/.cache/pypoetry/artifacts/4c/b2/dd/1d4042256280c049b64660b64edd2ebd4406089987a870153d2c432eef/redis-3.5.3-py2.py3-none-any.whl\r\nregex @ file:///home/ypaykov/.cache/pypoetry/artifacts/0e/d3/bf/3c5aefa12c8b2196d13771ce4a5ebfe64ba3a8e84aa361b44302484097/regex-2021.7.6-cp37-cp37m-manylinux2014_x86_64.whl\r\nrequests @ file:///home/ypaykov/.cache/pypoetry/artifacts/f0/3a/d1/78a915ed45a80aa3d9c912cf8622ab2d47ca17fadeec7cdf06fc6f7ad3/requests-2.25.1-py2.py3-none-any.whl\r\nrequests-mock @ file:///home/ypaykov/.cache/pypoetry/artifacts/12/57/48/eed8cfccf3937b83b919a1a7d9b0c137d6d9fd44600062ffbc5597577c/requests_mock-1.9.3-py2.py3-none-any.whl\r\nrequests-oauthlib @ file:///home/ypaykov/.cache/pypoetry/artifacts/eb/4f/27/28c7f4d3c9ea535c3e7907dcdf8e987cd8d5b0758d44ce1054e5367ab8/requests_oauthlib-1.3.0-py2.py3-none-any.whl\r\nrich @ file:///home/ypaykov/.cache/pypoetry/artifacts/11/a3/8f/c3048c41aa180563ff79471184fe6e1201155b893e15cc8d05e899f610/rich-10.3.0-py3-none-any.whl\r\nrsa @ file:///home/ypaykov/.cache/pypoetry/artifacts/17/3a/37/2a0593f5a3faadaec16585fb21e97ffb43dddcf9a4a0af59e488bab66e/rsa-4.7.2-py3-none-any.whl\r\nruamel.yaml @ file:///home/ypaykov/.cache/pypoetry/artifacts/e0/ba/e5/81a7a89daa6fa89582697824a5fec3eddd5247125629aa3731d2f78750/ruamel.yaml-0.17.9-py3-none-any.whl\r\nruamel.yaml.clib @ file:///home/ypaykov/.cache/pypoetry/artifacts/58/b8/e9/d7442431236564cea9c4ed339a2e0c9d84ae6aef903d9f5cbd27c3f375/ruamel.yaml.clib-0.2.2-cp37-cp37m-manylinux1_x86_64.whl\r\ns3fs @ file:///home/ypaykov/.cache/pypoetry/artifacts/0d/ee/1c/5d362b9ac5727a88212355d9105115a7b6711d436015167e1896395453/s3fs-2021.5.0-py3-none-any.whl\r\ns3transfer @ file:///home/ypaykov/.cache/pypoetry/artifacts/a5/d3/7a/062cd2e96134189568180c41abf43e9c3bafb76336e11250b9e509a731/s3transfer-0.4.2-py2.py3-none-any.whl\r\nsacremoses @ file:///home/ypaykov/.cache/pypoetry/artifacts/2a/06/e6/af589a22b8b9ec9262f53968791973a86f0460b1799368dcb0997d31ae/sacremoses-0.0.45-py3-none-any.whl\r\nscikit-learn @ file:///home/ypaykov/.cache/pypoetry/artifacts/07/d2/f6/cc68ffda1f3c153bbae341ae090dc80672846950b1965003baff1a8ffe/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl\r\nscipy @ file:///home/ypaykov/.cache/pypoetry/artifacts/cd/56/c3/e71f3ccd1a84f150c2be3effa71d306524a8395aa27133eadfd0c79ac5/scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl\r\nseaborn @ file:///home/ypaykov/.cache/pypoetry/artifacts/c5/e7/25/7d4f8def783c72c634bb8d8e9556ef6b8d203d907497e14ebfaaf2fee9/seaborn-0.10.1-py3-none-any.whl\r\nsentencepiece @ file:///home/ypaykov/.cache/pypoetry/artifacts/62/06/a8/06e241606751ae33cb6be8109242164f3f402818a9f7dcc9206d9cb0f3/sentencepiece-0.1.6-cp37-cp37m-manylinux1_x86_64.whl\r\nsentry-sdk @ file:///home/ypaykov/.cache/pypoetry/artifacts/cf/f0/ca/3c6f5b54adf2b20550fa7556a04c2957ed3258f449fff5b98b08afe845/sentry_sdk-0.14.3-py2.py3-none-any.whl\r\nshortuuid @ file:///home/ypaykov/.cache/pypoetry/artifacts/b2/b1/40/d2443f6efc92568af08cb96da37988e064a3108cb141b01840931172a8/shortuuid-1.0.1-py3-none-any.whl\r\nshtab @ file:///home/ypaykov/.cache/pypoetry/artifacts/9d/db/e3/3b2b4407481bb92969c1615d4adbae1b7d9854c6cca1a9e3b16c1f8b7e/shtab-1.3.6-py2.py3-none-any.whl\r\nsix @ file:///home/ypaykov/.cache/pypoetry/artifacts/d5/30/45/07617699b5d5ea0b81275d0d7ef6136fade8c065a3578dedd345b2799b/six-1.15.0-py2.py3-none-any.whl\r\nsklearn @ file:///home/ypaykov/.cache/pypoetry/artifacts/94/43/bc/0af66c1d38b5ef48a8c6b710c3f19f3324bbe630c38e23c6389eb988e8/sklearn-0.0.tar.gz\r\nsmmap @ file:///home/ypaykov/.cache/pypoetry/artifacts/5d/4f/e0/b2710b14b695e45447a256e186be64f0ac2a3a5d6a9fe5091ffee5eb22/smmap-4.0.0-py2.py3-none-any.whl\r\nsortedcontainers @ file:///home/ypaykov/.cache/pypoetry/artifacts/b9/bd/3e/2973f10950d2a0678cfdb30a8beb4306b252dcd6b7d1242efd47a2b20f/sortedcontainers-2.4.0-py2.py3-none-any.whl\r\nspacy @ file:///home/ypaykov/.cache/pypoetry/artifacts/cd/c4/00/a8d3c7909d907074080b517875d973d1a187bc6c33e22402dcf06a86b2/spacy-2.3.5-cp37-cp37m-manylinux2014_x86_64.whl\r\nSQLAlchemy @ file:///home/ypaykov/.cache/pypoetry/artifacts/4b/a8/f4/11d4514628cceffa66ad63682cc39e061b243be973a566e77c742cf679/SQLAlchemy-1.4.20-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\nsrsly @ file:///home/ypaykov/.cache/pypoetry/artifacts/28/81/45/a9743faab11584c88c44a93cdd91171e206264749e769d757bf4de607c/srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl\r\nstarlette @ file:///home/ypaykov/.cache/pypoetry/artifacts/b7/17/eb/cd993f65b4f40144711db3a632b72937af806d92808e163b5466d1fe48/starlette-0.13.6-py3-none-any.whl\r\nstevedore @ file:///home/ypaykov/.cache/pypoetry/artifacts/d6/3a/de/710f67ede8f2b1ca16396a5acafab9a5511c94825fe1f0cf9dbb586a2f/stevedore-3.3.0-py3-none-any.whl\r\nsubprocess32 @ file:///home/ypaykov/.cache/pypoetry/artifacts/f5/54/73/bf5d5b48490d10903521c768c7d42644333473979d2f94c65e8e64633d/subprocess32-3.5.4.tar.gz\r\nsubword-nmt @ file:///home/ypaykov/.cache/pypoetry/artifacts/d9/0a/00/b1651680e715db25081cb912e375da8678d866ea5c7f80e605019cf4d7/subword_nmt-0.3.7-py2.py3-none-any.whl\r\ntabulate @ file:///home/ypaykov/.cache/pypoetry/artifacts/ab/69/a0/4f3ed32a38462b9b722c4b6dfb9e5ba262758c6307616ebd6e30fd89ca/tabulate-0.8.9-py3-none-any.whl\r\ntenacity @ file:///home/ypaykov/.cache/pypoetry/artifacts/7d/2a/d4/4435d9d4695e3168dcdbaac9ca193163831d635a2b9aa25829afd67bd8/tenacity-6.3.1-py2.py3-none-any.whl\r\ntensorboard @ file:///home/ypaykov/.cache/pypoetry/artifacts/1d/ce/47/e8d0aeaeb24db1ba0693b2731701e8773f6eb84cfa705b3928aff8be4d/tensorboard-2.5.0-py3-none-any.whl\r\ntensorboard-data-server @ file:///home/ypaykov/.cache/pypoetry/artifacts/64/67/56/c86d6cc9784f7a820bcca94b36e228b392a09bcdeb07ea7b51efb639dc/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl\r\ntensorboard-plugin-wit @ file:///home/ypaykov/.cache/pypoetry/artifacts/90/a5/fc/ba021f33dba2c781b0b98cd7e8597db6c881999ab591df99e34fd2940c/tensorboard_plugin_wit-1.8.0-py3-none-any.whl\r\ntensorboardX @ file:///home/ypaykov/.cache/pypoetry/artifacts/09/a1/d3/2cd5265a1373b126bc186ab157754da4cb9df8063fa5811869277b753e/tensorboardX-2.2-py2.py3-none-any.whl\r\ntensorflow @ file:///home/ypaykov/.cache/pypoetry/artifacts/f4/ff/ff/e2361f008cadbbad802299de20d0d5f27d9c2bf8a20b91c57680948d6b/tensorflow-2.4.2-cp37-cp37m-manylinux2010_x86_64.whl\r\ntensorflow-estimator @ file:///home/ypaykov/.cache/pypoetry/artifacts/9c/5b/04/f1dbbdbc2ff305715224b098d985deb5279b8e49e7d72185a7abd6a7ba/tensorflow_estimator-2.4.0-py2.py3-none-any.whl\r\ntensorflow-hub @ file:///home/ypaykov/.cache/pypoetry/artifacts/f4/97/75/d4a28ed93df2e473fd0293d7c2522b81847b0419c6b5ca673be0c01a7e/tensorflow_hub-0.12.0-py2.py3-none-any.whl\r\ntensorflow-text @ file:///home/ypaykov/.cache/pypoetry/artifacts/58/a8/04/ae782c9ad1b68734208a9aa57658602889b3dc8c4fd684ee1cce19489c/tensorflow_text-2.4.3-cp37-cp37m-manylinux1_x86_64.whl\r\ntermcolor @ file:///home/ypaykov/.cache/pypoetry/artifacts/41/57/8a/45894af73d8c7ced5ac69d0d3b3d1de8a648c2fe4b72cb3579d50afe11/termcolor-1.1.0.tar.gz\r\ntestfixtures @ file:///home/ypaykov/.cache/pypoetry/artifacts/59/5c/44/3ea887f888082523e11bade52b3aea8809d294824cf152070ea815d8c4/testfixtures-6.17.1-py2.py3-none-any.whl\r\ntext-unidecode @ file:///home/ypaykov/.cache/pypoetry/artifacts/07/57/b8/1bc7089977ad3bfd658cf460af98a2aeb3e00063dded47718fb60768ad/text_unidecode-1.3-py2.py3-none-any.whl\r\nthinc @ file:///home/ypaykov/.cache/pypoetry/artifacts/03/e8/a2/6149b8d7dd0b69fa8f125f0654af414232f87e7b18fc06746917a5bd82/thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl\r\nthreadpoolctl @ file:///home/ypaykov/.cache/pypoetry/artifacts/5f/a8/55/46f8df66b64c9dd5412c245bfb85637f65f394cbfda21aa150393c979f/threadpoolctl-2.1.0-py3-none-any.whl\r\ntokenizers @ file:///home/ypaykov/.cache/pypoetry/artifacts/42/c6/5f/62cd859a601c36da6eb92279c1a18a9fe3be4da2dac05a27533f8acc8c/tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl\r\ntoml @ file:///home/ypaykov/.cache/pypoetry/artifacts/fb/24/3d/ca3473d5e25522da59a159331f04d388ac1123324bdf25bb5df62f61ad/toml-0.10.2-py2.py3-none-any.whl\r\ntorch @ file:///home/ypaykov/.cache/pypoetry/artifacts/71/f4/21/ea24c96c5c6dc388b28aa6b7195c973f34657a563eda27e279963ea9fc/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl\r\ntorchmetrics @ file:///home/ypaykov/.cache/pypoetry/virtualenvs/clusters-p3buAsje-py3.7/src/torchmetrics\r\ntqdm @ file:///home/ypaykov/.cache/pypoetry/artifacts/fa/17/db/6fda27d1e9504447d803b0060f604a5f2ea5928fc2e226347da49339d5/tqdm-4.61.1-py2.py3-none-any.whl\r\ntraitlets==5.0.5\r\ntransformers @ file:///home/ypaykov/.cache/pypoetry/artifacts/62/ab/63/447cbfec214bfbd2734c715d6e301c4e6433276f061d0714d145949dec/transformers-4.2.2-py3-none-any.whl\r\ntransliterate @ file:///home/ypaykov/.cache/pypoetry/artifacts/93/84/40/2f30456608a557d660a00c81c073f1c2167ef929dbff10c7850e810eca/transliterate-1.10.2-py2.py3-none-any.whl\r\ntyped-ast @ file:///home/ypaykov/.cache/pypoetry/artifacts/68/d4/5c/3a2864abc2622569530d2ab268f02d71a9a41701ef9c9791ba184f3aa1/typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl\r\ntyper @ file:///home/ypaykov/.cache/pypoetry/artifacts/11/aa/45/a75b659486d4e7b1e8368421963768cdf096c362f2fea2b49761797a82/typer-0.3.2-py3-none-any.whl\r\ntypes-redis @ file:///home/ypaykov/.cache/pypoetry/artifacts/e9/5e/05/daa16bd65a81cfb34b74e5b5da6824bd453202982d9682fa47295e78f8/types_redis-3.5.4-py3-none-any.whl\r\ntypes-requests @ file:///home/ypaykov/.cache/pypoetry/artifacts/50/21/fc/3b5528fdd9cd4deb03dcb2018e47a6efebc36bd634fe122b847618a6d1/types_requests-0.1.13-py3-none-any.whl\r\ntyping-extensions @ file:///home/ypaykov/.cache/pypoetry/artifacts/90/23/0b/46557cda998e41d336a1a6598d58b6502a20159c32930135c22f602225/typing_extensions-3.7.4.3-py3-none-any.whl\r\nunify @ file:///home/ypaykov/.cache/pypoetry/artifacts/72/a8/38/fb3b5a4feac4ccb8e2a8c77cf4f8af5bf601961d7fd7dd01d8359593a3/unify-0.5.tar.gz\r\nuntokenize @ file:///home/ypaykov/.cache/pypoetry/artifacts/b3/44/bd/cb3c20fa78ded15cc7e2b5450787046de73e2f7ba20f447e9fb2b063d4/untokenize-0.1.1.tar.gz\r\nurllib3 @ file:///home/ypaykov/.cache/pypoetry/artifacts/0b/71/9a/a9590301113bdd9521260d5dc2cd9c3ffa62c5d9f83e8dc07cbd64a479/urllib3-1.25.11-py2.py3-none-any.whl\r\nuvicorn @ file:///home/ypaykov/.cache/pypoetry/artifacts/93/96/d7/52e7fea860ab101c19d7ccfb57c7ef00f825efaad527be0f40689842cc/uvicorn-0.8.6.tar.gz\r\nuvloop @ file:///home/ypaykov/.cache/pypoetry/artifacts/da/3a/21/905291f81c2faacc2d9ca537f0e55fba082abd6c41979b672c6f10ab3a/uvloop-0.12.2-cp37-cp37m-manylinux1_x86_64.whl\r\nvine @ file:///home/ypaykov/.cache/pypoetry/artifacts/5a/ae/30/2314fe0f05736553cbd04ae6093df60aaf687a55126a2bba7c723aac73/vine-5.0.0-py2.py3-none-any.whl\r\nvoluptuous @ file:///home/ypaykov/.cache/pypoetry/artifacts/f9/81/a1/e64f196fcfb070d0be62135fda058aa213c3db87b3486c8b99530a2905/voluptuous-0.12.1-py3-none-any.whl\r\nwandb @ file:///home/ypaykov/.cache/pypoetry/artifacts/49/50/c3/3939aa7a6418e2766b92a38fcb05050b4668cf3b9861db80d3676fd8b2/wandb-0.10.33-py2.py3-none-any.whl\r\nwasabi @ file:///home/ypaykov/.cache/pypoetry/artifacts/f9/bc/61/c4dced1a4d4d2d937657969a6aeb47f52417a96549aafe972e7ace51ea/wasabi-0.8.2-py3-none-any.whl\r\nwatchgod @ file:///home/ypaykov/.cache/pypoetry/artifacts/db/9f/83/b18055d7eebfb3f31258a6e3a903c5b9179770cbac62a51e18cbcb86fe/watchgod-0.6-py35.py36.py37-none-any.whl\r\nwcwidth @ file:///home/ypaykov/.cache/pypoetry/artifacts/bc/a1/12/3aaa7174598add6587fa675cd00483260242df1bf456325ec1ff3b4023/wcwidth-0.2.5-py2.py3-none-any.whl\r\nwebsockets @ file:///home/ypaykov/.cache/pypoetry/artifacts/dd/41/05/c5d08e96860b213baf60dc559de5f544d193c0435700c138c4c3437269/websockets-7.0-cp37-cp37m-manylinux1_x86_64.whl\r\nWerkzeug @ file:///home/ypaykov/.cache/pypoetry/artifacts/9f/94/95/3dd6ff9ce03f9b2230ba11a2b90b57901d4c6e5275552def19392473b7/Werkzeug-2.0.1-py3-none-any.whl\r\nwordcloud @ file:///home/ypaykov/.cache/pypoetry/artifacts/2e/8d/92/c701d6d63fe4b81e5c8d2de04e61df8ca972dcbc3c5113fcc7b95c5a96/wordcloud-1.8.1-cp37-cp37m-manylinux1_x86_64.whl\r\nwrapt @ file:///home/ypaykov/.cache/pypoetry/artifacts/6e/b8/e2/9f80d253af2ade89be4d0ea1b2e271b153f43f816ca3394cfa3584bf67/wrapt-1.12.1.tar.gz\r\nxlrd @ file:///home/ypaykov/.cache/pypoetry/artifacts/6b/a1/1c/d83ae62b3aea5815d71c3e17f8d8003c660cc53121ae50aad982940164/xlrd-1.2.0-py2.py3-none-any.whl\r\nxmltodict @ file:///home/ypaykov/.cache/pypoetry/artifacts/27/24/31/4f46989064d8364057e17c5421db9bbd4bc987e1a94d266229d3625e3a/xmltodict-0.12.0-py2.py3-none-any.whl\r\nyarl @ file:///home/ypaykov/.cache/pypoetry/artifacts/47/73/21/4b13d1f6d3392960ff7f01339bd4a7832321bdd8aaf65bc23d17b94dd5/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl\r\nyoutokentome @ file:///home/ypaykov/.cache/pypoetry/artifacts/6a/89/07/4ec8a721f0531c22b0ab019a3f2d24b8916490eb8f46b6e86fcd3a6cbc/youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl\r\nzc.lockfile @ file:///home/ypaykov/.cache/pypoetry/artifacts/4e/25/21/85c0a3d65245ef6b557c3c13c889a5e7c6e574f8ee23ca1bd622611af4/zc.lockfile-2.0-py2.py3-none-any.whl\r\nzipp @ file:///home/ypaykov/.cache/pypoetry/artifacts/84/b9/75/4164ed8e999828b4df427ed954a3c112f6c38c0541db6e11da734933ca/zipp-3.5.0-py3-none-any.whl\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```python\r\nfrom pickle import dumps, loads\r\nfrom allennlp.common.checks import ConfigurationError\r\nloads(dumps(ConfigurationError('ololo')))\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5318/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5318/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5313", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5313/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5313/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5313/events", "html_url": "https://github.com/allenai/allennlp/issues/5313", "id": 946044334, "node_id": "MDU6SXNzdWU5NDYwNDQzMzQ=", "number": 5313, "title": "ConditionalRandomFields doesn't train on the GPU", "user": {"login": "alle-pawols", "id": 84400296, "node_id": "MDQ6VXNlcjg0NDAwMjk2", "avatar_url": "https://avatars.githubusercontent.com/u/84400296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alle-pawols", "html_url": "https://github.com/alle-pawols", "followers_url": "https://api.github.com/users/alle-pawols/followers", "following_url": "https://api.github.com/users/alle-pawols/following{/other_user}", "gists_url": "https://api.github.com/users/alle-pawols/gists{/gist_id}", "starred_url": "https://api.github.com/users/alle-pawols/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alle-pawols/subscriptions", "organizations_url": "https://api.github.com/users/alle-pawols/orgs", "repos_url": "https://api.github.com/users/alle-pawols/repos", "events_url": "https://api.github.com/users/alle-pawols/events{/privacy}", "received_events_url": "https://api.github.com/users/alle-pawols/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2021-07-16T08:02:20Z", "updated_at": "2021-07-19T19:31:49Z", "closed_at": "2021-07-19T19:31:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nWhen training the ConditionalRandomFields as an additional layer in a model implemented in the PyTorch lightning framework on the GPU I've got the error about inconsistent devices. \r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  [...]\r\n  File \"/root/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 812, in training_step_and_backward\r\n    result = self.training_step(split_batch, batch_idx, opt_idx, hiddens)\r\n  File \"/root/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 280, in training_step\r\n    training_step_output = self.trainer.accelerator.training_step(args)\r\n  File \"/root/.local/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 204, in training_step\r\n    return self.training_type_plugin.training_step(*args)\r\n  File \"/root/.local/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 155, in training_step\r\n    return self.lightning_module.training_step(*args, **kwargs)\r\n  File \"/root/.local/lib/python3.7/site-packages/marinero/architectures/models/sequence_taggers/lstm_crf_tagger.py\", line 103, in training_step\r\n    loss_value = self(input_tokens_ids, unrolled_target_tokens)\r\n  File \"/root/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/.local/lib/python3.7/site-packages/marinero/architectures/models/sequence_taggers/lstm_crf_tagger.py\", line 82, in forward\r\n    log_likelihood = self.crf_tagger(logits, targets)\r\n  File \"/root/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/.local/lib/python3.7/site-packages/allennlp/modules/conditional_random_field.py\", line 331, in forward\r\n    log_denominator = self._input_likelihood(inputs, mask)\r\n  File \"/root/.local/lib/python3.7/site-packages/allennlp/modules/conditional_random_field.py\", line 251, in _input_likelihood\r\n    alpha = util.logsumexp(inner, 1) * mask[i].view(batch_size, 1) + alpha * (\r\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux \r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:\r\n\r\n</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\npytorch-lightning==1.3.3\r\ntorch==1.7.1\r\ntorchmetrics==0.3.2\r\nallennlp==2.5.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\nPuttin\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5313/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5313/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5308", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5308/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5308/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5308/events", "html_url": "https://github.com/allenai/allennlp/issues/5308", "id": 942196054, "node_id": "MDU6SXNzdWU5NDIxOTYwNTQ=", "number": 5308, "title": "TextFieldTensors are not supported as input to a model Head", "user": {"login": "amitkparekh", "id": 7276308, "node_id": "MDQ6VXNlcjcyNzYzMDg=", "avatar_url": "https://avatars.githubusercontent.com/u/7276308?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amitkparekh", "html_url": "https://github.com/amitkparekh", "followers_url": "https://api.github.com/users/amitkparekh/followers", "following_url": "https://api.github.com/users/amitkparekh/following{/other_user}", "gists_url": "https://api.github.com/users/amitkparekh/gists{/gist_id}", "starred_url": "https://api.github.com/users/amitkparekh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amitkparekh/subscriptions", "organizations_url": "https://api.github.com/users/amitkparekh/orgs", "repos_url": "https://api.github.com/users/amitkparekh/repos", "events_url": "https://api.github.com/users/amitkparekh/events{/privacy}", "received_events_url": "https://api.github.com/users/amitkparekh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2021-07-12T15:44:45Z", "updated_at": "2021-07-26T18:05:23Z", "closed_at": "2021-07-26T18:05:23Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nI'm trying to pass a `TextFieldTensor` to a `Head` using the `multitask` Model. \r\n\r\nFor context, the `ClassifierHead` doesn't support `TextFieldTensors` for sequence decoding tasks. I created a simple head which inherits from the `AutoRegressiveSeqDecoder`, and puts the encoder text and mask into a dictionary before passing to the forward of the decoder. \r\n\r\n```python\r\n@Head.register(\"seq_decoder_tokens\")\r\nclass SeqDecoderTokensHead(AutoRegressiveSeqDecoder):\r\n    @overrides\r\n    def forward(\r\n        self,\r\n        encoded_text: torch.Tensor,\r\n        encoded_text_mask: torch.Tensor,\r\n        target_tokens: TextFieldTensors = None,\r\n    ) -> dict[str, torch.Tensor]:\r\n        encoder_out = {\r\n            \"encoder_outputs\": encoded_text,\r\n            \"source_mask\": encoded_text_mask,\r\n        }\r\n\r\n        return super().forward(encoder_out, target_tokens)\r\n```\r\n\r\nThe error, as in the traceback below, is with the `make_inputs_for_task` function.\r\nhttps://github.com/allenai/allennlp/blob/7d4a67263d7a210aca22d4f2b03e8568d3c34a48/allennlp/models/multitask.py#L114-L119\r\n\r\nFrom the type annotation, I'm assuming that it might not be supported by the model so I might be barking up the wrong tree? I assumed that I could just pass the variable to the Head and it would work. \r\n\r\nI'm not sure this is the best solution but I've made a fork with one possible solution, if it helps? \r\n\r\nhttps://github.com/amitkparekh/allennlp/commit/f1e0630d83ed0d459f1efa167e4b2bad76f80bb2\r\n\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/models/multitask.py\", line 125, in <listcomp>\r\n\treturn [whole_batch_input[i] for i in task_indices[task]]\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/models/multitask.py\", line 125, in make_inputs_for_task\r\n\treturn [whole_batch_input[i] for i in task_indices[task]]\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/models/multitask.py\", line 138, in <dictcomp>\r\n\thead_arguments = {key: make_inputs_for_task(head_name, value) for key, value in head_arguments.items()}\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/models/multitask.py\", line 138, in forward\r\n\thead_arguments = {key: make_inputs_for_task(head_name, value) for key, value in head_arguments.items()}\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\r\n\tresult = self.forward(*input, **kwargs)\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/training/gradient_descent_trainer.py\", line 351, in batch_outputs\r\n\toutput_dict = self._pytorch_model(**batch)\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/training/gradient_descent_trainer.py\", line 458, in _train_epoch\r\n\tbatch_outputs = self.batch_outputs(batch, for_training=True)\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/training/gradient_descent_trainer.py\", line 727, in _try_train\r\n\ttrain_metrics = self._train_epoch(epoch)\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/training/gradient_descent_trainer.py\", line 706, in train\r\n\tmetrics, epoch = self._try_train()\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/commands/train.py\", line 543, in run\r\n\treturn self.trainer.train()\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/commands/train.py\", line 470, in _train_worker\r\n\tmetrics = train_loop.run()\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/commands/train.py\", line 240, in train_model\r\n\tmodel = _train_worker(\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/commands/train.py\", line 171, in train_model_from_file\r\n\treturn train_model(\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/commands/train.py\", line 111, in train_model_from_args\r\n\ttrain_model_from_file(\r\nFile \"/Users/amit/Develop/pokerface/.venv/lib/python3.9/site-packages/allennlp/commands/__init__.py\", line 121, in main\r\n\targs.func(args)\r\nFile \"/Users/amit/Develop/pokerface/scraps/debug_allennlp.py\", line 35, in <module>\r\n\tmain()\r\nFile \"/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\r\n\texec(code, run_globals)\r\nFile \"/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 97, in _run_module_code\r\n\t_run_code(code, mod_globals, init_globals,\r\nFile \"/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 268, in run_path\r\n\treturn _run_module_code(code, init_globals, run_name,\r\nFile \"/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\r\n\texec(code, run_globals)\r\nFile \"/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main (Current frame)\r\n\treturn _run_code(code, main_globals, None,\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: OS X\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.9.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b1/ea/84/1d6e28cb885e4d55ac8939f78e408f7deb86ea845630a64f10d7700a62/allennlp-2.5.0-py3-none-any.whl\r\nallennlp-models @ file:///Users/amit/Library/Caches/pypoetry/artifacts/77/31/1f/2ef3c0ed6db0dc41de744411f56b478ab042f091dda6cd079b72b12c53/allennlp_models-2.5.0-py3-none-any.whl\r\nappdirs @ file:///Users/amit/Library/Caches/pypoetry/artifacts/47/cf/4f/4ef02fb715aa36daeebad18cc5570126159c659c41c7b5ec46a7387d9b/appdirs-1.4.4-py2.py3-none-any.whl\r\nappnope @ file:///Users/amit/Library/Caches/pypoetry/artifacts/fd/ae/b8/2382438588ec752ed602c2dcab2a0678b30ff15f2d9a30267ff97ecd64/appnope-0.1.2-py2.py3-none-any.whl\r\nargon2-cffi @ file:///Users/amit/Library/Caches/pypoetry/artifacts/3c/87/0e/fc0a0440e3e84e11c88d9d2d049f9aff2fdc4e7493dd19af67381b1d05/argon2_cffi-20.1.0-cp37-abi3-macosx_10_6_intel.whl\r\nastor @ file:///Users/amit/Library/Caches/pypoetry/artifacts/1f/03/36/982d1222edac5e8cb8ac6e0464249747fa800d4fb04728a99153ecfe4d/astor-0.8.1-py2.py3-none-any.whl\r\nasync-generator @ file:///Users/amit/Library/Caches/pypoetry/artifacts/fe/72/db/709736555b02c2d1ae90038b7b05138b15e24edde3aa7556fc2507a90f/async_generator-1.10-py3-none-any.whl\r\nattrs @ file:///Users/amit/Library/Caches/pypoetry/artifacts/6f/a9/ee/569c37f69a8c365ee41d2340aeac0214ee8c0086b8d8db43a21545204b/attrs-21.2.0-py2.py3-none-any.whl\r\nbackcall @ file:///Users/amit/Library/Caches/pypoetry/artifacts/43/8e/e8/4e598704edf6fb4a53d552ea511c04e9958dcf850897760e5387878b99/backcall-0.2.0-py2.py3-none-any.whl\r\nbackports.csv @ file:///Users/amit/Library/Caches/pypoetry/artifacts/30/84/1a/81a42cff31ce7f0b7a86ab54e2cbcb610d96fa8b735d63bdb7251e91cb/backports.csv-1.0.7-py2.py3-none-any.whl\r\nbandit @ file:///Users/amit/Library/Caches/pypoetry/artifacts/6a/05/4f/98680ab175e4b595c2d1b775974c208b6b20c05448a52944374c2db4b0/bandit-1.7.0-py3-none-any.whl\r\nbeartype @ file:///Users/amit/Library/Caches/pypoetry/artifacts/c3/fe/bd/c04bccf2fa951904264c6dc16cbdff35bc2aec170d65b9afb879841dfa/beartype-0.7.1-py3-none-any.whl\r\nbeautifulsoup4 @ file:///Users/amit/Library/Caches/pypoetry/artifacts/eb/47/47/287c1b8a386f9437d562f9221ae959756bc5bbfcd541c38c17968dfe8a/beautifulsoup4-4.9.3-py3-none-any.whl\r\nblack @ file:///Users/amit/Library/Caches/pypoetry/artifacts/6a/38/11/b77f947a81ed86d08787f98d076035bedb21abd3d3c57129221264c3ea/black-21.6b0-py3-none-any.whl\r\nbleach @ file:///Users/amit/Library/Caches/pypoetry/artifacts/15/bd/f0/eaed67c8e6d37dda902603474339528f29bde3f7ecc2bb4b8874e0da87/bleach-3.3.0-py2.py3-none-any.whl\r\nblis @ file:///Users/amit/Library/Caches/pypoetry/artifacts/96/b3/59/60398be6c97784bb3ba6ef5d76e86ce6bc530e27ca83de6d106b5dadd3/blis-0.7.4-cp39-cp39-macosx_10_9_x86_64.whl\r\nboto3 @ file:///Users/amit/Library/Caches/pypoetry/artifacts/5e/59/0d/9ce4b54813b37237c51d31bb0d3c0853123334f6309a2088f81ec49c03/boto3-1.17.109-py2.py3-none-any.whl\r\nbotocore @ file:///Users/amit/Library/Caches/pypoetry/artifacts/34/8e/85/14e136ebe48249de4155082aa1b2aa772ec3f7d415dd1c60067ed3a2ad/botocore-1.20.109-py2.py3-none-any.whl\r\ncachetools @ file:///Users/amit/Library/Caches/pypoetry/artifacts/04/ca/d7/8af05dc8ccae1212d4151afd99960369c2415b26bc13ed3bbb288c4f5a/cachetools-4.2.2-py3-none-any.whl\r\ncatalogue @ file:///Users/amit/Library/Caches/pypoetry/artifacts/af/cf/ab/153c9326701d6adc746e129e3e05991a55bd43b2f19e3c52d7ccc9a7b4/catalogue-1.0.0-py2.py3-none-any.whl\r\ncertifi @ file:///Users/amit/Library/Caches/pypoetry/artifacts/cd/2c/dc/e5bfda594e18f3f1e9af9f11e13581014d821425f325f3220b3ed2c337/certifi-2021.5.30-py2.py3-none-any.whl\r\ncffi @ file:///Users/amit/Library/Caches/pypoetry/artifacts/6e/aa/04/2c3c9401654c8f5580dc8965817a99e8ad464a0987e17149061aadfcbf/cffi-1.14.6-cp39-cp39-macosx_10_9_x86_64.whl\r\ncfgv @ file:///Users/amit/Library/Caches/pypoetry/artifacts/6b/52/b7/27617ac43f25c9962779813593809288745c414fd878b968cc3d91ca6c/cfgv-3.3.0-py2.py3-none-any.whl\r\nchardet @ file:///Users/amit/Library/Caches/pypoetry/artifacts/11/63/f9/797eda27963177a6b75a340f62aa194d462ea69e6b0dbb77a651fa2b62/chardet-4.0.0-py2.py3-none-any.whl\r\nchecklist @ file:///Users/amit/Library/Caches/pypoetry/artifacts/04/84/f3/1324eec13577715f52121b3073ab37792c08483aae7faa7d22b7dd5e1d/checklist-0.0.11.tar.gz\r\ncheroot @ file:///Users/amit/Library/Caches/pypoetry/artifacts/3c/cf/87/c9bb0e3b0d4c43affeb8f9714d5791b61c97750bc3a2ee35d276d425b5/cheroot-8.5.2-py2.py3-none-any.whl\r\nCherryPy @ file:///Users/amit/Library/Caches/pypoetry/artifacts/dd/d5/0c/5289a45f52e9aa001f7b8c2b9c792377e79ad572bc759f1a692d160818/CherryPy-18.6.1-py2.py3-none-any.whl\r\nclick @ file:///Users/amit/Library/Caches/pypoetry/artifacts/ae/32/83/e159324c1bd58177322f4e45f598d500fe22544bff20f53f55cf749da8/click-8.0.1-py3-none-any.whl\r\ncolorama @ file:///Users/amit/Library/Caches/pypoetry/artifacts/9e/b3/11/7d87ac44fdb2d557301f1f4086a37c080d1482a98751abe7cdbabbad26/colorama-0.4.4-py2.py3-none-any.whl\r\ncommonmark @ file:///Users/amit/Library/Caches/pypoetry/artifacts/11/56/f6/d054064b623fab5c7e4420f60d931f49fea2dacdebe1dc991201010c84/commonmark-0.9.1-py2.py3-none-any.whl\r\nconfigparser @ file:///Users/amit/Library/Caches/pypoetry/artifacts/4e/17/fd/30c9e84dc4b951f3587a4d5eb2894e20105120991793ff3e9f3a60d787/configparser-5.0.2-py3-none-any.whl\r\nconllu @ file:///Users/amit/Library/Caches/pypoetry/artifacts/a9/0b/c7/419ecfd4c8064217550121b01eb4c617ebb82d54c06c775a2d683abbe4/conllu-4.4-py2.py3-none-any.whl\r\ncryptography @ file:///Users/amit/Library/Caches/pypoetry/artifacts/c7/6d/36/40b404429242377c0424cb9957a04887a4be7399a62c1505197845c09f/cryptography-3.4.7-cp36-abi3-macosx_10_10_x86_64.whl\r\ncymem @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b8/f4/20/752f31c5ea9976672f58722949ff87b94832958712b6e3ba60e831421e/cymem-2.0.5-cp39-cp39-macosx_10_9_x86_64.whl\r\ndarglint @ file:///Users/amit/Library/Caches/pypoetry/artifacts/bb/64/25/6fa28703f05a524eef407d4425af6290f242eb131574704386e677624b/darglint-1.8.0-py3-none-any.whl\r\ndecorator @ file:///Users/amit/Library/Caches/pypoetry/artifacts/99/d8/37/35167f3a4175b089109325a5ee11846ac4de416442972573b87351396d/decorator-5.0.9-py3-none-any.whl\r\ndefusedxml @ file:///Users/amit/Library/Caches/pypoetry/artifacts/2b/69/07/7b13f7eaf3a4d7af737dcebe24d3d17b1c2a2f457fbddf746f5642bc43/defusedxml-0.7.1-py2.py3-none-any.whl\r\ndill @ file:///Users/amit/Library/Caches/pypoetry/artifacts/26/56/9e/73963d2285e6c700801f185e8c1d28f1f971c09aaa411cec9b799a5fca/dill-0.3.4-py2.py3-none-any.whl\r\ndistlib @ file:///Users/amit/Library/Caches/pypoetry/artifacts/6f/35/97/6a255392aaa7200818a8cd0f4b014ef2e0a086bab49dd568780f367ef5/distlib-0.3.2-py2.py3-none-any.whl\r\ndocker-pycreds @ file:///Users/amit/Library/Caches/pypoetry/artifacts/9b/0b/be/891931da9caf5e55102337a635d3a7eeeb92c93b4bd39c24d0810f1f25/docker_pycreds-0.4.0-py2.py3-none-any.whl\r\ndocutils @ file:///Users/amit/Library/Caches/pypoetry/artifacts/43/28/92/79000933ad30371dc938d9b368a9000e20ac0bb467a716c19ef1fbd3c7/docutils-0.17.1-py2.py3-none-any.whl\r\nentrypoints @ file:///Users/amit/Library/Caches/pypoetry/artifacts/63/c1/af/bbfdd91bcb544e62ac8f1567ef23c243cb188d1a9cb933532999c9bbb0/entrypoints-0.3-py2.py3-none-any.whl\r\neradicate @ file:///Users/amit/Library/Caches/pypoetry/artifacts/12/ce/ac/197035fe6d51568abb7ea160f5ad416d2164a2010005e8356b8229e550/eradicate-2.0.0.tar.gz\r\nfeedparser @ file:///Users/amit/Library/Caches/pypoetry/artifacts/d1/81/87/0f3c1c0b02176b2bf05af85261d8ce7522e4d241e5d9f7b3f0ec4f2a10/feedparser-6.0.8-py3-none-any.whl\r\nfilelock @ file:///Users/amit/Library/Caches/pypoetry/artifacts/7e/c4/97/2cfbeab3cc292d0b4290cb7cab0b969b3002dc24f6dd5944cbe340e684/filelock-3.0.12-py3-none-any.whl\r\nflake8 @ file:///Users/amit/Library/Caches/pypoetry/artifacts/3f/57/d5/11722093c13092cc3bfc3dd7c88aef6f8e4d5ac97cfe5fd054d5aba412/flake8-3.9.2-py2.py3-none-any.whl\r\nflake8-bandit @ file:///Users/amit/Library/Caches/pypoetry/artifacts/7e/e4/46/e15782d941f9cde39b64ca5b636180f47573f2b2c9315be56b55152f17/flake8_bandit-2.1.2.tar.gz\r\nflake8-broken-line @ file:///Users/amit/Library/Caches/pypoetry/artifacts/51/ea/87/37348b281b73d7df44fc46b09c0430e2984e991df11998e2e9bb459fce/flake8_broken_line-0.3.0-py3-none-any.whl\r\nflake8-bugbear @ file:///Users/amit/Library/Caches/pypoetry/artifacts/15/95/75/8c7a4504d7eda1a394c3d14349b88577ff2d98d59941944c95bd8672ba/flake8_bugbear-21.4.3-py36.py37.py38-none-any.whl\r\nflake8-commas @ file:///Users/amit/Library/Caches/pypoetry/artifacts/c3/47/1d/7f7fac0c58b2bd2bf7361bcba0bceba1c81c365cab5e1de352fa7fac68/flake8_commas-2.0.0-py2.py3-none-any.whl\r\nflake8-comprehensions @ file:///Users/amit/Library/Caches/pypoetry/artifacts/4e/10/91/04adae987aa18ee9463db75694dccee7bf7d5518118462f18252bd3e0a/flake8_comprehensions-3.5.0-py3-none-any.whl\r\nflake8-debugger @ file:///Users/amit/Library/Caches/pypoetry/artifacts/66/04/47/7bef98a8d237eb17cbfbcb803343be1c79e2c0674ceba163717b6c8e1b/flake8_debugger-4.0.0-py3-none-any.whl\r\nflake8-docstrings @ file:///Users/amit/Library/Caches/pypoetry/artifacts/e0/85/e9/6b482a11d48cf26e1170d9f5bf0b044a5a6c9b816ffe70945e90fc3e56/flake8_docstrings-1.6.0-py2.py3-none-any.whl\r\nflake8-eradicate @ file:///Users/amit/Library/Caches/pypoetry/artifacts/fc/3d/a0/58427b14b0a6d33587f3d6896e695615272c37c3ff2c89d6155b5155f6/flake8_eradicate-1.1.0-py3-none-any.whl\r\nflake8-isort @ file:///Users/amit/Library/Caches/pypoetry/artifacts/11/37/1c/68fb64c6704b9c2468f711b83090590abc2c8295eeafbac9a167f32e0a/flake8_isort-4.0.0-py2.py3-none-any.whl\r\nflake8-polyfill @ file:///Users/amit/Library/Caches/pypoetry/artifacts/28/17/cc/952c11cd5ffb2608137557f928dc4f9365b4dbe1e2a6015eeea78583ac/flake8_polyfill-1.0.2-py2.py3-none-any.whl\r\nflake8-quotes @ file:///Users/amit/Library/Caches/pypoetry/artifacts/75/61/73/b33ec4139bc79d01b0748fb1ae5889fbd6bd544c6f35521fb4dd981b1a/flake8-quotes-3.2.0.tar.gz\r\nflake8-rst-docstrings @ file:///Users/amit/Library/Caches/pypoetry/artifacts/69/c4/19/62afcee08756b2cc746fb4d585d02dd819556e0b0d30a6cc7acb6a101a/flake8_rst_docstrings-0.2.3-py3-none-any.whl\r\nflake8-string-format @ file:///Users/amit/Library/Caches/pypoetry/artifacts/24/89/bb/7ce8e216f8c7289aa8a2ad4c44f30f87af6c7cdaf5d510110d566d66ec/flake8_string_format-0.3.0-py2.py3-none-any.whl\r\nftfy @ file:///Users/amit/Library/Caches/pypoetry/artifacts/da/3c/cd/9230817d48f70d575b300d027e9d3845ffe7dec691cfeca5959d022536/ftfy-6.0.3.tar.gz\r\nfuture @ file:///Users/amit/Library/Caches/pypoetry/artifacts/f8/58/55/86be1f567b212fdd98854d12815964a49db8fb1bcff725018e5f95c61d/future-0.18.2.tar.gz\r\ngitdb @ file:///Users/amit/Library/Caches/pypoetry/artifacts/82/af/0d/fc5992ac7ef8a227e6b9705aa6de550211814dd0318b857530d3306d02/gitdb-4.0.7-py3-none-any.whl\r\nGitPython @ file:///Users/amit/Library/Caches/pypoetry/artifacts/89/d2/fc/aacfc97469f68f6b2da4db532a2e04ba3ba94e09728e3ea6d4444e0dd2/GitPython-3.1.18-py3-none-any.whl\r\ngoogle-api-core @ file:///Users/amit/Library/Caches/pypoetry/artifacts/5e/fa/f1/f104f6d061efd1ddb611c0cb4fcc9252c5e15459515b8991136cdf8886/google_api_core-1.31.0-py2.py3-none-any.whl\r\ngoogle-auth @ file:///Users/amit/Library/Caches/pypoetry/artifacts/c7/96/64/403c53d4b77d3b92517777391e7598970fd56386f0bc6098f99801e59f/google_auth-1.32.1-py2.py3-none-any.whl\r\ngoogle-cloud-core @ file:///Users/amit/Library/Caches/pypoetry/artifacts/ed/24/7b/fd351e28e6811f5ef5718d536c84e43df631d72487e2870d11a840b8b2/google_cloud_core-1.7.1-py2.py3-none-any.whl\r\ngoogle-cloud-storage @ file:///Users/amit/Library/Caches/pypoetry/artifacts/52/25/b2/b8d3db4a638b27dd17a77802f8eae114ac39325db23cd0f7c58781e35a/google_cloud_storage-1.38.0-py2.py3-none-any.whl\r\ngoogle-crc32c @ file:///Users/amit/Library/Caches/pypoetry/artifacts/ac/6b/f2/c976910125e4a02d8b127cb4138fc9ac6167c7c971a76bc1bde216ee7b/google_crc32c-1.1.2-cp39-cp39-macosx_10_14_x86_64.whl\r\ngoogle-resumable-media @ file:///Users/amit/Library/Caches/pypoetry/artifacts/7d/de/88/a84ae5cef0a9895612e0c4db686aab010ff824edd1aeceb3906c3cd7e0/google_resumable_media-1.3.1-py2.py3-none-any.whl\r\ngoogleapis-common-protos @ file:///Users/amit/Library/Caches/pypoetry/artifacts/8d/40/1f/21e71977c3d547b27842caaafc2e420c9a6dd40a745cce4b61673e3be3/googleapis_common_protos-1.53.0-py2.py3-none-any.whl\r\nh5py @ file:///Users/amit/Library/Caches/pypoetry/artifacts/21/20/f5/670da7f96cdc48c98aad052bf28c0efc57bf865ff1f9b2c50ae8d6b2a3/h5py-3.3.0-cp39-cp39-macosx_10_9_x86_64.whl\r\nhuggingface-hub @ file:///Users/amit/Library/Caches/pypoetry/artifacts/40/86/15/ea367547cd99a3a52f226c2b2b7fd5d28b0b7c0e1323eee2909b46cc31/huggingface_hub-0.0.13-py3-none-any.whl\r\nhypothesis @ file:///Users/amit/Library/Caches/pypoetry/artifacts/62/44/a7/47fd46593add79f575e8418b9aac6d209749e120cdd07fbf309533c548/hypothesis-6.14.1-py3-none-any.whl\r\nidentify @ file:///Users/amit/Library/Caches/pypoetry/artifacts/88/59/31/ca587f87a94f22f5d7f086dd53b95373139c023f75974e9293131680b7/identify-2.2.11-py2.py3-none-any.whl\r\nidna @ file:///Users/amit/Library/Caches/pypoetry/artifacts/ef/7f/a9/19cc0b8760bdf6f696290c06532496f8bb29fbdaad044f852fed00ec82/idna-2.10-py2.py3-none-any.whl\r\niniconfig @ file:///Users/amit/Library/Caches/pypoetry/artifacts/fa/b0/c6/10cfac68c9e6de9d2a1678366ca89fd9292b362c1760dbe758e41691cb/iniconfig-1.1.1-py2.py3-none-any.whl\r\nipykernel @ file:///Users/amit/Library/Caches/pypoetry/artifacts/30/98/d5/b01a5306b6404f2c2862d298a4f8649f5c2579c0f5973f59838fe3fc2b/ipykernel-5.5.5-py3-none-any.whl\r\nipython @ file:///Users/amit/Library/Caches/pypoetry/artifacts/1e/56/a1/122ee0fd1f99ee5a3e81bfe0366288a488583ed0be289fb244e1663376/ipython-7.25.0-py3-none-any.whl\r\nipython-genutils @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b4/31/01/6f96480580d1674cab0b5e26dc9fca7bbdf7a2fd5811a7807a92436268/ipython_genutils-0.2.0-py2.py3-none-any.whl\r\nipywidgets @ file:///Users/amit/Library/Caches/pypoetry/artifacts/75/67/72/e14b677150e119dacbd4bf8559095cb47df20ea3c6ecc37bac97964b4a/ipywidgets-7.6.3-py2.py3-none-any.whl\r\niso-639 @ file:///Users/amit/Library/Caches/pypoetry/artifacts/f0/a6/d6/17ede193e09cf4ac45d787cbef2e1c78ff7dff5a58775728212204bbd0/iso-639-0.4.5.tar.gz\r\nisort @ file:///Users/amit/Library/Caches/pypoetry/artifacts/e8/65/0b/2aee1c8017c733cd6111eb34137491a1456d443396b6d283fba8e0d4a3/isort-5.9.2-py3-none-any.whl\r\njaraco.classes @ file:///Users/amit/Library/Caches/pypoetry/artifacts/d0/3c/d2/f157bfb781b294c3d68a29e898ab39327bc2397eea1b42cf8afdfda14b/jaraco.classes-3.2.1-py3-none-any.whl\r\njaraco.collections @ file:///Users/amit/Library/Caches/pypoetry/artifacts/7d/46/b7/579da18cb7f7d7a7d7cd19be8b2d5f5cf3449b1a019c7ec307333b2346/jaraco.collections-3.3.0-py3-none-any.whl\r\njaraco.functools @ file:///Users/amit/Library/Caches/pypoetry/artifacts/4e/9d/9f/96376949fa50b18fc96d90f93d24360b467689922c512daa6beee4d08b/jaraco.functools-3.3.0-py3-none-any.whl\r\njaraco.text @ file:///Users/amit/Library/Caches/pypoetry/artifacts/d8/d0/b6/f9d37687fabea73a57ffc167a243a09255bc57413476984bab40bd0984/jaraco.text-3.5.0-py3-none-any.whl\r\njedi @ file:///Users/amit/Library/Caches/pypoetry/artifacts/2a/5b/d6/62e1f4e7b392c3e7f8258bbe3159dff695814a46e65547cd547ca0fedb/jedi-0.18.0-py2.py3-none-any.whl\r\nJinja2 @ file:///Users/amit/Library/Caches/pypoetry/artifacts/21/2e/46/0a76ea6f6a15e594c9828a85a781f1cee8ed5a1b77e361305645f9e1f4/Jinja2-3.0.1-py3-none-any.whl\r\njmespath @ file:///Users/amit/Library/Caches/pypoetry/artifacts/2c/f0/52/b0ba93d941bd49c8719dee7ca27d2096bf96e17948667388c3ee2ac8f8/jmespath-0.10.0-py2.py3-none-any.whl\r\njoblib @ file:///Users/amit/Library/Caches/pypoetry/artifacts/28/41/26/7ed6532cff9d56b8d2878f93bc289c075f338c12aa7d630862aae39d45/joblib-1.0.1-py3-none-any.whl\r\njsonnet @ file:///Users/amit/Library/Caches/pypoetry/artifacts/60/4e/2d/acde747a02049d38e6dbda9dc3fbf64f03bf2e14c8e9ad04f07edcc66b/jsonnet-0.17.0.tar.gz\r\njsonschema @ file:///Users/amit/Library/Caches/pypoetry/artifacts/db/1d/66/ad84fa70cc987bd4aad68be808562321cdab3cb03f4d5d7714a0e0571c/jsonschema-3.2.0-py2.py3-none-any.whl\r\njupyter @ file:///Users/amit/Library/Caches/pypoetry/artifacts/bb/e8/12/09df1332820a1126a780ab09cec78d2f50457f79bcd0cb2fbb07b19ef4/jupyter-1.0.0-py2.py3-none-any.whl\r\njupyter-client @ file:///Users/amit/Library/Caches/pypoetry/artifacts/8c/14/4d/593d81015262d7306a1f89c900a11dfb7d2f18ee37f8ef17ba7ab983bf/jupyter_client-6.2.0-py3-none-any.whl\r\njupyter-console @ file:///Users/amit/Library/Caches/pypoetry/artifacts/4b/2f/b8/119f975fb811a5e911beacc7a1bb8f8e1154254fb33204e753131e7aca/jupyter_console-6.4.0-py3-none-any.whl\r\njupyter-core @ file:///Users/amit/Library/Caches/pypoetry/artifacts/91/8f/22/1377f102bb4478eb073c741714348b7cbb6518d221da9c232cfc5242b3/jupyter_core-4.7.1-py3-none-any.whl\r\njupyterlab-pygments @ file:///Users/amit/Library/Caches/pypoetry/artifacts/de/ef/fc/5883436de4b7865f082f7cba0e0e0ff5fbf229fe55d6e7d5431a6080f4/jupyterlab_pygments-0.1.2-py2.py3-none-any.whl\r\njupyterlab-widgets @ file:///Users/amit/Library/Caches/pypoetry/artifacts/26/96/3a/11068104cd5f33e8f5437f04e75fb2220aa927c47ae5f01a7477acc169/jupyterlab_widgets-1.0.0-py3-none-any.whl\r\nlmdb @ file:///Users/amit/Library/Caches/pypoetry/artifacts/fd/60/fa/5d8bc278b7132dd8c6a50b32b0b4076f31080cee889a3e59167a93af64/lmdb-1.2.1-cp39-cp39-macosx_10_14_x86_64.whl\r\nlxml @ file:///Users/amit/Library/Caches/pypoetry/artifacts/9e/44/6a/570737853888f173f84e160c5772c792bfd10ea0385a76c138c94b23fc/lxml-4.6.3-cp39-cp39-macosx_10_9_x86_64.whl\r\nMarkupSafe @ file:///Users/amit/Library/Caches/pypoetry/artifacts/20/e4/29/5b1a93d4ee8437f01551437cffbb57ba6744c59796443ca99051473f75/MarkupSafe-2.0.1-cp39-cp39-macosx_10_9_x86_64.whl\r\nmatplotlib-inline @ file:///Users/amit/Library/Caches/pypoetry/artifacts/d8/4c/e1/8b0adf0d076721db928e74aaaf5cf1d73cec52ea2a27ebabe3e9be8957/matplotlib_inline-0.1.2-py3-none-any.whl\r\nmccabe @ file:///Users/amit/Library/Caches/pypoetry/artifacts/96/5e/5f/21ae5296697ca7f94de4da6e21d4936d74029c352a35202e4c339a4253/mccabe-0.6.1-py2.py3-none-any.whl\r\nmistune @ file:///Users/amit/Library/Caches/pypoetry/artifacts/33/31/4c/2d69dc65d06d1c8f8b00b8e995e24bae97fce2e1f8ec5d8d2d98e852da/mistune-0.8.4-py2.py3-none-any.whl\r\nmore-itertools @ file:///Users/amit/Library/Caches/pypoetry/artifacts/47/d4/7d/526affa62eb0c76eec19004cbbf18cc4e55f51c665e92b88bb2ed25752/more_itertools-8.8.0-py3-none-any.whl\r\nmunch @ file:///Users/amit/Library/Caches/pypoetry/artifacts/c3/f9/98/c46b861b1fe10f4d4fecd0ed8752a968be33d2c7e698b70589015aa0b2/munch-2.5.0-py2.py3-none-any.whl\r\nmurmurhash @ file:///Users/amit/Library/Caches/pypoetry/artifacts/03/a3/c8/88bb7a1608c5b641c88c47b5b0c9b5377ddbc103ca4574acf4af3f00b4/murmurhash-1.0.5-cp39-cp39-macosx_10_9_x86_64.whl\r\nmypy @ file:///Users/amit/Library/Caches/pypoetry/artifacts/ab/61/06/b62a10ea75c111856b223b2921035d273fd3d746110fde9ff4bb20fc0c/mypy-0.901-cp39-cp39-macosx_10_9_x86_64.whl\r\nmypy-extensions @ file:///Users/amit/Library/Caches/pypoetry/artifacts/92/45/bf/1807ce854ff668d92602207a37bfa9316def2a3f257bd03c4c5be4bc9b/mypy_extensions-0.4.3-py2.py3-none-any.whl\r\nnbclient @ file:///Users/amit/Library/Caches/pypoetry/artifacts/cd/06/72/d0468da165d742240bf6e43191ef3a942576956bf30426df2cba0ac668/nbclient-0.5.3-py3-none-any.whl\r\nnbconvert @ file:///Users/amit/Library/Caches/pypoetry/artifacts/cd/57/5f/0aebcf8edff99a9ea65795c24b549346cdb70b238cf2c200de0bf86f0f/nbconvert-6.1.0-py3-none-any.whl\r\nnbformat @ file:///Users/amit/Library/Caches/pypoetry/artifacts/36/a7/e7/e1a0c1c54f6151e23afd51bc71e3f6e0b24a96dd1e693b92dd9a4e4ab3/nbformat-5.1.3-py3-none-any.whl\r\nnest-asyncio @ file:///Users/amit/Library/Caches/pypoetry/artifacts/51/1a/ee/4f904dc67e6f59f0c8b75ef59d0111e4fb57dd4a884ad19d289ab31a77/nest_asyncio-1.5.1-py3-none-any.whl\r\nnltk @ file:///Users/amit/Library/Caches/pypoetry/artifacts/18/6d/ee/ffa73af7527056102cff0b73ffa10fc5a7ffa898f9214d546e6ec70b57/nltk-3.6.2-py3-none-any.whl\r\nnodeenv @ file:///Users/amit/Library/Caches/pypoetry/artifacts/54/f0/a1/53d1e469f8e160bad013c23411375fd63d4ea70cda0fc649fcb244ca7e/nodeenv-1.6.0-py2.py3-none-any.whl\r\nnotebook @ file:///Users/amit/Library/Caches/pypoetry/artifacts/8a/53/13/86803f6ca277cd2b45ce841ae8843ab6eb51d45b1d3a8fe96eb2382a07/notebook-6.4.0-py3-none-any.whl\r\nnumpy @ file:///Users/amit/Library/Caches/pypoetry/artifacts/d6/2b/b1/16975744b34a9b3ec7bd901b286178933b525ca493a93edd7441d3b807/numpy-1.21.0-cp39-cp39-macosx_10_9_x86_64.whl\r\norjson @ file:///Users/amit/Library/Caches/pypoetry/artifacts/c8/c9/04/a1cc49302292dbbe34795ed7d5a881c50cf02f4f813f336f7493949870/orjson-3.6.0-cp39-cp39-macosx_10_9_x86_64.macosx_11_0_arm64.macosx_10_9_universal2.whl\r\noverrides @ file:///Users/amit/Library/Caches/pypoetry/artifacts/24/45/16/62e842b5cdff34f5106ee676232cbcc7d7a1333e4900d111bca737b13a/overrides-3.1.0.tar.gz\r\npackaging @ file:///Users/amit/Library/Caches/pypoetry/artifacts/f9/4f/09/c91a145b26102e014fd6e33bd8c7b87306c8e1d4a771158f34dd13210e/packaging-21.0-py3-none-any.whl\r\npandocfilters @ file:///Users/amit/Library/Caches/pypoetry/artifacts/2b/8b/2b/6cd1e4385f3f7f98a25f05764a4ea3f2f20d1db00612ef79e25bb90fe9/pandocfilters-1.4.3.tar.gz\r\nparso @ file:///Users/amit/Library/Caches/pypoetry/artifacts/36/cd/ab/a8c3a5df337bc6f34a10f3f385417b62cdfebe2873ac2fec38206af0db/parso-0.8.2-py2.py3-none-any.whl\r\npastel @ file:///Users/amit/Library/Caches/pypoetry/artifacts/da/84/f3/3e4d8b15eabeba62960ed9d3ccc1e30b7ae5f1b93e6c28d291c67eaf93/pastel-0.2.1-py2.py3-none-any.whl\r\npathspec @ file:///Users/amit/Library/Caches/pypoetry/artifacts/40/8b/b2/80a6945971d8475bcc04d09afec4845855dd74f68da6a4c18bbf8f7784/pathspec-0.8.1-py2.py3-none-any.whl\r\npathtools @ file:///Users/amit/Library/Caches/pypoetry/artifacts/ce/ff/c7/31da76336d55d51d979a50868616c867c7b2ea6f2d2084b8c744726ae7/pathtools-0.1.2.tar.gz\r\npatternfork-nosql @ file:///Users/amit/Library/Caches/pypoetry/artifacts/fa/53/d7/a04c2b1cd20312460da3f82ca634ac259fc581089956ed73763c0757cc/patternfork_nosql-3.6.tar.gz\r\npbr @ file:///Users/amit/Library/Caches/pypoetry/artifacts/c7/6a/db/482c805b950fd5a0ece81e7a9a063cb1aa99169ca73fba511759c9db30/pbr-5.6.0-py2.py3-none-any.whl\r\npdfminer.six @ file:///Users/amit/Library/Caches/pypoetry/artifacts/21/c6/47/9aded02cbdd666be599af42cbfc0c6cf4ad847f177acf882ee11ff2f19/pdfminer.six-20201018-py3-none-any.whl\r\npep8-naming @ file:///Users/amit/Library/Caches/pypoetry/artifacts/a4/93/c7/a3b9b8b4aef682b4caa67015d897aff3d064860a460124ad8a23b6f45f/pep8_naming-0.11.1-py2.py3-none-any.whl\r\npexpect @ file:///Users/amit/Library/Caches/pypoetry/artifacts/5c/c2/43/b54fe59cab7e831df35401c8e6840162bf4a2ae5862604e7bc22db3000/pexpect-4.8.0-py2.py3-none-any.whl\r\npickleshare @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b5/48/a1/d2b823337003d531d87cf0d503ef28bb579703a74d14ad24a88863d616/pickleshare-0.7.5-py2.py3-none-any.whl\r\nPillow @ file:///Users/amit/Library/Caches/pypoetry/artifacts/d7/25/9f/10bf1b0f46db0f11f87fcf319db8e4a8d0acd2326569efb025a0b8b7aa/Pillow-8.3.1-cp39-cp39-macosx_10_10_x86_64.whl\r\nplac @ file:///Users/amit/Library/Caches/pypoetry/artifacts/a5/cb/88/6e55cfacecccbab7d6a03f0d05004c5a39c03a39265423788255714111/plac-1.1.3-py2.py3-none-any.whl\r\npluggy @ file:///Users/amit/Library/Caches/pypoetry/artifacts/29/58/fc/ed8b7451d3ef91a6465024f5656141da996e7aafd4d41a1659629a75e7/pluggy-0.13.1-py2.py3-none-any.whl\r\npoethepoet @ file:///Users/amit/Library/Caches/pypoetry/artifacts/36/42/75/cc7c77f4b9ac69fd8470c7524490be4f0c722f6f7b98d14da11fc2774e/poethepoet-0.10.0-py3-none-any.whl\r\npokerface==0.1.0\r\nportend @ file:///Users/amit/Library/Caches/pypoetry/artifacts/9e/0a/b1/aab32a1b4dbdac42ada198c9c4378651e9a6fba9698662d1e1838a7100/portend-2.7.1-py3-none-any.whl\r\npre-commit @ file:///Users/amit/Library/Caches/pypoetry/artifacts/7b/f6/8d/c5425b5811fbbbe85e82cc7980de882a7b239984e2338412a964d62d8f/pre_commit-2.13.0-py2.py3-none-any.whl\r\npreshed @ file:///Users/amit/Library/Caches/pypoetry/artifacts/f9/3c/c4/47684f5aebfe9d8a986343a71cbbdef4bcbc7494eb8d08857621978f33/preshed-3.0.5-cp39-cp39-macosx_10_9_x86_64.whl\r\nprometheus-client @ file:///Users/amit/Library/Caches/pypoetry/artifacts/ce/fa/c7/255d5bc58b6e1a7cc1e9d4eb3c5a993bea6af1aa016b5008147ab8beb7/prometheus_client-0.11.0-py2.py3-none-any.whl\r\npromise @ file:///Users/amit/Library/Caches/pypoetry/artifacts/d6/c6/43/95f1e737b1dd79d3a5ac6cfb264a889716bab4cd9d28a9bc8c69591d53/promise-2.3.tar.gz\r\nprompt-toolkit @ file:///Users/amit/Library/Caches/pypoetry/artifacts/c0/cc/91/2b2506bf1a53afc81d06682da5dce00b5f700a51ee2a8452dc8b98af15/prompt_toolkit-3.0.19-py3-none-any.whl\r\nprotobuf @ file:///Users/amit/Library/Caches/pypoetry/artifacts/88/20/9e/47da88de518b7b11435b39354a7b9a334acfae01916f4aee875b908765/protobuf-3.17.3-cp39-cp39-macosx_10_9_x86_64.whl\r\npsutil @ file:///Users/amit/Library/Caches/pypoetry/artifacts/c5/45/be/f328230784273b5b602263092a0788e3055d7fa032dc1dcb0b1583bcb9/psutil-5.8.0-cp39-cp39-macosx_10_9_x86_64.whl\r\nptyprocess @ file:///Users/amit/Library/Caches/pypoetry/artifacts/2a/29/5d/0cdc5ec916431d60f03d2f725c54edbfa9fe53700b75fdfee209a3291e/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npy @ file:///Users/amit/Library/Caches/pypoetry/artifacts/60/79/0b/c48bd9c2a989aa8b1eb7a67cd02b053c10734f2e4e5665f7995f09999c/py-1.10.0-py2.py3-none-any.whl\r\npy-rouge @ file:///Users/amit/Library/Caches/pypoetry/artifacts/31/31/4f/cc7585fdf5aec32c5b688726f52c2238f959caba4f6a65950f1a932745/py_rouge-1.1-py3-none-any.whl\r\npy-spy @ file:///Users/amit/Library/Caches/pypoetry/artifacts/23/40/09/d09dd2f0516f0d0e73fe6a8dcfc9aaa5c13ffc2ebe7361b237391b0625/py_spy-0.3.7-py2.py3-none-macosx_10_9_x86_64.whl\r\npyasn1 @ file:///Users/amit/Library/Caches/pypoetry/artifacts/7b/3a/54/42ce43b579bda01b9d79022fb733811594441e7a32e9f9a5a98f672bdc/pyasn1-0.4.8-py2.py3-none-any.whl\r\npyasn1-modules @ file:///Users/amit/Library/Caches/pypoetry/artifacts/dd/b8/4f/b56433e0354274a31074995e01b8671751e9f0ed0001f5254e5b03a54f/pyasn1_modules-0.2.8-py2.py3-none-any.whl\r\npycodestyle @ file:///Users/amit/Library/Caches/pypoetry/artifacts/4c/30/97/026c283ef67eb248e5b7e6fad1f8ffb99dae50c11fd93eb939fd7c1f46/pycodestyle-2.7.0-py2.py3-none-any.whl\r\npycparser @ file:///Users/amit/Library/Caches/pypoetry/artifacts/37/8e/5a/0ea4f84bc7f11e0e3468110efa2c7783241ea7eaa63a92a751de06f78f/pycparser-2.20-py2.py3-none-any.whl\r\npydantic @ file:///Users/amit/Library/Caches/pypoetry/artifacts/96/6b/c5/3defa89e523826db389eb2be9b0b808835134ab64c68e8193da2ac7d51/pydantic-1.8.2-cp39-cp39-macosx_10_9_x86_64.whl\r\npydocstyle @ file:///Users/amit/Library/Caches/pypoetry/artifacts/75/e7/e5/1acad15a51efd39cf39259c7888c205fd787a92efea28f7afc5a9e315c/pydocstyle-6.1.1-py3-none-any.whl\r\npyflakes @ file:///Users/amit/Library/Caches/pypoetry/artifacts/eb/c4/2c/47fcc1b3f387b1f7033e85b3ac6ee7772338461a8de8ac3977c6a7dcc1/pyflakes-2.3.1-py2.py3-none-any.whl\r\nPygments @ file:///Users/amit/Library/Caches/pypoetry/artifacts/d1/62/9b/10957d050758a3da079375961ec00a6c83b71a90eefd0199361d9d54de/Pygments-2.9.0-py3-none-any.whl\r\nPyment @ file:///Users/amit/Library/Caches/pypoetry/artifacts/e0/cc/65/a915b66c524613d67c0dfcd3b9e99a2916908d106a16a5909520b29036/Pyment-0.3.3-py2.py3-none-any.whl\r\npyparsing @ file:///Users/amit/Library/Caches/pypoetry/artifacts/92/0f/cf/effdcd5d76a6186df0969f85b3b030284ff8058936d5016540b5258ea3/pyparsing-2.4.7-py2.py3-none-any.whl\r\npyrsistent @ file:///Users/amit/Library/Caches/pypoetry/artifacts/a3/50/5c/55747fd13209ee597a3e45d1ad70eef133559516e470c05a47c29365b0/pyrsistent-0.18.0-cp39-cp39-macosx_10_9_x86_64.whl\r\npytest @ file:///Users/amit/Library/Caches/pypoetry/artifacts/17/a3/46/eb89acf91c8962553e409da649186ff5e3d2c1c93195f0643e7dfd1b57/pytest-6.2.4-py3-none-any.whl\r\npython-dateutil @ file:///Users/amit/Library/Caches/pypoetry/artifacts/93/67/cf/49f56d9e954addcfc50e5ffc9faee013c2eb00c6d77d56c6a22cb33b54/python_dateutil-2.8.1-py2.py3-none-any.whl\r\npython-docx @ file:///Users/amit/Library/Caches/pypoetry/artifacts/7f/3f/b0/ca05b61dd6a8beb8bc8317700154416271ddda4db5425c92e9d780cba7/python-docx-0.8.11.tar.gz\r\npython-dotenv @ file:///Users/amit/Library/Caches/pypoetry/artifacts/a6/61/71/a8300bb6be27750f8810f5d2a0c070e220ebc1a416f0837d4bbc283391/python_dotenv-0.17.1-py2.py3-none-any.whl\r\npytz @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b0/a7/8d/54de3ab4d1ff29abbbca1e9ccbaefdc2a1b290138311b84f73bee16de1/pytz-2021.1-py2.py3-none-any.whl\r\nPyYAML @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b6/55/22/537845ea953a4d8d5006f11bdd1b03824425d7f809d5a7ae8efbbeab95/PyYAML-5.4.1-cp39-cp39-macosx_10_9_x86_64.whl\r\npyzmq @ file:///Users/amit/Library/Caches/pypoetry/artifacts/0f/06/79/957f3cfec70cf4f952ea59dd7a62281c8687323814b532588d3690e2ec/pyzmq-22.1.0-cp39-cp39-macosx_10_15_universal2.whl\r\nqtconsole @ file:///Users/amit/Library/Caches/pypoetry/artifacts/88/04/9d/bfea17c2892fc9d54fe273876b3c28dc50389a75af0a43c4e5db123bbd/qtconsole-5.1.1-py3-none-any.whl\r\nQtPy @ file:///Users/amit/Library/Caches/pypoetry/artifacts/7b/28/5f/a53ed26195df09abacb0aa3383076185f0496f7dc9f7b496180c7316a1/QtPy-1.9.0-py2.py3-none-any.whl\r\nregex @ file:///Users/amit/Library/Caches/pypoetry/artifacts/0a/f5/b9/ac8ceed381bfa6deb8be166808f27353d5565085d6b762baac40befdff/regex-2021.7.6-cp39-cp39-macosx_10_9_x86_64.whl\r\nrequests @ file:///Users/amit/Library/Caches/pypoetry/artifacts/22/0a/9d/0df883fbffbb406d0cddbb35e881e4ac6bfb8f0dee8733056b6a054bf7/requests-2.25.1-py2.py3-none-any.whl\r\nrestructuredtext-lint @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b6/09/80/91d176f17ba9a28291203e41600b294aa26214e185082bcb0cc3543588/restructuredtext_lint-1.3.2.tar.gz\r\nrich @ file:///Users/amit/Library/Caches/pypoetry/artifacts/d8/09/d1/c1e297bde3276fe5289c3fc9cf6804eb531e28372b527f854b1427b012/rich-10.5.0-py3-none-any.whl\r\nrsa @ file:///Users/amit/Library/Caches/pypoetry/artifacts/27/21/1f/fea99b1c1766c11c2c47dd961d7773ebab5c6acbf730200bd2e021b836/rsa-4.7.2-py3-none-any.whl\r\ns3transfer @ file:///Users/amit/Library/Caches/pypoetry/artifacts/8f/96/42/4ec7dc1795d747cb348df8b6aad3b471251863f3eab457ce33668cf8a1/s3transfer-0.4.2-py2.py3-none-any.whl\r\nsacremoses @ file:///Users/amit/Library/Caches/pypoetry/artifacts/96/d8/48/cdb78bf884395d731e5af8316b4de4517cd3b3b2b7bd28ede180216c83/sacremoses-0.0.45-py3-none-any.whl\r\nscikit-learn @ file:///Users/amit/Library/Caches/pypoetry/artifacts/04/83/07/6b7befd90140a96d92542597559789a8e6f99ebcd86366336d38472ea6/scikit_learn-0.24.2-cp39-cp39-macosx_10_13_x86_64.whl\r\nscipy @ file:///Users/amit/Library/Caches/pypoetry/artifacts/d1/03/cb/ba3c405831dab5ed08abcc721f597e4374beb9ac88f9b0a426d101b02b/scipy-1.6.1-cp39-cp39-macosx_10_9_x86_64.whl\r\nSend2Trash @ file:///Users/amit/Library/Caches/pypoetry/artifacts/44/b5/57/aae8fa9005db0161e198bc50572d47f162988a2e2f3434bd4d8e6f78a0/Send2Trash-1.7.1-py3-none-any.whl\r\nsentencepiece @ file:///Users/amit/Library/Caches/pypoetry/artifacts/0c/cd/fe/92b552fb5511ad2ab9906a6b85474f6a7b6312629fe9524f11bff2933d/sentencepiece-0.1.96-cp39-cp39-macosx_10_6_x86_64.whl\r\nsentry-sdk @ file:///Users/amit/Library/Caches/pypoetry/artifacts/29/89/c1/911ea3ca1b49d945fd159b841827b63a00f57c439d6c0c26cb7aca5f7c/sentry_sdk-1.3.0-py2.py3-none-any.whl\r\nsgmllib3k @ file:///Users/amit/Library/Caches/pypoetry/artifacts/48/41/c1/47c574e94f31057312eab350c2a7e7b75d1105eb5b673a14efe485c128/sgmllib3k-1.0.0.tar.gz\r\nshortuuid @ file:///Users/amit/Library/Caches/pypoetry/artifacts/80/85/8d/5bdb9fbab8b4fc7bd9599a4982cac0ae2498f4c863d13869d4e1e7b722/shortuuid-1.0.1-py3-none-any.whl\r\nsix @ file:///Users/amit/Library/Caches/pypoetry/artifacts/08/9f/47/c16ae03035fc69eaf100ea39657a49baaeef714e25a52575710c34cd48/six-1.16.0-py2.py3-none-any.whl\r\nsmmap @ file:///Users/amit/Library/Caches/pypoetry/artifacts/fb/95/d9/27c304575d15e0faf1b64e46ec12611c0a683b4d9d6aa459850d5a77df/smmap-4.0.0-py2.py3-none-any.whl\r\nsnowballstemmer @ file:///Users/amit/Library/Caches/pypoetry/artifacts/c7/56/66/7613028d4906686fd240574f9e4ec773d99d60753a515f163d21b44935/snowballstemmer-2.1.0-py2.py3-none-any.whl\r\nsortedcontainers @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b9/80/e1/4bdfa349488797fd308ecbe48f4fad57a3245777fb47c8741730583262/sortedcontainers-2.4.0-py2.py3-none-any.whl\r\nsoupsieve @ file:///Users/amit/Library/Caches/pypoetry/artifacts/20/16/55/4a9893b172bb2a7815f46f6a947ff3506dd241ea679377ffdc0b2c811e/soupsieve-2.2.1-py3-none-any.whl\r\nspacy @ file:///Users/amit/Library/Caches/pypoetry/artifacts/7d/eb/24/0b844c7393780507707bd2faddc484095f21df0f6d0bc69be88d6d7137/spacy-2.3.7-cp39-cp39-macosx_10_9_x86_64.whl\r\nsrsly @ file:///Users/amit/Library/Caches/pypoetry/artifacts/4e/7f/ef/750f5466b050be2d76de8aaf076c3ffcdff5cd0a5af0cf11ef6ebea3c6/srsly-1.0.5-cp39-cp39-macosx_10_9_x86_64.whl\r\nstevedore @ file:///Users/amit/Library/Caches/pypoetry/artifacts/c2/31/a7/c2802b19c1cba9407f4254c97dacd72884d3b27c63bbbb3ada4edbf3a8/stevedore-3.3.0-py3-none-any.whl\r\nsubprocess32 @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b9/91/2e/cc8d3ccbf05fa27ee73859de9d02ef1a7eba84ed701970db1063a1848d/subprocess32-3.5.4.tar.gz\r\ntempora @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b9/f8/26/4304b7c3157148ded2a9f388c0c3e6b1c0016147ff5995928d8db2ce8b/tempora-4.1.1-py3-none-any.whl\r\ntensorboardX @ file:///Users/amit/Library/Caches/pypoetry/artifacts/f6/18/d3/c562b4cfa8f42a7172c29cfea8ded406d87b3e79e6bcc0032dc3eace99/tensorboardX-2.4-py2.py3-none-any.whl\r\ntermcolor @ file:///Users/amit/Library/Caches/pypoetry/artifacts/a2/5d/c7/e4ccb3b3bb8d3e3aff995fb6ffb12cfc78bbc8affa283907ee5eb5a5a5/termcolor-1.1.0.tar.gz\r\nterminado @ file:///Users/amit/Library/Caches/pypoetry/artifacts/ac/6f/f6/464b3b1e95eff0b0b464b918cbcf0b6a2f81b4fda008b8570450a25a7a/terminado-0.10.1-py3-none-any.whl\r\ntestfixtures @ file:///Users/amit/Library/Caches/pypoetry/artifacts/87/49/bd/0bf2640dd53740f9dc21bb1eecb8093631a71ea4703c8ef1a3a7bdd42d/testfixtures-6.17.1-py2.py3-none-any.whl\r\ntestpath @ file:///Users/amit/Library/Caches/pypoetry/artifacts/1e/2d/08/76691a9e7e429930fb378dd96f760de96f2686841c47da2b35a04c5aad/testpath-0.5.0-py3-none-any.whl\r\nthinc @ file:///Users/amit/Library/Caches/pypoetry/artifacts/71/1d/6d/f57a2fc5d6752b008f1583c84234c8909921813d7f863b65fac52afdc4/thinc-7.4.5-cp39-cp39-macosx_10_9_x86_64.whl\r\nthreadpoolctl @ file:///Users/amit/Library/Caches/pypoetry/artifacts/7b/b5/49/550b4953bb841e92404d74b7c7671139fd8bbdcec26c2e89c1843fcb76/threadpoolctl-2.2.0-py3-none-any.whl\r\ntokenizers @ file:///Users/amit/Library/Caches/pypoetry/artifacts/e3/67/87/626827d63f69f9c1357c553076ccf0ee9721c9764ef434fa3654531f3f/tokenizers-0.10.3-cp39-cp39-macosx_10_11_x86_64.whl\r\ntoml @ file:///Users/amit/Library/Caches/pypoetry/artifacts/6b/6a/c9/53b19f7870a77d855e8b05ecdc98193944e5d246dafe11bbcad850ecba/toml-0.10.2-py2.py3-none-any.whl\r\ntomlkit @ file:///Users/amit/Library/Caches/pypoetry/artifacts/fd/06/32/b79e75623225a9b5af79899482b9c2933c2fa2c6fb0eff80fcec10ae48/tomlkit-0.7.2-py2.py3-none-any.whl\r\ntorch @ file:///Users/amit/Library/Caches/pypoetry/artifacts/15/c9/5c/5d6856af4e4b18034b2e50b2cc08ba37035276b823f21dfa97a2e454b5/torch-1.8.1-cp39-none-macosx_10_9_x86_64.whl\r\ntorchvision @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b2/82/34/8438fea281caa4f92140f0bdd1ff59ee8bc2e3e0b35d68bfc3d0d14111/torchvision-0.9.1-cp39-cp39-macosx_10_9_x86_64.whl\r\ntornado @ file:///Users/amit/Library/Caches/pypoetry/artifacts/8a/d4/49/50c44b642217b81c4d63991cb2560ebb78029f8090bd4a23c1c11a4ac0/tornado-6.1-cp39-cp39-macosx_10_9_x86_64.whl\r\ntqdm @ file:///Users/amit/Library/Caches/pypoetry/artifacts/1a/46/38/2897fecc5f3ff99d118d7dd77d749365e163113a712337b2b28837bedd/tqdm-4.61.2-py2.py3-none-any.whl\r\ntraitlets @ file:///Users/amit/Library/Caches/pypoetry/artifacts/f3/6b/36/998ab52c38eb1c4820cdef1e66043ddebb64e04535f88dbfd04486ce03/traitlets-5.0.5-py3-none-any.whl\r\ntransformers @ file:///Users/amit/Library/Caches/pypoetry/artifacts/ae/3e/26/9a99e73cfd7d44463aad270e850034478e6258f45900175d268a0cd976/transformers-4.5.1-py3-none-any.whl\r\ntypes-orjson @ file:///Users/amit/Library/Caches/pypoetry/artifacts/e3/ac/f5/782a3257b6f17101317a753b694ce3dffc227c7eee054f8633cbb18700/types_orjson-0.1.1-py2.py3-none-any.whl\r\ntyping-extensions @ file:///Users/amit/Library/Caches/pypoetry/artifacts/3d/38/26/2c9b521373bbaf207e658ec81f51aa2a8af7454bfe4d7c15743a6533d5/typing_extensions-3.10.0.0-py3-none-any.whl\r\nurllib3 @ file:///Users/amit/Library/Caches/pypoetry/artifacts/d8/4b/3f/9e8027e7f15b2f99244ad505328c3cf87912ad87446c1c8e89efacf731/urllib3-1.25.11-py2.py3-none-any.whl\r\nvirtualenv @ file:///Users/amit/Library/Caches/pypoetry/artifacts/13/ab/72/1f00c98674e32cc5fcae271032c164917dfd53be7c009e119f1cf47f8d/virtualenv-20.4.7-py2.py3-none-any.whl\r\nwandb @ file:///Users/amit/Library/Caches/pypoetry/artifacts/49/f4/c8/324b20beeceb351e72c821219d999d460442c4b4ff903122f29979ab5e/wandb-0.10.33-py2.py3-none-any.whl\r\nwasabi @ file:///Users/amit/Library/Caches/pypoetry/artifacts/d5/9d/af/58d834e926bfc5371fb8208596bdec3d5824083600c5681f98ce0790d7/wasabi-0.8.2-py3-none-any.whl\r\nwcwidth @ file:///Users/amit/Library/Caches/pypoetry/artifacts/7d/f4/60/0737157bb9711fec72c70dff523aa54491eef317e0d586cf5388ff0908/wcwidth-0.2.5-py2.py3-none-any.whl\r\nwebencodings @ file:///Users/amit/Library/Caches/pypoetry/artifacts/ed/d4/da/61384706cfac042ba3bd148746d66e50695463993be117c7c8dadeef7a/webencodings-0.5.1-py2.py3-none-any.whl\r\nwemake-python-styleguide @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b2/30/6d/aff16dd6cc6e7169bd34e8f2e8feff71a3cc593d6ebb617acc9cf7e927/wemake_python_styleguide-0.15.3-py3-none-any.whl\r\nwidgetsnbextension @ file:///Users/amit/Library/Caches/pypoetry/artifacts/eb/b0/c5/e9e106309ddf8d2cbebcd3c9f2c2be8c7c7346f58d8ff7ace4196371d8/widgetsnbextension-3.5.1-py2.py3-none-any.whl\r\nword2number @ file:///Users/amit/Library/Caches/pypoetry/artifacts/91/7b/91/fd4e6b1580eb2a2f0bb8b725ba137628acb0adb21522a3ff9d69e6f5e1/word2number-1.1.zip\r\nzc.lockfile @ file:///Users/amit/Library/Caches/pypoetry/artifacts/b5/a8/c8/e94e98335e585be92e35e5d07dd8a75e5c2e7774c8bd24410160f9cfe0/zc.lockfile-2.0-py2.py3-none-any.whl\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nI wasn't sure how to do this step but I will if I'm not making any sense and you'd like me to. \r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5308/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5308/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5307", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5307/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5307/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5307/events", "html_url": "https://github.com/allenai/allennlp/issues/5307", "id": 940887109, "node_id": "MDU6SXNzdWU5NDA4ODcxMDk=", "number": 5307, "title": "Open IE separates auxiliary and participle into separate tuples", "user": {"login": "artidoro", "id": 11949572, "node_id": "MDQ6VXNlcjExOTQ5NTcy", "avatar_url": "https://avatars.githubusercontent.com/u/11949572?v=4", "gravatar_id": "", "url": "https://api.github.com/users/artidoro", "html_url": "https://github.com/artidoro", "followers_url": "https://api.github.com/users/artidoro/followers", "following_url": "https://api.github.com/users/artidoro/following{/other_user}", "gists_url": "https://api.github.com/users/artidoro/gists{/gist_id}", "starred_url": "https://api.github.com/users/artidoro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/artidoro/subscriptions", "organizations_url": "https://api.github.com/users/artidoro/orgs", "repos_url": "https://api.github.com/users/artidoro/repos", "events_url": "https://api.github.com/users/artidoro/events{/privacy}", "received_events_url": "https://api.github.com/users/artidoro/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-07-09T15:58:44Z", "updated_at": "2021-07-23T16:09:38Z", "closed_at": "2021-07-23T16:09:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>OpenIE separates auxiliary and participle into separate tuples. This affects the online demo and my local installation of AllenNLP.</b></summary>\r\n<p>\r\nIn the sentence \"He is running to the store\", my understanding is that there is only one predicate and that the output of OpenIE should be a single tuple:\r\n[Arg0: He] [V: is running] [Arg1: to the store]\r\n\r\nInstead, I get two tuples where the first is simply the auxiliary:\r\n[V: is]\r\n[Arg0: He] [V: running] [Arg1: to the store]\r\n\r\nYou can see the examples linked below from the online demo to see that it affects other sentences/auxiliaries too. I also noticed the SRL demo returns two predicates for the same sentence.\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\nOnline demo, though I initially noticed this on my local installation of AllenNLP.\r\n\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\nhttps://demo.allennlp.org/open-information-extraction/s/he-has-moved-out-appartment/L1E3P1E9G4\r\nhttps://demo.allennlp.org/open-information-extraction/s/he-is-running-to-store/E5E4Z1H6D9\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5307/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5307/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5285", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5285/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5285/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5285/events", "html_url": "https://github.com/allenai/allennlp/issues/5285", "id": 930361579, "node_id": "MDU6SXNzdWU5MzAzNjE1Nzk=", "number": 5285, "title": "Stale docstring in constructor of `PytorchTransformer`", "user": {"login": "lgessler", "id": 7650725, "node_id": "MDQ6VXNlcjc2NTA3MjU=", "avatar_url": "https://avatars.githubusercontent.com/u/7650725?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lgessler", "html_url": "https://github.com/lgessler", "followers_url": "https://api.github.com/users/lgessler/followers", "following_url": "https://api.github.com/users/lgessler/following{/other_user}", "gists_url": "https://api.github.com/users/lgessler/gists{/gist_id}", "starred_url": "https://api.github.com/users/lgessler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lgessler/subscriptions", "organizations_url": "https://api.github.com/users/lgessler/orgs", "repos_url": "https://api.github.com/users/lgessler/repos", "events_url": "https://api.github.com/users/lgessler/events{/privacy}", "received_events_url": "https://api.github.com/users/lgessler/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-06-25T17:16:02Z", "updated_at": "2021-07-07T01:34:43Z", "closed_at": "2021-07-07T01:34:43Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The docstring of `allennlp.modules.seq2seq_encoders.PytorchTransformer`'s `__init__` describes a [`use_positional_encoding`](https://github.com/allenai/allennlp/blob/main/allennlp/modules/seq2seq_encoders/pytorch_transformer_wrapper.py#L33L37) parameter, when in fact this parameter has since been replaced by two parameters, [`positional_encoding` and `positional_embedding_size`](https://github.com/allenai/allennlp/blob/main/allennlp/modules/seq2seq_encoders/pytorch_transformer_wrapper.py#L48L49), which are not documented in the docstring.\r\n\r\n(BTW sorry to open an issue for this instead of giving a PR, but I don't feel confident I could write a great docstring.)", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5285/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5285/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5260", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5260/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5260/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5260/events", "html_url": "https://github.com/allenai/allennlp/issues/5260", "id": 920930998, "node_id": "MDU6SXNzdWU5MjA5MzA5OTg=", "number": 5260, "title": "I think the implementation of bimpm_mathcing is wrong", "user": {"login": "zhaowei-wang-nlp", "id": 22047467, "node_id": "MDQ6VXNlcjIyMDQ3NDY3", "avatar_url": "https://avatars.githubusercontent.com/u/22047467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhaowei-wang-nlp", "html_url": "https://github.com/zhaowei-wang-nlp", "followers_url": "https://api.github.com/users/zhaowei-wang-nlp/followers", "following_url": "https://api.github.com/users/zhaowei-wang-nlp/following{/other_user}", "gists_url": "https://api.github.com/users/zhaowei-wang-nlp/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhaowei-wang-nlp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhaowei-wang-nlp/subscriptions", "organizations_url": "https://api.github.com/users/zhaowei-wang-nlp/orgs", "repos_url": "https://api.github.com/users/zhaowei-wang-nlp/repos", "events_url": "https://api.github.com/users/zhaowei-wang-nlp/events{/privacy}", "received_events_url": "https://api.github.com/users/zhaowei-wang-nlp/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2021-06-15T02:41:30Z", "updated_at": "2021-07-28T16:13:55Z", "closed_at": "2021-07-28T16:13:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ ] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ ] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nI read the code source code of Bi-MPM model(https://github.com/allenai/allennlp/blob/main/allennlp/modules/bimpm_matching.py) and I found the Attentive-Matching in the code is very different from what is described in the original paper. \r\nFor example,  the 350, 351 lines, softmax is used to the hidden_state dimension(the last dimension). However, to be the same as what is in the paper, I think we just need to devide the weighted sum with the sum of weights.\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5260/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5260/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5254", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5254/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5254/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5254/events", "html_url": "https://github.com/allenai/allennlp/issues/5254", "id": 918328034, "node_id": "MDU6SXNzdWU5MTgzMjgwMzQ=", "number": 5254, "title": "pretrained_transformer_indexer sets token_ids and mask to different lengths", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2021-06-11T07:20:24Z", "updated_at": "2021-06-15T22:42:38Z", "closed_at": "2021-06-13T01:16:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "In `pretrained_transformer_indexer` the method `tokens_to_indices` adds `token_ids`, `mask` and `type_ids` to the output dict.\r\n\r\nhttps://github.com/allenai/allennlp/blob/a6cfb1221520fca7a5cc55bef001c6a79a6a3e2f/allennlp/data/token_indexers/pretrained_transformer_indexer.py#L94\r\n\r\nThis is then passed to `_postprocess_output` which potentially resizes token_ids and type_ids (i.e. # Strips original special tokens), but it returns `segment_concat_mask` instead of `mask`. `mask` is now the same length as `token_ids`.\r\n\r\nAlso note the `_postprocess_output` only executes if _max_length is None. So special tokens only get stripped in this case? And the index sets `self._num_added_start_tokens` and `self._num_added_start_tokens` to 1 regardless of whether the tokenizer has include_special_tokens=true or false.\r\n\r\nThe issue I'm running into, is I'm using a CrfTagger with pretrained_transformer, setting the encoder to pass_through. The pass_through encoder accepts token_ids and mask, which are now misaligned so an exception is thrown.\r\n\r\nIt seems that the only combination which works is to not set `max_length` (in which case `segment_concat_mask` doesn't get added).\r\n\r\nI'm using the json below to construct the tokenizer, token_indexer and model. \r\n\r\n```\r\n{\r\n    \"tokenizer\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": \"/path/to/custom/model\"\r\n    },\r\n    \"token_indexers\": {\r\n        \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": \"/path/to/custom/model\",\r\n        \"max_length\": 128\r\n        }\r\n    }\r\n}\r\n\r\n{\r\n    \"text_field_embedder\":{\r\n        \"token_embedders\":{\r\n            \"tokens\": {\r\n                \"type\":\"pretrained_transformer\",\r\n                \"model_name\":\"path/to/custom/model\",\r\n                \"max_length\":128\r\n            }\r\n        }\r\n    },\r\n    \"encoder\":{\r\n        \"type\":\"pass_through\",\r\n        \"input_dim\":128\r\n    },\r\n    \"label_encoding\":\"BIOUL\",\r\n    \"constrain_crf_decoding\":true,\r\n    \"include_start_end_transitions\":true,\r\n    \"dropout\":0.5,\r\n    \"verbose_metrics\":false,\r\n    \"calculate_span_f1\":true\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5254/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5254/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5244", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5244/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5244/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5244/events", "html_url": "https://github.com/allenai/allennlp/issues/5244", "id": 913655549, "node_id": "MDU6SXNzdWU5MTM2NTU1NDk=", "number": 5244, "title": "[Docs] Link is broken in the Doc of fairness_metrics", "user": {"login": "bhadreshpsavani", "id": 26653468, "node_id": "MDQ6VXNlcjI2NjUzNDY4", "avatar_url": "https://avatars.githubusercontent.com/u/26653468?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bhadreshpsavani", "html_url": "https://github.com/bhadreshpsavani", "followers_url": "https://api.github.com/users/bhadreshpsavani/followers", "following_url": "https://api.github.com/users/bhadreshpsavani/following{/other_user}", "gists_url": "https://api.github.com/users/bhadreshpsavani/gists{/gist_id}", "starred_url": "https://api.github.com/users/bhadreshpsavani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bhadreshpsavani/subscriptions", "organizations_url": "https://api.github.com/users/bhadreshpsavani/orgs", "repos_url": "https://api.github.com/users/bhadreshpsavani/repos", "events_url": "https://api.github.com/users/bhadreshpsavani/events{/privacy}", "received_events_url": "https://api.github.com/users/bhadreshpsavani/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-06-07T15:06:31Z", "updated_at": "2021-06-07T18:02:44Z", "closed_at": "2021-06-07T18:02:44Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Checklist\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n![Screenshot from 2021-06-07 20-32-04](https://user-images.githubusercontent.com/26653468/121040994-fc4d1580-c7cf-11eb-8d8f-69329ad0ca92.png)\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5244/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5244/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5234", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5234/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5234/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5234/events", "html_url": "https://github.com/allenai/allennlp/issues/5234", "id": 907382874, "node_id": "MDU6SXNzdWU5MDczODI4NzQ=", "number": 5234, "title": "Tqdm logging into multiple files with allennlp-optuna", "user": {"login": "MagiaSN", "id": 15558746, "node_id": "MDQ6VXNlcjE1NTU4NzQ2", "avatar_url": "https://avatars.githubusercontent.com/u/15558746?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MagiaSN", "html_url": "https://github.com/MagiaSN", "followers_url": "https://api.github.com/users/MagiaSN/followers", "following_url": "https://api.github.com/users/MagiaSN/following{/other_user}", "gists_url": "https://api.github.com/users/MagiaSN/gists{/gist_id}", "starred_url": "https://api.github.com/users/MagiaSN/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MagiaSN/subscriptions", "organizations_url": "https://api.github.com/users/MagiaSN/orgs", "repos_url": "https://api.github.com/users/MagiaSN/repos", "events_url": "https://api.github.com/users/MagiaSN/events{/privacy}", "received_events_url": "https://api.github.com/users/MagiaSN/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-05-31T11:27:16Z", "updated_at": "2021-06-02T21:44:44Z", "closed_at": "2021-06-02T21:44:44Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nWhen running `allennlp-optuna`, tqdm logs for trial N was written to all log files from trial 1 to trial N-1.\r\n\r\nRunning `train_model` multiple times with different `serialization-dir` without `allennlp-optuna` has the same behavior.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nNone\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: CentOS 7\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.9\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalembic==1.6.5                                                                                                                                                                                                                                       [47/1148]\r\nallennlp==2.4.0\r\nallennlp-models==2.4.0\r\nallennlp-optuna==0.1.6\r\nattrs==21.2.0\r\nblis==0.7.4\r\nboto3==1.17.69\r\nbotocore==1.20.69\r\ncached-property==1.5.2\r\ncatalogue==2.0.4\r\ncertifi==2020.12.5\r\nchardet==4.0.0\r\nclick==7.1.2\r\ncliff==3.8.0\r\ncmaes==0.8.2\r\ncmd2==1.5.0\r\ncolorama==0.4.4\r\ncolorlog==5.0.1\r\nconfigparser==5.0.2\r\nconllu==4.4\r\ncymem==2.0.5\r\ndocker-pycreds==0.4.0\r\nfilelock==3.0.12\r\nftfy==6.0.1\r\ngitdb==4.0.7\r\nGitPython==3.1.15\r\ngreenlet==1.1.0\r\nh5py==3.2.1\r\nhuggingface-hub==0.0.8\r\nidna==2.10\r\nimportlib-metadata==4.0.1\r\niniconfig==1.1.1\r\nJinja2==2.11.3\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonnet==0.17.0\r\nlmdb==1.2.1\r\nMako==1.1.4\r\nMarkupSafe==1.1.1\r\nmore-itertools==8.7.0\r\nmurmurhash==1.0.5\r\nnltk==3.6.2\r\nnumpy==1.20.2\r\noptuna==2.7.0\r\noverrides==3.1.0\r\npackaging==20.9\r\npathtools==0.1.2\r\npathy==0.5.2\r\npbr==5.6.0\r\nPillow==8.2.0\r\npluggy==0.13.1\r\npreshed==3.0.5\r\nprettytable==2.1.0\r\npromise==2.3\r\nprotobuf==3.16.0\r\npsutil==5.8.0\r\npy==1.10.0\r\npy-rouge==1.1\r\npydantic==1.7.3\r\npyparsing==2.4.7\r\npyperclip==1.8.2\r\npytest==6.2.4\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\nPyYAML==5.4.1\r\nregex==2021.4.4\r\nrequests==2.25.1\r\ns3transfer==0.4.2\r\nsacremoses==0.0.45\r\nscikit-learn==0.24.2\r\nscipy==1.6.3\r\nsentencepiece==0.1.95\r\nsentry-sdk==1.1.0\r\nshortuuid==1.0.1\r\nsix==1.16.0\r\nsmart-open==3.0.0\r\nsmmap==4.0.0\r\nspacy==3.0.6\r\nspacy-legacy==3.0.5\r\nSQLAlchemy==1.4.16\r\nsrsly==2.4.1\r\nstevedore==3.3.0\r\nsubprocess32==3.5.4\r\ntensorboardX==2.2\r\nthinc==8.0.3\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.10.2\r\ntoml==0.10.2\r\ntorch @ file:///dockerdata/magialiao/torch-1.7.1%2Bcu101-cp37-cp37m-linux_x86_64.whl\r\ntorchvision==0.9.1\r\ntqdm==4.60.0\r\ntransformers==4.5.1\r\ntruecase==0.0.12\r\ntyper==0.3.2\r\ntyping-extensions==3.10.0.0\r\nurllib3==1.26.4\r\nwandb==0.10.30\r\nwasabi==0.8.2\r\nwcwidth==0.2.5\r\nword2number==1.1\r\nzipp==3.4.1\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n\r\nRun `allennlp-optuna` example with above environment and check `result/hpo/trial_0/out.log`, it will contain tqdm logs of all trials.\r\n\r\n```\r\nallennlp tune \\\r\n    config/imdb_optuna.jsonnet \\\r\n    config/hparams.json \\\r\n    --serialization-dir result/hpo \\\r\n    --study-name test\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5234/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5234/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5210", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5210/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5210/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5210/events", "html_url": "https://github.com/allenai/allennlp/issues/5210", "id": 894003982, "node_id": "MDU6SXNzdWU4OTQwMDM5ODI=", "number": 5210, "title": "miss O in allowed_transitions ?", "user": {"login": "flyangovoyang", "id": 45290558, "node_id": "MDQ6VXNlcjQ1MjkwNTU4", "avatar_url": "https://avatars.githubusercontent.com/u/45290558?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flyangovoyang", "html_url": "https://github.com/flyangovoyang", "followers_url": "https://api.github.com/users/flyangovoyang/followers", "following_url": "https://api.github.com/users/flyangovoyang/following{/other_user}", "gists_url": "https://api.github.com/users/flyangovoyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/flyangovoyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flyangovoyang/subscriptions", "organizations_url": "https://api.github.com/users/flyangovoyang/orgs", "repos_url": "https://api.github.com/users/flyangovoyang/repos", "events_url": "https://api.github.com/users/flyangovoyang/events{/privacy}", "received_events_url": "https://api.github.com/users/flyangovoyang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2021-05-18T06:15:25Z", "updated_at": "2021-05-23T13:17:15Z", "closed_at": "2021-05-23T13:17:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/allenai/allennlp/blob/79d16af1f9d719934a1aa4a3506482c05e24aae6/allennlp/modules/conditional_random_field.py#L14-L56\r\n\r\nhttps://github.com/allenai/allennlp/blob/79d16af1f9d719934a1aa4a3506482c05e24aae6/allennlp/modules/conditional_random_field.py#L138-L154\r\n\r\naccording to the codes above, O -> B-PER is not allowed when calling:\r\n\r\n```python\r\nid2tag = {0: 'O', 1: 'B-PER', 2: 'M-PER', 3: 'E-PER', 4: 'S-PER'}\r\nallowed_transitions('BMES', id2tag)\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5210/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5210/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5202", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5202/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5202/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5202/events", "html_url": "https://github.com/allenai/allennlp/issues/5202", "id": 892291356, "node_id": "MDU6SXNzdWU4OTIyOTEzNTY=", "number": 5202, "title": "Sentiment Analysis (RoBERTa) Prediction Error", "user": {"login": "ericluo04", "id": 39772787, "node_id": "MDQ6VXNlcjM5NzcyNzg3", "avatar_url": "https://avatars.githubusercontent.com/u/39772787?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ericluo04", "html_url": "https://github.com/ericluo04", "followers_url": "https://api.github.com/users/ericluo04/followers", "following_url": "https://api.github.com/users/ericluo04/following{/other_user}", "gists_url": "https://api.github.com/users/ericluo04/gists{/gist_id}", "starred_url": "https://api.github.com/users/ericluo04/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ericluo04/subscriptions", "organizations_url": "https://api.github.com/users/ericluo04/orgs", "repos_url": "https://api.github.com/users/ericluo04/repos", "events_url": "https://api.github.com/users/ericluo04/events{/privacy}", "received_events_url": "https://api.github.com/users/ericluo04/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-05-14T22:52:12Z", "updated_at": "2021-05-20T04:26:29Z", "closed_at": "2021-05-20T04:26:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello! I'm working in a google colab notebook and find the below error when trying to predict using the RoBERTa pretrained sentiment analysis model:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n<ipython-input-9-ad5209ed4732> in <module>()\r\n      1 # load sentiment analysis model\r\n      2 predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/stanford-sentiment-treebank-roberta.2021-03-11.tar.gz\")\r\n----> 3 predictor.predict(\"a very well-made, funny and entertaining picture.\")\r\n\r\n3 frames\r\n/usr/local/lib/python3.7/dist-packages/allennlp_models/classification/dataset_readers/stanford_sentiment_tree_bank.py in text_to_instance(self, tokens, sentiment)\r\n    113         \"\"\"\r\n    114         assert isinstance(\r\n--> 115             tokens, list\r\n    116         )  # If tokens is a str, nothing breaks but the results are garbage, so we check.\r\n    117         if self._tokenizer is None:\r\n\r\nAssertionError:\r\n```\r\n\r\nMy package installation code is:\r\n```\r\n# upgrade nltk\r\n!pip install -U nltk\r\n\r\n# AllenNLP (SOTA NLP)\r\n!pip install allennlp==2.1.0 allennlp-models==2.1.0\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.tagging\r\n```\r\nRunning this code (straight from the [documentation](https://demo.allennlp.org/sentiment-analysis/roberta-sentiment-analysis)) produces the mentioned error:\r\n```\r\n# load sentiment analysis model\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/stanford-sentiment-treebank-roberta.2021-03-11.tar.gz\")\r\npredictor.predict(\"a very well-made, funny and entertaining picture.\")\r\n```\r\n\r\nThe model itself seems to load but the predictions throw an unidentified error. Any help would be much appreciated - thanks so much!", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5202/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5202/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5197", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5197/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5197/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5197/events", "html_url": "https://github.com/allenai/allennlp/issues/5197", "id": 889132622, "node_id": "MDU6SXNzdWU4ODkxMzI2MjI=", "number": 5197, "title": "latest overrides package breaks allennlp", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "02b8d1", "default": false, "description": ""}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2021-05-11T23:33:22Z", "updated_at": "2022-02-07T20:35:10Z", "closed_at": "2022-02-07T20:35:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "The version of `overrides` dependency seems to have been bumped rapidly from `3.1.0` on 18 Jun 2020 to `6.1.0` 5 days ago (https://github.com/mkorpela/overrides/tags) with a release almost weekly. This seems to have added functionality to verify correctness of type annotations, which in turn throws exceptions on simple imports (see MRE below) which aren't annotated correctly such as `ArrayField.empty_field` has no return type annotation (should be the string 'ArrayField' since it returns an instance of it's class).\r\n\r\nI had to downgrade overrides to 3.1.0, I \"fixed\" the issue below by adding the correct return type to the `ArrayField.empty_field` property (-> 'ArrayField' works) and a few other trivial examples but then it quickly snowballed so I gave up and manually rolled back.\r\n\r\n`from allennlp.data.fields import ArrayField`\r\n\r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/allennlp/data/__init__.py\", line 1, in <module>\r\n>     from allennlp.data.dataset_readers.dataset_reader import DatasetReader\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/allennlp/data/dataset_readers/__init__.py\", line 10, in <module>\r\n>     from allennlp.data.dataset_readers.ccgbank import CcgBankDatasetReader\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/allennlp/data/dataset_readers/ccgbank.py\", line 9, in <module>\r\n>     from allennlp.data.dataset_readers.dataset_reader import DatasetReader\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/allennlp/data/dataset_readers/dataset_reader.py\", line 8, in <module>\r\n>     from allennlp.data.instance import Instance\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/allennlp/data/instance.py\", line 3, in <module>\r\n>     from allennlp.data.fields.field import DataArray, Field\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/allennlp/data/fields/__init__.py\", line 7, in <module>\r\n>     from allennlp.data.fields.array_field import ArrayField\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/allennlp/data/fields/array_field.py\", line 10, in <module>\r\n>     class ArrayField(Field[numpy.ndarray]):\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/allennlp/data/fields/array_field.py\", line 50, in ArrayField\r\n>     @overrides\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/overrides/overrides.py\", line 88, in overrides\r\n>     return _overrides(method, check_signature, check_at_runtime)\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/overrides/overrides.py\", line 114, in _overrides\r\n>     _validate_method(method, super_class, check_signature)\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/overrides/overrides.py\", line 135, in _validate_method\r\n>     ensure_signature_is_compatible(super_method, method, is_static)\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/overrides/signature.py\", line 93, in ensure_signature_is_compatible\r\n>     ensure_return_type_compatibility(super_type_hints, sub_type_hints, method_name)\r\n>   File \"/home/david/.pyenv/versions/wiser/lib/python3.7/site-packages/overrides/signature.py\", line 288, in ensure_return_type_compatibility\r\n>     f\"{method_name}: return type `{sub_return}` is not a `{super_return}`.\"\r\n> TypeError: ArrayField.empty_field: return type `None` is not a `<class 'allennlp.data.fields.field.Field'>`.\r\n> ", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5197/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5197/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5191", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5191/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5191/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5191/events", "html_url": "https://github.com/allenai/allennlp/issues/5191", "id": 884296972, "node_id": "MDU6SXNzdWU4ODQyOTY5NzI=", "number": 5191, "title": "Can not import allennlp.data.fields.array_field ", "user": {"login": "MHDBST", "id": 6802945, "node_id": "MDQ6VXNlcjY4MDI5NDU=", "avatar_url": "https://avatars.githubusercontent.com/u/6802945?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MHDBST", "html_url": "https://github.com/MHDBST", "followers_url": "https://api.github.com/users/MHDBST/followers", "following_url": "https://api.github.com/users/MHDBST/following{/other_user}", "gists_url": "https://api.github.com/users/MHDBST/gists{/gist_id}", "starred_url": "https://api.github.com/users/MHDBST/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MHDBST/subscriptions", "organizations_url": "https://api.github.com/users/MHDBST/orgs", "repos_url": "https://api.github.com/users/MHDBST/repos", "events_url": "https://api.github.com/users/MHDBST/events{/privacy}", "received_events_url": "https://api.github.com/users/MHDBST/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2021-05-10T14:03:12Z", "updated_at": "2021-05-24T16:13:06Z", "closed_at": "2021-05-24T16:13:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nWhen I import `from allennlp.data.fields.array_field import ArrayField` the following error occurs:\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/mbastan/context_home/XP_project/scibert/src/allennlp/allennlp/data/__init__.py\", line 1, in <module>\r\n    from allennlp.data.dataset_readers.dataset_reader import DatasetReader\r\n  File \"/home/mbastan/context_home/XP_project/scibert/src/allennlp/allennlp/data/dataset_readers/__init__.py\", line 10, in <module>\r\n    from allennlp.data.dataset_readers.ccgbank import CcgBankDatasetReader\r\n  File \"/home/mbastan/context_home/XP_project/scibert/src/allennlp/allennlp/data/dataset_readers/ccgbank.py\", line 9, in <module>\r\n    from allennlp.data.dataset_readers.dataset_reader import DatasetReader\r\n  File \"/home/mbastan/context_home/XP_project/scibert/src/allennlp/allennlp/data/dataset_readers/dataset_reader.py\", line 8, in <module>\r\n    from allennlp.data.instance import Instance\r\n  File \"/home/mbastan/context_home/XP_project/scibert/src/allennlp/allennlp/data/instance.py\", line 3, in <module>\r\n    from allennlp.data.fields.field import DataArray, Field\r\n  File \"/home/mbastan/context_home/XP_project/scibert/src/allennlp/allennlp/data/fields/__init__.py\", line 7, in <module>\r\n    from allennlp.data.fields.array_field import ArrayField\r\n  File \"/home/mbastan/context_home/XP_project/scibert/src/allennlp/allennlp/data/fields/array_field.py\", line 10, in <module>\r\n    class ArrayField(Field[numpy.ndarray]):\r\n  File \"/home/mbastan/context_home/XP_project/scibert/src/allennlp/allennlp/data/fields/array_field.py\", line 49, in ArrayField\r\n    @overrides\r\n  File \"/home/mbastan/context_home/anaconda2/envs/mypython3/lib/python3.6/site-packages/overrides/overrides.py\", line 88, in overrides\r\n    return _overrides(method, check_signature, check_at_runtime)\r\n  File \"/home/mbastan/context_home/anaconda2/envs/mypython3/lib/python3.6/site-packages/overrides/overrides.py\", line 114, in _overrides\r\n    _validate_method(method, super_class, check_signature)\r\n  File \"/home/mbastan/context_home/anaconda2/envs/mypython3/lib/python3.6/site-packages/overrides/overrides.py\", line 135, in _validate_method\r\n    ensure_signature_is_compatible(super_method, method, is_static)\r\n  File \"/home/mbastan/context_home/anaconda2/envs/mypython3/lib/python3.6/site-packages/overrides/signature.py\", line 93, in ensure_signature_is_compatible\r\n    ensure_return_type_compatibility(super_type_hints, sub_type_hints, method_name)\r\n  File \"/home/mbastan/context_home/anaconda2/envs/mypython3/lib/python3.6/site-packages/overrides/signature.py\", line 288, in ensure_return_type_compatibility\r\n    f\"{method_name}: return type `{sub_return}` is not a `{super_return}`.\"\r\nTypeError: ArrayField.empty_field: return type `None` is not a `allennlp.data.fields.field.Field`.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.6.10\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.12.0\r\naiohttp==3.7.4.post0\r\nalabaster==0.7.12\r\n-e git://github.com/ibeltagy/allennlp@ac2b21da6008d0e41d31192ea596153988c000a4#egg=allennlp\r\nantlr4-python3-runtime==4.9.2\r\nargon2-cffi==20.1.0\r\nastor==0.8.1\r\nastroid==2.5.3\r\nastunparse==1.6.3\r\nasync-generator==1.10\r\nasync-timeout==3.0.1\r\nattrs==20.3.0\r\nBabel==2.9.1\r\nbackcall==0.2.0\r\nbleach==3.3.0\r\nBLEURT @ file:///home/mbastan/context_home/XP_project/bleurt\r\nblis==0.2.4\r\nboto3==1.17.52\r\nbotocore==1.20.52\r\ncached-property==1.5.2\r\ncachetools==4.2.1\r\ncertifi==2020.12.5\r\ncffi==1.14.5\r\nchardet==4.0.0\r\nclick==7.1.2\r\nconllu==1.3.1\r\ncoverage==5.5\r\ncycler==0.10.0\r\ncymem==2.0.5\r\nCython==0.29.23\r\ndataclasses==0.8\r\ndebugpy==1.3.0\r\ndecorator==5.0.7\r\ndeepspeed==0.3.14\r\ndefusedxml==0.7.1\r\ndocutils==0.17\r\neditdistance==0.5.3\r\nentrypoints==0.3\r\nfairseq==0.10.2\r\nfastBPE==0.1.0\r\nfilelock==3.0.12\r\nfire==0.4.0\r\nflaky==3.7.0\r\nFlask==1.1.2\r\nFlask-Cors==3.0.10\r\nflatbuffers==1.12\r\nfsspec==0.9.0\r\nftfy==6.0.1\r\nfuture==0.18.2\r\ngast==0.3.3\r\nget==2019.4.13\r\ngevent==21.1.2\r\ngitdb==4.0.7\r\nGitPython==3.1.14\r\ngoogle-auth==1.28.1\r\ngoogle-auth-oauthlib==0.4.4\r\ngoogle-pasta==0.2.0\r\ngreenlet==1.1.0\r\ngrpcio==1.32.0\r\ngsub==0.1.5\r\nh5py==2.10.0\r\nhydra-core==1.0.6\r\nidna==2.10\r\nidna-ssl==1.1.0\r\nimagesize==1.2.0\r\nimportlib-metadata==3.10.1\r\nimportlib-resources==5.1.2\r\niniconfig==1.1.1\r\nipykernel==5.5.3\r\nipython==7.16.1\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.3\r\nisort==5.8.0\r\nitsdangerous==1.1.0\r\njedi==0.17.2\r\nJinja2==2.11.3\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonlines==2.0.0\r\njsonnet==0.17.0\r\njsonpickle==2.0.0\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==6.1.12\r\njupyter-console==6.4.0\r\njupyter-core==4.7.1\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.0\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.2\r\nkiwisolver==1.3.1\r\nlazy-object-proxy==1.6.0\r\nlxml==4.6.3\r\nMarkdown==3.3.4\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.3.4\r\nmccabe==0.6.1\r\nmistune==0.8.4\r\nmock==4.0.3\r\nmultidict==5.1.0\r\nmurmurhash==1.0.5\r\nmytorch==0.1.0.dev0\r\nnbclient==0.5.3\r\nnbconvert==6.0.7\r\nnbformat==5.1.3\r\nnest-asyncio==1.5.1\r\nninja==1.10.0.post2\r\nnltk==3.6.1\r\nnotebook==6.3.0\r\nnumpy==1.19.5\r\nnumpydoc==1.1.0\r\noauthlib==3.1.0\r\nomegaconf==2.0.6\r\nopt-einsum==3.3.0\r\noverrides==6.1.0\r\npackaging==20.9\r\npandas==1.1.5\r\npandocfilters==1.4.3\r\nparsimonious==0.8.1\r\nparso==0.7.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==8.2.0\r\nplac==0.9.6\r\npluggy==0.13.1\r\nportalocker==2.3.0\r\npost==2019.4.13\r\npreshed==2.0.1\r\nprometheus-client==0.10.1\r\nprompt-toolkit==3.0.18\r\nprotobuf==3.15.8\r\npsutil==5.8.0\r\nptyprocess==0.7.0\r\npublic==2020.12.3\r\npubmed-parser @ git+git://github.com/titipata/pubmed_parser.git@ee0fce583cf111b71430660e743fd0d72acd68ed\r\npy==1.10.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\npycurl==7.43.0.6\r\nPygments==2.8.1\r\npylint==2.7.4\r\npyparsing==2.4.7\r\npyrsistent==0.17.3\r\npytest==6.2.3\r\npytest-cov==2.11.1\r\npython-dateutil==2.8.1\r\npytorch-lightning==1.2.8\r\npytorch-pretrained-bert==0.6.2\r\npytorch-transformers==1.1.0\r\npytz==2021.1\r\nPyYAML==5.4.1\r\npyzmq==22.0.3\r\nqtconsole==5.0.3\r\nQtPy==1.9.0\r\nquery-string==2020.12.3\r\nregex==2021.4.4\r\nrequest==2019.4.13\r\nrequests==2.25.1\r\nrequests-oauthlib==1.3.0\r\nresponses==0.13.3\r\nrouge==1.0.0\r\nrouge-score==0.0.4\r\nrsa==4.7.2\r\ns3transfer==0.3.7\r\nsacrebleu==1.5.1\r\nsacremoses==0.0.44\r\nscikit-learn==0.24.1\r\nscipy==1.5.4\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.95\r\nsix==1.15.0\r\nsklearn==0.0\r\nsmmap==4.0.0\r\nsnowballstemmer==2.1.0\r\nspacy==2.1.9\r\nSphinx==4.0.0\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nsqlparse==0.4.1\r\nsrsly==1.0.5\r\nstyle==1.1.6\r\ntensorboard==2.4.1\r\ntensorboard-plugin-wit==1.8.0\r\ntensorboardX==2.2\r\ntensorflow==2.4.1\r\ntensorflow-estimator==2.4.0\r\ntensorflow-gpu==2.4.1\r\ntermcolor==1.1.0\r\nterminado==0.9.4\r\ntestpath==0.4.4\r\ntf-slim==1.1.0\r\nthinc==7.0.8\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.10.2\r\ntoml==0.10.2\r\ntoposort==1.6\r\ntorch==1.8.1\r\ntorchmetrics==0.2.0\r\ntorchvision==0.9.1\r\ntornado==6.1\r\ntqdm==4.60.0\r\ntraitlets==4.3.3\r\ntransformers==4.5.1\r\ntyped-ast==1.4.3\r\ntyping-extensions==3.7.4.3\r\ntyping-utils==0.0.3\r\nUnidecode==1.2.0\r\nupdate==0.0.1\r\nurllib3==1.26.4\r\nwasabi==0.8.2\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nwrapt==1.12.1\r\nyarl==1.6.3\r\nzipp==3.4.1\r\nzope.event==4.5.0\r\nzope.interface==5.4.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp.data.fields.array_field import ArrayField\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5191/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5191/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5186", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5186/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5186/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5186/events", "html_url": "https://github.com/allenai/allennlp/issues/5186", "id": 878228603, "node_id": "MDU6SXNzdWU4NzgyMjg2MDM=", "number": 5186, "title": "Input, output and indices must be on the current device", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-05-07T00:16:05Z", "updated_at": "2021-05-07T17:21:55Z", "closed_at": "2021-05-07T17:21:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "Reading the documentation for the Trainer \"If you are training your model using GPUs, your model should already be on the correct device. (If you are using our train command this will be handled for you.)\" - https://docs.allennlp.org/main/api/training/trainer/\r\n\r\nWhen I run the tutorial (https://github.com/allenai/allennlp-guide/blob/master/quick_start/train.py) the trainer throws `Input, output and indices must be on the current device`.\r\n\r\nThe issue appears to be that the data is copied to the gpu but the model isn't. I may be misreading the documentation - the quote above (for the model argument) seems to conflict with the default value for the cuda_device argument (-1 i.e. cpu).\r\n\r\nBut if this is the case shouldn't the data be loaded to the cpu not gpu?\r\n\r\nEdit: Note the documentation implies the default for the trainer argument `cuda_device` is -1 (cpu) but in fact it is None (which resutls in the `Trainer` super class automatically detecting the presence of cuda and setting it to 0. But the constructor of `GradientDescentTrainer` contains the following:\r\n\r\n        # I am not calling move_to_gpu here, because if the model is\r\n        # not already on the GPU then the optimizer is going to be wrong.\r\n        self.model = model\r\n\r\nSo it seems to be deliberate to require that the model already be on the gpu. But is this case the code in Trainer:\r\n\r\n        if cuda_device is None:\r\n            from torch import cuda\r\n\r\n            if cuda.device_count() > 0:\r\n                cuda_device = 0\r\n            else:\r\n                cuda_device = -1\r\n\r\n        self.cuda_device = int_to_device(cuda_device)\r\n\r\nResults in self.cuda_device='cuda' regardless of the location of the model (since cuda_device is None by default) . So the documentation appears incorrect and device management isn't handled by the Trainer. It's this code that results in the data loader moving the tensors to device 0.\r\n\r\nSo it seems you have to either pass `device = -1` to the trainer if the model is on the cpu, or device = None (or 0) if it's on the gpu. \r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ ] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [ x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [ x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nThe quickstart (https://github.com/allenai/allennlp-guide/blob/master/quick_start/train.py) fails out of the box since the data and model aren't being loaded to the same device. This appers contrary to the train documentation which implies this is handled automatically.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/david/.pyenv/versions/3.7.6/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/david/.pyenv/versions/3.7.6/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/david/.vscode/extensions/ms-python.python-2021.4.765268190/pythonFiles/lib/python/debugpy/__main__.py\", line 45, in <module>\r\n    cli.main()\r\n  File \"/home/david/.vscode/extensions/ms-python.python-2021.4.765268190/pythonFiles/lib/python/debugpy/../debugpy/server/cli.py\", line 444, in main\r\n    run()\r\n  File \"/home/david/.vscode/extensions/ms-python.python-2021.4.765268190/pythonFiles/lib/python/debugpy/../debugpy/server/cli.py\", line 285, in run_file\r\n    runpy.run_path(target_as_str, run_name=compat.force_str(\"__main__\"))\r\n  File \"/home/david/.pyenv/versions/3.7.6/lib/python3.7/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"/home/david/.pyenv/versions/3.7.6/lib/python3.7/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"/home/david/.pyenv/versions/3.7.6/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/david/dev/allennlp-guide/quick_start/train.py\", line 160, in <module>\r\n    run_training_loop()\r\n  File \"/home/david/dev/allennlp-guide/quick_start/train.py\", line 154, in run_training_loop\r\n    trainer.train()\r\n  File \"/home/david/.pyenv/versions/3.7.6/envs/allennlp/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 740, in train\r\n    metrics, epoch = self._try_train()\r\n  File \"/home/david/.pyenv/versions/3.7.6/envs/allennlp/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 772, in _try_train\r\n    train_metrics = self._train_epoch(epoch)\r\n  File \"/home/david/.pyenv/versions/3.7.6/envs/allennlp/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 506, in _train_epoch\r\n    batch_outputs = self.batch_outputs(batch, for_training=True)\r\n  File \"/home/david/.pyenv/versions/3.7.6/envs/allennlp/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 391, in batch_outputs\r\n    output_dict = self._pytorch_model(**batch)\r\n  File \"/home/david/.pyenv/versions/3.7.6/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/david/dev/allennlp-guide/quick_start/train.py\", line 68, in forward\r\n    embedded_text = self.embedder(text)\r\n  File \"/home/david/.pyenv/versions/3.7.6/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/david/.pyenv/versions/3.7.6/envs/allennlp/lib/python3.7/site-packages/allennlp/modules/text_field_embedders/basic_text_field_embedder.py\", line 99, in forward\r\n    token_vectors = embedder(list(tensors.values())[0], **forward_params_values)\r\n  File \"/home/david/.pyenv/versions/3.7.6/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/david/.pyenv/versions/3.7.6/envs/allennlp/lib/python3.7/site-packages/allennlp/modules/token_embedders/embedding.py\", line 203, in forward\r\n    sparse=self.sparse,\r\n  File \"/home/david/.pyenv/versions/3.7.6/envs/allennlp/lib/python3.7/site-packages/torch/nn/functional.py\", line 1916, in embedding\r\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\r\nRuntimeError: Input, output and indices must be on the current device\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux (ubuntu 20.04)\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.6\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==2.4.0\r\nattrs==21.1.0\r\nblis==0.7.4\r\nboto3==1.17.68\r\nbotocore==1.20.68\r\ncached-property==1.5.2\r\ncatalogue==2.0.4\r\ncertifi==2020.12.5\r\nchardet==4.0.0\r\nclick==7.1.2\r\nconfigparser==5.0.2\r\ncymem==2.0.5\r\ndocker-pycreds==0.4.0\r\nfilelock==3.0.12\r\ngitdb==4.0.7\r\nGitPython==3.1.14\r\nh5py==3.2.1\r\nhuggingface-hub==0.0.8\r\nidna==2.10\r\nimportlib-metadata==4.0.1\r\niniconfig==1.1.1\r\nJinja2==2.11.3\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonnet==0.17.0\r\nlmdb==1.2.1\r\nMarkupSafe==1.1.1\r\nmore-itertools==8.7.0\r\nmurmurhash==1.0.5\r\nnltk==3.6.2\r\nnumpy==1.20.2\r\noverrides==3.1.0\r\npackaging==20.9\r\npathtools==0.1.2\r\npathy==0.5.2\r\nPillow==8.2.0\r\npluggy==0.13.1\r\npreshed==3.0.5\r\npromise==2.3\r\nprotobuf==3.15.8\r\npsutil==5.8.0\r\npy==1.10.0\r\npydantic==1.7.3\r\npyparsing==2.4.7\r\npytest==6.2.4\r\npython-dateutil==2.8.1\r\nPyYAML==5.4.1\r\nregex==2021.4.4\r\nrequests==2.25.1\r\ns3transfer==0.4.2\r\nsacremoses==0.0.45\r\nscikit-learn==0.24.2\r\nscipy==1.6.3\r\nsentencepiece==0.1.95\r\nsentry-sdk==1.1.0\r\nshortuuid==1.0.1\r\nsix==1.16.0\r\nsmart-open==3.0.0\r\nsmmap==4.0.0\r\nspacy==3.0.6\r\nspacy-legacy==3.0.5\r\nsrsly==2.4.1\r\nsubprocess32==3.5.4\r\ntensorboardX==2.2\r\nthinc==8.0.3\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.10.2\r\ntoml==0.10.2\r\ntorch==1.8.1+cu111\r\ntorchaudio==0.8.1\r\ntorchvision==0.9.1+cu111\r\ntqdm==4.60.0\r\ntransformers==4.5.1\r\ntyper==0.3.2\r\ntyping-extensions==3.10.0.0\r\nurllib3==1.26.4\r\nwandb==0.10.29\r\nwasabi==0.8.2\r\nzipp==3.4.1\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nRun example source (note, my machine has two gpu's)\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\nhttps://github.com/allenai/allennlp-guide/blob/master/quick_start/train.py\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5186/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5186/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5170", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5170/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5170/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5170/events", "html_url": "https://github.com/allenai/allennlp/issues/5170", "id": 871361331, "node_id": "MDU6SXNzdWU4NzEzNjEzMzE=", "number": 5170, "title": "Cannot load the pre-trained models", "user": {"login": "MausamGaurav", "id": 51297767, "node_id": "MDQ6VXNlcjUxMjk3NzY3", "avatar_url": "https://avatars.githubusercontent.com/u/51297767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MausamGaurav", "html_url": "https://github.com/MausamGaurav", "followers_url": "https://api.github.com/users/MausamGaurav/followers", "following_url": "https://api.github.com/users/MausamGaurav/following{/other_user}", "gists_url": "https://api.github.com/users/MausamGaurav/gists{/gist_id}", "starred_url": "https://api.github.com/users/MausamGaurav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MausamGaurav/subscriptions", "organizations_url": "https://api.github.com/users/MausamGaurav/orgs", "repos_url": "https://api.github.com/users/MausamGaurav/repos", "events_url": "https://api.github.com/users/MausamGaurav/events{/privacy}", "received_events_url": "https://api.github.com/users/MausamGaurav/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2021-04-29T19:09:41Z", "updated_at": "2021-05-02T21:50:33Z", "closed_at": "2021-05-02T21:50:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "I want to load the pre-trained model. I have downloaded the model to my local drive since, I am unable to connect to https:// from command line due to corporate policy. When I try to load the model, it gives me a connection error. I have had this issue with the latest version 2.4 as well. What is the best practice to load pre-trained models saved on disk?\r\n\r\n## Description\r\n\r\nTrying to load the downloaded model.\r\n\r\n```\r\nimport os\r\nfrom allennlp.models.archival import archive_model, load_archive\r\narchive = load_archive(os.path.join(\"structured-prediction-srl-bert.2020.12.15.tar.gz\"))\r\n```\r\n\r\n I get the below error:\r\n```\r\nP:\\myPython37Env\\lib\\site-packages\\transformers\\configuration_utils.py in get_config_dict(cls, pretrained_model_name_or_path, **kwargs)\r\n    386                 proxies=proxies,\r\n    387                 resume_download=resume_download,\r\n--> 388                 local_files_only=local_files_only,\r\n    389             )\r\n    390             # Load config dict\r\n\r\nP:\\myPython37Env\\lib\\site-packages\\transformers\\file_utils.py in cached_path(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, local_files_only)\r\n    953             resume_download=resume_download,\r\n    954             user_agent=user_agent,\r\n--> 955             local_files_only=local_files_only,\r\n    956         )\r\n    957     elif os.path.exists(url_or_filename):\r\n\r\nP:\\myPython37Env\\lib\\site-packages\\transformers\\file_utils.py in get_from_cache(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only)\r\n   1123                 else:\r\n   1124                     raise ValueError(\r\n-> 1125                         \"Connection error, and we cannot find the requested files in the cached path.\"\r\n   1126                         \" Please try again or make sure your Internet connection is on.\"\r\n   1127                     )\r\n\r\nValueError: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.\r\n```\r\n</p>\r\n</details>\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Windows 10\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.4\r\n\r\n\r\n```\r\nallennlp==1.2.2\r\nallennlp-models==1.2.2\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5170/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5170/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5136", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5136/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5136/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5136/events", "html_url": "https://github.com/allenai/allennlp/issues/5136", "id": 863088595, "node_id": "MDU6SXNzdWU4NjMwODg1OTU=", "number": 5136, "title": "Setting max_instances_in_memory causes error in learning_rate_scheduler", "user": {"login": "vikigenius", "id": 12724810, "node_id": "MDQ6VXNlcjEyNzI0ODEw", "avatar_url": "https://avatars.githubusercontent.com/u/12724810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vikigenius", "html_url": "https://github.com/vikigenius", "followers_url": "https://api.github.com/users/vikigenius/followers", "following_url": "https://api.github.com/users/vikigenius/following{/other_user}", "gists_url": "https://api.github.com/users/vikigenius/gists{/gist_id}", "starred_url": "https://api.github.com/users/vikigenius/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vikigenius/subscriptions", "organizations_url": "https://api.github.com/users/vikigenius/orgs", "repos_url": "https://api.github.com/users/vikigenius/repos", "events_url": "https://api.github.com/users/vikigenius/events{/privacy}", "received_events_url": "https://api.github.com/users/vikigenius/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-04-20T18:06:15Z", "updated_at": "2021-04-27T22:34:11Z", "closed_at": "2021-04-27T22:34:11Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nSetting max_instances_in_memory causes an error in learning_rate_scheduler.\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/void/miniconda3/envs/lexsiamese/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 119, in main\r\n    args.func(args)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/commands/train.py\", line 119, in train_model_from_args\r\n    file_friendly_logging=args.file_friendly_logging,\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/commands/train.py\", line 178, in train_model_from_file\r\n    file_friendly_logging=file_friendly_logging,\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/commands/train.py\", line 323, in train_model\r\n    nprocs=num_procs,\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 230, in spawn\r\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 188, in start_processes\r\n    while not context.join():\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 150, in join\r\n    raise ProcessRaisedException(msg, error_index, failed_process.pid)\r\ntorch.multiprocessing.spawn.ProcessRaisedException: \r\n\r\n-- Process 6 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 59, in _wrap\r\n    fn(i, *args)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/commands/train.py\", line 456, in _train_worker\r\n    local_rank=process_rank,\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 593, in from_params\r\n    **extras,\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 623, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/commands/train.py\", line 732, in from_partial_objects\r\n    validation_data_loader=data_loaders.get(\"validation\"),\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/common/lazy.py\", line 80, in construct\r\n    return self.constructor(**contructor_kwargs)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/common/lazy.py\", line 66, in constructor_to_use\r\n    **kwargs,\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 593, in from_params\r\n    **extras,\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 623, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 1054, in from_partial_objects\r\n    optimizer=optimizer_, num_epochs=num_epochs, num_steps_per_epoch=batches_per_epoch\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/common/lazy.py\", line 80, in construct\r\n    return self.constructor(**contructor_kwargs)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/common/lazy.py\", line 66, in constructor_to_use\r\n    **kwargs,\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 593, in from_params\r\n    **extras,\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 623, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/training/learning_rate_schedulers/polynomial_decay.py\", line 46, in __init__\r\n    self.total_steps = num_epochs * num_steps_per_epoch\r\nTypeError: unsupported operand type(s) for *: 'int' and 'NoneType'\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nSetting max_instances_in_memory to zero solves this and no longer causes error.\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux x86_64\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.10\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalabaster @ file:///home/void/.cache/pypoetry/artifacts/cd/37/e0/89f7da30c12075ae566ff3d8107abdbc74fd3d19ae5644765d79dd5d47/alabaster-0.7.12-py2.py3-none-any.whl\r\nalembic @ file:///home/void/.cache/pypoetry/artifacts/cb/39/9a/86b56862682b530f53ebb1e69e78f816f9f8d08b29ffc82509f2ef76ac/alembic-1.5.8-py2.py3-none-any.whl\r\nallennlp @ file:///home/void/.cache/pypoetry/artifacts/2b/5d/f1/e0ad9a1e311da16af778085f277fa0c6a40d19d052d93ffd410785deb2/allennlp-2.3.0-py3-none-any.whl\r\nallennlp-optuna @ file:///home/void/.cache/pypoetry/artifacts/1b/6c/5b/1cea8d351d1eb5e32c282cfc0e3acb07f4e71ab6bc3d8ac96025cadf64/allennlp_optuna-0.1.5-py3-none-any.whl\r\nargon2-cffi @ file:///home/void/.cache/pypoetry/artifacts/40/58/da/99ea4f10c652469eb6c623b269fb96784ed9bbdab439c3a5bd9d9afa6e/argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl\r\nastor @ file:///home/void/.cache/pypoetry/artifacts/5f/e9/ea/ff2986fae56c8b24978d6ca48a057f02e9e4845b5b9b499a2506121369/astor-0.8.1-py2.py3-none-any.whl\r\nasync-generator @ file:///home/void/.cache/pypoetry/artifacts/5a/c9/85/708dc64d76e0faea9f132181d1f9589bfab62218ac9bbef7d6cfc821d2/async_generator-1.10-py3-none-any.whl\r\nattrs @ file:///home/void/.cache/pypoetry/artifacts/ae/b3/61/38a043abdba5ba4c0c510dde549dd1c8278bf56262dc5df55c19133a02/attrs-20.3.0-py2.py3-none-any.whl\r\nBabel @ file:///home/void/.cache/pypoetry/artifacts/0d/6c/d0/f735d4d0af68640ee69adddc80d3ecf336156e84c4ccf2078c8fe9e38b/Babel-2.9.0-py2.py3-none-any.whl\r\nbackcall @ file:///home/void/.cache/pypoetry/artifacts/d9/1c/14/88957e7a43c92c6678d8ca482196186836144475c67d11ff02a4ee2194/backcall-0.2.0-py2.py3-none-any.whl\r\nbandit @ file:///home/void/.cache/pypoetry/artifacts/b1/65/70/cb20da954def2f182c80e2555654f456552633122e9f8f23425855b46b/bandit-1.7.0-py3-none-any.whl\r\nbeautifulsoup4 @ file:///home/void/.cache/pypoetry/artifacts/d7/4b/c2/1a65d7699a83c83aaec6fa35b97cb59760569be3e24f903ae4b55ac3a5/beautifulsoup4-4.9.3-py3-none-any.whl\r\nbleach @ file:///home/void/.cache/pypoetry/artifacts/0c/19/da/291df1a8b71e9bd208e3e6f801afd6567b9ef47036b167c11e25f5c96c/bleach-3.3.0-py2.py3-none-any.whl\r\nblis @ file:///home/void/.cache/pypoetry/artifacts/22/59/92/fbc277252d447c1eea4adf771a209657eb1d536c3f9b2b5bbdf10b5b45/blis-0.7.4-cp37-cp37m-manylinux2014_x86_64.whl\r\nboto3 @ file:///home/void/.cache/pypoetry/artifacts/f0/1c/4b/54fd3599e1872242dddd68dea523ba5440560ba56bcace6a5271a5b7fb/boto3-1.17.53-py2.py3-none-any.whl\r\nbotocore @ file:///home/void/.cache/pypoetry/artifacts/39/30/63/e4763d6e3afc7c0cececf6d2af2171c305849dd83c6725134b2db0ad14/botocore-1.20.53-py2.py3-none-any.whl\r\ncached-property @ file:///home/void/.cache/pypoetry/artifacts/38/d8/aa/b8baaf6448a0029023e15cbfc6e1a278d60cc2e2b022c94bc850561996/cached_property-1.5.2-py2.py3-none-any.whl\r\ncatalogue @ file:///home/void/.cache/pypoetry/artifacts/6b/d2/12/e162a59d9b422d9802b9dced62cc39ab69afbf475f9c64779bf2400ec5/catalogue-2.0.3-py3-none-any.whl\r\ncertifi==2020.12.5\r\ncffi @ file:///home/void/.cache/pypoetry/artifacts/25/db/72/24c31ee860d752b550f7744febafb4d2b3bfe3ada972f163ccdf8ae711/cffi-1.14.5-cp37-cp37m-manylinux1_x86_64.whl\r\nchardet @ file:///home/void/.cache/pypoetry/artifacts/f0/e1/66/f8ced421461f1dda06ea89af6ac51a22cf72ff0595f329808634559b2b/chardet-4.0.0-py2.py3-none-any.whl\r\nclick @ file:///home/void/.cache/pypoetry/artifacts/21/fd/0f/f7ff619e0ab099fc284ee2b24a86129d9dc3ad2a475dc304bbbbe20ecb/click-7.1.2-py2.py3-none-any.whl\r\ncliff @ file:///home/void/.cache/pypoetry/artifacts/4c/37/89/981a4be88fc94f7ff2523f5646f2994032111d85da21ad553e32f343fe/cliff-3.7.0-py3-none-any.whl\r\ncmaes @ file:///home/void/.cache/pypoetry/artifacts/08/1c/a2/065ada5c6a31f5b9a476c139ce2ca736614b5d9ffb65172565b46d5ec7/cmaes-0.8.2-py3-none-any.whl\r\ncmd2 @ file:///home/void/.cache/pypoetry/artifacts/c9/15/0e/8e818c612a709f0e313c624f3dfed5ee30c95d42e57f49fe80cb2cc4f6/cmd2-1.5.0-py3-none-any.whl\r\ncolorama @ file:///home/void/.cache/pypoetry/artifacts/33/a2/a4/09f68d0a2176d987da70e9dee0eaea3cc48f68b56a7fa8ac56c2d22dc7/colorama-0.4.4-py2.py3-none-any.whl\r\ncolorlog @ file:///home/void/.cache/pypoetry/artifacts/1c/08/cf/e706def39db46dc00865c88496d0fa0b044c30a01831eb84d639d9f2f2/colorlog-5.0.1-py2.py3-none-any.whl\r\nconfigparser @ file:///home/void/.cache/pypoetry/artifacts/62/d3/97/a2949c74cc1115909f8c1f42f474c3ab22e1da2667d2ddff71b3e6efff/configparser-5.0.2-py3-none-any.whl\r\ncoverage @ file:///home/void/.cache/pypoetry/artifacts/9b/3b/0e/7304b9b5727e6d8c7dcb7790e5a7ada9f9b0eb3d447c55bafbd1e10a6e/coverage-5.5-cp37-cp37m-manylinux2010_x86_64.whl\r\ncymem @ file:///home/void/.cache/pypoetry/artifacts/89/dc/1c/cd70280e9193082ebee5dba1b3b3302ff4c64d1524e041c0c03516261c/cymem-2.0.5-cp37-cp37m-manylinux2014_x86_64.whl\r\ndarglint @ file:///home/void/.cache/pypoetry/artifacts/d0/22/a6/0ae1baa693bb2faf4f905bd3da5e7c7acf12bca962fc4d927838ee8b41/darglint-1.8.0-py3-none-any.whl\r\ndecorator @ file:///home/void/.cache/pypoetry/artifacts/4c/44/a3/98a9811f5ccd978d1c278eb97127c919a58ca805b3e54fba6c0b212265/decorator-5.0.7-py3-none-any.whl\r\ndefusedxml @ file:///home/void/.cache/pypoetry/artifacts/d3/69/a8/eb355ff24ffb8df62ec3dd9524bec0ad9d9dc719bd996734d6d7aa1d56/defusedxml-0.7.1-py2.py3-none-any.whl\r\ndictdiffer @ file:///home/void/.cache/pypoetry/artifacts/e4/93/97/60397fd0d7cca2bb6e18b78a6a7686f75a859f1b8f237167d7d4737b1d/dictdiffer-0.8.1-py2.py3-none-any.whl\r\ndoc8 @ file:///home/void/.cache/pypoetry/artifacts/79/3e/c8/ae33df607c50685be0d497522a1af2a835f1be1c77709951aaa6b195db/doc8-0.8.1-py2.py3-none-any.whl\r\ndocker-pycreds @ file:///home/void/.cache/pypoetry/artifacts/ae/d2/e4/d45ddf9b807389820c106b6d5cc636f5a794fb93631d9b8119fb110ec3/docker_pycreds-0.4.0-py2.py3-none-any.whl\r\ndocutils @ file:///home/void/.cache/pypoetry/artifacts/24/17/76/ad5143b189440a07a8cd43100d25b414c020d591981c6141f1881f7fe6/docutils-0.17-py2.py3-none-any.whl\r\ndparse @ file:///home/void/.cache/pypoetry/artifacts/61/38/88/d729d74e312bdef39a41d9388f962e838a49f53d9964f881552bd6b6db/dparse-0.5.1-py3-none-any.whl\r\nentrypoints @ file:///home/void/.cache/pypoetry/artifacts/5e/99/ed/7ceb3b7ba71bc66f2526e7ffc16315bfdb5bf955fe1051ec05516f7730/entrypoints-0.3-py2.py3-none-any.whl\r\neradicate @ file:///home/void/.cache/pypoetry/artifacts/4c/f8/6e/535a5eaa918010239f4badceb49f6e6ff22c1c5bad8db9ff54cee17163/eradicate-1.0.tar.gz\r\nfilelock @ file:///home/void/.cache/pypoetry/artifacts/08/55/8e/3a41c1abc99a96a15b063c1f6c0bb06c4ae6cbb78de462a1999579e087/filelock-3.0.12-py3-none-any.whl\r\nflake8 @ file:///home/void/.cache/pypoetry/artifacts/b8/54/22/c86908a17e023a917c963c0afe98570cf4b6f07c4407b85c6e3beb7128/flake8-3.9.1-py2.py3-none-any.whl\r\nflake8-bandit @ file:///home/void/.cache/pypoetry/artifacts/73/09/84/42a6b41975a42f2c631d7c0ba5cb35c38c0d0560af60ec888e95cbc82e/flake8_bandit-2.1.2.tar.gz\r\nflake8-broken-line @ file:///home/void/.cache/pypoetry/artifacts/fb/e0/e6/e7d66797cfa78abf59a681622e4a64ad26a3f37f755dff1aa2310e89ed/flake8_broken_line-0.2.1-py3-none-any.whl\r\nflake8-bugbear @ file:///home/void/.cache/pypoetry/artifacts/62/76/39/527cdbe01977956d193c1246dd1093d1c04368bf5020682fdd6b74408e/flake8_bugbear-19.8.0-py35.py36.py37-none-any.whl\r\nflake8-commas @ file:///home/void/.cache/pypoetry/artifacts/f5/ba/10/b4bde8612d74e39a007b65228f1167e91320847a48fe99d2514ccaa78d/flake8_commas-2.0.0-py2.py3-none-any.whl\r\nflake8-comprehensions @ file:///home/void/.cache/pypoetry/artifacts/e0/11/b2/d171d6145b51bc4e54263b0ffeba234d0b693e055e47eee4d2551e7e11/flake8_comprehensions-3.4.0-py3-none-any.whl\r\nflake8-debugger @ file:///home/void/.cache/pypoetry/artifacts/ea/b0/a2/b0f38254a64bb29ae6356646e0a6cd6607d383a7a3809358603dc0bb4c/flake8-debugger-3.2.1.tar.gz\r\nflake8-docstrings @ file:///home/void/.cache/pypoetry/artifacts/dd/61/0f/8c31b8a10df8152ee5f1400f965df4a1d9f14d1c2e73bdeda389921f06/flake8_docstrings-1.6.0-py2.py3-none-any.whl\r\nflake8-eradicate @ file:///home/void/.cache/pypoetry/artifacts/a0/87/7e/94d2c66c1eab6acc65ded58a867ad8c684c7bdd6eeceb91a0b336aa63b/flake8_eradicate-0.3.0-py3-none-any.whl\r\nflake8-isort @ file:///home/void/.cache/pypoetry/artifacts/aa/be/9e/5b4f728aa7c298adc33f71a13676c41d843bb89af6c0a71493b27aff01/flake8_isort-3.0.1-py2.py3-none-any.whl\r\nflake8-plugin-utils @ file:///home/void/.cache/pypoetry/artifacts/35/9a/10/f8f41d43896f3eac1b19353fd56b1de85622630254660e02d2504f5d6d/flake8_plugin_utils-1.3.1-py3-none-any.whl\r\nflake8-polyfill @ file:///home/void/.cache/pypoetry/artifacts/50/2e/1c/0ab55451b665fa42f02e5e0b60b4f1e3d0c5b97e523e6942fcb469b060/flake8_polyfill-1.0.2-py2.py3-none-any.whl\r\nflake8-pytest-style @ file:///home/void/.cache/pypoetry/artifacts/fa/25/c3/fc9f818d7a076d63faa217ea2adf691c92b0000cee5b6420bbe03ab19d/flake8_pytest_style-1.4.1-py3-none-any.whl\r\nflake8-quotes @ file:///home/void/.cache/pypoetry/artifacts/23/a7/ee/bc35529d5fb4ce0aef80dab51eca97b55a70c2183efcc68498a668f41a/flake8-quotes-2.1.2.tar.gz\r\nflake8-rst-docstrings @ file:///home/void/.cache/pypoetry/artifacts/13/52/41/eb73820e56d7ffb96a09509569d9d0e6b1068dc5d082da30c3ec40a390/flake8-rst-docstrings-0.0.12.tar.gz\r\nflake8-string-format @ file:///home/void/.cache/pypoetry/artifacts/fb/c5/8f/34f45df55140c42298862824e72ce2a67620ddad02e0173ac9654f927c/flake8_string_format-0.2.3-py2.py3-none-any.whl\r\ngitdb @ file:///home/void/.cache/pypoetry/artifacts/96/6b/0d/8c98bd5a440942e37e198088da688917df817926cdd1828c67629d73d1/gitdb-4.0.7-py3-none-any.whl\r\nGitPython @ file:///home/void/.cache/pypoetry/artifacts/d1/23/d7/b24886986eaf6c660285de59cee29e42c3a030b12d15b544fcacfc889b/GitPython-3.1.14-py3-none-any.whl\r\ngreenlet @ file:///home/void/.cache/pypoetry/artifacts/ec/cd/50/631d3cee3e8163d49884ac822731ba5854db56ef007f7b3d1687c12e99/greenlet-1.0.0-cp37-cp37m-manylinux2010_x86_64.whl\r\nh5py @ file:///home/void/.cache/pypoetry/artifacts/5f/5a/4c/0ae2db5f88cf83abf33db3ffa364e0a90e13d7a75cde8560e9c3981af7/h5py-3.2.1-cp37-cp37m-manylinux1_x86_64.whl\r\nidentify @ file:///home/void/.cache/pypoetry/artifacts/3a/22/ae/4b0b0071dcc3a4ac84f7e5968b9064201a9e64d5be0ffc1864095cfd4d/identify-2.2.3-py2.py3-none-any.whl\r\nidna @ file:///home/void/.cache/pypoetry/artifacts/71/d9/bc/a8481f6ac8b5d0ecc0fbd34aca906ee68d1757f24fefbd0f4294c0c9d2/idna-2.10-py2.py3-none-any.whl\r\nimagesize @ file:///home/void/.cache/pypoetry/artifacts/b0/0c/4c/2da9b5d688f3d57232a399cd66d8f682f2246dff0008a0253eed36d086/imagesize-1.2.0-py2.py3-none-any.whl\r\nimportlib-metadata @ file:///home/void/.cache/pypoetry/artifacts/31/fc/05/71417d693371ef10b30a9289eb98e554ae850569e049e4c7ba0dbe2e44/importlib_metadata-3.10.1-py3-none-any.whl\r\nipykernel @ file:///home/void/.cache/pypoetry/artifacts/50/d7/4f/776813e1bb58bc2288bef5ae69c62cc0710c62396910d1e6799f537c7c/ipykernel-5.5.3-py3-none-any.whl\r\nipython @ file:///home/void/.cache/pypoetry/artifacts/1b/f6/06/a4687a1a1ea57b27c1a2879652854425a44bd41192c02f799f1aaef247/ipython-7.22.0-py3-none-any.whl\r\nipython-genutils @ file:///home/void/.cache/pypoetry/artifacts/2c/69/c6/e1f2fd156ee87f59d0c32acc921a0da31121b0c7c192b1b9ac0908111d/ipython_genutils-0.2.0-py2.py3-none-any.whl\r\nipywidgets @ file:///home/void/.cache/pypoetry/artifacts/83/db/53/e89cbc09943d34d82339a205aa58c225bb26c9cb2cc104716f9c5bfeba/ipywidgets-7.6.3-py2.py3-none-any.whl\r\nisort @ file:///home/void/.cache/pypoetry/artifacts/4d/3d/1d/2bf08f2c5646377d4283866820ce20c18eb1615dec01e7288eefbf8695/isort-4.3.21-py2.py3-none-any.whl\r\njedi @ file:///home/void/.cache/pypoetry/artifacts/1b/c9/89/e6d1f3a2cb2069fa5cacdaf2b474f924b727f0c38edd54d886e07a75bc/jedi-0.18.0-py2.py3-none-any.whl\r\nJinja2 @ file:///home/void/.cache/pypoetry/artifacts/47/18/a4/1905063a877fa68496ecb2e347fc04c431948d96cf825a0960da5791e0/Jinja2-2.11.3-py2.py3-none-any.whl\r\njmespath @ file:///home/void/.cache/pypoetry/artifacts/a9/2b/32/eb9ed41e3f5118971d1741c1299d1e7a70ca4345e5898d5a5d663bfd5f/jmespath-0.10.0-py2.py3-none-any.whl\r\njoblib @ file:///home/void/.cache/pypoetry/artifacts/31/29/01/db4dcbbea55316357053572689a218c92920416d025fcdf575ed68d0c9/joblib-1.0.1-py3-none-any.whl\r\njsonnet @ file:///home/void/.cache/pypoetry/artifacts/fd/e3/b2/346cba762f726f74df60a0c229bb69087d9f3a06df6d4cf7ae8d0ba9d2/jsonnet-0.17.0.tar.gz\r\njsonschema @ file:///home/void/.cache/pypoetry/artifacts/a2/e2/79/5896dfe12b442a5a7583226fb0d61aec227575025e5ac51deecf719547/jsonschema-3.2.0-py2.py3-none-any.whl\r\njupyter @ file:///home/void/.cache/pypoetry/artifacts/12/56/8a/0c3f4ff4bf0613de3a1020ba2cb4f35919d4d55f3f364cc7b217f63a4c/jupyter-1.0.0-py2.py3-none-any.whl\r\njupyter-client @ file:///home/void/.cache/pypoetry/artifacts/75/86/a0/f28d8ede7e50d46c1394e240dcd1c2706cfdef4313f6fb502474491a75/jupyter_client-6.2.0-py3-none-any.whl\r\njupyter-console @ file:///home/void/.cache/pypoetry/artifacts/99/c8/ec/2de2d0ccfb90fe23e9752664cae6e94c963c37391f2ff44cfbbf5bfa31/jupyter_console-6.4.0-py3-none-any.whl\r\njupyter-core @ file:///home/void/.cache/pypoetry/artifacts/6c/b4/0a/8912b11fb38e65e26cdf07a09561b340b0a6f4f5cc4b03dc17f8f678db/jupyter_core-4.7.1-py3-none-any.whl\r\njupyterlab-pygments @ file:///home/void/.cache/pypoetry/artifacts/92/13/97/3ba1dbd6e97ac9bf843bceb4d66902ecd4dab945d10002cc16d0daa1d8/jupyterlab_pygments-0.1.2-py2.py3-none-any.whl\r\njupyterlab-widgets @ file:///home/void/.cache/pypoetry/artifacts/d9/bd/77/52835917d713d609702eab7cb97fdae0bb6c8c66ff068eb0dc62fd6bc8/jupyterlab_widgets-1.0.0-py3-none-any.whl\r\nlmdb @ file:///home/void/.cache/pypoetry/artifacts/66/40/81/8353114c19e9fedaca18f9af102abcf29fb8c18fec3b305ffba050d4bb/lmdb-1.2.0-cp37-cp37m-manylinux2010_x86_64.whl\r\nm2r @ file:///home/void/.cache/pypoetry/artifacts/76/16/4d/be80e6cd238bb41bb57dd8f2b2ec41716bd5c298140206f363d434c080/m2r-0.2.1.tar.gz\r\nMako @ file:///home/void/.cache/pypoetry/artifacts/95/cd/6c/b720114a151a63afb11ee90775d2d6543c40b925c7e1d30290d7496594/Mako-1.1.4-py2.py3-none-any.whl\r\nMarkupSafe @ file:///home/void/.cache/pypoetry/artifacts/cd/da/a5/4cfa20f311002e7588045a07491e292e7fb819fcc777144055b7c7ba89/MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl\r\nmarshmallow @ file:///home/void/.cache/pypoetry/artifacts/bf/03/40/3eadfe49de5c4d68198fb3901ac2691f77ad8fa480f0786256aee0714c/marshmallow-3.11.1-py2.py3-none-any.whl\r\nmarshmallow-polyfield @ file:///home/void/.cache/pypoetry/artifacts/85/27/e8/aec375b960a3f69ffde88981dd1211e65b7b7a692a8b44a3778acebf38/marshmallow_polyfield-5.10-py3-none-any.whl\r\nmccabe @ file:///home/void/.cache/pypoetry/artifacts/c2/cd/ed/3c4495a1422fb12eefbca8b3c6ccc83ab4ec92fd39df029199cc4f4ee4/mccabe-0.6.1-py2.py3-none-any.whl\r\nmistune @ file:///home/void/.cache/pypoetry/artifacts/80/fd/6c/c86cb01dda756e2e899197f574484928622e9ad453d90761abac9e1948/mistune-0.8.4-py2.py3-none-any.whl\r\nmore-itertools @ file:///home/void/.cache/pypoetry/artifacts/36/5e/6e/086e365056443ea7340684bae7e448349db3e9ed8be4d1f089f351b2e2/more_itertools-8.7.0-py3-none-any.whl\r\nmurmurhash @ file:///home/void/.cache/pypoetry/artifacts/6f/20/56/fb7c026c670b5c29fee53124be83411e1a7de6d85ed8daaca7589e9871/murmurhash-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl\r\nmypy @ file:///home/void/.cache/pypoetry/artifacts/ba/8d/14/63dc6e4251a288ca5cf70b45458c5e898780ab477364ebe918a3119997/mypy-0.790-cp37-cp37m-manylinux1_x86_64.whl\r\nmypy-extensions @ file:///home/void/.cache/pypoetry/artifacts/41/fb/ef/133cd18a3e22a06b8d77dfe2ba71c50c509e4d2484ee619c6631c0b5b2/mypy_extensions-0.4.3-py2.py3-none-any.whl\r\nnbclient @ file:///home/void/.cache/pypoetry/artifacts/92/7a/49/4c2666fa49a3f47e490b88dca3aaa53a92db0c1c3bf101db29b6c43164/nbclient-0.5.3-py3-none-any.whl\r\nnbconvert @ file:///home/void/.cache/pypoetry/artifacts/9f/b0/34/add1712e9bfa620ab77d2d5d5603591edc85cd6c4ba1a40b4385befda2/nbconvert-6.0.7-py3-none-any.whl\r\nnbformat @ file:///home/void/.cache/pypoetry/artifacts/0b/d3/e5/88a4198def0d0bfda1c57a758546b5d2f7bd8edd3dc9be0b71555110ba/nbformat-5.1.3-py3-none-any.whl\r\nnest-asyncio @ file:///home/void/.cache/pypoetry/artifacts/a6/03/5a/2c77454326bb7a0a235ae4a78437c007a6ef2631cf40b34da26b5729c4/nest_asyncio-1.5.1-py3-none-any.whl\r\nnitpick @ file:///home/void/.cache/pypoetry/artifacts/a5/20/b8/993266cc8ff195f92efb6ab96bd376eece4f04a7eaa5f7e7aeb9f52dfd/nitpick-0.23.1-py3-none-any.whl\r\nnltk @ file:///home/void/.cache/pypoetry/artifacts/59/92/71/a8c5b581863e7e25355f9e4468c27343f31b423976941e6325acd0554f/nltk-3.6.1-py3-none-any.whl\r\nnotebook @ file:///home/void/.cache/pypoetry/artifacts/8c/7f/b5/1734baadda7ddfda9a357cbc94c4eb7756a74fe40add4a4ab3a87bc828/notebook-6.3.0-py3-none-any.whl\r\nnumpy @ file:///home/void/.cache/pypoetry/artifacts/9b/29/b8/7e795a24270a4c1f149286b044e1aafd59ce92bdaad676b7d44ae8187f/numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl\r\noptuna @ file:///home/void/.cache/pypoetry/artifacts/fa/68/90/ceaf47da1b66a35a3fdc4b6e24b06bf9f88e233b5f739e430bd13d9d4c/optuna-2.7.0-py3-none-any.whl\r\noverrides @ file:///home/void/.cache/pypoetry/artifacts/84/72/62/00a8159d8d9cee75aefc43667435b680f1683000bf235588b78014f01f/overrides-3.1.0.tar.gz\r\npackaging @ file:///home/void/.cache/pypoetry/artifacts/bf/c9/4b/d4c56a8494978126d690da73a04dfe71b97fa991e52f1634afc46f263e/packaging-20.9-py2.py3-none-any.whl\r\npandas @ file:///home/void/.cache/pypoetry/artifacts/20/e6/0f/feac64ed8cd0e30be8e53f5127de980b8319f906615c21c8b7b5400296/pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl\r\npandocfilters @ file:///home/void/.cache/pypoetry/artifacts/95/80/e1/8047532d4a0988efe4c86231e4aede0125e9bb1dcd96dc7208e29099e6/pandocfilters-1.4.3.tar.gz\r\nparso @ file:///home/void/.cache/pypoetry/artifacts/dc/ff/07/1556e66e77c039a21cd51bc0de4c5777b35569c3903674997b2cdfb9f5/parso-0.8.2-py2.py3-none-any.whl\r\npathtools @ file:///home/void/.cache/pypoetry/artifacts/32/fd/91/3eef9683d97849cbd83965bdeee1d1c174066836230a13c775c457fa99/pathtools-0.1.2.tar.gz\r\npathy @ file:///home/void/.cache/pypoetry/artifacts/96/c6/de/613b8d4b2f063d538d827205a59b4b0d5370682ea65102e29a5f658c6d/pathy-0.4.0-py3-none-any.whl\r\npbr @ file:///home/void/.cache/pypoetry/artifacts/30/01/4f/39bfa10a7db631fdb8d04545f995c48353f33404db8ad29f7b3ab7847b/pbr-5.5.1-py2.py3-none-any.whl\r\npep8-naming @ file:///home/void/.cache/pypoetry/artifacts/0d/f2/0c/77ac3ab0d1cfa522f402e523b7fb4e93fe039c5f6ad9ecec1d783871ed/pep8_naming-0.9.1-py2.py3-none-any.whl\r\npexpect @ file:///home/void/.cache/pypoetry/artifacts/ac/ff/fd/e4fa201b733fa24e77b6e0f8e1a2e0e9d4bd7cb1936861c9b12e4653a0/pexpect-4.8.0-py2.py3-none-any.whl\r\npickleshare @ file:///home/void/.cache/pypoetry/artifacts/e3/49/c6/dda859db430eaa2b27acc6a8bab879e41d2bf09e99f792343ccc9d1fef/pickleshare-0.7.5-py2.py3-none-any.whl\r\nPillow @ file:///home/void/.cache/pypoetry/artifacts/33/2c/8b/596c551987d35a45fb1ec5bca0f603038a9d768054d449544befaede0e/Pillow-8.2.0-cp37-cp37m-manylinux1_x86_64.whl\r\npluggy @ file:///home/void/.cache/pypoetry/artifacts/bc/2e/c9/c04063460a7a68d2e59c9ea0a673de9d7930d54f788ed0510cdcf8aa78/pluggy-0.13.1-py2.py3-none-any.whl\r\npreshed @ file:///home/void/.cache/pypoetry/artifacts/2a/eb/44/6c826ae0ffba371a4f27e852dfee9ef9ffbfb3f6652cbbd380b42f6f4e/preshed-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl\r\nprettytable @ file:///home/void/.cache/pypoetry/artifacts/a9/0c/6c/03413065886102725c74f371e697bf00d608e02fcc1fadfc86e38b239a/prettytable-2.1.0-py3-none-any.whl\r\nprometheus-client @ file:///home/void/.cache/pypoetry/artifacts/0b/d6/f7/38818ac7b9cdc0284e61fcdf0611a28821f2590cc115109e0dbaca44a6/prometheus_client-0.10.1-py2.py3-none-any.whl\r\npromise @ file:///home/void/.cache/pypoetry/artifacts/2b/c7/61/34271997f7584c0fed7a921acc0b1fdf77a383cbed4844419c4e8a3d83/promise-2.3.tar.gz\r\nprompt-toolkit @ file:///home/void/.cache/pypoetry/artifacts/42/43/a5/0a3723dadc2a4c0c2daa3c0f1616bec63165729f3b7611a888dea550a4/prompt_toolkit-3.0.18-py3-none-any.whl\r\nprotobuf @ file:///home/void/.cache/pypoetry/artifacts/d7/0d/8c/079c0f0d7b3e2630df6660e993b5ee1a584fdd0dd5fe77b36d0b0444e5/protobuf-3.15.8-cp37-cp37m-manylinux1_x86_64.whl\r\npsutil @ file:///home/void/.cache/pypoetry/artifacts/e7/ee/ed/9817a6e3fa8217c13cf17b1bb44507668f1cfd9f057aaf816c8762f172/psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl\r\nptyprocess @ file:///home/void/.cache/pypoetry/artifacts/af/cd/8c/c1510ca357886f8af9948e5555f25db9e360b1dd798566e6e9540c3442/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npy @ file:///home/void/.cache/pypoetry/artifacts/56/1d/e3/7dad75e1bf797fbd8937b37dd43d1656357c67a199e9f54d48535697d0/py-1.10.0-py2.py3-none-any.whl\r\npycodestyle @ file:///home/void/.cache/pypoetry/artifacts/a5/4d/b8/38f79509a4c7ac2a12983ce715595e1f983965f0e4c03d632074c05eec/pycodestyle-2.7.0-py2.py3-none-any.whl\r\npycparser @ file:///home/void/.cache/pypoetry/artifacts/44/e9/07/88a70ff44631b83a33a8011053104dffbca00761b983eff85051639df2/pycparser-2.20-py2.py3-none-any.whl\r\npydantic @ file:///home/void/.cache/pypoetry/artifacts/a2/97/d0/ea9e192cb9618b7c2e414860077a8353f5153e377eab0aba2e3844f50e/pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl\r\npydocstyle @ file:///home/void/.cache/pypoetry/artifacts/72/0e/e5/0e72e0766b925b9443bad8038924832aaa21007eac3e41da5c3cd22bf4/pydocstyle-6.0.0-py3-none-any.whl\r\npyflakes @ file:///home/void/.cache/pypoetry/artifacts/23/7e/52/ea1293b6028d8abc80bab40d1d20c22ae4fb0290b35f06541da7cab403/pyflakes-2.3.1-py2.py3-none-any.whl\r\nPygments @ file:///home/void/.cache/pypoetry/artifacts/14/df/54/07ac62d5eed39cfb52f6439b1afc41e12a205a48755bd7586dda35e565/Pygments-2.8.1-py3-none-any.whl\r\npyparsing @ file:///home/void/.cache/pypoetry/artifacts/78/8b/03/23dc60df50f099a658dd13c86d7d94564b0b86bfa2ff61bc9595fb2fcb/pyparsing-2.4.7-py2.py3-none-any.whl\r\npyperclip @ file:///home/void/.cache/pypoetry/artifacts/32/88/cb/8cae34dd62a8a0152e9b330698cfdb022deb2f066b7944acf5511dfd6f/pyperclip-1.8.2.tar.gz\r\npyrsistent @ file:///home/void/.cache/pypoetry/artifacts/82/fd/98/fab6ad55bd376f1da134a3376cf61717a18104b408383b860716048249/pyrsistent-0.17.3.tar.gz\r\npytest @ file:///home/void/.cache/pypoetry/artifacts/a8/5a/78/7536a0da5c14b85637968b588ecf3bde096ce084658eab4180c94412fa/pytest-5.4.3-py3-none-any.whl\r\npytest-cov @ file:///home/void/.cache/pypoetry/artifacts/68/74/14/7ce422aeb24fffce22002e5981b110ae5719e0673fd0f8b053011944bf/pytest_cov-2.11.1-py2.py3-none-any.whl\r\npytest-randomly @ file:///home/void/.cache/pypoetry/artifacts/83/d8/d1/7651b8757550ced3b9754eee50cce8cc9d184de1ef7e756db8d960f0e1/pytest_randomly-3.7.0-py3-none-any.whl\r\npython-dateutil @ file:///home/void/.cache/pypoetry/artifacts/75/fa/68/ee8cf8ee229ebfb7947af0398184c39bbf243b7dc67ee46cca45938d09/python_dateutil-2.8.1-py2.py3-none-any.whl\r\npython-editor @ file:///home/void/.cache/pypoetry/artifacts/51/f9/12/c230460443322196110063793391d5d4ca9aabe0c697c4f402c32c5453/python_editor-1.0.4-py3-none-any.whl\r\npython-slugify @ file:///home/void/.cache/pypoetry/artifacts/55/f6/8f/1a0d0963c09d17ff4da7c7cec7183ab25e957e42a8e27d635c613d64c8/python-slugify-4.0.1.tar.gz\r\npytz @ file:///home/void/.cache/pypoetry/artifacts/0c/d0/94/bbd2fee71be292862261e85cefb2231b1df628c7a0e5cb0170d8304963/pytz-2021.1-py2.py3-none-any.whl\r\nPyYAML @ file:///home/void/.cache/pypoetry/artifacts/17/3c/f6/dd4498c1b6b7cdef0517d1e5c0a56e52886d36350589195788eed24d29/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl\r\npyzmq @ file:///home/void/.cache/pypoetry/artifacts/dd/a2/24/c8ec691e3ac51d6df3c9b91bc06a2d49ba9f99af4146527b6efb3c3585/pyzmq-22.0.3-cp37-cp37m-manylinux1_x86_64.whl\r\nqtconsole @ file:///home/void/.cache/pypoetry/artifacts/b6/7c/3e/f5d07f4ef3164595943d3e3dbd7a718b9cdb77a8e888af66af246b0d11/qtconsole-5.0.3-py3-none-any.whl\r\nQtPy @ file:///home/void/.cache/pypoetry/artifacts/8d/c8/7b/f07109a6dc6b92fe95473bd29a9abd2432c5117aba360c912a681384f4/QtPy-1.9.0-py2.py3-none-any.whl\r\nregex @ file:///home/void/.cache/pypoetry/artifacts/5b/86/c7/caf2fd4e0eace88a30e3b2109f1587ce13a19f81611406f179c9dd3754/regex-2021.4.4-cp37-cp37m-manylinux2014_x86_64.whl\r\nrequests @ file:///home/void/.cache/pypoetry/artifacts/f2/13/b8/cc7ac8d0aa2630507c04c2c0e72307bed4ee7e2c92d7c3d97a5d61e74e/requests-2.25.1-py2.py3-none-any.whl\r\nrestructuredtext-lint @ file:///home/void/.cache/pypoetry/artifacts/d8/9d/f9/d7f05191e8128f58b61dbdb962c85f40a4c14da47d397adcfe27d98193/restructuredtext_lint-1.3.2.tar.gz\r\nruamel.yaml @ file:///home/void/.cache/pypoetry/artifacts/82/7e/93/51925fb555452a6bea3fbc3f42bc1d342af303339634400c4f154a3fa5/ruamel.yaml-0.17.4-py3-none-any.whl\r\nruamel.yaml.clib @ file:///home/void/.cache/pypoetry/artifacts/a9/eb/ab/743349c1b48fce4dedaaab59b2ab0ced108f6c46161b470a5dd01a9f50/ruamel.yaml.clib-0.2.2-cp37-cp37m-manylinux1_x86_64.whl\r\ns3transfer @ file:///home/void/.cache/pypoetry/artifacts/0f/3e/bc/9588da108fc381717df2b2c71aa60bb824766e14f18fd46e4abf99dd67/s3transfer-0.3.7-py2.py3-none-any.whl\r\nsacremoses @ file:///home/void/.cache/pypoetry/artifacts/3b/67/ce/fc1e875ccddd89c0fc964d30eb160ce43474fa74836f2d9166c44fa5d0/sacremoses-0.0.44.tar.gz\r\nsafety @ file:///home/void/.cache/pypoetry/artifacts/d6/12/3a/0fada211c21fd9e66dfb15b64d9f8d21351c22702f61cd7a73594ee1de/safety-1.10.3-py2.py3-none-any.whl\r\nscikit-learn @ file:///home/void/.cache/pypoetry/artifacts/88/94/54/5c47ee3b72e9562608bad938570faf87e8381dcf99415a79dcfc865ad0/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl\r\nscipy @ file:///home/void/.cache/pypoetry/artifacts/e5/3e/a7/b69534d16cae11353f6db73f0fd62d7fc874f1640bd9d39fcc878d355e/scipy-1.6.1-cp37-cp37m-manylinux1_x86_64.whl\r\nSend2Trash @ file:///home/void/.cache/pypoetry/artifacts/65/5c/cf/74efc7119c07b06a3e5f3f1e4ffc62bd28315db7decee27e42ff7f5ee0/Send2Trash-1.5.0-py3-none-any.whl\r\nsentencepiece @ file:///home/void/.cache/pypoetry/artifacts/92/8f/92/0b4cb42c5fec658fb16785c669dd7eb4dbe925d8da8d6b0c12e2a151d9/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl\r\nsentry-sdk @ file:///home/void/.cache/pypoetry/artifacts/ec/58/9c/e73bd625efad4210888b269864ba3641df4516a9582f6722cf05ca0ac4/sentry_sdk-1.0.0-py2.py3-none-any.whl\r\nshortuuid @ file:///home/void/.cache/pypoetry/artifacts/83/75/5a/5955701463bbd5516b72ab60b68f3c5d7a4b513b2a7dddb58a96d6d071/shortuuid-1.0.1-py3-none-any.whl\r\nsiamenc==0.1.0\r\nsix @ file:///home/void/.cache/pypoetry/artifacts/e3/96/48/99c14ba5c6276fbf4dc2e216553590ec97b52e685863f73e39550418c5/six-1.15.0-py2.py3-none-any.whl\r\nsmart-open @ file:///home/void/.cache/pypoetry/artifacts/0f/33/80/1b361e7af0ed7288b20ed6c741e374857e5e832f84e73781e4226ba661/smart_open-3.0.0.tar.gz\r\nsmmap @ file:///home/void/.cache/pypoetry/artifacts/65/5b/7b/613313a5462b9286d173319b5c72030d91a09050eb726ee603f33ef524/smmap-4.0.0-py2.py3-none-any.whl\r\nsnowballstemmer @ file:///home/void/.cache/pypoetry/artifacts/1b/e7/37/c1ccd5c7451e2f738886b093508276afa6237726b3b8c391d26c98ddee/snowballstemmer-2.1.0-py2.py3-none-any.whl\r\nsortedcontainers @ file:///home/void/.cache/pypoetry/artifacts/f5/2e/d6/fb0cc783ac71136be1df7a9851a4f60077d0e2b8e662ce731e3a3c346c/sortedcontainers-2.3.0-py2.py3-none-any.whl\r\nsoupsieve @ file:///home/void/.cache/pypoetry/artifacts/6c/8d/4c/47458f64b200cf946383fd0d3e5498170178ef711558d4ef50c5f1e951/soupsieve-2.2.1-py3-none-any.whl\r\nspacy @ file:///home/void/.cache/pypoetry/artifacts/a7/4c/c1/278f97aabcf79dd734eac17a3588b6bc6c8621e050c173e69067786902/spacy-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl\r\nspacy-legacy @ file:///home/void/.cache/pypoetry/artifacts/f0/d3/d6/eca1889d307c0c12efde065b6fb3bcfb25a5c74d153c26626e11518bc4/spacy_legacy-3.0.2-py2.py3-none-any.whl\r\nSphinx @ file:///home/void/.cache/pypoetry/artifacts/48/f8/fa/28d5d3671759e44d1cde56947b9eee6b9007ec92bf008e9652aaa70220/Sphinx-2.4.4-py3-none-any.whl\r\nsphinx-autodoc-typehints @ file:///home/void/.cache/pypoetry/artifacts/c2/1b/5c/4c527daa01c9c515303fd7dae1c2fc68dd2a925a9256502d302ae32e6f/sphinx_autodoc_typehints-1.10.3-py3-none-any.whl\r\nsphinxcontrib-applehelp @ file:///home/void/.cache/pypoetry/artifacts/cc/cf/dd/8ba7c4afe2ff84e7204886e2fd837495627b3827a21925726fcc3125d1/sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl\r\nsphinxcontrib-devhelp @ file:///home/void/.cache/pypoetry/artifacts/59/da/dc/900e02cc5452883e989929e3784c1a7094cd7326af3cf4a6d8bb225055/sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl\r\nsphinxcontrib-htmlhelp @ file:///home/void/.cache/pypoetry/artifacts/11/b9/f6/329734fa1be1c805096ac23381f177cd4cc617499095ab385fce82bd95/sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl\r\nsphinxcontrib-jsmath @ file:///home/void/.cache/pypoetry/artifacts/7f/d8/ef/31320102fc49e5beeb72d480f0dab2dc5429fbd8cedf45817e2320d58e/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\r\nsphinxcontrib-qthelp @ file:///home/void/.cache/pypoetry/artifacts/81/5b/46/baf9bd9c58b789d2ff445165e5859021ea31139602fffcc773c39da86b/sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl\r\nsphinxcontrib-serializinghtml @ file:///home/void/.cache/pypoetry/artifacts/6a/e9/75/0afa870282075cec7b4aea1f133464212c82722b3cb72319d359cae77f/sphinxcontrib_serializinghtml-1.1.4-py2.py3-none-any.whl\r\nSQLAlchemy @ file:///home/void/.cache/pypoetry/artifacts/7f/42/44/655528faa76d83aec61bdced2f43e6a00416851a6fb609d9b2f42b77e4/SQLAlchemy-1.4.8-cp37-cp37m-manylinux2014_x86_64.whl\r\nsrsly @ file:///home/void/.cache/pypoetry/artifacts/7f/0e/05/c232e06f54f2c934727088bb73fbdabb194b37a53cc6fdfa3e67150180/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl\r\nstevedore @ file:///home/void/.cache/pypoetry/artifacts/64/3f/af/b25f40ac10bc9dafd39a798374d310acd1a62b0e9c3a432f7862a1de9e/stevedore-3.3.0-py3-none-any.whl\r\nsubprocess32 @ file:///home/void/.cache/pypoetry/artifacts/b6/a9/6e/74893ca81a4fe350238b027043f45690982bcbe3eb5edad507333c2de9/subprocess32-3.5.4.tar.gz\r\ntensorboardX @ file:///home/void/.cache/pypoetry/artifacts/59/da/a0/4ecae9c6e8f53733e1441997534f8008834bf3aaf5d7c6bfa9271f953c/tensorboardX-2.2-py2.py3-none-any.whl\r\nterminado @ file:///home/void/.cache/pypoetry/artifacts/d7/3f/73/57ecce9aba58022bc076bf9c923dc98b8fa13c2ed9fa7aad4c9e8231a6/terminado-0.9.4-py3-none-any.whl\r\ntestfixtures @ file:///home/void/.cache/pypoetry/artifacts/b2/d7/f8/e32b667c1a1326308364cc8415842331f55cee16d4bf84aeb7b00da260/testfixtures-6.17.1-py2.py3-none-any.whl\r\ntestpath @ file:///home/void/.cache/pypoetry/artifacts/20/41/61/40209212e3cc4ead6910ce1a83532987e232f01564d9e48fd1c1e2e12e/testpath-0.4.4-py2.py3-none-any.whl\r\ntext-unidecode @ file:///home/void/.cache/pypoetry/artifacts/71/f3/8c/83d57454c286b52f0f4545f78a5b77a274ee5bed5a42bc456e99c86023/text_unidecode-1.3-py2.py3-none-any.whl\r\nthinc @ file:///home/void/.cache/pypoetry/artifacts/9f/dc/7b/e47192857a9ad48df1d6570eced12ec83753ae1a6f4302d7dc23c0b96d/thinc-8.0.2-cp37-cp37m-manylinux2014_x86_64.whl\r\nthreadpoolctl @ file:///home/void/.cache/pypoetry/artifacts/10/d2/ec/b7f7827e6b16466e651b5a2ea18c64362ff41a15e221a88cc3064fb4dd/threadpoolctl-2.1.0-py3-none-any.whl\r\ntokenizers @ file:///home/void/.cache/pypoetry/artifacts/42/ff/97/038f38b3b1ad8266412d2e22edbba67fbc90e5ef71635c466a9117069a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl\r\ntoml @ file:///home/void/.cache/pypoetry/artifacts/ee/b4/26/b53b77a5db04c373edfec4046f6e15ab8a6dfbbaee30dcacd447b71c50/toml-0.10.0-py2.py3-none-any.whl\r\ntomlkit @ file:///home/void/.cache/pypoetry/artifacts/08/92/ad/3abffc10fb9db6842e047f90088ce25422c9eec5bf89f072620174120f/tomlkit-0.7.0-py2.py3-none-any.whl\r\ntorch @ file:///home/void/.cache/pypoetry/artifacts/21/c1/64/b18b0b42910be9b56e39d47eca39e249559304dcb7f7f0611b494df2d1/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl\r\ntorchvision @ file:///home/void/.cache/pypoetry/artifacts/09/3f/7e/c68656cce106803dad58bbe37993ad8c8549aa2362536e8ef70825dc00/torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl\r\ntornado @ file:///home/void/.cache/pypoetry/artifacts/73/ac/41/70b315914d448001a26418a2337c0a55911086b3a31a87013f55e807eb/tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl\r\ntqdm @ file:///home/void/.cache/pypoetry/artifacts/06/df/97/93c62ddbda15a68b2cb12a43b5f6a574d87f007c0605bccab122f5912e/tqdm-4.60.0-py2.py3-none-any.whl\r\ntraitlets @ file:///home/void/.cache/pypoetry/artifacts/25/0f/c0/2c71bbe86bec170e00a2ee9ef2af2df7b4504fbaf1e8e717622fd1d5b4/traitlets-5.0.5-py3-none-any.whl\r\ntransformers @ file:///home/void/.cache/pypoetry/artifacts/c0/1e/f0/c6485ae2555a0983158477ce44f6c9d410e65c47eebb2bda0380870055/transformers-4.5.1-py3-none-any.whl\r\ntyped-ast @ file:///home/void/.cache/pypoetry/artifacts/fe/7c/53/86cd82215775e7707b6f7cafaeed6802f93f0856a8371b0e15bc85d3c6/typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl\r\ntyper @ file:///home/void/.cache/pypoetry/artifacts/a1/4c/87/b93e3198d1bd31e5566da8c5edc193d36137b6801bb5cf651c4814fc13/typer-0.3.2-py3-none-any.whl\r\ntyping-extensions @ file:///home/void/.cache/pypoetry/artifacts/5a/dd/8f/5dc09cb3732cb0be9ecae5854eaa6aa0d4cd95752163c65283ecf9bd34/typing_extensions-3.7.4.3-py3-none-any.whl\r\nurllib3 @ file:///home/void/.cache/pypoetry/artifacts/54/b1/a1/ccbf6b869ccdaff965957abdd8e3e5aa4bee1533ed104a0d11bdc07a61/urllib3-1.26.4-py2.py3-none-any.whl\r\nwandb @ file:///home/void/.cache/pypoetry/artifacts/58/4a/7f/dec1795f5dd94d975be86acc8a335009da474696dee5d7ffd13bc93a5c/wandb-0.10.26-py2.py3-none-any.whl\r\nwasabi @ file:///home/void/.cache/pypoetry/artifacts/e9/07/cd/2f2259f00529ab2503644597edaa1bb14539b96fa7db82c95d03fce7e1/wasabi-0.8.2-py3-none-any.whl\r\nwcwidth @ file:///home/void/.cache/pypoetry/artifacts/92/12/86/71fde978823bd982c22bd549b0ba688e372403269396c892ac8160f4fe/wcwidth-0.2.5-py2.py3-none-any.whl\r\nwebencodings @ file:///home/void/.cache/pypoetry/artifacts/8e/39/d4/1735c959b3d85bebf80692957fe8ad83a2cb27de46bb08a6ababe12c44/webencodings-0.5.1-py2.py3-none-any.whl\r\nwemake-python-styleguide @ file:///home/void/.cache/pypoetry/artifacts/6e/95/41/d3af6c762397b478511953f9cea56887cffef04cd12516ff51bcfe3ad3/wemake_python_styleguide-0.14.1-py3-none-any.whl\r\nwidgetsnbextension @ file:///home/void/.cache/pypoetry/artifacts/df/8c/62/03b8d5e9a4adf6311653006eb285482908f2bf68cc88ba5c00ddc0df1c/widgetsnbextension-3.5.1-py2.py3-none-any.whl\r\nzipp @ file:///home/void/.cache/pypoetry/artifacts/16/0e/ae/e94ff238fe5d8b11b4eeb35f0ee94fd9f1b0d2182a3d47e3253ce47360/zipp-3.4.1-py3-none-any.whl\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nHere is the configuration I am using.\r\n\r\n<details>\r\n<summary><b>Configuration:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nlocal model_name = \"models/distilroberta-base-msmarco-v2/\";\r\nlocal num_gpus = 8;\r\nlocal data_base_url = \"data/SWPt512/\";\r\nlocal model = \"siamese_retrieval\";\r\nlocal base_dataset_reader = {\r\n    \"type\": \"retrieval\",\r\n    \"query_tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": model_name,\r\n      \"max_length\": 500,\r\n    },\r\n    \"query_token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": model_name,\r\n        \"namespace\": \"tokens\"\r\n      }\r\n    },\r\n};\r\n\r\n{\r\n  \"train_data_path\": data_base_url + \"valid/*.tsv\",\r\n  \"validation_data_path\": data_base_url + \"valid/2445n7jblu53lkvipo2gmm5ooq.tsv\",\r\n  \"dataset_reader\": {\r\n    \"type\": \"sharded\",\r\n    \"base_reader\": base_dataset_reader,\r\n  },\r\n  \"validation_dataset_reader\": base_dataset_reader,\r\n  'model': {\r\n    'type': model,\r\n    'transformer_model': model_name,\r\n  },\r\n  \"data_loader\": {\r\n    \"type\": \"multiprocess\",\r\n    \"batch_size\": 96,\r\n    \"shuffle\": true,\r\n    \"num_workers\": 8,\r\n    \"max_instances_in_memory\": 8800,\r\n  },\r\n  \"validation_data_loader\": {\r\n    \"type\": \"multiprocess\",\r\n    \"batch_size\": 96,\r\n    \"shuffle\": false,\r\n    \"num_workers\": 0,\r\n  },\r\n  \"distributed\": {\r\n    \"cuda_devices\": if num_gpus > 1 then std.range(0, num_gpus - 1) else 0,\r\n  },\r\n  \"trainer\": {\r\n    \"num_epochs\": 10,\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"lr\": 3e-5,\r\n      \"betas\": [0.9, 0.999],\r\n      \"eps\": 1e-8,\r\n      \"correct_bias\": true\r\n    },\r\n    \"learning_rate_scheduler\": {\r\n      \"type\": \"polynomial_decay\",\r\n    },\r\n    \"use_amp\": true,\r\n    \"grad_norm\": 1.0,\r\n    \"validation_metric\": \"+rec5\",\r\n    \"patience\": 3,\r\n  }\r\n}\r\n```\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5136/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5136/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5132", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5132/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5132/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5132/events", "html_url": "https://github.com/allenai/allennlp/issues/5132", "id": 861497454, "node_id": "MDU6SXNzdWU4NjE0OTc0NTQ=", "number": 5132, "title": "Multiprocess Data Loader with num_workers > 0 throws error about token_indexers already being applied", "user": {"login": "vikigenius", "id": 12724810, "node_id": "MDQ6VXNlcjEyNzI0ODEw", "avatar_url": "https://avatars.githubusercontent.com/u/12724810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vikigenius", "html_url": "https://github.com/vikigenius", "followers_url": "https://api.github.com/users/vikigenius/followers", "following_url": "https://api.github.com/users/vikigenius/following{/other_user}", "gists_url": "https://api.github.com/users/vikigenius/gists{/gist_id}", "starred_url": "https://api.github.com/users/vikigenius/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vikigenius/subscriptions", "organizations_url": "https://api.github.com/users/vikigenius/orgs", "repos_url": "https://api.github.com/users/vikigenius/repos", "events_url": "https://api.github.com/users/vikigenius/events{/privacy}", "received_events_url": "https://api.github.com/users/vikigenius/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2021-04-19T16:26:36Z", "updated_at": "2021-04-20T16:17:13Z", "closed_at": "2021-04-20T16:17:13Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nI created a custom dataset_reader and used sharded_dataset_reader for dealing with multiprocess_data_loader.\r\nHowever setting num_workers > 0 throws the following error\r\n\r\nThis does not happen with num_workers = 0\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/void/miniconda3/envs/lexsiamese/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 119, in main\r\n    args.func(args)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/commands/train.py\", line 119, in train_model_from_args\r\n    file_friendly_logging=args.file_friendly_logging,\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/commands/train.py\", line 178, in train_model_from_file\r\n    file_friendly_logging=file_friendly_logging,\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/commands/train.py\", line 292, in train_model\r\n    params.duplicate(), serialization_dir, print_statistics=dry_run\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/training/util.py\", line 466, in make_vocab_from_params\r\n    data_loaders = data_loaders_from_params(params, serialization_dir=serialization_dir)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/training/util.py\", line 116, in data_loaders_from_params\r\n    data_loader_params.duplicate(), reader=dataset_reader, data_path=train_data_path\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 593, in from_params\r\n    **extras,\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 623, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 281, in __init__\r\n    deque(self.iter_instances(), maxlen=0)\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 369, in iter_instances\r\n    self._gather_instances(queue), desc=\"loading instances\"\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/tqdm/std.py\", line 1178, in __iter__\r\n    for obj in iterable:\r\n  File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 509, in _gather_instances\r\n    raise WorkerError(e, tb)\r\nallennlp.data.data_loaders.multiprocess_data_loader.WorkerError: worker raised ValueError(\"Found a TextField (query_tokens) with token_indexers already applied, but you're using num_workers > 0 in your data loader. Make sure your dataset reader's text_to_instance() method doesn't add any token_indexers to the TextFields it creates. Instead, the token_indexers should be added to the instances in the apply_token_indexers() method of your dataset reader (which you'll have to implement if you haven't done so already).\")\r\n\r\n  Traceback from worker:\r\n    File \"/home/void/miniconda3/envs/lexsiamese/lib/python3.7/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 467, in _instance_worker\r\n      f\"Found a TextField ({field_name}) with token_indexers already \"\r\n  ValueError: Found a TextField (query_tokens) with token_indexers already applied, but you're using num_workers > 0 in your data loader. Make sure your dataset reader's text_to_instance() method doesn't add any token_indexers to the TextFields it creates. Instead, the token_indexers should be added to the instances in the apply_token_indexers() method of your dataset reader (which you'll have to implement if you haven't done so already).\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nSetting num_workers to 0 does not throw this error\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux x86_64\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.10\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalabaster @ file:///home/void/.cache/pypoetry/artifacts/cd/37/e0/89f7da30c12075ae566ff3d8107abdbc74fd3d19ae5644765d79dd5d47/alabaster-0.7.12-py2.py3-none-any.whl\r\nalembic @ file:///home/void/.cache/pypoetry/artifacts/cb/39/9a/86b56862682b530f53ebb1e69e78f816f9f8d08b29ffc82509f2ef76ac/alembic-1.5.8-py2.py3-none-any.whl\r\nallennlp @ file:///home/void/.cache/pypoetry/artifacts/2b/5d/f1/e0ad9a1e311da16af778085f277fa0c6a40d19d052d93ffd410785deb2/allennlp-2.3.0-py3-none-any.whl\r\nallennlp-optuna @ file:///home/void/.cache/pypoetry/artifacts/1b/6c/5b/1cea8d351d1eb5e32c282cfc0e3acb07f4e71ab6bc3d8ac96025cadf64/allennlp_optuna-0.1.5-py3-none-any.whl\r\nargon2-cffi @ file:///home/void/.cache/pypoetry/artifacts/40/58/da/99ea4f10c652469eb6c623b269fb96784ed9bbdab439c3a5bd9d9afa6e/argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl\r\nastor @ file:///home/void/.cache/pypoetry/artifacts/5f/e9/ea/ff2986fae56c8b24978d6ca48a057f02e9e4845b5b9b499a2506121369/astor-0.8.1-py2.py3-none-any.whl\r\nasync-generator @ file:///home/void/.cache/pypoetry/artifacts/5a/c9/85/708dc64d76e0faea9f132181d1f9589bfab62218ac9bbef7d6cfc821d2/async_generator-1.10-py3-none-any.whl\r\nattrs @ file:///home/void/.cache/pypoetry/artifacts/ae/b3/61/38a043abdba5ba4c0c510dde549dd1c8278bf56262dc5df55c19133a02/attrs-20.3.0-py2.py3-none-any.whl\r\nBabel @ file:///home/void/.cache/pypoetry/artifacts/0d/6c/d0/f735d4d0af68640ee69adddc80d3ecf336156e84c4ccf2078c8fe9e38b/Babel-2.9.0-py2.py3-none-any.whl\r\nbackcall @ file:///home/void/.cache/pypoetry/artifacts/d9/1c/14/88957e7a43c92c6678d8ca482196186836144475c67d11ff02a4ee2194/backcall-0.2.0-py2.py3-none-any.whl\r\nbandit @ file:///home/void/.cache/pypoetry/artifacts/b1/65/70/cb20da954def2f182c80e2555654f456552633122e9f8f23425855b46b/bandit-1.7.0-py3-none-any.whl\r\nbeautifulsoup4 @ file:///home/void/.cache/pypoetry/artifacts/d7/4b/c2/1a65d7699a83c83aaec6fa35b97cb59760569be3e24f903ae4b55ac3a5/beautifulsoup4-4.9.3-py3-none-any.whl\r\nbleach @ file:///home/void/.cache/pypoetry/artifacts/0c/19/da/291df1a8b71e9bd208e3e6f801afd6567b9ef47036b167c11e25f5c96c/bleach-3.3.0-py2.py3-none-any.whl\r\nblis @ file:///home/void/.cache/pypoetry/artifacts/22/59/92/fbc277252d447c1eea4adf771a209657eb1d536c3f9b2b5bbdf10b5b45/blis-0.7.4-cp37-cp37m-manylinux2014_x86_64.whl\r\nboto3 @ file:///home/void/.cache/pypoetry/artifacts/f0/1c/4b/54fd3599e1872242dddd68dea523ba5440560ba56bcace6a5271a5b7fb/boto3-1.17.53-py2.py3-none-any.whl\r\nbotocore @ file:///home/void/.cache/pypoetry/artifacts/39/30/63/e4763d6e3afc7c0cececf6d2af2171c305849dd83c6725134b2db0ad14/botocore-1.20.53-py2.py3-none-any.whl\r\ncached-property @ file:///home/void/.cache/pypoetry/artifacts/38/d8/aa/b8baaf6448a0029023e15cbfc6e1a278d60cc2e2b022c94bc850561996/cached_property-1.5.2-py2.py3-none-any.whl\r\ncatalogue @ file:///home/void/.cache/pypoetry/artifacts/6b/d2/12/e162a59d9b422d9802b9dced62cc39ab69afbf475f9c64779bf2400ec5/catalogue-2.0.3-py3-none-any.whl\r\ncertifi==2020.12.5\r\ncffi @ file:///home/void/.cache/pypoetry/artifacts/25/db/72/24c31ee860d752b550f7744febafb4d2b3bfe3ada972f163ccdf8ae711/cffi-1.14.5-cp37-cp37m-manylinux1_x86_64.whl\r\nchardet @ file:///home/void/.cache/pypoetry/artifacts/f0/e1/66/f8ced421461f1dda06ea89af6ac51a22cf72ff0595f329808634559b2b/chardet-4.0.0-py2.py3-none-any.whl\r\nclick @ file:///home/void/.cache/pypoetry/artifacts/21/fd/0f/f7ff619e0ab099fc284ee2b24a86129d9dc3ad2a475dc304bbbbe20ecb/click-7.1.2-py2.py3-none-any.whl\r\ncliff @ file:///home/void/.cache/pypoetry/artifacts/4c/37/89/981a4be88fc94f7ff2523f5646f2994032111d85da21ad553e32f343fe/cliff-3.7.0-py3-none-any.whl\r\ncmaes @ file:///home/void/.cache/pypoetry/artifacts/08/1c/a2/065ada5c6a31f5b9a476c139ce2ca736614b5d9ffb65172565b46d5ec7/cmaes-0.8.2-py3-none-any.whl\r\ncmd2 @ file:///home/void/.cache/pypoetry/artifacts/c9/15/0e/8e818c612a709f0e313c624f3dfed5ee30c95d42e57f49fe80cb2cc4f6/cmd2-1.5.0-py3-none-any.whl\r\ncolorama @ file:///home/void/.cache/pypoetry/artifacts/33/a2/a4/09f68d0a2176d987da70e9dee0eaea3cc48f68b56a7fa8ac56c2d22dc7/colorama-0.4.4-py2.py3-none-any.whl\r\ncolorlog @ file:///home/void/.cache/pypoetry/artifacts/1c/08/cf/e706def39db46dc00865c88496d0fa0b044c30a01831eb84d639d9f2f2/colorlog-5.0.1-py2.py3-none-any.whl\r\nconfigparser @ file:///home/void/.cache/pypoetry/artifacts/62/d3/97/a2949c74cc1115909f8c1f42f474c3ab22e1da2667d2ddff71b3e6efff/configparser-5.0.2-py3-none-any.whl\r\ncoverage @ file:///home/void/.cache/pypoetry/artifacts/9b/3b/0e/7304b9b5727e6d8c7dcb7790e5a7ada9f9b0eb3d447c55bafbd1e10a6e/coverage-5.5-cp37-cp37m-manylinux2010_x86_64.whl\r\ncymem @ file:///home/void/.cache/pypoetry/artifacts/89/dc/1c/cd70280e9193082ebee5dba1b3b3302ff4c64d1524e041c0c03516261c/cymem-2.0.5-cp37-cp37m-manylinux2014_x86_64.whl\r\ndarglint @ file:///home/void/.cache/pypoetry/artifacts/d0/22/a6/0ae1baa693bb2faf4f905bd3da5e7c7acf12bca962fc4d927838ee8b41/darglint-1.8.0-py3-none-any.whl\r\ndecorator @ file:///home/void/.cache/pypoetry/artifacts/4c/44/a3/98a9811f5ccd978d1c278eb97127c919a58ca805b3e54fba6c0b212265/decorator-5.0.7-py3-none-any.whl\r\ndefusedxml @ file:///home/void/.cache/pypoetry/artifacts/d3/69/a8/eb355ff24ffb8df62ec3dd9524bec0ad9d9dc719bd996734d6d7aa1d56/defusedxml-0.7.1-py2.py3-none-any.whl\r\ndictdiffer @ file:///home/void/.cache/pypoetry/artifacts/e4/93/97/60397fd0d7cca2bb6e18b78a6a7686f75a859f1b8f237167d7d4737b1d/dictdiffer-0.8.1-py2.py3-none-any.whl\r\ndoc8 @ file:///home/void/.cache/pypoetry/artifacts/79/3e/c8/ae33df607c50685be0d497522a1af2a835f1be1c77709951aaa6b195db/doc8-0.8.1-py2.py3-none-any.whl\r\ndocker-pycreds @ file:///home/void/.cache/pypoetry/artifacts/ae/d2/e4/d45ddf9b807389820c106b6d5cc636f5a794fb93631d9b8119fb110ec3/docker_pycreds-0.4.0-py2.py3-none-any.whl\r\ndocutils @ file:///home/void/.cache/pypoetry/artifacts/24/17/76/ad5143b189440a07a8cd43100d25b414c020d591981c6141f1881f7fe6/docutils-0.17-py2.py3-none-any.whl\r\ndparse @ file:///home/void/.cache/pypoetry/artifacts/61/38/88/d729d74e312bdef39a41d9388f962e838a49f53d9964f881552bd6b6db/dparse-0.5.1-py3-none-any.whl\r\nentrypoints @ file:///home/void/.cache/pypoetry/artifacts/5e/99/ed/7ceb3b7ba71bc66f2526e7ffc16315bfdb5bf955fe1051ec05516f7730/entrypoints-0.3-py2.py3-none-any.whl\r\neradicate @ file:///home/void/.cache/pypoetry/artifacts/4c/f8/6e/535a5eaa918010239f4badceb49f6e6ff22c1c5bad8db9ff54cee17163/eradicate-1.0.tar.gz\r\nfilelock @ file:///home/void/.cache/pypoetry/artifacts/08/55/8e/3a41c1abc99a96a15b063c1f6c0bb06c4ae6cbb78de462a1999579e087/filelock-3.0.12-py3-none-any.whl\r\nflake8 @ file:///home/void/.cache/pypoetry/artifacts/b8/54/22/c86908a17e023a917c963c0afe98570cf4b6f07c4407b85c6e3beb7128/flake8-3.9.1-py2.py3-none-any.whl\r\nflake8-bandit @ file:///home/void/.cache/pypoetry/artifacts/73/09/84/42a6b41975a42f2c631d7c0ba5cb35c38c0d0560af60ec888e95cbc82e/flake8_bandit-2.1.2.tar.gz\r\nflake8-broken-line @ file:///home/void/.cache/pypoetry/artifacts/fb/e0/e6/e7d66797cfa78abf59a681622e4a64ad26a3f37f755dff1aa2310e89ed/flake8_broken_line-0.2.1-py3-none-any.whl\r\nflake8-bugbear @ file:///home/void/.cache/pypoetry/artifacts/62/76/39/527cdbe01977956d193c1246dd1093d1c04368bf5020682fdd6b74408e/flake8_bugbear-19.8.0-py35.py36.py37-none-any.whl\r\nflake8-commas @ file:///home/void/.cache/pypoetry/artifacts/f5/ba/10/b4bde8612d74e39a007b65228f1167e91320847a48fe99d2514ccaa78d/flake8_commas-2.0.0-py2.py3-none-any.whl\r\nflake8-comprehensions @ file:///home/void/.cache/pypoetry/artifacts/e0/11/b2/d171d6145b51bc4e54263b0ffeba234d0b693e055e47eee4d2551e7e11/flake8_comprehensions-3.4.0-py3-none-any.whl\r\nflake8-debugger @ file:///home/void/.cache/pypoetry/artifacts/ea/b0/a2/b0f38254a64bb29ae6356646e0a6cd6607d383a7a3809358603dc0bb4c/flake8-debugger-3.2.1.tar.gz\r\nflake8-docstrings @ file:///home/void/.cache/pypoetry/artifacts/dd/61/0f/8c31b8a10df8152ee5f1400f965df4a1d9f14d1c2e73bdeda389921f06/flake8_docstrings-1.6.0-py2.py3-none-any.whl\r\nflake8-eradicate @ file:///home/void/.cache/pypoetry/artifacts/a0/87/7e/94d2c66c1eab6acc65ded58a867ad8c684c7bdd6eeceb91a0b336aa63b/flake8_eradicate-0.3.0-py3-none-any.whl\r\nflake8-isort @ file:///home/void/.cache/pypoetry/artifacts/aa/be/9e/5b4f728aa7c298adc33f71a13676c41d843bb89af6c0a71493b27aff01/flake8_isort-3.0.1-py2.py3-none-any.whl\r\nflake8-plugin-utils @ file:///home/void/.cache/pypoetry/artifacts/35/9a/10/f8f41d43896f3eac1b19353fd56b1de85622630254660e02d2504f5d6d/flake8_plugin_utils-1.3.1-py3-none-any.whl\r\nflake8-polyfill @ file:///home/void/.cache/pypoetry/artifacts/50/2e/1c/0ab55451b665fa42f02e5e0b60b4f1e3d0c5b97e523e6942fcb469b060/flake8_polyfill-1.0.2-py2.py3-none-any.whl\r\nflake8-pytest-style @ file:///home/void/.cache/pypoetry/artifacts/fa/25/c3/fc9f818d7a076d63faa217ea2adf691c92b0000cee5b6420bbe03ab19d/flake8_pytest_style-1.4.1-py3-none-any.whl\r\nflake8-quotes @ file:///home/void/.cache/pypoetry/artifacts/23/a7/ee/bc35529d5fb4ce0aef80dab51eca97b55a70c2183efcc68498a668f41a/flake8-quotes-2.1.2.tar.gz\r\nflake8-rst-docstrings @ file:///home/void/.cache/pypoetry/artifacts/13/52/41/eb73820e56d7ffb96a09509569d9d0e6b1068dc5d082da30c3ec40a390/flake8-rst-docstrings-0.0.12.tar.gz\r\nflake8-string-format @ file:///home/void/.cache/pypoetry/artifacts/fb/c5/8f/34f45df55140c42298862824e72ce2a67620ddad02e0173ac9654f927c/flake8_string_format-0.2.3-py2.py3-none-any.whl\r\ngitdb @ file:///home/void/.cache/pypoetry/artifacts/96/6b/0d/8c98bd5a440942e37e198088da688917df817926cdd1828c67629d73d1/gitdb-4.0.7-py3-none-any.whl\r\nGitPython @ file:///home/void/.cache/pypoetry/artifacts/d1/23/d7/b24886986eaf6c660285de59cee29e42c3a030b12d15b544fcacfc889b/GitPython-3.1.14-py3-none-any.whl\r\ngreenlet @ file:///home/void/.cache/pypoetry/artifacts/ec/cd/50/631d3cee3e8163d49884ac822731ba5854db56ef007f7b3d1687c12e99/greenlet-1.0.0-cp37-cp37m-manylinux2010_x86_64.whl\r\nh5py @ file:///home/void/.cache/pypoetry/artifacts/5f/5a/4c/0ae2db5f88cf83abf33db3ffa364e0a90e13d7a75cde8560e9c3981af7/h5py-3.2.1-cp37-cp37m-manylinux1_x86_64.whl\r\nidentify @ file:///home/void/.cache/pypoetry/artifacts/3a/22/ae/4b0b0071dcc3a4ac84f7e5968b9064201a9e64d5be0ffc1864095cfd4d/identify-2.2.3-py2.py3-none-any.whl\r\nidna @ file:///home/void/.cache/pypoetry/artifacts/71/d9/bc/a8481f6ac8b5d0ecc0fbd34aca906ee68d1757f24fefbd0f4294c0c9d2/idna-2.10-py2.py3-none-any.whl\r\nimagesize @ file:///home/void/.cache/pypoetry/artifacts/b0/0c/4c/2da9b5d688f3d57232a399cd66d8f682f2246dff0008a0253eed36d086/imagesize-1.2.0-py2.py3-none-any.whl\r\nimportlib-metadata @ file:///home/void/.cache/pypoetry/artifacts/31/fc/05/71417d693371ef10b30a9289eb98e554ae850569e049e4c7ba0dbe2e44/importlib_metadata-3.10.1-py3-none-any.whl\r\nipykernel @ file:///home/void/.cache/pypoetry/artifacts/50/d7/4f/776813e1bb58bc2288bef5ae69c62cc0710c62396910d1e6799f537c7c/ipykernel-5.5.3-py3-none-any.whl\r\nipython @ file:///home/void/.cache/pypoetry/artifacts/1b/f6/06/a4687a1a1ea57b27c1a2879652854425a44bd41192c02f799f1aaef247/ipython-7.22.0-py3-none-any.whl\r\nipython-genutils @ file:///home/void/.cache/pypoetry/artifacts/2c/69/c6/e1f2fd156ee87f59d0c32acc921a0da31121b0c7c192b1b9ac0908111d/ipython_genutils-0.2.0-py2.py3-none-any.whl\r\nipywidgets @ file:///home/void/.cache/pypoetry/artifacts/83/db/53/e89cbc09943d34d82339a205aa58c225bb26c9cb2cc104716f9c5bfeba/ipywidgets-7.6.3-py2.py3-none-any.whl\r\nisort @ file:///home/void/.cache/pypoetry/artifacts/4d/3d/1d/2bf08f2c5646377d4283866820ce20c18eb1615dec01e7288eefbf8695/isort-4.3.21-py2.py3-none-any.whl\r\njedi @ file:///home/void/.cache/pypoetry/artifacts/1b/c9/89/e6d1f3a2cb2069fa5cacdaf2b474f924b727f0c38edd54d886e07a75bc/jedi-0.18.0-py2.py3-none-any.whl\r\nJinja2 @ file:///home/void/.cache/pypoetry/artifacts/47/18/a4/1905063a877fa68496ecb2e347fc04c431948d96cf825a0960da5791e0/Jinja2-2.11.3-py2.py3-none-any.whl\r\njmespath @ file:///home/void/.cache/pypoetry/artifacts/a9/2b/32/eb9ed41e3f5118971d1741c1299d1e7a70ca4345e5898d5a5d663bfd5f/jmespath-0.10.0-py2.py3-none-any.whl\r\njoblib @ file:///home/void/.cache/pypoetry/artifacts/31/29/01/db4dcbbea55316357053572689a218c92920416d025fcdf575ed68d0c9/joblib-1.0.1-py3-none-any.whl\r\njsonnet @ file:///home/void/.cache/pypoetry/artifacts/fd/e3/b2/346cba762f726f74df60a0c229bb69087d9f3a06df6d4cf7ae8d0ba9d2/jsonnet-0.17.0.tar.gz\r\njsonschema @ file:///home/void/.cache/pypoetry/artifacts/a2/e2/79/5896dfe12b442a5a7583226fb0d61aec227575025e5ac51deecf719547/jsonschema-3.2.0-py2.py3-none-any.whl\r\njupyter @ file:///home/void/.cache/pypoetry/artifacts/12/56/8a/0c3f4ff4bf0613de3a1020ba2cb4f35919d4d55f3f364cc7b217f63a4c/jupyter-1.0.0-py2.py3-none-any.whl\r\njupyter-client @ file:///home/void/.cache/pypoetry/artifacts/75/86/a0/f28d8ede7e50d46c1394e240dcd1c2706cfdef4313f6fb502474491a75/jupyter_client-6.2.0-py3-none-any.whl\r\njupyter-console @ file:///home/void/.cache/pypoetry/artifacts/99/c8/ec/2de2d0ccfb90fe23e9752664cae6e94c963c37391f2ff44cfbbf5bfa31/jupyter_console-6.4.0-py3-none-any.whl\r\njupyter-core @ file:///home/void/.cache/pypoetry/artifacts/6c/b4/0a/8912b11fb38e65e26cdf07a09561b340b0a6f4f5cc4b03dc17f8f678db/jupyter_core-4.7.1-py3-none-any.whl\r\njupyterlab-pygments @ file:///home/void/.cache/pypoetry/artifacts/92/13/97/3ba1dbd6e97ac9bf843bceb4d66902ecd4dab945d10002cc16d0daa1d8/jupyterlab_pygments-0.1.2-py2.py3-none-any.whl\r\njupyterlab-widgets @ file:///home/void/.cache/pypoetry/artifacts/d9/bd/77/52835917d713d609702eab7cb97fdae0bb6c8c66ff068eb0dc62fd6bc8/jupyterlab_widgets-1.0.0-py3-none-any.whl\r\nlmdb @ file:///home/void/.cache/pypoetry/artifacts/66/40/81/8353114c19e9fedaca18f9af102abcf29fb8c18fec3b305ffba050d4bb/lmdb-1.2.0-cp37-cp37m-manylinux2010_x86_64.whl\r\nm2r @ file:///home/void/.cache/pypoetry/artifacts/76/16/4d/be80e6cd238bb41bb57dd8f2b2ec41716bd5c298140206f363d434c080/m2r-0.2.1.tar.gz\r\nMako @ file:///home/void/.cache/pypoetry/artifacts/95/cd/6c/b720114a151a63afb11ee90775d2d6543c40b925c7e1d30290d7496594/Mako-1.1.4-py2.py3-none-any.whl\r\nMarkupSafe @ file:///home/void/.cache/pypoetry/artifacts/cd/da/a5/4cfa20f311002e7588045a07491e292e7fb819fcc777144055b7c7ba89/MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl\r\nmarshmallow @ file:///home/void/.cache/pypoetry/artifacts/bf/03/40/3eadfe49de5c4d68198fb3901ac2691f77ad8fa480f0786256aee0714c/marshmallow-3.11.1-py2.py3-none-any.whl\r\nmarshmallow-polyfield @ file:///home/void/.cache/pypoetry/artifacts/85/27/e8/aec375b960a3f69ffde88981dd1211e65b7b7a692a8b44a3778acebf38/marshmallow_polyfield-5.10-py3-none-any.whl\r\nmccabe @ file:///home/void/.cache/pypoetry/artifacts/c2/cd/ed/3c4495a1422fb12eefbca8b3c6ccc83ab4ec92fd39df029199cc4f4ee4/mccabe-0.6.1-py2.py3-none-any.whl\r\nmistune @ file:///home/void/.cache/pypoetry/artifacts/80/fd/6c/c86cb01dda756e2e899197f574484928622e9ad453d90761abac9e1948/mistune-0.8.4-py2.py3-none-any.whl\r\nmore-itertools @ file:///home/void/.cache/pypoetry/artifacts/36/5e/6e/086e365056443ea7340684bae7e448349db3e9ed8be4d1f089f351b2e2/more_itertools-8.7.0-py3-none-any.whl\r\nmurmurhash @ file:///home/void/.cache/pypoetry/artifacts/6f/20/56/fb7c026c670b5c29fee53124be83411e1a7de6d85ed8daaca7589e9871/murmurhash-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl\r\nmypy @ file:///home/void/.cache/pypoetry/artifacts/ba/8d/14/63dc6e4251a288ca5cf70b45458c5e898780ab477364ebe918a3119997/mypy-0.790-cp37-cp37m-manylinux1_x86_64.whl\r\nmypy-extensions @ file:///home/void/.cache/pypoetry/artifacts/41/fb/ef/133cd18a3e22a06b8d77dfe2ba71c50c509e4d2484ee619c6631c0b5b2/mypy_extensions-0.4.3-py2.py3-none-any.whl\r\nnbclient @ file:///home/void/.cache/pypoetry/artifacts/92/7a/49/4c2666fa49a3f47e490b88dca3aaa53a92db0c1c3bf101db29b6c43164/nbclient-0.5.3-py3-none-any.whl\r\nnbconvert @ file:///home/void/.cache/pypoetry/artifacts/9f/b0/34/add1712e9bfa620ab77d2d5d5603591edc85cd6c4ba1a40b4385befda2/nbconvert-6.0.7-py3-none-any.whl\r\nnbformat @ file:///home/void/.cache/pypoetry/artifacts/0b/d3/e5/88a4198def0d0bfda1c57a758546b5d2f7bd8edd3dc9be0b71555110ba/nbformat-5.1.3-py3-none-any.whl\r\nnest-asyncio @ file:///home/void/.cache/pypoetry/artifacts/a6/03/5a/2c77454326bb7a0a235ae4a78437c007a6ef2631cf40b34da26b5729c4/nest_asyncio-1.5.1-py3-none-any.whl\r\nnitpick @ file:///home/void/.cache/pypoetry/artifacts/a5/20/b8/993266cc8ff195f92efb6ab96bd376eece4f04a7eaa5f7e7aeb9f52dfd/nitpick-0.23.1-py3-none-any.whl\r\nnltk @ file:///home/void/.cache/pypoetry/artifacts/59/92/71/a8c5b581863e7e25355f9e4468c27343f31b423976941e6325acd0554f/nltk-3.6.1-py3-none-any.whl\r\nnotebook @ file:///home/void/.cache/pypoetry/artifacts/8c/7f/b5/1734baadda7ddfda9a357cbc94c4eb7756a74fe40add4a4ab3a87bc828/notebook-6.3.0-py3-none-any.whl\r\nnumpy @ file:///home/void/.cache/pypoetry/artifacts/9b/29/b8/7e795a24270a4c1f149286b044e1aafd59ce92bdaad676b7d44ae8187f/numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl\r\noptuna @ file:///home/void/.cache/pypoetry/artifacts/fa/68/90/ceaf47da1b66a35a3fdc4b6e24b06bf9f88e233b5f739e430bd13d9d4c/optuna-2.7.0-py3-none-any.whl\r\noverrides @ file:///home/void/.cache/pypoetry/artifacts/84/72/62/00a8159d8d9cee75aefc43667435b680f1683000bf235588b78014f01f/overrides-3.1.0.tar.gz\r\npackaging @ file:///home/void/.cache/pypoetry/artifacts/bf/c9/4b/d4c56a8494978126d690da73a04dfe71b97fa991e52f1634afc46f263e/packaging-20.9-py2.py3-none-any.whl\r\npandas @ file:///home/void/.cache/pypoetry/artifacts/20/e6/0f/feac64ed8cd0e30be8e53f5127de980b8319f906615c21c8b7b5400296/pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl\r\npandocfilters @ file:///home/void/.cache/pypoetry/artifacts/95/80/e1/8047532d4a0988efe4c86231e4aede0125e9bb1dcd96dc7208e29099e6/pandocfilters-1.4.3.tar.gz\r\nparso @ file:///home/void/.cache/pypoetry/artifacts/dc/ff/07/1556e66e77c039a21cd51bc0de4c5777b35569c3903674997b2cdfb9f5/parso-0.8.2-py2.py3-none-any.whl\r\npathtools @ file:///home/void/.cache/pypoetry/artifacts/32/fd/91/3eef9683d97849cbd83965bdeee1d1c174066836230a13c775c457fa99/pathtools-0.1.2.tar.gz\r\npathy @ file:///home/void/.cache/pypoetry/artifacts/96/c6/de/613b8d4b2f063d538d827205a59b4b0d5370682ea65102e29a5f658c6d/pathy-0.4.0-py3-none-any.whl\r\npbr @ file:///home/void/.cache/pypoetry/artifacts/30/01/4f/39bfa10a7db631fdb8d04545f995c48353f33404db8ad29f7b3ab7847b/pbr-5.5.1-py2.py3-none-any.whl\r\npep8-naming @ file:///home/void/.cache/pypoetry/artifacts/0d/f2/0c/77ac3ab0d1cfa522f402e523b7fb4e93fe039c5f6ad9ecec1d783871ed/pep8_naming-0.9.1-py2.py3-none-any.whl\r\npexpect @ file:///home/void/.cache/pypoetry/artifacts/ac/ff/fd/e4fa201b733fa24e77b6e0f8e1a2e0e9d4bd7cb1936861c9b12e4653a0/pexpect-4.8.0-py2.py3-none-any.whl\r\npickleshare @ file:///home/void/.cache/pypoetry/artifacts/e3/49/c6/dda859db430eaa2b27acc6a8bab879e41d2bf09e99f792343ccc9d1fef/pickleshare-0.7.5-py2.py3-none-any.whl\r\nPillow @ file:///home/void/.cache/pypoetry/artifacts/33/2c/8b/596c551987d35a45fb1ec5bca0f603038a9d768054d449544befaede0e/Pillow-8.2.0-cp37-cp37m-manylinux1_x86_64.whl\r\npluggy @ file:///home/void/.cache/pypoetry/artifacts/bc/2e/c9/c04063460a7a68d2e59c9ea0a673de9d7930d54f788ed0510cdcf8aa78/pluggy-0.13.1-py2.py3-none-any.whl\r\npreshed @ file:///home/void/.cache/pypoetry/artifacts/2a/eb/44/6c826ae0ffba371a4f27e852dfee9ef9ffbfb3f6652cbbd380b42f6f4e/preshed-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl\r\nprettytable @ file:///home/void/.cache/pypoetry/artifacts/a9/0c/6c/03413065886102725c74f371e697bf00d608e02fcc1fadfc86e38b239a/prettytable-2.1.0-py3-none-any.whl\r\nprometheus-client @ file:///home/void/.cache/pypoetry/artifacts/0b/d6/f7/38818ac7b9cdc0284e61fcdf0611a28821f2590cc115109e0dbaca44a6/prometheus_client-0.10.1-py2.py3-none-any.whl\r\npromise @ file:///home/void/.cache/pypoetry/artifacts/2b/c7/61/34271997f7584c0fed7a921acc0b1fdf77a383cbed4844419c4e8a3d83/promise-2.3.tar.gz\r\nprompt-toolkit @ file:///home/void/.cache/pypoetry/artifacts/42/43/a5/0a3723dadc2a4c0c2daa3c0f1616bec63165729f3b7611a888dea550a4/prompt_toolkit-3.0.18-py3-none-any.whl\r\nprotobuf @ file:///home/void/.cache/pypoetry/artifacts/d7/0d/8c/079c0f0d7b3e2630df6660e993b5ee1a584fdd0dd5fe77b36d0b0444e5/protobuf-3.15.8-cp37-cp37m-manylinux1_x86_64.whl\r\npsutil @ file:///home/void/.cache/pypoetry/artifacts/e7/ee/ed/9817a6e3fa8217c13cf17b1bb44507668f1cfd9f057aaf816c8762f172/psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl\r\nptyprocess @ file:///home/void/.cache/pypoetry/artifacts/af/cd/8c/c1510ca357886f8af9948e5555f25db9e360b1dd798566e6e9540c3442/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npy @ file:///home/void/.cache/pypoetry/artifacts/56/1d/e3/7dad75e1bf797fbd8937b37dd43d1656357c67a199e9f54d48535697d0/py-1.10.0-py2.py3-none-any.whl\r\npycodestyle @ file:///home/void/.cache/pypoetry/artifacts/a5/4d/b8/38f79509a4c7ac2a12983ce715595e1f983965f0e4c03d632074c05eec/pycodestyle-2.7.0-py2.py3-none-any.whl\r\npycparser @ file:///home/void/.cache/pypoetry/artifacts/44/e9/07/88a70ff44631b83a33a8011053104dffbca00761b983eff85051639df2/pycparser-2.20-py2.py3-none-any.whl\r\npydantic @ file:///home/void/.cache/pypoetry/artifacts/a2/97/d0/ea9e192cb9618b7c2e414860077a8353f5153e377eab0aba2e3844f50e/pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl\r\npydocstyle @ file:///home/void/.cache/pypoetry/artifacts/72/0e/e5/0e72e0766b925b9443bad8038924832aaa21007eac3e41da5c3cd22bf4/pydocstyle-6.0.0-py3-none-any.whl\r\npyflakes @ file:///home/void/.cache/pypoetry/artifacts/23/7e/52/ea1293b6028d8abc80bab40d1d20c22ae4fb0290b35f06541da7cab403/pyflakes-2.3.1-py2.py3-none-any.whl\r\nPygments @ file:///home/void/.cache/pypoetry/artifacts/14/df/54/07ac62d5eed39cfb52f6439b1afc41e12a205a48755bd7586dda35e565/Pygments-2.8.1-py3-none-any.whl\r\npyparsing @ file:///home/void/.cache/pypoetry/artifacts/78/8b/03/23dc60df50f099a658dd13c86d7d94564b0b86bfa2ff61bc9595fb2fcb/pyparsing-2.4.7-py2.py3-none-any.whl\r\npyperclip @ file:///home/void/.cache/pypoetry/artifacts/32/88/cb/8cae34dd62a8a0152e9b330698cfdb022deb2f066b7944acf5511dfd6f/pyperclip-1.8.2.tar.gz\r\npyrsistent @ file:///home/void/.cache/pypoetry/artifacts/82/fd/98/fab6ad55bd376f1da134a3376cf61717a18104b408383b860716048249/pyrsistent-0.17.3.tar.gz\r\npytest @ file:///home/void/.cache/pypoetry/artifacts/a8/5a/78/7536a0da5c14b85637968b588ecf3bde096ce084658eab4180c94412fa/pytest-5.4.3-py3-none-any.whl\r\npytest-cov @ file:///home/void/.cache/pypoetry/artifacts/68/74/14/7ce422aeb24fffce22002e5981b110ae5719e0673fd0f8b053011944bf/pytest_cov-2.11.1-py2.py3-none-any.whl\r\npytest-randomly @ file:///home/void/.cache/pypoetry/artifacts/83/d8/d1/7651b8757550ced3b9754eee50cce8cc9d184de1ef7e756db8d960f0e1/pytest_randomly-3.7.0-py3-none-any.whl\r\npython-dateutil @ file:///home/void/.cache/pypoetry/artifacts/75/fa/68/ee8cf8ee229ebfb7947af0398184c39bbf243b7dc67ee46cca45938d09/python_dateutil-2.8.1-py2.py3-none-any.whl\r\npython-editor @ file:///home/void/.cache/pypoetry/artifacts/51/f9/12/c230460443322196110063793391d5d4ca9aabe0c697c4f402c32c5453/python_editor-1.0.4-py3-none-any.whl\r\npython-slugify @ file:///home/void/.cache/pypoetry/artifacts/55/f6/8f/1a0d0963c09d17ff4da7c7cec7183ab25e957e42a8e27d635c613d64c8/python-slugify-4.0.1.tar.gz\r\npytz @ file:///home/void/.cache/pypoetry/artifacts/0c/d0/94/bbd2fee71be292862261e85cefb2231b1df628c7a0e5cb0170d8304963/pytz-2021.1-py2.py3-none-any.whl\r\nPyYAML @ file:///home/void/.cache/pypoetry/artifacts/17/3c/f6/dd4498c1b6b7cdef0517d1e5c0a56e52886d36350589195788eed24d29/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl\r\npyzmq @ file:///home/void/.cache/pypoetry/artifacts/dd/a2/24/c8ec691e3ac51d6df3c9b91bc06a2d49ba9f99af4146527b6efb3c3585/pyzmq-22.0.3-cp37-cp37m-manylinux1_x86_64.whl\r\nqtconsole @ file:///home/void/.cache/pypoetry/artifacts/b6/7c/3e/f5d07f4ef3164595943d3e3dbd7a718b9cdb77a8e888af66af246b0d11/qtconsole-5.0.3-py3-none-any.whl\r\nQtPy @ file:///home/void/.cache/pypoetry/artifacts/8d/c8/7b/f07109a6dc6b92fe95473bd29a9abd2432c5117aba360c912a681384f4/QtPy-1.9.0-py2.py3-none-any.whl\r\nregex @ file:///home/void/.cache/pypoetry/artifacts/5b/86/c7/caf2fd4e0eace88a30e3b2109f1587ce13a19f81611406f179c9dd3754/regex-2021.4.4-cp37-cp37m-manylinux2014_x86_64.whl\r\nrequests @ file:///home/void/.cache/pypoetry/artifacts/f2/13/b8/cc7ac8d0aa2630507c04c2c0e72307bed4ee7e2c92d7c3d97a5d61e74e/requests-2.25.1-py2.py3-none-any.whl\r\nrestructuredtext-lint @ file:///home/void/.cache/pypoetry/artifacts/d8/9d/f9/d7f05191e8128f58b61dbdb962c85f40a4c14da47d397adcfe27d98193/restructuredtext_lint-1.3.2.tar.gz\r\nruamel.yaml @ file:///home/void/.cache/pypoetry/artifacts/82/7e/93/51925fb555452a6bea3fbc3f42bc1d342af303339634400c4f154a3fa5/ruamel.yaml-0.17.4-py3-none-any.whl\r\nruamel.yaml.clib @ file:///home/void/.cache/pypoetry/artifacts/a9/eb/ab/743349c1b48fce4dedaaab59b2ab0ced108f6c46161b470a5dd01a9f50/ruamel.yaml.clib-0.2.2-cp37-cp37m-manylinux1_x86_64.whl\r\ns3transfer @ file:///home/void/.cache/pypoetry/artifacts/0f/3e/bc/9588da108fc381717df2b2c71aa60bb824766e14f18fd46e4abf99dd67/s3transfer-0.3.7-py2.py3-none-any.whl\r\nsacremoses @ file:///home/void/.cache/pypoetry/artifacts/3b/67/ce/fc1e875ccddd89c0fc964d30eb160ce43474fa74836f2d9166c44fa5d0/sacremoses-0.0.44.tar.gz\r\nsafety @ file:///home/void/.cache/pypoetry/artifacts/d6/12/3a/0fada211c21fd9e66dfb15b64d9f8d21351c22702f61cd7a73594ee1de/safety-1.10.3-py2.py3-none-any.whl\r\nscikit-learn @ file:///home/void/.cache/pypoetry/artifacts/88/94/54/5c47ee3b72e9562608bad938570faf87e8381dcf99415a79dcfc865ad0/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl\r\nscipy @ file:///home/void/.cache/pypoetry/artifacts/e5/3e/a7/b69534d16cae11353f6db73f0fd62d7fc874f1640bd9d39fcc878d355e/scipy-1.6.1-cp37-cp37m-manylinux1_x86_64.whl\r\nSend2Trash @ file:///home/void/.cache/pypoetry/artifacts/65/5c/cf/74efc7119c07b06a3e5f3f1e4ffc62bd28315db7decee27e42ff7f5ee0/Send2Trash-1.5.0-py3-none-any.whl\r\nsentencepiece @ file:///home/void/.cache/pypoetry/artifacts/92/8f/92/0b4cb42c5fec658fb16785c669dd7eb4dbe925d8da8d6b0c12e2a151d9/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl\r\nsentry-sdk @ file:///home/void/.cache/pypoetry/artifacts/ec/58/9c/e73bd625efad4210888b269864ba3641df4516a9582f6722cf05ca0ac4/sentry_sdk-1.0.0-py2.py3-none-any.whl\r\nshortuuid @ file:///home/void/.cache/pypoetry/artifacts/83/75/5a/5955701463bbd5516b72ab60b68f3c5d7a4b513b2a7dddb58a96d6d071/shortuuid-1.0.1-py3-none-any.whl\r\nsiamenc==0.1.0\r\nsix @ file:///home/void/.cache/pypoetry/artifacts/e3/96/48/99c14ba5c6276fbf4dc2e216553590ec97b52e685863f73e39550418c5/six-1.15.0-py2.py3-none-any.whl\r\nsmart-open @ file:///home/void/.cache/pypoetry/artifacts/0f/33/80/1b361e7af0ed7288b20ed6c741e374857e5e832f84e73781e4226ba661/smart_open-3.0.0.tar.gz\r\nsmmap @ file:///home/void/.cache/pypoetry/artifacts/65/5b/7b/613313a5462b9286d173319b5c72030d91a09050eb726ee603f33ef524/smmap-4.0.0-py2.py3-none-any.whl\r\nsnowballstemmer @ file:///home/void/.cache/pypoetry/artifacts/1b/e7/37/c1ccd5c7451e2f738886b093508276afa6237726b3b8c391d26c98ddee/snowballstemmer-2.1.0-py2.py3-none-any.whl\r\nsortedcontainers @ file:///home/void/.cache/pypoetry/artifacts/f5/2e/d6/fb0cc783ac71136be1df7a9851a4f60077d0e2b8e662ce731e3a3c346c/sortedcontainers-2.3.0-py2.py3-none-any.whl\r\nsoupsieve @ file:///home/void/.cache/pypoetry/artifacts/6c/8d/4c/47458f64b200cf946383fd0d3e5498170178ef711558d4ef50c5f1e951/soupsieve-2.2.1-py3-none-any.whl\r\nspacy @ file:///home/void/.cache/pypoetry/artifacts/a7/4c/c1/278f97aabcf79dd734eac17a3588b6bc6c8621e050c173e69067786902/spacy-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl\r\nspacy-legacy @ file:///home/void/.cache/pypoetry/artifacts/f0/d3/d6/eca1889d307c0c12efde065b6fb3bcfb25a5c74d153c26626e11518bc4/spacy_legacy-3.0.2-py2.py3-none-any.whl\r\nSphinx @ file:///home/void/.cache/pypoetry/artifacts/48/f8/fa/28d5d3671759e44d1cde56947b9eee6b9007ec92bf008e9652aaa70220/Sphinx-2.4.4-py3-none-any.whl\r\nsphinx-autodoc-typehints @ file:///home/void/.cache/pypoetry/artifacts/c2/1b/5c/4c527daa01c9c515303fd7dae1c2fc68dd2a925a9256502d302ae32e6f/sphinx_autodoc_typehints-1.10.3-py3-none-any.whl\r\nsphinxcontrib-applehelp @ file:///home/void/.cache/pypoetry/artifacts/cc/cf/dd/8ba7c4afe2ff84e7204886e2fd837495627b3827a21925726fcc3125d1/sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl\r\nsphinxcontrib-devhelp @ file:///home/void/.cache/pypoetry/artifacts/59/da/dc/900e02cc5452883e989929e3784c1a7094cd7326af3cf4a6d8bb225055/sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl\r\nsphinxcontrib-htmlhelp @ file:///home/void/.cache/pypoetry/artifacts/11/b9/f6/329734fa1be1c805096ac23381f177cd4cc617499095ab385fce82bd95/sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl\r\nsphinxcontrib-jsmath @ file:///home/void/.cache/pypoetry/artifacts/7f/d8/ef/31320102fc49e5beeb72d480f0dab2dc5429fbd8cedf45817e2320d58e/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\r\nsphinxcontrib-qthelp @ file:///home/void/.cache/pypoetry/artifacts/81/5b/46/baf9bd9c58b789d2ff445165e5859021ea31139602fffcc773c39da86b/sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl\r\nsphinxcontrib-serializinghtml @ file:///home/void/.cache/pypoetry/artifacts/6a/e9/75/0afa870282075cec7b4aea1f133464212c82722b3cb72319d359cae77f/sphinxcontrib_serializinghtml-1.1.4-py2.py3-none-any.whl\r\nSQLAlchemy @ file:///home/void/.cache/pypoetry/artifacts/7f/42/44/655528faa76d83aec61bdced2f43e6a00416851a6fb609d9b2f42b77e4/SQLAlchemy-1.4.8-cp37-cp37m-manylinux2014_x86_64.whl\r\nsrsly @ file:///home/void/.cache/pypoetry/artifacts/7f/0e/05/c232e06f54f2c934727088bb73fbdabb194b37a53cc6fdfa3e67150180/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl\r\nstevedore @ file:///home/void/.cache/pypoetry/artifacts/64/3f/af/b25f40ac10bc9dafd39a798374d310acd1a62b0e9c3a432f7862a1de9e/stevedore-3.3.0-py3-none-any.whl\r\nsubprocess32 @ file:///home/void/.cache/pypoetry/artifacts/b6/a9/6e/74893ca81a4fe350238b027043f45690982bcbe3eb5edad507333c2de9/subprocess32-3.5.4.tar.gz\r\ntensorboardX @ file:///home/void/.cache/pypoetry/artifacts/59/da/a0/4ecae9c6e8f53733e1441997534f8008834bf3aaf5d7c6bfa9271f953c/tensorboardX-2.2-py2.py3-none-any.whl\r\nterminado @ file:///home/void/.cache/pypoetry/artifacts/d7/3f/73/57ecce9aba58022bc076bf9c923dc98b8fa13c2ed9fa7aad4c9e8231a6/terminado-0.9.4-py3-none-any.whl\r\ntestfixtures @ file:///home/void/.cache/pypoetry/artifacts/b2/d7/f8/e32b667c1a1326308364cc8415842331f55cee16d4bf84aeb7b00da260/testfixtures-6.17.1-py2.py3-none-any.whl\r\ntestpath @ file:///home/void/.cache/pypoetry/artifacts/20/41/61/40209212e3cc4ead6910ce1a83532987e232f01564d9e48fd1c1e2e12e/testpath-0.4.4-py2.py3-none-any.whl\r\ntext-unidecode @ file:///home/void/.cache/pypoetry/artifacts/71/f3/8c/83d57454c286b52f0f4545f78a5b77a274ee5bed5a42bc456e99c86023/text_unidecode-1.3-py2.py3-none-any.whl\r\nthinc @ file:///home/void/.cache/pypoetry/artifacts/9f/dc/7b/e47192857a9ad48df1d6570eced12ec83753ae1a6f4302d7dc23c0b96d/thinc-8.0.2-cp37-cp37m-manylinux2014_x86_64.whl\r\nthreadpoolctl @ file:///home/void/.cache/pypoetry/artifacts/10/d2/ec/b7f7827e6b16466e651b5a2ea18c64362ff41a15e221a88cc3064fb4dd/threadpoolctl-2.1.0-py3-none-any.whl\r\ntokenizers @ file:///home/void/.cache/pypoetry/artifacts/42/ff/97/038f38b3b1ad8266412d2e22edbba67fbc90e5ef71635c466a9117069a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl\r\ntoml @ file:///home/void/.cache/pypoetry/artifacts/ee/b4/26/b53b77a5db04c373edfec4046f6e15ab8a6dfbbaee30dcacd447b71c50/toml-0.10.0-py2.py3-none-any.whl\r\ntomlkit @ file:///home/void/.cache/pypoetry/artifacts/08/92/ad/3abffc10fb9db6842e047f90088ce25422c9eec5bf89f072620174120f/tomlkit-0.7.0-py2.py3-none-any.whl\r\ntorch @ file:///home/void/.cache/pypoetry/artifacts/21/c1/64/b18b0b42910be9b56e39d47eca39e249559304dcb7f7f0611b494df2d1/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl\r\ntorchvision @ file:///home/void/.cache/pypoetry/artifacts/09/3f/7e/c68656cce106803dad58bbe37993ad8c8549aa2362536e8ef70825dc00/torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl\r\ntornado @ file:///home/void/.cache/pypoetry/artifacts/73/ac/41/70b315914d448001a26418a2337c0a55911086b3a31a87013f55e807eb/tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl\r\ntqdm @ file:///home/void/.cache/pypoetry/artifacts/06/df/97/93c62ddbda15a68b2cb12a43b5f6a574d87f007c0605bccab122f5912e/tqdm-4.60.0-py2.py3-none-any.whl\r\ntraitlets @ file:///home/void/.cache/pypoetry/artifacts/25/0f/c0/2c71bbe86bec170e00a2ee9ef2af2df7b4504fbaf1e8e717622fd1d5b4/traitlets-5.0.5-py3-none-any.whl\r\ntransformers @ file:///home/void/.cache/pypoetry/artifacts/c0/1e/f0/c6485ae2555a0983158477ce44f6c9d410e65c47eebb2bda0380870055/transformers-4.5.1-py3-none-any.whl\r\ntyped-ast @ file:///home/void/.cache/pypoetry/artifacts/fe/7c/53/86cd82215775e7707b6f7cafaeed6802f93f0856a8371b0e15bc85d3c6/typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl\r\ntyper @ file:///home/void/.cache/pypoetry/artifacts/a1/4c/87/b93e3198d1bd31e5566da8c5edc193d36137b6801bb5cf651c4814fc13/typer-0.3.2-py3-none-any.whl\r\ntyping-extensions @ file:///home/void/.cache/pypoetry/artifacts/5a/dd/8f/5dc09cb3732cb0be9ecae5854eaa6aa0d4cd95752163c65283ecf9bd34/typing_extensions-3.7.4.3-py3-none-any.whl\r\nurllib3 @ file:///home/void/.cache/pypoetry/artifacts/54/b1/a1/ccbf6b869ccdaff965957abdd8e3e5aa4bee1533ed104a0d11bdc07a61/urllib3-1.26.4-py2.py3-none-any.whl\r\nwandb @ file:///home/void/.cache/pypoetry/artifacts/58/4a/7f/dec1795f5dd94d975be86acc8a335009da474696dee5d7ffd13bc93a5c/wandb-0.10.26-py2.py3-none-any.whl\r\nwasabi @ file:///home/void/.cache/pypoetry/artifacts/e9/07/cd/2f2259f00529ab2503644597edaa1bb14539b96fa7db82c95d03fce7e1/wasabi-0.8.2-py3-none-any.whl\r\nwcwidth @ file:///home/void/.cache/pypoetry/artifacts/92/12/86/71fde978823bd982c22bd549b0ba688e372403269396c892ac8160f4fe/wcwidth-0.2.5-py2.py3-none-any.whl\r\nwebencodings @ file:///home/void/.cache/pypoetry/artifacts/8e/39/d4/1735c959b3d85bebf80692957fe8ad83a2cb27de46bb08a6ababe12c44/webencodings-0.5.1-py2.py3-none-any.whl\r\nwemake-python-styleguide @ file:///home/void/.cache/pypoetry/artifacts/6e/95/41/d3af6c762397b478511953f9cea56887cffef04cd12516ff51bcfe3ad3/wemake_python_styleguide-0.14.1-py3-none-any.whl\r\nwidgetsnbextension @ file:///home/void/.cache/pypoetry/artifacts/df/8c/62/03b8d5e9a4adf6311653006eb285482908f2bf68cc88ba5c00ddc0df1c/widgetsnbextension-3.5.1-py2.py3-none-any.whl\r\nzipp @ file:///home/void/.cache/pypoetry/artifacts/16/0e/ae/e94ff238fe5d8b11b4eeb35f0ee94fd9f1b0d2182a3d47e3253ce47360/zipp-3.4.1-py3-none-any.whl\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n1. Use configuration with multiprocess data_loader with num_workers > 0 and multiple GPUs\r\n2. Use sharded dataset_reader with instances containing text fields.\r\n\r\nHere is the configuration I am using.\r\n\r\n<details>\r\n<summary><b>Configuration:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nlocal model_name = \"models/distilroberta-base-msmarco-v2/\";\r\nlocal num_gpus = 8;\r\nlocal data_base_url = \"data/SWPt512/\";\r\nlocal model = \"siamese_retrieval\";\r\nlocal base_dataset_reader = {\r\n    \"type\": \"retrieval\",\r\n    \"query_tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": model_name,\r\n      \"max_length\": 500,\r\n    },\r\n    \"query_token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": model_name,\r\n        \"namespace\": \"tokens\"\r\n      }\r\n    },\r\n};\r\n\r\n{\r\n  \"train_data_path\": data_base_url + \"valid/*.tsv\",\r\n  \"validation_data_path\": data_base_url + \"valid/2445n7jblu53lkvipo2gmm5ooq.tsv\",\r\n  \"dataset_reader\": {\r\n    \"type\": \"sharded\",\r\n    \"base_reader\": base_dataset_reader,\r\n  },\r\n  \"validation_dataset_reader\": base_dataset_reader,\r\n  'model': {\r\n    'type': model,\r\n    'transformer_model': model_name,\r\n  },\r\n  \"data_loader\": {\r\n    \"type\": \"multiprocess\",\r\n    \"batch_size\": 96,\r\n    \"shuffle\": true,\r\n    \"num_workers\": 4,\r\n  },\r\n  \"validation_data_loader\": {\r\n    \"type\": \"multiprocess\",\r\n    \"batch_size\": 96,\r\n    \"shuffle\": false,\r\n    \"num_workers\": 0,\r\n  },\r\n  \"distributed\": {\r\n    \"cuda_devices\": if num_gpus > 1 then std.range(0, num_gpus - 1) else 0,\r\n  },\r\n  \"trainer\": {\r\n    \"num_epochs\": 10,\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"lr\": 3e-5,\r\n      \"betas\": [0.9, 0.999],\r\n      \"eps\": 1e-8,\r\n      \"correct_bias\": true\r\n    },\r\n    \"learning_rate_scheduler\": {\r\n      \"type\": \"polynomial_decay\",\r\n    },\r\n    \"use_amp\": true,\r\n    \"grad_norm\": 1.0,\r\n    \"validation_metric\": \"+rec5\",\r\n    \"patience\": 3,\r\n  }\r\n}\r\n```\r\n</p>\r\n</details>\r\n\r\nAlso, here is the dataset_reader I am using.\r\n\r\n<details>\r\n<summary><b>Dataset Reader:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n# -*- coding: utf-8 -*-\r\nimport csv\r\nimport logging\r\nfrom typing import Dict, Optional\r\n\r\nfrom allennlp.common.checks import ConfigurationError\r\nfrom allennlp.common.file_utils import cached_path\r\nfrom allennlp.data.dataset_readers.dataset_reader import DatasetReader\r\nfrom allennlp.data.fields import TextField\r\nfrom allennlp.data.instance import Instance\r\nfrom allennlp.data.token_indexers import TokenIndexer\r\nfrom allennlp.data.tokenizers import Tokenizer\r\nfrom overrides import overrides\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\n@DatasetReader.register('retrieval')\r\nclass RetrievalDatasetReader(DatasetReader):\r\n    r\"\"\"Retrieval Dataset Reader.\r\n\r\n    Read a tsv file containing paired sequences, and create a dataset suitable for a\r\n    `Retrieval` model, or any model with a matching API.\r\n    Expected format for each input line: <query_string><delimiter><document_string>\r\n    The output of `read` is a list of `Instance` s with the fields:\r\n    query_tokens : `TextField` and\r\n    document_tokens : `TextField`\r\n    `START_SYMBOL` and `END_SYMBOL` tokens are added to the query and document sequences.\r\n\r\n    Args:\r\n        query_tokenizer : `Tokenizer`,\r\n            Tokenizer to use to split the input sequences into words or other kinds of tokens.\r\n            Defaults to `SpacyTokenizer()`.\r\n        query_token_indexers : `Dict[str, TokenIndexer]`,\r\n            Indexers used to define input (query side) token representations. Defaults to\r\n            `{\"tokens\": SingleIdTokenIndexer()}`.\r\n        document_tokenizer : `Tokenizer`, optional\r\n            Tokenizer to use to split the output sequences (during training) into words or\r\n            other kinds of tokens. Defaults to `query_tokenizer`.\r\n        document_token_indexers : `Dict[str, TokenIndexer]`, optional\r\n            Indexers used to define output (document side) token representations. Defaults to\r\n            `query_token_indexers`.\r\n        delimiter : `str`, (optional, default=\"\\t\")\r\n            Set delimiter for tsv/csv file.\r\n        quoting : `int`, (optional, default=`csv.QUOTE_MINIMAL`)\r\n            Quoting to use for csv reader.\r\n    \"\"\"\r\n\r\n    def __init__(  # noqa: WPS211\r\n        self,\r\n        query_tokenizer: Tokenizer,\r\n        query_token_indexers: Dict[str, TokenIndexer],\r\n        document_tokenizer: Optional[Tokenizer] = None,\r\n        document_token_indexers: Optional[Dict[str, TokenIndexer]] = None,\r\n        delimiter: str = '\\t',\r\n        query_max_tokens: Optional[int] = None,\r\n        document_max_tokens: Optional[int] = None,\r\n        quoting: int = csv.QUOTE_MINIMAL,\r\n        **kwargs,\r\n    ) -> None:\r\n        \"\"\"Initialize the dataset reader.\"\"\"\r\n        super().__init__(**kwargs)\r\n        self._query_tokenizer = query_tokenizer\r\n        self._query_token_indexers = query_token_indexers\r\n        self._document_tokenizer = document_tokenizer or self._query_tokenizer\r\n        self._document_token_indexers = document_token_indexers or self._query_token_indexers\r\n\r\n        self._delimiter = delimiter\r\n        self._query_max_tokens = query_max_tokens\r\n        self._document_max_tokens = document_max_tokens\r\n        self._query_max_exceeded = 0\r\n        self._document_max_exceeded = 0\r\n        self.quoting = quoting\r\n\r\n    @overrides\r\n    def text_to_instance(\r\n        self, query_string: str, document_string: str,\r\n    ) -> Instance:\r\n        \"\"\"Convert query and document string to instances.\"\"\"\r\n        tokenized_query = self._query_tokenizer.tokenize(query_string)\r\n        if self._query_max_tokens and len(tokenized_query) > self._query_max_tokens:\r\n            self._query_max_exceeded += 1\r\n            tokenized_query = tokenized_query[: self._query_max_tokens]\r\n        query_field = TextField(tokenized_query)\r\n        tokenized_document = self._document_tokenizer.tokenize(document_string)\r\n        if self._document_max_tokens and len(tokenized_document) > self._document_max_tokens:\r\n            self._document_max_exceeded += 1\r\n            tokenized_document = tokenized_document[: self._document_max_tokens]\r\n        document_field = TextField(tokenized_document)\r\n        return Instance({'query_tokens': query_field, 'document_tokens': document_field})\r\n\r\n    @overrides\r\n    def apply_token_indexers(self, instance: Instance):\r\n        \"\"\"Apply the token indexers.\"\"\"\r\n        query_field: TextField = instance.fields['query_tokens']  # type: ignore\r\n        document_field: TextField = instance.fields['document_tokens']  # type: ignore\r\n        query_field._token_indexers = self._query_token_indexers\r\n        document_field._token_indexers = self._document_token_indexers\r\n\r\n    @overrides\r\n    def _read(self, file_path: str):  # noqa: WPS231\r\n        # Reset exceeded counts\r\n        self._query_max_exceeded = 0\r\n        self._document_max_exceeded = 0\r\n        with open(cached_path(file_path), 'r') as data_file:\r\n            logger.info('Reading instances from lines in file at: {0}'.format(file_path))\r\n            reader = csv.reader(data_file, delimiter=self._delimiter, quoting=self.quoting)\r\n            for line_num, row in enumerate(reader):\r\n                if len(row) != 2:\r\n                    raise ConfigurationError(\r\n                        'Invalid line format: {0} (line number {1})'.format(row, line_num + 1),\r\n                    )\r\n                query_sequence, document_sequence = row\r\n                if not (query_sequence and document_sequence):\r\n                    continue\r\n                yield self.text_to_instance(query_sequence, document_sequence)\r\n        truncation_msg = 'In {0} instances, the {1} exceeded the max limit {2} and were truncated.'\r\n        if self._query_max_tokens and self._query_max_exceeded:\r\n            logger.info(\r\n                truncation_msg.format(\r\n                    self._query_max_exceeded, 'query tokens', self._query_max_tokens,\r\n                ),\r\n            )\r\n        if self._document_max_tokens and self._document_max_exceeded:\r\n            logger.info(\r\n                truncation_msg.format(\r\n                    self._document_max_exceeded, 'document tokens', self._document_max_tokens,\r\n                ),\r\n            )\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5132/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5132/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5129", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5129/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5129/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5129/events", "html_url": "https://github.com/allenai/allennlp/issues/5129", "id": 860265491, "node_id": "MDU6SXNzdWU4NjAyNjU0OTE=", "number": 5129, "title": "MNLI BERT Transformer Model Is Not Using Token Type IDs", "user": {"login": "nelson-liu", "id": 7272031, "node_id": "MDQ6VXNlcjcyNzIwMzE=", "avatar_url": "https://avatars.githubusercontent.com/u/7272031?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nelson-liu", "html_url": "https://github.com/nelson-liu", "followers_url": "https://api.github.com/users/nelson-liu/followers", "following_url": "https://api.github.com/users/nelson-liu/following{/other_user}", "gists_url": "https://api.github.com/users/nelson-liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/nelson-liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nelson-liu/subscriptions", "organizations_url": "https://api.github.com/users/nelson-liu/orgs", "repos_url": "https://api.github.com/users/nelson-liu/repos", "events_url": "https://api.github.com/users/nelson-liu/events{/privacy}", "received_events_url": "https://api.github.com/users/nelson-liu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2021-04-17T00:12:18Z", "updated_at": "2021-04-26T23:02:32Z", "closed_at": "2021-04-26T23:02:32Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nI've been getting consistently low numbers with the MNLI BERT model ~1-2 accuracy points. It appears that the MNLI model is not using `token_type_ids`.\r\n\r\nHere's what i see from allennlp\r\n\r\n```\r\n(Pdb) p tokens[\"tokens\"][\"type_ids\"][0]\r\ntensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\r\n(Pdb) p tokens[\"tokens\"][\"mask\"][0].long()\r\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\r\n(Pdb) p tokens[\"tokens\"][\"token_ids\"][0].long()\r\ntensor([  101,  1996,  2047,  2916,  2024,  3835,  2438,   102,  3071,  2428,\r\n         7777,  1996, 14751,  6666,   102,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\r\n```\r\n\r\nHere's what I see with huggingface's run_glue script\r\n\r\n```\r\n(Pdb) input_ids[0]\r\ntensor([  101,  1996,  2047,  2916,  2024,  3835,  2438,   102,  3071,  2428,\r\n         7777,  1996, 14751,  6666,   102,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n            0,     0,     0,     0,     0,     0,     0,     0])\r\n(Pdb) attention_mask[0]\r\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0])\r\n(Pdb) token_type_ids[0]\r\ntensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0])\r\n```\r\n\r\nThe input IDs and attention mask match exactly (modulo padding), but the huggingface model provides token_type_ids while the AllenNLP model has them as all 0's.\r\n\r\nThis might also be an issue in question answering, I haven't checked.\r\n\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 20.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: \r\nPython 3.7.10\r\n\r\n\r\n## Steps to reproduce\r\n\r\n1. Put a breakpoint at https://github.com/allenai/allennlp/blob/master/allennlp/modules/token_embedders/pretrained_transformer_embedder.py#L184 .\r\n2. Run https://github.com/allenai/allennlp-models/blob/main/training_config/pair_classification/mnli_roberta.jsonnet , but with BERT instead of RoBERTa\r\n3. Inspect the tokenizer output.\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5129/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5129/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5128", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5128/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5128/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5128/events", "html_url": "https://github.com/allenai/allennlp/issues/5128", "id": 859400372, "node_id": "MDU6SXNzdWU4NTk0MDAzNzI=", "number": 5128, "title": "HuggingFace Tokenizers and multiprocess worker parallelism warnings", "user": {"login": "nelson-liu", "id": 7272031, "node_id": "MDQ6VXNlcjcyNzIwMzE=", "avatar_url": "https://avatars.githubusercontent.com/u/7272031?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nelson-liu", "html_url": "https://github.com/nelson-liu", "followers_url": "https://api.github.com/users/nelson-liu/followers", "following_url": "https://api.github.com/users/nelson-liu/following{/other_user}", "gists_url": "https://api.github.com/users/nelson-liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/nelson-liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nelson-liu/subscriptions", "organizations_url": "https://api.github.com/users/nelson-liu/orgs", "repos_url": "https://api.github.com/users/nelson-liu/repos", "events_url": "https://api.github.com/users/nelson-liu/events{/privacy}", "received_events_url": "https://api.github.com/users/nelson-liu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2021-04-16T02:28:19Z", "updated_at": "2021-04-30T14:32:15Z", "closed_at": "2021-04-30T14:32:14Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "If i use a multiprocess worker, i get the following warning when loading my data:\r\n\r\n```\r\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\nTo disable this warning, you can either:\r\n        - Avoid using `tokenizers` before the fork if possible\r\n        - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n```\r\n\r\nMy dataloader config looks like:\r\n```\r\n  \"data_loader\": {\r\n    \"batch_sampler\": {\r\n      \"type\": \"bucket\",\r\n      \"batch_size\" : 8,\r\n    },\r\n    \"num_workers\": 4\r\n  },\r\n```\r\n\r\nand I'm using a pretrained transformer tokenizer like so:\r\n```\r\n    \"tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": transformer_model,\r\n      \"add_special_tokens\": false,\r\n      \"max_length\": 128\r\n    },\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5128/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5128/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5116", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5116/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5116/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5116/events", "html_url": "https://github.com/allenai/allennlp/issues/5116", "id": 856386150, "node_id": "MDU6SXNzdWU4NTYzODYxNTA=", "number": 5116, "title": "`namespace` field in `basic_classifier` has no docstring", "user": {"login": "nelson-liu", "id": 7272031, "node_id": "MDQ6VXNlcjcyNzIwMzE=", "avatar_url": "https://avatars.githubusercontent.com/u/7272031?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nelson-liu", "html_url": "https://github.com/nelson-liu", "followers_url": "https://api.github.com/users/nelson-liu/followers", "following_url": "https://api.github.com/users/nelson-liu/following{/other_user}", "gists_url": "https://api.github.com/users/nelson-liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/nelson-liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nelson-liu/subscriptions", "organizations_url": "https://api.github.com/users/nelson-liu/orgs", "repos_url": "https://api.github.com/users/nelson-liu/repos", "events_url": "https://api.github.com/users/nelson-liu/events{/privacy}", "received_events_url": "https://api.github.com/users/nelson-liu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-04-12T21:47:45Z", "updated_at": "2021-04-14T21:51:24Z", "closed_at": "2021-04-14T21:51:24Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Ref: https://github.com/allenai/allennlp/blob/main/allennlp/models/basic_classifier.py#L61", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5116/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5116/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5098", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5098/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5098/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5098/events", "html_url": "https://github.com/allenai/allennlp/issues/5098", "id": 851853371, "node_id": "MDU6SXNzdWU4NTE4NTMzNzE=", "number": 5098, "title": "`allennlp predict` broken for multitask predictors with v2.1.0+", "user": {"login": "ethch18", "id": 12580176, "node_id": "MDQ6VXNlcjEyNTgwMTc2", "avatar_url": "https://avatars.githubusercontent.com/u/12580176?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ethch18", "html_url": "https://github.com/ethch18", "followers_url": "https://api.github.com/users/ethch18/followers", "following_url": "https://api.github.com/users/ethch18/following{/other_user}", "gists_url": "https://api.github.com/users/ethch18/gists{/gist_id}", "starred_url": "https://api.github.com/users/ethch18/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ethch18/subscriptions", "organizations_url": "https://api.github.com/users/ethch18/orgs", "repos_url": "https://api.github.com/users/ethch18/repos", "events_url": "https://api.github.com/users/ethch18/events{/privacy}", "received_events_url": "https://api.github.com/users/ethch18/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2021-04-06T22:24:50Z", "updated_at": "2021-04-14T01:02:50Z", "closed_at": "2021-04-14T00:54:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nI've trained a multitask model with allennlp v2.1.0 and am trying to use it with `allennlp predict`.  However, it seems that even when I use the multitask predictor and set the default predictor for each head, I get the error message reported in #4973, even though my installation has the patch from PR #4991.\r\n\r\nI think the problem occurs when `self._get_instance_data()` is called in the `run()` function of `predict.py`.  Even though I specify that I'm using a multitask predictor, it's still going through the model's dataset reader.  I suppose another way of framing this question is, how would I specify which task name the data corresponds to (similar to the last [stack overflow](https://stackoverflow.com/questions/66156046/allennlp-2-0-using-allennlp-predict-with-multitaskdatasetreader-leads-to-runt) question)?\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/homes/gws/echau18/miniconda3/envs/lr-ssmba-multitask/bin/allennlp\", line 33, in <module>\r\n    sys.exit(load_entry_point('allennlp', 'console_scripts', 'allennlp')())\r\n  File \"/homes/gws/echau18/research-lr-ssmba/allennlp-v2/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/homes/gws/echau18/research-lr-ssmba/allennlp-v2/allennlp/commands/__init__.py\", line 119, in main\r\n    args.func(args)\r\n  File \"/homes/gws/echau18/research-lr-ssmba/allennlp-v2/allennlp/commands/predict.py\", line 258, in _predict\r\n    manager.run()\r\n  File \"/homes/gws/echau18/research-lr-ssmba/allennlp-v2/allennlp/commands/predict.py\", line 223, in run\r\n    for batch in lazy_groups_of(self._get_instance_data(), self._batch_size):\r\n  File \"/homes/gws/echau18/research-lr-ssmba/allennlp-v2/allennlp/common/util.py\", line 139, in lazy_groups_of\r\n    s = list(islice(iterator, group_size))\r\n  File \"/homes/gws/echau18/research-lr-ssmba/allennlp-v2/allennlp/commands/predict.py\", line 209, in _get_instance_data\r\n    yield from self._dataset_reader.read(self._input_file)\r\n  File \"/homes/gws/echau18/research-lr-ssmba/allennlp-v2/allennlp/data/dataset_readers/multitask.py\", line 31, in read\r\n    raise RuntimeError(\"This class is not designed to be called like this\")\r\nRuntimeError: This class is not designed to be called like this\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- #4973\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.10\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n-e git+git@github.com:ethch18/allennlp.git@3d3c6176215cae46a0be8bf9a40a8141a04e76d7#egg=allennlp&subdirectory=../../allennlp-v2\r\nappdirs==1.4.4\r\nattrs==20.3.0\r\nblack==20.8b1\r\nblis==0.7.4\r\nboto3==1.17.27\r\nbotocore==1.20.27\r\ncached-property==1.5.2\r\ncatalogue==2.0.1\r\ncertifi==2020.12.5\r\nchardet==4.0.0\r\nclick==7.1.2\r\nconllu==4.4\r\ncycler==0.10.0\r\ncymem==2.0.5\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl\r\nfilelock==3.0.12\r\nh5py==3.2.1\r\nidna==2.10\r\nimportlib-metadata==3.7.2\r\niniconfig==1.1.1\r\njavapackages==4.3.2\r\nJinja2==3.0.0a1\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonnet==0.17.0\r\njsonpickle==2.0.0\r\nkiwisolver==1.3.1\r\nlmdb==1.1.1\r\nMarkupSafe==2.0.0rc1\r\nmatplotlib==3.4.0\r\nmccabe==0.6.1\r\nmkl-fft==1.3.0\r\nmkl-random==1.1.1\r\nmkl-service==2.3.0\r\nmore-itertools==8.7.0\r\nmurmurhash==1.0.5\r\nmypy-extensions==0.4.3\r\nnltk==3.5\r\nnumpy @ file:///tmp/build/80754af9/numpy_and_numpy_base_1603479632437/work\r\nolefile==0.46\r\noverrides==3.1.0\r\npackaging==20.9\r\npathspec==0.8.1\r\npathy==0.4.0\r\nPillow @ file:///tmp/build/80754af9/pillow_1615057347459/work\r\npluggy==1.0.0.dev0\r\npreshed==3.0.5\r\nprotobuf==4.0.0rc2\r\npy==1.10.0\r\npycodestyle==2.6.0\r\npydantic==1.7.3\r\npyflakes==2.2.0\r\npyparsing==3.0.0b2\r\npytest==6.2.2\r\npython-dateutil==2.8.1\r\nPyXB==1.2.4\r\nregex==2020.11.13\r\nrequests==2.25.1\r\ns3transfer==0.3.4\r\nsacremoses==0.0.43\r\nscikit-learn==0.24.1\r\nscipy==1.6.1\r\nsentencepiece==0.1.95\r\nsix @ file:///tmp/build/80754af9/six_1605205313296/work\r\nsmart-open==3.0.0\r\nspacy==3.0.5\r\nspacy-legacy==3.0.1\r\nsrsly==2.4.0\r\ntensorboardX==2.1\r\nthinc==8.0.2\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.10.1\r\ntoml==0.10.2\r\ntorch==1.7.1\r\ntorchaudio==0.7.0a0+a853dff\r\ntorchvision==0.8.2\r\ntqdm==4.59.0\r\ntransformers==4.3.3\r\ntyped-ast==1.4.2\r\ntyper==0.3.2\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.26.3\r\nwasabi==0.8.2\r\nzipp==3.4.1\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n1. Train a multitask model (example config [here](https://gist.github.com/ethch18/adb1750451bc80cec7dc5017dace26e7))\r\n2. Run `allennlp predict` as follows:\r\n```bash\r\nallennlp predict /path/to/model.tar.gz /path/to/test.conllu --use-dataset-reader --include-package modules-v2 --predictor multitask --cuda-device -1 --output-file ./mtlud.txt --dataset-reader-choice validation\r\n```\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5098/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5098/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5088", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5088/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5088/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5088/events", "html_url": "https://github.com/allenai/allennlp/issues/5088", "id": 848779663, "node_id": "MDU6SXNzdWU4NDg3Nzk2NjM=", "number": 5088, "title": "Multi-GPU training hangs", "user": {"login": "aleSuglia", "id": 1479733, "node_id": "MDQ6VXNlcjE0Nzk3MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1479733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aleSuglia", "html_url": "https://github.com/aleSuglia", "followers_url": "https://api.github.com/users/aleSuglia/followers", "following_url": "https://api.github.com/users/aleSuglia/following{/other_user}", "gists_url": "https://api.github.com/users/aleSuglia/gists{/gist_id}", "starred_url": "https://api.github.com/users/aleSuglia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aleSuglia/subscriptions", "organizations_url": "https://api.github.com/users/aleSuglia/orgs", "repos_url": "https://api.github.com/users/aleSuglia/repos", "events_url": "https://api.github.com/users/aleSuglia/events{/privacy}", "received_events_url": "https://api.github.com/users/aleSuglia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 31, "created_at": "2021-04-01T20:49:40Z", "updated_at": "2021-08-03T20:39:48Z", "closed_at": "2021-04-21T22:44:23Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `main` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/main/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/main/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/main) to find out if the bug was already fixed in the main branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nI am trying to run multi-GPU training (using 4 GPUs) but it hangs after a few iterations (roughly 15 iterations). This happens both with my custom model as well as with models in `allennlp-models` (I tried [roberta-large](https://github.com/allenai/allennlp-models/blob/main/training_config/classification/boolq_roberta.jsonnet)). \r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\nOS: Deep Learning AMI (Ubuntu 18.04) Version 42.1 -- AWS EC2 p3.8xlarge\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.8 installed via Anaconda\r\n\r\n## Steps to reproduce\r\n\r\nI have installed `allennlp-models` and changed the configuration file reported above as follows:\r\n\r\n```\r\nlocal transformer_model = \"roberta-base\";\r\nlocal transformer_dim = 768;\r\n\r\n{\r\n  \"dataset_reader\":{\r\n    \"type\": \"boolq\",\r\n    \"token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": transformer_model,\r\n      }\r\n    },\r\n    \"tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": transformer_model,\r\n    }\r\n  },\r\n  \"train_data_path\": \"https://storage.googleapis.com/allennlp-public-data/BoolQ.zip!BoolQ/train.jsonl\",\r\n  \"validation_data_path\": \"https://storage.googleapis.com/allennlp-public-data/BoolQ.zip!BoolQ/val.jsonl\",\r\n  \"test_data_path\": \"https://storage.googleapis.com/allennlp-public-data/BoolQ.zip!BoolQ/test.jsonl\",\r\n  \"model\": {\r\n    \"type\": \"basic_classifier\",\r\n    \"text_field_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer\",\r\n          \"model_name\": transformer_model,\r\n        }\r\n      }\r\n    },\r\n    \"seq2vec_encoder\": {\r\n       \"type\": \"bert_pooler\",\r\n       \"pretrained_model\": transformer_model,\r\n       \"dropout\": 0.1,\r\n    },\r\n    \"namespace\": \"tags\",\r\n    \"num_labels\": 2,\r\n  },\r\n  \"data_loader\": {\r\n    \"batch_sampler\": {\r\n      \"type\": \"bucket\",\r\n      \"sorting_keys\": [\"tokens\"],\r\n      \"batch_size\" : 4\r\n    }\r\n  },\r\n  \"distributed\": {\r\n      \"cuda_devices\": [0,1,2,3]\r\n  },\r\n  \"trainer\": {\r\n    \"num_epochs\": 10,\r\n    \"num_gradient_accumulation_steps\": 2,\r\n    \"validation_metric\": \"+accuracy\",\r\n    \"learning_rate_scheduler\": {\r\n      \"type\": \"slanted_triangular\",\r\n      \"num_epochs\": 10,\r\n      \"num_steps_per_epoch\": 3088,\r\n      \"cut_frac\": 0.06\r\n    },\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"lr\": 1e-5,\r\n      \"weight_decay\": 0.1,\r\n    }\r\n  },\r\n}\r\n```\r\n@epwalsh Any ideas?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5088/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5088/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5081", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5081/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5081/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5081/events", "html_url": "https://github.com/allenai/allennlp/issues/5081", "id": 846322913, "node_id": "MDU6SXNzdWU4NDYzMjI5MTM=", "number": 5081, "title": "FeedForward not pickable", "user": {"login": "aleSuglia", "id": 1479733, "node_id": "MDQ6VXNlcjE0Nzk3MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1479733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aleSuglia", "html_url": "https://github.com/aleSuglia", "followers_url": "https://api.github.com/users/aleSuglia/followers", "following_url": "https://api.github.com/users/aleSuglia/following{/other_user}", "gists_url": "https://api.github.com/users/aleSuglia/gists{/gist_id}", "starred_url": "https://api.github.com/users/aleSuglia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aleSuglia/subscriptions", "organizations_url": "https://api.github.com/users/aleSuglia/orgs", "repos_url": "https://api.github.com/users/aleSuglia/repos", "events_url": "https://api.github.com/users/aleSuglia/events{/privacy}", "received_events_url": "https://api.github.com/users/aleSuglia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2021-03-31T09:54:26Z", "updated_at": "2021-03-31T21:26:37Z", "closed_at": "2021-03-31T21:26:37Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nHi, I'm unable to use multiprocessing code that is using a Predictor having a FeedForward component. The worker is not able to copy the object with error: `AttributeError: Can't pickle local object '<lambda>.<locals>.<lambda>'`. I've also reported a runnable script that allows you to replicate the error.\r\n\r\n## Related issues or possible duplicates\r\n\r\n- I believe this could be a problem to what the `Lazy` class previously had. It doesn't look the `FeedForward` class has any lambda function in it though.\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: MacOS\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.12.0\r\naddict==2.4.0\r\nai2thor==2.1.0\r\naiohttp==3.7.4.post0\r\nallennlp @ git+https://github.com/allenai/allennlp@4baf19ab7b3aeae9f1c47700d4ac71616af0316e\r\nappnope==0.1.2\r\nargon2-cffi==20.1.0\r\nasync-generator==1.10\r\nasync-timeout==3.0.1\r\nattrs==20.3.0\r\naws-requests-auth==0.4.3\r\nbackcall==0.2.0\r\nbleach==3.3.0\r\nblis==0.7.4\r\nboto3==1.17.31\r\nbotocore==1.20.31\r\ncachetools==4.2.1\r\ncatalogue==2.0.1\r\ncertifi==2020.12.5\r\ncffi==1.14.5\r\nchardet==4.0.0\r\nclick==7.1.2\r\nconfigparser==5.0.2\r\ncycler==0.10.0\r\ncymem==2.0.5\r\ndecorator==4.4.2\r\ndefusedxml==0.7.1\r\ndocker-pycreds==0.4.0\r\nentrypoints==0.3\r\nfilelock==3.0.12\r\nFlask==1.1.2\r\nfsspec==0.8.7\r\nfuture==0.18.2\r\nfutures==3.1.1\r\ngitdb==4.0.7\r\nGitPython==3.1.14\r\ngoogle-auth==1.28.0\r\ngoogle-auth-oauthlib==0.4.3\r\ngrpcio==1.36.1\r\nh5py==3.2.1\r\nidna==2.10\r\niniconfig==1.1.1\r\nipykernel==5.5.0\r\nipython==7.21.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.3\r\nitsdangerous==1.1.0\r\njedi==0.18.0\r\nJinja2==2.11.3\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonnet==0.17.0\r\njsonpickle==2.0.0\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==6.1.12\r\njupyter-console==6.3.0\r\njupyter-core==4.7.1\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.0\r\nkiwisolver==1.3.1\r\nlmdb==1.1.1\r\nMarkdown==3.3.4\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.3.4\r\nmistune==0.8.4\r\nmkl-fft==1.3.0\r\nmkl-random==1.1.1\r\nmkl-service==2.3.0\r\nmore-itertools==8.7.0\r\nmsgpack==1.0.2\r\nmultidict==5.1.0\r\nmurmurhash==1.0.5\r\nnbclient==0.5.3\r\nnbconvert==6.0.7\r\nnbformat==5.1.2\r\nnest-asyncio==1.5.1\r\nnetworkx==2.5\r\nnltk==3.5\r\nnotebook==6.3.0\r\nnumpy @ file:///opt/concourse/worker/volumes/live/5572694e-967a-4c0c-52cf-b53d43e72de9/volume/numpy_and_numpy_base_1603491881791/work\r\noauthlib==3.1.0\r\nolefile==0.46\r\nopen3d==0.12.0\r\nopencv-python==4.5.1.48\r\noverrides==3.1.0\r\npackaging==20.9\r\npandas==1.2.3\r\npandocfilters==1.4.3\r\nparso==0.8.1\r\npathtools==0.1.2\r\npathy==0.4.0\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow @ file:///opt/concourse/worker/volumes/live/b6dec6d8-7e9d-4d46-615c-691883c22eae/volume/pillow_1615057391629/work\r\npluggy==0.13.1\r\nplyfile==0.7.3\r\npreshed==3.0.5\r\nprogressbar2==3.53.1\r\nprometheus-client==0.9.0\r\npromise==2.3\r\nprompt-toolkit==3.0.17\r\nprotobuf==3.15.6\r\npsutil==5.8.0\r\nptyprocess==0.7.0\r\npy==1.10.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\npydantic==1.7.3\r\nPygments==2.8.1\r\npyparsing==2.4.7\r\npyrsistent==0.17.3\r\npytest==6.2.2\r\npython-dateutil==2.8.1\r\npython-utils==2.5.6\r\npytorch-lightning==1.2.4\r\npytz==2021.1\r\nPyYAML==5.3.1\r\npyzmq==22.0.3\r\nqtconsole==5.0.3\r\nQtPy==1.9.0\r\nregex==2021.3.17\r\nrequests==2.25.1\r\nrequests-oauthlib==1.3.0\r\nrsa==4.7.2\r\ns3transfer==0.3.5\r\nsacremoses==0.0.43\r\nscikit-learn==0.24.1\r\nscipy==1.6.1\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.95\r\nsentry-sdk==1.0.0\r\nshortuuid==1.0.1\r\nsix @ file:///opt/concourse/worker/volumes/live/5b31cb27-1e37-4ca5-6e9f-86246eb206d2/volume/six_1605205320872/work\r\nsklearn==0.0\r\nsmart-open==3.0.0\r\nsmmap==4.0.0\r\nspacy==3.0.5\r\nspacy-legacy==3.0.1\r\nsrsly==2.4.0\r\nsubprocess32==3.5.4\r\ntensorboard==2.4.1\r\ntensorboard-plugin-wit==1.8.0\r\ntensorboardX==2.1\r\nterminado==0.9.3\r\ntestpath==0.4.4\r\nthinc==8.0.2\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.10.1\r\ntoml==0.10.2\r\ntorch==1.7.1\r\ntorchaudio==0.8.0a0+a751e1d\r\ntorchvision==0.8.2\r\ntornado==6.1\r\ntqdm==4.59.0\r\ntraitlets==5.0.5\r\ntransformers==4.3.3\r\ntyper==0.3.2\r\ntyping-extensions @ file:///home/ktietz/src/ci_mi/typing_extensions_1612808209620/work\r\nurllib3==1.26.4\r\nwandb==0.10.24\r\nwasabi==0.8.2\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.5.1\r\nyarl==1.6.3\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nimport torch.multiprocessing as mp\r\nfrom allennlp.common import Params\r\nfrom allennlp.modules import FeedForward\r\n\r\n\r\ndef run(model):\r\n    pass\r\n\r\n\r\ndef main():\r\n    model = FeedForward.from_params(Params({\r\n        \"input_dim\": 768,\r\n        \"hidden_dims\": [13],\r\n        \"num_layers\": 1,\r\n        \"activations\": [\"linear\"],\r\n        \"dropout\": [0.0]\r\n    }))\r\n\r\n    model.share_memory()\r\n\r\n    threads = []\r\n\r\n    for n in range(4):\r\n        thread = mp.Process(target=run, args=[model])\r\n        thread.start()\r\n        threads.append(thread)\r\n\r\n    for t in threads:\r\n        t.join()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5081/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5081/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5080", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5080/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5080/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5080/events", "html_url": "https://github.com/allenai/allennlp/issues/5080", "id": 845774359, "node_id": "MDU6SXNzdWU4NDU3NzQzNTk=", "number": 5080, "title": "error output", "user": {"login": "shihuanting", "id": 29172116, "node_id": "MDQ6VXNlcjI5MTcyMTE2", "avatar_url": "https://avatars.githubusercontent.com/u/29172116?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shihuanting", "html_url": "https://github.com/shihuanting", "followers_url": "https://api.github.com/users/shihuanting/followers", "following_url": "https://api.github.com/users/shihuanting/following{/other_user}", "gists_url": "https://api.github.com/users/shihuanting/gists{/gist_id}", "starred_url": "https://api.github.com/users/shihuanting/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shihuanting/subscriptions", "organizations_url": "https://api.github.com/users/shihuanting/orgs", "repos_url": "https://api.github.com/users/shihuanting/repos", "events_url": "https://api.github.com/users/shihuanting/events{/privacy}", "received_events_url": "https://api.github.com/users/shihuanting/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2021-03-31T03:39:46Z", "updated_at": "2021-04-21T22:44:53Z", "closed_at": "2021-04-21T22:44:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "I havr a problem,hope you can give me some advice\r\n\r\n```\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.tagging\r\nfrom allennlp.models import archival\r\n\r\n\r\ndef TestSRL():\r\n    input = {\"sentence\": \"However, voters decided that if the stadium was such a good idea someone would build it himself, and rejected it 59% to 41%.\"}\r\n    arc = archival\r\n    arch = arc.load_archive('D:/srl-model-2018.05.25.tar.gz')\r\n    predictor = Predictor.from_archive(arch, 'semantic-role-labeling')\r\n    result = predictor.predict_json(input)\r\n    print(result)\r\n\r\n\r\nif __name__ == '__main__':\r\n    TestSRL()\r\n```\r\n\r\nerror output:      `allennlp.common.checks.ConfigurationError: srl not in acceptable choices for dataset_reader.type: ['babi', 'conll2003', 'interleaving', 'multitask', 'sequence_tagging', 'sharded', 'text_classification_json', 'multitask_shim', 'ccgbank', 'conll2000', 'ontonotes_ner']. You should either use the --include-package flag to make sure the correct module is loaded, or use a fully qualified class name in your config file like {\"model\": \"my_module.models.MyModel\"} to have it imported automatically.`\r\n\r\n```\r\nallennlp == 2.2.0\r\nallennlp_models ==2.2.0\r\n```\r\n\r\nThank you for your reply", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5080/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5080/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5076", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5076/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5076/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5076/events", "html_url": "https://github.com/allenai/allennlp/issues/5076", "id": 845325663, "node_id": "MDU6SXNzdWU4NDUzMjU2NjM=", "number": 5076, "title": "1 model state file left when num_serialized_models_to_keep=0 and patience used", "user": {"login": "ksteimel", "id": 25189520, "node_id": "MDQ6VXNlcjI1MTg5NTIw", "avatar_url": "https://avatars.githubusercontent.com/u/25189520?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ksteimel", "html_url": "https://github.com/ksteimel", "followers_url": "https://api.github.com/users/ksteimel/followers", "following_url": "https://api.github.com/users/ksteimel/following{/other_user}", "gists_url": "https://api.github.com/users/ksteimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ksteimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ksteimel/subscriptions", "organizations_url": "https://api.github.com/users/ksteimel/orgs", "repos_url": "https://api.github.com/users/ksteimel/repos", "events_url": "https://api.github.com/users/ksteimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ksteimel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2021-03-30T21:47:09Z", "updated_at": "2021-04-23T00:09:32Z", "closed_at": "2021-04-23T00:09:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Checklist\r\n\r\n\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nIf `num_serialized_models_to_keep` is set to 0 and the model stops early due to running out of patience, it leaves one model state file behind in the serialization directory. The expected behavior is that there are no model state files left in this directory (as is the case when training is not stopped due to running out of patience).\r\n\r\nI can quickly submit a PR to fix this.\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- https://github.com/allenai/allennlp/pull/2880/commits \r\n  - Though this is different because the present issue only emerging when the model stops training due to running out of patience.\r\n\r\n## Environment\r\n\r\nOS: Linux\r\n\r\nPython version: 3.8.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp==3.7.4.post0\r\n-e git+git@github.com:ksteimel/allennlp.git@59b92106443ff6ce26776beef5259dee3a422b40#egg=allennlp\r\nallennlp-models==2.1.0\r\nappdirs==1.4.3\r\nasync-timeout==3.0.1\r\nattrs==20.3.0\r\nbeautifulsoup4==4.9.3\r\nblis==0.4.1\r\nboto3==1.17.22\r\nbotocore==1.20.22\r\nCacheControl==0.12.6\r\ncatalogue==1.0.0\r\ncertifi==2019.11.28\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncolorama==0.4.3\r\nconfigparser==5.0.2\r\nconllu==4.4\r\ncontextlib2==0.6.0\r\ncoverage==5.5\r\ncycler==0.10.0\r\ncymem==2.0.5\r\ndistlib==0.3.0\r\ndistro==1.4.0\r\ndocker-pycreds==0.4.0\r\nfilelock==3.0.12\r\nftfy==5.9\r\nfuture==0.18.2\r\ngitdb==4.0.7\r\nGitPython==3.1.14\r\ngoogle==3.0.0\r\ngrpcio==1.36.1\r\nh5py==3.2.1\r\nhtml5lib==1.0.1\r\nidna==2.8\r\niniconfig==1.1.1\r\nipaddr==2.2.0\r\nJinja2==2.11.3\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonnet==0.17.0\r\njsonpickle==2.0.0\r\njsonschema==3.2.0\r\nkiwisolver==1.3.1\r\nlmdb==1.1.1\r\nlockfile==0.12.2\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.4.0\r\nmore-itertools==8.7.0\r\nmsgpack==0.6.2\r\nmultidict==5.1.0\r\nmurmurhash==1.0.5\r\nnltk==3.5\r\nnumpy==1.20.1\r\noverrides==3.1.0\r\npackaging==20.3\r\npandas==1.2.3\r\npathtools==0.1.2\r\npathy==0.4.0\r\npep517==0.8.2\r\nPillow==8.1.2\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.5\r\nprogress==1.5\r\npromise==2.3\r\nprotobuf==3.15.5\r\npsutil==5.8.0\r\npy==1.10.0\r\npy-rouge==1.1\r\npy-spy==0.3.5\r\npydantic==1.7.3\r\npyparsing==2.4.6\r\npyrsistent==0.17.3\r\npytest==6.2.2\r\npytest-cov==2.11.1\r\npython-dateutil==2.8.1\r\npytoml==0.1.21\r\npytz==2021.1\r\nPyYAML==5.4.1\r\nray==0.8.6\r\nredis==3.4.1\r\nregex==2020.11.13\r\nrequests==2.22.0\r\nretrying==1.3.3\r\ns3transfer==0.3.4\r\nsacremoses==0.0.43\r\nscikit-learn==0.24.1\r\nscipy==1.6.1\r\nseaborn==0.11.1\r\nsentencepiece==0.1.95\r\nsentry-sdk==1.0.0\r\nshortuuid==1.0.1\r\nsix==1.14.0\r\nsmart-open==3.0.0\r\nsmmap==4.0.0\r\nsoupsieve==2.2.1\r\nspacy==2.2.4\r\nspacy-legacy==3.0.1\r\nsrsly==1.0.5\r\nsubprocess32==3.5.4\r\ntabulate==0.8.9\r\ntensorboardX==2.1\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.10.1\r\ntoml==0.10.2\r\ntorch==1.7.1\r\ntorchvision==0.8.2\r\ntqdm==4.59.0\r\ntransformers==4.3.3\r\ntyper==0.3.2\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.25.8\r\nwandb==0.10.23\r\nwasabi==0.8.2\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nword2number==1.1\r\nyarl==1.6.3\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\nHere is a minimal config file that causes this issue:\r\n```\r\n{\r\n    \"dataset_reader\": {\r\n        \"type\": \"classification-tsv\",\r\n        \"token_indexers\": {\"tokens\": {\"type\": \"single_id\"}}\r\n    },\r\n    \"train_data_path\": \"../../../quick_start/data/movie_review/train.tsv\",\r\n    \"validation_data_path\": \"../../../quick_start/data/movie_review/dev.tsv\",\r\n    \"model\": {\r\n        \"type\": \"simple_classifier\",\r\n        \"embedder\": {\r\n            \"token_embedders\": {\"tokens\": {\"type\": \"embedding\", \"embedding_dim\": 10}}\r\n        },\r\n        \"encoder\": {\"type\": \"bag_of_embeddings\", \"embedding_dim\": 10}\r\n    },\r\n    \"data_loader\": {\"batch_size\": 8, \"shuffle\": true},\r\n    \"trainer\": {\"optimizer\": \"adam\", \"num_epochs\": 50, \"patience\": 1, \"checkpointer\" : {\"num_serialized_models_to_keep\": 0}}\r\n}\r\n```\r\nThis minimal config uses the example and model from [part 1 of the allennlp-guide](https://github.com/allenai/allennlp-guide/blob/master/exercises/part1/training-and-prediction/config_setup.py).", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5076/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5076/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5071", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5071/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5071/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5071/events", "html_url": "https://github.com/allenai/allennlp/issues/5071", "id": 843188155, "node_id": "MDU6SXNzdWU4NDMxODgxNTU=", "number": 5071, "title": "Model performance on validation is not deterministic in GradientDescentTrainer", "user": {"login": "Aktsvigun", "id": 36672861, "node_id": "MDQ6VXNlcjM2NjcyODYx", "avatar_url": "https://avatars.githubusercontent.com/u/36672861?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aktsvigun", "html_url": "https://github.com/Aktsvigun", "followers_url": "https://api.github.com/users/Aktsvigun/followers", "following_url": "https://api.github.com/users/Aktsvigun/following{/other_user}", "gists_url": "https://api.github.com/users/Aktsvigun/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aktsvigun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aktsvigun/subscriptions", "organizations_url": "https://api.github.com/users/Aktsvigun/orgs", "repos_url": "https://api.github.com/users/Aktsvigun/repos", "events_url": "https://api.github.com/users/Aktsvigun/events{/privacy}", "received_events_url": "https://api.github.com/users/Aktsvigun/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-03-29T09:42:06Z", "updated_at": "2021-04-02T01:05:29Z", "closed_at": "2021-04-02T01:05:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "Apologizes, my mistake, please delete the issue.\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5071/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5071/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5067", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5067/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5067/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5067/events", "html_url": "https://github.com/allenai/allennlp/issues/5067", "id": 840850576, "node_id": "MDU6SXNzdWU4NDA4NTA1NzY=", "number": 5067, "title": "Training state of last epoch not saved due to early stopping", "user": {"login": "alanwang93", "id": 13610343, "node_id": "MDQ6VXNlcjEzNjEwMzQz", "avatar_url": "https://avatars.githubusercontent.com/u/13610343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alanwang93", "html_url": "https://github.com/alanwang93", "followers_url": "https://api.github.com/users/alanwang93/followers", "following_url": "https://api.github.com/users/alanwang93/following{/other_user}", "gists_url": "https://api.github.com/users/alanwang93/gists{/gist_id}", "starred_url": "https://api.github.com/users/alanwang93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alanwang93/subscriptions", "organizations_url": "https://api.github.com/users/alanwang93/orgs", "repos_url": "https://api.github.com/users/alanwang93/repos", "events_url": "https://api.github.com/users/alanwang93/events{/privacy}", "received_events_url": "https://api.github.com/users/alanwang93/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2021-03-25T11:50:53Z", "updated_at": "2021-04-23T00:09:32Z", "closed_at": "2021-04-23T00:09:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "`trainer.py` line 1006 will break the loop, and `dump_metrics` on line 1030 & `save_checkpoint` on line 1043 are skipped.\r\n\r\n```python\r\nthis_epoch_val_metric = self._metric_tracker.combined_score(val_metrics)                    self._metric_tracker.add_metrics(val_metrics)\r\nif self._metric_tracker.should_stop_early():\r\n   logger.info(\"Ran out of patience.  Stopping training.\")\r\n   break\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5067/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5067/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5064", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5064/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5064/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5064/events", "html_url": "https://github.com/allenai/allennlp/issues/5064", "id": 836334672, "node_id": "MDU6SXNzdWU4MzYzMzQ2NzI=", "number": 5064, "title": "RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling cublasSgemm", "user": {"login": "nelson-liu", "id": 7272031, "node_id": "MDQ6VXNlcjcyNzIwMzE=", "avatar_url": "https://avatars.githubusercontent.com/u/7272031?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nelson-liu", "html_url": "https://github.com/nelson-liu", "followers_url": "https://api.github.com/users/nelson-liu/followers", "following_url": "https://api.github.com/users/nelson-liu/following{/other_user}", "gists_url": "https://api.github.com/users/nelson-liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/nelson-liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nelson-liu/subscriptions", "organizations_url": "https://api.github.com/users/nelson-liu/orgs", "repos_url": "https://api.github.com/users/nelson-liu/repos", "events_url": "https://api.github.com/users/nelson-liu/events{/privacy}", "received_events_url": "https://api.github.com/users/nelson-liu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 17, "created_at": "2021-03-19T20:25:55Z", "updated_at": "2021-06-03T18:29:55Z", "closed_at": "2021-05-24T23:20:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nWhen I train RoBERTa (or BERT, but let's just stick with RoBERTa in this issue in the interest of simplicity) on MNLI, I get an odd CUDA error.\r\n\r\n```\r\n  File \"/opt/conda/lib/python3.7/site-packages/allennlp/models/basic_classifier.py\", line 116,[26/1829$\r\nrd\r\n    embedded_text = self._text_field_embedder(tokens)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/allennlp/modules/text_field_embedders/basic_text_field_e\r\nmbedder.py\", line 103, in forward\r\n    token_vectors = embedder(**tensors, **forward_params_values)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/allennlp/modules/token_embedders/pretrained_transformer_\r\nembedder.py\", line 201, in forward\r\n    transformer_output = self.transformer_model(**parameters)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\", line 8\r\n22, in forward\r\n    return_dict=return_dict,\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\", line 5\r\n15, in forward\r\n    output_attentions,\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\", line 4\r\n36, in forward\r\n    self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\r\n  File \"/opt/conda/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 1819, in apply_chu\r\nnking_to_forward\r\n    return forward_fn(*input_tensors)\r\n  File \"/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\", line 4\r\n47, in feed_forward_chunk\r\n    intermediate_output = self.intermediate(attention_output)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\", line 3\r\n48, in forward\r\n    hidden_states = self.dense(hidden_states)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\", line 94, in forward\r\n    return F.linear(input, self.weight, self.bias)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\", line 1753, in linear\r\n    return torch._C._nn.linear(input, weight, bias)\r\nRuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m\r\n, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\r\n```\r\n\r\n## Environment\r\n\r\nI made a docker image that reproduces this issue at: https://hub.docker.com/r/nfliu/torch1.8.0-sgemm-execution-debugging . The associated dockerfile is https://gist.github.com/nelson-liu/f80d76f5557d48f2a52b2082b1bf86da . In short, it is based off of the NVIDIA cuda 11.1 container, and installs allennlp and allennlp-models off the most recent commits, and also pytorch 1.8.0+cu111. The python is python 3.7\r\n\r\nHere's the output of nvidia-smi (for things like driver version, etc)\r\n\r\n```\r\n$ nvidia-smi\r\nFri Mar 19 13:26:08 2021\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN Xp            On   | 00000000:5E:00.0 Off |                  N/A |\r\n| 23%   26C    P8     9W / 250W |      1MiB / 12196MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\n\r\n## Steps to reproduce\r\n\r\n1. Go to a machine with a titanxp and a driver that supports cuda 11.1\r\n2. `nvidia-docker run --rm -it nfliu/torch1.8.0-sgemm-execution-debugging`\r\n3. `allennlp train https://gist.githubusercontent.com/nelson-liu/2164bb51097c5a8f9f9e8\r\nd7784f8473e/raw/ce93da75558489177556355c8d54ca4949417b8b/roberta_base_mnli.jsonnet -s output`\r\n4. You should see the error above within the first epoch. If not, it'd be great to know that you can't reproduce the issue.\r\n\r\nThe config is at https://gist.github.com/nelson-liu/2164bb51097c5a8f9f9e8d7784f8473e , it's exactly the same as the RoBERTa MNLI config except I'm using RoBERTa base and a batch size of 8, since the titanxp has a bit less memory.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5064/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5064/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5060", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5060/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5060/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5060/events", "html_url": "https://github.com/allenai/allennlp/issues/5060", "id": 834789777, "node_id": "MDU6SXNzdWU4MzQ3ODk3Nzc=", "number": 5060, "title": "When using AllenNLP DEMO 'Semantic Role Labeling',it doesn't work.", "user": {"login": "gaozhiguang", "id": 34132216, "node_id": "MDQ6VXNlcjM0MTMyMjE2", "avatar_url": "https://avatars.githubusercontent.com/u/34132216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gaozhiguang", "html_url": "https://github.com/gaozhiguang", "followers_url": "https://api.github.com/users/gaozhiguang/followers", "following_url": "https://api.github.com/users/gaozhiguang/following{/other_user}", "gists_url": "https://api.github.com/users/gaozhiguang/gists{/gist_id}", "starred_url": "https://api.github.com/users/gaozhiguang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gaozhiguang/subscriptions", "organizations_url": "https://api.github.com/users/gaozhiguang/orgs", "repos_url": "https://api.github.com/users/gaozhiguang/repos", "events_url": "https://api.github.com/users/gaozhiguang/events{/privacy}", "received_events_url": "https://api.github.com/users/gaozhiguang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-03-18T13:09:08Z", "updated_at": "2021-03-18T13:24:10Z", "closed_at": "2021-03-18T13:20:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "**My code is as same as the demo:**\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.tagging\r\n\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")\r\npredictor.predict(\r\n    sentence=\"Did Uriah honestly think he could beat the game in under three hours?.\"\r\n)\r\n**But this bug happens:**\r\nTraceback (most recent call last):\r\n  File \"/home/zggao/anaconda3/envs/test-coreference-resolution/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/zggao/anaconda3/envs/test-coreference-resolution/lib/python3.6/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/zggao/anaconda3/envs/test-coreference-resolution/lib/python3.6/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/zggao/anaconda3/envs/test-coreference-resolution/lib/python3.6/site-packages/allennlp/commands/predict.py\", line 197, in _predict\r\n    predictor = _get_predictor(args)\r\n  File \"/home/zggao/anaconda3/envs/test-coreference-resolution/lib/python3.6/site-packages/allennlp/commands/predict.py\", line 98, in _get_predictor\r\n    overrides=args.overrides,\r\n  File \"/home/zggao/anaconda3/envs/test-coreference-resolution/lib/python3.6/site-packages/allennlp/models/archival.py\", line 197, in load_archive\r\n    opt_level=opt_level,\r\n  File \"/home/zggao/anaconda3/envs/test-coreference-resolution/lib/python3.6/site-packages/allennlp/models/model.py\", line 398, in load\r\n    return model_class._load(config, serialization_dir, weights_file, cuda_device, opt_level)\r\n  File \"/home/zggao/anaconda3/envs/test-coreference-resolution/lib/python3.6/site-packages/allennlp/models/model.py\", line 337, in _load\r\n    model.load_state_dict(model_state)\r\n  File \"/home/zggao/anaconda3/envs/test-coreference-resolution/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 847, in load_state_dict\r\n    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\r\nRuntimeError: Error(s) in loading state_dict for SrlBert:\r\n\tUnexpected key(s) in state_dict: \"bert_model.embeddings.position_ids\".\r\n\r\nI don't know why,is it the version problem?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5060/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5060/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5055", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5055/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5055/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5055/events", "html_url": "https://github.com/allenai/allennlp/issues/5055", "id": 832691475, "node_id": "MDU6SXNzdWU4MzI2OTE0NzU=", "number": 5055, "title": "from_pretrained_transformer not called in commnad line predict mode with BasicClassifier", "user": {"login": "McKracken", "id": 7049505, "node_id": "MDQ6VXNlcjcwNDk1MDU=", "avatar_url": "https://avatars.githubusercontent.com/u/7049505?v=4", "gravatar_id": "", "url": "https://api.github.com/users/McKracken", "html_url": "https://github.com/McKracken", "followers_url": "https://api.github.com/users/McKracken/followers", "following_url": "https://api.github.com/users/McKracken/following{/other_user}", "gists_url": "https://api.github.com/users/McKracken/gists{/gist_id}", "starred_url": "https://api.github.com/users/McKracken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/McKracken/subscriptions", "organizations_url": "https://api.github.com/users/McKracken/orgs", "repos_url": "https://api.github.com/users/McKracken/repos", "events_url": "https://api.github.com/users/McKracken/events{/privacy}", "received_events_url": "https://api.github.com/users/McKracken/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2021-03-16T11:22:25Z", "updated_at": "2021-03-24T15:03:46Z", "closed_at": "2021-03-24T15:03:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [X] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [X] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [X] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [X] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [X] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [X] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [X] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [X] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [X] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [X] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nHi, I'm running a very basic text classification experiment with pretrained  transformers as embeddings. I implemented only a very basic the data reader and wrote the config file (see 'steps to reproduce'). I run everything from command line, `allennlp train`, `evaluate` and `predict`. `train` and `evaluate` work like a charm, while I get a `KeyError` exception when running the `predict` command. The error seems to be caused by the absence of the `tokens.txt` entry in the `vocabulary` folder of the trained model, which makes the namespace 'tokens' not to be present in the `vocab`, when called in `make_output_human_readable` of the `BasicClassifier`. The only namespaces available there are `labels` and `tags`.\r\n\r\nThe command I run is\r\n\r\n```\r\nallennlp predict experiments/bert_train__max_512__batch_16/model.tar.gz data/test.jsonl --include-package my_allennlp_pkg --cuda-device 3 --batch-size 8 --output-file test --use-dataset-reader\r\n```\r\n\r\nTraceback\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/path/to/my/env/env/allen210/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/commands/__init__.py\", line 119, in main\r\n    args.func(args)\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/commands/predict.py\", line 239, in _predict\r\n    manager.run()\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/commands/predict.py\", line 206, in run\r\n    for model_input_instance, result in zip(batch, self._predict_instances(batch)):\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/commands/predict.py\", line 167, in _predict_instances\r\n    results = self._predictor.predict_batch_instance(batch_data)\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/predictors/predictor.py\", line 296, in predict_batch_instance\r\n    outputs = self._model.forward_on_instances(instances)\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/models/model.py\", line 185, in forward_on_instances\r\n    outputs = self.make_output_human_readable(self(**model_input))\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/models/basic_classifier.py\", line 166, in make_output_human_readable\r\n    [\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/models/basic_classifier.py\", line 167, in <listcomp>\r\n    self.vocab.get_token_from_index(token_id.item(), namespace=self._namespace)\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/data/vocabulary.py\", line 737, in get_token_from_index\r\n    return self._index_to_token[namespace][index]\r\nKeyError: 101\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nIn general, it seems like when running `allennlp predict` without specifying a predictor it does not read the pretrained model vocabulary inside the vocab object (thus not generating the namespace), or something similar.\r\n\r\n### Attempted solutions\r\n1. I tried inserting a vocabulary entry in the config as suggested in [4690](https://github.com/allenai/allennlp/issues/4690), re-creating the `model.tar.gz` with the so updated config file, but nothing changed.\r\n```\r\n\"vocabulary\": {\r\n     \"type\": \"from_pretrained_transformer\",\r\n     \"model_name\": \"bart-base-cased\"\r\n}\r\n```\r\n2. I downloaded the `bert-base-cased` vocab from huggingface [here](https://huggingface.co/bert-base-cased/raw/main/vocab.txt) inside the `vocabulary` folder, named it `tokens.txt`, and re-created the `model.tar.gz` with this new `vocabulary` dir. The error changed to \r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/path/to/my/env//allen210/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/commands/__init__.py\", line 119, in main\r\n    args.func(args)\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/commands/predict.py\", line 224, in _predict\r\n    predictor = _get_predictor(args)\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/commands/predict.py\", line 115, in _get_predictor\r\n    archive = load_archive(\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/models/archival.py\", line 208, in load_archive\r\n    model = _load_model(config.duplicate(), weights_path, serialization_dir, cuda_device)\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/models/archival.py\", line 242, in _load_model\r\n    return Model.load(\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/models/model.py\", line 406, in load\r\n    return model_class._load(config, serialization_dir, weights_file, cuda_device)\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/models/model.py\", line 293, in _load\r\n    vocab = vocab_class.from_files(\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/data/vocabulary.py\", line 383, in from_files\r\n    vocab.set_from_file(filename, is_padded, namespace=namespace, oov_token=oov_token)\r\n  File \"/path/to/my/env/env/allen210/lib/python3.8/site-packages/allennlp/data/vocabulary.py\", line 511, in set_from_file\r\n    assert self._oov_token in self._token_to_index[namespace], \"OOV token not found!\"\r\nAssertionError: OOV token not found!\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nwhich I suppose is due to the absence of the `@@UNKNOWN@@`  token in the vocab. Inserting that token at the beginning or end of the said `tokens.txt` vocabulary would make the predict command to work, but I could notice a clear misalignment in the index-to-token conversion.\r\n\r\n## Related issues or possible duplicates\r\nThis may be related to the general issues (partly solved) about loading a vocab from a pretrained (transformer) model, like in [4973](https://github.com/allenai/allennlp/issues/4937), [4958](https://github.com/allenai/allennlp/pull/4958), [4690](https://github.com/allenai/allennlp/issues/4690), [3456](https://github.com/allenai/allennlp/issues/3456)\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux 3.10.0-1127.19.1.el7.x86_64\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.8\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py @ file:///home/conda/feedstock_root/build_artifacts/absl-py_1615404881292/work\r\naiohttp @ file:///home/conda/feedstock_root/build_artifacts/aiohttp_1605734406386/work\r\nallennlp==2.1.0\r\nargon2-cffi==20.1.0\r\nasync-generator==1.10\r\nasync-timeout==3.0.1\r\nattrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1605083924122/work\r\nbackcall==0.2.0\r\nbleach==3.3.0\r\nblinker==1.4\r\nblis==0.7.4\r\nboto3==1.17.25\r\nbotocore==1.20.25\r\nbrotlipy==0.7.0\r\ncachetools @ file:///home/conda/feedstock_root/build_artifacts/cachetools_1611555765219/work\r\ncatalogue==2.0.1\r\ncertifi==2020.12.5\r\ncffi @ file:///tmp/build/80754af9/cffi_1613246945912/work\r\nchardet==4.0.0\r\nclick==7.1.2\r\ncryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography_1615405999564/work\r\ncymem==2.0.5\r\ndecorator==4.4.2\r\ndefusedxml==0.7.1\r\nentrypoints==0.3\r\nfilelock==3.0.12\r\ngoogle-auth @ file:///home/conda/feedstock_root/build_artifacts/google-auth_1608136875028/work\r\ngoogle-auth-oauthlib==0.4.1\r\ngrpcio @ file:///home/conda/feedstock_root/build_artifacts/grpcio_1604365522020/work\r\nh5py==3.2.1\r\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1593328102638/work\r\nimportlib-metadata @ file:///home/conda/feedstock_root/build_artifacts/importlib-metadata_1615169443604/work\r\niniconfig==1.1.1\r\nipykernel==5.5.0\r\nipython==7.21.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.3\r\njedi==0.18.0\r\nJinja2==2.11.3\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonlines==2.0.0\r\njsonnet==0.17.0\r\njsonpickle==2.0.0\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==6.1.11\r\njupyter-console==6.2.0\r\njupyter-core==4.7.1\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.0\r\nlmdb==1.1.1\r\nMarkdown @ file:///home/conda/feedstock_root/build_artifacts/markdown_1614595805172/work\r\nMarkupSafe==1.1.1\r\nmistune==0.8.4\r\nmore-itertools==8.7.0\r\nmultidict @ file:///home/conda/feedstock_root/build_artifacts/multidict_1602413132207/work\r\nmurmurhash==1.0.5\r\nnbclient==0.5.3\r\nnbconvert==6.0.7\r\nnbformat==5.1.2\r\nnest-asyncio==1.5.1\r\nnltk==3.5\r\nnotebook==6.2.0\r\nnumpy==1.20.1\r\noauthlib==3.0.1\r\noverrides==3.1.0\r\npackaging==20.9\r\npandas==1.2.3\r\npandocfilters==1.4.3\r\nparso==0.8.1\r\npathy==0.4.0\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==8.1.2\r\npluggy==0.13.1\r\npreshed==3.0.5\r\nprometheus-client==0.9.0\r\nprompt-toolkit==3.0.17\r\nprotobuf==3.15.5\r\nptyprocess==0.7.0\r\npy==1.10.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.7\r\npycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1593275161868/work\r\npydantic==1.7.3\r\nPygments==2.8.1\r\nPyJWT @ file:///home/conda/feedstock_root/build_artifacts/pyjwt_1610910308735/work\r\npyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1608055815057/work\r\npyparsing==2.4.7\r\npyrsistent==0.17.3\r\nPySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1610291447907/work\r\npytest==6.2.2\r\npython-dateutil==2.8.1\r\npytz==2021.1\r\npyzmq==22.0.3\r\nqtconsole==5.0.2\r\nQtPy==1.9.0\r\nregex==2020.11.13\r\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1608156231189/work\r\nrequests-oauthlib @ file:///home/conda/feedstock_root/build_artifacts/requests-oauthlib_1595492159598/work\r\nrsa @ file:///home/conda/feedstock_root/build_artifacts/rsa_1614171254180/work\r\ns3transfer==0.3.4\r\nsacremoses==0.0.43\r\nscikit-learn==0.24.1\r\nscipy==1.6.1\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.95\r\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1590081179328/work\r\nsmart-open==3.0.0\r\nspacy==3.0.5\r\nspacy-legacy==3.0.1\r\nsrsly==2.4.0\r\ntensorboard @ file:///home/conda/feedstock_root/build_artifacts/tensorboard_1610699261066/work/tensorboard-2.4.1-py3-none-any.whl\r\ntensorboard-plugin-wit @ file:///home/conda/feedstock_root/build_artifacts/tensorboard-plugin-wit_1611075653546/work/tensorboard_plugin_wit-1.8.0-py3-none-any.whl\r\ntensorboardX==2.1\r\nterminado==0.9.2\r\ntestpath==0.4.4\r\nthinc==8.0.2\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.10.1\r\ntoml==0.10.2\r\ntorch==1.7.1\r\ntorchvision==0.8.2\r\ntornado==6.1\r\ntqdm==4.59.0\r\ntraitlets==5.0.5\r\ntransformers==4.3.3\r\ntyper==0.3.2\r\ntyping-extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1602702424206/work\r\nurllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1611695416663/work\r\nwasabi==0.8.2\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.5.1\r\nyarl @ file:///home/conda/feedstock_root/build_artifacts/yarl_1605429457708/work\r\nzipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1614945704755/work\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\nI have a very basic data reader \r\n```\r\n@DatasetReader.register(\"case_description\")\r\nclass CaseDescriptionReader(DatasetReader):\r\n    def __init__(\r\n        self,\r\n        label: str,\r\n        token_indexers: Dict[str, TokenIndexer] = None,\r\n        tokenizer: Optional[Tokenizer] = None,\r\n        max_instances: Optional[int] = None,\r\n        serialization_dir: Optional[str] = None\r\n    ) -> None:\r\n        super().__init__(max_instances=max_instances, serialization_dir=serialization_dir)\r\n        self._token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\r\n        self._tokenizer = tokenizer\r\n        self._label = label\r\n\r\n    @overrides\r\n    def _read(self, file_path):\r\n        tot_skipped = 0\r\n        if file_path.endswith(\".jsonl\"):\r\n            with jsonlines.open(file_path) as reader:\r\n                for i, doc in enumerate(reader):\r\n                    instance = self.text_to_instance(text=doc[\"caseDescription\"],\r\n                                                                          label=doc[self._label])\r\n                    if instance is not None:\r\n                        yield instance\r\n\r\n    @overrides\r\n    def text_to_instance(self, text: str, label: str) -> Optional[Instance]:\r\n        if not self._tokenizer:\r\n            tokens = text.split(\" \")\r\n            tokens = [Token(t) for t in tokens]\r\n        else:\r\n            tokens = self._tokenizer.tokenize(text)\r\n        text_field = TextField(tokens)\r\n        fields: Dict[str, Field] = {\"tokens\": text_field, \"label\": LabelField(label)}\r\n        return Instance(fields)\r\n\r\n    @overrides\r\n    def apply_token_indexers(self, instance: Instance) -> None:\r\n        instance.fields[\"tokens\"]._token_indexers = self._token_indexers  # type: ignore\r\n```\r\n\r\nand my config file is as follow\r\n\r\n```\r\n{\r\n  \"dataset_reader\": {\r\n    \"type\": \"case_description\",\r\n    \"label\": \"label\",\r\n    \"token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": \"bert-base-cased\"\r\n      }\r\n    },\r\n    \"tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": \"bert-base-cased\",\r\n      \"max_length\": 512\r\n    }\r\n  },\r\n  \"train_data_path\": \"data/splits_no_material/train.jsonl\",\r\n  \"validation_data_path\": \"data/splits_no_material/val.jsonl\",\r\n\r\n  \"model\": {\r\n    \"type\": \"basic_classifier\",\r\n    \"text_field_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer\",\r\n          \"model_name\": \"bert-base-cased\",\r\n          \"train_parameters\": true\r\n        }\r\n      }\r\n    },\r\n    \"seq2vec_encoder\": {\r\n      \"type\": \"bert_pooler\",\r\n      \"pretrained_model\": \"bert-base-cased\",\r\n      \"dropout\": 0.1\r\n    }\r\n  },\r\n\r\n  \"data_loader\": {\r\n    \"type\": \"multiprocess\",\r\n    \"batch_size\": 16\r\n  },\r\n\r\n  \"trainer\": {\r\n       ...some trainer specs...\r\n  }\r\n}\r\n```\r\n\r\nmy dataset is a `jsonl` with lines like\r\n\r\n```\r\n{\"caseDescription\": \"xxxxxxxx\", \"label\": \"yyyyyy\"}\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5055/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5055/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5048", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5048/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5048/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5048/events", "html_url": "https://github.com/allenai/allennlp/issues/5048", "id": 827547281, "node_id": "MDU6SXNzdWU4Mjc1NDcyODE=", "number": 5048, "title": "Coreference model: clusters removed with more text being added.", "user": {"login": "matyaspjuhasz", "id": 59828210, "node_id": "MDQ6VXNlcjU5ODI4MjEw", "avatar_url": "https://avatars.githubusercontent.com/u/59828210?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matyaspjuhasz", "html_url": "https://github.com/matyaspjuhasz", "followers_url": "https://api.github.com/users/matyaspjuhasz/followers", "following_url": "https://api.github.com/users/matyaspjuhasz/following{/other_user}", "gists_url": "https://api.github.com/users/matyaspjuhasz/gists{/gist_id}", "starred_url": "https://api.github.com/users/matyaspjuhasz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matyaspjuhasz/subscriptions", "organizations_url": "https://api.github.com/users/matyaspjuhasz/orgs", "repos_url": "https://api.github.com/users/matyaspjuhasz/repos", "events_url": "https://api.github.com/users/matyaspjuhasz/events{/privacy}", "received_events_url": "https://api.github.com/users/matyaspjuhasz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2021-03-10T11:03:17Z", "updated_at": "2021-04-02T01:38:34Z", "closed_at": "2021-04-02T01:38:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<p>\r\nHi!\r\n\r\nI've observed an issue, whereby the coreference solution doesn't include clusters for longer text, that it identifies for a shorter version of the same text. This problem can be reproduced when using [your demo](https://demo.allennlp.org/coreference-resolution) too, so for the ease of explanation, I'll include the screenshots from there.\r\n\r\nBelow is the case with the \"short text\" - cluster 4 is identified correctly with 2 spans in it. (Interestingly it also includes cluster 6 with just 1 span in it)\r\n\r\n![image](https://user-images.githubusercontent.com/59828210/110619036-a0a2ca00-8197-11eb-801a-b5bec5ebcb09.png)\r\n\r\n\r\nHere's the text with 2 extra sentences, that results in the earlier cluster disappearing.\r\n\r\n![image](https://user-images.githubusercontent.com/59828210/110619195-ce880e80-8197-11eb-970a-5bceb1327f55.png)\r\n\r\nIs there any way to retain all clusters the model would find even for longer pieces of text?\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: MacOS\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.6\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5048/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5048/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5044", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5044/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5044/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5044/events", "html_url": "https://github.com/allenai/allennlp/issues/5044", "id": 824246300, "node_id": "MDU6SXNzdWU4MjQyNDYzMDA=", "number": 5044, "title": "Allennlp unnecessarily downloading huggingface models during evaluation", "user": {"login": "nelson-liu", "id": 7272031, "node_id": "MDQ6VXNlcjcyNzIwMzE=", "avatar_url": "https://avatars.githubusercontent.com/u/7272031?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nelson-liu", "html_url": "https://github.com/nelson-liu", "followers_url": "https://api.github.com/users/nelson-liu/followers", "following_url": "https://api.github.com/users/nelson-liu/following{/other_user}", "gists_url": "https://api.github.com/users/nelson-liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/nelson-liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nelson-liu/subscriptions", "organizations_url": "https://api.github.com/users/nelson-liu/orgs", "repos_url": "https://api.github.com/users/nelson-liu/repos", "events_url": "https://api.github.com/users/nelson-liu/events{/privacy}", "received_events_url": "https://api.github.com/users/nelson-liu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "02b8d1", "default": false, "description": ""}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2021-03-08T07:01:25Z", "updated_at": "2021-04-17T04:49:46Z", "closed_at": "2021-04-17T04:49:46Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi!\r\n\r\nI trained a model with BERT (base) on MNLI, using the config in `allennlp-models`. I offhandedly noticed this, and I'm not sure if it's a bug.\r\n\r\nWhen I moved the output of the allennlp run to another machine (without a huggingface or allennlp cache) and ran `allennlp evaluate` with it, I noticed that downloads were happening. I've put the full evaluation log below, but it seems like these are the BERT base files (tokenizer, vocabulary, model checkpoints) being downloaded by huggingface (just comparing to my training logs and what I'd expect given what I know about the model). I'd imagine this is probably partially an issue with AllenNLP and partially an issue with huggingface, but figured I'd mention it here so it's documented at least.\r\n\r\nAnyway, this is probably pretty low-priority, but it seems like in this case, the model is instantiated with the pre-trained BERT weights (which have to be downloaded from the internet), and then immediately overwritten with what's stored in `model.tar.gz`. I wonder if there's some way to defer this download in the `evaluate` / `predict` case, since it really doesn't seem like they should be necessary (i.e., I'd expect inference to work fully offline).\r\n\r\nThanks!\r\n\r\n\r\n```\r\n[nltk_data] Downloading package punkt to\r\n[nltk_data]     /0xa1bf5d3e4bb248fd99bb5a28b6029041/nltk_data...\r\n[nltk_data]   Unzipping tokenizers/punkt.zip.\r\n[nltk_data] Downloading package wordnet to\r\n[nltk_data]     /0xa1bf5d3e4bb248fd99bb5a28b6029041/nltk_data...\r\n[nltk_data]   Unzipping corpora/wordnet.zip.\r\n2021-03-08 04:42:41,199 - INFO - allennlp.common.plugins - Plugin allennlp_models available\r\n2021-03-08 04:42:41,202 - INFO - allennlp.models.archival - loading archive file model_bundle/sampled_hps_05c6993db950b757ac8a02f9516055b8_fixed/model.tar.gz\r\n2021-03-08 04:42:41,203 - INFO - allennlp.models.archival - extracting archive file model_bundle/sampled_hps_05c6993db950b757ac8a02f9516055b8_fixed/model.tar.gz to temp dir /tmp/tmphow9s0vy\r\n\r\nDownloading:   0%|          | 0.00/433 [00:00<?, ?B/s]\r\nDownloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 433/433 [00:00<00:00, 202kB/s]\r\n\r\nDownloading:   0%|          | 0.00/213k [00:00<?, ?B/s]\r\n<snip>\r\nDownloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 213k/213k [00:00<00:00, 1.03MB/s]\r\n\r\nDownloading:   0%|          | 0.00/436k [00:00<?, ?B/s]\r\n<snip>\r\nDownloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 436k/436k [00:00<00:00, 1.34MB/s]\r\n2021-03-08 04:42:48,189 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmphow9s0vy/vocabulary.\r\n\r\nDownloading:   0%|          | 0.00/436M [00:00<?, ?B/s]\r\nDownloading:   0%|          | 1.49M/436M [00:00<00:29, 14.9MB/s]\r\n<snip>\r\nDownloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 436M/436M [00:34<00:00, 12.6MB/s]\r\n2021-03-08 04:43:29,667 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmphow9s0vy\r\n2021-03-08 04:43:29,716 - INFO - allennlp.common.checks - Pytorch version: 1.7.1+cu101\r\n2021-03-08 04:43:29,717 - INFO - allennlp.commands.evaluate - Reading evaluation data from test.json\r\nloading instances: 0it [00:00, ?it/s]\r\nloading instances: 2742it [00:02, 1370.67it/s]\r\nloading instances: 5484it [00:04, 1366.55it/s]\r\nloading instances: 8218it [00:06, 1365.18it/s]\r\nloading instances: 9824it [00:07, 1379.82it/s]\r\n2021-03-08 04:43:37,200 - INFO - allennlp.training.util - Iterating over dataset\r\n0it [00:00, ?it/s]\r\n2021-03-08 04:43:37,209 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one\r\n2021-03-08 04:43:37,209 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys\r\naccuracy: 0.73, loss: 1.07 ||: : 114it [00:02, 56.76it/s]\r\naccuracy: 0.73, loss: 1.09 ||: : 232it [00:04, 58.02it/s]\r\naccuracy: 0.72, loss: 1.08 ||: : 349it [00:06, 57.70it/s]\r\naccuracy: 0.72, loss: 1.08 ||: : 465it [00:08, 57.55it/s]\r\naccuracy: 0.73, loss: 1.07 ||: : 584it [00:10, 58.09it/s]\r\naccuracy: 0.73, loss: 1.05 ||: : 703it [00:12, 58.47it/s]\r\naccuracy: 0.73, loss: 1.04 ||: : 821it [00:14, 58.60it/s]\r\naccuracy: 0.73, loss: 1.04 ||: : 942it [00:16, 59.07it/s]\r\naccuracy: 0.73, loss: 1.03 ||: : 1061it [00:18, 58.47it/s]\r\naccuracy: 0.73, loss: 1.03 ||: : 1180it [00:20, 58.75it/s]\r\naccuracy: 0.73, loss: 1.02 ||: : 1228it [00:21, 58.38it/s]\r\n2021-03-08 04:43:58,234 - INFO - allennlp.common.util - Metrics: {\r\n  \"accuracy\": 0.7325936482084691,\r\n  \"loss\": 1.0198601739944098\r\n}\r\n2021-03-08 04:43:58,234 - INFO - allennlp.commands.evaluate - Finished evaluating.\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5044/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5044/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5043", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5043/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5043/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5043/events", "html_url": "https://github.com/allenai/allennlp/issues/5043", "id": 824017495, "node_id": "MDU6SXNzdWU4MjQwMTc0OTU=", "number": 5043, "title": "bug", "user": {"login": "apsiriwat", "id": 79339412, "node_id": "MDQ6VXNlcjc5MzM5NDEy", "avatar_url": "https://avatars.githubusercontent.com/u/79339412?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apsiriwat", "html_url": "https://github.com/apsiriwat", "followers_url": "https://api.github.com/users/apsiriwat/followers", "following_url": "https://api.github.com/users/apsiriwat/following{/other_user}", "gists_url": "https://api.github.com/users/apsiriwat/gists{/gist_id}", "starred_url": "https://api.github.com/users/apsiriwat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apsiriwat/subscriptions", "organizations_url": "https://api.github.com/users/apsiriwat/orgs", "repos_url": "https://api.github.com/users/apsiriwat/repos", "events_url": "https://api.github.com/users/apsiriwat/events{/privacy}", "received_events_url": "https://api.github.com/users/apsiriwat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-03-07T20:55:37Z", "updated_at": "2021-03-08T19:06:41Z", "closed_at": "2021-03-08T19:06:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ ] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [ ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ ] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5043/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5043/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5036", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5036/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5036/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5036/events", "html_url": "https://github.com/allenai/allennlp/issues/5036", "id": 822530116, "node_id": "MDU6SXNzdWU4MjI1MzAxMTY=", "number": 5036, "title": "spacy 3.0 warnings about lemmatization and POS", "user": {"login": "nelson-liu", "id": 7272031, "node_id": "MDQ6VXNlcjcyNzIwMzE=", "avatar_url": "https://avatars.githubusercontent.com/u/7272031?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nelson-liu", "html_url": "https://github.com/nelson-liu", "followers_url": "https://api.github.com/users/nelson-liu/followers", "following_url": "https://api.github.com/users/nelson-liu/following{/other_user}", "gists_url": "https://api.github.com/users/nelson-liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/nelson-liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nelson-liu/subscriptions", "organizations_url": "https://api.github.com/users/nelson-liu/orgs", "repos_url": "https://api.github.com/users/nelson-liu/repos", "events_url": "https://api.github.com/users/nelson-liu/events{/privacy}", "received_events_url": "https://api.github.com/users/nelson-liu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "leo-liuzy", "id": 11146950, "node_id": "MDQ6VXNlcjExMTQ2OTUw", "avatar_url": "https://avatars.githubusercontent.com/u/11146950?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leo-liuzy", "html_url": "https://github.com/leo-liuzy", "followers_url": "https://api.github.com/users/leo-liuzy/followers", "following_url": "https://api.github.com/users/leo-liuzy/following{/other_user}", "gists_url": "https://api.github.com/users/leo-liuzy/gists{/gist_id}", "starred_url": "https://api.github.com/users/leo-liuzy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leo-liuzy/subscriptions", "organizations_url": "https://api.github.com/users/leo-liuzy/orgs", "repos_url": "https://api.github.com/users/leo-liuzy/repos", "events_url": "https://api.github.com/users/leo-liuzy/events{/privacy}", "received_events_url": "https://api.github.com/users/leo-liuzy/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "leo-liuzy", "id": 11146950, "node_id": "MDQ6VXNlcjExMTQ2OTUw", "avatar_url": "https://avatars.githubusercontent.com/u/11146950?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leo-liuzy", "html_url": "https://github.com/leo-liuzy", "followers_url": "https://api.github.com/users/leo-liuzy/followers", "following_url": "https://api.github.com/users/leo-liuzy/following{/other_user}", "gists_url": "https://api.github.com/users/leo-liuzy/gists{/gist_id}", "starred_url": "https://api.github.com/users/leo-liuzy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leo-liuzy/subscriptions", "organizations_url": "https://api.github.com/users/leo-liuzy/orgs", "repos_url": "https://api.github.com/users/leo-liuzy/repos", "events_url": "https://api.github.com/users/leo-liuzy/events{/privacy}", "received_events_url": "https://api.github.com/users/leo-liuzy/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2021-03-04T21:39:14Z", "updated_at": "2021-03-24T22:28:31Z", "closed_at": "2021-03-24T22:28:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I'm training a model (https://github.com/allenai/allennlp-models/blob/main/training_config/pair_classification/mnli_roberta.jsonnet) with allennlp 2.1.0, using SpaCy 3.\r\n\r\nThere are a bunch of warnings that show up (I'm not sure if these were here before, but I noticed them now because my log files are now massive):\r\n\r\n```\r\n[W108] The rule-based lemmatizer did not find POS annotation for the token 'Tommy'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\r\n[W108] The rule-based lemmatizer did not find POS annotation for the token 'hesitated'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\r\n[W108] The rule-based lemmatizer did not find POS annotation for the token '.'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\r\n[W108] The rule-based lemmatizer did not find POS annotation for the token 'Tommy'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\r\n[W108] The rule-based lemmatizer did not find POS annotation for the token 'hesitated'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\r\n[W108] The rule-based lemmatizer did not find POS annotation for the token 'for'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\r\n[W108] The rule-based lemmatizer did not find POS annotation for the token 'a'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\r\n[W108] The rule-based lemmatizer did not find POS annotation for the token 'short'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\r\n...\r\n```\r\n\r\nI think this is because `allennlp.common.util.get_spacy_model` (https://github.com/allenai/allennlp/blob/96415b2bab6d8c70a0fa80ca4a8b9d1dc988720e/allennlp/common/util.py#L258) has POS off by default, but doesn't disable lemmatization by default.\r\n\r\nNot sure what y'all think is the best way to solve this...can add a lemmatization argument for get_spacy_model that is default by false? This is a change in the defaults from previous versions, though.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5036/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5036/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5028", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5028/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5028/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5028/events", "html_url": "https://github.com/allenai/allennlp/issues/5028", "id": 818390316, "node_id": "MDU6SXNzdWU4MTgzOTAzMTY=", "number": 5028, "title": "Open Information Extraction Training fails with \"status code 404\"", "user": {"login": "MM-Vianai", "id": 57116726, "node_id": "MDQ6VXNlcjU3MTE2NzI2", "avatar_url": "https://avatars.githubusercontent.com/u/57116726?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MM-Vianai", "html_url": "https://github.com/MM-Vianai", "followers_url": "https://api.github.com/users/MM-Vianai/followers", "following_url": "https://api.github.com/users/MM-Vianai/following{/other_user}", "gists_url": "https://api.github.com/users/MM-Vianai/gists{/gist_id}", "starred_url": "https://api.github.com/users/MM-Vianai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MM-Vianai/subscriptions", "organizations_url": "https://api.github.com/users/MM-Vianai/orgs", "repos_url": "https://api.github.com/users/MM-Vianai/repos", "events_url": "https://api.github.com/users/MM-Vianai/events{/privacy}", "received_events_url": "https://api.github.com/users/MM-Vianai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2021-03-01T02:02:50Z", "updated_at": "2021-03-25T16:17:33Z", "closed_at": "2021-03-25T16:17:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nrunning the command \r\n\r\n$ allennlp train \\\\\r\n        https://raw.githubusercontent.com/allenai/allennlp-models/main/training_config/structured-prediction/srl.jsonnet \\\\\r\n        -s /path/to/output\r\n\r\nfrom [Model Usage](https://demo.allennlp.org/open-information-extraction) results in the following error message \r\n\r\nOSError: HEAD request failed for url https://raw.githubusercontent.com/allenai/allennlp-models/main/training_config/structured-prediction/srl.jsonnet with status code 404\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n2021-02-28 17:49:16,852 - INFO - transformers.file_utils - PyTorch version 1.5.1 available.\r\nTraceback (most recent call last):\r\n  File \"/Users/mmir/Desktop/Explorations/allennlp_openie/venv/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/Users/mmir/Desktop/Explorations/allennlp_openie/venv/lib/python3.7/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/Users/mmir/Desktop/Explorations/allennlp_openie/venv/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/Users/mmir/Desktop/Explorations/allennlp_openie/venv/lib/python3.7/site-packages/allennlp/commands/train.py\", line 112, in train_model_from_args\r\n    dry_run=args.dry_run,\r\n  File \"/Users/mmir/Desktop/Explorations/allennlp_openie/venv/lib/python3.7/site-packages/allennlp/commands/train.py\", line 162, in train_model_from_file\r\n    params = Params.from_file(parameter_filename, overrides)\r\n  File \"/Users/mmir/Desktop/Explorations/allennlp_openie/venv/lib/python3.7/site-packages/allennlp/common/params.py\", line 487, in from_file\r\n    params_file = cached_path(params_file)\r\n  File \"/Users/mmir/Desktop/Explorations/allennlp_openie/venv/lib/python3.7/site-packages/allennlp/common/file_utils.py\", line 105, in cached_path\r\n    return get_from_cache(url_or_filename, cache_dir)\r\n  File \"/Users/mmir/Desktop/Explorations/allennlp_openie/venv/lib/python3.7/site-packages/allennlp/common/file_utils.py\", line 301, in get_from_cache\r\n    etag = _http_etag(url)\r\n  File \"/Users/mmir/Desktop/Explorations/allennlp_openie/venv/lib/python3.7/site-packages/allennlp/common/file_utils.py\", line 211, in _http_etag\r\n    \"HEAD request failed for url {} with status code {}\".format(url, response.status_code)\r\nOSError: HEAD request failed for url https://raw.githubusercontent.com/allenai/allennlp-models/main/training_config/structured-prediction/srl.jsonnet with status code 404\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: macOS 10.15.4\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.6\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==1.0.0\r\nallennlp-models==1.0.0\r\nattrs==20.3.0\r\nblis==0.4.1\r\nboto3==1.17.14\r\nbotocore==1.20.14\r\ncached-property==1.5.2\r\ncatalogue==1.0.0\r\ncertifi==2020.12.5\r\nchardet==4.0.0\r\nclick==7.1.2\r\nconllu==3.0\r\ncymem==2.0.5\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nfilelock==3.0.12\r\nfuture==0.18.2\r\nh5py==3.1.0\r\nidna==2.10\r\nimportlib-metadata==3.5.0\r\niniconfig==1.1.1\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonnet==0.17.0\r\njsonpickle==2.0.0\r\nmurmurhash==1.0.5\r\nnltk==3.5\r\nnumpy==1.20.1\r\noverrides==3.0.0\r\npackaging==20.9\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.5\r\nprotobuf==3.15.1\r\npy==1.10.0\r\npy-rouge==1.1\r\npyparsing==2.4.7\r\npytest==6.2.2\r\npython-dateutil==2.8.1\r\nregex==2020.11.13\r\nrequests==2.25.1\r\ns3transfer==0.3.4\r\nsacremoses==0.0.43\r\nscikit-learn==0.24.1\r\nscipy==1.6.1\r\nsentencepiece==0.1.95\r\nsix==1.15.0\r\nspacy==2.2.4\r\nsrsly==1.0.5\r\ntensorboardX==2.1\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.7.0\r\ntoml==0.10.2\r\ntorch==1.5.1\r\ntqdm==4.57.0\r\ntransformers==2.11.0\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.26.3\r\nwasabi==0.8.2\r\nword2number==1.1\r\nzipp==3.4.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n\r\n$ pip install allennlp==1.0.0 allennlp-models==1.0.0\r\n$ allennlp train \\\r\n        https://raw.githubusercontent.com/allenai/allennlp-models/main/training_config/structured-prediction/srl.jsonnet \\\r\n        -s /path/to/output\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5028/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5028/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5027", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5027/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5027/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5027/events", "html_url": "https://github.com/allenai/allennlp/issues/5027", "id": 818260256, "node_id": "MDU6SXNzdWU4MTgyNjAyNTY=", "number": 5027, "title": "lmdb.BadRslotError: mdb_txn_begin: MDB_BAD_RSLOT: Invalid reuse of reader locktable slot", "user": {"login": "aleSuglia", "id": 1479733, "node_id": "MDQ6VXNlcjE0Nzk3MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1479733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aleSuglia", "html_url": "https://github.com/aleSuglia", "followers_url": "https://api.github.com/users/aleSuglia/followers", "following_url": "https://api.github.com/users/aleSuglia/following{/other_user}", "gists_url": "https://api.github.com/users/aleSuglia/gists{/gist_id}", "starred_url": "https://api.github.com/users/aleSuglia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aleSuglia/subscriptions", "organizations_url": "https://api.github.com/users/aleSuglia/orgs", "repos_url": "https://api.github.com/users/aleSuglia/repos", "events_url": "https://api.github.com/users/aleSuglia/events{/privacy}", "received_events_url": "https://api.github.com/users/aleSuglia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 16, "created_at": "2021-02-28T17:32:32Z", "updated_at": "2021-08-05T18:24:27Z", "closed_at": "2021-08-05T18:24:26Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Checklist\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nI'm having issues in reusing a single LMDB from multiple processes running on a SLURM-managed cluster. I'm trying to use multiple `VisionReader`s in a multi-task setup. The error seems to be at line 593 of the `TensorCache` class. Please see below:\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 19, in _wrap\r\n    fn(i, *args)\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/allennlp/commands/train.py\", line 466, in _train_worker\r\n    metrics = train_loop.run()\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/allennlp/commands/train.py\", line 528, in run\r\n    return self.trainer.train()\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/allennlp/training/trainer.py\", line 930, in train\r\n    metrics, epoch = self._try_train()\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/allennlp/training/trainer.py\", line 962, in _try_train\r\n    train_metrics = self._train_epoch(epoch)\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/allennlp/training/trainer.py\", line 663, in _train_epoch\r\n    for batch_group in batch_group_generator_tqdm:\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/allennlp/common/util.py\", line 139, in lazy_groups_of\r\n    s = list(islice(iterator, group_size))\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/allennlp/data/data_loaders/multitask_data_loader.py\", line 194, in <genexpr>\r\n    return (\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/more_itertools/recipes.py\", line 317, in roundrobin\r\n    yield next()\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/more_itertools/recipes.py\", line 73, in take\r\n    return list(islice(iterable, n))\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/allennlp/common/util.py\", line 668, in shuffle_iterable\r\n    for item in i:\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/allennlp/data/data_loaders/multiprocess_data_loader.py\", line 349, in iter_instances\r\n    for instance in Tqdm.tqdm(\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/tqdm/std.py\", line 1166, in __iter__\r\n    for obj in iterable:\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/allennlp/data/data_loaders/multitask_data_loader.py\", line 290, in read\r\n    for instance in self.inner.read(file_path):\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/allennlp/data/dataset_readers/dataset_reader.py\", line 192, in read\r\n    for instance in self._multi_worker_islice(self._read(file_path)):  # type: ignore\r\n  File \"/lustre/home/ec156/asuglia/workspace/VILGEN/vilgen/readers/pretraining.py\", line 1026, in _read\r\n    for caption_tuple, processed_image in zip(caption_dicts, processed_images):\r\n  File \"/lustre/home/ec156/asuglia/workspace/VILGEN/vilgen/readers/pretraining.py\", line 970, in _process_image_paths\r\n    coordinates: Tensor = self._coordinates_cache[basename].cpu()\r\n  File \"/lustre/home/ec156/asuglia/miniconda3/envs/devel/lib/python3.8/site-packages/allennlp/common/file_utils.py\", line 594, in __getitem__\r\n    with self.lmdb_env.begin(write=False) as txn:\r\nlmdb.BadRslotError: mdb_txn_begin: MDB_BAD_RSLOT: Invalid reuse of reader locktable slot\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\nThe error has been reported on [StackOverflow](https://stackoverflow.com/questions/56905502/lmdb-badrsloterror-mdb-txn-begin-mdb-bad-rslot-invalid-reuse-of-reader-lockta) and seems to have to do with how the transaction is opened.\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.8.5 (via Miniconda)\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==2.1.0\r\nallennlp-models==2.0.1\r\nattrs==20.3.0\r\nbackcall==0.2.0\r\nblis==0.7.4\r\nboto3==1.17.12\r\nbotocore==1.20.12\r\ncatalogue==1.0.0\r\ncertifi==2020.12.5\r\nchardet==4.0.0\r\nclick==7.1.2\r\nconllu==4.3\r\ncymem==2.0.5\r\ndecorator==4.4.2\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\r\nfilelock==3.0.12\r\nfire==0.4.0\r\nftfy==5.9\r\nh5py==3.1.0\r\nidna==2.10\r\niniconfig==1.1.1\r\nipdb==0.13.4\r\nipython==7.20.0\r\nipython-genutils==0.2.0\r\njedi==0.18.0\r\njmespath==0.10.0\r\njoblib==1.0.0\r\njsonlines==2.0.0\r\njsonnet==0.17.0\r\njsonpickle==1.4.2\r\nlmdb==1.1.1\r\nmore-itertools==8.7.0\r\nmurmurhash==1.0.5\r\nnltk==3.5\r\nnumpy==1.19.5\r\noverrides==3.1.0\r\npackaging==20.8\r\npandas==1.2.2\r\nparso==0.8.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==8.1.0\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.5\r\nprompt-toolkit==3.0.16\r\nprotobuf==3.14.0\r\nptyprocess==0.7.0\r\npy==1.10.0\r\npy-rouge==1.1\r\nPygments==2.8.0\r\npyparsing==2.4.7\r\npytest==6.2.1\r\npython-dateutil==2.8.1\r\npytz==2021.1\r\nregex==2020.11.13\r\nrequests==2.25.1\r\ns3transfer==0.3.4\r\nsacremoses==0.0.43\r\nscikit-learn==0.24.0\r\nscipy==1.6.0\r\nsentencepiece==0.1.95\r\nsix==1.15.0\r\nspacy==2.3.5\r\nsrsly==1.0.5\r\ntensorboardX==2.1\r\ntermcolor==1.1.0\r\nthinc==7.4.5\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.9.4\r\ntoml==0.10.2\r\ntorch==1.7.1\r\ntorchvision==0.8.2\r\ntqdm==4.56.0\r\ntraitlets==5.0.5\r\ntransformers==4.2.2\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.26.2\r\nwasabi==0.8.0\r\nwcwidth==0.2.5\r\nword2number==1.1\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nIn my case, I use a script to run multiple training sessions as multiple SLURM jobs (I use `allennlp train` to start the training sessions). All these training sessions are using the same image feature cache. I am indeed able to run a single job without any problems.   ", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5027/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5027/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5022", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5022/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5022/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5022/events", "html_url": "https://github.com/allenai/allennlp/issues/5022", "id": 815992071, "node_id": "MDU6SXNzdWU4MTU5OTIwNzE=", "number": 5022, "title": "The SRL predictor doesn't work with the following error message", "user": {"login": "shinyemimalef", "id": 20720288, "node_id": "MDQ6VXNlcjIwNzIwMjg4", "avatar_url": "https://avatars.githubusercontent.com/u/20720288?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shinyemimalef", "html_url": "https://github.com/shinyemimalef", "followers_url": "https://api.github.com/users/shinyemimalef/followers", "following_url": "https://api.github.com/users/shinyemimalef/following{/other_user}", "gists_url": "https://api.github.com/users/shinyemimalef/gists{/gist_id}", "starred_url": "https://api.github.com/users/shinyemimalef/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shinyemimalef/subscriptions", "organizations_url": "https://api.github.com/users/shinyemimalef/orgs", "repos_url": "https://api.github.com/users/shinyemimalef/repos", "events_url": "https://api.github.com/users/shinyemimalef/events{/privacy}", "received_events_url": "https://api.github.com/users/shinyemimalef/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2021-02-25T01:48:43Z", "updated_at": "2021-03-30T21:37:19Z", "closed_at": "2021-03-30T21:37:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x ] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x ] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\nThe error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/skhanehzar/DeployedProjects/Narrative/pipeline/srl.py\", line 112, in <module>\r\n    \"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")\r\n  File \"/home/skhanehzar/anaconda3/envs/narrative/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 275, in from_path\r\n    load_archive(archive_path, cuda_device=cuda_device),\r\n  File \"/home/skhanehzar/anaconda3/envs/narrative/lib/python3.7/site-packages/allennlp/models/archival.py\", line 197, in load_archive\r\n    opt_level=opt_level,\r\n  File \"/home/skhanehzar/anaconda3/envs/narrative/lib/python3.7/site-packages/allennlp/models/model.py\", line 398, in load\r\n    return model_class._load(config, serialization_dir, weights_file, cuda_device, opt_level)\r\n  File \"/home/skhanehzar/anaconda3/envs/narrative/lib/python3.7/site-packages/allennlp/models/model.py\", line 337, in _load\r\n    model.load_state_dict(model_state)\r\n  File \"/home/skhanehzar/anaconda3/envs/narrative/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 847, in load_state_dict\r\n    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\r\nRuntimeError: Error(s) in loading state_dict for SrlBert:\r\n\tUnexpected key(s) in state_dict: \"bert_model.embeddings.position_ids\". \r\n\r\nProcess finished with exit code 1\r\n```\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.9\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n(narrative) skhanehzar@slug:~$ pip freeze\r\nallennlp==1.0.0\r\nallennlp-models==1.0.0\r\nattrs==20.3.0\r\nblis==0.4.1\r\nboto3==1.17.8\r\nbotocore==1.20.8\r\ncached-property==1.5.2\r\ncatalogue==1.0.0\r\ncertifi==2020.12.5\r\nchardet==4.0.0\r\nclick==7.1.2\r\nconllu==3.0\r\ncymem==2.0.5\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nfilelock==3.0.12\r\nfuture==0.18.2\r\nh5py==3.1.0\r\nidna==2.10\r\nimportlib-metadata==3.4.0\r\niniconfig==1.1.1\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonnet==0.17.0\r\njsonpickle==2.0.0\r\nmurmurhash==1.0.5\r\nnltk==3.5\r\nnumpy==1.20.1\r\noverrides==3.0.0\r\npackaging==20.9\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.5\r\nprotobuf==3.14.0\r\npy==1.10.0\r\npy-rouge==1.1\r\npyparsing==2.4.7\r\npytest==6.2.2\r\npython-dateutil==2.8.1\r\nregex==2020.11.13\r\nrequests==2.25.1\r\ns3transfer==0.3.4\r\nsacremoses==0.0.43\r\nscikit-learn==0.24.1\r\nscipy==1.6.0\r\nsentencepiece==0.1.95\r\nsix==1.15.0\r\nspacy==2.2.4\r\nsrsly==1.0.5\r\ntensorboardX==2.1\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.7.0\r\ntoml==0.10.2\r\ntorch==1.5.1\r\ntqdm==4.56.2\r\ntransformers==2.11.0\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.26.3\r\nwasabi==0.8.2\r\nword2number==1.1\r\nzipp==3.4.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\nRun the following code with python interpreter\r\n\r\n```\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.tagging\r\npredictor = Predictor.from_path(\r\n        \"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")\r\npp = predictor.predict(\r\n        sentence=\"Did Uriah honestly think he could beat the game in under three hours?.\"\r\n )\r\n```\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n\r\nSee steps to reproduce above\r\n\r\n</p>\r\n</details>\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5022/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5022/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5014", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5014/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5014/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5014/events", "html_url": "https://github.com/allenai/allennlp/issues/5014", "id": 814293588, "node_id": "MDU6SXNzdWU4MTQyOTM1ODg=", "number": 5014, "title": "Better device handling in VisionReader", "user": {"login": "aleSuglia", "id": 1479733, "node_id": "MDQ6VXNlcjE0Nzk3MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1479733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aleSuglia", "html_url": "https://github.com/aleSuglia", "followers_url": "https://api.github.com/users/aleSuglia/followers", "following_url": "https://api.github.com/users/aleSuglia/following{/other_user}", "gists_url": "https://api.github.com/users/aleSuglia/gists{/gist_id}", "starred_url": "https://api.github.com/users/aleSuglia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aleSuglia/subscriptions", "organizations_url": "https://api.github.com/users/aleSuglia/orgs", "repos_url": "https://api.github.com/users/aleSuglia/repos", "events_url": "https://api.github.com/users/aleSuglia/events{/privacy}", "received_events_url": "https://api.github.com/users/aleSuglia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2021-02-23T09:49:35Z", "updated_at": "2021-03-01T17:53:41Z", "closed_at": "2021-03-01T17:53:41Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Checklist\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n## Description\r\n\r\nI am using the `VisionReader` for a specific task and I've noticed that, when the `cuda_device` is set, the batch processing generates features and region coordinates that are always on the GPU (please see [here](https://github.com/allenai/allennlp-models/blob/main/allennlp_models/vision/dataset_readers/vision_reader.py#L281)). However, I can see that the elements are stored in the cache as GPU tensor (please see [here](https://github.com/allenai/allennlp/blob/da4dba150d91c6863580912f71cbb62fc2a02d99/allennlp/common/file_utils.py#L611)) and then mapped to CPU once loaded (please see [here](https://github.com/allenai/allennlp/blob/da4dba150d91c6863580912f71cbb62fc2a02d99/allennlp/common/file_utils.py#L598)). However, when I try to use the image features tensors, I can definitely see that they are on the GPU and this breaks my code because all the other tensors that I'm creating are on the wrong device (CPU).\r\n\r\nUnfortunately, I don't really have a full understanding of the AllenNLP internals for this dataset reader so any help is appreciated.  The way to solve it for now is to manually move the image features and region tensors to CPU in my `text_to_instance()`.\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\nabsl-py==0.11.0\r\nallennlp==2.0.1\r\nallennlp-models==2.0.1\r\napex==0.1\r\nastunparse==1.6.3\r\nattrs==20.3.0\r\nbackcall==0.2.0\r\nbert-score==0.3.7\r\nBLEURT @ git+https://github.com/google-research/bleurt.git@2b7a3a1092daefce7c16ce9e243d37d23d497849\r\nblis==0.7.4\r\nboto3==1.16.34\r\nbotocore==1.19.34\r\ncachetools==4.2.0\r\ncatalogue==1.0.0\r\ncertifi==2020.12.5\r\ncffi==1.14.4\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncloudpickle==1.6.0\r\nconllu==4.3\r\ncycler==0.10.0\r\ncymem==2.0.5\r\nCython==0.29.21\r\ncytoolz==0.11.0\r\ndatasets==1.2.1\r\ndecorator==4.4.2\r\ndill==0.3.3\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\r\nfilelock==3.0.12\r\nfire==0.4.0\r\nflatbuffers==1.12\r\nftfy==5.9\r\ngast==0.3.3\r\ngensim==3.8.3\r\ngoogle-auth==1.24.0\r\ngoogle-auth-oauthlib==0.4.2\r\ngoogle-pasta==0.2.0\r\ngrpcio==1.32.0\r\nh5py==2.10.0\r\nhorovod==0.21.1\r\nidna==2.10\r\niniconfig==1.1.1\r\nipdb==0.13.4\r\nipython==7.20.0\r\nipython-genutils==0.2.0\r\njedi==0.18.0\r\njmespath==0.10.0\r\njoblib==0.17.0\r\njsonlines==2.0.0\r\njsonnet==0.17.0\r\njsonpickle==1.4.2\r\nKeras-Preprocessing==1.1.2\r\nkiwisolver==1.3.1\r\nlmdb==1.0.0\r\nlz4==3.1.1\r\nMarkdown==3.3.3\r\nmatplotlib==3.3.3\r\nmkl-fft==1.2.0\r\nmkl-random==1.1.1\r\nmkl-service==2.3.0\r\nmore-itertools==8.7.0\r\nmsgpack==1.0.2\r\nmsgpack-numpy==0.4.7.1\r\nmultiprocess==0.70.11.1\r\nmurmurhash==1.0.5\r\nnlg-eval @ git+https://github.com/Maluuba/nlg-eval.git@2533028c3e325459f2a402698ec9c14a9298f124\r\nnltk==3.5\r\nnumpy @ file:///tmp/build/80754af9/numpy_and_numpy_base_1603570489231/work\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nAny class that inherits from `VisionReader` will generate features that are on a specific `self.cuda_device` (if specified in the constructor). Usually, developers that are creating a dataset reader are not working with GPU yet therefore this breaks most of the code (I believe).\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5014/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5014/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5009", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5009/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5009/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5009/events", "html_url": "https://github.com/allenai/allennlp/issues/5009", "id": 813786795, "node_id": "MDU6SXNzdWU4MTM3ODY3OTU=", "number": 5009, "title": "@Registrable.register decorator hinders annotation-based suggestions in IDEs", "user": {"login": "willfrey", "id": 13784361, "node_id": "MDQ6VXNlcjEzNzg0MzYx", "avatar_url": "https://avatars.githubusercontent.com/u/13784361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/willfrey", "html_url": "https://github.com/willfrey", "followers_url": "https://api.github.com/users/willfrey/followers", "following_url": "https://api.github.com/users/willfrey/following{/other_user}", "gists_url": "https://api.github.com/users/willfrey/gists{/gist_id}", "starred_url": "https://api.github.com/users/willfrey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/willfrey/subscriptions", "organizations_url": "https://api.github.com/users/willfrey/orgs", "repos_url": "https://api.github.com/users/willfrey/repos", "events_url": "https://api.github.com/users/willfrey/events{/privacy}", "received_events_url": "https://api.github.com/users/willfrey/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-02-22T19:16:54Z", "updated_at": "2021-02-24T01:37:29Z", "closed_at": "2021-02-24T01:37:29Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I have a fix for your consideration that I'll open a PR for.\r\n\r\n<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nThe `@<cls>.register(...)` decorator masks IDE-like completions derived from type annotations due to the annotations in [registrable.py](../blob/main/allennlp/common/registrable.py)\r\n\r\nConsider the following\r\n\r\n```py3\r\nimport abc\r\n\r\nfrom allennlp.common import Registrable\r\n\r\n\r\nclass Interface(Registrable, abc.ABC):\r\n    @abc.abstractmethod\r\n    def method(self) -> object:\r\n        raise NotImplementedError\r\n\r\n\r\n@Interface.register(\"mplementation\")\r\nclass Implementation(Interface):\r\n    def method(self) -> object:\r\n        return object()\r\n\r\n\r\ninstance = Implementation()\r\n# Tab completion will not work for `instance.method()`\r\nobj = instance.method()\r\n```\r\n\r\nNeither Jedi or Pylance will offer tab completions for anything that has to do with `Implementation` except for methods on `Registrable`.\r\n\r\nmypy will get the type information correct but Pylance will not.\r\n\r\n<details>\r\n<summary><b>Python traceback: N/A</b></summary>\r\n<p>\r\n\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: macOS 11.2.1\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.9.1\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\nVisual Studio Code version: 1.53.2\r\nPylance version: 2021.2.3\r\nmypy version: 0.800\r\nJedi version: 0.18.0\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```py3\r\nimport abc\r\n\r\nfrom allennlp.common import Registrable\r\n\r\n\r\nclass Interface(Registrable, abc.ABC):\r\n    @abc.abstractmethod\r\n    def method(self) -> object:\r\n        raise NotImplementedError\r\n\r\n\r\n@Interface.register(\"mplementation\")\r\nclass Implementation(Interface):\r\n    def method(self) -> object:\r\n        return object()\r\n\r\n\r\nobj = Implementation()\r\n# Tab completion will not work for `obj.method`\r\nobj.method() \r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5009/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5009/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/5006", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/5006/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/5006/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/5006/events", "html_url": "https://github.com/allenai/allennlp/issues/5006", "id": 813381435, "node_id": "MDU6SXNzdWU4MTMzODE0MzU=", "number": 5006, "title": "KeyError: 'elmo'", "user": {"login": "manelAffi", "id": 12198986, "node_id": "MDQ6VXNlcjEyMTk4OTg2", "avatar_url": "https://avatars.githubusercontent.com/u/12198986?v=4", "gravatar_id": "", "url": "https://api.github.com/users/manelAffi", "html_url": "https://github.com/manelAffi", "followers_url": "https://api.github.com/users/manelAffi/followers", "following_url": "https://api.github.com/users/manelAffi/following{/other_user}", "gists_url": "https://api.github.com/users/manelAffi/gists{/gist_id}", "starred_url": "https://api.github.com/users/manelAffi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/manelAffi/subscriptions", "organizations_url": "https://api.github.com/users/manelAffi/orgs", "repos_url": "https://api.github.com/users/manelAffi/repos", "events_url": "https://api.github.com/users/manelAffi/events{/privacy}", "received_events_url": "https://api.github.com/users/manelAffi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2021-02-22T10:49:21Z", "updated_at": "2021-05-01T11:44:54Z", "closed_at": "2021-05-01T11:44:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "System:\r\nOS: linux \r\nPython version: 3.7 \r\nAllenNLP version: 0.9.0 \r\nPyTorch version: 1.7.2\r\nQuestion:\r\nI'm trying to train crf-tagger model for named entity recognition task on CoNLL 2003 dataset using BERT and elmo embeddings.I got the following error message:\r\n\r\n**KeyError: 'elmo'**\r\n\r\n**_here is the config file code:_**\r\n```\r\n{\r\n\r\n  \"dataset_reader\": {\r\n    \"type\": \"conll2003\",\r\n    \"tag_label\": \"ner\",\r\n    \"coding_scheme\": \"BIOUL\",\r\n    \"token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"single_id\"\r\n\r\n              },\r\n        \"elmo\": {\r\n        \"type\": \"elmo_characters\"\r\n          } ,\r\n\"bert\": {\r\n         \"type\": \"bert-pretrained\",\r\n        \"pretrained_model\":\"bert-base-cased\",\r\n        \"do_lowercase\": false,\r\n\"use_starting_offsets\": true\r\n      }\r\n\r\n    }\r\n  },\r\n\"train_data_path\": \"########\",\r\n    \"validation_data_path\": \"#########\",\r\n  \r\n  \"model\": {\r\n    \"type\": \"crf_tagger\",\r\n    \"label_encoding\": \"BIOUL\",\r\n    \"dropout\": 0.5,\r\n    \"include_start_end_transitions\": false,\r\n    \"text_field_embedder\": {\r\n\"allow_unmatched_keys\": true,\r\n\r\n      \"embedder_to_indexer_map\": {\r\n                \"bert\": [\"bert\", \"bert-offsets\"],\r\n                \"token_characters\": [\"token_characters\"],\r\n            }, \r\n\r\n       \"bert\": {\r\n                    \"type\": \"bert-pretrained\",\r\n                    \"pretrained_model\": \"bert-base-cased\"\r\n                },\r\n\r\n\r\n        \"elmo\":{\r\n            \"type\": \"elmo_token_embedder\",\r\n        \"options_file\": \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\",\r\n        \"weight_file\": \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\",\r\n            \"do_layer_norm\": false,\r\n            \"dropout\": 0.0\r\n        }\r\n     \r\n             \r\n    },\r\n    \"encoder\": {\r\n      \"type\": \"lstm\",\r\n      \"input_size\": 1792,\r\n      \"hidden_size\": 200,\r\n      \"num_layers\": 2,\r\n      \"dropout\": 0.5,\r\n      \"bidirectional\": true\r\n    },\r\n    \"regularizer\": [\r\n      [\r\n        \"scalar_parameters\",\r\n        {\r\n          \"type\": \"l2\",\r\n          \"alpha\": 0.1\r\n        }\r\n      ]\r\n    ]\r\n  },\r\n  \"iterator\": {\r\n    \"type\": \"basic\",\r\n    \"batch_size\": 64\r\n  },\r\n  \"trainer\": {\r\n    \"optimizer\": {\r\n        \"type\": \"adam\",\r\n        \"lr\": 0.0001\r\n    },\r\n    \"validation_metric\": \"+f1-measure-overall\",\r\n    \"num_serialized_models_to_keep\": 3,\r\n    \"num_epochs\": 200,\r\n    \"grad_norm\": 5.0,\r\n\r\n    \"cuda_device\": -1\r\n  }\r\n}\r\n```\r\nIs there any idea what should be the problem?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/5006/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/5006/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4982", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4982/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4982/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4982/events", "html_url": "https://github.com/allenai/allennlp/issues/4982", "id": 808674965, "node_id": "MDU6SXNzdWU4MDg2NzQ5NjU=", "number": 4982, "title": "Nesting Issue on the 'Reading Data' section of the Guide", "user": {"login": "gabeorlanski", "id": 18234433, "node_id": "MDQ6VXNlcjE4MjM0NDMz", "avatar_url": "https://avatars.githubusercontent.com/u/18234433?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gabeorlanski", "html_url": "https://github.com/gabeorlanski", "followers_url": "https://api.github.com/users/gabeorlanski/followers", "following_url": "https://api.github.com/users/gabeorlanski/following{/other_user}", "gists_url": "https://api.github.com/users/gabeorlanski/gists{/gist_id}", "starred_url": "https://api.github.com/users/gabeorlanski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gabeorlanski/subscriptions", "organizations_url": "https://api.github.com/users/gabeorlanski/orgs", "repos_url": "https://api.github.com/users/gabeorlanski/repos", "events_url": "https://api.github.com/users/gabeorlanski/events{/privacy}", "received_events_url": "https://api.github.com/users/gabeorlanski/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-02-15T16:29:37Z", "updated_at": "2021-02-15T20:23:11Z", "closed_at": "2021-02-15T20:23:11Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I had included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included the \"Environment\" section below the output of `pip freeze.`\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nWhen browsing the 'Reading Data' section of the AllenNLP Guide, the subsections 'Vocabulary' and 'Datasets, the dataset loader, and samplers' are nested inside of the 'Dataset Readers' subsection. Clicking on either of the nested elements closes the 'Dataset Readers' subsection. \r\n\r\nScreenshots of the issue:\r\n\r\n![image](https://user-images.githubusercontent.com/18234433/107971295-4c357180-6f80-11eb-8136-420c27433d86.png)\r\n\r\n![image](https://user-images.githubusercontent.com/18234433/107971521-94549400-6f80-11eb-9da0-42e1a0339b50.png)\r\n\r\n## Environment\r\n\r\nWindows 10\r\n\r\nGoogle Chrome with uBlock, Grammarly, & Zotero Connector.\r\n\r\n## Related Issues\r\n\r\nNone\r\n\r\n## Steps to reproduce\r\n\r\nGo to https://guide.allennlp.org/reading-data. I tested it both with and w/o extensions, and the issue persisted. \r\n\r\nApologies if this is not the right place to post this issue; please let me know if there is a more appropriate location.\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4982/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4982/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4978", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4978/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4978/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4978/events", "html_url": "https://github.com/allenai/allennlp/issues/4978", "id": 807659940, "node_id": "MDU6SXNzdWU4MDc2NTk5NDA=", "number": 4978, "title": "We cache 404 responses", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/16", "html_url": "https://github.com/allenai/allennlp/milestone/16", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/16/labels", "id": 6087040, "node_id": "MDk6TWlsZXN0b25lNjA4NzA0MA==", "number": 16, "title": "2.1", "description": "", "creator": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 22, "state": "closed", "created_at": "2020-11-09T18:44:24Z", "updated_at": "2021-02-25T22:13:18Z", "due_on": "2021-02-26T08:00:00Z", "closed_at": "2021-02-25T22:13:18Z"}, "comments": 1, "created_at": "2021-02-13T02:53:34Z", "updated_at": "2021-02-15T23:46:50Z", "closed_at": "2021-02-15T23:46:50Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "When you do `cached_path(\"https://raw.githubusercontent.com/allenai/allennlp-models/main/training_config/snli_roberta.jsonnet\")`, we get a 404 response with a body. We cache the body as if nothing had happened. We should throw an exception in this case.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4978/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4978/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4977", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4977/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4977/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4977/events", "html_url": "https://github.com/allenai/allennlp/issues/4977", "id": 807642427, "node_id": "MDU6SXNzdWU4MDc2NDI0Mjc=", "number": 4977, "title": "BART model make_output_human_readable produces special characters that are not removed", "user": {"login": "vikigenius", "id": 12724810, "node_id": "MDQ6VXNlcjEyNzI0ODEw", "avatar_url": "https://avatars.githubusercontent.com/u/12724810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vikigenius", "html_url": "https://github.com/vikigenius", "followers_url": "https://api.github.com/users/vikigenius/followers", "following_url": "https://api.github.com/users/vikigenius/following{/other_user}", "gists_url": "https://api.github.com/users/vikigenius/gists{/gist_id}", "starred_url": "https://api.github.com/users/vikigenius/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vikigenius/subscriptions", "organizations_url": "https://api.github.com/users/vikigenius/orgs", "repos_url": "https://api.github.com/users/vikigenius/repos", "events_url": "https://api.github.com/users/vikigenius/events{/privacy}", "received_events_url": "https://api.github.com/users/vikigenius/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-02-13T01:11:15Z", "updated_at": "2021-02-17T19:01:18Z", "closed_at": "2021-02-17T19:01:18Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nBART model make_output_human_readable still produces these spacial characters in every token\r\nsuch as `\u0120slated`\r\n\r\nProper decoding should be applied similar to the huggingface tokenizer `batch_decode`, The leading `\u0120 ` should be removed.\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalabaster @ file:///home/void/.cache/pypoetry/artifacts/01/50/a4/e8f66b1cc7b3896e348a7976ec6390f61a7ed3cc0583b406c9a737955a/alabaster-0.7.12-py2.py3-none-any.whl\r\nallennlp @ file:///home/void/.cache/pypoetry/artifacts/92/1b/b7/71bd8d4b1e397db4e64917d96cf231c82332f91dcab792b4cea05e7d8e/allennlp-2.0.1-py3-none-any.whl\r\nallennlp-models @ file:///home/void/.cache/pypoetry/artifacts/20/b2/f8/bd59ebe6e37f9f6cdb68a70fc8b2082913616a30bb48362e47874321e6/allennlp_models-2.0.1-py3-none-any.whl\r\nargon2-cffi @ file:///home/void/.cache/pypoetry/artifacts/ed/b1/79/070afdded6990696180ad5ca5dc36c165047414604d3b43d51b546c2a3/argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl\r\nastor @ file:///home/void/.cache/pypoetry/artifacts/00/68/e3/b2c93c6b1eabbb453b7a288336d64a2bb9f32b6821173440843f97f64b/astor-0.8.1-py2.py3-none-any.whl\r\nasync-generator @ file:///home/void/.cache/pypoetry/artifacts/60/d6/35/e25389ca9cdf584a7a41be4eab45a490150210296ca82c7eb696a7e21b/async_generator-1.10-py3-none-any.whl\r\nattrs @ file:///home/void/.cache/pypoetry/artifacts/b7/28/6f/acdd2c0e759f1cda97abf00db7723a0ffb3a151696d8d96398aea16171/attrs-20.3.0-py2.py3-none-any.whl\r\nBabel @ file:///home/void/.cache/pypoetry/artifacts/e3/ab/8c/e6b588d52a460a9eca8f0b62cffeb18d90d8631d8b5c7e180c56b123f8/Babel-2.9.0-py2.py3-none-any.whl\r\nbackcall @ file:///home/void/.cache/pypoetry/artifacts/62/2c/f2/bf9c43ca0bcfca41150901227b0d023dc854851b710f82a72f5beaa09b/backcall-0.2.0-py2.py3-none-any.whl\r\nbandit @ file:///home/void/.cache/pypoetry/artifacts/a2/02/ff/eaae30b6c44acbb38e05e07e4a685c781ebb46ec87a72eeafbc8ede15b/bandit-1.7.0-py3-none-any.whl\r\nbleach @ file:///home/void/.cache/pypoetry/artifacts/03/c4/86/6b724fd4941eb6dc691b41bd051edfcef5f751fd330f8dfdded6148c22/bleach-3.3.0-py2.py3-none-any.whl\r\nblis @ file:///home/void/.cache/pypoetry/artifacts/c1/6a/53/ab49b0541a65090ca3787de6651b2c5cf228cc4a7b93c093bbbb5f415d/blis-0.7.4-cp38-cp38-manylinux2014_x86_64.whl\r\nboto3 @ file:///home/void/.cache/pypoetry/artifacts/53/59/12/93f0af855a74db70fd3e94e4f8655aa5928c6b705691e161741cbec4a8/boto3-1.17.6-py2.py3-none-any.whl\r\nbotocore @ file:///home/void/.cache/pypoetry/artifacts/02/bd/6d/fd3a405051dd0a37f20868bc69d2f1d50233395fb823381149c5d5ffd2/botocore-1.20.6-py2.py3-none-any.whl\r\ncatalogue @ file:///home/void/.cache/pypoetry/artifacts/66/0c/9f/6e9dcd1587b0eb24a7c0c5a7209d9d3329db000eccd099aba006ce8c42/catalogue-1.0.0-py2.py3-none-any.whl\r\ncertifi==2020.12.5\r\ncffi @ file:///home/void/.cache/pypoetry/artifacts/cf/25/46/fba32f6d9f6905002c6effaf3af43b2dc09c22ec500ea40c30a8e7ca8f/cffi-1.14.5-cp38-cp38-manylinux1_x86_64.whl\r\nchardet @ file:///home/void/.cache/pypoetry/artifacts/47/b7/82/19c2b887f87f3adbaf4e34c55189388e5132c78f6929d7001a78b0209b/chardet-4.0.0-py2.py3-none-any.whl\r\nclick @ file:///home/void/.cache/pypoetry/artifacts/30/bc/bf/e00ffd8f0edf0294942e70e80e42a839bd2649d2c5b864e6389e526d2a/click-7.1.2-py2.py3-none-any.whl\r\nconllu @ file:///home/void/.cache/pypoetry/artifacts/db/cb/54/851ab0e9a095980cd0c4972efed5d0158b363ccdcebc69cd0e41b1c802/conllu-4.3-py2.py3-none-any.whl\r\ncoverage @ file:///home/void/.cache/pypoetry/artifacts/f6/0d/b6/e93b30b39eccb8fc81e24a14c71c3d8530393712e541716ec051102f1b/coverage-5.3.1-cp38-cp38-manylinux2010_x86_64.whl\r\ncymem @ file:///home/void/.cache/pypoetry/artifacts/ca/8e/37/15120086d6b07407d5d4c8b642a7bec13108a8b7c3a00ae2a35e205881/cymem-2.0.5-cp38-cp38-manylinux2014_x86_64.whl\r\ndarglint @ file:///home/void/.cache/pypoetry/artifacts/2a/9e/ad/0486d2f4b39ac06deb141e646b9aa9148018824d9b349f134e23062660/darglint-1.5.8-py3-none-any.whl\r\ndecorator @ file:///home/void/.cache/pypoetry/artifacts/e8/56/46/038f0f95c2eb2a2792092491cba740226306e663708d5062754d1cb91f/decorator-4.4.2-py2.py3-none-any.whl\r\ndefusedxml @ file:///home/void/.cache/pypoetry/artifacts/8b/b9/f6/56ba9b58f3a759ce345d18bad38edfc12a9f60420962a17a2084202e0e/defusedxml-0.6.0-py2.py3-none-any.whl\r\ndictdiffer @ file:///home/void/.cache/pypoetry/artifacts/eb/97/47/75d6a828e2d9ef1962485d485975c13ff4d8935bb03440f802941f5df2/dictdiffer-0.8.1-py2.py3-none-any.whl\r\ndoc8 @ file:///home/void/.cache/pypoetry/artifacts/15/14/54/c10d16daae42bacb0d561fbf93d68019c90d273d773c79cdb447cb9111/doc8-0.8.1-py2.py3-none-any.whl\r\ndocutils @ file:///home/void/.cache/pypoetry/artifacts/9e/78/f1/81f20d21f3ed304c86fa5394fadbb173e75ad363029a8fefa635dadf2e/docutils-0.16-py2.py3-none-any.whl\r\ndparse @ file:///home/void/.cache/pypoetry/artifacts/45/f0/d9/1a980d82905c06a7365c6227aac29281c69dce4021fafe2a199de092e8/dparse-0.5.1-py3-none-any.whl\r\nentrypoints @ file:///home/void/.cache/pypoetry/artifacts/27/67/42/5ca7438658f76c8700ff6c44ea1cf9dc128cf0862adb7de53d3a35266c/entrypoints-0.3-py2.py3-none-any.whl\r\neradicate @ file:///home/void/.cache/pypoetry/artifacts/d7/9d/a9/4eb3af3b79f810cc0b1b6f09395d9ee84772b603a8e8978e12b12717d2/eradicate-1.0.tar.gz\r\nfilelock @ file:///home/void/.cache/pypoetry/artifacts/f4/78/c1/69555c3867649a2a5dac43f12a078830700480a49be273fb2de82be2ab/filelock-3.0.12-py3-none-any.whl\r\nflake8 @ file:///home/void/.cache/pypoetry/artifacts/5c/5b/91/23d9fee55905e042e829a14e2fa56ffd39c81246aba659e2840bab728b/flake8-3.8.4-py2.py3-none-any.whl\r\nflake8-bandit @ file:///home/void/.cache/pypoetry/artifacts/cc/6d/cf/94dc0d884687c0e10baebe95be53977448e1b59d7ad05e41a0f046cd7e/flake8_bandit-2.1.2.tar.gz\r\nflake8-broken-line @ file:///home/void/.cache/pypoetry/artifacts/b6/72/5f/b138cf8858a3bb7411d5443831c6a3d9c2170f1a4fb01b07a96a33b801/flake8_broken_line-0.2.1-py3-none-any.whl\r\nflake8-bugbear @ file:///home/void/.cache/pypoetry/artifacts/2d/c4/51/6e0f2c02d3e6a846fd30eded9b747688cecf8e55e1c9280ab30a793c04/flake8_bugbear-19.8.0-py35.py36.py37-none-any.whl\r\nflake8-commas @ file:///home/void/.cache/pypoetry/artifacts/b7/aa/76/e620a68b0be70f4132be94bfbfdacb20b16c060174b33dc856818db92d/flake8_commas-2.0.0-py2.py3-none-any.whl\r\nflake8-comprehensions @ file:///home/void/.cache/pypoetry/artifacts/79/68/a1/ad2a93c936991789c7abe3cfaad2061386a4a605875dc6031c7bf68a96/flake8_comprehensions-3.3.1-py3-none-any.whl\r\nflake8-debugger @ file:///home/void/.cache/pypoetry/artifacts/da/2c/e3/d62fd2fc55b1f63fccb2997d98af07223eae27b3216cdb75fa9975b398/flake8-debugger-3.2.1.tar.gz\r\nflake8-docstrings @ file:///home/void/.cache/pypoetry/artifacts/14/46/f1/42800107fb2815121aebf831e269f0af48a45c669a24dbcec60fbbac9f/flake8_docstrings-1.5.0-py2.py3-none-any.whl\r\nflake8-eradicate @ file:///home/void/.cache/pypoetry/artifacts/ad/cc/3b/7c679e5a37dbe9e9d3b056d2e5ee8e3dceac70460c3edcb852b0c650f4/flake8_eradicate-0.3.0-py3-none-any.whl\r\nflake8-isort @ file:///home/void/.cache/pypoetry/artifacts/56/70/ee/b8f0228abc9e3e9ff24faa6cf960fe806dc20e1a9d327835b90545585a/flake8_isort-3.0.1-py2.py3-none-any.whl\r\nflake8-plugin-utils @ file:///home/void/.cache/pypoetry/artifacts/99/73/fc/1fd22f303405c472d0dd047300335cdbbcc598f106b402ce1176be733b/flake8_plugin_utils-1.3.1-py3-none-any.whl\r\nflake8-polyfill @ file:///home/void/.cache/pypoetry/artifacts/37/d4/b9/446f3fe801eea4de2fdff2cd1e0be3fa836d08c04d62174d4ec65113f3/flake8_polyfill-1.0.2-py2.py3-none-any.whl\r\nflake8-pytest-style @ file:///home/void/.cache/pypoetry/artifacts/b9/91/aa/24d42f27861d7e5a75ff711270a98440f637f704a85bc7e67fbaa683c9/flake8_pytest_style-1.3.0-py3-none-any.whl\r\nflake8-quotes @ file:///home/void/.cache/pypoetry/artifacts/fb/94/4e/57a6dae12a87b982e4d35a28f9336ab761e0333a4be207d2d9f3ff5c99/flake8-quotes-2.1.2.tar.gz\r\nflake8-rst-docstrings @ file:///home/void/.cache/pypoetry/artifacts/a2/a0/d5/c25770b5624cb722839214583bf7156c6716d34aeb62ff9ee9d96ed7e6/flake8-rst-docstrings-0.0.12.tar.gz\r\nflake8-string-format @ file:///home/void/.cache/pypoetry/artifacts/54/fe/a4/42804621e559c82bc460b782340c42d279633fb413fe8911e1c45707fc/flake8_string_format-0.2.3-py2.py3-none-any.whl\r\nftfy @ file:///home/void/.cache/pypoetry/artifacts/c7/b0/76/41a4cd05c70fc8a10607999388f756cfe86e90c18cf35bacf8f431ec69/ftfy-5.9.tar.gz\r\ngitdb @ file:///home/void/.cache/pypoetry/artifacts/45/a9/94/d73ced00c6cf302a2e08bedd4f10d3424342b7a8a2fae6e4ccb7276641/gitdb-4.0.5-py3-none-any.whl\r\nGitPython @ file:///home/void/.cache/pypoetry/artifacts/bb/7d/e3/03ce0e77da368e61f7ddc587b791b0272880265992f05053a40cb306e3/GitPython-3.1.11-py3-none-any.whl\r\nh5py @ file:///home/void/.cache/pypoetry/artifacts/7f/72/5d/4e83293f7117dc8b4bdebb63cefc313bdc02268760f020ed7817f38500/h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl\r\nidentify @ file:///home/void/.cache/pypoetry/artifacts/34/21/4f/24b1c0e2baea12dab9a043a6482e09c5c75c4029276a093e581e069af8/identify-1.5.11-py2.py3-none-any.whl\r\nidna @ file:///home/void/.cache/pypoetry/artifacts/9e/f9/03/6066b92d35486e7f0d4f310126e3c60a6619726e43ef98e32e105b5c52/idna-2.10-py2.py3-none-any.whl\r\nimagesize @ file:///home/void/.cache/pypoetry/artifacts/0b/69/4e/8e64ed37efc2f5438fce870c94736b2e1a21bc4cb0c286f936de14357b/imagesize-1.2.0-py2.py3-none-any.whl\r\niniconfig @ file:///home/void/.cache/pypoetry/artifacts/ac/f9/da/e990ffcd9ec361a68676a5916e391286e1ea5d1b8907ae887e141a71f5/iniconfig-1.1.1-py2.py3-none-any.whl\r\nipykernel @ file:///home/void/.cache/pypoetry/artifacts/ca/cc/51/21510e246e9deb89203de406b6dab87f42b80731a134a35c3b35ae0a94/ipykernel-5.4.3-py3-none-any.whl\r\nipython @ file:///home/void/.cache/pypoetry/artifacts/9d/5c/6c/fd11fbc1b7f9f030c25ae5398fdb36c2f354bad2e1b3174140e50cb128/ipython-7.20.0-py3-none-any.whl\r\nipython-genutils @ file:///home/void/.cache/pypoetry/artifacts/e6/8e/a3/8f37e14310c0072b3fcc4240490bcb42630aa695d069aee89953ebd9f8/ipython_genutils-0.2.0-py2.py3-none-any.whl\r\nipywidgets @ file:///home/void/.cache/pypoetry/artifacts/9e/60/06/3c8baa28b9c599236a810c64f38155a30bce229240ba64138d28e72a12/ipywidgets-7.6.3-py2.py3-none-any.whl\r\nisort @ file:///home/void/.cache/pypoetry/artifacts/6e/4e/fa/c1a31b7a066920f2d2cebcdf14f804e3f48fc87e5d4c85ae4805b246b2/isort-4.3.21-py2.py3-none-any.whl\r\njedi @ file:///home/void/.cache/pypoetry/artifacts/42/26/07/496d2180e241dbf58cf832e0c7a617d8fcbdd6f3f93937056d106545fc/jedi-0.18.0-py2.py3-none-any.whl\r\nJinja2 @ file:///home/void/.cache/pypoetry/artifacts/a0/8d/d0/dce9f8c04cdcf457adcd58424bdacab8a7a2c3c42854fd3c0d2135046e/Jinja2-2.11.2-py2.py3-none-any.whl\r\njmespath @ file:///home/void/.cache/pypoetry/artifacts/43/d5/a2/f83573231324de7f5b61f5c607fbbe82ca535359a452de4852d2e25e8d/jmespath-0.10.0-py2.py3-none-any.whl\r\njoblib @ file:///home/void/.cache/pypoetry/artifacts/99/5d/16/954581189911abfb7964c29411008b77f05fc968eb150b76de0105298a/joblib-1.0.1-py3-none-any.whl\r\njsonnet @ file:///home/void/.cache/pypoetry/artifacts/23/ba/91/41be2f00e06a18e8c220311460dc643bb9975fe5bbf08a3e0017e887fb/jsonnet-0.17.0.tar.gz\r\njsonpickle @ file:///home/void/.cache/pypoetry/artifacts/a3/43/36/9eb7c32fbeffd93e855d2090f208d1bb0660f56aa2e6d0a7234c3faae2/jsonpickle-2.0.0-py2.py3-none-any.whl\r\njsonschema @ file:///home/void/.cache/pypoetry/artifacts/8a/0f/f1/4a51263f4c7019004d5abd49f41d94c0eb4618233008d82a629134c337/jsonschema-3.2.0-py2.py3-none-any.whl\r\njupyter @ file:///home/void/.cache/pypoetry/artifacts/2e/44/a0/764f7d3907f220eb94db0e2bce1f8f3e50dcb48aca15a625dd210cb114/jupyter-1.0.0-py2.py3-none-any.whl\r\njupyter-client @ file:///home/void/.cache/pypoetry/artifacts/e2/8c/b4/2b7ad7ff3b52d561ad5f83e7539824b05c76d43d6ef4559c7a7f9a0f6a/jupyter_client-6.1.11-py3-none-any.whl\r\njupyter-console @ file:///home/void/.cache/pypoetry/artifacts/f9/ff/81/0dd86dc0829e56f6031db9604a9e65b360496a4fdfb6ccd866328c4bd8/jupyter_console-6.2.0-py3-none-any.whl\r\njupyter-core @ file:///home/void/.cache/pypoetry/artifacts/07/55/c4/ee3e77bec69dd940d44470676d43b7922aaca3c58d5a03fb779a70d5a8/jupyter_core-4.7.1-py3-none-any.whl\r\njupyterlab-pygments @ file:///home/void/.cache/pypoetry/artifacts/c8/b0/10/ad75ecf240424057a12f5b4320da2c9f380541cdf830a39e7e8437c2c0/jupyterlab_pygments-0.1.2-py2.py3-none-any.whl\r\njupyterlab-widgets @ file:///home/void/.cache/pypoetry/artifacts/d9/1d/4c/f2ccbffd2367bfd6f8b6f8674c9c2fc2c3a2c15472525bc9f9148fcdca/jupyterlab_widgets-1.0.0-py3-none-any.whl\r\nlmdb @ file:///home/void/.cache/pypoetry/artifacts/54/a8/b8/1d9edee5ee69cf6587981d9ef24e8df6a76b193405c73eb0df8a92f714/lmdb-1.1.1-cp38-cp38-manylinux2010_x86_64.whl\r\nm2r2 @ file:///home/void/.cache/pypoetry/artifacts/39/34/88/117e6424dbc37ae8415c6169ce97fad37fb90000feb01d9870e3a01667/m2r2-0.2.7-py3-none-any.whl\r\nMarkupSafe @ file:///home/void/.cache/pypoetry/artifacts/35/5e/ca/be6dbd0c55edef35786f1f6959189a0bdc523ab487501dbc604366a387/MarkupSafe-1.1.1-cp38-cp38-manylinux2010_x86_64.whl\r\nmarshmallow @ file:///home/void/.cache/pypoetry/artifacts/78/e7/6d/37c098bfe4a91d91057e01d2b2df13cd652fccf5434981b817618a71ae/marshmallow-3.10.0-py2.py3-none-any.whl\r\nmarshmallow-polyfield @ file:///home/void/.cache/pypoetry/artifacts/d1/50/95/b389132f11c645bf60b00b2a724eafd5a0191c62606e50e0c9ef69a505/marshmallow-polyfield-5.9.tar.gz\r\nmccabe @ file:///home/void/.cache/pypoetry/artifacts/37/6e/69/4a33a4d6c80c775b1ee205face2c6e07b762c8602bb0f0d236ebe790c5/mccabe-0.6.1-py2.py3-none-any.whl\r\nmistune @ file:///home/void/.cache/pypoetry/artifacts/d9/d8/5c/8eac14aaa95c3aa81409d56b7423ff6dd88eb398f551c1bf0b8c05b916/mistune-0.8.4-py2.py3-none-any.whl\r\nmore-itertools @ file:///home/void/.cache/pypoetry/artifacts/b7/39/2d/8628adfd013f3bf1658dafd470eef925f88b584f61666e69578a88b3b0/more_itertools-8.6.0-py3-none-any.whl\r\nmurmurhash @ file:///home/void/.cache/pypoetry/artifacts/99/c1/59/75a52b11305210d2b16251ce2dbcff345d77a00adbe3a3507a3e76c138/murmurhash-1.0.5-cp38-cp38-manylinux2014_x86_64.whl\r\nmypy @ file:///home/void/.cache/pypoetry/artifacts/c0/83/dd/de8e034d2958bf2280009b38cce3a6e64f029aadf2f6195d159e1e324c/mypy-0.800-cp38-cp38-manylinux2010_x86_64.whl\r\nmypy-extensions @ file:///home/void/.cache/pypoetry/artifacts/b6/a0/b0/a5dc9acd6fd12aba308634f21bb7cf0571448f20848797d7ecb327aa12/mypy_extensions-0.4.3-py2.py3-none-any.whl\r\nnbclient @ file:///home/void/.cache/pypoetry/artifacts/32/e0/83/62cd3e6565e844ed346844a6e4f9ea7c88f74a10fd813de14d97db655b/nbclient-0.5.2-py3-none-any.whl\r\nnbconvert @ file:///home/void/.cache/pypoetry/artifacts/6d/04/d2/6f698739d85cec6503abcfed57a421b113f6f66af399a25bf9994a1a87/nbconvert-6.0.7-py3-none-any.whl\r\nnbformat @ file:///home/void/.cache/pypoetry/artifacts/ef/d0/08/2cbfc9a5271fecac60296b690ec71df30e1a74edd3ff54c3caaffa35fe/nbformat-5.1.2-py3-none-any.whl\r\nnest-asyncio @ file:///home/void/.cache/pypoetry/artifacts/f5/d1/32/8bc78b4ee2a2d3a377491872fe5aa705448a863af0bb0968676a0e2d3b/nest_asyncio-1.5.1-py3-none-any.whl\r\nnitpick @ file:///home/void/.cache/pypoetry/artifacts/28/98/16/5682d5116b7b7060227becef96a14e31c189a936800abb96b0c0dfc7b9/nitpick-0.23.1-py3-none-any.whl\r\nnltk @ file:///home/void/.cache/pypoetry/artifacts/4e/a8/c9/3b9dad78f26601cae847a376b6c3342fc0f0e5d6bf78e56a12ac16dfbd/nltk-3.5.zip\r\nnotebook @ file:///home/void/.cache/pypoetry/artifacts/3e/8a/25/b1670acaec388e488b5241e4817ce5dcc033c659e66dcabd9bc167ed3e/notebook-6.2.0-py3-none-any.whl\r\nnumpy @ file:///home/void/.cache/pypoetry/artifacts/6b/78/d9/a99c8aed193c40fe75f4d38ae09ec07b5050b395579583ecc8546837fd/numpy-1.20.1-cp38-cp38-manylinux2010_x86_64.whl\r\noverrides @ file:///home/void/.cache/pypoetry/artifacts/2e/a1/58/bef997b290151ed8dc40c8873f5a581732643e73c41da963ab65b75838/overrides-3.1.0.tar.gz\r\npackaging @ file:///home/void/.cache/pypoetry/artifacts/e5/ad/d2/fc9c55d2e45df943eb12bd2454a16feb4608127ec5f4a8ec9c0c9d2b57/packaging-20.8-py2.py3-none-any.whl\r\npandocfilters @ file:///home/void/.cache/pypoetry/artifacts/a0/de/ee/57ddb36e87aac56bbe9fe7c7bee8049805d79bcc280239a9fc1e913a69/pandocfilters-1.4.3.tar.gz\r\nparso @ file:///home/void/.cache/pypoetry/artifacts/fe/ac/61/368c9383d3833586c1d666ec86359b6511fa79adb884e5f3ac5fd47a90/parso-0.8.1-py2.py3-none-any.whl\r\npbr @ file:///home/void/.cache/pypoetry/artifacts/85/81/cf/9255f6df466921f8291c85ab33df01caeda1916c2745a5071ce06a963f/pbr-5.5.1-py2.py3-none-any.whl\r\npep8-naming @ file:///home/void/.cache/pypoetry/artifacts/ce/6c/45/d883218e7ee597f1796a1593478f89443587aea185b8a63a863060d473/pep8_naming-0.9.1-py2.py3-none-any.whl\r\npexpect @ file:///home/void/.cache/pypoetry/artifacts/c0/05/08/f23ddb8e3d5b19e7cf01eb434220310be2aaf69226bdec78bc53589024/pexpect-4.8.0-py2.py3-none-any.whl\r\npickleshare @ file:///home/void/.cache/pypoetry/artifacts/27/b2/0a/93a92c700a1993b2923519262ddf76a629bd459a0597c0ae28bf80c7a6/pickleshare-0.7.5-py2.py3-none-any.whl\r\nPillow @ file:///home/void/.cache/pypoetry/artifacts/dc/72/1a/7393100a5a901ad79543139bc47b75318e812714a4ce45fba76f5869f0/Pillow-8.1.0-cp38-cp38-manylinux1_x86_64.whl\r\nplac @ file:///home/void/.cache/pypoetry/artifacts/80/ac/29/737762264fecacc0a2e9b9e3b000ce340249e75dd163f5eeb09521a1b4/plac-1.1.3-py2.py3-none-any.whl\r\npluggy @ file:///home/void/.cache/pypoetry/artifacts/9c/e5/0b/2d64d03361a081edeb5d2ec5f286ccf9719587781fbf6822e1b6384c27/pluggy-0.13.1-py2.py3-none-any.whl\r\npreshed @ file:///home/void/.cache/pypoetry/artifacts/f9/b7/0d/1caab8f6c606e6c5f86c52dc4a4f1f25b864815745958357cee910ce07/preshed-3.0.5-cp38-cp38-manylinux2014_x86_64.whl\r\nprometheus-client @ file:///home/void/.cache/pypoetry/artifacts/69/94/b3/926903ae24487f948be927c737b37ead3a9e0865b5ec0d3007cc4fa89f/prometheus_client-0.9.0-py2.py3-none-any.whl\r\nprompt-toolkit @ file:///home/void/.cache/pypoetry/artifacts/1e/13/17/7425192027400d23f6923827f245db808199c09c9edcd56ebdcbbae12d/prompt_toolkit-3.0.16-py3-none-any.whl\r\nprotobuf @ file:///home/void/.cache/pypoetry/artifacts/90/80/b4/17c7f9af1fcc5134e1e95664b3cb0c8ce7ed5cbe790cf81a6839dc4618/protobuf-3.14.0-cp38-cp38-manylinux1_x86_64.whl\r\nptyprocess @ file:///home/void/.cache/pypoetry/artifacts/b5/84/64/9519e6926ac101cbc8d93423b8165f4abac4f8a8e3e099f74d3c7e0e67/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npy @ file:///home/void/.cache/pypoetry/artifacts/6b/b2/2b/e6686e7d0183dbd36bd66921efa3e77ce26260a3671524cd86614290e0/py-1.10.0-py2.py3-none-any.whl\r\npy-rouge @ file:///home/void/.cache/pypoetry/artifacts/8c/da/8b/765cd7f7641eb25264c1d00e40e19d69d198c3f838160614aa34ff2fc7/py_rouge-1.1-py3-none-any.whl\r\npycodestyle @ file:///home/void/.cache/pypoetry/artifacts/01/f4/cf/c7e34cb76e03e95d9eff28af16fe09ee8edd01cc985fc2b88453b6d311/pycodestyle-2.6.0-py2.py3-none-any.whl\r\npycparser @ file:///home/void/.cache/pypoetry/artifacts/f1/03/25/40eb46f7bede64f78ba073e2141b8216e611cbcde72e3117c326560101/pycparser-2.20-py2.py3-none-any.whl\r\npydocstyle @ file:///home/void/.cache/pypoetry/artifacts/a4/ef/58/498033174cb8c68875036ec5d8a3d9d2e169c51bec9d35866bd62ff5ac/pydocstyle-5.1.1-py3-none-any.whl\r\npyflakes @ file:///home/void/.cache/pypoetry/artifacts/da/83/11/1e9a80c39638c6967e9b1117b17d8ec5f723ddd0a88251cc08dc0807b0/pyflakes-2.2.0-py2.py3-none-any.whl\r\nPygments @ file:///home/void/.cache/pypoetry/artifacts/e5/a5/53/d98f2a9beba10dd0ffb48968f421a7d8c4339a9ed2bb90b668bdbf1772/Pygments-2.7.3-py3-none-any.whl\r\npyparsing @ file:///home/void/.cache/pypoetry/artifacts/da/e7/3d/1780282f558e5fd157bf708b28b8ba0d08323ef6bc5b6396139ce38a0b/pyparsing-2.4.7-py2.py3-none-any.whl\r\npyrsistent @ file:///home/void/.cache/pypoetry/artifacts/d8/37/43/5ceed6677fc301784b0e62604a431e293d12c402f4ca588304e916a04d/pyrsistent-0.17.3.tar.gz\r\npytest @ file:///home/void/.cache/pypoetry/artifacts/ba/91/14/23adb9b15ce836665a99c972a5135db1ca93b99dfe4946fddf87c531b6/pytest-6.2.2-py3-none-any.whl\r\npytest-cov @ file:///home/void/.cache/pypoetry/artifacts/e8/ed/6e/eac235440db34634156d9b3964828f68d21a7a936edfeed08da39c8ba4/pytest_cov-2.11.1-py2.py3-none-any.whl\r\npytest-randomly @ file:///home/void/.cache/pypoetry/artifacts/ec/d0/3c/142a2f637a49d6c11feea2a694c02e488b83021cfc00b940c1b09736ce/pytest_randomly-3.5.0-py3-none-any.whl\r\npython-dateutil @ file:///home/void/.cache/pypoetry/artifacts/1e/2c/dc/0e811c2299b40168ee1da03bc13c11762ce9fa96eb867ad22280db11fc/python_dateutil-2.8.1-py2.py3-none-any.whl\r\npython-slugify @ file:///home/void/.cache/pypoetry/artifacts/fb/48/0c/b3d105b241e71968321b5a90e86893953d66bded05418da96166cd7d7f/python-slugify-4.0.1.tar.gz\r\npytz @ file:///home/void/.cache/pypoetry/artifacts/82/a3/7d/f351b383d5fc50fa6c93691abd2eb98ce223942fc7ddaa5ab57df3a2d0/pytz-2020.5-py2.py3-none-any.whl\r\nPyYAML @ file:///home/void/.cache/pypoetry/artifacts/28/fe/c8/ee41918e776a0a8fea86e3b4d45d54620381726103e666941e1218c099/PyYAML-5.3.1.tar.gz\r\npyzmq @ file:///home/void/.cache/pypoetry/artifacts/0e/70/6f/dd9819776d1423b5f0c7e85bb49bac637df39b6505a7c5bec1cf47487d/pyzmq-22.0.2-cp38-cp38-manylinux2010_x86_64.whl\r\nqtconsole @ file:///home/void/.cache/pypoetry/artifacts/cb/cb/80/e45d4b10cb73fc8b5dc809f4f02a66324699d0c489a5e997120279eaec/qtconsole-5.0.2-py3-none-any.whl\r\nQtPy @ file:///home/void/.cache/pypoetry/artifacts/68/e6/b3/652e75104edbe2a4b47170036550f3c8df1bf6f4f9ae6be442ef16c336/QtPy-1.9.0-py2.py3-none-any.whl\r\nregex @ file:///home/void/.cache/pypoetry/artifacts/1a/c5/d0/d7e7c5f9ae704a0f1d45d0c7de61dd2a09d8d8dca37ea2ef84cacd8014/regex-2020.11.13-cp38-cp38-manylinux2014_x86_64.whl\r\nrequests @ file:///home/void/.cache/pypoetry/artifacts/fe/f0/74/d691c7619cd645682c495ff78949b9c284e88d3f2ee85124df5cec5b0a/requests-2.25.1-py2.py3-none-any.whl\r\nrestructuredtext-lint @ file:///home/void/.cache/pypoetry/artifacts/7b/45/5c/94b65fa89812c0d8701b8af07cdd43b8a91f5e8d84776984b12942b4cc/restructuredtext_lint-1.3.2.tar.gz\r\nruamel.yaml @ file:///home/void/.cache/pypoetry/artifacts/fa/10/2b/409b73cb7fd78317ea1094d48cb62274d1ceb83475047162e073699ec5/ruamel.yaml-0.16.12-py2.py3-none-any.whl\r\nruamel.yaml.clib @ file:///home/void/.cache/pypoetry/artifacts/97/f1/f1/1e2842d208a1b2fb98118062b928f0534297168decb2e8006fb82d3d20/ruamel.yaml.clib-0.2.2-cp38-cp38-manylinux1_x86_64.whl\r\ns3transfer @ file:///home/void/.cache/pypoetry/artifacts/cf/63/c5/7580e86fcf1fa802988931d06bc716be085bbc9517773c51d9b73de2fa/s3transfer-0.3.4-py2.py3-none-any.whl\r\nsacremoses @ file:///home/void/.cache/pypoetry/artifacts/94/85/15/980a84215423e23c131132e651f13e7cfbda060563ddf4699c72417524/sacremoses-0.0.43.tar.gz\r\nsafety @ file:///home/void/.cache/pypoetry/artifacts/63/c0/5e/ad040630c3c4e32471b7b2dbd488d35607706d7edfa79c7cd005822b82/safety-1.10.3-py2.py3-none-any.whl\r\nscikit-learn @ file:///home/void/.cache/pypoetry/artifacts/2b/13/bb/3e2b5565a547674f528dca45735afbb3a04a266ea3fbbe58f8686ea474/scikit_learn-0.24.1-cp38-cp38-manylinux2010_x86_64.whl\r\nscipy @ file:///home/void/.cache/pypoetry/artifacts/7a/f6/ba/197cd382ed7840dab3372a4bcbd2858141d32e3f940c08cf324d453be3/scipy-1.6.0-cp38-cp38-manylinux1_x86_64.whl\r\nSend2Trash @ file:///home/void/.cache/pypoetry/artifacts/40/97/0a/f421bca5e8da2c4a13d0c5abe9f2309550d5ebc2067b67c3929997663c/Send2Trash-1.5.0-py3-none-any.whl\r\nsentencepiece @ file:///home/void/.cache/pypoetry/artifacts/86/35/07/3ea3ee9f67b6776a9a2ce98f1fc55d6490965fb7f63cad2c9785e423d1/sentencepiece-0.1.95-cp38-cp38-manylinux2014_x86_64.whl\r\nsix @ file:///home/void/.cache/pypoetry/artifacts/be/98/c7/69fe6fea7a59659af1c6260899226129565330b1e07c9c5b3769be76bf/six-1.15.0-py2.py3-none-any.whl\r\nsmmap @ file:///home/void/.cache/pypoetry/artifacts/39/8f/16/e7986b1d62635c17d6635e446732dd98686c7b0f663445a0cd6e59dcdf/smmap-3.0.4-py2.py3-none-any.whl\r\nsnowballstemmer @ file:///home/void/.cache/pypoetry/artifacts/00/58/78/ad3aa1f5e8e5da623c9a205c7cdb41811fb480646c3e79278fc2aec1ad/snowballstemmer-2.0.0-py2.py3-none-any.whl\r\nsortedcontainers @ file:///home/void/.cache/pypoetry/artifacts/b3/bf/a2/83677c4175a4561da36b5ec625e33e1cdd6d78137304a914eb5d6fdcdd/sortedcontainers-2.3.0-py2.py3-none-any.whl\r\nspacy @ file:///home/void/.cache/pypoetry/artifacts/36/c2/b9/7a41c7004dcbf5e37582293be65afba57732df23a5725156b9af97da12/spacy-2.3.5-cp38-cp38-manylinux2014_x86_64.whl\r\nSphinx @ file:///home/void/.cache/pypoetry/artifacts/0d/7d/82/f28778a133e439612c72eef9e913015ae6acee86ebbd4676d008b5f359/Sphinx-3.4.3-py3-none-any.whl\r\nsphinx-autodoc-typehints @ file:///home/void/.cache/pypoetry/artifacts/07/e9/63/83f90539db71f9ae4be4b5a9fb90ad6e5cb77afd4ae1303de549d51d3a/sphinx_autodoc_typehints-1.11.1-py3-none-any.whl\r\nsphinxcontrib-applehelp @ file:///home/void/.cache/pypoetry/artifacts/06/55/7c/cf28d2c944f7fc7cba94678d0ca98b77947cae69b6c801ffd04601cc8c/sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl\r\nsphinxcontrib-devhelp @ file:///home/void/.cache/pypoetry/artifacts/95/e9/af/55ffd1a6f2b03f2bc460172ec6a9ee4a9353404fc6b9026b0fd4776f84/sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl\r\nsphinxcontrib-htmlhelp @ file:///home/void/.cache/pypoetry/artifacts/a0/ad/8e/a970be3040e06e0264ff5263c1c64053370852e5711ebce0169f50d4c0/sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl\r\nsphinxcontrib-jsmath @ file:///home/void/.cache/pypoetry/artifacts/5f/c9/8c/2bf04b76e3b07f85857acb15a02dec77db17eb7069ef7e3e8200580fa0/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\r\nsphinxcontrib-qthelp @ file:///home/void/.cache/pypoetry/artifacts/bd/a5/cb/8f6c168f27ca463b2c09d5dfbaabea32b6bb9ebff80556a11bc2b1152f/sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl\r\nsphinxcontrib-serializinghtml @ file:///home/void/.cache/pypoetry/artifacts/83/d2/78/3f17c9e1fa5ed17cb815a8d897bf2003c1197b16a36d4e9c6ffa0e8592/sphinxcontrib_serializinghtml-1.1.4-py2.py3-none-any.whl\r\nsrsly @ file:///home/void/.cache/pypoetry/artifacts/95/28/16/fc7e1f5b629858033577ba88d1323166891a41a37a73796c10cd181bbb/srsly-1.0.5-cp38-cp38-manylinux2014_x86_64.whl\r\nstevedore @ file:///home/void/.cache/pypoetry/artifacts/df/1c/87/ee139e37999b53501924b31a04b30301f789c2944af24daea1ada94ceb/stevedore-3.3.0-py3-none-any.whl\r\ntensorboardX @ file:///home/void/.cache/pypoetry/artifacts/5c/f4/0c/18de8e039c6894db1eff82340d262b49639d8e0b820d4ad2b193085f7c/tensorboardX-2.1-py2.py3-none-any.whl\r\nterminado @ file:///home/void/.cache/pypoetry/artifacts/cb/a1/eb/b520f4a95413cc2b0d167b65543cd45d4931d8d558b34a500425420d51/terminado-0.9.2-py3-none-any.whl\r\ntestfixtures @ file:///home/void/.cache/pypoetry/artifacts/05/e3/a1/03c61121816abcf7ccef77f4209a1af6f7f395449b0e20a01319b1ed77/testfixtures-6.17.0-py2.py3-none-any.whl\r\ntestpath @ file:///home/void/.cache/pypoetry/artifacts/71/31/06/e1366905608d747ada47997b3406776c1f88e2628e47674e40b9ae2b0b/testpath-0.4.4-py2.py3-none-any.whl\r\ntext-unidecode @ file:///home/void/.cache/pypoetry/artifacts/9b/cc/f2/c615087594418f3b86c03fb83c56a1d3b673e89924d4bd0cece68a7615/text_unidecode-1.3-py2.py3-none-any.whl\r\nthinc @ file:///home/void/.cache/pypoetry/artifacts/85/e0/9a/a14504a9d22c9132b1c6010fe04251c021c45b2f0d59a38b2aa2528d5a/thinc-7.4.5-cp38-cp38-manylinux2014_x86_64.whl\r\nthreadpoolctl @ file:///home/void/.cache/pypoetry/artifacts/51/cf/f3/45cf01a8bc970a364ec52ad5b3efb73b5796bed51e1aef77f8f1127009/threadpoolctl-2.1.0-py3-none-any.whl\r\ntokenizers @ file:///home/void/.cache/pypoetry/artifacts/82/ef/c8/addb069aa47b4035ef0259126dcb6827ee49fcac9ec39fdd9ab5f1a26d/tokenizers-0.9.4-cp38-cp38-manylinux2010_x86_64.whl\r\ntoml @ file:///home/void/.cache/pypoetry/artifacts/9f/8c/c3/7b4f6778d60f3c9fa11f8fd0e48243bbad25a04975e0a01006b6350594/toml-0.10.2-py2.py3-none-any.whl\r\ntomlkit @ file:///home/void/.cache/pypoetry/artifacts/db/c3/df/baf014ce3b04caffe7ac34bde699f5be82c4acbaf43f49db1ce681a500/tomlkit-0.7.0-py2.py3-none-any.whl\r\ntorch @ file:///home/void/.cache/pypoetry/artifacts/58/3f/f5/0143b619b912b168d35ccd1a65e440458b9ef10e5a42d443a10ac2e071/torch-1.7.1-cp38-cp38-manylinux1_x86_64.whl\r\ntorchvision @ file:///home/void/.cache/pypoetry/artifacts/f2/b6/1d/b571445a54fde1310d71131b43e93cd136961c80dbd2baf4c62da3ec87/torchvision-0.8.2-cp38-cp38-manylinux1_x86_64.whl\r\ntornado @ file:///home/void/.cache/pypoetry/artifacts/ec/fb/c8/e022dee175b03afe90ae806e12ec894741303dfc5a6debe95d80154754/tornado-6.1-cp38-cp38-manylinux2010_x86_64.whl\r\ntqdm @ file:///home/void/.cache/pypoetry/artifacts/b7/3d/36/e88ff18c4013224925383df2c50ce69406578cf75a62d066f2b91444ca/tqdm-4.56.2-py2.py3-none-any.whl\r\ntraitlets @ file:///home/void/.cache/pypoetry/artifacts/8a/f4/fd/48c1725dcdd56393737bb0696379f91042dae8fbe51d06801caadfb12b/traitlets-5.0.5-py3-none-any.whl\r\ntransformers @ file:///home/void/.cache/pypoetry/artifacts/14/d5/c1/4c5fd5e061cbc24684e1d396c3b1e6597e29f2b9ab1294b856f93f7035/transformers-4.2.2-py3-none-any.whl\r\ntyped-ast @ file:///home/void/.cache/pypoetry/artifacts/7d/97/79/f9eecff289044d0c21f1a65724cabcb6f00068e17f1cb5d16154d73a6a/typed_ast-1.4.2-cp38-cp38-manylinux1_x86_64.whl\r\ntyping-extensions @ file:///home/void/.cache/pypoetry/artifacts/ac/8f/3a/97dfae6ca13a6e156f19a5e8aa95fc250129d7e5e6cd0f7c76a1d45b4f/typing_extensions-3.7.4.3-py3-none-any.whl\r\nurllib3 @ file:///home/void/.cache/pypoetry/artifacts/96/0a/4c/8762c25f99b3c4f2118ea3d1999202c730ac5141ce379adc90469d265a/urllib3-1.26.2-py2.py3-none-any.whl\r\nwasabi @ file:///home/void/.cache/pypoetry/artifacts/42/4a/9d/f75bd98be0123c02fb2a2dbb95d920914b644aced2fc781e2e4111685d/wasabi-0.8.2-py3-none-any.whl\r\nwcwidth @ file:///home/void/.cache/pypoetry/artifacts/36/68/e2/7232f431072d5e8aeec124120b9a1d095d45da10311d271fac10982473/wcwidth-0.2.5-py2.py3-none-any.whl\r\nwebencodings @ file:///home/void/.cache/pypoetry/artifacts/60/1e/b4/eff9915b6506bb01a5ad61dfae3fa4f0302be9e2ad45eaccc833925b95/webencodings-0.5.1-py2.py3-none-any.whl\r\nwemake-python-styleguide @ file:///home/void/.cache/pypoetry/artifacts/c6/77/cd/c271dd6015ac40fc5bd5444626301783611963034f5c3a0c2a621106ea/wemake_python_styleguide-0.14.1-py3-none-any.whl\r\nwidgetsnbextension @ file:///home/void/.cache/pypoetry/artifacts/4f/c4/8c/95c9c932a9649e98240304b336a4c725419ee2fd517897c94b817722d6/widgetsnbextension-3.5.1-py2.py3-none-any.whl\r\nword2number @ file:///home/void/.cache/pypoetry/artifacts/f1/a2/d9/65e48a223ce6054ccc45f9ba049ee4ce8b8000656ddebb233642b52225/word2number-1.1.zip\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\nRun the BART example from allennlp-models. Get the 'predicted_tokens' from model outputs during inference.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4977/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4977/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4973", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4973/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4973/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4973/events", "html_url": "https://github.com/allenai/allennlp/issues/4973", "id": 806864662, "node_id": "MDU6SXNzdWU4MDY4NjQ2NjI=", "number": 4973, "title": "`allennlp predict` is broken for multitask models", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/16", "html_url": "https://github.com/allenai/allennlp/milestone/16", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/16/labels", "id": 6087040, "node_id": "MDk6TWlsZXN0b25lNjA4NzA0MA==", "number": 16, "title": "2.1", "description": "", "creator": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 22, "state": "closed", "created_at": "2020-11-09T18:44:24Z", "updated_at": "2021-02-25T22:13:18Z", "due_on": "2021-02-26T08:00:00Z", "closed_at": "2021-02-25T22:13:18Z"}, "comments": 0, "created_at": "2021-02-12T00:54:36Z", "updated_at": "2021-02-24T03:15:32Z", "closed_at": "2021-02-24T03:15:32Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "See https://stackoverflow.com/questions/66156046/allennlp-2-0-using-allennlp-predict-with-multitaskdatasetreader-leads-to-runt.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4973/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4973/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4955", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4955/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4955/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4955/events", "html_url": "https://github.com/allenai/allennlp/issues/4955", "id": 799703902, "node_id": "MDU6SXNzdWU3OTk3MDM5MDI=", "number": 4955, "title": "Learning rate scheduler do not work on AllenNLP v2", "user": {"login": "bratao", "id": 1090152, "node_id": "MDQ6VXNlcjEwOTAxNTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1090152?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bratao", "html_url": "https://github.com/bratao", "followers_url": "https://api.github.com/users/bratao/followers", "following_url": "https://api.github.com/users/bratao/following{/other_user}", "gists_url": "https://api.github.com/users/bratao/gists{/gist_id}", "starred_url": "https://api.github.com/users/bratao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bratao/subscriptions", "organizations_url": "https://api.github.com/users/bratao/orgs", "repos_url": "https://api.github.com/users/bratao/repos", "events_url": "https://api.github.com/users/bratao/events{/privacy}", "received_events_url": "https://api.github.com/users/bratao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2021-02-02T21:26:48Z", "updated_at": "2021-02-04T19:21:59Z", "closed_at": "2021-02-04T19:21:59Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hello, I\u00b4m porting my code to the v2 version, and realized that the Learning rate scheduler was not working. \r\n\r\nAfter inspecting the training code, I realized that on def _try_train(self) the variable:\r\n\r\n`this_epoch_val_metric: float = 0.0` never changes it values\r\n\r\nHowever the scheduler API requires a validation metric\r\n\r\n```\r\n# The Scheduler API is agnostic to whether your schedule requires a validation metric -\r\n            # if it doesn't, the validation metric passed here is ignored.\r\n            if self._learning_rate_scheduler:\r\n                self._learning_rate_scheduler.step(this_epoch_val_metric)\r\n            if self._momentum_scheduler:\r\n                self._momentum_scheduler.step(this_epoch_val_metric)\r\n```\r\n\r\nI guess it is related to _metric_tracker change, that now receives a list of metrics. But I guess @dirkgr would solve it more elegantly as he was the designer of the improved metric tracker", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4955/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4955/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4949", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4949/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4949/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4949/events", "html_url": "https://github.com/allenai/allennlp/issues/4949", "id": 798376278, "node_id": "MDU6SXNzdWU3OTgzNzYyNzg=", "number": 4949, "title": "Unexpected keyword arguments with textual entailment", "user": {"login": "jackcrane", "id": 45675751, "node_id": "MDQ6VXNlcjQ1Njc1NzUx", "avatar_url": "https://avatars.githubusercontent.com/u/45675751?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jackcrane", "html_url": "https://github.com/jackcrane", "followers_url": "https://api.github.com/users/jackcrane/followers", "following_url": "https://api.github.com/users/jackcrane/following{/other_user}", "gists_url": "https://api.github.com/users/jackcrane/gists{/gist_id}", "starred_url": "https://api.github.com/users/jackcrane/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jackcrane/subscriptions", "organizations_url": "https://api.github.com/users/jackcrane/orgs", "repos_url": "https://api.github.com/users/jackcrane/repos", "events_url": "https://api.github.com/users/jackcrane/events{/privacy}", "received_events_url": "https://api.github.com/users/jackcrane/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2021-02-01T13:58:03Z", "updated_at": "2021-04-02T17:06:31Z", "closed_at": "2021-04-02T17:06:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "Following the code sample at https://demo.allennlp.org/textual-entailment, I stumbled across an issue (discussed in #4192 ), but has not been solved:\r\n```python\r\npip install allennlp==1.0.0 allennlp-models==1.0.0\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.tagging\r\n\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/snli-roberta-2020-07-29.tar.gz\")\r\n\r\npredictor.predict(\r\n    premise=\"Two women are wandering along the shore drinking iced tea.\",\r\n    hypothesis=\"Two women are sitting on a blanket near some rocks talking about politics.\"\r\n)\r\n```\r\nAnd it returns an error:\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-33-9b5a14a8a794> in <module>()\r\n      1 predictor.predict(\r\n      2     premise=\"Two women are wandering along the shore drinking iced tea.\",\r\n----> 3     hypothesis=\"Two women are sitting on a blanket near some rocks talking about politics.\"\r\n      4 )\r\n\r\nTypeError: predict() got an unexpected keyword argument 'premise'\r\n```\r\nIt should just return the values.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4949/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4949/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4938", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4938/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4938/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4938/events", "html_url": "https://github.com/allenai/allennlp/issues/4938", "id": 796020797, "node_id": "MDU6SXNzdWU3OTYwMjA3OTc=", "number": 4938, "title": "Demo pages don't scroll right", "user": {"login": "lenyabloko", "id": 55606, "node_id": "MDQ6VXNlcjU1NjA2", "avatar_url": "https://avatars.githubusercontent.com/u/55606?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lenyabloko", "html_url": "https://github.com/lenyabloko", "followers_url": "https://api.github.com/users/lenyabloko/followers", "following_url": "https://api.github.com/users/lenyabloko/following{/other_user}", "gists_url": "https://api.github.com/users/lenyabloko/gists{/gist_id}", "starred_url": "https://api.github.com/users/lenyabloko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lenyabloko/subscriptions", "organizations_url": "https://api.github.com/users/lenyabloko/orgs", "repos_url": "https://api.github.com/users/lenyabloko/repos", "events_url": "https://api.github.com/users/lenyabloko/events{/privacy}", "received_events_url": "https://api.github.com/users/lenyabloko/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-01-28T13:49:14Z", "updated_at": "2021-02-11T16:40:30Z", "closed_at": "2021-02-11T16:40:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "Since this morning Jan 28, the Demo pages no longer allow to scroll right when overflow", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4938/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4938/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4937", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4937/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4937/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4937/events", "html_url": "https://github.com/allenai/allennlp/issues/4937", "id": 796016732, "node_id": "MDU6SXNzdWU3OTYwMTY3MzI=", "number": 4937, "title": "Empty vocab when use multiprocess dataloader", "user": {"login": "wlhgtc", "id": 16603773, "node_id": "MDQ6VXNlcjE2NjAzNzcz", "avatar_url": "https://avatars.githubusercontent.com/u/16603773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wlhgtc", "html_url": "https://github.com/wlhgtc", "followers_url": "https://api.github.com/users/wlhgtc/followers", "following_url": "https://api.github.com/users/wlhgtc/following{/other_user}", "gists_url": "https://api.github.com/users/wlhgtc/gists{/gist_id}", "starred_url": "https://api.github.com/users/wlhgtc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wlhgtc/subscriptions", "organizations_url": "https://api.github.com/users/wlhgtc/orgs", "repos_url": "https://api.github.com/users/wlhgtc/repos", "events_url": "https://api.github.com/users/wlhgtc/events{/privacy}", "received_events_url": "https://api.github.com/users/wlhgtc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2021-01-28T13:44:20Z", "updated_at": "2021-02-09T05:08:52Z", "closed_at": "2021-02-09T05:08:52Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I use a [BART](https://github.com/allenai/allennlp-models/blob/main/training_config/generation/bart_cnn_dm.jsonnet) like config. And I got a Key Error when convert idx to token, cause I got an empty vocab in [here]( https://github.com/allenai/allennlp-models/blob/main/allennlp_models/generation/models/bart.py#L369).\r\n```\r\nipdb> self.vocab\r\nVocabulary with namespaces:  Non Padded Namespaces: {'*tags', '*labels'}\r\n```\r\nBut when I set `num_workers=0` , all things go well.\r\n```\r\nipdb> self.vocab\r\nVocabulary with namespaces:  tokens, Size: 21130 || Non Padded Namespaces: {'*tags', '*labels'}\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4937/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4937/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4899", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4899/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4899/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4899/events", "html_url": "https://github.com/allenai/allennlp/issues/4899", "id": 779965712, "node_id": "MDU6SXNzdWU3Nzk5NjU3MTI=", "number": 4899, "title": "Coreference Resolutions fails when input passage is \"short\" ", "user": {"login": "gud111", "id": 58678112, "node_id": "MDQ6VXNlcjU4Njc4MTEy", "avatar_url": "https://avatars.githubusercontent.com/u/58678112?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gud111", "html_url": "https://github.com/gud111", "followers_url": "https://api.github.com/users/gud111/followers", "following_url": "https://api.github.com/users/gud111/following{/other_user}", "gists_url": "https://api.github.com/users/gud111/gists{/gist_id}", "starred_url": "https://api.github.com/users/gud111/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gud111/subscriptions", "organizations_url": "https://api.github.com/users/gud111/orgs", "repos_url": "https://api.github.com/users/gud111/repos", "events_url": "https://api.github.com/users/gud111/events{/privacy}", "received_events_url": "https://api.github.com/users/gud111/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2021-01-06T03:46:59Z", "updated_at": "2021-07-09T20:25:23Z", "closed_at": "2021-07-09T20:25:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ ] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [ ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ ] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details> When the input to the coreference resolution is a short 1-2 word texts, it throws and exception and crashes.\r\nIn general, while I understand a two-word passage probably does not need coreference resolution, it probably should \r\njust return empty ?\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n    p = coref_predictor.predict(document=orgdoc)\r\n\r\n  File \"/home/sdas/anaconda3/lib/python3.7/site-packages/allennlp_models/coref/predictors/coref.py\", line 64, in predict\r\n    return self.predict_json({\"document\": document})\r\n\r\n  File \"/home/sdas/anaconda3/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 48, in predict_json\r\n    return self.predict_instance(instance)\r\n\r\n  File \"/home/sdas/anaconda3/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 182, in predict_instance\r\n    outputs = self._model.forward_on_instance(instance)\r\n\r\n  File \"/home/sdas/anaconda3/lib/python3.7/site-packages/allennlp/models/model.py\", line 146, in forward_on_instance\r\n    return self.forward_on_instances([instance])[0]\r\n\r\n  File \"/home/sdas/anaconda3/lib/python3.7/site-packages/allennlp/models/model.py\", line 172, in forward_on_instances\r\n    outputs = self.make_output_human_readable(self(**model_input))\r\n\r\n  File \"/home/sdas/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n\r\n  File \"/home/sdas/anaconda3/lib/python3.7/site-packages/allennlp_models/coref/models/coref.py\", line 221, in forward\r\n    span_mention_scores, span_mask, num_spans_to_keep\r\n\r\n  File \"/home/sdas/anaconda3/lib/python3.7/site-packages/allennlp/nn/util.py\", line 1834, in masked_topk\r\n    fill_value, _ = top_indices.max(dim=1, keepdim=True)\r\n\r\nRuntimeError: cannot perform reduction function max on tensor with no elements because the operation does not have an identity\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\nTry any random text e.g. \"Instant Death\" in the demo API for coreference resolution\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4899/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4899/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4897", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4897/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4897/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4897/events", "html_url": "https://github.com/allenai/allennlp/issues/4897", "id": 778301622, "node_id": "MDU6SXNzdWU3NzgzMDE2MjI=", "number": 4897, "title": "Configure Uptime Robot to check our demo APIs", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/16", "html_url": "https://github.com/allenai/allennlp/milestone/16", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/16/labels", "id": 6087040, "node_id": "MDk6TWlsZXN0b25lNjA4NzA0MA==", "number": 16, "title": "2.1", "description": "", "creator": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 22, "state": "closed", "created_at": "2020-11-09T18:44:24Z", "updated_at": "2021-02-25T22:13:18Z", "due_on": "2021-02-26T08:00:00Z", "closed_at": "2021-02-25T22:13:18Z"}, "comments": 3, "created_at": "2021-01-04T19:13:06Z", "updated_at": "2021-02-22T19:11:41Z", "closed_at": "2021-02-22T19:11:40Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4897/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4897/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4886", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4886/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4886/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4886/events", "html_url": "https://github.com/allenai/allennlp/issues/4886", "id": 773729826, "node_id": "MDU6SXNzdWU3NzM3Mjk4MjY=", "number": 4886, "title": "[Model] The RC model training just hung there", "user": {"login": "gladuo", "id": 5893628, "node_id": "MDQ6VXNlcjU4OTM2Mjg=", "avatar_url": "https://avatars.githubusercontent.com/u/5893628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gladuo", "html_url": "https://github.com/gladuo", "followers_url": "https://api.github.com/users/gladuo/followers", "following_url": "https://api.github.com/users/gladuo/following{/other_user}", "gists_url": "https://api.github.com/users/gladuo/gists{/gist_id}", "starred_url": "https://api.github.com/users/gladuo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gladuo/subscriptions", "organizations_url": "https://api.github.com/users/gladuo/orgs", "repos_url": "https://api.github.com/users/gladuo/repos", "events_url": "https://api.github.com/users/gladuo/events{/privacy}", "received_events_url": "https://api.github.com/users/gladuo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/14", "html_url": "https://github.com/allenai/allennlp/milestone/14", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/14/labels", "id": 5601713, "node_id": "MDk6TWlsZXN0b25lNTYwMTcxMw==", "number": 14, "title": "2.0", "description": "", "creator": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 32, "state": "closed", "created_at": "2020-06-30T17:05:12Z", "updated_at": "2021-02-12T00:43:23Z", "due_on": null, "closed_at": "2021-02-12T00:43:23Z"}, "comments": 8, "created_at": "2020-12-23T12:49:23Z", "updated_at": "2021-01-20T20:59:39Z", "closed_at": "2021-01-20T20:59:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nI use https://github.com/allenai/allennlp-models/tree/master/allennlp_models/rc here, and I met problems when using \"distributed mode\". When an epoch training \"seemly\" ended, and the next epoch is just going to start, the process just hung there, nothing happened for a loooong time until you killed it manually. It is really hard to find what's the problem there.\r\n\r\nBut when you killed it, and recovered it, it just worked well, until the end of epoch, again.\r\n\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4886/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4886/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4876", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4876/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4876/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4876/events", "html_url": "https://github.com/allenai/allennlp/issues/4876", "id": 772252430, "node_id": "MDU6SXNzdWU3NzIyNTI0MzA=", "number": 4876, "title": "Running SRL example is giving me -  Errors in loading state_dict for SrlBert", "user": {"login": "mgiardinelli", "id": 2343785, "node_id": "MDQ6VXNlcjIzNDM3ODU=", "avatar_url": "https://avatars.githubusercontent.com/u/2343785?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mgiardinelli", "html_url": "https://github.com/mgiardinelli", "followers_url": "https://api.github.com/users/mgiardinelli/followers", "following_url": "https://api.github.com/users/mgiardinelli/following{/other_user}", "gists_url": "https://api.github.com/users/mgiardinelli/gists{/gist_id}", "starred_url": "https://api.github.com/users/mgiardinelli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mgiardinelli/subscriptions", "organizations_url": "https://api.github.com/users/mgiardinelli/orgs", "repos_url": "https://api.github.com/users/mgiardinelli/repos", "events_url": "https://api.github.com/users/mgiardinelli/events{/privacy}", "received_events_url": "https://api.github.com/users/mgiardinelli/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-12-21T15:28:24Z", "updated_at": "2020-12-23T15:23:54Z", "closed_at": "2020-12-23T15:23:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [X ] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [ ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ ] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nRunning the SRL example using allennlp 1.0 is giving me an error. \r\nRuntimeError: Error(s) in loading state_dict for SrlBert:\r\n\tUnexpected key(s) in state_dict: \"bert_model.embeddings.position_ids\".\r\n\r\n\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\nRunning the AllenNLP example gives me the error below\r\n```\r\necho '{\"sentence\": \"Did Uriah honestly think he could beat the game in under three hours?\"}' | \\\r\nallennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.11.19.tar.gz -\r\n```\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/user1/dev/Pedestal/srl/demo/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/Users/user1/dev/Pedestal/srl/demo/lib/python3.8/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/Users/user1/dev/Pedestal/srl/demo/lib/python3.8/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/Users/user1/dev/Pedestal/srl/demo/lib/python3.8/site-packages/allennlp/commands/predict.py\", line 197, in _predict\r\n    predictor = _get_predictor(args)\r\n  File \"/Users/user1/dev/Pedestal/srl/demo/lib/python3.8/site-packages/allennlp/commands/predict.py\", line 94, in _get_predictor\r\n    archive = load_archive(\r\n  File \"/Users/user1/dev/Pedestal/srl/demo/lib/python3.8/site-packages/allennlp/models/archival.py\", line 192, in load_archive\r\n    model = Model.load(\r\n  File \"/Users/user1/dev/Pedestal/srl/demo/lib/python3.8/site-packages/allennlp/models/model.py\", line 398, in load\r\n    return model_class._load(config, serialization_dir, weights_file, cuda_device, opt_level)\r\n  File \"/Users/user1/dev/Pedestal/srl/demo/lib/python3.8/site-packages/allennlp/models/model.py\", line 337, in _load\r\n    model.load_state_dict(model_state)\r\n  File \"/Users/user1/dev/Pedestal/srl/demo/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 846, in load_state_dict\r\n    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\r\nRuntimeError: Error(s) in loading state_dict for SrlBert:\r\n\tUnexpected key(s) in state_dict: \"bert_model.embeddings.position_ids\".\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Mac Catalina 10.15.7\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:3.8.6\r\nPIP Version: 20.2.1\r\n\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==1.0.0\r\nallennlp-models==1.0.0\r\nattrs==20.3.0\r\nblis==0.4.1\r\nboto3==1.16.40\r\nbotocore==1.19.40\r\ncatalogue==1.0.0\r\ncertifi==2020.12.5\r\nchardet==4.0.0\r\nclick==7.1.2\r\nconllu==3.0\r\ncymem==2.0.5\r\nfilelock==3.0.12\r\nfuture==0.18.2\r\nh5py==3.1.0\r\nidna==2.10\r\niniconfig==1.1.1\r\njmespath==0.10.0\r\njoblib==1.0.0\r\njsonnet==0.17.0\r\njsonpickle==1.4.2\r\nmurmurhash==1.0.5\r\nnltk==3.5\r\nnumpy==1.19.4\r\noverrides==3.0.0\r\npackaging==20.8\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.5\r\nprotobuf==3.14.0\r\npy==1.10.0\r\npy-rouge==1.1\r\npyparsing==2.4.7\r\npytest==6.2.1\r\npython-dateutil==2.8.1\r\nrake-nltk==1.0.4\r\nregex==2020.11.13\r\nrequests==2.25.1\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.2\r\nscipy==1.5.4\r\nsentencepiece==0.1.94\r\nsix==1.15.0\r\nspacy==2.2.4\r\nsrsly==1.0.5\r\ntensorboardX==2.1\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.7.0\r\ntoml==0.10.2\r\ntorch==1.5.1\r\ntqdm==4.54.1\r\ntransformers==2.11.0\r\nurllib3==1.26.2\r\nwasabi==0.8.0\r\nword2number==1.1\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\npip install allennlp==1.0.0 allennlp-models==1.0.0\r\n\r\necho '{\"sentence\": \"Did Uriah honestly think he could beat the game in under three hours?\"}' | \\\r\nallennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.11.19.tar.gz -\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4876/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4876/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4875", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4875/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4875/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4875/events", "html_url": "https://github.com/allenai/allennlp/issues/4875", "id": 772237672, "node_id": "MDU6SXNzdWU3NzIyMzc2NzI=", "number": 4875, "title": "ViLBERT demo not working: vqav2 not in acceptable choices for dataset_reader.type when loading model", "user": {"login": "yonatanbitton", "id": 26148975, "node_id": "MDQ6VXNlcjI2MTQ4OTc1", "avatar_url": "https://avatars.githubusercontent.com/u/26148975?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yonatanbitton", "html_url": "https://github.com/yonatanbitton", "followers_url": "https://api.github.com/users/yonatanbitton/followers", "following_url": "https://api.github.com/users/yonatanbitton/following{/other_user}", "gists_url": "https://api.github.com/users/yonatanbitton/gists{/gist_id}", "starred_url": "https://api.github.com/users/yonatanbitton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yonatanbitton/subscriptions", "organizations_url": "https://api.github.com/users/yonatanbitton/orgs", "repos_url": "https://api.github.com/users/yonatanbitton/repos", "events_url": "https://api.github.com/users/yonatanbitton/events{/privacy}", "received_events_url": "https://api.github.com/users/yonatanbitton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-12-21T15:08:08Z", "updated_at": "2021-01-04T16:57:47Z", "closed_at": "2021-01-04T16:57:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey\r\n\r\nI want to try to ViLBERT demo:\r\nhttps://demo.allennlp.org/visual-question-answering\r\n\r\nI cannot install the repo from the link you provided: \r\n`pip install git+git://github.com/allenai/allennlp.git@0b20f80c1ea700766fe53d2eaf1c28de764f9710`, \r\nbecause I receieve: \r\n```python\r\n(CondaEnv) a483e75eac4c:ChallangerCocoAlign yonatab$ pip install git+git://github.com/allenai/allennlp.git@0b20f80c1ea700766fe53d2eaf1c28de764f9710\r\nCollecting git+git://github.com/allenai/allennlp.git@0b20f80c1ea700766fe53d2eaf1c28de764f9710\r\n  Cloning git://github.com/allenai/allennlp.git (to revision 0b20f80c1ea700766fe53d2eaf1c28de764f9710) to /private/var/folders/sp/0n98h0kn4w7dq4xhl02ljk4n6r2n52/T/pip-req-build-sc0vamlj\r\n  Running command git clone -q git://github.com/allenai/allennlp.git /private/var/folders/sp/0n98h0kn4w7dq4xhl02ljk4n6r2n52/T/pip-req-build-sc0vamlj\r\n  Running command git checkout -q 0b20f80c1ea700766fe53d2eaf1c28de764f9710\r\n  fatal: reference is not a tree: 0b20f80c1ea700766fe53d2eaf1c28de764f9710\r\nERROR: Command errored out with exit status 128: git checkout -q 0b20f80c1ea700766fe53d2eaf1c28de764f9710 Check the logs for full command output.\r\n```\r\n\r\nSo I installed allennlp with pip. \r\n\r\nWhen this command runs: \r\n`predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/vilbert-vqa-2020.10.01.tar.gz\")\r\n`\r\nI receieve the following stacktrace:\r\n\r\nTraceback (most recent call last):\r\n ```python\r\n File \"/Users/yonatab/PycharmProjects/ChallangerCocoAlign/vilbert_allen.py\", line 4, in <module>\r\n    predictor = Predictor.from_path(pred_p)\r\n  File \"/Users/yonatab/opt/anaconda3/envs/CondaEnv/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 354, in from_path\r\n    load_archive(archive_path, cuda_device=cuda_device, overrides=overrides),\r\n  File \"/Users/yonatab/opt/anaconda3/envs/CondaEnv/lib/python3.7/site-packages/allennlp/models/archival.py\", line 206, in load_archive\r\n    config.duplicate(), serialization_dir\r\n  File \"/Users/yonatab/opt/anaconda3/envs/CondaEnv/lib/python3.7/site-packages/allennlp/models/archival.py\", line 232, in _load_dataset_readers\r\n    dataset_reader_params, serialization_dir=serialization_dir\r\n  File \"/Users/yonatab/opt/anaconda3/envs/CondaEnv/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 581, in from_params\r\n    default_to_first_choice=default_to_first_choice,\r\n  File \"/Users/yonatab/opt/anaconda3/envs/CondaEnv/lib/python3.7/site-packages/allennlp/common/params.py\", line 352, in pop_choice\r\n    raise ConfigurationError(message)\r\nallennlp.common.checks.ConfigurationError: vqav2 not in acceptable choices for dataset_reader.type: ['conll2003', 'interleaving', 'sequence_tagging', 'sharded', 'babi', 'text_classification_json']. You should either use the --include-package flag to make sure the correct module is loaded, or use a fully qualified class name in your config file like {\"model\": \"my_module.models.MyModel\"} to have it imported automatically.\r\n```\r\n\r\nI've tried installing allennlp from source, using the **vision** branch: \r\nhttps://github.com/allenai/allennlp/tree/vision\r\n\r\nI've also tried to download the model and loading from local path, getting the same problem.\r\n\r\nHow can I solve it?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4875/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4875/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4855", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4855/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4855/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4855/events", "html_url": "https://github.com/allenai/allennlp/issues/4855", "id": 760368113, "node_id": "MDU6SXNzdWU3NjAzNjgxMTM=", "number": 4855, "title": "Models: missing None check in PrecoReader's text_to_instance method.", "user": {"login": "frcnt", "id": 51097034, "node_id": "MDQ6VXNlcjUxMDk3MDM0", "avatar_url": "https://avatars.githubusercontent.com/u/51097034?v=4", "gravatar_id": "", "url": "https://api.github.com/users/frcnt", "html_url": "https://github.com/frcnt", "followers_url": "https://api.github.com/users/frcnt/followers", "following_url": "https://api.github.com/users/frcnt/following{/other_user}", "gists_url": "https://api.github.com/users/frcnt/gists{/gist_id}", "starred_url": "https://api.github.com/users/frcnt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/frcnt/subscriptions", "organizations_url": "https://api.github.com/users/frcnt/orgs", "repos_url": "https://api.github.com/users/frcnt/repos", "events_url": "https://api.github.com/users/frcnt/events{/privacy}", "received_events_url": "https://api.github.com/users/frcnt/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-12-09T14:16:36Z", "updated_at": "2020-12-10T20:30:06Z", "closed_at": "2020-12-10T20:30:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nHi,\r\n\r\nI think a `None` check is missing at that [line](https://github.com/allenai/allennlp-models/blob/ea1f71c79c329db1b66d9db79f0eaa39d2fd2857/allennlp_models/coref/dataset_readers/preco.py#L94) in `PrecoReader`. \r\nAccording to the function argument list, and the subsequent call to `make_coref_instance`, `clusters` should be allowed to be `None`. \r\n\r\nA typical use-case would be e.g. inference where we don't have any info about the clusters.\r\n\r\n<details>\r\n<summary><b>Python traceback: \r\n</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/fco/coreference/bug.py\", line 15, in <module>\r\n    instance = reader.text_to_instance(sentences)\r\n  File \"/home/fco/anaconda3/envs/coref/lib/python3.8/site-packages/allennlp_models/coref/dataset_readers/preco.py\", line 94, in text_to_instance\r\n    for cluster in gold_clusters:\r\nTypeError: 'NoneType' object is not iterable\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 18.04.3 LTS\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.11.0\r\nallennlp==1.2.0\r\nallennlp-models==1.2.0\r\nattrs==20.3.0\r\nblis==0.4.1\r\nboto3==1.16.14\r\nbotocore==1.19.14\r\ncachetools==4.1.1\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\nchardet==3.0.4\r\nclick==7.1.2\r\nconllu==4.2.1\r\ncymem==2.0.4\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\r\nfilelock==3.0.12\r\nftfy==5.8\r\nfuture==0.18.2\r\ngoogle-auth==1.23.0\r\ngoogle-auth-oauthlib==0.4.2\r\ngrpcio==1.33.2\r\nh5py==3.1.0\r\nidna==2.10\r\nimportlib-metadata==2.0.0\r\niniconfig==1.1.1\r\njmespath==0.10.0\r\njoblib==0.17.0\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\nMarkdown==3.3.3\r\nmurmurhash==1.0.4\r\nnltk==3.5\r\nnumpy==1.19.4\r\noauthlib==3.1.0\r\noverrides==3.1.0\r\npackaging==20.4\r\npandas==1.1.4\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.4\r\nprotobuf==3.13.0\r\npy==1.9.0\r\npy-rouge==1.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npyconll==2.3.3\r\npyparsing==2.4.7\r\nPySocks==1.7.1\r\npytest==6.1.2\r\npython-dateutil==2.8.1\r\npytz==2020.4\r\nregex==2020.10.28\r\nrequests==2.24.0\r\nrequests-oauthlib==1.3.0\r\nrsa==4.6\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.2\r\nscipy==1.5.4\r\nsentencepiece==0.1.94\r\nsix==1.15.0\r\nspacy==2.3.2\r\nsrsly==1.0.3\r\ntensorboard==2.4.0\r\ntensorboard-plugin-wit==1.7.0\r\ntensorboardX==2.1\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.9.2\r\ntoml==0.10.2\r\ntorch==1.7.0\r\ntqdm==4.51.0\r\ntransformers==3.4.0\r\ntweepy==3.9.0\r\ntyping==3.7.4.3\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.25.11\r\nwasabi==0.8.0\r\nwcwidth==0.2.5\r\nWerkzeug==1.0.1\r\nword2number==1.1\r\nzipp==3.4.0\r\n```\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```python\r\nimport spacy\r\nfrom allennlp.data.token_indexers import SingleIdTokenIndexer, TokenCharactersIndexer\r\nfrom allennlp_models.coref import PrecoReader\r\n\r\nmy_text = \"Night you. Subdue creepeth cattle creeping living lesser.\"\r\n\r\nsp = spacy.load(\"en_core_web_sm\")\r\ndoc = sp(my_text)\r\nsentences = [[token.text for token in sent] for sent in doc.sents]\r\n\r\nreader = PrecoReader(max_span_width=10, token_indexers={\"tokens\": SingleIdTokenIndexer(),\r\n                                                        \"token_characters\": TokenCharactersIndexer()})\r\ninstance = reader.text_to_instance(sentences)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4855/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4855/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4848", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4848/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4848/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4848/events", "html_url": "https://github.com/allenai/allennlp/issues/4848", "id": 758163297, "node_id": "MDU6SXNzdWU3NTgxNjMyOTc=", "number": 4848, "title": "Multi-process data loading occasionally hangs when worker does tensor ops on CPU", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2020-12-07T05:13:57Z", "updated_at": "2021-03-17T22:48:49Z", "closed_at": "2021-03-17T22:48:49Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "When using `num_workers > 0` and `start_method = \"fork\"` with the multi-process data loader, there is the potential for dead locks if the dataset reader does any tensor computations on CPU.\r\n\r\nThe solution is to set the `start_method` to \"spawn\" or set the environment variable `OMP_NUM_THREADS` to 1. See https://discuss.pytorch.org/t/pytorch-cpu-hangs-on-nn-linear/17748/4.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4848/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4848/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4847", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4847/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4847/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4847/events", "html_url": "https://github.com/allenai/allennlp/issues/4847", "id": 758058038, "node_id": "MDU6SXNzdWU3NTgwNTgwMzg=", "number": 4847, "title": "Multi-process data loader bug with TensorField (RuntimeError: received 0 items of ancdata)", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-12-07T00:02:33Z", "updated_at": "2022-04-11T09:45:33Z", "closed_at": "2020-12-21T16:47:17Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I discovered this issue while using the new `MultiprocessDataLoader` with `num_workers > 0` and `max_instances_in_memory` set to some high number (1000 in my case) to load batches that are built with instances that contain `TensorField`s.\r\n\r\n```\r\n  ...\r\n  File \"/home/epwalsh/AllenAI/allennlp/allennlp/data/data_loaders/multi_process_data_loader.py\", line 236, in __iter__\r\n    yield from self._iter_batches()\r\n  File \"/home/epwalsh/AllenAI/allennlp/allennlp/data/data_loaders/multi_process_data_loader.py\", line 421, in _iter_batches\r\n    raise e\r\nRuntimeError: received 0 items of ancdata\r\n```\r\n\r\n\r\nThe issue is stems from the fact that tensors are passed between processes using shared memory, but some systems (like the one I was on) may have strict limits on shared memory by default. So if you pile too many tensors into shared memory by having `max_instances_in_memory` too high, you're going to run into this. https://github.com/pytorch/pytorch/issues/973#issuecomment-291287925.\r\n\r\n**Luckily the solution is simple:** either decrease `max_instances_in_memory` (bringing it down to 100 worked in my case), or increase the shared memory available to your training process.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4847/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4847/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4839", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4839/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4839/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4839/events", "html_url": "https://github.com/allenai/allennlp/issues/4839", "id": 757223772, "node_id": "MDU6SXNzdWU3NTcyMjM3NzI=", "number": 4839, "title": "Superfluous warning when extending the vocab in the `Embedding`", "user": {"login": "dcfidalgo", "id": 15979778, "node_id": "MDQ6VXNlcjE1OTc5Nzc4", "avatar_url": "https://avatars.githubusercontent.com/u/15979778?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dcfidalgo", "html_url": "https://github.com/dcfidalgo", "followers_url": "https://api.github.com/users/dcfidalgo/followers", "following_url": "https://api.github.com/users/dcfidalgo/following{/other_user}", "gists_url": "https://api.github.com/users/dcfidalgo/gists{/gist_id}", "starred_url": "https://api.github.com/users/dcfidalgo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dcfidalgo/subscriptions", "organizations_url": "https://api.github.com/users/dcfidalgo/orgs", "repos_url": "https://api.github.com/users/dcfidalgo/repos", "events_url": "https://api.github.com/users/dcfidalgo/events{/privacy}", "received_events_url": "https://api.github.com/users/dcfidalgo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "02b8d1", "default": false, "description": ""}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-12-04T16:17:48Z", "updated_at": "2020-12-16T02:09:45Z", "closed_at": "2020-12-16T02:09:45Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nIf one creates an `allennlp.modules.token_embedders.embedding.Embedding` without a `pretrained_file`, you still get a warning when extending the vocab that no `pretrained_file` is found. I would expect the warning only to trigger if one specified a `pretrained_file` when creating the `Embedding` or when an `extension_pretrained_file` is passed on to `Embedding.extend_vocab`. \r\n\r\nI would be more than happy to provide a PR if you think this is actually and issue and should be addressed.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nWARNING:root:Embedding at model_path, None cannot locate the pretrained_file.  If you are fine-tuning and want to use using pretrained_file for embedding extension, please pass the mapping by --embedding-sources argument.\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 20.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.0\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nattrs==20.3.0\r\nblis==0.7.3\r\nboto3==1.16.29\r\nbotocore==1.19.29\r\ncatalogue==1.0.0\r\ncertifi==2020.11.8\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncymem==2.0.4\r\ndataclasses==0.6\r\nfilelock==3.0.12\r\nfuture==0.18.2\r\nh5py==3.1.0\r\nidna==2.10\r\niniconfig==1.1.1\r\njmespath==0.10.0\r\njoblib==0.17.0\r\njsonnet==0.17.0\r\njsonpickle==1.4.2\r\nmurmurhash==1.0.4\r\nnltk==3.5\r\nnumpy==1.19.4\r\noverrides==3.1.0\r\npackaging==20.7\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.4\r\nprotobuf==3.14.0\r\npy==1.9.0\r\npyparsing==2.4.7\r\npytest==6.1.2\r\npython-dateutil==2.8.1\r\nregex==2020.11.13\r\nrequests==2.25.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.2\r\nscipy==1.5.4\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.3.4\r\nsrsly==1.0.4\r\ntensorboardX==2.1\r\nthinc==7.4.3\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.9.3\r\ntoml==0.10.2\r\ntorch==1.7.0\r\ntqdm==4.54.0\r\ntransformers==3.5.1\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.26.2\r\nwasabi==0.8.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```python\r\nfrom allennlp.data import Token, Instance, Vocabulary\r\nfrom allennlp.data.fields import TextField\r\nfrom allennlp.data.token_indexers import SingleIdTokenIndexer\r\nfrom allennlp.modules.token_embedders.embedding import Embedding\r\n\r\ninstance = Instance({\"token\": TextField([Token(\"test\")], {\"tokens\": SingleIdTokenIndexer()})})\r\nvocab = Vocabulary.from_instances([instance])\r\n\r\ninstance2 = Instance({\"token\": TextField([Token(\"this\")], {\"tokens\": SingleIdTokenIndexer()})})\r\nvocab2 = Vocabulary.from_instances([instance, instance2])\r\n\r\nembedder = Embedding(1, vocab=vocab)\r\nembedder.extend_vocab(vocab2)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4839/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4839/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4826", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4826/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4826/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4826/events", "html_url": "https://github.com/allenai/allennlp/issues/4826", "id": 753586553, "node_id": "MDU6SXNzdWU3NTM1ODY1NTM=", "number": 4826, "title": "TrackEpochCallback is not an EpochCallback", "user": {"login": "mahnerak", "id": 1367529, "node_id": "MDQ6VXNlcjEzNjc1Mjk=", "avatar_url": "https://avatars.githubusercontent.com/u/1367529?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mahnerak", "html_url": "https://github.com/mahnerak", "followers_url": "https://api.github.com/users/mahnerak/followers", "following_url": "https://api.github.com/users/mahnerak/following{/other_user}", "gists_url": "https://api.github.com/users/mahnerak/gists{/gist_id}", "starred_url": "https://api.github.com/users/mahnerak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mahnerak/subscriptions", "organizations_url": "https://api.github.com/users/mahnerak/orgs", "repos_url": "https://api.github.com/users/mahnerak/repos", "events_url": "https://api.github.com/users/mahnerak/events{/privacy}", "received_events_url": "https://api.github.com/users/mahnerak/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 15, "created_at": "2020-11-30T15:44:24Z", "updated_at": "2021-01-18T18:48:00Z", "closed_at": "2021-01-14T17:32:47Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Is there any reason why `TrackEpochCallback` should not inherit from `EpochCallback`?\r\nhttps://github.com/allenai/allennlp/blob/5b30658514a00e11000e648fec23be11a998bd92/allennlp/training/trainer.py#L179-L188", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4826/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4826/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4825", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4825/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4825/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4825/events", "html_url": "https://github.com/allenai/allennlp/issues/4825", "id": 753565198, "node_id": "MDU6SXNzdWU3NTM1NjUxOTg=", "number": 4825, "title": "ShardedDatasetReader doesn't inherit lazy from base reader", "user": {"login": "aleSuglia", "id": 1479733, "node_id": "MDQ6VXNlcjE0Nzk3MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1479733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aleSuglia", "html_url": "https://github.com/aleSuglia", "followers_url": "https://api.github.com/users/aleSuglia/followers", "following_url": "https://api.github.com/users/aleSuglia/following{/other_user}", "gists_url": "https://api.github.com/users/aleSuglia/gists{/gist_id}", "starred_url": "https://api.github.com/users/aleSuglia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aleSuglia/subscriptions", "organizations_url": "https://api.github.com/users/aleSuglia/orgs", "repos_url": "https://api.github.com/users/aleSuglia/repos", "events_url": "https://api.github.com/users/aleSuglia/events{/privacy}", "received_events_url": "https://api.github.com/users/aleSuglia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-11-30T15:18:25Z", "updated_at": "2020-12-04T17:27:21Z", "closed_at": "2020-12-04T17:27:21Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Checklist\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nCurrently the `ShardedDatasetReader` doesn't inherit the `lazy` property from the `base_reader`. Therefore, the dataset reader becomes not `lazy` anymore. \r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n```\r\nProcessed killed for insufficient RAM\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: OS X\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.8.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==1.2.2\r\nattrs==20.3.0\r\nbeautifulsoup4 @ file:///tmp/build/80754af9/beautifulsoup4_1601924105527/work\r\nblis==0.7.3\r\nboto3==1.16.25\r\nbotocore==1.19.25\r\ncatalogue==1.0.0\r\ncertifi==2020.11.8\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncymem==2.0.4\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\r\nfilelock==3.0.12\r\nfuture==0.18.2\r\nh5py==3.1.0\r\nidna==2.10\r\nimportlib-metadata==3.1.0\r\niniconfig==1.1.1\r\njmespath==0.10.0\r\njoblib==0.17.0\r\njsonlines==1.2.0\r\njsonnet==0.17.0\r\njsonpickle==1.4.1\r\nlxml==4.6.2\r\nmurmurhash==1.0.4\r\nnltk==3.5\r\nnumpy==1.19.4\r\noverrides==3.1.0\r\npackaging==20.4\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.4\r\nprotobuf==3.14.0\r\npy==1.9.0\r\npyparsing==2.4.7\r\npytest==6.1.2\r\npython-dateutil==2.8.1\r\nregex==2020.11.13\r\nrequests==2.25.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.2\r\nscipy==1.5.4\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nsoupsieve==2.0.1\r\nspacy==2.3.4\r\nsrsly==1.0.4\r\ntensorboardX==2.1\r\nthinc==7.4.3\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.9.3\r\ntoml==0.10.2\r\ntorch==1.7.0\r\ntqdm==4.54.0\r\ntransformers==3.5.1\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.26.2\r\nwasabi==0.8.0\r\nzipp==3.4.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\nFor any model training using a `ShardedDatasetReader` this configuration file will not set the `lazy` property for it:\r\n```\r\n \"dataset_reader\" : {\r\n        \"type\": \"sharded\",\r\n        \"base_reader\": {\r\n            \"type\": \"wiki_er\",\r\n            \"token_indexers\": {\r\n                \"tokens\": {\r\n                    \"type\": \"pretrained_transformer_mismatched\",\r\n                    \"model_name\": model_name\r\n                }\r\n            },\r\n            \"lazy\": true\r\n        }\r\n    }\r\n```\r\nwhile this one will work:\r\n```\r\n \"dataset_reader\" : {\r\n        \"type\": \"sharded\",\r\n        \"base_reader\": {\r\n            \"type\": \"wiki_er\",\r\n            \"token_indexers\": {\r\n                \"tokens\": {\r\n                    \"type\": \"pretrained_transformer_mismatched\",\r\n                    \"model_name\": model_name\r\n                }\r\n            }\r\n        },\r\n        \"lazy\": true\r\n    }\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nI believe that a fix for this issue can be implemented by following this rule: if the `ShardedDatasetReader` sets the `lazy` parameter, then use it. If it doesn't then inherit from `base_reader`.\r\n\r\nIn general, looks like this is true also for other `DatasetReader` parameters like `max_instances`.\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4825/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 1, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4825/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4819", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4819/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4819/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4819/events", "html_url": "https://github.com/allenai/allennlp/issues/4819", "id": 751002309, "node_id": "MDU6SXNzdWU3NTEwMDIzMDk=", "number": 4819, "title": "Rename token.py to avoid bugs in certain Python versions", "user": {"login": "tmcclintock", "id": 10226392, "node_id": "MDQ6VXNlcjEwMjI2Mzky", "avatar_url": "https://avatars.githubusercontent.com/u/10226392?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tmcclintock", "html_url": "https://github.com/tmcclintock", "followers_url": "https://api.github.com/users/tmcclintock/followers", "following_url": "https://api.github.com/users/tmcclintock/following{/other_user}", "gists_url": "https://api.github.com/users/tmcclintock/gists{/gist_id}", "starred_url": "https://api.github.com/users/tmcclintock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tmcclintock/subscriptions", "organizations_url": "https://api.github.com/users/tmcclintock/orgs", "repos_url": "https://api.github.com/users/tmcclintock/repos", "events_url": "https://api.github.com/users/tmcclintock/events{/privacy}", "received_events_url": "https://api.github.com/users/tmcclintock/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2020-11-25T17:31:11Z", "updated_at": "2020-12-05T06:53:32Z", "closed_at": "2020-12-05T06:48:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Checklist\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nIn certain version of Python (verified with 3.7.8) attempting to import from the file `token.py` causes a circular import because there is an identically named file in the dependency tree of the `dataclasses` module.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"token.py\", line 1, in <module>\r\n    from dataclasses import dataclass\r\n  File \"/opt/anaconda3/envs/allentest/lib/python3.7/dataclasses.py\", line 5, in <module>\r\n    import inspect\r\n  File \"/opt/anaconda3/envs/allentest/lib/python3.7/inspect.py\", line 40, in <module>\r\n    import linecache\r\n  File \"/opt/anaconda3/envs/allentest/lib/python3.7/linecache.py\", line 11, in <module>\r\n    import tokenize\r\n  File \"/opt/anaconda3/envs/allentest/lib/python3.7/tokenize.py\", line 35, in <module>\r\n    from token import *\r\n  File \"/Users/tmcclintock/Github/allennlp/allennlp/data/tokenizers/token.py\", line 1, in <module>\r\n    from dataclasses import dataclass\r\nImportError: cannot import name 'dataclass' from 'dataclasses' (/opt/anaconda3/envs/allentest/lib/python3.7/dataclasses.py)\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\nI was not able to find duplicate issue in the open or closed issues or in the current PRs.\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: OSX\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.8\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\ncertifi==2020.11.8\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\nBegin by creating a fresh environment, cloning, and changing into the relevant directory:\r\n```bash\r\nconda create --name allentest python=3.7.8\r\nconda activate allentest\r\ngit clone https://github.com/allenai/allennlp.git\r\ncd allennlp/allennlp/data/tokenizers/\r\n```\r\n\r\nAttempt to run the file in question:\r\n```bash\r\npython token.py\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n## Proposed solution\r\n\r\nThe fix is easy, in that you can just rename the file so there is no collision `mv token.py token_class.py` and update import statements.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4819/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4819/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4818", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4818/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4818/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4818/events", "html_url": "https://github.com/allenai/allennlp/issues/4818", "id": 750254522, "node_id": "MDU6SXNzdWU3NTAyNTQ1MjI=", "number": 4818, "title": "SRL bert-base-srl predictor basic to be \u201cis\u201d verb examples return no results", "user": {"login": "KTRosenberg", "id": 16908296, "node_id": "MDQ6VXNlcjE2OTA4Mjk2", "avatar_url": "https://avatars.githubusercontent.com/u/16908296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KTRosenberg", "html_url": "https://github.com/KTRosenberg", "followers_url": "https://api.github.com/users/KTRosenberg/followers", "following_url": "https://api.github.com/users/KTRosenberg/following{/other_user}", "gists_url": "https://api.github.com/users/KTRosenberg/gists{/gist_id}", "starred_url": "https://api.github.com/users/KTRosenberg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KTRosenberg/subscriptions", "organizations_url": "https://api.github.com/users/KTRosenberg/orgs", "repos_url": "https://api.github.com/users/KTRosenberg/repos", "events_url": "https://api.github.com/users/KTRosenberg/events{/privacy}", "received_events_url": "https://api.github.com/users/KTRosenberg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "02b8d1", "default": false, "description": ""}], "state": "closed", "locked": true, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 21, "created_at": "2020-11-25T01:41:20Z", "updated_at": "2020-12-09T18:38:32Z", "closed_at": "2020-12-09T18:38:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nSimple sentences involving the verb, \"is\" return no results for semantic role labeling, either via the demo page or by using AllenNLP in Python3.8 with the latest November Bert base model.\r\n\r\nFor example, \"I am here.\" returns nothing.\r\n\r\nIn short:\r\n- Instances of simple \"A is B\" sentences don't return any results.\r\n- I believe there should be some sort of output, as other SRL engines do return results.\r\n- The same goes for \"I am.\" The expected result is an ARG1 for \"I\" and a predicate of \"am.\"\r\n\r\nThis used to work with an earlier version:\r\n```\r\nallennlp==1.0.0\r\nallennlp-models==1.0.0\r\n```\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: macOS 10.15.7 (Catalina)\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.6 (via home-brew)\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==1.2.2\r\nallennlp-models==1.2.2\r\nattrs==20.3.0\r\nblis==0.4.1\r\nboto3==1.16.24\r\nbotocore==1.19.24\r\ncatalogue==1.0.0\r\ncertifi==2020.11.8\r\nchardet==3.0.4\r\nclick==7.1.2\r\nconllu==4.2.1\r\ncymem==2.0.4\r\ndataclasses==0.6\r\nfilelock==3.0.12\r\nftfy==5.8\r\nfuture==0.18.2\r\nh5py==3.1.0\r\nidna==2.10\r\nimportlib-metadata==3.1.0\r\niniconfig==1.1.1\r\njmespath==0.10.0\r\njoblib==0.17.0\r\njsonnet==0.17.0\r\njsonpickle==1.4.1\r\nmurmurhash==1.0.4\r\nnltk==3.5\r\nnumpy==1.19.4\r\noverrides==3.1.0\r\npackaging==20.4\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.4\r\nprotobuf==3.14.0\r\npy==1.9.0\r\npy-rouge==1.1\r\npyparsing==2.4.7\r\npytest==6.1.2\r\npython-dateutil==2.8.1\r\nregex==2020.11.13\r\nrequests==2.25.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.2\r\nscipy==1.5.4\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.3.2\r\nsrsly==1.0.4\r\ntensorboardX==2.1\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.9.3\r\ntoml==0.10.2\r\ntorch==1.7.0\r\ntqdm==4.53.0\r\ntransformers==3.5.1\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.26.2\r\nwasabi==0.8.0\r\nwcwidth==0.2.5\r\nword2number==1.1\r\nzipp==3.4.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n[Visit the demo website for SRL](https://demo.allennlp.org/semantic-role-labeling)\r\n<details>\r\n<summary><b>Example:</b></summary>\r\n\r\nEnter almost any variation of:\r\n\"I am here.\"\r\n\"We are people.\"\r\n\"I am.\"\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n#  https://demo.allennlp.org/semantic-role-labeling/MjU3NDk3NA==\r\n\r\n# or\r\nfrom allennlp.predictors.predictor import Predictor\r\n\r\nallen_predictor_srl = Predictor.from_path(\r\n    \"./models/bert-base-srl-2020.11.19.tar.gz\"\r\n)\r\n\r\noutput = allen_predictor_srl.predict(sentence=\"I am here.\")\r\nprint(output)\r\n\r\n# observe nothing\r\n```\r\n\r\nMy install script:\r\n```\r\npython3 -m venv env\r\nsource ./env/bin/activate\r\n\r\n\r\npip3 install --upgrade pip\r\n\r\npip3 install -U --no-cache-dir\r\n\r\npip3 install -U allennlp allennlp-models --no-cache-dir\r\n\r\npython3 -m spacy download en_core_web_lg    --no-cache-dir\r\npython3 -m spacy download en_core_web_sm    --no-cache-dir\r\npython3 -m spacy download en_vectors_web_lg --no-cache-dir\r\npython3 -m spacy download de_core_news_md   --no-cache-dir\r\n```\r\n</p>\r\n</details>\r\n\r\nUPDATE: I tried downgrading to v1.0 and am still experiencing the issue. I tried installing from source. Getting rid of all other dependencies to see what would happen. In addition to the issue I'm describing, results are generally worse for subordinate clauses and the like. It's unclear whether this is an allennlp bug or a bug related to some dependency. The online demo has similar issues.\r\n\r\nUPDATE2: I tried on a completely different machine (Linux with NVIDIA GPUs) using pip -- same result. Could something be wrong with the toolchain/dependencies?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4818/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4818/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4813", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4813/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4813/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4813/events", "html_url": "https://github.com/allenai/allennlp/issues/4813", "id": 748594694, "node_id": "MDU6SXNzdWU3NDg1OTQ2OTQ=", "number": 4813, "title": "run coreference resolution demo error.", "user": {"login": "baiziyuandyufei", "id": 20787650, "node_id": "MDQ6VXNlcjIwNzg3NjUw", "avatar_url": "https://avatars.githubusercontent.com/u/20787650?v=4", "gravatar_id": "", "url": "https://api.github.com/users/baiziyuandyufei", "html_url": "https://github.com/baiziyuandyufei", "followers_url": "https://api.github.com/users/baiziyuandyufei/followers", "following_url": "https://api.github.com/users/baiziyuandyufei/following{/other_user}", "gists_url": "https://api.github.com/users/baiziyuandyufei/gists{/gist_id}", "starred_url": "https://api.github.com/users/baiziyuandyufei/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/baiziyuandyufei/subscriptions", "organizations_url": "https://api.github.com/users/baiziyuandyufei/orgs", "repos_url": "https://api.github.com/users/baiziyuandyufei/repos", "events_url": "https://api.github.com/users/baiziyuandyufei/events{/privacy}", "received_events_url": "https://api.github.com/users/baiziyuandyufei/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-11-23T08:38:13Z", "updated_at": "2020-11-24T06:52:12Z", "closed_at": "2020-11-24T03:44:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n@ZhaofengWu when I run the demo [Coreference Resolution Demo](https://demo.allennlp.org/coreference-resolution/MjU2NjExMA== ), I got the error below.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"coref-demo.py\", line 4, in <module>\r\n    predictor = Predictor.from_path(\"./coref-spanbert-large.tar.gz\")\r\n  File \"/Users/username/git_code/2020-coref/allennlp/allennlp/predictors/predictor.py\", line 323, in from_path\r\n    load_archive(archive_path, cuda_device=cuda_device, overrides=overrides),\r\n  File \"/Users/username/git_code/2020-coref/allennlp/allennlp/models/archival.py\", line 202, in load_archive\r\n    config = Params.from_file(os.path.join(serialization_dir, CONFIG_NAME), overrides)\r\n  File \"/Users/username/git_code/2020-coref/allennlp/allennlp/common/params.py\", line 485, in from_file\r\n    params_file = cached_path(params_file)\r\n  File \"/Users/username/git_code/2020-coref/allennlp/allennlp/common/file_utils.py\", line 202, in cached_path\r\n    raise FileNotFoundError(f\"file {url_or_filename} not found\")\r\nFileNotFoundError: file /var/folders/_v/t8wzr_fj2gj83msgwd4t179c0000gn/T/tmp1f1z5a6w/config.json not found\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: OS X\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n% pip freeze\r\n-e git+https://github.com/allenai/allennlp.git@f353c6ce326affc07a7ea359611c22b103934144#egg=allennlp\r\nallennlp-models==1.2.2\r\nappdirs==1.4.4\r\nattrs==20.3.0\r\nblack==20.8b1\r\nbleach==3.2.1\r\nblis==0.4.1\r\nboto3==1.16.23\r\nbotocore==1.19.23\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncodecov==2.1.10\r\ncolorama==0.4.4\r\nconllu==4.2.1\r\ncoverage==5.3\r\ncycler==0.10.0\r\ncymem==2.0.4\r\ndataclasses==0.6\r\ndocutils==0.16\r\nfilelock==3.0.12\r\nflake8==3.8.4\r\nflaky==3.7.0\r\nftfy==5.8\r\nfuture==0.18.2\r\nh5py==3.1.0\r\nidna==2.10\r\nimportlib-metadata==3.0.0\r\niniconfig==1.1.1\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.17.0\r\njsonnet==0.17.0\r\njsonpickle==1.4.1\r\nkeyring==21.5.0\r\nkiwisolver==1.3.1\r\nlivereload==2.6.3\r\nlunr==0.5.8\r\nMarkdown==3.3.3\r\nmarkdown-include==0.6.0\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.3.3\r\nmccabe==0.6.1\r\nmkdocs==1.1.2\r\nmkdocs-material==6.1.6\r\nmkdocs-material-extensions==1.0.1\r\nmurmurhash==1.0.4\r\nmypy==0.790\r\nmypy-extensions==0.4.3\r\nnltk==3.5\r\nnr.collections==0.0.1\r\nnr.databind.core==0.0.16\r\nnr.databind.json==0.0.13\r\nnr.interface==0.0.3\r\nnr.metaclass==0.0.5\r\nnr.parsing.date==0.4.2\r\nnr.pylang.utils==0.0.3\r\nnr.stream==0.0.4\r\nnr.utils.re==0.1.0\r\nnumpy==1.19.4\r\noverrides==3.1.0\r\npackaging==20.4\r\npathspec==0.8.1\r\npathtools==0.1.2\r\nPillow==8.0.1\r\npkginfo==1.6.1\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.4\r\nprotobuf==3.14.0\r\npy==1.9.0\r\npy-cpuinfo==7.0.0\r\npy-rouge==1.1\r\npycodestyle==2.6.0\r\npydoc-markdown @ git+https://github.com/NiklasRosenstein/pydoc-markdown.git@f0bf8af1db4f11581c19d206d4ed1ab34b4854c1\r\npyflakes==2.2.0\r\nPygments==2.7.2\r\npymdown-extensions==8.0.1\r\npyparsing==2.4.7\r\npytest==6.1.2\r\npytest-benchmark==3.2.3\r\npytest-cov==2.10.1\r\npython-dateutil==2.8.1\r\nPyYAML==5.3.1\r\nreadme-renderer==28.0\r\nregex==2020.11.13\r\nrequests==2.25.0\r\nrequests-toolbelt==0.9.1\r\nresponses==0.12.1\r\nrfc3986==1.4.0\r\nruamel.yaml==0.16.12\r\nruamel.yaml.clib==0.2.2\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.2\r\nscipy==1.5.4\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.3.2\r\nsrsly==1.0.4\r\ntensorboardX==2.1\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.9.3\r\ntoml==0.10.2\r\ntorch==1.7.0\r\ntornado==6.1\r\ntqdm==4.53.0\r\ntransformers==3.5.1\r\ntwine==3.2.0\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.25.11\r\nwasabi==0.8.0\r\nwatchdog==0.10.4\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nword2number==1.1\r\nzipp==3.4.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.coref\r\n# predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz\")\r\npredictor = Predictor.from_path(\"./coref-spanbert-large.tar.gz\")\r\npredictor.predict(\r\n  document=\"The woman reading a newspaper sat on the bench with her dog.\"\r\n)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4813/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4813/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4810", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4810/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4810/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4810/events", "html_url": "https://github.com/allenai/allennlp/issues/4810", "id": 748264019, "node_id": "MDU6SXNzdWU3NDgyNjQwMTk=", "number": 4810, "title": "GradientDescentTrainer breaks when constructed with validation_data_loader==None and learning_rate_scheduler!=None", "user": {"login": "IINemo", "id": 21058413, "node_id": "MDQ6VXNlcjIxMDU4NDEz", "avatar_url": "https://avatars.githubusercontent.com/u/21058413?v=4", "gravatar_id": "", "url": "https://api.github.com/users/IINemo", "html_url": "https://github.com/IINemo", "followers_url": "https://api.github.com/users/IINemo/followers", "following_url": "https://api.github.com/users/IINemo/following{/other_user}", "gists_url": "https://api.github.com/users/IINemo/gists{/gist_id}", "starred_url": "https://api.github.com/users/IINemo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/IINemo/subscriptions", "organizations_url": "https://api.github.com/users/IINemo/orgs", "repos_url": "https://api.github.com/users/IINemo/repos", "events_url": "https://api.github.com/users/IINemo/events{/privacy}", "received_events_url": "https://api.github.com/users/IINemo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-11-22T15:15:12Z", "updated_at": "2020-11-23T02:34:51Z", "closed_at": "2020-11-23T02:34:51Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nWhen you construct GradientDescentTrainer with validation_data_loader==None and learning_rate_scheduler!=None, the code\r\nbreaks when an update step is performed for learning_rate_scheduler.  This is a typical case for training a Transformer model. \r\n\r\nThis issue appeared since version 1.2.0 and is present now in the master branch.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n```\r\nUnboundLocalErrorTraceback (most recent call last)\r\n<ipython-input-9-513339770b41> in <module>\r\n     46 \r\n     47 try:\r\n---> 48     metrics = trainer.train()\r\n     49 except KeyboardInterrupt:\r\n     50     pass\r\n\r\n/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/allennlp/training/trainer.py in train(self)\r\n    964         \"\"\"\r\n    965         try:\r\n--> 966             return self._try_train()\r\n    967         finally:\r\n    968             # make sure pending events are flushed to disk and files are closed properly\r\n\r\n/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/allennlp/training/trainer.py in _try_train(self)\r\n   1080             # if it doesn't, the validation metric passed here is ignored.\r\n   1081             if self._learning_rate_scheduler:\r\n-> 1082                 self._learning_rate_scheduler.step(this_epoch_val_metric)\r\n   1083             if self._momentum_scheduler:\r\n   1084                 self._momentum_scheduler.step(this_epoch_val_metric)\r\n\r\nUnboundLocalError: local variable 'this_epoch_val_metric' referenced before assignment\r\n```\r\n\r\nThe problem happens because the ```this_epoch_val_metric``` on the line 987 is not initialized.\r\n\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 18.04.3 LTS\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.4\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.8.1\r\nactleto==0.1.0\r\nalabaster==0.7.12\r\nallennlp==1.2.2\r\nallennlp-models==1.1.0\r\nannoy==1.16.2\r\nastor==0.8.0\r\nastroid==2.3.3\r\nastropy==3.2.3\r\natomicwrites==1.3.0\r\nattrs==19.3.0\r\nBabel==2.7.0\r\nbackcall==0.1.0\r\nbleach==3.1.0\r\nblis==0.2.4\r\nbokeh==1.4.0\r\nboto==2.49.0\r\nboto3==1.16.6\r\nbotocore==1.19.6\r\nbpemb==0.3.2\r\ncategory-encoders==2.1.0\r\ncertifi==2019.9.11\r\nchardet==3.0.4\r\nClick==7.0\r\ncloudpickle==1.2.2\r\ncolorama==0.4.1\r\nconfuse==1.0.0\r\nconllu==4.1\r\ncycler==0.10.0\r\ncymem==2.0.3\r\nCython==0.29.14\r\ndask==2.8.0\r\ndecorator==4.4.1\r\ndeeppavlov==0.6.1\r\ndefusedxml==0.6.0\r\nDeprecated==1.2.10\r\ndistributed==2.8.0\r\ndocopt==0.6.2\r\ndocutils==0.15.2\r\neditdistance==0.5.3\r\neli5==0.10.1\r\nen-core-web-sm==2.1.0\r\nentrypoints==0.3\r\nfastcluster==1.1.25\r\nfasttext==0.9.1\r\nfb-re2==1.0.7\r\nfilelock==3.0.12\r\nfitter==1.1.11\r\nflair==0.6.1\r\nflaky==3.6.1\r\nFlask==1.1.1\r\nFlask-Cors==3.0.8\r\nforestci==0.3\r\nfsspec==0.6.0\r\nftfy==5.6\r\nfuture==0.18.2\r\ngast==0.3.2\r\ngdown==3.12.2\r\ngensim==3.8.1\r\ngevent==1.4.0\r\ngitdb2==2.0.6\r\nGitPython==3.0.5\r\ngoogle-pasta==0.1.8\r\ngraphviz==0.13.2\r\ngreenlet==0.4.15\r\ngrpcio==1.25.0\r\ngym==0.15.4\r\nh5py==2.10.0\r\nhdbscan==0.8.23\r\nHeapDict==1.0.1\r\nhtmlmin==0.1.12\r\nhydra-core==0.11.3\r\nhyperopt==0.2.5\r\nidna==2.8\r\nimageio==2.6.1\r\nimagesize==1.1.0\r\nimbalanced-learn==0.5.0\r\nimgaug==0.3.0\r\nimportlib-metadata==0.23\r\nipykernel==5.1.3\r\nipython==7.9.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\nisanlp==0.0.6\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\nJanome==0.4.1\r\njedi==0.15.1\r\nJinja2==2.10.3\r\njmespath==0.9.4\r\njoblib==0.14.0\r\njson5==0.8.5\r\njsonnet==0.14.0\r\njsonpickle==0.9.6\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==5.3.4\r\njupyter-console==6.0.0\r\njupyter-contrib-core==0.3.3\r\njupyter-contrib-nbextensions==0.5.1\r\njupyter-core==4.6.1\r\njupyter-highlight-selected-word==0.2.0\r\njupyter-latex-envs==1.4.6\r\njupyter-nbextensions-configurator==0.4.1\r\njupyterlab==1.2.3\r\njupyterlab-server==1.0.6\r\nKeras==2.3.1\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.0\r\nkeras-vis==0.4.1\r\nkiwisolver==1.1.0\r\nkonoha==4.6.2\r\nlangdetect==1.0.8\r\nlazy-object-proxy==1.4.3\r\nlibact==0.1.3b0\r\nlightgbm==2.3.1\r\nlime==0.1.1.36\r\nline-profiler==2.1.1\r\nllvmlite==0.30.0\r\nlocket==0.2.0\r\nlxml==4.4.1\r\nMarkdown==3.1.1\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.1.1\r\nmccabe==0.6.1\r\nmissingno==0.4.2\r\nmistune==0.8.4\r\nmlxtend==0.17.0\r\nmore-itertools==7.2.0\r\nmpld3==0.3\r\nmsgpack==0.6.2\r\nmunch==2.5.0\r\nmurmurhash==1.0.2\r\nnbconvert==5.6.1\r\nnbformat==4.4.0\r\nnetworkx==2.4\r\nnltk==3.4.5\r\nnmslib==2.0.5\r\nnose==1.3.7\r\nnotebook==6.0.2\r\nnumba==0.46.0\r\nnumexpr==2.7.0\r\nnumpy==1.17.4\r\nnumpydoc==0.9.1\r\nomegaconf==1.4.1\r\nopencv-python==4.1.1.26\r\nopencv-python-headless==4.1.1.26\r\noverrides==3.1.0\r\npackaging==19.2\r\npandas==0.25.3\r\npandas-profiling==2.3.0\r\npandocfilters==1.4.2\r\nparsimonious==0.8.1\r\nparso==0.5.1\r\npartd==1.0.0\r\npatool==1.12\r\npatsy==0.5.1\r\npexpect==4.7.0\r\nphik==0.9.8\r\npickleshare==0.7.5\r\nPillow==6.2.1\r\nplac==0.9.6\r\nplotly==4.3.0\r\npluggy==0.13.0\r\npprofile==2.0.2\r\npreshed==2.0.1\r\nprogressbar==2.5\r\nprometheus-client==0.7.1\r\nprompt-toolkit==2.0.10\r\nprotobuf==3.10.0\r\npsutil==5.6.5\r\nptyprocess==0.6.0\r\npy==1.8.0\r\npy-cpuinfo==5.0.0\r\npy-rouge==1.1\r\npybind11==2.4.dev4\r\npydot==1.4.1\r\npyglet==1.3.2\r\nPygments==2.4.2\r\npylint==2.4.4\r\npymystem3==0.2.0\r\npyparsing==2.4.5\r\npyrsistent==0.15.5\r\npytest==5.2.4\r\npytest-pylint==0.14.1\r\npython-crfsuite==0.9.7\r\npython-dateutil==2.8.0\r\npytorch-pretrained-bert==0.6.2\r\npytorch-transformers==1.1.0\r\npytz==2019.3\r\nPyWavelets==1.1.1\r\nPyYAML==5.1.2\r\npyzmq==18.1.1\r\nqtconsole==4.6.0\r\nregex==2019.11.1\r\nrequests==2.22.0\r\nresponses==0.10.6\r\nretrying==1.3.3\r\ns3transfer==0.3.3\r\nsacred==0.8.0\r\nsacremoses==0.0.35\r\nscikit-image==0.16.2\r\nscikit-learn==0.21.3\r\nscipy==1.3.2\r\nseaborn==0.9.0\r\nsegtok==1.5.10\r\nSend2Trash==1.5.0\r\nsentence-transformers==0.3.8\r\nsentencepiece==0.1.91\r\nseqeval==1.2.2\r\nShapely==1.6.4.post2\r\nsharedmem==0.3.7\r\nsix==1.13.0\r\nsklearn==0.0\r\nsklearn-crfsuite==0.3.6\r\nskorch==0.6.0\r\nsmart-open==1.9.0\r\nsmmap2==2.0.5\r\nsnowballstemmer==2.0.0\r\nsortedcontainers==2.1.0\r\nspacy==2.1.9\r\nSphinx==2.2.1\r\nsphinxcontrib-applehelp==1.0.1\r\nsphinxcontrib-devhelp==1.0.1\r\nsphinxcontrib-htmlhelp==1.0.2\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.2\r\nsphinxcontrib-serializinghtml==1.1.3\r\nsqlitedict==1.7.0\r\nsqlparse==0.3.0\r\nsrsly==0.2.0\r\nstatsmodels==0.10.1\r\ntables==3.6.1\r\ntabulate==0.8.6\r\ntblib==1.5.0\r\ntensorboard==1.14.0\r\ntensorboardX==1.9\r\ntensorflow-estimator==1.14.0\r\ntensorflow-gpu==1.14.0\r\ntermcolor==1.1.0\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\nthinc==7.0.8\r\ntokenizers==0.9.3\r\ntoolz==0.10.0\r\ntorch==1.6.0\r\ntorchvision==0.4.2\r\ntornado==6.0.3\r\ntqdm==4.38.0\r\ntraitlets==4.3.3\r\ntransformers==3.5.1\r\ntyped-ast==1.4.0\r\nujson==1.35\r\nUnidecode==1.1.1\r\nurllib3==1.25.7\r\nwasabi==0.4.0\r\nwcwidth==0.1.7\r\nwebencodings==0.5.1\r\nWerkzeug==0.16.0\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nwrapt==1.11.2\r\nxgboost==0.90\r\nzict==1.0.0\r\nzipp==0.6.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\nCan be replicated in Colab: https://colab.research.google.com/drive/1w3lhUG1zvvx8XHFcEP_921KGdZc_Ie8Y?usp=sharing\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4810/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4810/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4805", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4805/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4805/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4805/events", "html_url": "https://github.com/allenai/allennlp/issues/4805", "id": 747459178, "node_id": "MDU6SXNzdWU3NDc0NTkxNzg=", "number": 4805, "title": "CUDA OOV when use beam_search with amp", "user": {"login": "wlhgtc", "id": 16603773, "node_id": "MDQ6VXNlcjE2NjAzNzcz", "avatar_url": "https://avatars.githubusercontent.com/u/16603773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wlhgtc", "html_url": "https://github.com/wlhgtc", "followers_url": "https://api.github.com/users/wlhgtc/followers", "following_url": "https://api.github.com/users/wlhgtc/following{/other_user}", "gists_url": "https://api.github.com/users/wlhgtc/gists{/gist_id}", "starred_url": "https://api.github.com/users/wlhgtc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wlhgtc/subscriptions", "organizations_url": "https://api.github.com/users/wlhgtc/orgs", "repos_url": "https://api.github.com/users/wlhgtc/repos", "events_url": "https://api.github.com/users/wlhgtc/events{/privacy}", "received_events_url": "https://api.github.com/users/wlhgtc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2020-11-20T12:38:27Z", "updated_at": "2020-12-08T15:46:46Z", "closed_at": "2020-12-08T15:46:46Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi, there. \r\nThanks for your great job that add multiple samplers and reconstruct Beam Search.\r\nBut recently, I find a bug when use beam_search with amp.\r\nI use the config in allennlp-models: [config](https://github.com/allenai/allennlp-models/blob/master/training_config/generation/bart_cnn_dm.jsonnet)\r\n**And I construct the demo data: a sequence for 200 words source and 100 words target, then repeat it for 512 times.**\r\nAll things goes well until I add `use_amp : true`.\r\nThe cuda memory is as follows( I use a 32G v100):\r\n|   | use amp | no amp |\r\n| ------------- | ------------- |------------- |\r\n| train  | 13G | 15G |\r\n| valid  | 32+G | 15G |\r\n\r\n\r\nIt's strange and I wonder why beam search in amp takes twice memory ?\r\n @epwalsh @jvstokes Hope you could help!\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4805/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4805/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4803", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4803/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4803/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4803/events", "html_url": "https://github.com/allenai/allennlp/issues/4803", "id": 745805907, "node_id": "MDU6SXNzdWU3NDU4MDU5MDc=", "number": 4803, "title": "SRL model produces wrong outputs on the same examples taken from the official demo", "user": {"login": "plroit", "id": 1734563, "node_id": "MDQ6VXNlcjE3MzQ1NjM=", "avatar_url": "https://avatars.githubusercontent.com/u/1734563?v=4", "gravatar_id": "", "url": "https://api.github.com/users/plroit", "html_url": "https://github.com/plroit", "followers_url": "https://api.github.com/users/plroit/followers", "following_url": "https://api.github.com/users/plroit/following{/other_user}", "gists_url": "https://api.github.com/users/plroit/gists{/gist_id}", "starred_url": "https://api.github.com/users/plroit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/plroit/subscriptions", "organizations_url": "https://api.github.com/users/plroit/orgs", "repos_url": "https://api.github.com/users/plroit/repos", "events_url": "https://api.github.com/users/plroit/events{/privacy}", "received_events_url": "https://api.github.com/users/plroit/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2020-11-18T16:24:00Z", "updated_at": "2022-02-22T21:57:52Z", "closed_at": "2020-11-19T19:15:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log]\r\n- [x] I have included in the \"Related issues or possible duplicates\" \r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nHello, \r\nI use AllenNLP version: 1.2.1 and I follow instructions for the SRL predictor (based on BERT)\r\nin the demo: https://demo.allennlp.org/semantic-role-labeling/\r\nThe srl model I load is stored in this path:\r\nhttps://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz\r\nand I load the predictor locally, following the usage instructions in the demo. \r\nWhen I input the sentence, taken from the demo to my local predictor (on my machine, not the demo website, obviously)\r\nthe predictions get very weird, very different than the model advertised in the demo, and not inline with the high scores that I know this model has. \r\n\r\nsentence:\r\n> However, voters decided that if the stadium was such a good idea someone would build it himself, and rejected it 59% to 41%.\r\n\r\nI get the following predictions:\r\n**decided**: \r\n> 'description': '[ARGM-PRD: However ,] [ARG0: voters] [V: decided] [ARG1: that if the stadium] was such a good idea someone would build it himself , and rejected it 59 % to 41 %\r\n\r\n**would**\r\n> However , voters decided that [ARG1: if the stadium was such a good idea] someone [V: would] [ARGM-TMP: build it himself ,] and rejected it 59 % to 41 % .\r\n\r\n**build**\r\n> However , voters decided that if the stadium was such a good idea someone would [V: build] [ARG1: it himself] , and rejected it 59 % to 41 %\r\n\r\n**rejected**\r\n> However , voters decided that if the stadium was such a good idea someone would build it himself , and [V: rejected] it 59 % to 41 % .\r\n\r\n\r\n## Related issues or possible duplicates\r\n#3166 \r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4803/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4803/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4798", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4798/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4798/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4798/events", "html_url": "https://github.com/allenai/allennlp/issues/4798", "id": 744332359, "node_id": "MDU6SXNzdWU3NDQzMzIzNTk=", "number": 4798, "title": "PretrainedTransformerTokenizer doesn't work with seq2seq dataset reader", "user": {"login": "JohnGiorgi", "id": 8917831, "node_id": "MDQ6VXNlcjg5MTc4MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/8917831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JohnGiorgi", "html_url": "https://github.com/JohnGiorgi", "followers_url": "https://api.github.com/users/JohnGiorgi/followers", "following_url": "https://api.github.com/users/JohnGiorgi/following{/other_user}", "gists_url": "https://api.github.com/users/JohnGiorgi/gists{/gist_id}", "starred_url": "https://api.github.com/users/JohnGiorgi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JohnGiorgi/subscriptions", "organizations_url": "https://api.github.com/users/JohnGiorgi/orgs", "repos_url": "https://api.github.com/users/JohnGiorgi/repos", "events_url": "https://api.github.com/users/JohnGiorgi/events{/privacy}", "received_events_url": "https://api.github.com/users/JohnGiorgi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-11-17T01:31:42Z", "updated_at": "2020-11-18T16:09:58Z", "closed_at": "2020-11-18T16:09:58Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [X] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [X] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [X] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [X] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [X] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [X] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [X] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [X] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [X] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [X] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nAs far as I can tell, `PretrainedTransformerTokenizer` is not compatible with the `seq2seq` dataset reader of [`allennlp-models`](https://github.com/allenai/allennlp-models) when it is used as the `source_tokenizer`. The same error, contained in this try/except block [here](https://github.com/allenai/allennlp-models/blob/236034ff54ac3197ec4d710438cebdfa919c5a45/allennlp_models/generation/dataset_readers/seq2seq.py#L94-L102) is triggered in multiple cases.\r\n\r\n1. When `allennlp.common.util.START_SYMBOL` and `allennlp.common.util.END_SYMBOL` are not in the pretrained transformers vocabulary. I was able to solve this in the config as follows:\r\n\r\n```json\r\n    \"dataset_reader\": {\r\n        \"type\": \"copynet_seq2seq\",\r\n        \"target_namespace\": \"target_tokens\",\r\n        \"source_tokenizer\": {\r\n            \"type\": \"pretrained_transformer\",\r\n            \"model_name\": \"distilroberta-base\",\r\n            \"tokenizer_kwargs\": {\r\n                \"additional_special_tokens\": {\r\n                    \"allennlp_start_symbol\": \"@start@\",\r\n                    \"allennlp_end_symbol\": \"@end@\",\r\n                },\r\n            }\r\n        },\r\n```\r\n\r\n2. If `PretrainedTransformerTokenizer.add_special_tokens` is `True` (the default) for wordpiece-based tokenizers.\r\n3. For any BPE-based tokenizer I tried.\r\n\r\nThe error arises because there are more than two tokens in the list returned by `self._source_tokeniser.tokenizer` in the [try/except block](https://github.com/allenai/allennlp-models/blob/236034ff54ac3197ec4d710438cebdfa919c5a45/allennlp_models/generation/dataset_readers/seq2seq.py#L94-L102) for all cases listed above:\r\n\r\n```python\r\ntry:\r\n    self._start_token, self._end_token = self._source_tokenizer.tokenize(\r\n        start_symbol + \" \" + end_symbol\r\n    )\r\nexcept ValueError:\r\n    raise ValueError(\r\n        f\"Bad start or end symbol ('{start_symbol}', '{end_symbol}') \"\r\n        f\"for tokenizer {self._source_tokenizer}\"\r\n    )\r\n```\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n2020-11-16 16:53:24,760 - CRITICAL - root - Uncaught exception\r\nTraceback (most recent call last):\r\n  File \"/project/6006286/johnmg/allennlp-models/allennlp_models/generation/dataset_readers/seq2seq.py\", line 98, in __init__\r\n    self._start_token, self._end_token = self._source_tokenizer.tokenize(\r\nValueError: too many values to unpack (expected 2)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/johnmg/seq2rel/bin/allennlp\", line 33, in <module>\r\n    sys.exit(load_entry_point('allennlp', 'console_scripts', 'allennlp')())\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/commands/__init__.py\", line 118, in main\r\n    args.func(args)\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/commands/train.py\", line 110, in train_model_from_args\r\n    train_model_from_file(\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/commands/train.py\", line 170, in train_model_from_file\r\n    return train_model(\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/commands/train.py\", line 236, in train_model\r\n    model = _train_worker(\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/commands/train.py\", line 453, in _train_worker\r\n    train_loop = TrainModel.from_params(\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/common/from_params.py\", line 595, in from_params\r\n    return retyped_subclass.from_params(\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/common/from_params.py\", line 627, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/common/from_params.py\", line 198, in create_kwargs\r\n    constructed_arg = pop_and_construct_arg(\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/common/from_params.py\", line 305, in pop_and_construct_arg\r\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/common/from_params.py\", line 339, in construct_arg\r\n    return annotation.from_params(params=popped_params, **subextras)\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/common/from_params.py\", line 595, in from_params\r\n    return retyped_subclass.from_params(\r\n  File \"/project/6006286/johnmg/allennlp/allennlp/common/from_params.py\", line 629, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/project/6006286/johnmg/allennlp-models/allennlp_models/generation/dataset_readers/seq2seq.py\", line 102, in __init__\r\n    raise ValueError(\r\nValueError: Bad start or end symbol ('@start@', '@end@') for tokenizer <allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer object at 0x2b6503248970>\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.0\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```bash\r\n-f /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/avx2\r\n-f /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/nix/generic\r\n-f /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\r\n-e git+https://github.com/allenai/allennlp.git@0d8873cfef628eaf0457bee02422bbf8dae475a2#egg=allennlp\r\n-e git+https://github.com/allenai/allennlp-models.git@236034ff54ac3197ec4d710438cebdfa919c5a45#egg=allennlp_models\r\nattrs==20.2.0\r\nblis==0.4.1\r\nboto3==1.16.2\r\nbotocore==1.19.2\r\ncertifi==2020.6.20\r\nchardet==3.0.4\r\nclick==7.1.2\r\nconllu==4.2.1\r\ncymem==2.0.2\r\nfilelock==3.0.12\r\nftfy==5.5.1\r\nfuture==0.18.2\r\nh5py==2.10.0\r\nidna==2.10\r\nimportlib-metadata==2.0.0\r\niniconfig==1.0.1\r\njmespath==0.10.0\r\njoblib==0.17.0\r\njsonnet==0.14.0\r\njsonpickle==1.4.1\r\nmore-itertools==8.5.0\r\nmurmurhash==1.0.2\r\nnltk==3.5\r\nnumpy==1.19.1\r\noverrides==3.1.0\r\npackaging==20.4\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprotobuf==3.13.0\r\npy==1.9.0\r\npy-rouge==1.1\r\npyparsing==2.4.7\r\npytest==6.0.1\r\npython-dateutil==2.8.1\r\nregex==2019.11.1\r\nrequests==2.24.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.0\r\nscipy==1.5.2\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.2.2\r\nsrsly==0.2.0\r\ntensorboardX==2.1\r\nthinc==7.3.1\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.9.3\r\ntoml==0.10.1\r\ntorch==1.7.0\r\ntqdm==4.51.0\r\ntransformers==3.5.1\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.25.10\r\nwasabi==0.6.0\r\nwcwidth==0.2.5\r\nword2number==1.1\r\nzipp==3.4.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\nThe proximate cause of the error can be reproduced as follows:\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```python\r\nfrom allennlp.data.tokenizers import PretrainedTransformerTokenizer\r\nfrom allennlp.common.util import START_SYMBOL, END_SYMBOL\r\n\r\ntokenizer_kwargs = {\"additional_special_tokens\": [START_SYMBOL, END_SYMBOL]}\r\n\r\n# Case 1, don't add AllenNLPs start/end symbols to vocabulary\r\ntokenizer = PretrainedTransformerTokenizer(\"bert-base-uncased\")\r\nstart_token, end_token = tokenizer.tokenize(START_SYMBOL + \" \" + END_SYMBOL)\r\n\r\n# Case 2, set add_special_tokens=True (the default) in PretrainedTransformerTokenizer for a wordpiece based tokenizer\r\n# this WON'T fail\r\ntokenizer = PretrainedTransformerTokenizer(\"bert-base-uncased\", tokenizer_kwargs=tokenizer_kwargs, add_special_tokens=False)\r\nstart_token, end_token = tokenizer.tokenize(START_SYMBOL + \" \" + END_SYMBOL)\r\n# this WILL fail\r\ntokenizer = PretrainedTransformerTokenizer(\"bert-base-uncased\", tokenizer_kwargs=tokenizer_kwargs, add_special_tokens=True)\r\nstart_token, end_token = tokenizer.tokenize(START_SYMBOL + \" \" + END_SYMBOL)\r\n\r\n# Case 3, BPE-based tokenizers fail regardless\r\n# this WILL fail\r\ntokenizer = PretrainedTransformerTokenizer(\"distilroberta-base\", tokenizer_kwargs=tokenizer_kwargs, add_special_tokens=False)\r\nstart_token, end_token = tokenizer.tokenize(START_SYMBOL + \" \" + END_SYMBOL)\r\n# this WILL fail\r\ntokenizer = PretrainedTransformerTokenizer(\"distilroberta-base\", tokenizer_kwargs=tokenizer_kwargs, add_special_tokens=True)\r\nstart_token, end_token = tokenizer.tokenize(START_SYMBOL + \" \" + END_SYMBOL)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4798/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4798/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4794", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4794/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4794/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4794/events", "html_url": "https://github.com/allenai/allennlp/issues/4794", "id": 742912736, "node_id": "MDU6SXNzdWU3NDI5MTI3MzY=", "number": 4794, "title": "Multi GPU training deadlocks when using patience", "user": {"login": "vikigenius", "id": 12724810, "node_id": "MDQ6VXNlcjEyNzI0ODEw", "avatar_url": "https://avatars.githubusercontent.com/u/12724810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vikigenius", "html_url": "https://github.com/vikigenius", "followers_url": "https://api.github.com/users/vikigenius/followers", "following_url": "https://api.github.com/users/vikigenius/following{/other_user}", "gists_url": "https://api.github.com/users/vikigenius/gists{/gist_id}", "starred_url": "https://api.github.com/users/vikigenius/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vikigenius/subscriptions", "organizations_url": "https://api.github.com/users/vikigenius/orgs", "repos_url": "https://api.github.com/users/vikigenius/repos", "events_url": "https://api.github.com/users/vikigenius/events{/privacy}", "received_events_url": "https://api.github.com/users/vikigenius/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2020-11-14T03:18:13Z", "updated_at": "2021-04-17T01:28:05Z", "closed_at": "2020-12-21T17:22:09Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [*] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [*] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [*] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [*] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [*] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [*] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [*] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [*] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [*] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [*] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nIn my config I set patience to 3 and am using 8 GPUs. I notice that Worker 5 ran out of patience according to out_worker5.log and it says it was going to load the best weights. But the master said it was the best validation metric yet and was saving the weights to best.th ?\r\nThis causes a deadlock and the whole thing hangs.\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalabaster @ file:///home/void/.cache/pypoetry/artifacts/01/50/a4/e8f66b1cc7b3896e348a7976ec6390f61a7ed3cc0583b406c9a737955a/alabaster-0.7.12-py2.py3-none-any.whl\r\nalembic @ file:///home/void/.cache/pypoetry/artifacts/0e/1c/e4/ac76b5bee931060d4168f965e85b4348bd828c3c2058657c87632dd955/alembic-1.4.3-py2.py3-none-any.whl\r\nallennlp @ file:///home/void/.cache/pypoetry/artifacts/c8/b7/56/941c7cd1328bf83c98ebc9cbc49a69faf3bf13c67b7b84c0783ca82747/allennlp-1.2.0-py3-none-any.whl\r\nallennlp-optuna @ file:///home/void/.cache/pypoetry/artifacts/f8/e9/9e/6a38853efc3077da4d9b19b4d30d110f196142c142b04392112e7ee71f/allennlp_optuna-0.1.3-py3-none-any.whl\r\nargon2-cffi @ file:///home/void/.cache/pypoetry/artifacts/ed/b1/79/070afdded6990696180ad5ca5dc36c165047414604d3b43d51b546c2a3/argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl\r\nastor @ file:///home/void/.cache/pypoetry/artifacts/00/68/e3/b2c93c6b1eabbb453b7a288336d64a2bb9f32b6821173440843f97f64b/astor-0.8.1-py2.py3-none-any.whl\r\nasync-generator @ file:///home/void/.cache/pypoetry/artifacts/60/d6/35/e25389ca9cdf584a7a41be4eab45a490150210296ca82c7eb696a7e21b/async_generator-1.10-py3-none-any.whl\r\nattrs @ file:///home/void/.cache/pypoetry/artifacts/b7/28/6f/acdd2c0e759f1cda97abf00db7723a0ffb3a151696d8d96398aea16171/attrs-20.3.0-py2.py3-none-any.whl\r\nBabel @ file:///home/void/.cache/pypoetry/artifacts/ff/50/c8/59488715be6e53024188713fe5f553c3c5cb8cf90d5cb67d99a4537a1d/Babel-2.8.0-py2.py3-none-any.whl\r\nbackcall @ file:///home/void/.cache/pypoetry/artifacts/62/2c/f2/bf9c43ca0bcfca41150901227b0d023dc854851b710f82a72f5beaa09b/backcall-0.2.0-py2.py3-none-any.whl\r\nbandit @ file:///home/void/.cache/pypoetry/artifacts/47/cd/d3/5a6d0033a8180d54f1386733bfc852e9af38065a6ac17167ef1d419519/bandit-1.6.2-py2.py3-none-any.whl\r\nbleach @ file:///home/void/.cache/pypoetry/artifacts/50/10/08/2418e45f83f9f6538283b4889dfe95f638b059a3b1171361964a942443/bleach-3.2.1-py2.py3-none-any.whl\r\nblis @ file:///home/void/.cache/pypoetry/artifacts/80/ff/ca/24796c31aec948caac3c34282feaad98a28e3f33a02f6d508d1b3ecce0/blis-0.4.1-cp38-cp38-manylinux1_x86_64.whl\r\nboto3 @ file:///home/void/.cache/pypoetry/artifacts/f1/0d/ca/969ea797ea9937193dce47efea279576d05bf299a640572acb3d2bcb52/boto3-1.16.15-py2.py3-none-any.whl\r\nbotocore @ file:///home/void/.cache/pypoetry/artifacts/fd/2f/cc/cb42383caa85c75496e64acc5b2ae3802293f35c36e783d6ddd1eaf594/botocore-1.19.15-py2.py3-none-any.whl\r\ncatalogue @ file:///home/void/.cache/pypoetry/artifacts/66/0c/9f/6e9dcd1587b0eb24a7c0c5a7209d9d3329db000eccd099aba006ce8c42/catalogue-1.0.0-py2.py3-none-any.whl\r\ncertifi @ file:///home/void/.cache/pypoetry/artifacts/8d/cd/09/57a024ed8656c6768f725b42dee14ac65c94684f2896a5831cdff33338/certifi-2020.11.8-py2.py3-none-any.whl\r\ncffi @ file:///home/void/.cache/pypoetry/artifacts/67/3e/bf/ce28c804d7c4471104482a78ebbdb727dd2fc2d2e051e8cbd010528cc5/cffi-1.14.3-cp38-cp38-manylinux1_x86_64.whl\r\nchardet @ file:///home/void/.cache/pypoetry/artifacts/c2/02/35/0d93b80c730b360c5e3d9bdc1b8d1929dbd784ffa8e3db025c14c045e4/chardet-3.0.4-py2.py3-none-any.whl\r\nclick @ file:///home/void/.cache/pypoetry/artifacts/30/bc/bf/e00ffd8f0edf0294942e70e80e42a839bd2649d2c5b864e6389e526d2a/click-7.1.2-py2.py3-none-any.whl\r\ncliff @ file:///home/void/.cache/pypoetry/artifacts/fb/21/92/915d48b852194d9ce982d585b0285fb54b4f9cedeadf7dc562a07eecf0/cliff-3.5.0-py3-none-any.whl\r\ncmaes @ file:///home/void/.cache/pypoetry/artifacts/6c/56/15/8e79d028097c737756c60c374563860146e0f7df08aa1db65c016029fc/cmaes-0.7.0-py3-none-any.whl\r\ncmd2 @ file:///home/void/.cache/pypoetry/artifacts/78/14/5d/905559dbc4645b2f4dee7e7fc2e6c173b916be3571da97a3fcefb08296/cmd2-1.4.0-py3-none-any.whl\r\ncolorama @ file:///home/void/.cache/pypoetry/artifacts/b0/f3/a3/cf94f06cbe1d286a25116cfe54d5a75cb1c4b54d15b2b1b4fc03a7f657/colorama-0.4.4-py2.py3-none-any.whl\r\ncolorlog @ file:///home/void/.cache/pypoetry/artifacts/27/6e/0a/5fbde594aaa2a559f7a0eb38e2516470b4fca329664c3cf201300e282c/colorlog-4.6.2-py2.py3-none-any.whl\r\ncoverage @ file:///home/void/.cache/pypoetry/artifacts/3a/91/54/2cf1dc70616c58be152f7d5c8a2d4e5a73c30c07a3dee33242ebf0bf2a/coverage-5.3-cp38-cp38-manylinux1_x86_64.whl\r\ncymem @ file:///home/void/.cache/pypoetry/artifacts/23/51/99/2761ff165e0524dee6b93e63eb65d28172174fe38bcf938d002bbb3b7d/cymem-2.0.4-cp38-cp38-manylinux2014_x86_64.whl\r\ndarglint @ file:///home/void/.cache/pypoetry/artifacts/75/d3/fa/7f69c452fedb144eba1f91f7d8a347871b1b088288b7162abf65603901/darglint-1.5.5-py3-none-any.whl\r\ndecorator @ file:///home/void/.cache/pypoetry/artifacts/e8/56/46/038f0f95c2eb2a2792092491cba740226306e663708d5062754d1cb91f/decorator-4.4.2-py2.py3-none-any.whl\r\ndefusedxml @ file:///home/void/.cache/pypoetry/artifacts/8b/b9/f6/56ba9b58f3a759ce345d18bad38edfc12a9f60420962a17a2084202e0e/defusedxml-0.6.0-py2.py3-none-any.whl\r\ndictdiffer @ file:///home/void/.cache/pypoetry/artifacts/eb/97/47/75d6a828e2d9ef1962485d485975c13ff4d8935bb03440f802941f5df2/dictdiffer-0.8.1-py2.py3-none-any.whl\r\ndoc8 @ file:///home/void/.cache/pypoetry/artifacts/15/14/54/c10d16daae42bacb0d561fbf93d68019c90d273d773c79cdb447cb9111/doc8-0.8.1-py2.py3-none-any.whl\r\ndocutils @ file:///home/void/.cache/pypoetry/artifacts/9e/78/f1/81f20d21f3ed304c86fa5394fadbb173e75ad363029a8fefa635dadf2e/docutils-0.16-py2.py3-none-any.whl\r\ndparse @ file:///home/void/.cache/pypoetry/artifacts/45/f0/d9/1a980d82905c06a7365c6227aac29281c69dce4021fafe2a199de092e8/dparse-0.5.1-py3-none-any.whl\r\nentrypoints @ file:///home/void/.cache/pypoetry/artifacts/27/67/42/5ca7438658f76c8700ff6c44ea1cf9dc128cf0862adb7de53d3a35266c/entrypoints-0.3-py2.py3-none-any.whl\r\neradicate @ file:///home/void/.cache/pypoetry/artifacts/d7/9d/a9/4eb3af3b79f810cc0b1b6f09395d9ee84772b603a8e8978e12b12717d2/eradicate-1.0.tar.gz\r\nfilelock @ file:///home/void/.cache/pypoetry/artifacts/f4/78/c1/69555c3867649a2a5dac43f12a078830700480a49be273fb2de82be2ab/filelock-3.0.12-py3-none-any.whl\r\nflake8 @ file:///home/void/.cache/pypoetry/artifacts/5c/5b/91/23d9fee55905e042e829a14e2fa56ffd39c81246aba659e2840bab728b/flake8-3.8.4-py2.py3-none-any.whl\r\nflake8-bandit @ file:///home/void/.cache/pypoetry/artifacts/cc/6d/cf/94dc0d884687c0e10baebe95be53977448e1b59d7ad05e41a0f046cd7e/flake8_bandit-2.1.2.tar.gz\r\nflake8-broken-line @ file:///home/void/.cache/pypoetry/artifacts/b6/72/5f/b138cf8858a3bb7411d5443831c6a3d9c2170f1a4fb01b07a96a33b801/flake8_broken_line-0.2.1-py3-none-any.whl\r\nflake8-bugbear @ file:///home/void/.cache/pypoetry/artifacts/2d/c4/51/6e0f2c02d3e6a846fd30eded9b747688cecf8e55e1c9280ab30a793c04/flake8_bugbear-19.8.0-py35.py36.py37-none-any.whl\r\nflake8-commas @ file:///home/void/.cache/pypoetry/artifacts/b7/aa/76/e620a68b0be70f4132be94bfbfdacb20b16c060174b33dc856818db92d/flake8_commas-2.0.0-py2.py3-none-any.whl\r\nflake8-comprehensions @ file:///home/void/.cache/pypoetry/artifacts/22/08/cf/e2489bbc8810faf889c7d3b805e312583d8ad4992dc695e97dfa258126/flake8_comprehensions-3.3.0-py3-none-any.whl\r\nflake8-debugger @ file:///home/void/.cache/pypoetry/artifacts/da/2c/e3/d62fd2fc55b1f63fccb2997d98af07223eae27b3216cdb75fa9975b398/flake8-debugger-3.2.1.tar.gz\r\nflake8-docstrings @ file:///home/void/.cache/pypoetry/artifacts/14/46/f1/42800107fb2815121aebf831e269f0af48a45c669a24dbcec60fbbac9f/flake8_docstrings-1.5.0-py2.py3-none-any.whl\r\nflake8-eradicate @ file:///home/void/.cache/pypoetry/artifacts/ad/cc/3b/7c679e5a37dbe9e9d3b056d2e5ee8e3dceac70460c3edcb852b0c650f4/flake8_eradicate-0.3.0-py3-none-any.whl\r\nflake8-isort @ file:///home/void/.cache/pypoetry/artifacts/56/70/ee/b8f0228abc9e3e9ff24faa6cf960fe806dc20e1a9d327835b90545585a/flake8_isort-3.0.1-py2.py3-none-any.whl\r\nflake8-plugin-utils @ file:///home/void/.cache/pypoetry/artifacts/99/73/fc/1fd22f303405c472d0dd047300335cdbbcc598f106b402ce1176be733b/flake8_plugin_utils-1.3.1-py3-none-any.whl\r\nflake8-polyfill @ file:///home/void/.cache/pypoetry/artifacts/37/d4/b9/446f3fe801eea4de2fdff2cd1e0be3fa836d08c04d62174d4ec65113f3/flake8_polyfill-1.0.2-py2.py3-none-any.whl\r\nflake8-pytest-style @ file:///home/void/.cache/pypoetry/artifacts/b9/91/aa/24d42f27861d7e5a75ff711270a98440f637f704a85bc7e67fbaa683c9/flake8_pytest_style-1.3.0-py3-none-any.whl\r\nflake8-quotes @ file:///home/void/.cache/pypoetry/artifacts/fb/94/4e/57a6dae12a87b982e4d35a28f9336ab761e0333a4be207d2d9f3ff5c99/flake8-quotes-2.1.2.tar.gz\r\nflake8-rst-docstrings @ file:///home/void/.cache/pypoetry/artifacts/a2/a0/d5/c25770b5624cb722839214583bf7156c6716d34aeb62ff9ee9d96ed7e6/flake8-rst-docstrings-0.0.12.tar.gz\r\nflake8-string-format @ file:///home/void/.cache/pypoetry/artifacts/54/fe/a4/42804621e559c82bc460b782340c42d279633fb413fe8911e1c45707fc/flake8_string_format-0.2.3-py2.py3-none-any.whl\r\nfuture @ file:///home/void/.cache/pypoetry/artifacts/d9/62/dc/809bb3ddfe360ddc60ebb287ad6b0eaf71aef98937f0ea0c466d44aa19/future-0.18.2.tar.gz\r\ngitdb @ file:///home/void/.cache/pypoetry/artifacts/45/a9/94/d73ced00c6cf302a2e08bedd4f10d3424342b7a8a2fae6e4ccb7276641/gitdb-4.0.5-py3-none-any.whl\r\nGitPython @ file:///home/void/.cache/pypoetry/artifacts/bb/7d/e3/03ce0e77da368e61f7ddc587b791b0272880265992f05053a40cb306e3/GitPython-3.1.11-py3-none-any.whl\r\nh5py @ file:///home/void/.cache/pypoetry/artifacts/7f/72/5d/4e83293f7117dc8b4bdebb63cefc313bdc02268760f020ed7817f38500/h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl\r\nidentify @ file:///home/void/.cache/pypoetry/artifacts/c2/72/f0/e25a22eddff10e4ae2266e784139047f4109caec463c4b65abd49ee4b4/identify-1.5.9-py2.py3-none-any.whl\r\nidna @ file:///home/void/.cache/pypoetry/artifacts/9e/f9/03/6066b92d35486e7f0d4f310126e3c60a6619726e43ef98e32e105b5c52/idna-2.10-py2.py3-none-any.whl\r\nimagesize @ file:///home/void/.cache/pypoetry/artifacts/0b/69/4e/8e64ed37efc2f5438fce870c94736b2e1a21bc4cb0c286f936de14357b/imagesize-1.2.0-py2.py3-none-any.whl\r\nimportlib-metadata @ file:///home/void/.cache/pypoetry/artifacts/d9/e3/e4/ca2146a4dcbada8cbfc004ed50b62d7b3ba48592b3e3fb551a226072bd/importlib_metadata-2.0.0-py2.py3-none-any.whl\r\nipykernel @ file:///home/void/.cache/pypoetry/artifacts/b6/f1/35/0d377d3057b4a92f8c1c3080fc6e4edeae65ce62153393fe9f9fcb8c98/ipykernel-5.3.4-py3-none-any.whl\r\nipython @ file:///home/void/.cache/pypoetry/artifacts/86/9e/ba/5c31b7289babe78ae856682b4ff7efab7f6fcc59c8820d0c1c7fdc3495/ipython-7.19.0-py3-none-any.whl\r\nipython-genutils @ file:///home/void/.cache/pypoetry/artifacts/e6/8e/a3/8f37e14310c0072b3fcc4240490bcb42630aa695d069aee89953ebd9f8/ipython_genutils-0.2.0-py2.py3-none-any.whl\r\nipywidgets @ file:///home/void/.cache/pypoetry/artifacts/3c/b0/1a/37aa8262e80401dbdc4471dcb1950d538b572da46d9a0dfa578bcacc57/ipywidgets-7.5.1-py2.py3-none-any.whl\r\nisort @ file:///home/void/.cache/pypoetry/artifacts/6e/4e/fa/c1a31b7a066920f2d2cebcdf14f804e3f48fc87e5d4c85ae4805b246b2/isort-4.3.21-py2.py3-none-any.whl\r\njedi @ file:///home/void/.cache/pypoetry/artifacts/ce/2e/ee/4ef6ff749cd3e9580ef93bd301cece06bf4d86072c8695b60e5fccf93b/jedi-0.17.2-py2.py3-none-any.whl\r\nJinja2 @ file:///home/void/.cache/pypoetry/artifacts/a0/8d/d0/dce9f8c04cdcf457adcd58424bdacab8a7a2c3c42854fd3c0d2135046e/Jinja2-2.11.2-py2.py3-none-any.whl\r\njmespath @ file:///home/void/.cache/pypoetry/artifacts/43/d5/a2/f83573231324de7f5b61f5c607fbbe82ca535359a452de4852d2e25e8d/jmespath-0.10.0-py2.py3-none-any.whl\r\njoblib @ file:///home/void/.cache/pypoetry/artifacts/10/13/81/235e8fe20e06fb00513a93800e192a123d6460ba954647f191cd40dfe4/joblib-0.17.0-py3-none-any.whl\r\njsonnet @ file:///home/void/.cache/pypoetry/artifacts/97/25/a0/259a8cca23e7f52729440ecc27d09b25485d2ad214755673efa01bd6c7/jsonnet-0.16.0.tar.gz\r\njsonpickle @ file:///home/void/.cache/pypoetry/artifacts/f7/ca/3a/c9e8a5a4f75785143bacc85f4531e21e0ee322f147b2b665c1d7cf79d2/jsonpickle-1.4.1-py2.py3-none-any.whl\r\njsonschema @ file:///home/void/.cache/pypoetry/artifacts/8a/0f/f1/4a51263f4c7019004d5abd49f41d94c0eb4618233008d82a629134c337/jsonschema-3.2.0-py2.py3-none-any.whl\r\njupyter @ file:///home/void/.cache/pypoetry/artifacts/2e/44/a0/764f7d3907f220eb94db0e2bce1f8f3e50dcb48aca15a625dd210cb114/jupyter-1.0.0-py2.py3-none-any.whl\r\njupyter-client @ file:///home/void/.cache/pypoetry/artifacts/ed/8f/6b/34e54eebe94bd8de806a24eba8ffa40cce2b70ee935ffc814149087e04/jupyter_client-6.1.7-py3-none-any.whl\r\njupyter-console @ file:///home/void/.cache/pypoetry/artifacts/f9/ff/81/0dd86dc0829e56f6031db9604a9e65b360496a4fdfb6ccd866328c4bd8/jupyter_console-6.2.0-py3-none-any.whl\r\njupyter-core @ file:///home/void/.cache/pypoetry/artifacts/2d/be/09/4ec704f627ac1b4d9755240dea59f977424b48cd82994baf006f35fc9f/jupyter_core-4.6.3-py2.py3-none-any.whl\r\njupyterlab-pygments @ file:///home/void/.cache/pypoetry/artifacts/c8/b0/10/ad75ecf240424057a12f5b4320da2c9f380541cdf830a39e7e8437c2c0/jupyterlab_pygments-0.1.2-py2.py3-none-any.whl\r\nm2r @ file:///home/void/.cache/pypoetry/artifacts/4f/27/1c/8c4108008bcf8c4bb68f981912836a9bdefd1e6b91408a2291566af273/m2r-0.2.1.tar.gz\r\nMako @ file:///home/void/.cache/pypoetry/artifacts/9b/af/a3/2e37b4b97ccbbc5fecf69d31154f2c2ee3fc4a34809cb4a1daf5ed72e1/Mako-1.1.3-py2.py3-none-any.whl\r\nMarkupSafe @ file:///home/void/.cache/pypoetry/artifacts/11/bd/ad/5012ca1b0f41b786ac09ee7c185c0383d54f89f9d6f87e13a22b085a4f/MarkupSafe-1.1.1-cp38-cp38-manylinux1_x86_64.whl\r\nmarshmallow @ file:///home/void/.cache/pypoetry/artifacts/5b/8d/70/bc83a7f80e1c5cd994f8bdd90731d058c433cd03d2c5e0647194620bd9/marshmallow-3.9.1-py2.py3-none-any.whl\r\nmarshmallow-polyfield @ file:///home/void/.cache/pypoetry/artifacts/d1/50/95/b389132f11c645bf60b00b2a724eafd5a0191c62606e50e0c9ef69a505/marshmallow-polyfield-5.9.tar.gz\r\nmccabe @ file:///home/void/.cache/pypoetry/artifacts/37/6e/69/4a33a4d6c80c775b1ee205face2c6e07b762c8602bb0f0d236ebe790c5/mccabe-0.6.1-py2.py3-none-any.whl\r\nmistune @ file:///home/void/.cache/pypoetry/artifacts/d9/d8/5c/8eac14aaa95c3aa81409d56b7423ff6dd88eb398f551c1bf0b8c05b916/mistune-0.8.4-py2.py3-none-any.whl\r\nmore-itertools @ file:///home/void/.cache/pypoetry/artifacts/b7/39/2d/8628adfd013f3bf1658dafd470eef925f88b584f61666e69578a88b3b0/more_itertools-8.6.0-py3-none-any.whl\r\nmurmurhash @ file:///home/void/.cache/pypoetry/artifacts/ba/67/cb/b8b15a73b18cb43797cb5becfd0c8ba9162bed0da57b22bd32bea801c8/murmurhash-1.0.4-cp38-cp38-manylinux2014_x86_64.whl\r\nmypy @ file:///home/void/.cache/pypoetry/artifacts/c4/0d/91/abaaf7d6878463da63ac45235c6eeaa23c95ebe7b60a2aed71224b6394/mypy-0.790-cp38-cp38-manylinux1_x86_64.whl\r\nmypy-extensions @ file:///home/void/.cache/pypoetry/artifacts/b6/a0/b0/a5dc9acd6fd12aba308634f21bb7cf0571448f20848797d7ecb327aa12/mypy_extensions-0.4.3-py2.py3-none-any.whl\r\nnbclient @ file:///home/void/.cache/pypoetry/artifacts/ca/75/28/4f846efe867484804f4e1e3ed8735ab8c75a0a186cf3742fc5381a08fc/nbclient-0.5.1-py3-none-any.whl\r\nnbconvert @ file:///home/void/.cache/pypoetry/artifacts/6d/04/d2/6f698739d85cec6503abcfed57a421b113f6f66af399a25bf9994a1a87/nbconvert-6.0.7-py3-none-any.whl\r\nnbformat @ file:///home/void/.cache/pypoetry/artifacts/08/a0/7e/bf15ec9700d71d6abb3cf0279bb861c9e9fd74edc3e7d3ec9a18605ee5/nbformat-5.0.8-py3-none-any.whl\r\nnest-asyncio @ file:///home/void/.cache/pypoetry/artifacts/ca/11/7c/18e3746fa2c8f3359f9d84a671e4ee45f673b59a0a0c81ba68a5345ca9/nest_asyncio-1.4.2-py3-none-any.whl\r\nnitpick @ file:///home/void/.cache/pypoetry/artifacts/28/98/16/5682d5116b7b7060227becef96a14e31c189a936800abb96b0c0dfc7b9/nitpick-0.23.1-py3-none-any.whl\r\nnltk @ file:///home/void/.cache/pypoetry/artifacts/4e/a8/c9/3b9dad78f26601cae847a376b6c3342fc0f0e5d6bf78e56a12ac16dfbd/nltk-3.5.zip\r\nnotebook @ file:///home/void/.cache/pypoetry/artifacts/b9/b4/5b/c03c39ceee9407c9f0623ff14549ca199c7bb86df87d5a029e652ba8ea/notebook-6.1.5-py3-none-any.whl\r\nnumpy @ file:///home/void/.cache/pypoetry/artifacts/34/b2/b2/d3c8437d5f488bbd58ff83c4a586ff06cd34fe60aad95d0d662034be5b/numpy-1.19.4-cp38-cp38-manylinux2010_x86_64.whl\r\noptuna @ file:///home/void/.cache/pypoetry/artifacts/b4/27/fc/f57667b8bf2a132732ddebf7bcf93e3fe3939e462072fdcf64d5d8e2d2/optuna-2.3.0.tar.gz\r\noverrides @ file:///home/void/.cache/pypoetry/artifacts/2e/a1/58/bef997b290151ed8dc40c8873f5a581732643e73c41da963ab65b75838/overrides-3.1.0.tar.gz\r\npackaging @ file:///home/void/.cache/pypoetry/artifacts/09/cd/29/a435224f3203dfba4af491065632910aadb6f3ddd87ce3c6590ac29e7a/packaging-20.4-py2.py3-none-any.whl\r\npandocfilters @ file:///home/void/.cache/pypoetry/artifacts/a0/de/ee/57ddb36e87aac56bbe9fe7c7bee8049805d79bcc280239a9fc1e913a69/pandocfilters-1.4.3.tar.gz\r\nparso @ file:///home/void/.cache/pypoetry/artifacts/68/b7/ab/104272f01420d39035467c3910fd1e927d05b020948799cbfebd116405/parso-0.7.1-py2.py3-none-any.whl\r\npbr @ file:///home/void/.cache/pypoetry/artifacts/85/81/cf/9255f6df466921f8291c85ab33df01caeda1916c2745a5071ce06a963f/pbr-5.5.1-py2.py3-none-any.whl\r\npep8-naming @ file:///home/void/.cache/pypoetry/artifacts/ce/6c/45/d883218e7ee597f1796a1593478f89443587aea185b8a63a863060d473/pep8_naming-0.9.1-py2.py3-none-any.whl\r\npexpect @ file:///home/void/.cache/pypoetry/artifacts/c0/05/08/f23ddb8e3d5b19e7cf01eb434220310be2aaf69226bdec78bc53589024/pexpect-4.8.0-py2.py3-none-any.whl\r\npickleshare @ file:///home/void/.cache/pypoetry/artifacts/27/b2/0a/93a92c700a1993b2923519262ddf76a629bd459a0597c0ae28bf80c7a6/pickleshare-0.7.5-py2.py3-none-any.whl\r\nplac @ file:///home/void/.cache/pypoetry/artifacts/80/ac/29/737762264fecacc0a2e9b9e3b000ce340249e75dd163f5eeb09521a1b4/plac-1.1.3-py2.py3-none-any.whl\r\npluggy @ file:///home/void/.cache/pypoetry/artifacts/9c/e5/0b/2d64d03361a081edeb5d2ec5f286ccf9719587781fbf6822e1b6384c27/pluggy-0.13.1-py2.py3-none-any.whl\r\npreshed @ file:///home/void/.cache/pypoetry/artifacts/86/8a/ba/30556be82374ba7060bcaa318f3ca78781c79f55ff1d7641ace59490a2/preshed-3.0.4-cp38-cp38-manylinux2014_x86_64.whl\r\nprettytable @ file:///home/void/.cache/pypoetry/artifacts/74/22/23/b5629ff30d2c0b82c55f90d3dfbb6c2d40ec8f6b7d63b99677b8bfc43f/prettytable-0.7.2.tar.bz2\r\nprometheus-client @ file:///home/void/.cache/pypoetry/artifacts/d0/c3/47/75f3e2e1a613c920838a5c3f03bb72429c418b191fcd0f5f030f913e5d/prometheus_client-0.8.0-py2.py3-none-any.whl\r\nprompt-toolkit @ file:///home/void/.cache/pypoetry/artifacts/b1/31/5d/6662f0325b5535bca04f9072b21522c4b3b6f2f14a8be144a8e7d51830/prompt_toolkit-3.0.8-py3-none-any.whl\r\nprotobuf @ file:///home/void/.cache/pypoetry/artifacts/f4/03/e2/297d499fdbac329cb0b33be3098be366a799735835fd81b8482aa2bb12/protobuf-3.13.0-cp38-cp38-manylinux1_x86_64.whl\r\nptyprocess @ file:///home/void/.cache/pypoetry/artifacts/2c/6a/98/a555fa30b04faf75866656b49dfd32457704fbd3811c6ae29eecfc2715/ptyprocess-0.6.0-py2.py3-none-any.whl\r\npy @ file:///home/void/.cache/pypoetry/artifacts/f5/51/7d/d8aec03f59299351465053794c7b1f0e0e7a918e4a67911664f83929af/py-1.9.0-py2.py3-none-any.whl\r\npycodestyle @ file:///home/void/.cache/pypoetry/artifacts/01/f4/cf/c7e34cb76e03e95d9eff28af16fe09ee8edd01cc985fc2b88453b6d311/pycodestyle-2.6.0-py2.py3-none-any.whl\r\npycparser @ file:///home/void/.cache/pypoetry/artifacts/f1/03/25/40eb46f7bede64f78ba073e2141b8216e611cbcde72e3117c326560101/pycparser-2.20-py2.py3-none-any.whl\r\npydocstyle @ file:///home/void/.cache/pypoetry/artifacts/a4/ef/58/498033174cb8c68875036ec5d8a3d9d2e169c51bec9d35866bd62ff5ac/pydocstyle-5.1.1-py3-none-any.whl\r\npyflakes @ file:///home/void/.cache/pypoetry/artifacts/da/83/11/1e9a80c39638c6967e9b1117b17d8ec5f723ddd0a88251cc08dc0807b0/pyflakes-2.2.0-py2.py3-none-any.whl\r\nPygments @ file:///home/void/.cache/pypoetry/artifacts/d0/37/a5/bdd862c4f6538fafaf79d37ec67fd2337ac277eef4817a8ecd525570c9/Pygments-2.7.2-py3-none-any.whl\r\npyparsing @ file:///home/void/.cache/pypoetry/artifacts/da/e7/3d/1780282f558e5fd157bf708b28b8ba0d08323ef6bc5b6396139ce38a0b/pyparsing-2.4.7-py2.py3-none-any.whl\r\npyperclip @ file:///home/void/.cache/pypoetry/artifacts/3b/76/d9/aca188073af784ee724f422bdad1dee18c9438ca556e10b955ad3498ee/pyperclip-1.8.1.tar.gz\r\npyrsistent @ file:///home/void/.cache/pypoetry/artifacts/d8/37/43/5ceed6677fc301784b0e62604a431e293d12c402f4ca588304e916a04d/pyrsistent-0.17.3.tar.gz\r\npytest @ file:///home/void/.cache/pypoetry/artifacts/9d/40/6b/50d2cb06df545acea43c65379c5456f4fbc703115a703bc7cd433ddf70/pytest-5.4.3-py3-none-any.whl\r\npytest-cov @ file:///home/void/.cache/pypoetry/artifacts/b9/58/55/db0439b8e3e9c6ad7790a801ddb71803fd3791b5d6fd7f65efe27016f5/pytest_cov-2.10.1-py2.py3-none-any.whl\r\npytest-randomly @ file:///home/void/.cache/pypoetry/artifacts/10/85/3e/d5c0ccbc022ddb857a1401198a620cb6ce5e06ca6a8a8efb75953cd558/pytest_randomly-3.4.1-py3-none-any.whl\r\npython-dateutil @ file:///home/void/.cache/pypoetry/artifacts/1e/2c/dc/0e811c2299b40168ee1da03bc13c11762ce9fa96eb867ad22280db11fc/python_dateutil-2.8.1-py2.py3-none-any.whl\r\npython-editor @ file:///home/void/.cache/pypoetry/artifacts/88/e4/9a/6a3b58d3811aabb356fe1af49b223e67e18505daf666e0dca62c12f260/python_editor-1.0.4-py3-none-any.whl\r\npython-slugify @ file:///home/void/.cache/pypoetry/artifacts/fb/48/0c/b3d105b241e71968321b5a90e86893953d66bded05418da96166cd7d7f/python-slugify-4.0.1.tar.gz\r\npytz @ file:///home/void/.cache/pypoetry/artifacts/7a/8e/a2/e796ae4d320aded38d3d61817b158184888dcd18c6a4f6d6ab011a6cda/pytz-2020.4-py2.py3-none-any.whl\r\nPyYAML @ file:///home/void/.cache/pypoetry/artifacts/28/fe/c8/ee41918e776a0a8fea86e3b4d45d54620381726103e666941e1218c099/PyYAML-5.3.1.tar.gz\r\npyzmq @ file:///home/void/.cache/pypoetry/artifacts/37/29/30/1d0ad12da5a691de9d7c68bd116cc0a81bdb8c3fd4ddd8abe767606373/pyzmq-19.0.2-cp38-cp38-manylinux1_x86_64.whl\r\nqtconsole @ file:///home/void/.cache/pypoetry/artifacts/a4/da/87/61dddc98b433ed2b87477ca19c06d3c03d7b1f8f31111a2fb042bf6ff6/qtconsole-4.7.7-py2.py3-none-any.whl\r\nQtPy @ file:///home/void/.cache/pypoetry/artifacts/68/e6/b3/652e75104edbe2a4b47170036550f3c8df1bf6f4f9ae6be442ef16c336/QtPy-1.9.0-py2.py3-none-any.whl\r\nregex @ file:///home/void/.cache/pypoetry/artifacts/7b/ae/3c/12683960145c5f53e6dd03567a3ee58d3ec0e1d3d9b31430ad96ec85ff/regex-2020.10.28-cp38-cp38-manylinux2014_x86_64.whl\r\nrequests @ file:///home/void/.cache/pypoetry/artifacts/1e/9a/75/03520154e60eb952530469162a6d43cd95ece92de272e2c3392058401c/requests-2.24.0-py2.py3-none-any.whl\r\nrestructuredtext-lint @ file:///home/void/.cache/pypoetry/artifacts/b7/45/71/382cdebdbfe4603f3ff0494bfd4460f84940c634dd95f1e1ce1a023a82/restructuredtext_lint-1.3.1.tar.gz\r\nruamel.yaml @ file:///home/void/.cache/pypoetry/artifacts/fa/10/2b/409b73cb7fd78317ea1094d48cb62274d1ceb83475047162e073699ec5/ruamel.yaml-0.16.12-py2.py3-none-any.whl\r\nruamel.yaml.clib @ file:///home/void/.cache/pypoetry/artifacts/97/f1/f1/1e2842d208a1b2fb98118062b928f0534297168decb2e8006fb82d3d20/ruamel.yaml.clib-0.2.2-cp38-cp38-manylinux1_x86_64.whl\r\ns3transfer @ file:///home/void/.cache/pypoetry/artifacts/6b/c7/58/1aed9dbe74f228d78b9584e09cfb29b03cb2428d9c7a0c2e4d204b9faf/s3transfer-0.3.3-py2.py3-none-any.whl\r\nsacremoses @ file:///home/void/.cache/pypoetry/artifacts/94/85/15/980a84215423e23c131132e651f13e7cfbda060563ddf4699c72417524/sacremoses-0.0.43.tar.gz\r\nsafety @ file:///home/void/.cache/pypoetry/artifacts/d5/1e/9c/fcd40e725914ec495de4d13790d3dbdeccdbdf1761cf5c42943c4ee4f8/safety-1.9.0-py2.py3-none-any.whl\r\nscikit-learn @ file:///home/void/.cache/pypoetry/artifacts/f1/b0/0f/fc8f3775e8a01ee194030bf0e6600c96fd091442f1c9b978fac7f647ec/scikit_learn-0.23.2-cp38-cp38-manylinux1_x86_64.whl\r\nscipy @ file:///home/void/.cache/pypoetry/artifacts/9a/85/e7/b422d8294ea40767b1b0a79a28397709cf7def94b3fa0f122656a096da/scipy-1.5.4-cp38-cp38-manylinux1_x86_64.whl\r\nSend2Trash @ file:///home/void/.cache/pypoetry/artifacts/40/97/0a/f421bca5e8da2c4a13d0c5abe9f2309550d5ebc2067b67c3929997663c/Send2Trash-1.5.0-py3-none-any.whl\r\nsentencepiece @ file:///home/void/.cache/pypoetry/artifacts/31/43/b7/1e712bf610a890a65f96e39eee41e72ac9341d7292deb8c9e976c234b0/sentencepiece-0.1.94-cp38-cp38-manylinux2014_x86_64.whl\r\nsix @ file:///home/void/.cache/pypoetry/artifacts/be/98/c7/69fe6fea7a59659af1c6260899226129565330b1e07c9c5b3769be76bf/six-1.15.0-py2.py3-none-any.whl\r\nsmmap @ file:///home/void/.cache/pypoetry/artifacts/39/8f/16/e7986b1d62635c17d6635e446732dd98686c7b0f663445a0cd6e59dcdf/smmap-3.0.4-py2.py3-none-any.whl\r\nsnowballstemmer @ file:///home/void/.cache/pypoetry/artifacts/00/58/78/ad3aa1f5e8e5da623c9a205c7cdb41811fb480646c3e79278fc2aec1ad/snowballstemmer-2.0.0-py2.py3-none-any.whl\r\nsortedcontainers @ file:///home/void/.cache/pypoetry/artifacts/b3/bf/a2/83677c4175a4561da36b5ec625e33e1cdd6d78137304a914eb5d6fdcdd/sortedcontainers-2.3.0-py2.py3-none-any.whl\r\nspacy @ file:///home/void/.cache/pypoetry/artifacts/37/86/ad/fb5633e5431a9469b9dfa81e4a465ee37c67c2eda1d5e1f7138b6825f7/spacy-2.3.2-cp38-cp38-manylinux1_x86_64.whl\r\nSphinx @ file:///home/void/.cache/pypoetry/artifacts/1d/ed/5b/1be39c6e21184601c628545a74a3116019d3382e5a453a6c6bfd52449b/Sphinx-2.4.4-py3-none-any.whl\r\nsphinx-autodoc-typehints @ file:///home/void/.cache/pypoetry/artifacts/e7/ce/18/148b1186b401fd894226b0f906b3ed753597fdfc66383cd617f7540fce/sphinx_autodoc_typehints-1.10.3-py3-none-any.whl\r\nsphinxcontrib-applehelp @ file:///home/void/.cache/pypoetry/artifacts/06/55/7c/cf28d2c944f7fc7cba94678d0ca98b77947cae69b6c801ffd04601cc8c/sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl\r\nsphinxcontrib-devhelp @ file:///home/void/.cache/pypoetry/artifacts/95/e9/af/55ffd1a6f2b03f2bc460172ec6a9ee4a9353404fc6b9026b0fd4776f84/sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl\r\nsphinxcontrib-htmlhelp @ file:///home/void/.cache/pypoetry/artifacts/a0/ad/8e/a970be3040e06e0264ff5263c1c64053370852e5711ebce0169f50d4c0/sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl\r\nsphinxcontrib-jsmath @ file:///home/void/.cache/pypoetry/artifacts/5f/c9/8c/2bf04b76e3b07f85857acb15a02dec77db17eb7069ef7e3e8200580fa0/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\r\nsphinxcontrib-qthelp @ file:///home/void/.cache/pypoetry/artifacts/bd/a5/cb/8f6c168f27ca463b2c09d5dfbaabea32b6bb9ebff80556a11bc2b1152f/sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl\r\nsphinxcontrib-serializinghtml @ file:///home/void/.cache/pypoetry/artifacts/83/d2/78/3f17c9e1fa5ed17cb815a8d897bf2003c1197b16a36d4e9c6ffa0e8592/sphinxcontrib_serializinghtml-1.1.4-py2.py3-none-any.whl\r\nSQLAlchemy @ file:///home/void/.cache/pypoetry/artifacts/05/26/db/d7d70d2f2a385bdac6d40e4da10a09ae7196ea5c849f56adf88ac4f3b3/SQLAlchemy-1.3.20-cp38-cp38-manylinux2010_x86_64.whl\r\nsrsly @ file:///home/void/.cache/pypoetry/artifacts/ed/9f/73/6d1c2c47ab56d3049b1f004778a8351e4694403c1e6e620206c4b47e2c/srsly-1.0.4-cp38-cp38-manylinux2014_x86_64.whl\r\nstevedore @ file:///home/void/.cache/pypoetry/artifacts/82/a9/1a/89ccf2529a0533a62894da67e9660c47190abdfacf1f9d96eb7a17df85/stevedore-3.2.2-py3-none-any.whl\r\ntensorboardX @ file:///home/void/.cache/pypoetry/artifacts/5c/f4/0c/18de8e039c6894db1eff82340d262b49639d8e0b820d4ad2b193085f7c/tensorboardX-2.1-py2.py3-none-any.whl\r\nterminado @ file:///home/void/.cache/pypoetry/artifacts/16/26/98/8a096ebe53cf81cf3b1d1c57cd613f3c8195d48c42d45aa07df7a3bdb5/terminado-0.9.1-py3-none-any.whl\r\ntestfixtures @ file:///home/void/.cache/pypoetry/artifacts/a7/32/a6/0fc95c70fae6ebc94fe74576a34cb054ee50832a4cfd380ca3754c2bc6/testfixtures-6.15.0-py2.py3-none-any.whl\r\ntestpath @ file:///home/void/.cache/pypoetry/artifacts/71/31/06/e1366905608d747ada47997b3406776c1f88e2628e47674e40b9ae2b0b/testpath-0.4.4-py2.py3-none-any.whl\r\ntext-unidecode @ file:///home/void/.cache/pypoetry/artifacts/9b/cc/f2/c615087594418f3b86c03fb83c56a1d3b673e89924d4bd0cece68a7615/text_unidecode-1.3-py2.py3-none-any.whl\r\nthinc @ file:///home/void/.cache/pypoetry/artifacts/3a/51/eb/46e64cb71bab30ab2fdca32ebc4aa86d43df9f622a1373ad7aa36a9287/thinc-7.4.1-cp38-cp38-manylinux1_x86_64.whl\r\nthreadpoolctl @ file:///home/void/.cache/pypoetry/artifacts/51/cf/f3/45cf01a8bc970a364ec52ad5b3efb73b5796bed51e1aef77f8f1127009/threadpoolctl-2.1.0-py3-none-any.whl\r\ntokenizers @ file:///home/void/.cache/pypoetry/artifacts/53/0b/88/4ea2dfa30a87710972809e690deb5e137107c3f73927cdc38ae0d4eb92/tokenizers-0.9.2-cp38-cp38-manylinux1_x86_64.whl\r\ntoml @ file:///home/void/.cache/pypoetry/artifacts/fb/01/94/0219377a74b149d8ffe3b6f96c113b460850ec2846a86a302d6156dfef/toml-0.10.0-py2.py3-none-any.whl\r\ntomlkit @ file:///home/void/.cache/pypoetry/artifacts/db/c3/df/baf014ce3b04caffe7ac34bde699f5be82c4acbaf43f49db1ce681a500/tomlkit-0.7.0-py2.py3-none-any.whl\r\ntorch @ file:///home/void/.cache/pypoetry/artifacts/8f/0b/9a/52152cc1a51f13d2081ec3c41b5b16c0b37a819ea651c6130c24d7f3f0/torch-1.7.0-cp38-cp38-manylinux1_x86_64.whl\r\ntornado @ file:///home/void/.cache/pypoetry/artifacts/ec/fb/c8/e022dee175b03afe90ae806e12ec894741303dfc5a6debe95d80154754/tornado-6.1-cp38-cp38-manylinux2010_x86_64.whl\r\ntqdm @ file:///home/void/.cache/pypoetry/artifacts/ee/76/9f/005e71b2c85a47268f2e08a034446e11a8237cdb7f058f365b9e79803c/tqdm-4.51.0-py2.py3-none-any.whl\r\ntraitlets @ file:///home/void/.cache/pypoetry/artifacts/8a/f4/fd/48c1725dcdd56393737bb0696379f91042dae8fbe51d06801caadfb12b/traitlets-5.0.5-py3-none-any.whl\r\ntransform==0.1.0\r\ntransformers @ file:///home/void/.cache/pypoetry/artifacts/1f/3d/6b/7de60a0442e2d3a267065391505319b367922bbe6a5271fc8ff7155706/transformers-3.4.0-py3-none-any.whl\r\ntyped-ast @ file:///home/void/.cache/pypoetry/artifacts/18/1f/94/6f7cab4b91b697a39bde0b9dad925b0717b2f4b410a070d2cae0e44f7b/typed_ast-1.4.1-cp38-cp38-manylinux1_x86_64.whl\r\ntyping-extensions @ file:///home/void/.cache/pypoetry/artifacts/ac/8f/3a/97dfae6ca13a6e156f19a5e8aa95fc250129d7e5e6cd0f7c76a1d45b4f/typing_extensions-3.7.4.3-py3-none-any.whl\r\nurllib3 @ file:///home/void/.cache/pypoetry/artifacts/b0/87/9a/1a8e2a4a36c962a03a9c1a35c9c0634febb4353159f230d7e9a76957a7/urllib3-1.25.11-py2.py3-none-any.whl\r\nwasabi @ file:///home/void/.cache/pypoetry/artifacts/47/69/94/73ff8ee90be80c4184a0cedff1c90b8c08e298e4296fc7eba7345ff79f/wasabi-0.8.0-py3-none-any.whl\r\nwcwidth @ file:///home/void/.cache/pypoetry/artifacts/36/68/e2/7232f431072d5e8aeec124120b9a1d095d45da10311d271fac10982473/wcwidth-0.2.5-py2.py3-none-any.whl\r\nwebencodings @ file:///home/void/.cache/pypoetry/artifacts/60/1e/b4/eff9915b6506bb01a5ad61dfae3fa4f0302be9e2ad45eaccc833925b95/webencodings-0.5.1-py2.py3-none-any.whl\r\nwemake-python-styleguide @ file:///home/void/.cache/pypoetry/artifacts/c6/77/cd/c271dd6015ac40fc5bd5444626301783611963034f5c3a0c2a621106ea/wemake_python_styleguide-0.14.1-py3-none-any.whl\r\nwidgetsnbextension @ file:///home/void/.cache/pypoetry/artifacts/4f/c4/8c/95c9c932a9649e98240304b336a4c725419ee2fd517897c94b817722d6/widgetsnbextension-3.5.1-py2.py3-none-any.whl\r\nzipp @ file:///home/void/.cache/pypoetry/artifacts/6d/a4/76/c77b47779fc6e06dbaaa25fa3e031007bf3e05bb7ba887d03a5900a89a/zipp-3.4.0-py3-none-any.whl\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nlocal model_name = \"models/distilroberta-base-msmarco-v1/0_Transformer\";\r\nlocal num_gpus = 8;\r\nlocal data_base_url = \"data/mydata/processed/\";\r\nlocal model = \"my_model\";\r\nlocal dataset_reader = \"my_reader\";\r\n\r\n{\r\n  \"train_data_path\": data_base_url + \"train.tsv.part*\",\r\n  \"validation_data_path\": data_base_url + \"valid.tsv.part*\",\r\n  \"dataset_reader\": {\r\n    \"type\": \"sharded\",\r\n    \"base_reader\": {\r\n      \"type\": dataset_reader,\r\n      \"query_tokenizer\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": model_name,\r\n        \"max_length\": 500,\r\n      },\r\n      \"query_token_indexers\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer\",\r\n          \"model_name\": model_name,\r\n          \"namespace\": \"tokens\"\r\n        }\r\n      },\r\n    }\r\n  },\r\n  'model': {\r\n    'type': model,\r\n    'transformer_model': model_name,\r\n  },\r\n  \"data_loader\": {\r\n    \"batch_size\": 28,\r\n    \"shuffle\": true\r\n  },\r\n  \"distributed\": {\r\n    \"cuda_devices\": if num_gpus > 1 then std.range(0, num_gpus - 1) else 0,\r\n  },\r\n  \"trainer\": {\r\n    \"num_epochs\": 10,\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"lr\": 3e-5,\r\n      \"betas\": [0.9, 0.999],\r\n      \"eps\": 1e-8,\r\n      \"correct_bias\": true\r\n    },\r\n    \"learning_rate_scheduler\": {\r\n      \"type\": \"polynomial_decay\",\r\n    },\r\n    \"use_amp\": true,\r\n    \"grad_norm\": 1.0,\r\n    \"validation_metric\": \"+rec5\",\r\n    \"patience\": 3,\r\n  }\r\n}\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4794/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4794/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4788", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4788/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4788/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4788/events", "html_url": "https://github.com/allenai/allennlp/issues/4788", "id": 741467058, "node_id": "MDU6SXNzdWU3NDE0NjcwNTg=", "number": 4788, "title": "Installation of allennlp-server breaking allennlp command", "user": {"login": "simvetanylen", "id": 12927129, "node_id": "MDQ6VXNlcjEyOTI3MTI5", "avatar_url": "https://avatars.githubusercontent.com/u/12927129?v=4", "gravatar_id": "", "url": "https://api.github.com/users/simvetanylen", "html_url": "https://github.com/simvetanylen", "followers_url": "https://api.github.com/users/simvetanylen/followers", "following_url": "https://api.github.com/users/simvetanylen/following{/other_user}", "gists_url": "https://api.github.com/users/simvetanylen/gists{/gist_id}", "starred_url": "https://api.github.com/users/simvetanylen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/simvetanylen/subscriptions", "organizations_url": "https://api.github.com/users/simvetanylen/orgs", "repos_url": "https://api.github.com/users/simvetanylen/repos", "events_url": "https://api.github.com/users/simvetanylen/events{/privacy}", "received_events_url": "https://api.github.com/users/simvetanylen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2020-11-12T10:15:05Z", "updated_at": "2020-11-18T20:53:38Z", "closed_at": "2020-11-18T20:53:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "The installation of allennlp-server breaks the allennlp command.\r\nOS : Ubuntu 20.04\r\nPython version : 3.8\r\n\r\nMy procedure : \r\n1) Create a freash env\r\n```\r\nVIRTUAL_ENV=/opt/venv\r\npython3 -m venv $VIRTUAL_ENV\r\nPATH=\"$VIRTUAL_ENV/bin:$PATH\"\r\n```\r\n2) Installing allennlp : \r\n\r\n```\r\npip install allennlp\r\npip uninstall -y dataclasses   # uninstalling dataclasses because https://github.com/mitsuse/typedjson-python/issues/8\r\n\r\n```\r\nHere, allennlp command is working.\r\n\r\n3) Installing allennlp server : \r\n\r\n```\r\ngit clone https://github.com/allenai/allennlp-server\r\ncd allennlp-server\r\npip install --editable .\r\n\r\n```\r\n\r\nFrom now, all allennlp-commands are broken, even the simple allennlp --help : \r\n\r\n```\r\n2020-11-12 11:12:11,196 - INFO - allennlp.common.plugins - Plugin allennlp_models available\r\nTraceback (most recent call last):\r\n  File \"/home/psygnosis/workspace/pyenv/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/psygnosis/workspace/pyenv/lib/python3.8/site-packages/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/psygnosis/workspace/pyenv/lib/python3.8/site-packages/allennlp/commands/__init__.py\", line 109, in main\r\n    parser, args = parse_args(prog)\r\n  File \"/home/psygnosis/workspace/pyenv/lib/python3.8/site-packages/allennlp/commands/__init__.py\", line 88, in parse_args\r\n    import_plugins()\r\n  File \"/home/psygnosis/workspace/pyenv/lib/python3.8/site-packages/allennlp/common/plugins.py\", line 87, in import_plugins\r\n    import_module_and_submodules(module_name)\r\n  File \"/home/psygnosis/workspace/pyenv/lib/python3.8/site-packages/allennlp/common/util.py\", line 351, in import_module_and_submodules\r\n    import_module_and_submodules(subpackage)\r\n  File \"/home/psygnosis/workspace/pyenv/lib/python3.8/site-packages/allennlp/common/util.py\", line 351, in import_module_and_submodules\r\n    import_module_and_submodules(subpackage)\r\n  File \"/home/psygnosis/workspace/pyenv/lib/python3.8/site-packages/allennlp/common/util.py\", line 351, in import_module_and_submodules\r\n    import_module_and_submodules(subpackage)\r\n  File \"/home/psygnosis/workspace/pyenv/lib/python3.8/site-packages/allennlp/common/util.py\", line 340, in import_module_and_submodules\r\n    module = importlib.import_module(package_name)\r\n  File \"/usr/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/psygnosis/workspace/test-allen/allennlp-server/allennlp_server/tests/commands/docstring_help_test.py\", line 10, in <module>\r\n    from allennlp.commands import create_parser\r\nImportError: cannot import name 'create_parser' from 'allennlp.commands' (/home/psygnosis/workspace/pyenv/lib/python3.8/site-packages/allennlp/commands/__init__.py)\r\n\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4788/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4788/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4767", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4767/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4767/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4767/events", "html_url": "https://github.com/allenai/allennlp/issues/4767", "id": 734932742, "node_id": "MDU6SXNzdWU3MzQ5MzI3NDI=", "number": 4767, "title": "No super class method found for \"decode\"", "user": {"login": "Jazzssmine", "id": 44516315, "node_id": "MDQ6VXNlcjQ0NTE2MzE1", "avatar_url": "https://avatars.githubusercontent.com/u/44516315?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jazzssmine", "html_url": "https://github.com/Jazzssmine", "followers_url": "https://api.github.com/users/Jazzssmine/followers", "following_url": "https://api.github.com/users/Jazzssmine/following{/other_user}", "gists_url": "https://api.github.com/users/Jazzssmine/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jazzssmine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jazzssmine/subscriptions", "organizations_url": "https://api.github.com/users/Jazzssmine/orgs", "repos_url": "https://api.github.com/users/Jazzssmine/repos", "events_url": "https://api.github.com/users/Jazzssmine/events{/privacy}", "received_events_url": "https://api.github.com/users/Jazzssmine/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-11-03T00:35:51Z", "updated_at": "2020-11-06T11:08:58Z", "closed_at": "2020-11-06T08:26:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nI'm running classifier and got the following error:\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/allennlp/commands/__init__.py\", line 117, in main\r\n    import_module_and_submodules(package_name)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/allennlp/common/util.py\", line 351, in import_module_and_submodules\r\n    import_module_and_submodules(subpackage)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/allennlp/common/util.py\", line 340, in import_module_and_submodules\r\n    module = importlib.import_module(package_name)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/Users/wangyian/Desktop/Jasmine/EPFL/semester_project_I/ALLEN/allen_tweet/dont_stop_pretraining/models/__init__.py\", line 1, in <module>\r\n    from dont_stop_pretraining.models.basic_classifier_with_f1 import BasicClassifierWithF1\r\n  File \"/Users/wangyian/Desktop/Jasmine/EPFL/semester_project_I/ALLEN/allen_tweet/dont_stop_pretraining/models/basic_classifier_with_f1.py\", line 15, in <module>\r\n    class BasicClassifierWithF1(Model):\r\n  File \"/Users/wangyian/Desktop/Jasmine/EPFL/semester_project_I/ALLEN/allen_tweet/dont_stop_pretraining/models/basic_classifier_with_f1.py\", line 149, in BasicClassifierWithF1\r\n    def decode(self, output_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/overrides/overrides.py\", line 67, in overrides\r\n    raise AssertionError('No super class method found for \"%s\"' % method.__name__)\r\nAssertionError: No super class method found for \"decode\"\r\n```\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n<details>\r\n<summary><b>code of basic_classifier_with_f1</b></summary>\r\n<p>\r\n`@Model.register(\"basic_classifier_with_f1\")\r\nclass BasicClassifierWithF1(Model):\r\n    \"\"\"\r\n    This ``Model`` implements a basic text classifier. After embedding the text into\r\n    a text field, we will optionally encode the embeddings with a ``Seq2SeqEncoder``. The\r\n    resulting sequence is pooled using a ``Seq2VecEncoder`` and then passed to\r\n    a linear classification layer, which projects into the label space. If a\r\n    ``Seq2SeqEncoder`` is not provided, we will pass the embedded text directly to the\r\n    ``Seq2VecEncoder``.\r\n\r\n    This model additionally provides F1 measure for classification.\r\n    \r\n    Parameters\r\n    ----------\r\n    vocab : ``Vocabulary``\r\n    text_field_embedder : ``TextFieldEmbedder``\r\n        Used to embed the input text into a ``TextField``\r\n    seq2seq_encoder : ``Seq2SeqEncoder``, optional (default=``None``)\r\n        Optional Seq2Seq encoder layer for the input text.\r\n    seq2vec_encoder : ``Seq2VecEncoder``\r\n        Required Seq2Vec encoder layer. If `seq2seq_encoder` is provided, this encoder\r\n        will pool its output. Otherwise, this encoder will operate directly on the output\r\n        of the `text_field_embedder`.\r\n    dropout : ``float``, optional (default = ``None``)\r\n        Dropout percentage to use.\r\n    num_labels: ``int``, optional (default = ``None``)\r\n        Number of labels to project to in classification layer. By default, the classification layer will\r\n        project to the size of the vocabulary namespace corresponding to labels.\r\n    label_namespace: ``str``, optional (default = \"labels\")\r\n        Vocabulary namespace corresponding to labels. By default, we use the \"labels\" namespace.\r\n    initializer : ``InitializerApplicator``, optional (default=``InitializerApplicator()``)\r\n        If provided, will be used to initialize the model parameters.\r\n    regularizer : ``RegularizerApplicator``, optional (default=``None``)\r\n        If provided, will be used to calculate the regularization penalty during training.\r\n    \"\"\"\r\n\r\n    def __init__(\r\n        self,\r\n        vocab: Vocabulary,\r\n        text_field_embedder: TextFieldEmbedder,\r\n        seq2vec_encoder: Seq2VecEncoder,\r\n        feedforward_layer: FeedForward,\r\n        seq2seq_encoder: Seq2SeqEncoder = None,\r\n        dropout: float = None,\r\n        num_labels: int = None,\r\n        label_namespace: str = \"labels\",\r\n        initializer: InitializerApplicator = InitializerApplicator(),\r\n        regularizer: Optional[RegularizerApplicator] = None,\r\n    ) -> None:\r\n\r\n        super().__init__(vocab, regularizer)\r\n        self._text_field_embedder = text_field_embedder\r\n\r\n        if seq2seq_encoder:\r\n            self._seq2seq_encoder = seq2seq_encoder\r\n        else:\r\n            self._seq2seq_encoder = None\r\n\r\n        self._seq2vec_encoder = seq2vec_encoder\r\n        self._classifier_input_dim = self._seq2vec_encoder.get_output_dim()\r\n\r\n        if dropout:\r\n            self._dropout = torch.nn.Dropout(dropout)\r\n        else:\r\n            self._dropout = None\r\n\r\n        self._label_namespace = label_namespace\r\n\r\n        if num_labels:\r\n            self._num_labels = num_labels\r\n        else:\r\n            self._num_labels = vocab.get_vocab_size(namespace=self._label_namespace)\r\n        self._feedforward_layer = feedforward_layer\r\n        self._classification_layer = torch.nn.Linear(self._classifier_input_dim, self._num_labels)\r\n        self._accuracy = CategoricalAccuracy()\r\n        self._label_f1_metrics: Dict[str, F1Measure] = {}\r\n        for i in range(self._num_labels):\r\n            self._label_f1_metrics[vocab.get_token_from_index(index=i, namespace=\"labels\")] = F1Measure(positive_label=i)\r\n        self._loss = torch.nn.CrossEntropyLoss()\r\n        initializer(self)\r\n\r\n    def forward(  # type: ignore\r\n        self, tokens: Dict[str, torch.LongTensor], label: torch.IntTensor = None\r\n    ) -> Dict[str, torch.Tensor]:\r\n\r\n        \"\"\"\r\n        Parameters\r\n        ----------\r\n        tokens : Dict[str, torch.LongTensor]\r\n            From a ``TextField``\r\n        label : torch.IntTensor, optional (default = None)\r\n            From a ``LabelField``\r\n\r\n        Returns\r\n        -------\r\n        An output dictionary consisting of:\r\n\r\n        logits : torch.FloatTensor\r\n            A tensor of shape ``(batch_size, num_labels)`` representing\r\n            unnormalized log probabilities of the label.\r\n        probs : torch.FloatTensor\r\n            A tensor of shape ``(batch_size, num_labels)`` representing\r\n            probabilities of the label.\r\n        loss : torch.FloatTensor, optional\r\n            A scalar loss to be optimised.\r\n        \"\"\"\r\n        embedded_text = self._text_field_embedder(tokens)\r\n        mask = get_text_field_mask(tokens).float()\r\n\r\n        if self._seq2seq_encoder:\r\n            embedded_text = self._seq2seq_encoder(embedded_text, mask=mask)\r\n\r\n        embedded_text = self._seq2vec_encoder(embedded_text, mask=mask)\r\n\r\n        if self._dropout:\r\n            embedded_text = self._dropout(embedded_text)\r\n\r\n        feedforward_output = self._feedforward_layer(embedded_text)\r\n\r\n        logits = self._classification_layer(feedforward_output)\r\n        probs = torch.nn.functional.softmax(logits, dim=-1)\r\n\r\n        output_dict = {\"logits\": logits, \"probs\": probs}\r\n\r\n        if label is not None:\r\n            loss = self._loss(logits, label.long().view(-1))\r\n            output_dict[\"loss\"] = loss\r\n            for i in range(self._num_labels):\r\n                metric = self._label_f1_metrics[self.vocab.get_token_from_index(index=i, namespace=\"labels\")]\r\n                metric(probs, label)\r\n            self._accuracy(logits, label)\r\n\r\n        return output_dict\r\n\r\n    @overrides\r\n    def decode(self, output_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\r\n        \"\"\"\r\n        Does a simple argmax over the probabilities, converts index to string label, and\r\n        add ``\"label\"`` key to the dictionary with the result.\r\n        \"\"\"\r\n        predictions = output_dict[\"probs\"]\r\n        if predictions.dim() == 2:\r\n            predictions_list = [predictions[i] for i in range(predictions.shape[0])]\r\n        else:\r\n            predictions_list = [predictions]\r\n        classes = []\r\n        for prediction in predictions_list:\r\n            label_idx = prediction.argmax(dim=-1).item()\r\n            '''label_str = self.vocab.get_index_to_token_vocabulary(self._label_namespace).get(\r\n                label_idx, str(label_idx)\r\n            )'''\r\n            label_str = self.vocab.get_token_from_index(label_idx, namespace=\"labels\")\r\n            classes.append(label_str)\r\n        output_dict[\"label\"] = classes\r\n        return output_dict\r\n\r\n    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\r\n        metric_dict = {}\r\n        sum_f1 = 0.0\r\n        for name, metric in self._label_f1_metrics.items():\r\n            metric_val = metric.get_metric(reset)\r\n            sum_f1 += metric_val[2]\r\n        names = list(self._label_f1_metrics.keys())\r\n        total_len = len(names)\r\n        average_f1 = sum_f1 / total_len\r\n        metric_dict['f1'] = average_f1\r\n        metric_dict['accuracy'] = self._accuracy.get_metric(reset)\r\n        return metric_dict\r\n`\r\n</p>\r\n</details>\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\nabsl-py==0.11.0\r\naltair==4.1.0\r\nappnope==0.1.0\r\nargon2-cffi==20.1.0\r\nastor==0.8.1\r\nasync-generator==1.10\r\nattrs==20.2.0\r\nbackcall==0.2.0\r\nbase58==2.0.1\r\nbleach==3.2.1\r\nblinker==1.4\r\nboto3==1.16.4\r\nbotocore==1.19.4\r\ncachetools==4.1.1\r\ncertifi==2020.6.20\r\ncffi==1.14.3\r\nchardet==3.0.4\r\nclick==7.1.2\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\nentrypoints==0.3\r\nenum-compat==0.0.3\r\ngitdb==4.0.5\r\nGitPython==3.1.11\r\ngoogle-auth==1.23.0\r\ngoogle-auth-oauthlib==0.4.2\r\ngrpcio==1.33.2\r\nidna==2.10\r\nipykernel==5.3.4\r\nipython==7.18.1\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\njedi==0.17.2\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.17.0\r\njsonschema==3.2.0\r\njupyter-client==6.1.7\r\njupyter-core==4.6.3\r\njupyterlab-pygments==0.1.2\r\nMarkdown==3.3.3\r\nMarkupSafe==1.1.1\r\nmistune==0.8.4\r\nnbclient==0.5.1\r\nnbconvert==6.0.7\r\nnbformat==5.0.8\r\nnest-asyncio==1.4.2\r\nnotebook==6.1.4\r\nnumpy==1.19.2\r\noauthlib==3.1.0\r\npackaging==20.4\r\npandas==1.1.3\r\npandocfilters==1.4.3\r\nparso==0.7.1\r\npathtools==0.1.2\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==8.0.1\r\nprometheus-client==0.8.0\r\nprompt-toolkit==3.0.8\r\nprotobuf==3.13.0\r\nptyprocess==0.6.0\r\npyarrow==2.0.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\npydeck==0.5.0\r\nPygments==2.7.2\r\npyparsing==2.4.7\r\npyrsistent==0.17.3\r\npython-dateutil==2.8.1\r\npytz==2020.1\r\npyzmq==19.0.2\r\nrequests==2.24.0\r\nrequests-oauthlib==1.3.0\r\nrsa==4.6\r\ns3transfer==0.3.3\r\nscikit-learn==0.23.2\r\nscipy==1.5.3\r\nSend2Trash==1.5.0\r\nseqeval==1.2.2\r\nsix==1.15.0\r\nsmmap==3.0.4\r\ntensorboard==2.3.0\r\ntensorboard-plugin-wit==1.7.0\r\ntensorboardX==2.1\r\nterminado==0.9.1\r\ntestpath==0.4.4\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.9.2\r\ntoml==0.10.1\r\ntoolz==0.11.1\r\ntornado==6.0.4\r\ntqdm==4.51.0\r\ntraitlets==5.0.5\r\ntzlocal==2.1\r\nurllib3==1.25.11\r\nvalidators==0.18.1\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.5.1\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4767/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4767/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4757", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4757/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4757/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4757/events", "html_url": "https://github.com/allenai/allennlp/issues/4757", "id": 731193111, "node_id": "MDU6SXNzdWU3MzExOTMxMTE=", "number": 4757, "title": "PretrainedTransformerTokenizer fails when disabling \"fast\" tokenizer", "user": {"login": "mklimasz", "id": 16540593, "node_id": "MDQ6VXNlcjE2NTQwNTkz", "avatar_url": "https://avatars.githubusercontent.com/u/16540593?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mklimasz", "html_url": "https://github.com/mklimasz", "followers_url": "https://api.github.com/users/mklimasz/followers", "following_url": "https://api.github.com/users/mklimasz/following{/other_user}", "gists_url": "https://api.github.com/users/mklimasz/gists{/gist_id}", "starred_url": "https://api.github.com/users/mklimasz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mklimasz/subscriptions", "organizations_url": "https://api.github.com/users/mklimasz/orgs", "repos_url": "https://api.github.com/users/mklimasz/repos", "events_url": "https://api.github.com/users/mklimasz/events{/privacy}", "received_events_url": "https://api.github.com/users/mklimasz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-10-28T07:46:07Z", "updated_at": "2020-10-28T19:38:48Z", "closed_at": "2020-10-28T19:38:48Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [X] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [X] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [X] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [X] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [X] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [X] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [X] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [X] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [X] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [X] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n**Tested on 1.2.0rc1 and master**\r\nIntra work tokenizer doesn't work when we deliberately set use fast tokenizer to false (not sure if it's new transformers change).\r\nI think that setting return_token_type_ids to None instead of False is solution here. \r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"bug_example.py\", line 4, in <module>\r\n    tokenizer_kwargs={\"use_fast\": False}).intra_word_tokenize([\"My\", \"text\", \"will\"])\r\n  File \"X/venv/lib/python3.6/site-packages/allennlp-1.2.0rc1-py3.6.egg/allennlp/data/tokenizers/pretrained_transformer_tokenizer.py\", line 387, in intra_word_tokenize\r\n    tokens, offsets = self._intra_word_tokenize(string_tokens)\r\n  File \"X/venv/lib/python3.6/site-packages/allennlp-1.2.0rc1-py3.6.egg/allennlp/data/tokenizers/pretrained_transformer_tokenizer.py\", line 354, in _intra_word_tokenize\r\n    return_token_type_ids=False,\r\n  File \"X/venv/lib/python3.6/site-packages/transformers-3.4.0-py3.6.egg/transformers/tokenization_utils_base.py\", line 2229, in encode_plus\r\n    **kwargs,\r\n  File \"X/venv/lib/python3.6/site-packages/transformers-3.4.0-py3.6.egg/transformers/tokenization_utils.py\", line 490, in _encode_plus\r\n    verbose=verbose,\r\n  File \"X/venv/lib/python3.6/site-packages/transformers-3.4.0-py3.6.egg/transformers/tokenization_utils_base.py\", line 2617, in prepare_for_model\r\n    \"Asking to return token_type_ids while setting add_special_tokens to False \"\r\nValueError: Asking to return token_type_ids while setting add_special_tokens to False results in an undefined behavior. Please set add_special_tokens to True or set return_token_type_ids to None.\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\nNot to my knowledge\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\nUbuntu 18.04 LTS\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n3.6.9 and 3.8.0\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.9.0\r\nallennlp==1.2.0rc1\r\nattrs==20.2.0\r\nblis==0.4.1\r\nboto3==1.16.5\r\nbotocore==1.19.5\r\ncached-property==1.5.2\r\ncachetools==4.1.1\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\nchardet==3.0.4\r\nclick==7.1.2\r\nconllu==2.3.2\r\ncymem==2.0.3\r\ndataclasses==0.5\r\ndataclasses-json==0.5.2\r\nen-core-web-sm==2.3.1\r\nfilelock==3.0.12\r\nfuture==0.18.2\r\ngoogle-auth==1.22.1\r\ngoogle-auth-oauthlib==0.4.1\r\ngrpcio==1.33.1\r\nh5py==3.0.0rc1\r\nidna==2.10\r\nimportlib-metadata==2.0.0\r\niniconfig==1.1.1\r\njmespath==0.10.0\r\njoblib==0.14.1\r\njsonnet==0.15.0\r\njsonpickle==1.4.1\r\nMarkdown==3.3.3\r\nmarshmallow==3.8.0\r\nmarshmallow-enum==1.5.1\r\nmurmurhash==1.0.2\r\nmypy-extensions==0.4.3\r\nnltk==3.5\r\nnumpy==1.19.2\r\noauthlib==3.1.0\r\noverrides==3.1.0\r\npackaging==20.4\r\npkg-resources==0.0.0\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprotobuf==4.0.0rc2\r\npy==1.9.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npyparsing==3.0.0a2\r\npytest==6.1.1\r\npython-dateutil==2.8.1\r\nregex==2020.10.23\r\nrequests==2.23.0\r\nrequests-oauthlib==1.3.0\r\nrsa==4.6\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.2\r\nscipy==1.5.3\r\nsentencepiece==0.1.94\r\nsix==1.15.0\r\nspacy==2.3.2\r\nsrsly==1.0.2\r\nstringcase==1.2.0\r\ntensorboard==2.1.0\r\ntensorboardX==2.1\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.9.2\r\ntoml==0.10.1\r\ntorch==1.6.0\r\ntqdm==4.43.0\r\ntransformers==3.4.0\r\ntyping-extensions==3.7.4.3\r\ntyping-inspect==0.6.0\r\nurllib3==1.25.11\r\nwasabi==0.8.0\r\nWerkzeug==1.0.1\r\nzipp==3.4.0\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp.data.tokenizers import PretrainedTransformerTokenizer\r\n\r\nPretrainedTransformerTokenizer(\"bert-base-cased\",\r\n                               tokenizer_kwargs={\"use_fast\": False}).intra_word_tokenize([\"My\", \"text\", \"will\"])\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4757/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4757/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4755", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4755/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4755/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4755/events", "html_url": "https://github.com/allenai/allennlp/issues/4755", "id": 730958934, "node_id": "MDU6SXNzdWU3MzA5NTg5MzQ=", "number": 4755, "title": "Installation issues due to PyPI version of dataclasses", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/16", "html_url": "https://github.com/allenai/allennlp/milestone/16", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/16/labels", "id": 6087040, "node_id": "MDk6TWlsZXN0b25lNjA4NzA0MA==", "number": 16, "title": "2.1", "description": "", "creator": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 22, "state": "closed", "created_at": "2020-11-09T18:44:24Z", "updated_at": "2021-02-25T22:13:18Z", "due_on": "2021-02-26T08:00:00Z", "closed_at": "2021-02-25T22:13:18Z"}, "comments": 8, "created_at": "2020-10-28T00:00:02Z", "updated_at": "2021-02-22T22:13:12Z", "closed_at": "2021-02-22T22:13:12Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "After installing the latest build with PyTorch 1.7 in a Python 3.7 or 3.8 environment, I'm getting this error after running `allennlp test-install`:\r\n\r\n```\r\n$> allennlp test-install\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/allennlp\", line 5, in <module>\r\n    from allennlp.__main__ import run\r\n  File \"/usr/local/lib/python3.8/site-packages/allennlp/__main__.py\", line 30, in <module>\r\n    from allennlp.commands import main  # noqa\r\n  File \"/usr/local/lib/python3.8/site-packages/allennlp/commands/__init__.py\", line 9, in <module>\r\n    from allennlp.commands.build_vocab import BuildVocab\r\n  File \"/usr/local/lib/python3.8/site-packages/allennlp/commands/build_vocab.py\", line 14, in <module>\r\n    from allennlp.commands.subcommand import Subcommand\r\n  File \"/usr/local/lib/python3.8/site-packages/allennlp/commands/subcommand.py\", line 10, in <module>\r\n    from allennlp.common import Registrable\r\n  File \"/usr/local/lib/python3.8/site-packages/allennlp/common/__init__.py\", line 1, in <module>\r\n    from allennlp.common.from_params import FromParams\r\n  File \"/usr/local/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 22, in <module>\r\n    from allennlp.common.lazy import Lazy\r\n  File \"/usr/local/lib/python3.8/site-packages/allennlp/common/lazy.py\", line 4, in <module>\r\n    from allennlp.common.params import Params\r\n  File \"/usr/local/lib/python3.8/site-packages/allennlp/common/params.py\", line 33, in <module>\r\n    from allennlp.common.file_utils import cached_path\r\n  File \"/usr/local/lib/python3.8/site-packages/allennlp/common/file_utils.py\", line 545, in <module>\r\n    class _Meta:\r\n  File \"/usr/local/lib/python3.8/site-packages/dataclasses.py\", line 958, in dataclass\r\n    return wrap(_cls)\r\n  File \"/usr/local/lib/python3.8/site-packages/dataclasses.py\", line 950, in wrap\r\n    return _process_class(cls, init, repr, eq, order, unsafe_hash, frozen)\r\n  File \"/usr/local/lib/python3.8/site-packages/dataclasses.py\", line 800, in _process_class\r\n    cls_fields = [_get_field(cls, name, type)\r\n  File \"/usr/local/lib/python3.8/site-packages/dataclasses.py\", line 800, in <listcomp>\r\n    cls_fields = [_get_field(cls, name, type)\r\n  File \"/usr/local/lib/python3.8/site-packages/dataclasses.py\", line 659, in _get_field\r\n    if (_is_classvar(a_type, typing)\r\n  File \"/usr/local/lib/python3.8/site-packages/dataclasses.py\", line 550, in _is_classvar\r\n    return type(a_type) is typing._ClassVar\r\nAttributeError: module 'typing' has no attribute '_ClassVar'\r\n```\r\n\r\nThe issue only happens when the PyPI version of `dataclasses` is installed. The thing is, it shouldn't be installed when using Python >= 3.7, but it is because PyTorch 1.7 lists `dataclasses` as an **unconditional** dependency. This has since been fixed in PyTorch, i.e. `dataclasses` is now properly listed as a **conditional** dependency for Python < 3.7, so with the next PyTorch release we shouldn't see this issue.\r\n\r\nFor now I think the best we can do is keep this issue open so other people can find it and add a note in the README that you should `pip uninstall -y dataclasses` if using Python >= 3.7. I made a PR for that: https://github.com/allenai/allennlp/pull/4754", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4755/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4755/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4750", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4750/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4750/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4750/events", "html_url": "https://github.com/allenai/allennlp/issues/4750", "id": 729758959, "node_id": "MDU6SXNzdWU3Mjk3NTg5NTk=", "number": 4750, "title": "trainer_callbacks parameter missing from GradientDescentTrainer.from_partial_objects", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "02b8d1", "default": false, "description": ""}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/13", "html_url": "https://github.com/allenai/allennlp/milestone/13", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/13/labels", "id": 5535962, "node_id": "MDk6TWlsZXN0b25lNTUzNTk2Mg==", "number": 13, "title": "1.2", "description": "", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 24, "state": "closed", "created_at": "2020-06-12T16:16:52Z", "updated_at": "2020-11-02T18:45:36Z", "due_on": null, "closed_at": "2020-11-02T18:45:36Z"}, "comments": 0, "created_at": "2020-10-26T17:23:04Z", "updated_at": "2020-10-26T18:44:22Z", "closed_at": "2020-10-26T18:44:22Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Brought to our attention by @jacobdanovitch [here](https://github.com/allenai/allennlp/issues/4675#issuecomment-716193673).", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4750/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4750/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4749", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4749/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4749/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4749/events", "html_url": "https://github.com/allenai/allennlp/issues/4749", "id": 729547457, "node_id": "MDU6SXNzdWU3Mjk1NDc0NTc=", "number": 4749, "title": "Docker image instructions or command incorrect", "user": {"login": "theashworld", "id": 8036330, "node_id": "MDQ6VXNlcjgwMzYzMzA=", "avatar_url": "https://avatars.githubusercontent.com/u/8036330?v=4", "gravatar_id": "", "url": "https://api.github.com/users/theashworld", "html_url": "https://github.com/theashworld", "followers_url": "https://api.github.com/users/theashworld/followers", "following_url": "https://api.github.com/users/theashworld/following{/other_user}", "gists_url": "https://api.github.com/users/theashworld/gists{/gist_id}", "starred_url": "https://api.github.com/users/theashworld/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/theashworld/subscriptions", "organizations_url": "https://api.github.com/users/theashworld/orgs", "repos_url": "https://api.github.com/users/theashworld/repos", "events_url": "https://api.github.com/users/theashworld/events{/privacy}", "received_events_url": "https://api.github.com/users/theashworld/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-10-26T13:07:36Z", "updated_at": "2020-10-26T16:40:49Z", "closed_at": "2020-10-26T16:40:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ X] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [ X] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ X] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [X ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ X] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [X ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [X ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nAs per the page here http://docs.allennlp.org/v1.2.0rc1/#installing-using-docker\r\n\r\nRunning the Docker image\r\nYou can run the image with docker run --rm -it allennlp/allennlp:latest. The --rm flag cleans up the image on exit and the -it flags make the session interactive so you can use the bash shell the Docker image starts.\r\n\r\nhowever, when I run that command \r\n`docker run --gpus all  --rm -it -v $HOME/.allennlp:/root/.allennlp allennlp/allennlp:latest`\r\n\r\n```\r\nStatus: Downloaded newer image for allennlp/allennlp:latest\r\nusage: allennlp [-h] [--version]  ...\r\n\r\nRun AllenNLP\r\n\r\noptional arguments:\r\n  -h, --help     show this help message and exit\r\n  --version      show program's version number and exit\r\n\r\nCommands:\r\n\r\n    build-vocab  Build a vocabulary from an experiment config file.\r\n    cached-path  Cache remote files to the AllenNLP cache.\r\n    evaluate     Evaluate the specified model + dataset.\r\n    find-lr      Find a learning rate range.\r\n    predict      Use a trained model to make predictions.\r\n    print-results\r\n                 Print results from allennlp serialization directories to the console.\r\n    test-install\r\n                 Test AllenNLP installation.\r\n    train        Train a model.\r\n```\r\n\r\nThere is no interactive prompt\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4749/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4749/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4745", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4745/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4745/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4745/events", "html_url": "https://github.com/allenai/allennlp/issues/4745", "id": 727646549, "node_id": "MDU6SXNzdWU3Mjc2NDY1NDk=", "number": 4745, "title": "Interpret broken for GPT2 NextTokenLM", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/15", "html_url": "https://github.com/allenai/allennlp/milestone/15", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/15/labels", "id": 5996193, "node_id": "MDk6TWlsZXN0b25lNTk5NjE5Mw==", "number": 15, "title": "1.4", "description": "", "creator": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 9, "state": "closed", "created_at": "2020-10-15T21:34:47Z", "updated_at": "2021-02-12T00:44:07Z", "due_on": null, "closed_at": "2021-02-12T00:44:07Z"}, "comments": 1, "created_at": "2020-10-22T19:03:04Z", "updated_at": "2021-01-07T23:57:15Z", "closed_at": "2021-01-07T23:57:15Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "<img width=\"1138\" alt=\"image\" src=\"https://user-images.githubusercontent.com/8812459/96914373-c08c5800-1459-11eb-9e87-0f6a2dda6e40.png\">\r\n\r\nSteps to reproduce:\r\n\r\n```python\r\nfrom allennlp.interpret.saliency_interpreters import (\r\n    SimpleGradient,\r\n)\r\nfrom allennlp_models.pretrained import load_predictor\r\n\r\npredictor = load_predictor(\"lm-next-token-lm-gpt2\", overrides={\r\n    \"dataset_reader.max_tokens\": 512,\r\n    \"model.beam_search_generator\": {\r\n        \"type\": \"transformer\",\r\n        \"beam_search\": {\r\n            \"end_index\": 50256,\r\n            \"max_steps\": 5,\r\n            \"beam_size\": 5,\r\n        }\r\n    }\r\n})\r\ninterpreter = SimpleGradient(predictor)\r\ninterpreter.saliency_interpret_from_json({\"sentence\": \"Hi there\"})\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4745/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4745/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4739", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4739/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4739/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4739/events", "html_url": "https://github.com/allenai/allennlp/issues/4739", "id": 725051021, "node_id": "MDU6SXNzdWU3MjUwNTEwMjE=", "number": 4739, "title": "Potential bug: The maxpool in cnn_encoder can be triggered by pad tokens.", "user": {"login": "MichalMalyska", "id": 12971408, "node_id": "MDQ6VXNlcjEyOTcxNDA4", "avatar_url": "https://avatars.githubusercontent.com/u/12971408?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MichalMalyska", "html_url": "https://github.com/MichalMalyska", "followers_url": "https://api.github.com/users/MichalMalyska/followers", "following_url": "https://api.github.com/users/MichalMalyska/following{/other_user}", "gists_url": "https://api.github.com/users/MichalMalyska/gists{/gist_id}", "starred_url": "https://api.github.com/users/MichalMalyska/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MichalMalyska/subscriptions", "organizations_url": "https://api.github.com/users/MichalMalyska/orgs", "repos_url": "https://api.github.com/users/MichalMalyska/repos", "events_url": "https://api.github.com/users/MichalMalyska/events{/privacy}", "received_events_url": "https://api.github.com/users/MichalMalyska/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2020-10-19T23:30:31Z", "updated_at": "2020-11-05T23:50:04Z", "closed_at": "2020-11-05T23:50:04Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n\r\nWhen using a text_field_embedder -> cnn_encoder (without seq2seq_encoder), the output of the embedder (and mask) get fed directly into the cnn_encoder. The pad tokens will get masked (set to 0), but it's still possible that after applying the mask followed by the CNN, the PAD tokens are those with highest activations. This could lead to the same exact datapoint getting different predictions if's part of a batch vs single prediction.\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n## Environment\r\n\r\nOS:  NA\r\n\r\nPython version: NA\r\n\r\n## Steps to reproduce\r\n\r\nThis can be reproduced by replacing\r\nhttps://github.com/allenai/allennlp/blob/00bb6c59b3ac8fdc78dfe8d5b9b645ce8ed085c0/allennlp/modules/seq2vec_encoders/cnn_encoder.py#L113\r\n\r\n```\r\nfilter_outputs.append(self._activation(convolution_layer(tokens)).max(dim=2)[0])\r\n```\r\nwith\r\n\r\n```\r\nactivated_outputs, max_indices = self._activation(convolution_layer(tokens)).max(dim=2)\r\n```\r\n\r\nand checking the indices for the same example inside of a batch vs unpadded. \r\n\r\n## Possible solution:\r\n\r\nWe could resolve this by adding a large negative value to all CNN outputs for masked tokens, similarly to what they do in the transformers library (https://github.com/huggingface/transformers/issues/542, https://github.com/huggingface/transformers/blob/c912ba5f69a47396244c64deada5c2b8a258e2b8/src/transformers/modeling_bert.py#L262), but I have not been able to figure out how to do this efficiently.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4739/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 1}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4739/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4736", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4736/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4736/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4736/events", "html_url": "https://github.com/allenai/allennlp/issues/4736", "id": 723904238, "node_id": "MDU6SXNzdWU3MjM5MDQyMzg=", "number": 4736, "title": "logging information gets truncated for 1.1.0", "user": {"login": "niansong1996", "id": 10934810, "node_id": "MDQ6VXNlcjEwOTM0ODEw", "avatar_url": "https://avatars.githubusercontent.com/u/10934810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/niansong1996", "html_url": "https://github.com/niansong1996", "followers_url": "https://api.github.com/users/niansong1996/followers", "following_url": "https://api.github.com/users/niansong1996/following{/other_user}", "gists_url": "https://api.github.com/users/niansong1996/gists{/gist_id}", "starred_url": "https://api.github.com/users/niansong1996/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/niansong1996/subscriptions", "organizations_url": "https://api.github.com/users/niansong1996/orgs", "repos_url": "https://api.github.com/users/niansong1996/repos", "events_url": "https://api.github.com/users/niansong1996/events{/privacy}", "received_events_url": "https://api.github.com/users/niansong1996/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2020-10-18T04:49:47Z", "updated_at": "2020-10-26T16:35:21Z", "closed_at": "2020-10-26T16:35:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am experiencing very weird logging issues with allennlp 1.1.0. The logging information gets truncated and it's refreshing every ~10s and burst out many lines all at once, see the screenshot below:\r\n![image](https://user-images.githubusercontent.com/10934810/96358986-51baa200-10db-11eb-8889-9ec6df21bbbc.png)\r\n\r\nAnd this is the behavior of the same run with allennlp 1.1.0rc1, which is far more pleasant for me to monitor the process:\r\n![image](https://user-images.githubusercontent.com/10934810/96359003-89294e80-10db-11eb-8650-f8b5ea2b3b1f.png)", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4736/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4736/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4725", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4725/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4725/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4725/events", "html_url": "https://github.com/allenai/allennlp/issues/4725", "id": 719514365, "node_id": "MDU6SXNzdWU3MTk1MTQzNjU=", "number": 4725, "title": "Dependabot is running on forks", "user": {"login": "matt-gardner", "id": 3291951, "node_id": "MDQ6VXNlcjMyOTE5NTE=", "avatar_url": "https://avatars.githubusercontent.com/u/3291951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matt-gardner", "html_url": "https://github.com/matt-gardner", "followers_url": "https://api.github.com/users/matt-gardner/followers", "following_url": "https://api.github.com/users/matt-gardner/following{/other_user}", "gists_url": "https://api.github.com/users/matt-gardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/matt-gardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matt-gardner/subscriptions", "organizations_url": "https://api.github.com/users/matt-gardner/orgs", "repos_url": "https://api.github.com/users/matt-gardner/repos", "events_url": "https://api.github.com/users/matt-gardner/events{/privacy}", "received_events_url": "https://api.github.com/users/matt-gardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-10-12T16:40:20Z", "updated_at": "2020-10-27T16:39:54Z", "closed_at": "2020-10-27T16:39:54Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "See [here](https://github.com/matt-gardner/allennlp/pull/4) for a PR that was created by dependabot on my fork.  My guess is that this is because of [this file](https://github.com/allenai/allennlp/blob/master/.github/dependabot.yml), but it wasn't obvious to me how to disable this on forks (nothing in the [documentation](https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/configuration-options-for-dependency-updates) that I could easily find, either).", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4725/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4725/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4715", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4715/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4715/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4715/events", "html_url": "https://github.com/allenai/allennlp/issues/4715", "id": 716716178, "node_id": "MDU6SXNzdWU3MTY3MTYxNzg=", "number": 4715, "title": "Rouge metric incorrectly computed with distributed training", "user": {"login": "vikigenius", "id": 12724810, "node_id": "MDQ6VXNlcjEyNzI0ODEw", "avatar_url": "https://avatars.githubusercontent.com/u/12724810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vikigenius", "html_url": "https://github.com/vikigenius", "followers_url": "https://api.github.com/users/vikigenius/followers", "following_url": "https://api.github.com/users/vikigenius/following{/other_user}", "gists_url": "https://api.github.com/users/vikigenius/gists{/gist_id}", "starred_url": "https://api.github.com/users/vikigenius/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vikigenius/subscriptions", "organizations_url": "https://api.github.com/users/vikigenius/orgs", "repos_url": "https://api.github.com/users/vikigenius/repos", "events_url": "https://api.github.com/users/vikigenius/events{/privacy}", "received_events_url": "https://api.github.com/users/vikigenius/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "02b8d1", "default": false, "description": ""}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/13", "html_url": "https://github.com/allenai/allennlp/milestone/13", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/13/labels", "id": 5535962, "node_id": "MDk6TWlsZXN0b25lNTUzNTk2Mg==", "number": 13, "title": "1.2", "description": "", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 24, "state": "closed", "created_at": "2020-06-12T16:16:52Z", "updated_at": "2020-11-02T18:45:36Z", "due_on": null, "closed_at": "2020-11-02T18:45:36Z"}, "comments": 2, "created_at": "2020-10-07T17:23:47Z", "updated_at": "2020-10-08T05:22:20Z", "closed_at": "2020-10-08T05:22:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you have a question rather than a bug, please ask on [Stack Overflow](https://stackoverflow.com/questions/tagged/allennlp) rather than posting an issue here.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nTraining the same model with and without distributed training produces drastically different metrics and incorrect metrics with distributed.\r\n\r\nIn fact distributed training on 8 GPUs gives me scores > 1 which is obviously incorrect.\r\n\r\n<details>\r\n<summary><b>Multi GPU metrics:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n  \"validation_ROUGE-1_R\": 3.7029976844787598,\r\n  \"validation_ROUGE-2_R\": 1.9398850351572037,\r\n  \"validation_ROUGE-1_P\": 4.3116472363471985,\r\n  \"validation_ROUGE-2_P\": 2.3042131861050925,\r\n  \"validation_ROUGE-1_F1\": 3.819778541723887,\r\n  \"validation_ROUGE-2_F1\": 2.039711813131968,\r\n  \"validation_ROUGE-L\": 3.579911470413208,\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n<details>\r\n<summary><b>Single GPU metrics:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n  \"validation_ROUGE-1_R\": 0.49840065422148055,\r\n  \"validation_ROUGE-2_R\": 0.28016004520356264,\r\n  \"validation_ROUGE-1_P\": 0.5445739355913551,\r\n  \"validation_ROUGE-2_P\": 0.3068941746277846,\r\n  \"validation_ROUGE-1_F1\": 0.5003892512410818,\r\n  \"validation_ROUGE-2_F1\": 0.28298027227105127,\r\n  \"validation_ROUGE-L\": 0.4661126545409945,\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- #4050 is a possibly related issue\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: GNU/Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalabaster==0.7.12\r\nalembic==1.4.3\r\n-e git+https://github.com/allenai/allennlp.git@edcb6d3466d2c4263f1e6a5731c6ace5358f47e8#egg=allennlp\r\n-e git+https://github.com/allenai/allennlp-models.git@a330876f95cfec99f0ab724fbc0237f7d1f3288c#egg=allennlp_models\r\napache-airflow==1.10.12\r\napispec==1.3.3\r\nargcomplete==1.12.0\r\nargon2-cffi==20.1.0\r\nastor==0.8.1\r\nasync-generator==1.10\r\nattrs==19.3.0\r\nBabel==2.8.0\r\nbackcall==0.2.0\r\nbandit==1.6.2\r\nbert-serving-client==1.10.0\r\nbleach==3.2.1\r\nblis==0.4.1\r\nboto3==1.15.4\r\nbotocore==1.18.4\r\ncached-property==1.5.2\r\ncatalogue==1.0.0\r\ncattrs==1.0.0\r\ncertifi==2020.4.5.2\r\ncffi==1.14.3\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncolorama==0.4.3\r\ncolorlog==4.0.2\r\nconfigparser==3.5.3\r\nconllu==4.2\r\ncoverage==5.1\r\ncroniter==0.3.34\r\ncymem==2.0.3\r\ndarglint==1.4.1\r\ndatasets==1.0.1\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndictdiffer==0.8.1\r\ndill==0.3.2\r\ndnspython==2.0.0\r\ndoc8==0.8.1\r\ndocutils==0.16\r\ndparse==0.5.1\r\nemail-validator==1.1.1\r\nentrypoints==0.3\r\neradicate==1.0\r\nfilelock==3.0.12\r\nflake8==3.8.3\r\nflake8-bandit==2.1.2\r\nflake8-broken-line==0.2.0\r\nflake8-bugbear==19.8.0\r\nflake8-commas==2.0.0\r\nflake8-comprehensions==3.2.3\r\nflake8-debugger==3.2.1\r\nflake8-docstrings==1.5.0\r\nflake8-eradicate==0.3.0\r\nflake8-isort==3.0.1\r\nflake8-plugin-utils==1.3.1\r\nflake8-polyfill==1.0.2\r\nflake8-pytest-style==1.3.0\r\nflake8-quotes==2.1.2\r\nflake8-rst-docstrings==0.0.12\r\nflake8-string-format==0.2.3\r\nFlask==1.1.2\r\nFlask-Admin==1.5.4\r\nFlask-AppBuilder==2.3.0\r\nFlask-Babel==1.0.0\r\nFlask-Caching==1.3.3\r\nFlask-JWT-Extended==3.24.1\r\nFlask-Login==0.4.1\r\nFlask-OpenID==1.2.5\r\nFlask-SQLAlchemy==2.4.4\r\nflask-swagger==0.2.14\r\nFlask-WTF==0.14.3\r\nftfy==5.8\r\nfuncsigs==1.0.2\r\nfuture==0.18.2\r\ngitdb==4.0.5\r\nGitPython==3.1.3\r\ngraphviz==0.14.1\r\ngunicorn==20.0.4\r\nh5py==2.10.0\r\nidna==2.9\r\nimagesize==1.2.0\r\nimportlib-metadata==1.6.1\r\nipykernel==5.3.4\r\nipython==7.16.1\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\niso8601==0.1.13\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njedi==0.17.2\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.16.0\r\njson-merge-patch==0.2\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==6.1.7\r\njupyter-console==6.2.0\r\njupyter-core==4.6.3\r\njupyterlab-pygments==0.1.1\r\nlazy-object-proxy==1.5.1\r\nlockfile==0.12.2\r\nm2r==0.2.1\r\nMako==1.1.3\r\nMarkdown==2.6.11\r\nMarkupSafe==1.1.1\r\nmarshmallow==3.6.1\r\nmarshmallow-enum==1.5.1\r\nmarshmallow-polyfield==5.9\r\nmarshmallow-sqlalchemy==0.23.1\r\nmccabe==0.6.1\r\nmistune==0.8.4\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nmypy==0.782\r\nmypy-extensions==0.4.3\r\nnatsort==7.0.1\r\nnbclient==0.5.0\r\nnbconvert==6.0.3\r\nnbformat==5.0.7\r\nnest-asyncio==1.4.0\r\nnitpick==0.22.2\r\nnltk==3.5\r\nnotebook==6.1.4\r\nnumpy==1.19.2\r\noverrides==3.1.0\r\npackaging==20.4\r\npandas==0.25.3\r\npandocfilters==1.4.2\r\nparso==0.7.1\r\npbr==5.4.5\r\npendulum==1.4.4\r\npep8-naming==0.9.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprison==0.1.3\r\nprometheus-client==0.8.0\r\nprompt-toolkit==3.0.3\r\nprotobuf==3.13.0\r\npsutil==5.7.2\r\nptyprocess==0.6.0\r\npy==1.8.1\r\npy-rouge==1.1\r\npy4j==0.10.9\r\npyarrow==1.0.1\r\npycodestyle==2.6.0\r\npycparser==2.20\r\npydocstyle==5.0.2\r\npyflakes==2.2.0\r\nPygments==2.6.1\r\nPyJWT==1.7.1\r\npyparsing==2.4.7\r\npyrsistent==0.17.3\r\npyspark==3.0.1\r\npytest==5.4.3\r\npytest-cov==2.10.1\r\npytest-randomly==3.4.1\r\npython-daemon==2.2.4\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npython-nvd3==0.15.0\r\npython-openid==2.2.5\r\npython-slugify==4.0.0\r\npytz==2020.1\r\npytzdata==2020.1\r\nPyYAML==5.3.1\r\npyzmq==19.0.2\r\nqtconsole==4.7.7\r\nQtPy==1.9.0\r\nregex==2020.9.27\r\nrequests==2.23.0\r\nrestructuredtext-lint==1.3.1\r\nruamel.yaml==0.16.10\r\nruamel.yaml.clib==0.2.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nsafety==1.9.0\r\nscikit-learn==0.23.2\r\nscipy==1.5.2\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsetproctitle==1.1.10\r\nsix==1.15.0\r\nsmmap==3.0.4\r\nsnowballstemmer==2.0.0\r\nsortedcontainers==2.2.2\r\nspacy==2.3.2\r\nSphinx==2.4.4\r\nsphinx-autodoc-typehints==1.10.3\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nSQLAlchemy==1.3.19\r\nSQLAlchemy-JSONField==0.9.0\r\nSQLAlchemy-Utils==0.36.8\r\nsrsly==1.0.2\r\nstevedore==2.0.0\r\ntabulate==0.8.7\r\ntenacity==4.12.0\r\ntensorboardX==2.1\r\nterminado==0.8.3\r\ntestfixtures==6.14.1\r\ntestpath==0.4.4\r\ntext-unidecode==1.3\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\nthrift==0.13.0\r\ntokenizers==0.8.1rc2\r\ntoml==0.10.0\r\ntomlkit==0.7.0\r\ntorch==1.6.0\r\ntornado==6.0.4\r\ntqdm==4.49.0\r\ntraitlets==4.3.3\r\ntransformers==3.3.1\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.2\r\ntzlocal==1.5.1\r\nunicodecsv==0.14.1\r\nurllib3==1.25.9\r\nwasabi==0.8.0\r\nwcwidth==0.2.4\r\nwebencodings==0.5.1\r\nwemake-python-styleguide==0.14.1\r\nWerkzeug==0.16.1\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nWTForms==2.3.3\r\nxxhash==2.0.0\r\nzipp==3.1.0\r\nzope.deprecation==4.4.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\nTrain BART twice, once with distributed training on multiple GPUs and the other on a single GPU without distributed training and compare the metrics.json file.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4715/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4715/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4703", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4703/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4703/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4703/events", "html_url": "https://github.com/allenai/allennlp/issues/4703", "id": 714467111, "node_id": "MDU6SXNzdWU3MTQ0NjcxMTE=", "number": 4703, "title": "Simple/Smooth/Integrated Gradient examples are returning `'grad_input_1': [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]`", "user": {"login": "cfregly", "id": 1438064, "node_id": "MDQ6VXNlcjE0MzgwNjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1438064?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cfregly", "html_url": "https://github.com/cfregly", "followers_url": "https://api.github.com/users/cfregly/followers", "following_url": "https://api.github.com/users/cfregly/following{/other_user}", "gists_url": "https://api.github.com/users/cfregly/gists{/gist_id}", "starred_url": "https://api.github.com/users/cfregly/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cfregly/subscriptions", "organizations_url": "https://api.github.com/users/cfregly/orgs", "repos_url": "https://api.github.com/users/cfregly/repos", "events_url": "https://api.github.com/users/cfregly/events{/privacy}", "received_events_url": "https://api.github.com/users/cfregly/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-10-05T02:36:10Z", "updated_at": "2020-10-09T23:09:04Z", "closed_at": "2020-10-09T23:09:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n\r\nFollowing the example in this Usage section: \r\n https://demo.allennlp.org/sentiment-analysis/MjMxMzE4Mw==\r\n\r\nHere is my notebook:\r\nhttps://github.com/data-science-on-aws/workshop/blob/925387e/07_train/wip/99_AllenNLP_RoBERTa_Prediction.ipynb\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:  Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.6.10\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.10.0\r\nalabaster==0.7.12\r\nallennlp==1.0.0\r\nallennlp-models==1.0.0\r\nanaconda-client==1.7.2\r\nanaconda-project==0.8.3\r\nargh==0.26.2\r\nasn1crypto==1.3.0\r\nastor==0.8.1\r\nastroid==2.4.2\r\nastropy==4.0.1.post1\r\nastunparse==1.6.3\r\natomicwrites==1.3.0\r\nattrs==19.3.0\r\nAutomat==20.2.0\r\nautopep8==1.4.4\r\nautovizwidget==0.15.0\r\nawscli==1.18.137\r\nawswrangler==1.9.3\r\nBabel==2.8.0\r\nbackcall==0.1.0\r\nbackports.shutil-get-terminal-size==1.0.0\r\nbcrypt==3.2.0\r\nbeautifulsoup4==4.8.2\r\nbitarray==1.2.1\r\nbkcharts==0.2\r\nbleach==3.1.4\r\nblis==0.4.1\r\nbokeh==2.0.1\r\nboto==2.49.0\r\nboto3==1.14.60\r\nbotocore==1.17.60\r\nBottleneck==1.3.2\r\ncached-property==1.5.1\r\ncachetools==4.1.1\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi==1.14.0\r\nchardet==3.0.4\r\nclick==7.1.1\r\ncloudpickle==1.3.0\r\nclyent==1.2.2\r\ncolorama==0.4.3\r\nconllu==3.0\r\ncontextlib2==0.6.0.post1\r\ncryptography==2.8\r\ncycler==0.10.0\r\ncymem==2.0.3\r\nCython==0.29.15\r\ncytoolz==0.10.1\r\ndask==2.14.0\r\ndataclasses==0.7\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndiff-match-patch==20181111\r\ndistributed==2.14.0\r\ndistro==1.5.0\r\ndocker==4.3.1\r\ndocker-compose==1.26.2\r\ndockerpty==0.4.1\r\ndocopt==0.6.2\r\ndocutils==0.15.2\r\nen-core-web-sm==2.2.5\r\nentrypoints==0.3\r\nenum-compat==0.0.3\r\nenum34==1.1.10\r\nenvironment-kernels==1.1.1\r\net-xmlfile==1.0.1\r\nfastcache==1.1.0\r\nfilelock==3.0.12\r\nflake8==3.7.9\r\nFlask==1.1.1\r\nfsspec==0.7.1\r\nfuture==0.18.2\r\ngast==0.2.2\r\ngevent==1.4.0\r\nglob2==0.7\r\ngmpy2==2.0.8\r\ngoogle-auth==1.21.1\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-pasta==0.2.0\r\ngreenlet==0.4.15\r\ngrpcio==1.32.0\r\nh5py==2.10.0\r\nhdijupyterutils==0.15.0\r\nHeapDict==1.0.1\r\nhtml5lib==1.0.1\r\nhypothesis==5.8.3\r\nidna==2.10\r\nimageio==2.8.0\r\nimagesize==1.2.0\r\nimportlib-metadata==1.7.0\r\nintervaltree==3.0.2\r\nipykernel==5.1.4\r\nipyparallel==6.2.4\r\nipython==7.13.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njdcal==1.4.1\r\njedi==0.15.2\r\njeepney==0.4.3\r\nJinja2==2.11.1\r\njmespath==0.9.4\r\njoblib==0.14.1\r\njson5==0.9.4\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==6.1.2\r\njupyter-console==6.1.0\r\njupyter-core==4.6.3\r\njupyterlab==1.2.6\r\njupyterlab-server==1.1.0\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.2\r\nkeyring==21.1.1\r\nkiwisolver==1.1.0\r\nlazy-object-proxy==1.4.3\r\nlibarchive-c==2.8\r\nlief==0.9.0\r\nllvmlite==0.31.0\r\nlocket==0.2.0\r\nlxml==4.5.0\r\nMarkdown==3.2.2\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.1.3\r\nmccabe==0.6.1\r\nmistune==0.8.4\r\nmkl-fft==1.0.15\r\nmkl-random==1.1.0\r\nmkl-service==2.3.0\r\nmock==4.0.1\r\nmore-itertools==8.2.0\r\nmpmath==1.1.0\r\nmsgpack==1.0.0\r\nmultipledispatch==0.6.0\r\nmurmurhash==1.0.2\r\nnb-conda==2.2.1\r\nnb-conda-kernels==2.2.3\r\nnbconvert==5.6.1\r\nnbformat==5.0.4\r\nnetworkx==2.4\r\nnltk==3.4.5\r\nnose==1.3.7\r\nnotebook==6.0.3\r\nnumba==0.48.0\r\nnumexpr==2.7.1\r\nnumpy==1.18.5\r\nnumpydoc==0.9.2\r\nnvidia-ml-py==10.418.84\r\noauthlib==3.1.0\r\nolefile==0.46\r\nopencv-python==4.2.0.32\r\nopenpyxl==3.0.3\r\nopt-einsum==3.3.0\r\noverrides==3.0.0\r\npackaging==20.3\r\npandas==1.0.5\r\npandocfilters==1.4.2\r\nparamiko==2.7.1\r\nparso==0.5.2\r\npartd==1.1.0\r\npath==13.1.0\r\npathlib2==2.3.5\r\npathtools==0.1.2\r\npatsy==0.5.1\r\npep8==1.7.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.1.2\r\npkginfo==1.5.0.1\r\nplac==1.1.3\r\nplotly==4.9.0\r\npluggy==0.13.1\r\nply==3.11\r\npreshed==3.0.2\r\nprometheus-client==0.7.1\r\nprompt-toolkit==3.0.4\r\nprotobuf==3.13.0\r\nprotobuf3-to-dict==0.1.5\r\npsutil==5.7.0\r\npsycopg2==2.7.5\r\npsycopg2-binary==2.8.6\r\nptyprocess==0.6.0\r\npy==1.8.1\r\npy-rouge==1.1\r\npy4j==0.10.7\r\npyarrow==1.0.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\nPyAthena==1.10.7\r\npycodestyle==2.5.0\r\npycosat==0.6.3\r\npycparser==2.20\r\npycrypto==2.6.1\r\npycurl==7.43.0.5\r\npydocstyle==4.0.1\r\npyflakes==2.1.1\r\npygal==2.4.0\r\nPygments==2.6.1\r\npykerberos==1.2.1\r\npylint==2.5.3\r\nPyMySQL==0.10.1\r\nPyNaCl==1.4.0\r\npyodbc===4.0.0-unsupported\r\npyOpenSSL==19.1.0\r\npyparsing==2.4.6\r\npyrsistent==0.16.0\r\nPySocks==1.7.1\r\npyspark==2.3.4\r\npytest==5.4.1\r\npytest-arraydiff==0.3\r\npytest-astropy==0.8.0\r\npytest-astropy-header==0.1.2\r\npytest-doctestplus==0.5.0\r\npytest-openfiles==0.4.0\r\npytest-remotedata==0.3.2\r\npython-dateutil==2.8.1\r\npython-dotenv==0.14.0\r\npython-jsonrpc-server==0.3.4\r\npython-language-server==0.31.10\r\npytz==2019.3\r\nPyWavelets==1.1.1\r\npyxdg==0.26\r\nPyYAML==5.3.1\r\npyzmq==18.1.1\r\nQDarkStyle==2.8\r\nQtAwesome==0.7.0\r\nqtconsole==4.7.2\r\nQtPy==1.9.0\r\nregex==2020.7.14\r\nrequests==2.24.0\r\nrequests-kerberos==0.12.0\r\nrequests-oauthlib==1.3.0\r\nretrying==1.3.3\r\nrope==0.16.0\r\nrsa==4.5\r\nRtree==0.9.4\r\nruamel-yaml==0.15.87\r\ns3fs==0.4.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nsagemaker==2.9.2\r\nsagemaker-experiments==0.1.24\r\nsagemaker-pyspark==1.4.0\r\nscikit-image==0.16.2\r\nscikit-learn==0.23.1\r\nscipy==1.4.1\r\nseaborn==0.10.0\r\nSecretStorage==3.1.2\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsimplegeneric==0.8.1\r\nsingledispatch==3.4.0.3\r\nsix==1.15.0\r\nsmdebug==0.9.3\r\nsmdebug-rulesconfig==0.1.5\r\nsnowballstemmer==2.0.0\r\nsortedcollections==1.1.2\r\nsortedcontainers==2.1.0\r\nsoupsieve==2.0\r\nspacy==2.2.4\r\nsparkmagic==0.15.0\r\nSphinx==3.0.4\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nsphinxcontrib-websupport==1.2.1\r\nspyder==4.1.2\r\nspyder-kernels==1.9.0\r\nSQLAlchemy==1.3.13\r\nsqlalchemy-redshift==0.8.1\r\nsrsly==1.0.2\r\nstatsmodels==0.11.0\r\nstepfunctions==2.0.0rc1\r\nsympy==1.5.1\r\ntables==3.6.1\r\ntblib==1.6.0\r\ntenacity==6.2.0\r\ntensorboard==2.1.1\r\ntensorboard-plugin-wit==1.7.0\r\ntensorboardX==2.1\r\ntensorflow==2.1.0\r\ntensorflow-estimator==2.1.0\r\ntermcolor==1.1.0\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\ntexttable==1.6.2\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.7.0\r\ntoml==0.10.1\r\ntoolz==0.10.0\r\ntorch==1.5.1\r\ntorch-model-archiver==0.1.1\r\ntorchserve==0.1.1\r\ntornado==6.0.4\r\ntqdm==4.44.1\r\ntraitlets==4.3.3\r\ntransformers==2.11.0\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.1\r\nujson==1.35\r\nunicodecsv==0.14.1\r\nurllib3==1.25.10\r\nwasabi==0.8.0\r\nwatchdog==0.10.2\r\nwcwidth==0.1.9\r\nwebencodings==0.5.1\r\nwebsocket-client==0.57.0\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nwrapt==1.12.1\r\nwurlitzer==2.0.0\r\nxlrd==1.2.0\r\nXlsxWriter==1.2.8\r\nxlwt==1.3.0\r\nyapf==0.28.0\r\nzict==2.0.0\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n```\r\n!pip install -q allennlp==1.0.0\r\n!pip install -q allennlp-models==1.0.0\r\n```\r\n```\r\nfrom allennlp.predictors.predictor import Predictor\r\n\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/sst-roberta-large-2020.06.08.tar.gz\")\r\n\r\nsentence = \"a very well-made, funny and entertaining picture.\"\r\n\r\ninputs = {\"sentence\": sentence}\r\n\r\nfrom allennlp.interpret.saliency_interpreters import SimpleGradient\r\n\r\nsimple_gradient_interpreter = SimpleGradient(predictor)\r\n\r\nsimple_gradient_interpretation = simple_gradient_interpreter.saliency_interpret_from_json(inputs)\r\n\r\nprint(simple_gradient_interpretation)\r\n```\r\nOUTPUT\r\n```\r\n{'instance_1': {'grad_input_1': [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4703/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4703/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4691", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4691/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4691/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4691/events", "html_url": "https://github.com/allenai/allennlp/issues/4691", "id": 712949429, "node_id": "MDU6SXNzdWU3MTI5NDk0Mjk=", "number": 4691, "title": "AttributeError: 'Tensor' object has no attribute 'keys' when using ComposedSeq2Seq", "user": {"login": "izaskr", "id": 38069449, "node_id": "MDQ6VXNlcjM4MDY5NDQ5", "avatar_url": "https://avatars.githubusercontent.com/u/38069449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/izaskr", "html_url": "https://github.com/izaskr", "followers_url": "https://api.github.com/users/izaskr/followers", "following_url": "https://api.github.com/users/izaskr/following{/other_user}", "gists_url": "https://api.github.com/users/izaskr/gists{/gist_id}", "starred_url": "https://api.github.com/users/izaskr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/izaskr/subscriptions", "organizations_url": "https://api.github.com/users/izaskr/orgs", "repos_url": "https://api.github.com/users/izaskr/repos", "events_url": "https://api.github.com/users/izaskr/events{/privacy}", "received_events_url": "https://api.github.com/users/izaskr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2763124639, "node_id": "MDU6TGFiZWwyNzYzMTI0NjM5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "ededed", "default": false, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2020-10-01T15:26:18Z", "updated_at": "2021-04-07T16:10:43Z", "closed_at": "2021-04-07T16:10:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/CE/skr/anaconda3/lib/python3.6/site-packages/allennlp/training/trainer.py\", line 867, in train\r\n    train_metrics = self._train_epoch(epoch)\r\n  File \"/home/CE/skr/anaconda3/lib/python3.6/site-packages/allennlp/training/trainer.py\", line 589, in _train_epoch\r\n    batch_outputs = self.batch_outputs(batch, for_training=True)\r\n  File \"/home/CE/skr/anaconda3/lib/python3.6/site-packages/allennlp/training/trainer.py\", line 479, in batch_outputs\r\n    output_dict = self._pytorch_model(**batch)\r\n  File \"/home/CE/skr/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/CE/skr/anaconda3/lib/python3.6/site-packages/allennlp_models/generation/models/composed_seq2seq.py\", line 121, in forward\r\n    return self._decoder(state, target_tokens)\r\n  File \"/home/CE/skr/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/CE/skr/anaconda3/lib/python3.6/site-packages/allennlp_models/generation/modules/seq_decoders/auto_regressive.py\", line 416, in forward\r\n    output_dict = self._forward_loss(state_forward_loss, target_tokens)\r\n  File \"/home/CE/skr/anaconda3/lib/python3.6/site-packages/allennlp_models/generation/modules/seq_decoders/auto_regressive.py\", line 161, in _forward_loss\r\n    target_embedding = self.target_embedder(targets)\r\n  File \"/home/CE/skr/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/CE/skr/anaconda3/lib/python3.6/site-packages/allennlp/modules/text_field_embedders/basic_text_field_embedder.py\", line 56, in forward\r\n    if self._token_embedders.keys() != text_field_input.keys():\r\nAttributeError: 'Tensor' object has no attribute 'keys'\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.6.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalabaster==0.7.10\r\nallennlp==1.1.0\r\nallennlp-models==1.1.0\r\nanaconda-client==1.6.14\r\nanaconda-navigator==1.8.7\r\nanaconda-project==0.8.2\r\nasn1crypto==0.24.0\r\nastroid==1.6.3\r\nastropy==3.0.2\r\nattrs==18.1.0\r\nBabel==2.5.3\r\nbackcall==0.1.0\r\nbackports.shutil-get-terminal-size==1.0.0\r\nbeautifulsoup4==4.6.0\r\nbitarray==0.8.1\r\nbkcharts==0.2\r\nblaze==0.11.3\r\nbleach==2.1.3\r\nblis==0.4.1\r\nbokeh==0.12.16\r\nboto==2.48.0\r\nboto3==1.15.6\r\nbotocore==1.18.6\r\nBottleneck==1.2.1\r\ncatalogue==1.0.0\r\ncertifi==2018.4.16\r\ncffi==1.11.5\r\nchardet==3.0.4\r\nclick==6.7\r\ncloudpickle==0.5.3\r\nclyent==1.2.2\r\ncolorama==0.3.9\r\nconda==4.5.4\r\nconda-build==3.10.5\r\nconda-verify==2.0.0\r\nconllu==4.1\r\ncontextlib2==0.5.5\r\ncryptography==2.2.2\r\ncycler==0.10.0\r\ncymem==2.0.3\r\nCython==0.28.2\r\ncytoolz==0.9.0.1\r\ndask==0.17.5\r\ndataclasses==0.7\r\ndatashape==0.5.4\r\ndecorator==4.3.0\r\ndistributed==1.21.8\r\ndocutils==0.14\r\nen-core-web-sm==2.3.1\r\nentrypoints==0.2.3\r\net-xmlfile==1.0.1\r\nfastcache==1.0.2\r\nfilelock==3.0.4\r\nFlask==1.0.2\r\nFlask-Cors==3.0.4\r\nftfy==5.8\r\nfuture==0.18.2\r\ngevent==1.3.0\r\nglob2==0.6\r\ngmpy2==2.0.8\r\ngreenlet==0.4.13\r\nh5py==2.7.1\r\nheapdict==1.0.0\r\nhtml5lib==1.0.1\r\nidna==2.6\r\nimageio==2.3.0\r\nimagesize==1.0.0\r\nimportlib-metadata==2.0.0\r\nipykernel==4.8.2\r\nipython==6.4.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.2.1\r\nisort==4.3.4\r\nitsdangerous==0.24\r\njdcal==1.4\r\njedi==0.12.0\r\nJinja2==2.10\r\njmespath==0.10.0\r\njoblib==0.16.0\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==2.6.0\r\njupyter==1.0.0\r\njupyter-client==5.2.3\r\njupyter-console==5.2.0\r\njupyter-core==4.4.0\r\njupyterlab==0.32.1\r\njupyterlab-launcher==0.10.5\r\nkiwisolver==1.0.1\r\nlazy-object-proxy==1.3.1\r\nllvmlite==0.23.1\r\nlocket==0.2.0\r\nlxml==4.2.1\r\nMarkupSafe==1.0\r\nmatplotlib==2.2.2\r\nmccabe==0.6.1\r\nmistune==0.8.3\r\nmkl-fft==1.0.0\r\nmkl-random==1.0.1\r\nmore-itertools==4.1.0\r\nmpmath==1.0.0\r\nmsgpack-python==0.5.6\r\nmultipledispatch==0.5.0\r\nmurmurhash==1.0.2\r\nnavigator-updater==0.2.1\r\nnbconvert==5.3.1\r\nnbformat==4.4.0\r\nnetworkx==2.1\r\nnltk==3.3\r\nnose==1.3.7\r\nnotebook==5.5.0\r\nnumba==0.38.0\r\nnumexpr==2.6.5\r\nnumpy==1.14.3\r\nnumpydoc==0.8.0\r\nodo==0.5.1\r\nolefile==0.45.1\r\nopenpyxl==2.5.3\r\noverrides==3.1.0\r\npackaging==17.1\r\npandas==0.23.0\r\npandocfilters==1.4.2\r\nparso==0.2.0\r\npartd==0.3.8\r\npath.py==11.0.1\r\npathlib2==2.3.2\r\npatsy==0.5.0\r\npep8==1.7.1\r\npexpect==4.5.0\r\npickleshare==0.7.4\r\nPillow==5.1.0\r\npkginfo==1.4.2\r\nplac==1.1.3\r\npluggy==0.6.0\r\nply==3.11\r\npreshed==3.0.2\r\nprompt-toolkit==1.0.15\r\nprotobuf==3.13.0\r\npsutil==5.4.5\r\nptyprocess==0.5.2\r\npy==1.5.3\r\npy-rouge==1.1\r\npycodestyle==2.4.0\r\npycosat==0.6.3\r\npycparser==2.18\r\npycrypto==2.6.1\r\npycurl==7.43.0.1\r\npyflakes==1.6.0\r\nPygments==2.2.0\r\npylint==1.8.4\r\npyodbc==4.0.23\r\npyOpenSSL==18.0.0\r\npyparsing==2.2.0\r\nPySocks==1.6.8\r\npytest==3.5.1\r\npytest-arraydiff==0.2\r\npytest-astropy==0.3.0\r\npytest-doctestplus==0.1.3\r\npytest-openfiles==0.3.0\r\npytest-remotedata==0.2.1\r\npython-dateutil==2.7.3\r\npytz==2018.4\r\nPyWavelets==0.5.2\r\nPyYAML==3.12\r\npyzmq==17.0.0\r\nQtAwesome==0.4.4\r\nqtconsole==4.3.1\r\nQtPy==1.4.1\r\nregex==2020.9.27\r\nrequests==2.18.4\r\nrope==0.10.7\r\nruamel-yaml==0.15.35\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-image==0.13.1\r\nscikit-learn==0.19.1\r\nscipy==1.1.0\r\nseaborn==0.8.1\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsimplegeneric==0.8.1\r\nsingledispatch==3.4.0.3\r\nsix==1.11.0\r\nsnowballstemmer==1.2.1\r\nsortedcollections==0.6.1\r\nsortedcontainers==1.5.10\r\nspacy==2.3.2\r\nSphinx==1.7.4\r\nsphinxcontrib-websupport==1.0.1\r\nspyder==3.2.8\r\nSQLAlchemy==1.2.7\r\nsrsly==1.0.2\r\nstatsmodels==0.9.0\r\nsympy==1.1.1\r\ntables==3.4.3\r\ntblib==1.3.2\r\ntensorboardX==2.1\r\nterminado==0.8.1\r\ntestpath==0.3.1\r\nthinc==7.4.1\r\ntokenizers==0.8.1rc1\r\ntoolz==0.9.0\r\ntorch==1.6.0\r\ntorchtext==0.7.0\r\ntornado==5.0.2\r\ntqdm==4.49.0\r\ntraitlets==4.3.2\r\ntransformers==3.0.2\r\ntyping==3.6.4\r\nunicodecsv==0.14.1\r\nUnidecode==1.1.1\r\nurllib3==1.22\r\nwasabi==0.8.0\r\nwcwidth==0.1.7\r\nwebencodings==0.5.1\r\nWerkzeug==0.14.1\r\nwidgetsnbextension==3.2.1\r\nword2number==1.1\r\nwrapt==1.10.11\r\nxlrd==1.1.0\r\nXlsxWriter==1.0.4\r\nxlwt==1.3.0\r\nzict==0.1.3\r\nzipp==3.2.0\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nreader = Seq2SeqDatasetReader(source_tokenizer=WhitespaceTokenizer(),\r\n\t\ttarget_tokenizer=WhitespaceTokenizer(), \r\n\t\tsource_token_indexers={'tokens': SingleIdTokenIndexer()}, \r\n\t\ttarget_token_indexers={'tokens': SingleIdTokenIndexer(namespace='target_tokens')})\r\n\r\ntrain_dataset = reader.read(train_path)\r\nvalidation_dataset = reader.read(val_path)\r\ntest_dataset = reader.read(test_path)\r\nvocab = Vocabulary.from_instances(train_dataset + validation_dataset, min_count={'tokens': 1, 'target_tokens': 1})\r\n\r\ntrain_dataset.index_with(vocab)\r\nvalidation_dataset.index_with(vocab)\r\n\r\nSRC_EMBEDDING_DIM = 128\r\nTG_EMBEDDING_DIM = 128\r\nHIDDEN_DIM = 512\r\nenc_layers = 3\r\ndec_layers = 3\r\nenc_heads = 2\r\ndec_heads = 2\r\nff_dim = 512\r\nproj_dim = 128\r\nenc_dropout = 0.2\r\ndec_dropout = 0.2\r\nmax_decoding_steps = 40\r\nbeam = 3\r\nCUDA_DEVICE = 0\r\n\r\nsrc_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\r\n                             embedding_dim=SRC_EMBEDDING_DIM)\r\nsource_embedder = BasicTextFieldEmbedder({\"tokens\": src_embedding})\r\n\r\ntrg_embedding = Embedding(num_embeddings=vocab.get_vocab_size('target_tokens'),\r\n                             embedding_dim=TG_EMBEDDING_DIM)\r\ntarget_embedder = BasicTextFieldEmbedder({\"target_tokens\": trg_embedding})\r\n\r\nencoder = StackedSelfAttentionEncoder(input_dim=SRC_EMBEDDING_DIM, hidden_dim=HIDDEN_DIM,\r\n                                      projection_dim=proj_dim, feedforward_hidden_dim=ff_dim, num_layers=enc_layers,\r\n                                      num_attention_heads=enc_heads, dropout_prob=enc_dropout, use_positional_encoding=True)\r\n\r\ndecoder_net = StackedSelfAttentionDecoderNet(decoding_dim=TG_EMBEDDING_DIM, target_embedding_dim=TG_EMBEDDING_DIM,\r\n                                             feedforward_hidden_dim=128, num_layers=dec_layers,                                             num_attention_heads=dec_heads, use_positional_encoding=True, dropout_prob=dec_dropout)\r\n\r\ndecoder = AutoRegressiveSeqDecoder(vocab=vocab, decoder_net=decoder_net, max_decoding_steps=max_decoding_steps,\r\n                                target_embedder=target_embedder, target_namespace='target_tokens', beam_size=beam)\r\n\r\nmodel = ComposedSeq2Seq(vocab=vocab, source_text_embedder=source_embedder,\r\n                        encoder=encoder, decoder=decoder)\r\n\r\nmodel = model.cuda(CUDA_DEVICE)\r\n\r\noptimizer = optim.Adam(model.parameters(), lr=0.0005)\r\n\r\ntrain_data_loader = PyTorchDataLoader(train_dataset,batch_sampler=BucketBatchSampler(train_dataset,batch_size=16))\r\ndev_data_loader = PyTorchDataLoader(validation_dataset,batch_sampler=BucketBatchSampler(validation_dataset,batch_size=16))\r\n\r\ntrainer = GradientDescentTrainer(model=model, optimizer=optimizer,data_loader=train_data_loader,\r\n                                 validation_data_loader=dev_data_loader,num_epochs=3)\r\n\r\ntrainer.train()\r\n```\r\n\r\n</p>\r\n</details>\r\nI'm using the ComposedSeq2Seq class. The error is raised also when I replace the Transformer encoder with an LSTM, and the same with the decoder. I suspect the error is connected to the data loader or iterator.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4691/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 1}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4691/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4690", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4690/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4690/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4690/events", "html_url": "https://github.com/allenai/allennlp/issues/4690", "id": 712732381, "node_id": "MDU6SXNzdWU3MTI3MzIzODE=", "number": 4690, "title": "Train a model with transformer embeddings and additional_special_tokens", "user": {"login": "pvcastro", "id": 12713359, "node_id": "MDQ6VXNlcjEyNzEzMzU5", "avatar_url": "https://avatars.githubusercontent.com/u/12713359?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pvcastro", "html_url": "https://github.com/pvcastro", "followers_url": "https://api.github.com/users/pvcastro/followers", "following_url": "https://api.github.com/users/pvcastro/following{/other_user}", "gists_url": "https://api.github.com/users/pvcastro/gists{/gist_id}", "starred_url": "https://api.github.com/users/pvcastro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pvcastro/subscriptions", "organizations_url": "https://api.github.com/users/pvcastro/orgs", "repos_url": "https://api.github.com/users/pvcastro/repos", "events_url": "https://api.github.com/users/pvcastro/events{/privacy}", "received_events_url": "https://api.github.com/users/pvcastro/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "02b8d1", "default": false, "description": ""}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 32, "created_at": "2020-10-01T10:58:10Z", "updated_at": "2021-02-09T10:30:57Z", "closed_at": "2021-02-09T10:30:57Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nHi there! I'm trying to train a transformer-based text classifier model in AllenNLP, but I need to add 5 additional special tokens, in a way compatible with tokenizers lib. I tried adding them to the jsonnet AllenNLP config file and then to the transformer's model path, but neither worked, with each approach having a different problem, which will be described below.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n2020-09-30 23:56:17,398 - INFO - allennlp.training.trainer - Epoch 0/9\r\n2020-09-30 23:56:17,398 - INFO - allennlp.training.trainer - Worker 0 memory usage MB: 10065.304\r\n2020-09-30 23:56:17,484 - WARNING - allennlp.common.util - unable to check gpu_memory_mb() due to occasional failure, continuing\r\nTraceback (most recent call last):\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/util.py\", line 415, in gpu_memory_mb\r\n    encoding=\"utf-8\",\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/subprocess.py\", line 411, in check_output\r\n    **kwargs).stdout\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/subprocess.py\", line 488, in run\r\n    with Popen(*popenargs, **kwargs) as process:\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/subprocess.py\", line 800, in __init__\r\n    restore_signals, start_new_session)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/subprocess.py\", line 1482, in _execute_child\r\n    restore_signals, start_new_session, preexec_fn)\r\n  File \"/media/discoD/pycharm-community-2019.2/plugins/python-ce/helpers/pydev/_pydev_bundle/pydev_monkey.py\", line 526, in new_fork_exec\r\n    return getattr(_posixsubprocess, original_name)(args, *patch_fork_exec_executable_list(args, other_args))\r\nOSError: [Errno 12] Cannot allocate memory\r\n2020-09-30 23:56:17,489 - INFO - allennlp.training.trainer - Training\r\n  0%|          | 0/11817 [00:00<?, ?it/s]/pytorch/aten/src/THC/THCTensorIndex.cu:272: indexSelectLargeIndex: block: [69,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n/pytorch/aten/src/THC/THCTensorIndex.cu:272: indexSelectLargeIndex: block: [69,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n/pytorch/aten/src/THC/THCTensorIndex.cu:272: indexSelectLargeIndex: block: [69,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n/pytorch/aten/src/THC/THCTensorIndex.cu:272: indexSelectLargeIndex: block: [69,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n...\r\n...\r\n...\r\n/pytorch/aten/src/THC/THCTensorIndex.cu:272: indexSelectLargeIndex: block: [102,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n/pytorch/aten/src/THC/THCTensorIndex.cu:272: indexSelectLargeIndex: block: [102,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n  0%|          | 0/11817 [00:00<?, ?it/s]\r\nTraceback (most recent call last):\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/commands/train.py\", line 443, in _train_worker\r\n    metrics = train_loop.run()\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/commands/train.py\", line 505, in run\r\n    return self.trainer.train()\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/training/trainer.py\", line 872, in train\r\n    train_metrics = self._train_epoch(epoch)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/training/trainer.py\", line 594, in _train_epoch\r\n    batch_outputs = self.batch_outputs(batch, for_training=True)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/training/trainer.py\", line 479, in batch_outputs\r\n    output_dict = self._pytorch_model(**batch)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/models/basic_classifier.py\", line 121, in forward\r\n    embedded_text = self._text_field_embedder(tokens)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/modules/text_field_embedders/basic_text_field_embedder.py\", line 88, in forward\r\n    token_vectors = embedder(**tensors, **forward_params_values)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/modules/token_embedders/pretrained_transformer_embedder.py\", line 184, in forward\r\n    transformer_output = self.transformer_model(**parameters)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/transformers/modeling_bert.py\", line 762, in forward\r\n    output_hidden_states=output_hidden_states,\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/transformers/modeling_bert.py\", line 439, in forward\r\n    output_attentions,\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/transformers/modeling_bert.py\", line 371, in forward\r\n    hidden_states, attention_mask, head_mask, output_attentions=output_attentions,\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/transformers/modeling_bert.py\", line 315, in forward\r\n    hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions,\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/transformers/modeling_bert.py\", line 221, in forward\r\n    mixed_query_layer = self.query(hidden_states)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/linear.py\", line 91, in forward\r\n    return F.linear(input, self.weight, self.bias)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/functional.py\", line 1676, in linear\r\n    output = input.matmul(weight.t())\r\nRuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\r\npython-BaseException\r\nTHCudaCheck FAIL file=/pytorch/aten/src/THC/THCCachingHostAllocator.cpp line=278 error=710 : device-side assert triggered\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==1.1.0\r\nallennlp-models==1.1.0\r\n-e git+git@github.com:allenai/allennlp-server.git@bc56288b9295391051f7b7b042fe34219bfe33ab#egg=allennlp_server\r\nattrs==19.3.0\r\nbackcall==0.2.0\r\nbleach==3.1.5\r\nblis==0.4.1\r\nboto3==1.14.31\r\nbotocore==1.17.31\r\ncachetools==4.1.1\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\nchardet==3.0.4\r\nclick==7.1.2\r\nconllu==4.1\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ncytoolz==0.10.1\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndocutils==0.15.2\r\neland==7.7.0a1\r\nelasticsearch-dsl==7.2.1\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\r\nentrypoints==0.3\r\nfilelock==3.0.12\r\nfire==0.3.1\r\nFlask==1.1.2\r\nFlask-Cors==3.0.8\r\nftfy==5.8\r\nfuture==0.18.2\r\ngevent==20.6.2\r\ngreenlet==0.4.16\r\nh5py==2.10.0\r\nidna==2.10\r\nimportlib-metadata==1.7.0\r\niniconfig==1.0.1\r\nipykernel==5.3.4\r\nipython==7.16.1\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\nitsdangerous==1.1.0\r\njedi==0.17.2\r\njellyfish==0.8.2\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.16.0\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\njupyter-client==6.1.6\r\njupyter-core==4.6.3\r\nKeras==2.4.3\r\nkiwisolver==1.2.0\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.3.0\r\nmistune==0.8.4\r\nmkl-fft==1.1.0\r\nmkl-random==1.1.1\r\nmkl-service==2.3.0\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nnbconvert==5.6.1\r\nnbformat==5.0.7\r\nnetworkx==2.4\r\nnltk==3.5\r\nnotebook==6.0.3\r\nnumpy==1.18.5\r\nolefile==0.46\r\noverrides==3.1.0\r\npackaging==20.4\r\npandas==1.1.0\r\npandocfilters==1.4.2\r\nparso==0.7.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.2.0\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprometheus-client==0.8.0\r\nprompt-toolkit==3.0.5\r\nprotobuf==3.12.4\r\nptyprocess==0.6.0\r\npy==1.9.0\r\npy-rouge==1.1\r\npydot==1.4.1\r\npyemd==0.5.1\r\nPygments==2.6.1\r\npyparsing==2.4.7\r\nPyphen==0.9.5\r\npyrsistent==0.16.0\r\npytest==6.0.1\r\npython-dateutil==2.8.1\r\npytz==2020.1\r\nPyYAML==5.3.1\r\npyzmq==19.0.1\r\nregex==2020.7.14\r\nrequests==2.24.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.5.2\r\nseaborn==0.11.0\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nseqeval==0.0.12\r\nsix==1.15.0\r\nspacy==2.3.2\r\nsrsly==1.0.2\r\ntensorboardX==2.1\r\ntermcolor==1.1.0\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.8.1rc1\r\ntoml==0.10.1\r\ntoolz==0.10.0\r\ntorch==1.6.0+cu101\r\ntorchvision==0.7.0+cu101\r\ntornado==6.0.4\r\ntqdm==4.48.0\r\ntraitlets==4.3.3\r\ntransformers==3.0.2\r\nurllib3==1.25.10\r\nvisualise-spacy-tree==0.0.6\r\nwasabi==0.7.1\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nzipp==3.1.0\r\nzope.event==4.4\r\nzope.interface==5.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nFirst I tried adding the 5 additional special tokens directly in the jsonnet model config, like this:\r\n\r\n```\r\n    \"token_indexers\": {\r\n            \"tokens\": {\r\n                \"type\": \"pretrained_transformer\",\r\n                \"model_name\": transformer_model,\r\n                \"max_length\": transformer_dim,\r\n                \"tokenizer_kwargs\": {\"additional_special_tokens\": [['<REL_SEP>'], ['[['], [']]'], ['<<'], ['>>']], \"max_len\": transformer_dim}\r\n            }\r\n     },\r\n```\r\n\r\nBut I ran into a problem at `allennlp.common.cached_transformer.get_tokenizer`, because `cache_key = (model_name, frozenset(kwargs.items()))` tries to use the \"tokenizer_kwargs\" value as a cache key, but it can't parse the additional_special_tokens list into a string, throwing the following exception:\r\n\r\n<details>\r\n<summary><b>TypeError: unhashable type: 'list'</b></summary>\r\n<p>\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/media/discoD/pycharm-community-2019.2/plugins/python-ce/helpers/pydev/pydevd.py\", line 1465, in _exec\r\n    runpy._run_module_as_main(module_name, alter_argv=False)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/media/discoD/anaconda3/envs/allennlp/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/__main__.py\", line 38, in <module>\r\n    run()\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/commands/__init__.py\", line 94, in main\r\n    args.func(args)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/commands/train.py\", line 118, in train_model_from_args\r\n    file_friendly_logging=args.file_friendly_logging,\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/commands/train.py\", line 177, in train_model_from_file\r\n    file_friendly_logging=file_friendly_logging,\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/commands/train.py\", line 238, in train_model\r\n    file_friendly_logging=file_friendly_logging,\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/commands/train.py\", line 433, in _train_worker\r\n    local_rank=process_rank,\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 599, in from_params\r\n    **extras,\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 626, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 197, in create_kwargs\r\n    cls.__name__, param_name, annotation, param.default, params, **extras\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 306, in pop_and_construct_arg\r\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 340, in construct_arg\r\n    return annotation.from_params(params=popped_params, **subextras)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 599, in from_params\r\n    **extras,\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 626, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 197, in create_kwargs\r\n    cls.__name__, param_name, annotation, param.default, params, **extras\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 306, in pop_and_construct_arg\r\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 387, in construct_arg\r\n    **extras,\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 340, in construct_arg\r\n    return annotation.from_params(params=popped_params, **subextras)\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 599, in from_params\r\n    **extras,\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/from_params.py\", line 628, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/data/token_indexers/pretrained_transformer_indexer.py\", line 58, in __init__\r\n    model_name, tokenizer_kwargs=tokenizer_kwargs\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/data/tokenizers/pretrained_transformer_tokenizer.py\", line 71, in __init__\r\n    model_name, add_special_tokens=False, **tokenizer_kwargs\r\n  File \"/media/discoD/repositorios/allennlp/allennlp/common/cached_transformers.py\", line 101, in get_tokenizer\r\n    cache_key = (model_name, frozenset(kwargs.items()))\r\nTypeError: unhashable type: 'list'\r\n```\r\n</p>\r\n</details>\r\n\r\nI couldn't find a way to work passing the tokens in this way, so I ended up downloading the bert model to my local disk and added the tokenizers config files to the same path (the vocab size of my bert model is 29794, so the last index is 29793). Files contents I changed are in the \"Example source\" section below.\r\n\r\nAfter debugging, looks like this config at least was enough to get the bert tokenizer to recognize the 5 tokens and tokenize the training data accordingly, but then I ran into another issue once training actually began (the one pasted in the \"Python traceback\" section of this issue).\r\n\r\nLooks like this error is due to the fact that the transformer's model embeddings layer weren't properly resized according to the new vocabulary size, which would be accomplished with a code like this: `model.resize_token_embeddings(len(tokenizer))`. I didn't find any code in the AllenNLP lib that would do something like this, so I'm thinking this is the issue's cause. \r\n\r\nIs there another way to accomplish this using AllenNLP that I'm not aware of? Looks like both ways to expand the vocab size should be possible.\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n`added_tokens.json`:\r\n\r\n`{\"<REL_SEP>\": 29794, \"[[\": 29795, \"]]\": 29796, \"<<\": 29797, \">>\": 29798}`\r\n\r\n`special_tokens_map.json`:\r\n\r\n`{\"unk_token\": \"[UNK]\", \"sep_token\": \"[SEP]\", \"pad_token\": \"[PAD]\", \"cls_token\": \"[CLS]\", \"mask_token\": \"[MASK]\", \"additional_special_tokens\": [\"<REL_SEP>\", \"[[\", \"]]\", \"<<\", \">>\"]}`\r\n\r\n`tokenizer_config.json`:\r\n\r\n`{\"do_lower_case\": false, \"additional_special_tokens\": [\"<REL_SEP>\", \"[[\", \"]]\", \"<<\", \">>\"]}`\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nThanks!", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4690/reactions", "total_count": 3, "+1": 3, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4690/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4689", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4689/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4689/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4689/events", "html_url": "https://github.com/allenai/allennlp/issues/4689", "id": 712486822, "node_id": "MDU6SXNzdWU3MTI0ODY4MjI=", "number": 4689, "title": "OOM with BART during validation even with low batch size and truncation", "user": {"login": "vikigenius", "id": 12724810, "node_id": "MDQ6VXNlcjEyNzI0ODEw", "avatar_url": "https://avatars.githubusercontent.com/u/12724810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vikigenius", "html_url": "https://github.com/vikigenius", "followers_url": "https://api.github.com/users/vikigenius/followers", "following_url": "https://api.github.com/users/vikigenius/following{/other_user}", "gists_url": "https://api.github.com/users/vikigenius/gists{/gist_id}", "starred_url": "https://api.github.com/users/vikigenius/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vikigenius/subscriptions", "organizations_url": "https://api.github.com/users/vikigenius/orgs", "repos_url": "https://api.github.com/users/vikigenius/repos", "events_url": "https://api.github.com/users/vikigenius/events{/privacy}", "received_events_url": "https://api.github.com/users/vikigenius/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2020-10-01T05:09:11Z", "updated_at": "2020-12-02T16:41:48Z", "closed_at": "2020-12-02T16:41:48Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I am training BART on a custom Seq2Seq dataset.\r\nI am getting OOM errors during validation even when the batch size is 1.\r\n\r\nCurrently my training batch size is 3, with source_max_tokens=1022 and target_max_tokens=54.\r\nMy validation batch size is 1, with source_max_tokens=512 and target_max_tokens=54.\r\n\r\nI am training on the 16GB Tesla V100.\r\n\r\nEven with reduced source_max_tokens I am getting an OOM during validation. How is it possible that training does not cause OOM but validation does?\r\n\r\n<details>\r\n<summary><b>Configuration:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nlocal model_name = \"sshleifer/distilbart-xsum-12-6\";\r\nlocal data_base_url = \"data/hqa_canlii/processed/\";\r\nlocal num_gpus = 8;\r\n\r\n{\r\n  \"train_data_path\": data_base_url + \"train.tsv\",\r\n  \"validation_data_path\": data_base_url + \"test.tsv\",\r\n  \"dataset_reader\": {\r\n    \"type\": \"seq2seq\",\r\n    \"source_tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": model_name,\r\n    },\r\n    \"source_token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": model_name,\r\n        \"namespace\": \"tokens\"\r\n      }\r\n    },\r\n    \"start_symbol\": \"\",\r\n    \"end_symbol\": \"\",\r\n    \"source_add_start_token\": false,\r\n    \"source_add_end_token\": false,\r\n    \"target_add_start_token\": false,\r\n    \"target_add_end_token\": false,\r\n    \"source_max_tokens\": 1022,\r\n    \"target_max_tokens\": 54,\r\n  },\r\n  \"validation_dataset_reader\": {\r\n    \"type\": \"seq2seq\",\r\n    \"source_tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": model_name,\r\n    },\r\n    \"source_token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": model_name,\r\n        \"namespace\": \"tokens\"\r\n      }\r\n    },\r\n    \"start_symbol\": \"\",\r\n    \"end_symbol\": \"\",\r\n    \"source_add_start_token\": false,\r\n    \"source_add_end_token\": false,\r\n    \"target_add_start_token\": false,\r\n    \"target_add_end_token\": false,\r\n    \"source_max_tokens\": 512,\r\n    \"target_max_tokens\": 40,\r\n  },\r\n  \"model\": {\r\n    \"type\": \"bartqgen\",\r\n    \"model_name\": model_name,\r\n    \"max_decoding_steps\": 40,\r\n    \"beam_size\": 4,\r\n  },\r\n  \"data_loader\": {\r\n    \"batch_size\": 3,\r\n    \"shuffle\": true\r\n  },\r\n  \"validation_data_loader\": {\r\n    \"batch_size\": 1,\r\n    \"shuffle\": true\r\n  },\r\n  \"distributed\": {\r\n    \"cuda_devices\": if num_gpus > 1 then std.range(0, num_gpus - 1) else 0,\r\n  },\r\n  \"trainer\": {\r\n    \"num_epochs\": 6,\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"lr\": 3e-5,\r\n      \"betas\": [0.9, 0.999],\r\n      \"eps\": 1e-8,\r\n      \"correct_bias\": true\r\n    },\r\n    \"learning_rate_scheduler\": {\r\n      \"type\": \"polynomial_decay\",\r\n    },\r\n    \"use_amp\": true,\r\n    \"grad_norm\": 1.0,\r\n  }\r\n}\r\n```\r\n</p>\r\n</details>\r\n\r\n<details>\r\n<summary><b>Traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp/commands/train.py\", line 109, in train_model_from_args\r\n    train_model_from_file(\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp/commands/train.py\", line 169, in train_model_from_file\r\n    return train_model(\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp/commands/train.py\", line 232, in train_model\r\n    model = _train_worker(\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp/commands/train.py\", line 443, in _train_worker\r\n    metrics = train_loop.run()\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp/commands/train.py\", line 505, in run\r\n    return self.trainer.train()\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp/training/trainer.py\", line 879, in train\r\n    val_loss, val_reg_loss, num_batches = self._validation_loss(epoch)\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp/training/trainer.py\", line 776, in _validation_loss\r\n    batch_outputs = self.batch_outputs(batch, for_training=False)\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp/training/trainer.py\", line 479, in batch_outputs\r\n    output_dict = self._pytorch_model(**batch)\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp_models/generation/models/bart.py\", line 243, in forward\r\n    beam_result = self._beam_search.search(\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 15, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp/nn/beam_search.py\", line 233, in search\r\n    class_log_probabilities, state = step(last_predictions, state, timestep + 1)\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/allennlp_models/generation/models/bart.py\", line 342, in take_step\r\n    outputs = self.bart(\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/transformers/modeling_bart.py\", line 1005, in forward\r\n    lm_logits = F.linear(outputs[0], self.model.shared.weight, bias=self.final_logits_bias)\r\n  File \"/home/ec2-user/miniconda3/envs/sqgendebug/lib/python3.8/site-packages/torch/nn/functional.py\", line 1676, in linear\r\n    output = input.matmul(weight.t())\r\nRuntimeError: CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 15.78 GiB total capacity; 14.45 GiB already allocated; 13.75 MiB free; 14.60 GiB reserved in total by PyTorch)\r\n\r\n```\r\n</p>\r\n</details>\r\n\r\nJust for verification I tried to train on the validation set to see if I get OOM during training, but I don't so maybe the issue lies with beam search?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4689/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4689/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4687", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4687/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4687/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4687/events", "html_url": "https://github.com/allenai/allennlp/issues/4687", "id": 712150245, "node_id": "MDU6SXNzdWU3MTIxNTAyNDU=", "number": 4687, "title": "allennlp-models Seq2Seq dataset reader does not work with pretrained transformer tokenizers", "user": {"login": "vikigenius", "id": 12724810, "node_id": "MDQ6VXNlcjEyNzI0ODEw", "avatar_url": "https://avatars.githubusercontent.com/u/12724810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vikigenius", "html_url": "https://github.com/vikigenius", "followers_url": "https://api.github.com/users/vikigenius/followers", "following_url": "https://api.github.com/users/vikigenius/following{/other_user}", "gists_url": "https://api.github.com/users/vikigenius/gists{/gist_id}", "starred_url": "https://api.github.com/users/vikigenius/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vikigenius/subscriptions", "organizations_url": "https://api.github.com/users/vikigenius/orgs", "repos_url": "https://api.github.com/users/vikigenius/repos", "events_url": "https://api.github.com/users/vikigenius/events{/privacy}", "received_events_url": "https://api.github.com/users/vikigenius/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-09-30T17:49:56Z", "updated_at": "2020-09-30T19:24:24Z", "closed_at": "2020-09-30T19:18:43Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nThe Seq2Seq dataset reader from allennlp-models does not work with pretrained transformer tokenizers.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/void/.miniconda3/envs/sqgen/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/commands/train.py\", line 109, in train_model_from_args\r\n    train_model_from_file(\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/commands/train.py\", line 169, in train_model_from_file\r\n    return train_model(\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/commands/train.py\", line 232, in train_model\r\n    model = _train_worker(\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/commands/train.py\", line 430, in _train_worker\r\n    train_loop = TrainModel.from_params(\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 591, in from_params\r\n    return retyped_subclass.from_params(\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 622, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 192, in create_kwargs\r\n    constructed_arg = pop_and_construct_arg(\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 302, in pop_and_construct_arg\r\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 336, in construct_arg\r\n    return annotation.from_params(params=popped_params, **subextras)\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 591, in from_params\r\n    return retyped_subclass.from_params(\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 624, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/home/void/.miniconda3/envs/sqgen/lib/python3.8/site-packages/allennlp_models/generation/dataset_readers/seq2seq.py\", line 85, in __init__\r\n    self._start_token, self._end_token = self._source_tokenizer.tokenize(\r\nValueError: too many values to unpack (expected 2)\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: GNU/LINUX 5.8.9_1\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalabaster==0.7.12\r\nalembic==1.4.3\r\nallennlp==1.1.0\r\nallennlp-models==1.1.0\r\napache-airflow==1.10.12\r\napispec==1.3.3\r\nargcomplete==1.12.0\r\nargon2-cffi==20.1.0\r\nastor==0.8.1\r\nasync-generator==1.10\r\nattrs==19.3.0\r\nBabel==2.8.0\r\nbackcall==0.2.0\r\nbandit==1.6.2\r\nbleach==3.2.1\r\nblis==0.4.1\r\nboto3==1.15.4\r\nbotocore==1.18.4\r\ncached-property==1.5.2\r\ncatalogue==1.0.0\r\ncattrs==1.0.0\r\ncertifi==2020.4.5.2\r\ncffi==1.14.3\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncolorama==0.4.3\r\ncolorlog==4.0.2\r\nconfigparser==3.5.3\r\nconllu==4.1\r\ncoverage==5.1\r\ncroniter==0.3.34\r\ncymem==2.0.3\r\ndarglint==1.4.1\r\ndatasets==1.0.1\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndictdiffer==0.8.1\r\ndill==0.3.2\r\ndnspython==2.0.0\r\ndoc8==0.8.1\r\ndocutils==0.16\r\ndparse==0.5.1\r\nemail-validator==1.1.1\r\nentrypoints==0.3\r\neradicate==1.0\r\nfilelock==3.0.12\r\nflake8==3.8.3\r\nflake8-bandit==2.1.2\r\nflake8-broken-line==0.2.0\r\nflake8-bugbear==19.8.0\r\nflake8-commas==2.0.0\r\nflake8-comprehensions==3.2.3\r\nflake8-debugger==3.2.1\r\nflake8-docstrings==1.5.0\r\nflake8-eradicate==0.3.0\r\nflake8-isort==3.0.1\r\nflake8-plugin-utils==1.3.1\r\nflake8-polyfill==1.0.2\r\nflake8-pytest-style==1.3.0\r\nflake8-quotes==2.1.2\r\nflake8-rst-docstrings==0.0.12\r\nflake8-string-format==0.2.3\r\nFlask==1.1.2\r\nFlask-Admin==1.5.4\r\nFlask-AppBuilder==2.3.0\r\nFlask-Babel==1.0.0\r\nFlask-Caching==1.3.3\r\nFlask-JWT-Extended==3.24.1\r\nFlask-Login==0.4.1\r\nFlask-OpenID==1.2.5\r\nFlask-SQLAlchemy==2.4.4\r\nflask-swagger==0.2.14\r\nFlask-WTF==0.14.3\r\nftfy==5.8\r\nfuncsigs==1.0.2\r\nfuture==0.18.2\r\ngitdb==4.0.5\r\nGitPython==3.1.3\r\ngraphviz==0.14.1\r\ngunicorn==20.0.4\r\nh5py==2.10.0\r\nidna==2.9\r\nimagesize==1.2.0\r\nimportlib-metadata==1.6.1\r\nipykernel==5.3.4\r\nipython==7.16.1\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\niso8601==0.1.13\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njedi==0.17.2\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.16.0\r\njson-merge-patch==0.2\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==6.1.7\r\njupyter-console==6.2.0\r\njupyter-core==4.6.3\r\njupyterlab-pygments==0.1.1\r\nlazy-object-proxy==1.5.1\r\nlockfile==0.12.2\r\nm2r==0.2.1\r\nMako==1.1.3\r\nMarkdown==2.6.11\r\nMarkupSafe==1.1.1\r\nmarshmallow==3.6.1\r\nmarshmallow-enum==1.5.1\r\nmarshmallow-polyfield==5.9\r\nmarshmallow-sqlalchemy==0.23.1\r\nmccabe==0.6.1\r\nmistune==0.8.4\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nmypy==0.782\r\nmypy-extensions==0.4.3\r\nnatsort==7.0.1\r\nnbclient==0.5.0\r\nnbconvert==6.0.3\r\nnbformat==5.0.7\r\nnest-asyncio==1.4.0\r\nnitpick==0.22.2\r\nnltk==3.5\r\nnotebook==6.1.4\r\nnumpy==1.19.2\r\noverrides==3.1.0\r\npackaging==20.4\r\npandas==0.25.3\r\npandocfilters==1.4.2\r\nparso==0.7.1\r\npbr==5.4.5\r\npendulum==1.4.4\r\npep8-naming==0.9.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprison==0.1.3\r\nprometheus-client==0.8.0\r\nprompt-toolkit==3.0.3\r\nprotobuf==3.13.0\r\npsutil==5.7.2\r\nptyprocess==0.6.0\r\npy==1.8.1\r\npy-rouge==1.1\r\npy4j==0.10.9\r\npyarrow==1.0.1\r\npycodestyle==2.6.0\r\npycparser==2.20\r\npydocstyle==5.0.2\r\npyflakes==2.2.0\r\nPygments==2.6.1\r\nPyJWT==1.7.1\r\npyparsing==2.4.7\r\npyrsistent==0.17.3\r\npyspark==3.0.1\r\npytest==5.4.3\r\npytest-cov==2.10.1\r\npytest-randomly==3.4.1\r\npython-daemon==2.2.4\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npython-nvd3==0.15.0\r\npython-openid==2.2.5\r\npython-slugify==4.0.0\r\npytz==2020.1\r\npytzdata==2020.1\r\nPyYAML==5.3.1\r\npyzmq==19.0.2\r\nqtconsole==4.7.7\r\nQtPy==1.9.0\r\nregex==2020.9.27\r\nrequests==2.23.0\r\nrestructuredtext-lint==1.3.1\r\nruamel.yaml==0.16.10\r\nruamel.yaml.clib==0.2.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nsafety==1.9.0\r\nscikit-learn==0.23.2\r\nscipy==1.5.2\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsetproctitle==1.1.10\r\nsix==1.15.0\r\nsmmap==3.0.4\r\nsnowballstemmer==2.0.0\r\nsortedcontainers==2.2.2\r\nspacy==2.3.2\r\nSphinx==2.4.4\r\nsphinx-autodoc-typehints==1.10.3\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nSQLAlchemy==1.3.19\r\nSQLAlchemy-JSONField==0.9.0\r\nSQLAlchemy-Utils==0.36.8\r\nsrsly==1.0.2\r\nstevedore==2.0.0\r\ntabulate==0.8.7\r\ntenacity==4.12.0\r\ntensorboardX==2.1\r\nterminado==0.8.3\r\ntestfixtures==6.14.1\r\ntestpath==0.4.4\r\ntext-unidecode==1.3\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\nthrift==0.13.0\r\ntokenizers==0.8.1rc1\r\ntoml==0.10.0\r\ntomlkit==0.7.0\r\ntorch==1.6.0\r\ntornado==6.0.4\r\ntqdm==4.49.0\r\ntraitlets==4.3.3\r\ntransformers==3.0.2\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.2\r\ntzlocal==1.5.1\r\nunicodecsv==0.14.1\r\nurllib3==1.25.9\r\nwasabi==0.8.0\r\nwcwidth==0.2.4\r\nwebencodings==0.5.1\r\nwemake-python-styleguide==0.14.1\r\nWerkzeug==0.16.1\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nWTForms==2.3.3\r\nxxhash==2.0.0\r\nzipp==3.1.0\r\nzope.deprecation==4.4.0\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\nUse any Seq2Seq dataset with the bart model:\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nlocal model_name = \"sshleifer/distilbart-xsum-12-6\";\r\nlocal data_base_url = \"data/pubmedqa/processed/\";\r\n\r\n{\r\n  \"train_data_path\": data_base_url + \"train.tsv\",\r\n  \"validation_data_path\": data_base_url + \"test.tsv\",\r\n  \"dataset_reader\": {\r\n    \"type\": \"seq2seq\",\r\n    \"source_tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": model_name\r\n    },\r\n    \"source_token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": model_name,\r\n        \"namespace\": \"tokens\"\r\n      }\r\n    },\r\n    \"source_add_start_token\": false,\r\n    \"source_add_end_token\": false,\r\n    \"target_add_start_token\": false,\r\n    \"target_add_end_token\": false,\r\n    \"source_max_tokens\": 512,\r\n    \"target_max_tokens\": 40,\r\n  },\r\n  \"model\": {\r\n    \"type\": \"bart\",\r\n    \"model_name\": model_name\r\n  },\r\n  \"data_loader\": {\r\n    \"batch_size\": 2,\r\n    \"shuffle\": true\r\n  },\r\n  \"trainer\": {\r\n    \"num_epochs\": 1,\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"lr\": 3e-5,\r\n      \"betas\": [0.9, 0.999],\r\n      \"eps\": 1e-8,\r\n      \"correct_bias\": true\r\n    },\r\n    \"learning_rate_scheduler\": {\r\n      \"type\": \"polynomial_decay\",\r\n    },\r\n    \"grad_norm\": 1.0,\r\n  }\r\n}\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4687/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4687/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4667", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4667/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4667/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4667/events", "html_url": "https://github.com/allenai/allennlp/issues/4667", "id": 708093531, "node_id": "MDU6SXNzdWU3MDgwOTM1MzE=", "number": 4667, "title": "from allennlp.data.dataset_readers.seq2seq import Seq2SeqDatasetReader in v 1.1.0", "user": {"login": "izaskr", "id": 38069449, "node_id": "MDQ6VXNlcjM4MDY5NDQ5", "avatar_url": "https://avatars.githubusercontent.com/u/38069449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/izaskr", "html_url": "https://github.com/izaskr", "followers_url": "https://api.github.com/users/izaskr/followers", "following_url": "https://api.github.com/users/izaskr/following{/other_user}", "gists_url": "https://api.github.com/users/izaskr/gists{/gist_id}", "starred_url": "https://api.github.com/users/izaskr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/izaskr/subscriptions", "organizations_url": "https://api.github.com/users/izaskr/orgs", "repos_url": "https://api.github.com/users/izaskr/repos", "events_url": "https://api.github.com/users/izaskr/events{/privacy}", "received_events_url": "https://api.github.com/users/izaskr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-09-24T11:34:14Z", "updated_at": "2020-09-30T13:55:05Z", "closed_at": "2020-09-30T13:55:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n>>> from allennlp.data.dataset_readers.seq2seq import Seq2SeqDatasetReader\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'allennlp.data.dataset_readers.seq2seq'\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.9\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==1.1.0\r\nallennlp-models==1.1.0\r\nattrs==20.2.0\r\nAutomat==20.2.0\r\nblis==0.4.1\r\nboto3==1.15.4\r\nbotocore==1.18.4\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\nchardet==3.0.4\r\nclick==7.1.2\r\nComet==3.1.0\r\ncomet-ml==3.2.1\r\nconfigobj==5.0.6\r\nconllu==4.1\r\nconstantly==15.1.0\r\ncymem==2.0.3\r\ndulwich==0.20.6\r\neverett==1.0.2\r\nfilelock==3.0.12\r\nftfy==5.8\r\nfuture==0.18.2\r\nh5py==2.10.0\r\nhyperlink==20.0.1\r\nidna==2.10\r\nimportlib-metadata==2.0.0\r\nincremental==17.5.0\r\niniconfig==1.0.1\r\njmespath==0.10.0\r\njoblib==0.16.0\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\nlxml==4.5.2\r\nmore-itertools==8.5.0\r\nmurmurhash==1.0.2\r\nnetifaces==0.10.9\r\nnltk==3.5\r\nnumpy==1.19.2\r\nnvidia-ml-py3==7.352.0\r\noverrides==3.1.0\r\npackaging==20.4\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprotobuf==3.13.0\r\npy==1.9.0\r\npy-rouge==1.1\r\nPyHamcrest==2.0.2\r\npyparsing==2.4.7\r\npyrsistent==0.17.3\r\npytest==6.0.2\r\npython-dateutil==2.8.1\r\nregex==2020.7.14\r\nrequests==2.24.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.2\r\nscipy==1.5.2\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.3.2\r\nsrsly==1.0.2\r\ntensorboardX==2.1\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.8.1rc1\r\ntoml==0.10.1\r\ntorch==1.6.0\r\ntqdm==4.49.0\r\ntransformers==3.0.2\r\nTwisted==20.3.0\r\nurllib3==1.25.10\r\nwasabi==0.8.0\r\nwcwidth==0.2.5\r\nwebsocket-client==0.57.0\r\nword2number==1.1\r\nwrapt==1.12.1\r\nwurlitzer==2.0.1\r\nzipp==3.2.0\r\nzope.interface==5.1.0\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\nActivate the conda env for allennlp 1.1.0, start python console. Import allennlp and then from allennlp.data.dataset_readers.seq2seq import Seq2SeqDatasetReader.\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nimport allennlp\r\nfrom allennlp.data.dataset_readers.seq2seq import Seq2SeqDatasetReader\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4667/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4667/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4666", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4666/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4666/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4666/events", "html_url": "https://github.com/allenai/allennlp/issues/4666", "id": 707719997, "node_id": "MDU6SXNzdWU3MDc3MTk5OTc=", "number": 4666, "title": "When running multiple distributed runs on the same box, AllenNLP says \"RuntimeError address already in use\u201d", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/13", "html_url": "https://github.com/allenai/allennlp/milestone/13", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/13/labels", "id": 5535962, "node_id": "MDk6TWlsZXN0b25lNTUzNTk2Mg==", "number": 13, "title": "1.2", "description": "", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 24, "state": "closed", "created_at": "2020-06-12T16:16:52Z", "updated_at": "2020-11-02T18:45:36Z", "due_on": null, "closed_at": "2020-11-02T18:45:36Z"}, "comments": 0, "created_at": "2020-09-23T22:31:39Z", "updated_at": "2020-10-07T18:14:35Z", "closed_at": "2020-10-07T18:14:35Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The workaround is to set `\"distributed\" { \"master_port\": 29501 }` in the training config, but we can do better and automatically find a free port.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4666/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4666/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4662", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4662/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4662/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4662/events", "html_url": "https://github.com/allenai/allennlp/issues/4662", "id": 707115273, "node_id": "MDU6SXNzdWU3MDcxMTUyNzM=", "number": 4662, "title": "ModuleNotFoundError: No module named 'allennlp.data.iterators'", "user": {"login": "kapeed1011", "id": 49570096, "node_id": "MDQ6VXNlcjQ5NTcwMDk2", "avatar_url": "https://avatars.githubusercontent.com/u/49570096?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kapeed1011", "html_url": "https://github.com/kapeed1011", "followers_url": "https://api.github.com/users/kapeed1011/followers", "following_url": "https://api.github.com/users/kapeed1011/following{/other_user}", "gists_url": "https://api.github.com/users/kapeed1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/kapeed1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kapeed1011/subscriptions", "organizations_url": "https://api.github.com/users/kapeed1011/orgs", "repos_url": "https://api.github.com/users/kapeed1011/repos", "events_url": "https://api.github.com/users/kapeed1011/events{/privacy}", "received_events_url": "https://api.github.com/users/kapeed1011/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-09-23T07:21:11Z", "updated_at": "2020-09-23T08:20:13Z", "closed_at": "2020-09-23T08:20:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am to trying import BucketIterator using -\"from allennlp.data.iterators import BucketIterator\" in Google colab.But it is raising the same error again and again-\r\n\"ModuleNotFoundError: No module named 'allennlp.data.iterators\"\r\nAfter installing allennlp the imports like:\r\nfrom allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\r\nfrom allennlp.data.tokenizers.character_tokenizer import CharacterTokenizer\r\nfrom allennlp.data.vocabulary import Vocabulary\r\nfrom allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\r\nare working fine. Is there a way to solve this issue?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4662/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4662/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4658", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4658/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4658/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4658/events", "html_url": "https://github.com/allenai/allennlp/issues/4658", "id": 706606677, "node_id": "MDU6SXNzdWU3MDY2MDY2Nzc=", "number": 4658, "title": "No module named 'allennlp_models'", "user": {"login": "DalilaB000", "id": 53010079, "node_id": "MDQ6VXNlcjUzMDEwMDc5", "avatar_url": "https://avatars.githubusercontent.com/u/53010079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DalilaB000", "html_url": "https://github.com/DalilaB000", "followers_url": "https://api.github.com/users/DalilaB000/followers", "following_url": "https://api.github.com/users/DalilaB000/following{/other_user}", "gists_url": "https://api.github.com/users/DalilaB000/gists{/gist_id}", "starred_url": "https://api.github.com/users/DalilaB000/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DalilaB000/subscriptions", "organizations_url": "https://api.github.com/users/DalilaB000/orgs", "repos_url": "https://api.github.com/users/DalilaB000/repos", "events_url": "https://api.github.com/users/DalilaB000/events{/privacy}", "received_events_url": "https://api.github.com/users/DalilaB000/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-09-22T18:38:19Z", "updated_at": "2020-10-07T16:27:02Z", "closed_at": "2020-10-07T16:27:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nInstalled the latest allennp in its own environment, on my Mac OS 10.15.6 I have the latest Python 3.7 \r\nI'm trying to run the sample example:\r\n```\r\n from allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.tagging\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/ner-model-2020.02.10.tar.gz\")\r\npredictor.predict(\r\n  sentence=\"Did Uriah honestly think he could beat The Legend of Zelda in under three hours?\"\r\n)\r\n```\r\n\r\nbut I either get an error that no module allennlp.predictos exists  or no module allennlp_models exists\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4658/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4658/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4657", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4657/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4657/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4657/events", "html_url": "https://github.com/allenai/allennlp/issues/4657", "id": 706604490, "node_id": "MDU6SXNzdWU3MDY2MDQ0OTA=", "number": 4657, "title": "No module named allennlp_models", "user": {"login": "DalilaB000", "id": 53010079, "node_id": "MDQ6VXNlcjUzMDEwMDc5", "avatar_url": "https://avatars.githubusercontent.com/u/53010079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DalilaB000", "html_url": "https://github.com/DalilaB000", "followers_url": "https://api.github.com/users/DalilaB000/followers", "following_url": "https://api.github.com/users/DalilaB000/following{/other_user}", "gists_url": "https://api.github.com/users/DalilaB000/gists{/gist_id}", "starred_url": "https://api.github.com/users/DalilaB000/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DalilaB000/subscriptions", "organizations_url": "https://api.github.com/users/DalilaB000/orgs", "repos_url": "https://api.github.com/users/DalilaB000/repos", "events_url": "https://api.github.com/users/DalilaB000/events{/privacy}", "received_events_url": "https://api.github.com/users/DalilaB000/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-09-22T18:34:29Z", "updated_at": "2020-09-23T16:01:27Z", "closed_at": "2020-09-23T16:01:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nInstalled the latest allennp in its own environment, I have the latest Python 3.7 \r\nI'm trying to run the sample example:\r\n```\r\n from allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.tagging\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/ner-model-2020.02.10.tar.gz\")\r\npredictor.predict(\r\n  sentence=\"Did Uriah honestly think he could beat The Legend of Zelda in under three hours?\"\r\n)\r\n```\r\n\r\nbut I either get an error that no module allennlp.predictos exists  or no module allennlp_models exists\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4657/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4657/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4653", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4653/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4653/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4653/events", "html_url": "https://github.com/allenai/allennlp/issues/4653", "id": 705149124, "node_id": "MDU6SXNzdWU3MDUxNDkxMjQ=", "number": 4653, "title": "Closing the TensorBoard writer", "user": {"login": "mahnerak", "id": 1367529, "node_id": "MDQ6VXNlcjEzNjc1Mjk=", "avatar_url": "https://avatars.githubusercontent.com/u/1367529?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mahnerak", "html_url": "https://github.com/mahnerak", "followers_url": "https://api.github.com/users/mahnerak/followers", "following_url": "https://api.github.com/users/mahnerak/following{/other_user}", "gists_url": "https://api.github.com/users/mahnerak/gists{/gist_id}", "starred_url": "https://api.github.com/users/mahnerak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mahnerak/subscriptions", "organizations_url": "https://api.github.com/users/mahnerak/orgs", "repos_url": "https://api.github.com/users/mahnerak/repos", "events_url": "https://api.github.com/users/mahnerak/events{/privacy}", "received_events_url": "https://api.github.com/users/mahnerak/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/13", "html_url": "https://github.com/allenai/allennlp/milestone/13", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/13/labels", "id": 5535962, "node_id": "MDk6TWlsZXN0b25lNTUzNTk2Mg==", "number": 13, "title": "1.2", "description": "", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 24, "state": "closed", "created_at": "2020-06-12T16:16:52Z", "updated_at": "2020-11-02T18:45:36Z", "due_on": null, "closed_at": "2020-11-02T18:45:36Z"}, "comments": 3, "created_at": "2020-09-20T17:21:56Z", "updated_at": "2020-10-19T18:32:06Z", "closed_at": "2020-10-19T18:32:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I had noticed that sometimes tensorboard fails to properly read the `tfevents` files.\r\nThey are mainly in case of runs which I decided to interrupt the training (not sure about other abortion scenarios).\r\nThen, I wanted to make sure the tensorboard writer is properly closed. I found the `close()` is called only here, but not inside any `with` or `finally` construct:\r\nhttps://github.com/allenai/allennlp/blob/fbd2ccca1dd767e919a62d344c6b6569fc38227a/allennlp/training/trainer.py#L970\r\nHere we can see the writer is closed just by calling `.close()` so there's no guarantee that the data is going to be flushed.\r\n\r\nIs there any reason for this implementation? Does this need to be fixed?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4653/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4653/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4649", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4649/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4649/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4649/events", "html_url": "https://github.com/allenai/allennlp/issues/4649", "id": 704011505, "node_id": "MDU6SXNzdWU3MDQwMTE1MDU=", "number": 4649, "title": "Problem with PretrainedTransformerEmbedder and models such as T5", "user": {"login": "ianupright", "id": 1504871, "node_id": "MDQ6VXNlcjE1MDQ4NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1504871?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ianupright", "html_url": "https://github.com/ianupright", "followers_url": "https://api.github.com/users/ianupright/followers", "following_url": "https://api.github.com/users/ianupright/following{/other_user}", "gists_url": "https://api.github.com/users/ianupright/gists{/gist_id}", "starred_url": "https://api.github.com/users/ianupright/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ianupright/subscriptions", "organizations_url": "https://api.github.com/users/ianupright/orgs", "repos_url": "https://api.github.com/users/ianupright/repos", "events_url": "https://api.github.com/users/ianupright/events{/privacy}", "received_events_url": "https://api.github.com/users/ianupright/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/15", "html_url": "https://github.com/allenai/allennlp/milestone/15", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/15/labels", "id": 5996193, "node_id": "MDk6TWlsZXN0b25lNTk5NjE5Mw==", "number": 15, "title": "1.4", "description": "", "creator": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 9, "state": "closed", "created_at": "2020-10-15T21:34:47Z", "updated_at": "2021-02-12T00:44:07Z", "due_on": null, "closed_at": "2021-02-12T00:44:07Z"}, "comments": 0, "created_at": "2020-09-18T01:26:02Z", "updated_at": "2020-11-11T00:44:06Z", "closed_at": "2020-11-11T00:44:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "In  PretrainedTransformerEmbedder and PretrainedTransformerTokenizer, there is the line:\r\n\r\n        self._num_added_end_tokens = len(tokenizer.single_sequence_end_tokens)\r\n\r\nIn the case of models such as T5, the _num_added_tokens results in zero.\r\n\r\nbut then there is code like:\r\n\r\n        embeddings = embeddings[\r\n            :, :, self._num_added_start_tokens : -(self._num_added_end_tokens), :\r\n        ]  # truncate segment-level start/end tokens\r\n\r\nwhich results in an empty tensor, because I think it should be a -1 to get the last element in the array, instead of -(self._num_added_end_tokens), which results in 0?\r\n\r\nNevertheless, a T5 model doesn't seem to work with the PretrainedTransformerEmbedder/PretrainedTransformerTokenizer\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4649/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4649/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4646", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4646/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4646/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4646/events", "html_url": "https://github.com/allenai/allennlp/issues/4646", "id": 703782482, "node_id": "MDU6SXNzdWU3MDM3ODI0ODI=", "number": 4646, "title": "Cannot train NER model that uses bidirectional_lm_token_embedder: RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu", "user": {"login": "tpanza", "id": 19810086, "node_id": "MDQ6VXNlcjE5ODEwMDg2", "avatar_url": "https://avatars.githubusercontent.com/u/19810086?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tpanza", "html_url": "https://github.com/tpanza", "followers_url": "https://api.github.com/users/tpanza/followers", "following_url": "https://api.github.com/users/tpanza/following{/other_user}", "gists_url": "https://api.github.com/users/tpanza/gists{/gist_id}", "starred_url": "https://api.github.com/users/tpanza/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tpanza/subscriptions", "organizations_url": "https://api.github.com/users/tpanza/orgs", "repos_url": "https://api.github.com/users/tpanza/repos", "events_url": "https://api.github.com/users/tpanza/events{/privacy}", "received_events_url": "https://api.github.com/users/tpanza/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2020-09-17T17:38:06Z", "updated_at": "2020-10-15T01:48:51Z", "closed_at": "2020-10-15T01:48:51Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ ] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n2020-09-16 17:06:02,589 - INFO - allennlp.training.trainer - Beginning training.\r\n2020-09-16 17:06:02,589 - INFO - allennlp.training.trainer - Epoch 0/21\r\n2020-09-16 17:06:02,589 - INFO - allennlp.training.trainer - Worker 0 memory usage MB: 3118.312\r\n2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1314\r\n2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 1 memory usage MB: 11\r\n2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 2 memory usage MB: 11\r\n2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 3 memory usage MB: 11\r\n2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 4 memory usage MB: 11\r\n2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 5 memory usage MB: 11\r\n2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 6 memory usage MB: 11\r\n2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 7 memory usage MB: 11\r\n2020-09-16 17:06:02,732 - INFO - allennlp.training.trainer - Training\r\n  0%|          | 0/169 [00:00<?, ?it/s]\r\n2020-09-16 17:06:02,784 - CRITICAL - root - Uncaught exception\r\nTraceback (most recent call last):\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 118, in train_model_from_args\r\n    file_friendly_logging=args.file_friendly_logging,\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 177, in train_model_from_file\r\n    file_friendly_logging=file_friendly_logging,\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 238, in train_model\r\n    file_friendly_logging=file_friendly_logging,\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 443, in _train_worker\r\n    metrics = train_loop.run()\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 505, in run\r\n    return self.trainer.train()\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 867, in train\r\n    train_metrics = self._train_epoch(epoch)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 589, in _train_epoch\r\n    batch_outputs = self.batch_outputs(batch, for_training=True)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 479, in batch_outputs\r\n    output_dict = self._pytorch_model(**batch)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/localdata/tony/data-science/ner-refactor-pytorch/src/models/lstm.py\", line 46, in forward\r\n    embedded = self._embedder(tokens)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/modules/text_field_embedders/basic_text_field_embedder.py\", line 84, in forward\r\n    token_vectors = embedder(list(tensors.values())[0], **forward_params_values)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp_models/lm/modules/token_embedders/language_model.py\", line 187, in forward\r\n    tokens, mask, self._bos_indices, self._eos_indices\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/nn/util.py\", line 1565, in add_sentence_boundary_token_ids\r\n    tensor_with_boundary_tokens[i, j + 1, :] = sentence_end_token\r\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\r\n2020-09-16 17:06:02,789 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpobwn4xyg\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- #4336 (not positive about this one, but including it in case)\r\n- #4554 \r\n- #4623 \r\n- #4632 \r\n\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Red Hat Enterprise Linux Server release 7.6 (Maipo), `Linux 3.10.0-957.12.2.el7.x86_64 #1 SMP Fri Apr 19 21:09:07 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux`\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08) [GCC 7.5.0] on linux\r\n\r\nIssue observed with `1.1.0` release of `allennlp` and `allennlp-models`, plus the following patches manually applied:\r\n- #4632\r\n- allenai/allennlp-models#129\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalabaster==0.7.12\r\nalembic==1.4.2\r\nallennlp==1.1.0\r\nallennlp-models==1.1.0\r\nappdirs==1.4.3\r\nargon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1596629848788/work\r\nastroid @ file:///home/conda/feedstock_root/build_artifacts/astroid_1591645081755/work\r\nattrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1597959372343/work\r\nBabel==2.8.0\r\nbackcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\r\nbackports.functools-lru-cache==1.6.1\r\nbeautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1597679909012/work\r\nblack @ file:///home/conda/feedstock_root/build_artifacts/black-recipe_1596181673569/work\r\nbleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1588608214987/work\r\nblis==0.4.1\r\nboto==2.49.0\r\nboto3 @ file:///home/conda/feedstock_root/build_artifacts/boto3_1599083817494/work\r\nbotocore @ file:///home/conda/feedstock_root/build_artifacts/botocore_1599079795233/work\r\nbrotlipy==0.7.0\r\nbz2file==0.98\r\ncachetools @ file:///home/conda/feedstock_root/build_artifacts/cachetools_1593420445823/work\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1595805535531/work\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncliff @ file:///home/conda/feedstock_root/build_artifacts/cliff_1596473693634/work\r\ncmaes @ file:///home/conda/feedstock_root/build_artifacts/cmaes_1596014311252/work\r\ncmd2 @ file:///home/conda/feedstock_root/build_artifacts/cmd2_1591809284986/work\r\ncolorama==0.4.3\r\ncolorlog==4.2.1\r\nconllu==4.1\r\ncryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography_1598621005849/work\r\ncss-html-js-minify @ file:///home/conda/feedstock_root/build_artifacts/css-html-js-minify_1589201803800/work\r\ncycler==0.10.0\r\ncymem==2.0.3\r\nCython @ file:///home/conda/feedstock_root/build_artifacts/cython_1594253470382/work\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndocutils==0.15.2\r\nen-core-web-sm @ file:///home/conda/feedstock_root/build_artifacts/spacy-model-en_core_web_1595437534769/work/sm\r\nentrypoints==0.3\r\nfilelock==3.0.12\r\nflake8 @ file:///home/conda/feedstock_root/build_artifacts/flake8_1594584774608/work\r\nftfy==5.8\r\nfuture==0.18.2\r\ngensim @ file:///home/conda/feedstock_root/build_artifacts/gensim_1589441213562/work\r\ngoogle-api-core @ file:///home/conda/feedstock_root/build_artifacts/google-api-core-split_1597353416133/work\r\ngoogle-auth @ file:///home/conda/feedstock_root/build_artifacts/google-auth_1598972371532/work\r\ngoogle-cloud-core @ file:///home/conda/feedstock_root/build_artifacts/google-cloud-core_1596721852962/work\r\ngoogle-cloud-storage @ file:///home/conda/feedstock_root/build_artifacts/google-cloud-storage_1598557481535/work\r\ngoogle-crc32c @ file:///home/conda/feedstock_root/build_artifacts/google-crc32c_1597069930917/work\r\ngoogle-resumable-media @ file:///home/conda/feedstock_root/build_artifacts/google-resumable-media_1598452053521/work\r\ngoogleapis-common-protos==1.51.0\r\ngrpcio @ file:///home/conda/feedstock_root/build_artifacts/grpcio_1596715635580/work\r\nh5py==2.10.0\r\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1593328102638/work\r\nimagesize==1.2.0\r\nimportlib-metadata @ file:///home/conda/feedstock_root/build_artifacts/importlib-metadata_1593211369179/work\r\niniconfig==1.0.1\r\nipykernel @ file:///home/conda/feedstock_root/build_artifacts/ipykernel_1595446871027/work/dist/ipykernel-5.3.4-py3-none-any.whl\r\nipython @ file:///home/conda/feedstock_root/build_artifacts/ipython_1598749946943/work\r\nipython-genutils==0.2.0\r\nisort @ file:///home/conda/feedstock_root/build_artifacts/isort_1599134253980/work\r\njedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1595018882455/work\r\nJinja2==2.11.2\r\njmespath @ file:///home/conda/feedstock_root/build_artifacts/jmespath_1589369830981/work\r\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1593624380152/work\r\njson5 @ file:///home/conda/feedstock_root/build_artifacts/json5_1591810480056/work\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\njupyter-client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1598486169312/work\r\njupyter-core==4.6.3\r\njupyterlab==2.2.6\r\njupyterlab-server @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_server_1593951277307/work\r\nkiwisolver==1.2.0\r\nlazy-object-proxy==1.4.3\r\nlivereload @ file:///home/conda/feedstock_root/build_artifacts/livereload_1598114753789/work\r\nlunr==0.5.8\r\nlxml @ file:///home/conda/feedstock_root/build_artifacts/lxml_1594322698782/work\r\nMako @ file:///home/conda/feedstock_root/build_artifacts/mako_1595925083607/work\r\nMarkdown @ file:///home/conda/feedstock_root/build_artifacts/markdown_1589366472132/work\r\nMarkupSafe==1.1.1\r\nmatplotlib @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-base_1597952254444/work\r\nmccabe==0.6.1\r\nmistune==0.8.4\r\nmkdocs @ file:///home/conda/feedstock_root/build_artifacts/mkdocs_1591017186129/work\r\nmkdocs-material @ file:///home/conda/feedstock_root/build_artifacts/mkdocs-material_1598971568401/work\r\nmore-itertools==8.5.0\r\nmurmurhash==1.0.2\r\nmypy @ file:///home/conda/feedstock_root/build_artifacts/mypy_1592923020520/work\r\nmypy-extensions==0.4.3\r\nnbconvert==5.6.1\r\nnbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1594060262917/work\r\nnetworkx==2.5\r\nnltk==3.4.4\r\nnotebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1597285190767/work\r\nnumpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1597938346492/work\r\nolefile==0.46\r\noptuna @ file:///home/conda/feedstock_root/build_artifacts/optuna_1598323699360/work\r\noverrides==3.1.0\r\npackaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1589925210001/work\r\npandas @ file:///home/conda/feedstock_root/build_artifacts/pandas_1598294454723/work\r\npandocfilters==1.4.2\r\nparso @ file:///home/conda/feedstock_root/build_artifacts/parso_1595548966091/work\r\npathspec==0.8.0\r\npatsy==0.5.1\r\npbr @ file:///home/conda/feedstock_root/build_artifacts/pbr_1598996708473/work\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow @ file:///home/conda/feedstock_root/build_artifacts/pillow_1594213010297/work\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprettytable==0.7.2\r\nprometheus-client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1590412252446/work\r\nprompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1598885455507/work\r\nprotobuf==3.13.0\r\npsutil @ file:///home/conda/feedstock_root/build_artifacts/psutil_1594826921622/work\r\nptyprocess==0.6.0\r\npy==1.9.0\r\npy-rouge==1.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.7\r\npycodestyle @ file:///home/conda/feedstock_root/build_artifacts/pycodestyle_1589305246696/work\r\npycorenlp==0.3.0\r\npycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1593275161868/work\r\npyflakes==2.2.0\r\nPygments==2.6.1\r\npylint @ file:///home/conda/feedstock_root/build_artifacts/pylint_1598117058668/work\r\npymdown-extensions @ file:///home/conda/feedstock_root/build_artifacts/pymdown-extensions_1597166028984/work\r\nPyment==0.3.3\r\npyneuroner==1.0.8\r\npyOpenSSL==19.1.0\r\npyparsing==2.4.7\r\npyperclip @ file:///home/conda/feedstock_root/build_artifacts/pyperclip_1591810382257/work\r\npyrsistent==0.16.0\r\nPySocks==1.7.1\r\npytest==6.0.1\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npython-magic==0.4.18\r\npython-slugify @ file:///home/conda/feedstock_root/build_artifacts/python-slugify_1593573453419/work\r\npytz==2020.1\r\nPyYAML==5.3.1\r\npyzmq==19.0.2\r\nregex @ file:///home/conda/feedstock_root/build_artifacts/regex_1594799371287/work\r\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1592425495151/work\r\nrsa @ file:///home/conda/feedstock_root/build_artifacts/rsa_1591996208734/work\r\ns3cmd==2.1.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn @ file:///home/conda/feedstock_root/build_artifacts/scikit-learn_1596546074663/work\r\nscipy @ file:///home/conda/feedstock_root/build_artifacts/scipy_1595583586868/work\r\nseaborn @ file:///home/conda/feedstock_root/build_artifacts/seaborn-base_1591878760859/work\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1590081179328/work\r\nslugify==0.0.1\r\nsmart-open @ file:///home/conda/feedstock_root/build_artifacts/smart_open_1598572939086/work\r\nsnowballstemmer==2.0.0\r\nsoupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1597680516047/work\r\nspacy==2.3.2\r\nSphinx @ file:///home/conda/feedstock_root/build_artifacts/sphinx_1597405755328/work\r\nsphinx-material @ file:///home/conda/feedstock_root/build_artifacts/sphinx-material_1597663680729/work\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nSQLAlchemy @ file:///home/conda/feedstock_root/build_artifacts/sqlalchemy_1597701920245/work\r\nsrsly==1.0.2\r\nstatsmodels @ file:///home/conda/feedstock_root/build_artifacts/statsmodels_1598551025620/work\r\nstevedore @ file:///home/conda/feedstock_root/build_artifacts/stevedore_1598982656343/work\r\ntensorboardX==2.1\r\nteradata==15.10.0.21\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\ntext-unidecode==1.3\r\nthinc==7.4.1\r\nthreadpoolctl @ file:///tmp/tmp79xdzxkt/threadpoolctl-2.1.0-py3-none-any.whl\r\ntokenizers==0.8.1rc1\r\ntoml @ file:///home/conda/feedstock_root/build_artifacts/toml_1589469402899/work\r\ntorch==1.6.0\r\ntorchvision==0.7.0\r\ntornado==6.0.4\r\ntqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1596476591553/work\r\ntraitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1598976315411/work\r\ntransformers==3.0.2\r\ntyped-ast==1.4.1\r\ntyping-extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1588470653596/work\r\nUnidecode==1.1.1\r\nurllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1595434816409/work\r\nwasabi==0.8.0\r\nwcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1595859607677/work\r\nwebencodings==0.5.1\r\nword2number==1.1\r\nwrapt==1.11.2\r\nXlsxWriter @ file:///home/conda/feedstock_root/build_artifacts/xlsxwriter_1597362230404/work\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n<details>\r\n<summary><b>Output of <code>conda list</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n# packages in environment at /app/local/anaconda3/envs/torch1.6_allennlp1.1:\r\n#\r\n# Name                    Version                   Build  Channel\r\n_libgcc_mutex             0.1                 conda_forge\r\n_openmp_mutex             4.5                      1_llvm\r\nalabaster                 0.7.12                     py_0\r\nalembic                   1.4.2              pyh9f0ad1d_0\r\nallennlp                  1.1.0                    pypi_0    pypi\r\nallennlp-models           1.1.0                    pypi_0    pypi\r\nappdirs                   1.4.3                      py_1\r\nargon2-cffi               20.1.0           py37h8f50634_1\r\nastroid                   2.4.2            py37hc8dfbb8_0\r\nattrs                     20.1.0             pyh9f0ad1d_0\r\nbabel                     2.8.0                      py_0\r\nbackcall                  0.2.0              pyh9f0ad1d_0\r\nbackports                 1.0                        py_2\r\nbackports.functools_lru_cache 1.6.1                      py_0\r\nbeautifulsoup4            4.9.1                      py_1\r\nblack                     19.10b0                    py_4\r\nblas                      2.16                        mkl\r\nbleach                    3.1.5              pyh9f0ad1d_0\r\nblis                      0.4.1                    pypi_0    pypi\r\nboto                      2.49.0                     py_0\r\nboto3                     1.14.54            pyh9f0ad1d_0\r\nbotocore                  1.17.54            pyh9f0ad1d_0\r\nbrotlipy                  0.7.0           py37h8f50634_1000\r\nbz2file                   0.98                       py_0\r\nc-ares                    1.16.1               h516909a_3\r\nca-certificates           2020.6.20            hecda079_0\r\ncachetools                4.1.1                      py_0\r\ncatalogue                 1.0.0                    pypi_0    pypi\r\ncertifi                   2020.6.20        py37hc8dfbb8_0\r\ncffi                      1.14.1           py37h2b28604_0\r\nchardet                   3.0.4           py37hc8dfbb8_1006\r\nclick                     7.1.2              pyh9f0ad1d_0\r\ncliff                     3.4.0                      py_0\r\ncmaes                     0.6.0              pyhbc3b93e_0\r\ncmd2                      0.9.22                   py37_0\r\ncolorama                  0.4.3                      py_0\r\ncolorlog                  4.2.1            py37hc8dfbb8_0\r\nconllu                    4.1                      pypi_0    pypi\r\ncryptography              3.1              py37hb09aad4_0\r\ncss-html-js-minify        2.5.5            py37hc8dfbb8_1\r\ncudatoolkit               9.2                           0\r\ncycler                    0.10.0                     py_2\r\ncymem                     2.0.3                    pypi_0    pypi\r\ncython                    0.29.21          py37h3340039_0\r\ndecorator                 4.4.2                      py_0\r\ndefusedxml                0.6.0                      py_0\r\ndocutils                  0.15.2                   py37_0\r\nentrypoints               0.3             py37hc8dfbb8_1001\r\nfilelock                  3.0.12                   pypi_0    pypi\r\nflake8                    3.8.3                      py_1\r\nfreetype                  2.10.2               he06d7ca_0\r\nftfy                      5.8                      pypi_0    pypi\r\nfuture                    0.18.2           py37hc8dfbb8_1\r\ngensim                    3.8.3            py37h3340039_2\r\ngoogle-api-core           1.22.1           py37hc8dfbb8_0\r\ngoogle-auth               1.21.0                     py_0\r\ngoogle-cloud-core         1.4.1              pyh9f0ad1d_0\r\ngoogle-cloud-storage      1.31.0             pyh9f0ad1d_0\r\ngoogle-crc32c             1.0.0            py37h193935f_0\r\ngoogle-resumable-media    1.0.0              pyh9f0ad1d_0\r\ngoogleapis-common-protos  1.51.0           py37hc8dfbb8_2\r\ngrpcio                    1.31.0           py37hb0870dc_0\r\nh5py                      2.10.0                   pypi_0    pypi\r\nicu                       67.1                 he1b5a44_0\r\nidna                      2.10               pyh9f0ad1d_0\r\nimagesize                 1.2.0                      py_0\r\nimportlib-metadata        1.7.0            py37hc8dfbb8_0\r\nimportlib_metadata        1.7.0                         0\r\niniconfig                 1.0.1                    pypi_0    pypi\r\nipykernel                 5.3.4            py37h43977f1_0\r\nipython                   7.18.1           py37hc6149b9_0\r\nipython_genutils          0.2.0                      py_1\r\nisort                     5.5.0            py37hc8dfbb8_0\r\njedi                      0.17.2           py37hc8dfbb8_0\r\njinja2                    2.11.2             pyh9f0ad1d_0\r\njmespath                  0.10.0             pyh9f0ad1d_0\r\njoblib                    0.16.0                     py_0\r\njpeg                      9d                   h516909a_0\r\njson5                     0.9.4              pyh9f0ad1d_0\r\njsonnet                   0.16.0                   pypi_0    pypi\r\njsonpickle                1.4.1                    pypi_0    pypi\r\njsonschema                3.2.0            py37hc8dfbb8_1\r\njupyter_client            6.1.7                      py_0\r\njupyter_core              4.6.3            py37hc8dfbb8_1\r\njupyterlab                2.2.6                      py_0\r\njupyterlab_server         1.2.0                      py_0\r\nkiwisolver                1.2.0            py37h99015e2_0\r\nlazy-object-proxy         1.4.3            py37h8f50634_2\r\nlcms2                     2.11                 hbd6801e_0\r\nld_impl_linux-64          2.34                 hc38a660_9\r\nlibblas                   3.8.0                    16_mkl\r\nlibcblas                  3.8.0                    16_mkl\r\nlibcrc32c                 1.1.1                he1b5a44_2\r\nlibffi                    3.2.1             he1b5a44_1007\r\nlibgcc-ng                 9.3.0               h24d8f2e_16\r\nlibgfortran-ng            7.5.0               hdf63c60_16\r\nlibiconv                  1.16                 h516909a_0\r\nliblapack                 3.8.0                    16_mkl\r\nliblapacke                3.8.0                    16_mkl\r\nlibpng                    1.6.37               hed695b0_2\r\nlibprotobuf               3.13.0               h8b12597_0\r\nlibsodium                 1.0.18               h516909a_0\r\nlibstdcxx-ng              9.3.0               hdf63c60_16\r\nlibtiff                   4.1.0                hc7e4089_6\r\nlibuv                     1.39.0               h516909a_0\r\nlibwebp-base              1.1.0                h516909a_3\r\nlibxml2                   2.9.10               h68273f3_2\r\nlibxslt                   1.1.33               h572872d_1\r\nlivereload                2.6.3              pyh9f0ad1d_0\r\nllvm-openmp               10.0.1               hc9558a2_0\r\nlunr                      0.5.8            py37hc8dfbb8_0\r\nlxml                      4.5.2            py37he3881c9_0\r\nlz4-c                     1.9.2                he1b5a44_3\r\nmako                      1.1.3              pyh9f0ad1d_0\r\nmarkdown                  3.2.2                      py_0\r\nmarkupsafe                1.1.1            py37h8f50634_1\r\nmatplotlib-base           3.3.1            py37hd478181_1\r\nmccabe                    0.6.1                      py_1\r\nmistune                   0.8.4           py37h8f50634_1001\r\nmkdocs                    1.1.2                      py_0\r\nmkdocs-material           5.5.12                     py_0\r\nmkl                       2020.2                      256\r\nmore-itertools            8.5.0                    pypi_0    pypi\r\nmurmurhash                1.0.2                    pypi_0    pypi\r\nmypy                      0.782                      py_0\r\nmypy_extensions           0.4.3            py37hc8dfbb8_1\r\nnbconvert                 5.6.1            py37hc8dfbb8_1\r\nnbformat                  5.0.7                      py_0\r\nncurses                   6.2                  he1b5a44_1\r\nnetworkx                  2.5                      pypi_0    pypi\r\nninja                     1.10.1               hc9558a2_1\r\nnltk                      3.4.4                      py_0\r\nnodejs                    14.9.0               h568c755_0\r\nnotebook                  6.1.3            py37hc8dfbb8_0\r\nnumpy                     1.19.1           py37h7ea13bd_2\r\nolefile                   0.46                       py_0\r\nopenssl                   1.1.1g               h516909a_1\r\noptuna                    2.0.0                      py_1\r\noverrides                 3.1.0                    pypi_0    pypi\r\npackaging                 20.4               pyh9f0ad1d_0\r\npandas                    1.1.1            py37h3340039_0\r\npandoc                    2.10.1               h516909a_0\r\npandocfilters             1.4.2                      py_1\r\nparso                     0.7.1              pyh9f0ad1d_0\r\npathspec                  0.8.0              pyh9f0ad1d_0\r\npatsy                     0.5.1                      py_0\r\npbr                       5.5.0              pyh9f0ad1d_0\r\npexpect                   4.8.0            py37hc8dfbb8_1\r\npickleshare               0.7.5           py37hc8dfbb8_1001\r\npillow                    7.2.0            py37h718be6c_1\r\npip                       20.2.2                     py_0\r\nplac                      1.1.3                    pypi_0    pypi\r\npluggy                    0.13.1                   pypi_0    pypi\r\npreshed                   3.0.2                    pypi_0    pypi\r\nprettytable               0.7.2                      py_3\r\nprometheus_client         0.8.0              pyh9f0ad1d_0\r\nprompt-toolkit            3.0.7                      py_0\r\nprotobuf                  3.13.0                   pypi_0    pypi\r\npsutil                    5.7.2            py37h8f50634_0\r\nptyprocess                0.6.0                   py_1001\r\npy                        1.9.0                    pypi_0    pypi\r\npy-rouge                  1.1                      pypi_0    pypi\r\npyasn1                    0.4.8                      py_0\r\npyasn1-modules            0.2.7                      py_0\r\npycodestyle               2.6.0              pyh9f0ad1d_0\r\npycorenlp                 0.3.0                    pypi_0    pypi\r\npycparser                 2.20               pyh9f0ad1d_2\r\npyflakes                  2.2.0              pyh9f0ad1d_0\r\npygments                  2.6.1                      py_0\r\npylint                    2.6.0            py37hc8dfbb8_0\r\npymdown-extensions        8.0                pyh9f0ad1d_0\r\npyment                    0.3.3                    pypi_0    pypi\r\npyneuroner                1.0.8                    pypi_0    pypi\r\npyopenssl                 19.1.0                     py_1\r\npyparsing                 2.4.7              pyh9f0ad1d_0\r\npyperclip                 1.8.0              pyh9f0ad1d_0\r\npyrsistent                0.16.0           py37h8f50634_0\r\npysocks                   1.7.1            py37hc8dfbb8_1\r\npytest                    6.0.1                    pypi_0    pypi\r\npython                    3.7.8           h6f2ec95_1_cpython\r\npython-dateutil           2.8.1                      py_0\r\npython-editor             1.0.4                      py_0\r\npython-magic              0.4.18                   pypi_0    pypi\r\npython-slugify            4.0.1              pyh9f0ad1d_0\r\npython_abi                3.7                     1_cp37m\r\npytorch                   1.6.0           py3.7_cuda9.2.148_cudnn7.6.3_0\r\npytz                      2020.1             pyh9f0ad1d_0\r\npyyaml                    5.3.1            py37h8f50634_0\r\npyzmq                     19.0.2           py37hac76be4_0\r\nreadline                  8.0                  he28a2e2_2\r\nregex                     2020.7.14        py37h8f50634_0\r\nrequests                  2.24.0             pyh9f0ad1d_0\r\nrsa                       4.6                pyh9f0ad1d_0\r\ns3cmd                     2.1.0                    pypi_0    pypi\r\ns3transfer                0.3.3            py37hc8dfbb8_1\r\nsacremoses                0.0.43                   pypi_0    pypi\r\nscikit-learn              0.23.2           py37h6785257_0\r\nscipy                     1.5.2            py37hb14ef9d_0\r\nseaborn                   0.10.1                        1\r\nseaborn-base              0.10.1                     py_1\r\nsend2trash                1.5.0                      py_0\r\nsentencepiece             0.1.91                   pypi_0    pypi\r\nsetuptools                49.6.0           py37hc8dfbb8_0\r\nsix                       1.15.0             pyh9f0ad1d_0\r\nslugify                   0.0.1                      py_2\r\nsmart_open                2.1.1              pyh9f0ad1d_0\r\nsnowballstemmer           2.0.0                      py_0\r\nsoupsieve                 2.0.1                      py_1\r\nspacy                     2.3.2                    pypi_0    pypi\r\nspacy-model-en_core_web_sm 2.3.1              pyh9f0ad1d_0\r\nsphinx                    3.2.1                      py_0\r\nsphinx-material           0.0.30                     py_1\r\nsphinxcontrib-applehelp   1.0.2                      py_0\r\nsphinxcontrib-devhelp     1.0.2                      py_0\r\nsphinxcontrib-htmlhelp    1.0.3                      py_0\r\nsphinxcontrib-jsmath      1.0.1                      py_0\r\nsphinxcontrib-qthelp      1.0.3                      py_0\r\nsphinxcontrib-serializinghtml 1.1.4                      py_0\r\nsqlalchemy                1.3.19           py37h8f50634_0\r\nsqlite                    3.33.0               h4cf870e_0\r\nsrsly                     1.0.2                    pypi_0    pypi\r\nstatsmodels               0.12.0           py37h8f50634_0\r\nstevedore                 3.2.1            py37hc8dfbb8_0\r\ntensorboardx              2.1                      pypi_0    pypi\r\nteradata                  15.10.0.21               py37_0\r\nterminado                 0.8.3            py37hc8dfbb8_1\r\ntestpath                  0.4.4                      py_0\r\ntext-unidecode            1.3                        py_0\r\nthinc                     7.4.1                    pypi_0    pypi\r\nthreadpoolctl             2.1.0              pyh5ca1d4c_0\r\ntini                      0.18.0            h14c3975_1001\r\ntk                        8.6.10               hed695b0_0\r\ntokenizers                0.8.1rc1                 pypi_0    pypi\r\ntoml                      0.10.1             pyh9f0ad1d_0\r\ntorchvision               0.7.0                 py37_cu92\r\ntornado                   6.0.4            py37h8f50634_1\r\ntqdm                      4.48.2             pyh9f0ad1d_0\r\ntraitlets                 5.0.0            py37hc8dfbb8_0\r\ntransformers              3.0.2                    pypi_0    pypi\r\ntyped-ast                 1.4.1            py37h516909a_0\r\ntyping_extensions         3.7.4.2                    py_0\r\nunidecode                 1.1.1                      py_0\r\nurllib3                   1.25.10                    py_0\r\nwasabi                    0.8.0                    pypi_0    pypi\r\nwcwidth                   0.2.5              pyh9f0ad1d_1\r\nwebencodings              0.5.1                      py_1\r\nwheel                     0.35.1             pyh9f0ad1d_0\r\nword2number               1.1                      pypi_0    pypi\r\nwrapt                     1.11.2           py37h8f50634_0\r\nxlsxwriter                1.3.3              pyh9f0ad1d_0\r\nxz                        5.2.5                h516909a_1\r\nyaml                      0.2.5                h516909a_0\r\nzeromq                    4.3.2                he1b5a44_3\r\nzipp                      3.1.0                      py_0\r\nzlib                      1.2.11            h516909a_1009\r\nzstd                      1.4.5                h6597ccf_2\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n# First, train the LM (this works):\r\nallennlp train --force --include-package src --serialization-dir tmp/elmo_lm_tran1 configs/bidirectional_language_model_part_notes.jsonnet\r\n\r\n# Second, train the NER model (this is what fails and produces the error):\r\nallennlp train --force --include-package src --serialization-dir tmp/ner_elmo_lm_tran1 configs/train_lstm_nobi_char_elmo1_v2.jsonnet\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n<details>\r\n<summary><b>Contents of Language Model config file <code>bidirectional_language_model_part_notes.jsonnet</code></b></summary>\r\n\r\n```\r\n{\r\n  dataset_reader: {\r\n    type: 'language_model_conll_reader',\r\n    //\"tokenizer\": {\r\n    //    \"type\": \"just_spaces\"\r\n    //},\r\n    token_indexers: {\r\n      tokens: {\r\n        type: 'single_id',\r\n      },\r\n      token_characters: {\r\n        type: 'elmo_characters',\r\n      },\r\n    },\r\n    //\"max_sequence_length\": 400,\r\n    //\"start_tokens\": [\"<S>\"],\r\n    //\"end_tokens\": [\"</S>\"]\r\n  },\r\n  train_data_path: 'data/processed/no_bi_tags/new_model1_train.txt',\r\n  model: {\r\n    type: 'language_model',\r\n    bidirectional: true,\r\n    //\"num_samples\": 8192,\r\n    sparse_embeddings: true,\r\n    text_field_embedder: {\r\n      //\"allow_unmatched_keys\": true,\r\n      token_embedders: {\r\n        //tokens: {\r\n        //          type: 'embedding',\r\n        //          pretrained_file: 'models/word2vec_newtoken1.txt',\r\n        //          embedding_dim: 50,\r\n        //          trainable: false\r\n        //      },\r\n        tokens: {\r\n          type: 'empty',\r\n        },\r\n        token_characters: {\r\n          type: 'character_encoding',\r\n          embedding: {\r\n            num_embeddings: 262,\r\n            embedding_dim: 16,\r\n          },\r\n          encoder: {\r\n            type: 'cnn-highway',\r\n            activation: 'relu',\r\n            embedding_dim: 16,\r\n            filters: [\r\n              [1, 32],\r\n              [2, 32],\r\n              [3, 64],\r\n              [4, 128],\r\n              [5, 256],\r\n              [6, 512],\r\n              [7, 1024],\r\n            ],\r\n            num_highway: 2,\r\n            projection_dim: 512,\r\n            projection_location: 'after_highway',\r\n            do_layer_norm: true,\r\n          },\r\n        },\r\n      },\r\n    },\r\n    dropout: 0.1,\r\n    contextualizer: {\r\n      type: 'bidirectional_language_model_transformer',\r\n      input_dim: 512,\r\n      hidden_dim: 2048,\r\n      num_layers: 6,\r\n      dropout: 0.1,\r\n      input_dropout: 0.1,\r\n    },\r\n  },\r\n  data_loader: {\r\n    batch_size: 64,\r\n  },\r\n  distributed: {\r\n    cuda_devices: std.range(0, 8 - 1),\r\n  },\r\n  trainer: {\r\n    num_epochs: 10,\r\n    optimizer: {\r\n      type: 'dense_sparse_adam',\r\n    },\r\n    // TODO(brendanr): Needed with transformer too?\r\n    // \"grad_norm\": 10.0,\r\n    learning_rate_scheduler: {\r\n      type: 'noam',\r\n      // See https://github.com/allenai/calypso/blob/master/calypso/train.py#L401\r\n      model_size: 512,\r\n      // See https://github.com/allenai/calypso/blob/master/bin/train_transformer_lm1b.py#L51.\r\n      // Adjusted based on our sample size relative to Calypso's.\r\n      warmup_steps: 6000,\r\n    },\r\n    //\"should_log_learning_rate\": true\r\n  },\r\n}\r\n```\r\n<p>\r\n</p>\r\n</details>\r\n\r\n<details>\r\n<summary><b>Contents of NER model config file <code>train_lstm_nobi_char_elmo1_v2.jsonnet</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n{\r\n  dataset_reader: {\r\n    type: 'conll_03_reader_elmo',\r\n    token_indexers: {\r\n      tokens: {\r\n        type: 'single_id',\r\n        namespace: 'tokens',\r\n      },\r\n      elmo: {\r\n        type: 'elmo_characters',\r\n        //namespace: 'token_characters'\r\n      },\r\n    },\r\n    lazy: false,\r\n  },\r\n  train_data_path: 'data/processed/no_bi_tags/new_model1_train.txt',\r\n  validation_data_path: 'data/processed/no_bi_tags/new_model1_val.txt',\r\n  model: {\r\n    //type: 'ner_lstm_crf',\r\n    type: 'NER_LSTM',  //without crf\r\n    embedder: {\r\n      token_embedders: {\r\n        tokens: {\r\n          type: 'embedding',\r\n          pretrained_file: 'models/word2vec_newtoken1.txt',\r\n          embedding_dim: 50,\r\n          trainable: false,\r\n        },\r\n        //elmo: {\r\n        //    type: 'elmo_token_embedder',\r\n        //    options_file: \"models/elmo_2x4096_512_2048cnn_2xhighway_options.json\",\r\n        //    weight_file: \"models/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\",\r\n        //    do_layer_norm: false,\r\n        //    dropout: 0.3\r\n        // }\r\n        elmo: {\r\n          type: 'bidirectional_lm_token_embedder',\r\n          archive_file: 'tmp/elmo_lm_tran1/model.tar.gz',\r\n          dropout: 0.2,\r\n          bos_eos_tokens: ['<S>', '</S>'],\r\n          remove_bos_eos: true,\r\n          requires_grad: false,\r\n        },\r\n      },\r\n    },\r\n    encoder: {\r\n      type: 'lstm',\r\n      input_size: 1024 + 50,\r\n      hidden_size: 25,\r\n      dropout: 0.3,\r\n      bidirectional: true,\r\n    },\r\n  },\r\n  data_loader: {\r\n    batch_size: 128,\r\n  },\r\n  trainer: {\r\n    num_epochs: 22,\r\n    patience: 10,\r\n    cuda_device: 0,\r\n    grad_clipping: 5.0,\r\n    validation_metric: '-loss',\r\n    optimizer: {\r\n      type: 'adam',\r\n      lr: 0.01,\r\n    },\r\n  },\r\n}\r\n```\r\n\r\n</p>\r\n</details>", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4646/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4646/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4640", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4640/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4640/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4640/events", "html_url": "https://github.com/allenai/allennlp/issues/4640", "id": 701743465, "node_id": "MDU6SXNzdWU3MDE3NDM0NjU=", "number": 4640, "title": "'Predictor' object has no attribute 'predict'", "user": {"login": "GuanNiPiShi123", "id": 46016296, "node_id": "MDQ6VXNlcjQ2MDE2Mjk2", "avatar_url": "https://avatars.githubusercontent.com/u/46016296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GuanNiPiShi123", "html_url": "https://github.com/GuanNiPiShi123", "followers_url": "https://api.github.com/users/GuanNiPiShi123/followers", "following_url": "https://api.github.com/users/GuanNiPiShi123/following{/other_user}", "gists_url": "https://api.github.com/users/GuanNiPiShi123/gists{/gist_id}", "starred_url": "https://api.github.com/users/GuanNiPiShi123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GuanNiPiShi123/subscriptions", "organizations_url": "https://api.github.com/users/GuanNiPiShi123/orgs", "repos_url": "https://api.github.com/users/GuanNiPiShi123/repos", "events_url": "https://api.github.com/users/GuanNiPiShi123/events{/privacy}", "received_events_url": "https://api.github.com/users/GuanNiPiShi123/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-09-15T08:55:34Z", "updated_at": "2020-09-15T19:47:54Z", "closed_at": "2020-09-15T19:47:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nfrom allennlp_models.rc import bidaf\r\nfrom allennlp.predictors.predictor import Predictor\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/bidaf-elmo-model-2020.03.19.tar.gz\")\r\npredictor.predict(\r\n  passage=\"The Matrix is a 1999 science fiction action film written and directed by The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\",\r\n  question=\"Who stars in The Matrix?\"\r\n)\r\n\r\nI run this script but have the \"AttributeError: 'Predictor' object has no attribute 'predict'\"   how to solve it?\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ ] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [ ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ ] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4640/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4640/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4627", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4627/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4627/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4627/events", "html_url": "https://github.com/allenai/allennlp/issues/4627", "id": 694092655, "node_id": "MDU6SXNzdWU2OTQwOTI2NTU=", "number": 4627, "title": "No module named allennlp.run", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2020-09-05T14:03:21Z", "updated_at": "2020-09-11T21:16:53Z", "closed_at": "2020-09-11T21:16:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi\r\nI installed allennlp 1.0.0, and then I want to use it to run this repo:\r\nhttps://github.com/mrqa/MRQA-Shared-Task-2019/tree/master/baseline\r\nI write this command to run bert-base on some QA datasets:\r\n\r\npython -m allennlp.run train https://multiqa.s3.amazonaws.com/config/MRQA_BERTbase.json -s Models/SQuAD -o \"{'train_data_path': 'https://mrqa.s3.us-east-2.amazonaws.com/data/train/SQuAD.jsonl.gz', 'validation_data_path': 'https://mrqa.s3.us-east-2.amazonaws.com/data/dev/SQuAD.jsonl.gz', 'trainer': {'cuda_device': -1, 'num_epochs': 2, 'optimizer': {'type': 'bert_adam', 'lr': 3e-05, 'warmup': 0.1, 't_total': 29000}}}\" --include-package mrqa_allennlp\r\n\r\nbut then it says \r\nNo module named allennlp.run\r\n\r\nthanks for your help \r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4627/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4627/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4623", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4623/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4623/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4623/events", "html_url": "https://github.com/allenai/allennlp/issues/4623", "id": 692388369, "node_id": "MDU6SXNzdWU2OTIzODgzNjk=", "number": 4623, "title": "Cannot train language_model: RuntimeError: Tensors must be CUDA and dense", "user": {"login": "tpanza", "id": 19810086, "node_id": "MDQ6VXNlcjE5ODEwMDg2", "avatar_url": "https://avatars.githubusercontent.com/u/19810086?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tpanza", "html_url": "https://github.com/tpanza", "followers_url": "https://api.github.com/users/tpanza/followers", "following_url": "https://api.github.com/users/tpanza/following{/other_user}", "gists_url": "https://api.github.com/users/tpanza/gists{/gist_id}", "starred_url": "https://api.github.com/users/tpanza/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tpanza/subscriptions", "organizations_url": "https://api.github.com/users/tpanza/orgs", "repos_url": "https://api.github.com/users/tpanza/repos", "events_url": "https://api.github.com/users/tpanza/events{/privacy}", "received_events_url": "https://api.github.com/users/tpanza/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2020-09-03T21:31:31Z", "updated_at": "2020-10-02T14:40:03Z", "closed_at": "2020-09-08T17:17:02Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n0 | 2020-09-03 12:39:41,240 - INFO - allennlp.training.trainer - Beginning training.\r\n0 | 2020-09-03 12:39:41,240 - INFO - allennlp.training.trainer - Epoch 0/9\r\n0 | 2020-09-03 12:39:41,241 - INFO - allennlp.training.trainer - Worker 0 memory usage MB: 2984.032\r\n0 | 2020-09-03 12:39:41,241 - INFO - allennlp.training.trainer - Worker 1 memory usage MB: 2985.344\r\n0 | 2020-09-03 12:39:41,241 - INFO - allennlp.training.trainer - Worker 2 memory usage MB: 2988.028\r\n0 | 2020-09-03 12:39:41,241 - INFO - allennlp.training.trainer - Worker 3 memory usage MB: 2984.496\r\n0 | 2020-09-03 12:39:41,241 - INFO - allennlp.training.trainer - Worker 4 memory usage MB: 2989.064\r\n0 | 2020-09-03 12:39:41,241 - INFO - allennlp.training.trainer - Worker 5 memory usage MB: 2987.996\r\n0 | 2020-09-03 12:39:41,241 - INFO - allennlp.training.trainer - Worker 6 memory usage MB: 2988.592\r\n0 | 2020-09-03 12:39:41,241 - INFO - allennlp.training.trainer - Worker 7 memory usage MB: 2991.332\r\nreading instances: 0it [00:00, ?it/s]0 | 2020-09-03 12:39:41,601 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1614\r\n0 | 2020-09-03 12:39:41,601 - INFO - allennlp.training.trainer - GPU 1 memory usage MB: 1614\r\n0 | 2020-09-03 12:39:41,601 - INFO - allennlp.training.trainer - GPU 2 memory usage MB: 1614\r\n0 | 2020-09-03 12:39:41,601 - INFO - allennlp.training.trainer - GPU 3 memory usage MB: 1614\r\n0 | 2020-09-03 12:39:41,601 - INFO - allennlp.training.trainer - GPU 4 memory usage MB: 1614\r\n0 | 2020-09-03 12:39:41,601 - INFO - allennlp.training.trainer - GPU 5 memory usage MB: 1614\r\n0 | 2020-09-03 12:39:41,601 - INFO - allennlp.training.trainer - GPU 6 memory usage MB: 1614\r\n0 | 2020-09-03 12:39:41,601 - INFO - allennlp.training.trainer - GPU 7 memory usage MB: 1614\r\nreading instances: 0it [00:00, ?it/s]0 | 2020-09-03 12:39:41,603 - INFO - allennlp.training.trainer - Training\r\nreading instances: 0it [00:00, ?it/s]0 | 2020-09-03 12:39:41,605 - INFO - src.models.language_model_conll_reader - Loading data from data/processed/no_bi_tags/new_model1_train.txt\r\nreading instances: 0it [00:00, ?it/s]/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/metrics/average.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n  total_value = torch.tensor(_total_value).to(device)\r\nreading instances: 63it [00:00, 91.52it/s]\r\n/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/metrics/average.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n  total_value = torch.tensor(_total_value).to(device)\r\nreading instances: 63it [00:00, 85.48it/s]\r\n/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/metrics/average.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n  total_value = torch.tensor(_total_value).to(device)\r\n0it [00:00, ?it/s]\r\nreading instances: 63it [00:00, 83.76it/s]\r\n/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/metrics/average.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n  total_value = torch.tensor(_total_value).to(device)\r\nreading instances: 63it [00:00, 83.20it/s]\r\n/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/metrics/average.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n  total_value = torch.tensor(_total_value).to(device)\r\nreading instances: 63it [00:00, 81.84it/s]\r\n/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/metrics/average.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n  total_value = torch.tensor(_total_value).to(device)\r\n/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/metrics/average.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n  total_value = torch.tensor(_total_value).to(device)\r\nreading instances: 63it [00:00, 79.57it/s]\r\nreading instances: 63it [00:00, 80.02it/s]\r\n/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/metrics/average.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n  total_value = torch.tensor(_total_value).to(device)\r\nreading instances: 63it [00:00, 79.14it/s]\r\nTraceback (most recent call last):\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 118, in train_model_from_args\r\n    file_friendly_logging=args.file_friendly_logging,\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 177, in train_model_from_file\r\n    file_friendly_logging=file_friendly_logging,\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 304, in train_model\r\n    nprocs=num_procs,\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 200, in spawn\r\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 158, in start_processes\r\n    while not context.join():\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 2 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 439, in _train_worker\r\n    metrics = train_loop.run()\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 501, in run\r\n    return self.trainer.train()\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 867, in train\r\n    train_metrics = self._train_epoch(epoch)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 589, in _train_epoch\r\n    batch_outputs = self.batch_outputs(batch, for_training=True)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 479, in batch_outputs\r\n    output_dict = self._pytorch_model(**batch)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 511, in forward\r\n    output = self.module(*inputs[0], **kwargs[0])\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp_models/lm/models/language_model.py\", line 297, in forward\r\n    self._perplexity(average_loss)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/metrics/average.py\", line 37, in __call__\r\n    dist.all_reduce(count, op=dist.ReduceOp.SUM)\r\n  File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py\", line 936, in all_reduce\r\n    work = _default_pg.allreduce([tensor], opts)\r\nRuntimeError: Tensors must be CUDA and dense\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- allenai/allennlp/issues/4554\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Red Hat Enterprise Linux Server release 7.6 (Maipo), `Linux  3.10.0-957.12.2.el7.x86_64 #1 SMP Fri Apr 19 21:09:07 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux`\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.8 `3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08)`\r\nAlso: `cudatoolkit` 9.2, installed via `conda`\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalabaster==0.7.12\r\nalembic==1.4.2\r\nallennlp==1.1.0rc4\r\nallennlp-models==1.1.0rc4\r\nappdirs==1.4.3\r\nargon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1596629848788/work\r\nastroid @ file:///home/conda/feedstock_root/build_artifacts/astroid_1591645081755/work\r\nattrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1597959372343/work\r\nBabel==2.8.0\r\nbackcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\r\nbackports.functools-lru-cache==1.6.1\r\nbeautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1597679909012/work\r\nblack @ file:///home/conda/feedstock_root/build_artifacts/black-recipe_1596181673569/work\r\nbleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1588608214987/work\r\nblis==0.4.1\r\nboto==2.49.0\r\nboto3 @ file:///home/conda/feedstock_root/build_artifacts/boto3_1599083817494/work\r\nbotocore @ file:///home/conda/feedstock_root/build_artifacts/botocore_1599079795233/work\r\nbrotlipy==0.7.0\r\nbz2file==0.98\r\ncachetools @ file:///home/conda/feedstock_root/build_artifacts/cachetools_1593420445823/work\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1595805535531/work\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncliff @ file:///home/conda/feedstock_root/build_artifacts/cliff_1596473693634/work\r\ncmaes @ file:///home/conda/feedstock_root/build_artifacts/cmaes_1596014311252/work\r\ncmd2 @ file:///home/conda/feedstock_root/build_artifacts/cmd2_1591809284986/work\r\ncolorama==0.4.3\r\ncolorlog==4.2.1\r\nconllu==4.0\r\ncryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography_1598621005849/work\r\ncss-html-js-minify @ file:///home/conda/feedstock_root/build_artifacts/css-html-js-minify_1589201803800/work\r\ncycler==0.10.0\r\ncymem==2.0.3\r\nCython @ file:///home/conda/feedstock_root/build_artifacts/cython_1594253470382/work\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndocutils==0.15.2\r\nen-core-web-sm @ file:///home/conda/feedstock_root/build_artifacts/spacy-model-en_core_web_1595437534769/work/sm\r\nentrypoints==0.3\r\nfilelock==3.0.12\r\nflake8 @ file:///home/conda/feedstock_root/build_artifacts/flake8_1594584774608/work\r\nftfy==5.8\r\nfuture==0.18.2\r\ngensim @ file:///home/conda/feedstock_root/build_artifacts/gensim_1589441213562/work\r\ngoogle-api-core @ file:///home/conda/feedstock_root/build_artifacts/google-api-core-split_1597353416133/work\r\ngoogle-auth @ file:///home/conda/feedstock_root/build_artifacts/google-auth_1598972371532/work\r\ngoogle-cloud-core @ file:///home/conda/feedstock_root/build_artifacts/google-cloud-core_1596721852962/work\r\ngoogle-cloud-storage @ file:///home/conda/feedstock_root/build_artifacts/google-cloud-storage_1598557481535/work\r\ngoogle-crc32c @ file:///home/conda/feedstock_root/build_artifacts/google-crc32c_1597069930917/work\r\ngoogle-resumable-media @ file:///home/conda/feedstock_root/build_artifacts/google-resumable-media_1598452053521/work\r\ngoogleapis-common-protos==1.51.0\r\ngrpcio @ file:///home/conda/feedstock_root/build_artifacts/grpcio_1596715635580/work\r\nh5py==2.10.0\r\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1593328102638/work\r\nimagesize==1.2.0\r\nimportlib-metadata @ file:///home/conda/feedstock_root/build_artifacts/importlib-metadata_1593211369179/work\r\niniconfig==1.0.1\r\nipykernel @ file:///home/conda/feedstock_root/build_artifacts/ipykernel_1595446871027/work/dist/ipykernel-5.3.4-py3-none-any.whl\r\nipython @ file:///home/conda/feedstock_root/build_artifacts/ipython_1598749946943/work\r\nipython-genutils==0.2.0\r\nisort @ file:///home/conda/feedstock_root/build_artifacts/isort_1599134253980/work\r\njedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1595018882455/work\r\nJinja2==2.11.2\r\njmespath @ file:///home/conda/feedstock_root/build_artifacts/jmespath_1589369830981/work\r\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1593624380152/work\r\njson5 @ file:///home/conda/feedstock_root/build_artifacts/json5_1591810480056/work\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\njupyter-client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1598486169312/work\r\njupyter-core==4.6.3\r\njupyterlab==2.2.6\r\njupyterlab-server @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_server_1593951277307/work\r\nkiwisolver==1.2.0\r\nlazy-object-proxy==1.4.3\r\nlivereload @ file:///home/conda/feedstock_root/build_artifacts/livereload_1598114753789/work\r\nlunr==0.5.8\r\nlxml @ file:///home/conda/feedstock_root/build_artifacts/lxml_1594322698782/work\r\nMako @ file:///home/conda/feedstock_root/build_artifacts/mako_1595925083607/work\r\nMarkdown @ file:///home/conda/feedstock_root/build_artifacts/markdown_1589366472132/work\r\nMarkupSafe==1.1.1\r\nmatplotlib @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-base_1597952254444/work\r\nmccabe==0.6.1\r\nmistune==0.8.4\r\nmkdocs @ file:///home/conda/feedstock_root/build_artifacts/mkdocs_1591017186129/work\r\nmkdocs-material @ file:///home/conda/feedstock_root/build_artifacts/mkdocs-material_1598971568401/work\r\nmore-itertools==8.5.0\r\nmurmurhash==1.0.2\r\nmypy @ file:///home/conda/feedstock_root/build_artifacts/mypy_1592923020520/work\r\nmypy-extensions==0.4.3\r\nnbconvert==5.6.1\r\nnbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1594060262917/work\r\nnetworkx==2.5\r\nnltk==3.4.4\r\nnotebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1597285190767/work\r\nnumpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1597938346492/work\r\nolefile==0.46\r\noptuna @ file:///home/conda/feedstock_root/build_artifacts/optuna_1598323699360/work\r\noverrides==3.1.0\r\npackaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1589925210001/work\r\npandas @ file:///home/conda/feedstock_root/build_artifacts/pandas_1598294454723/work\r\npandocfilters==1.4.2\r\nparso @ file:///home/conda/feedstock_root/build_artifacts/parso_1595548966091/work\r\npathspec==0.8.0\r\npatsy==0.5.1\r\npbr @ file:///home/conda/feedstock_root/build_artifacts/pbr_1598996708473/work\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow @ file:///home/conda/feedstock_root/build_artifacts/pillow_1594213010297/work\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprettytable==0.7.2\r\nprometheus-client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1590412252446/work\r\nprompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1598885455507/work\r\nprotobuf==3.13.0\r\npsutil @ file:///home/conda/feedstock_root/build_artifacts/psutil_1594826921622/work\r\nptyprocess==0.6.0\r\npy==1.9.0\r\npy-rouge==1.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.7\r\npycodestyle @ file:///home/conda/feedstock_root/build_artifacts/pycodestyle_1589305246696/work\r\npycorenlp==0.3.0\r\npycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1593275161868/work\r\npyflakes==2.2.0\r\nPygments==2.6.1\r\npylint @ file:///home/conda/feedstock_root/build_artifacts/pylint_1598117058668/work\r\npymdown-extensions @ file:///home/conda/feedstock_root/build_artifacts/pymdown-extensions_1597166028984/work\r\nPyment==0.3.3\r\npyneuroner==1.0.8\r\npyOpenSSL==19.1.0\r\npyparsing==2.4.7\r\npyperclip @ file:///home/conda/feedstock_root/build_artifacts/pyperclip_1591810382257/work\r\npyrsistent==0.16.0\r\nPySocks==1.7.1\r\npytest==6.0.1\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npython-magic==0.4.18\r\npython-slugify @ file:///home/conda/feedstock_root/build_artifacts/python-slugify_1593573453419/work\r\npytz==2020.1\r\nPyYAML==5.3.1\r\npyzmq==19.0.2\r\nregex @ file:///home/conda/feedstock_root/build_artifacts/regex_1594799371287/work\r\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1592425495151/work\r\nrsa @ file:///home/conda/feedstock_root/build_artifacts/rsa_1591996208734/work\r\ns3cmd==2.1.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn @ file:///home/conda/feedstock_root/build_artifacts/scikit-learn_1596546074663/work\r\nscipy @ file:///home/conda/feedstock_root/build_artifacts/scipy_1595583586868/work\r\nseaborn @ file:///home/conda/feedstock_root/build_artifacts/seaborn-base_1591878760859/work\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1590081179328/work\r\nslugify==0.0.1\r\nsmart-open @ file:///home/conda/feedstock_root/build_artifacts/smart_open_1598572939086/work\r\nsnowballstemmer==2.0.0\r\nsoupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1597680516047/work\r\nspacy==2.3.2\r\nSphinx @ file:///home/conda/feedstock_root/build_artifacts/sphinx_1597405755328/work\r\nsphinx-material @ file:///home/conda/feedstock_root/build_artifacts/sphinx-material_1597663680729/work\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nSQLAlchemy @ file:///home/conda/feedstock_root/build_artifacts/sqlalchemy_1597701920245/work\r\nsrsly==1.0.2\r\nstatsmodels @ file:///home/conda/feedstock_root/build_artifacts/statsmodels_1598551025620/work\r\nstevedore @ file:///home/conda/feedstock_root/build_artifacts/stevedore_1598982656343/work\r\ntensorboardX==2.1\r\nteradata==15.10.0.21\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\ntext-unidecode==1.3\r\nthinc==7.4.1\r\nthreadpoolctl @ file:///tmp/tmp79xdzxkt/threadpoolctl-2.1.0-py3-none-any.whl\r\ntokenizers==0.8.1rc1\r\ntoml @ file:///home/conda/feedstock_root/build_artifacts/toml_1589469402899/work\r\ntorch==1.6.0\r\ntorchvision==0.7.0\r\ntornado==6.0.4\r\ntqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1596476591553/work\r\ntraitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1598976315411/work\r\ntransformers==3.0.2\r\ntyped-ast==1.4.1\r\ntyping-extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1588470653596/work\r\nUnidecode==1.1.1\r\nurllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1595434816409/work\r\nwasabi==0.8.0\r\nwcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1595859607677/work\r\nwebencodings==0.5.1\r\nword2number==1.1\r\nwrapt==1.11.2\r\nXlsxWriter @ file:///home/conda/feedstock_root/build_artifacts/xlsxwriter_1597362230404/work\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```bash\r\nallennlp train --force --include-package src --serialization-dir tmp/elmo_lm_tran1 configs/bidirectional_language_model_part_notes.jsonnet\r\n```\r\n\r\nContents of `configs/bidirectional_language_model_part_notes.jsonnet`:\r\n\r\n```\r\n{\r\n  dataset_reader: {\r\n    type: 'language_model_conll_reader',\r\n    //\"tokenizer\": {\r\n    //    \"type\": \"just_spaces\"\r\n    //},\r\n    token_indexers: {\r\n      tokens: {\r\n        type: 'single_id',\r\n      },\r\n      token_characters: {\r\n        type: 'elmo_characters',\r\n      },\r\n    },\r\n    //\"max_sequence_length\": 400,\r\n    //\"start_tokens\": [\"<S>\"],\r\n    //\"end_tokens\": [\"</S>\"]\r\n  },\r\n  train_data_path: 'data/processed/no_bi_tags/new_model1_train.txt',\r\n  model: {\r\n    type: 'language_model',\r\n    bidirectional: true,\r\n    //\"num_samples\": 8192,\r\n    sparse_embeddings: true,\r\n    text_field_embedder: {\r\n      //\"allow_unmatched_keys\": true,\r\n      token_embedders: {\r\n        //tokens: {\r\n        //          type: 'embedding',\r\n        //          pretrained_file: 'models/word2vec_newtoken1.txt',\r\n        //          embedding_dim: 50,\r\n        //          trainable: false\r\n        //      },\r\n        tokens: {\r\n          type: 'empty',\r\n        },\r\n        token_characters: {\r\n          type: 'character_encoding',\r\n          embedding: {\r\n            num_embeddings: 262,\r\n            embedding_dim: 16,\r\n          },\r\n          encoder: {\r\n            type: 'cnn-highway',\r\n            activation: 'relu',\r\n            embedding_dim: 16,\r\n            filters: [\r\n              [1, 32],\r\n              [2, 32],\r\n              [3, 64],\r\n              [4, 128],\r\n              [5, 256],\r\n              [6, 512],\r\n              [7, 1024],\r\n            ],\r\n            num_highway: 2,\r\n            projection_dim: 512,\r\n            projection_location: 'after_highway',\r\n            do_layer_norm: true,\r\n          },\r\n        },\r\n      },\r\n    },\r\n    dropout: 0.1,\r\n    contextualizer: {\r\n      type: 'bidirectional_language_model_transformer',\r\n      input_dim: 512,\r\n      hidden_dim: 2048,\r\n      num_layers: 6,\r\n      dropout: 0.1,\r\n      input_dropout: 0.1,\r\n    },\r\n  },\r\n  data_loader: {\r\n    batch_size: 64,\r\n  },\r\n  distributed: {\r\n    cuda_devices: std.range(0, 8 - 1),\r\n  },\r\n  trainer: {\r\n    num_epochs: 10,\r\n    optimizer: {\r\n      type: 'dense_sparse_adam',\r\n    },\r\n    // TODO(brendanr): Needed with transformer too?\r\n    // \"grad_norm\": 10.0,\r\n    learning_rate_scheduler: {\r\n      type: 'noam',\r\n      // See https://github.com/allenai/calypso/blob/master/calypso/train.py#L401\r\n      model_size: 512,\r\n      // See https://github.com/allenai/calypso/blob/master/bin/train_transformer_lm1b.py#L51.\r\n      // Adjusted based on our sample size relative to Calypso's.\r\n      warmup_steps: 6000,\r\n    },\r\n    //\"should_log_learning_rate\": true\r\n  },\r\n}\r\n```\r\n\r\nThe `dataset_reader` and the data itself in the `train_data_path` are custom code and custom data, respectively. I imagine that part is not the issue, since we are able to build a vocabulary and attempt to train. Should be reproducible with any data and dataset_reader.\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4623/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4623/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4614", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4614/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4614/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4614/events", "html_url": "https://github.com/allenai/allennlp/issues/4614", "id": 688394371, "node_id": "MDU6SXNzdWU2ODgzOTQzNzE=", "number": 4614, "title": "FromParams doesn't handle kwargs on base class", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-28T22:49:32Z", "updated_at": "2020-09-06T09:33:43Z", "closed_at": "2020-08-31T19:57:54Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nIf your create class that inherits from `FromParams`, and this class takes `**kwargs` in its constructor, then calling the `.from_params` method on this class will fail. See \"Steps to reproduce\" below.\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- This issue is similar: https://github.com/allenai/allennlp/issues/4592\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: OS X\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n-e git+git@github.com:allenai/allennlp.git@e840a589afc4bfdac0165a8650145259a7603807#egg=allennlp\r\n-e git+git@github.com:allenai/allennlp-models.git@2e5444997f416c112c0c6e02cc33175c24982049#egg=allennlp_models\r\napipkg==1.5\r\nappdirs==1.4.4\r\nappnope==0.1.0\r\nattrs==20.1.0\r\nbackcall==0.2.0\r\nblack==20.8b1\r\nbleach==3.1.5\r\nblis==0.4.1\r\nboto3==1.14.51\r\nbotocore==1.17.51\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncodecov==2.1.9\r\ncolorama==0.4.3\r\nconllu==4.0\r\ncoverage==5.2.1\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ndecorator==4.4.2\r\ndocutils==0.15\r\nexecnet==1.7.1\r\nfilelock==3.0.12\r\nflake8==3.8.3\r\nflaky==3.7.0\r\nftfy==5.8\r\nfuture==0.18.2\r\ngreenlet==0.4.16\r\nh5py==2.10.0\r\nidna==2.10\r\nimportlib-metadata==1.7.0\r\niniconfig==1.0.1\r\nipython==7.18.0\r\nipython-genutils==0.2.0\r\njedi==0.17.2\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.16.0\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\nkeyring==21.3.1\r\nkiwisolver==1.2.0\r\nlivereload==2.6.3\r\nlunr==0.5.8\r\nMarkdown==3.2.2\r\nmarkdown-include==0.5.1\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.3.1\r\nmccabe==0.6.1\r\nmkdocs==1.1.2\r\nmkdocs-material==5.5.11\r\nmkdocs-material-extensions==1.0\r\nmore-itertools==8.5.0\r\nmsgpack==0.5.6\r\nmurmurhash==1.0.2\r\nmypy==0.782\r\nmypy-extensions==0.4.3\r\nneovim==0.2.6\r\nnltk==3.5\r\nnr.collections==0.0.1\r\nnr.databind.core==0.0.16\r\nnr.databind.json==0.0.13\r\nnr.interface==0.0.3\r\nnr.metaclass==0.0.5\r\nnr.parsing.date==0.3.0\r\nnr.pylang.utils==0.0.3\r\nnr.stream==0.0.4\r\nnr.utils.re==0.1.0\r\nnumpy==1.19.1\r\noverrides==3.1.0\r\npackaging==20.4\r\nparso==0.7.1\r\npathspec==0.8.0\r\npathtools==0.1.2\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.2.0\r\npkginfo==1.5.0.1\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprompt-toolkit==3.0.6\r\nprotobuf==3.13.0\r\nptyprocess==0.6.0\r\npy==1.9.0\r\npy-cpuinfo==7.0.0\r\npy-rouge==1.1\r\npycodestyle==2.6.0\r\npydoc-markdown @ git+https://github.com/NiklasRosenstein/pydoc-markdown.git@f0bf8af1db4f11581c19d206d4ed1ab34b4854c1\r\npydocstyle==5.1.0\r\npyflakes==2.2.0\r\nPygments==2.6.1\r\npymdown-extensions==8.0\r\npyparsing==2.4.7\r\npytest==6.0.1\r\npytest-benchmark==3.2.3\r\npytest-cov==2.10.1\r\npytest-forked==1.3.0\r\npytest-xdist==2.1.0\r\npython-dateutil==2.8.1\r\nPyYAML==5.3.1\r\nreadme-renderer==26.0\r\nregex==2020.7.14\r\nrequests==2.24.0\r\nrequests-toolbelt==0.9.1\r\nresponses==0.11.0\r\nrfc3986==1.4.0\r\nruamel.yaml==0.16.10\r\nruamel.yaml.clib==0.2.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.2\r\nscipy==1.5.2\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nsnowballstemmer==2.0.0\r\nspacy==2.3.2\r\nsrsly==1.0.2\r\ntensorboardX==2.1\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.8.1rc1\r\ntoml==0.10.1\r\ntorch==1.6.0\r\ntornado==6.0.4\r\ntqdm==4.48.2\r\ntraitlets==4.3.3\r\ntransformers==3.0.2\r\ntwine==3.2.0\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.25.10\r\nwasabi==0.8.0\r\nwatchdog==0.10.3\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nword2number==1.1\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```python\r\nfrom allennlp.common.from_params import FromParams, Params\r\n\r\nclass Foo(FromParams):\r\n    def __init__(self, a: int, b: str = None, **kwargs) -> None:\r\n        self.a = a\r\n        self.b = b\r\n\r\nFoo.from_params(Params({\"a\": 2, \"b\": \"hi\"}))\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"tmp.py\", line 10, in <module>\r\n    Foo.from_params(Params({\"a\": 2, \"b\": \"hi\"}))\r\n  File \"/Users/evanw/AllenAI/allennlp/allennlp/common/from_params.py\", line 610, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/Users/evanw/AllenAI/allennlp/allennlp/common/from_params.py\", line 163, in create_kwargs\r\n    parameters = infer_params(cls, constructor)\r\n  File \"/Users/evanw/AllenAI/allennlp/allennlp/common/from_params.py\", line 140, in infer_params\r\n    super_parameters = infer_params(super_class)\r\n  File \"/Users/evanw/AllenAI/allennlp/allennlp/common/from_params.py\", line 139, in infer_params\r\n    raise RuntimeError(\"found a kwargs parameter with no inspectable super class\")\r\nRuntimeError: found a kwargs parameter with no inspectable super class\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nI would expect `Foo.from_params(Params({\"a\": 2, \"b\": \"hi\"}))` to work just fine. And if additional keyword argument were passed to `.from_params`, I would expect those to be passed on to `Foo`'s constructor as is.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4614/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4614/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4612", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4612/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4612/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4612/events", "html_url": "https://github.com/allenai/allennlp/issues/4612", "id": 687635017, "node_id": "MDU6SXNzdWU2ODc2MzUwMTc=", "number": 4612, "title": "PretrainedTransformerMismatchedIndexer fails silently when given empty strings as input.", "user": {"login": "dwadden", "id": 3091916, "node_id": "MDQ6VXNlcjMwOTE5MTY=", "avatar_url": "https://avatars.githubusercontent.com/u/3091916?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dwadden", "html_url": "https://github.com/dwadden", "followers_url": "https://api.github.com/users/dwadden/followers", "following_url": "https://api.github.com/users/dwadden/following{/other_user}", "gists_url": "https://api.github.com/users/dwadden/gists{/gist_id}", "starred_url": "https://api.github.com/users/dwadden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dwadden/subscriptions", "organizations_url": "https://api.github.com/users/dwadden/orgs", "repos_url": "https://api.github.com/users/dwadden/repos", "events_url": "https://api.github.com/users/dwadden/events{/privacy}", "received_events_url": "https://api.github.com/users/dwadden/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-08-28T00:59:28Z", "updated_at": "2020-09-01T15:27:53Z", "closed_at": "2020-09-01T15:27:53Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Checklist\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n## Description\r\n\r\nWhen the `PretrainedTransformerMismatchedEmbedder` is used to embed an empty string `''`, running `backward` on the output of the embedder produces `nan` gradients in the transformer parameters, but it's tough to track down where they came from. It's easier to see with an example; see \"Steps to Reproduce\". \r\n\r\n__Suggested fix__: The `PretrainedTransformerMismatchedEmbedder` should throw an error or give a warning when given an empty string as input. I'm happy to implement this if I can get some guidance on the appropriate files to change.\r\n\r\nThe output of `pip freeze` is long and (I think) uninformative, so I've moved it to the bottom of this bug report.\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Steps to reproduce\r\n\r\nRunnable example below. The first example will not produce `nan` gradients, but the second one will. \r\n\r\n```\r\nimport torch\r\n\r\nfrom allennlp import data\r\nfrom allennlp.data import fields\r\nfrom allennlp import modules\r\n\r\n\r\ndef check_nan_grads(words):\r\n    \"Encode a list of words, take a gradient, and check for NaN's.\"\r\n    print(f\"Checking {words}.\")\r\n    # Create indexer and embedder.\r\n    tok_indexers = {\"bert\": data.token_indexers.PretrainedTransformerMismatchedIndexer(\r\n        \"bert-base-cased\")}\r\n    token_embedder = modules.token_embedders.PretrainedTransformerMismatchedEmbedder(\r\n        \"bert-base-cased\")\r\n    embedder = modules.text_field_embedders.BasicTextFieldEmbedder({\"bert\": token_embedder})\r\n\r\n    # Convert words to tensor dict.\r\n    vocab = data.Vocabulary()\r\n    text_field = fields.TextField(\r\n        [data.Token(word) for word in words], tok_indexers)\r\n    text_field.index(vocab)\r\n    token_tensor = text_field.as_tensor(text_field.get_padding_lengths())\r\n    tensor_dict = text_field.batch_tensors([token_tensor])\r\n\r\n    # Run forward pass. We need a scalar to take the gradient of, so just take the mean of the\r\n    # embeddings.\r\n    output = embedder(tensor_dict)\r\n    loss = output.mean()\r\n    loss.backward()\r\n\r\n    # Check whether this produces an NaN in the model parameters.\r\n    for name, param in embedder.named_parameters():\r\n        grad = param.grad\r\n        if grad is not None and torch.any(torch.isnan(param.grad)):\r\n            print(\"Found NaN grad.\")\r\n            print(\"Offending tensor_dict:\")\r\n            print(tensor_dict)\r\n            print()\r\n            return\r\n\r\n    print(\"No NaN's.\")\r\n    print()\r\n\r\n\r\n####################\r\n\r\n# This works fine.\r\nexample_safe = [\"An\", \"example\"]\r\ncheck_nan_grads(example_safe)\r\n\r\n# This produces NaN grads because of the empty string.\r\nexample_bad_empty = [\"An\", \"\", \"example\"]\r\ncheck_nan_grads(example_bad_empty)\r\n\r\n# This produces NaN grads because there's a weird character the indexer doesn't know about.\r\nweird_character = \"\\uf732\\uf730\\uf730\\uf733\"\r\nprint(f\"Weird character: {weird_character}.\")\r\nexample_bad_unicode = [\"A\", weird_character, \"example\"]\r\ncheck_nan_grads(example_bad_unicode)\r\n```\r\n\r\n\r\n## Environment\r\nOS: Linux\r\nPython version: 3.7.6\r\n\r\n<details>\r\n<summary>Pip freeze output:</summary>\r\n```\r\n-e git+https://github.com/allenai/allennlp.git@73220d71cd5990f38747e50e64674a5166347e52#egg=allennlp\r\n-e git+https://github.com/allenai/allennlp-models.git@a730fed9424bcbe21186fc7866b195ea9ac7ecc5#egg=allennlp_models\r\nattrs==19.3.0\r\nautopep8 @ file:///tmp/build/80754af9/autopep8_1592412889138/work\r\nbackcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\r\nbeautifulsoup4==4.8.1\r\nblis==0.4.1\r\nboto3==1.14.20\r\nbotocore==1.17.20\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\nchardet==3.0.4\r\nclick==7.1.2\r\nconllu==3.0\r\ncymem==2.0.3\r\ndecorator==4.4.2\r\ndocutils==0.15.2\r\nfilelock==3.0.12\r\nflake8==3.8.3\r\nflaky==3.7.0\r\nfuture==0.18.2\r\nh5py==2.10.0\r\nidna==2.10\r\nimportlib-metadata @ file:///tmp/build/80754af9/importlib-metadata_1593446408836/work\r\nipdb==0.11\r\nipython==7.9.0\r\nipython-genutils==0.2.0\r\njavapackages==4.3.2\r\njedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1592619900914/work\r\njmespath==0.10.0\r\njoblib==0.16.0\r\njsonnet @ file:///home/conda/feedstock_root/build_artifacts/jsonnet_1590349750875/work\r\njsonpickle==1.4.1\r\nlxml==4.5.2\r\nmccabe==0.6.1\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nmypy @ file:///tmp/build/80754af9/mypy_1593442617121/work\r\nmypy-extensions==0.4.3\r\nnltk==3.5\r\nnumpy==1.19.0\r\noverrides==3.1.0\r\npackaging==20.4\r\npandas==0.25.2\r\nparso==0.7.0\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprompt-toolkit==2.0.10\r\nprotobuf==3.12.2\r\npsutil==5.7.0\r\nptyprocess==0.6.0\r\npy==1.9.0\r\npy-rouge==1.1\r\npycodestyle==2.6.0\r\npyflakes==2.2.0\r\nPygments==2.6.1\r\npyparsing==2.4.7\r\npytest==5.4.3\r\npython-dateutil==2.8.1\r\npython-Levenshtein==0.12.0\r\npytz==2020.1\r\nPyXB==1.2.4\r\nregex==2020.6.8\r\nrequests==2.24.0\r\nresponses==0.10.15\r\nrope==0.17.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.5.1\r\nsemantic-version==2.8.5\r\nsentencepiece==0.1.91\r\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1590081179328/work\r\nsoupsieve==2.0.1\r\nspacy==2.2.4\r\nsrsly==1.0.2\r\ntensorboardX==2.1\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.8.1rc1\r\ntoml @ file:///tmp/build/80754af9/toml_1592853716807/work\r\ntorch==1.6.0\r\ntqdm==4.47.0\r\ntraitlets==4.3.3\r\ntransformers==3.0.2\r\ntyped-ast==1.4.1\r\ntyping-extensions @ file:///tmp/build/80754af9/typing_extensions_1592847887441/work\r\nurllib3==1.25.9\r\nwasabi==0.7.0\r\nwcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1592931742287/work\r\nword2number==1.1\r\nzipp==3.1.0\r\n```\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4612/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4612/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4610", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4610/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4610/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4610/events", "html_url": "https://github.com/allenai/allennlp/issues/4610", "id": 687221745, "node_id": "MDU6SXNzdWU2ODcyMjE3NDU=", "number": 4610, "title": "Demo results for Sentiment Analysis model does not yields same results as locally downloaded model", "user": {"login": "uahmad235", "id": 30628125, "node_id": "MDQ6VXNlcjMwNjI4MTI1", "avatar_url": "https://avatars.githubusercontent.com/u/30628125?v=4", "gravatar_id": "", "url": "https://api.github.com/users/uahmad235", "html_url": "https://github.com/uahmad235", "followers_url": "https://api.github.com/users/uahmad235/followers", "following_url": "https://api.github.com/users/uahmad235/following{/other_user}", "gists_url": "https://api.github.com/users/uahmad235/gists{/gist_id}", "starred_url": "https://api.github.com/users/uahmad235/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/uahmad235/subscriptions", "organizations_url": "https://api.github.com/users/uahmad235/orgs", "repos_url": "https://api.github.com/users/uahmad235/repos", "events_url": "https://api.github.com/users/uahmad235/events{/privacy}", "received_events_url": "https://api.github.com/users/uahmad235/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/13", "html_url": "https://github.com/allenai/allennlp/milestone/13", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/13/labels", "id": 5535962, "node_id": "MDk6TWlsZXN0b25lNTUzNTk2Mg==", "number": 13, "title": "1.2", "description": "", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 24, "state": "closed", "created_at": "2020-06-12T16:16:52Z", "updated_at": "2020-11-02T18:45:36Z", "due_on": null, "closed_at": "2020-11-02T18:45:36Z"}, "comments": 3, "created_at": "2020-08-27T12:57:25Z", "updated_at": "2020-08-28T16:45:45Z", "closed_at": "2020-08-28T16:45:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nAfter using the demo for sentiment Analysis (GloVe-LSTM) on the URL :https://demo.allennlp.org/sentiment-analysis/MjI2NDEzOQ== I tried to replicate the results on the local system by following the instructions on the same URL. After downloading model on the local machine, i tried to calculate the sentiment of some generic text and its very strange that the results are different on the demo than those on my local machine.\r\n<!-- .  -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.6.9\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==1.0.0\r\nallennlp-models==1.0.0\r\nargon2-cffi==20.1.0\r\nattrs==20.1.0\r\nbackcall==0.2.0\r\nbleach==3.1.5\r\nblis==0.4.1\r\nboto3==1.14.48\r\nbotocore==1.17.48\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi==1.14.2\r\nchardet==3.0.4\r\nclick==7.1.2\r\nconllu==3.0\r\ncymem==2.0.3\r\ndataclasses==0.7\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndocutils==0.15.2\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nentrypoints==0.3\r\nfilelock==3.0.12\r\nfuture==0.18.2\r\nh5py==2.10.0\r\nidna==2.10\r\nimportlib-metadata==1.7.0\r\niniconfig==1.0.1\r\nipykernel==5.3.4\r\nipython==7.16.1\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\njedi==0.17.2\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.16.0\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\njupyter-client==6.1.7\r\njupyter-core==4.6.3\r\nMarkupSafe==1.1.1\r\nmistune==0.8.4\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nnbconvert==5.6.1\r\nnbformat==5.0.7\r\nnltk==3.5\r\nnotebook==6.1.3\r\nnumpy==1.19.1\r\noverrides==3.0.0\r\npackaging==20.4\r\npandas==1.1.1\r\npandocfilters==1.4.2\r\nparso==0.7.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprometheus-client==0.8.0\r\nprompt-toolkit==3.0.6\r\nprotobuf==3.13.0\r\nptyprocess==0.6.0\r\npy==1.9.0\r\npy-rouge==1.1\r\npycparser==2.20\r\nPygments==2.6.1\r\npyparsing==2.4.7\r\npyrsistent==0.16.0\r\npytest==6.0.1\r\npython-dateutil==2.8.1\r\npytz==2020.1\r\npyzmq==19.0.2\r\nregex==2020.7.14\r\nrequests==2.24.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.2\r\nscipy==1.5.2\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.2.4\r\nsrsly==1.0.2\r\ntensorboardX==2.1\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.7.0\r\ntoml==0.10.1\r\ntorch==1.5.1\r\ntornado==6.0.4\r\ntqdm==4.48.2\r\ntraitlets==4.3.3\r\ntransformers==2.11.0\r\nurllib3==1.25.10\r\nwasabi==0.8.0\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nzipp==3.1.0\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source: </b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.classification\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/basic_stanford_sentiment_treebank-2020.06.09.tar.gz\")\r\npredictor.predict(\r\n  sentence=\"The movie was overall good but not very excellent.\"\r\n)\r\n\r\noutput:\r\n{'logits': [0.28388914465904236, -0.3324323296546936],\r\n 'probs': [0.6493814587593079, 0.35061854124069214],\r\n 'token_ids': [24, 20, 106, 965, 45, 22, 28, 72, 473, 7],\r\n 'label': '1',\r\n 'tokens': ['The',\r\n  'movie',\r\n  'was',\r\n  'overall',\r\n  'good',\r\n  'but',\r\n  'not',\r\n  'very',\r\n  'excellent',\r\n  '.']}\r\n```\r\nNote: If we input the same text into the Demo, we get the following output:\r\nThe model is quite sure the sentence is Negative. (98.2%)\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4610/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4610/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4593", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4593/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4593/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4593/events", "html_url": "https://github.com/allenai/allennlp/issues/4593", "id": 684660140, "node_id": "MDU6SXNzdWU2ODQ2NjAxNDA=", "number": 4593, "title": "Support for make-vocab in latest version", "user": {"login": "aleSuglia", "id": 1479733, "node_id": "MDQ6VXNlcjE0Nzk3MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1479733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aleSuglia", "html_url": "https://github.com/aleSuglia", "followers_url": "https://api.github.com/users/aleSuglia/followers", "following_url": "https://api.github.com/users/aleSuglia/following{/other_user}", "gists_url": "https://api.github.com/users/aleSuglia/gists{/gist_id}", "starred_url": "https://api.github.com/users/aleSuglia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aleSuglia/subscriptions", "organizations_url": "https://api.github.com/users/aleSuglia/orgs", "repos_url": "https://api.github.com/users/aleSuglia/repos", "events_url": "https://api.github.com/users/aleSuglia/events{/privacy}", "received_events_url": "https://api.github.com/users/aleSuglia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-24T13:19:54Z", "updated_at": "2020-08-24T15:02:58Z", "closed_at": "2020-08-24T15:02:57Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I've noticed that in the latest allennlp version has been removed the useful command `make-vocab`. What's the reason for it? How can we reintroduce it without breaking the current code? I think it was extremely useful when it comes to processing a *very big* dataset avoiding running the vocabulary creation process all the time. On a related note, I was wondering whether the vocabulary creation was now using multiprocessing and whether was possible to configure the number of workers running in parallel.\r\n\r\nThanks,\r\nAlessandro", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4593/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4593/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4590", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4590/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4590/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4590/events", "html_url": "https://github.com/allenai/allennlp/issues/4590", "id": 684137165, "node_id": "MDU6SXNzdWU2ODQxMzcxNjU=", "number": 4590, "title": "how to set segment_id in pretrained_transformer model", "user": {"login": "wj-Mcat", "id": 10242208, "node_id": "MDQ6VXNlcjEwMjQyMjA4", "avatar_url": "https://avatars.githubusercontent.com/u/10242208?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wj-Mcat", "html_url": "https://github.com/wj-Mcat", "followers_url": "https://api.github.com/users/wj-Mcat/followers", "following_url": "https://api.github.com/users/wj-Mcat/following{/other_user}", "gists_url": "https://api.github.com/users/wj-Mcat/gists{/gist_id}", "starred_url": "https://api.github.com/users/wj-Mcat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wj-Mcat/subscriptions", "organizations_url": "https://api.github.com/users/wj-Mcat/orgs", "repos_url": "https://api.github.com/users/wj-Mcat/repos", "events_url": "https://api.github.com/users/wj-Mcat/events{/privacy}", "received_events_url": "https://api.github.com/users/wj-Mcat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2020-08-23T08:01:54Z", "updated_at": "2021-05-03T23:19:18Z", "closed_at": "2020-09-11T16:21:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "I train my sequence tagging model, here is my configuration file.\r\n```json\r\n{\r\n  \"dataset_reader\": {\r\n    \"type\": \"ccks-sequence_tagging\",\r\n    \"token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer_mismatched\",\r\n        \"model_name\": \"bert-base-chinese\"\r\n      }\r\n    }\r\n  },\r\n  \"train_data_path\": \"./data/train_base_phrase_clear.txt\",\r\n  \"data_loader\": {\r\n    \"batch_size\": 4,\r\n    \"shuffle\": true\r\n  },\r\n  \"model\": {\r\n    \"type\": \"crf_tagger\",\r\n    \"text_field_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer_mismatched\",\r\n          \"model_name\": \"bert-base-chinese\"\r\n        }\r\n      }\r\n    },\r\n    \"encoder\": {\r\n      \"type\": \"pass_through\",\r\n      \"input_dim\":768\r\n    },\r\n    \"calculate_span_f1\": true,\r\n    \"label_encoding\": \"BIO\"\r\n  },\r\n  \"trainer\": {\r\n    \"optimizer\": \"adam\",\r\n    \"patience\": 10,\r\n    \"cuda_device\": 2,\r\n    \"num_epochs\": 2\r\n  }\r\n}\r\n```\r\nAnd the data in `train_base_phrase_clear.txt` file is like: `word###label word###label [SEP]###O sentence-question-word###O sentence-question-word###O`.\r\n\r\nMy main problem is that the result from token_embedders doesn't contains type_ids info, which is all 0 value. I have set `[SEP]` word label in my trainning file, So I think there should be different type_ids. \r\n\r\nSo, I finnaly check that there is no type_id info from `SequenceTaggingDatasetReader` class. Then I custom this reader and add init `PretrainedTransformerTokenizer` instance to this reader, and add type_ids to Instance. B-U-T, when the data flow from dataset_reader to crf_tagger module, there is no type_id info. \r\n\r\nThis make me confused. where does `type_id` info go away ? And how to tokenize sentence with segment_id information in allennlp ? \r\n\r\nThis one is urgent. Waiting for your reply! Thanks for your later help.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4590/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4590/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4584", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4584/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4584/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4584/events", "html_url": "https://github.com/allenai/allennlp/issues/4584", "id": 683089838, "node_id": "MDU6SXNzdWU2ODMwODk4Mzg=", "number": 4584, "title": "ELMo RuntimeError: CUDA out of memory.", "user": {"login": "calusbr", "id": 25322394, "node_id": "MDQ6VXNlcjI1MzIyMzk0", "avatar_url": "https://avatars.githubusercontent.com/u/25322394?v=4", "gravatar_id": "", "url": "https://api.github.com/users/calusbr", "html_url": "https://github.com/calusbr", "followers_url": "https://api.github.com/users/calusbr/followers", "following_url": "https://api.github.com/users/calusbr/following{/other_user}", "gists_url": "https://api.github.com/users/calusbr/gists{/gist_id}", "starred_url": "https://api.github.com/users/calusbr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/calusbr/subscriptions", "organizations_url": "https://api.github.com/users/calusbr/orgs", "repos_url": "https://api.github.com/users/calusbr/repos", "events_url": "https://api.github.com/users/calusbr/events{/privacy}", "received_events_url": "https://api.github.com/users/calusbr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-08-20T20:54:10Z", "updated_at": "2020-09-30T16:24:37Z", "closed_at": "2020-09-30T16:24:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello I have a problem when running a Corpus NER with size 25 mb.\r\n\r\nSee my .jsonnet attachment\r\n\r\n```\r\n{\r\n  \"dataset_reader\": {\r\n    \"type\": \"conll2003\",\r\n    \"tag_label\": \"ner\",\r\n    \"coding_scheme\": \"BIOUL\",\r\n    \"token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"single_id\",\r\n        \"lowercase_tokens\": true\r\n      },\r\n      \"token_characters\": {\r\n        \"type\": \"characters\",\r\n        \"min_padding_length\": 3\r\n      },\r\n      \"elmo\": {\r\n        \"type\": \"elmo_characters\"\r\n     }\r\n    }\r\n  },\r\n  \"train_data_path\": \"/home/xxx/datasets/ner/wikiner/train.txt\",\r\n  \"validation_data_path\": \"/home/xxx/datasets/ner/wikiner/dev.txt\",\r\n  \"test_data_path\": \"/home/xxx/datasets/ner/wikiner/test.txt\",\r\n  \"model\": {\r\n    \"type\": \"crf_tagger\",\r\n    \"label_encoding\": \"BIOUL\",\r\n    \"calculate_span_f1\": true,\r\n    \"dropout\": 0.5,\r\n    \"include_start_end_transitions\": false,\r\n    \"text_field_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n            \"type\": \"embedding\",\r\n            \"embedding_dim\": 300,\r\n            \"pretrained_file\": \"/home/xxx/model/glove/glove_s300.zip\",\r\n            \"trainable\": true\r\n        },\r\n        \"elmo\":{\r\n          \"type\": \"elmo_token_embedder\",\r\n          \"options_file\": \"/home/lucasrodrigues/model/elmo/options.json\",\r\n          \"weight_file\": \"/home/lucasrodrigues/model/elmo/elmo_pt_weights_dgx1.hdf5\",\r\n          \"do_layer_norm\": false,\r\n          \"dropout\": 0.0\r\n        },\r\n        \"token_characters\": {\r\n            \"type\": \"character_encoding\",\r\n            \"embedding\": {\r\n            \"embedding_dim\": 16\r\n            },\r\n            \"encoder\": {\r\n            \"type\": \"cnn\",\r\n            \"embedding_dim\": 16,\r\n            \"num_filters\": 128,\r\n            \"ngram_filter_sizes\": [3],\r\n            \"conv_layer_activation\": \"relu\"\r\n            }\r\n        }\r\n      }\r\n    },\r\n    \"encoder\": {\r\n      \"type\": \"lstm\",\r\n      \"input_size\": 1452,\r\n      \"hidden_size\": 200,\r\n      \"num_layers\": 2,\r\n      \"dropout\": 0.5,\r\n      \"bidirectional\": true\r\n    },\r\n    \"verbose_metrics\": true,\r\n    \"regularizer\": [\r\n      [\r\n        \"scalar_parameters\",\r\n        {\r\n          \"type\": \"l2\",\r\n          \"alpha\": 0.1\r\n        }\r\n      ]\r\n    ]\r\n  },\r\n  \"iterator\": {\r\n    \"type\": \"basic\",\r\n    \"batch_size\":2\r\n  },\r\n  \"trainer\": {\r\n    \"optimizer\": {\r\n        \"type\": \"adam\",\r\n        \"lr\": 0.001\r\n    },\r\n    \"validation_metric\": \"+f1-measure-overall\",\r\n    \"num_serialized_models_to_keep\": 3,\r\n    \"num_epochs\": 10,\r\n    \"grad_norm\": 5.0,\r\n    \"patience\": 25,\r\n    \"cuda_device\":[0] \r\n  },\r\n}\r\n```\r\n\r\nLog Error:\r\n\r\n```\r\nFile \"/home/xxx/.conda/envs/allennlp09/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 212, in forward\r\n    self.padding, self.dilation, self.groups)\r\nRuntimeError: CUDA out of memory. Tried to allocate 12.25 GiB (GPU 0; 10.92 GiB total capacity; 1.96 GiB already allocated; 1.92 GiB free; 8.40 GiB reserved in total by PyTorch)\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4584/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4584/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4580", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4580/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4580/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4580/events", "html_url": "https://github.com/allenai/allennlp/issues/4580", "id": 682374159, "node_id": "MDU6SXNzdWU2ODIzNzQxNTk=", "number": 4580, "title": "a small pretrained model occurs error with `out of memory `", "user": {"login": "wj-Mcat", "id": 10242208, "node_id": "MDQ6VXNlcjEwMjQyMjA4", "avatar_url": "https://avatars.githubusercontent.com/u/10242208?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wj-Mcat", "html_url": "https://github.com/wj-Mcat", "followers_url": "https://api.github.com/users/wj-Mcat/followers", "following_url": "https://api.github.com/users/wj-Mcat/following{/other_user}", "gists_url": "https://api.github.com/users/wj-Mcat/gists{/gist_id}", "starred_url": "https://api.github.com/users/wj-Mcat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wj-Mcat/subscriptions", "organizations_url": "https://api.github.com/users/wj-Mcat/orgs", "repos_url": "https://api.github.com/users/wj-Mcat/repos", "events_url": "https://api.github.com/users/wj-Mcat/events{/privacy}", "received_events_url": "https://api.github.com/users/wj-Mcat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-08-20T03:22:44Z", "updated_at": "2020-09-03T16:21:59Z", "closed_at": "2020-09-03T16:21:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "When I run `bert+crf` model to complete sequence tagging task, it occurs RuntimeError:\r\n```shell\r\nRuntimeError: CUDA out of memory. Tried to allocate 148.00 MiB (GPU 2; 10.92 GiB total capacity; 7.35 GiB already allocated; 124.50 MiB free; 7.60 GiB reserved in total by PyTorch)\r\n```\r\nConfiguration file is:\r\n```json\r\n{\r\n  \"dataset_reader\": {\r\n    \"type\": \"sequence_tagging\",\r\n    \"token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer_mismatched\",\r\n        \"model_name\": \"bert-base-chinese\"\r\n      }\r\n    }\r\n  },\r\n  \"train_data_path\": \"./data/train_base_phrase.txt\",\r\n  \"data_loader\": {\r\n    \"batch_size\": 16,\r\n    \"shuffle\": true\r\n  },\r\n  \"model\": {\r\n    \"type\": \"crf_tagger\",\r\n    \"text_field_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer_mismatched\",\r\n          \"model_name\": \"bert-base-chinese\"\r\n        }\r\n      }\r\n    },\r\n    \"encoder\": {\r\n      \"type\": \"pass_through\",\r\n      \"input_dim\":768\r\n    },\r\n    \"calculate_span_f1\": true,\r\n    \"label_encoding\": \"BIO\"\r\n  },\r\n  \"trainer\": {\r\n    \"optimizer\": \"adagrad\",\r\n    \"patience\": 10,\r\n    \"cuda_device\": 2\r\n  }\r\n}\r\n```\r\n\r\nMy dataset is 2.3M. So this error make me confused.  \r\n\r\nrefer to : [pretrained-model-gpu-memory-consumption](https://discourse.allennlp.org/t/pretrained-model-gpu-memory-consumption/356) , how to make pre-trained model run well for me ?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4580/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4580/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4572", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4572/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4572/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4572/events", "html_url": "https://github.com/allenai/allennlp/issues/4572", "id": 680973004, "node_id": "MDU6SXNzdWU2ODA5NzMwMDQ=", "number": 4572, "title": "Default `add_special_tokens` to `False` in the pretrained transformer tokenizer", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/16", "html_url": "https://github.com/allenai/allennlp/milestone/16", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/16/labels", "id": 6087040, "node_id": "MDk6TWlsZXN0b25lNjA4NzA0MA==", "number": 16, "title": "2.1", "description": "", "creator": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 22, "state": "closed", "created_at": "2020-11-09T18:44:24Z", "updated_at": "2021-02-25T22:13:18Z", "due_on": "2021-02-26T08:00:00Z", "closed_at": "2021-02-25T22:13:18Z"}, "comments": 4, "created_at": "2020-08-18T11:41:12Z", "updated_at": "2021-02-22T18:44:02Z", "closed_at": "2021-02-22T18:44:02Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "It should be `False` by default, with special tokens added using the `add_special_tokens` call. All the training configs will have to be updated accordingly, or better, the code should be updated to add special tokens, at least when we know that we'll only use transformer tokenizers. We didn't do this in 1.0 because of backwards compatibility.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4572/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4572/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4567", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4567/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4567/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4567/events", "html_url": "https://github.com/allenai/allennlp/issues/4567", "id": 680369130, "node_id": "MDU6SXNzdWU2ODAzNjkxMzA=", "number": 4567, "title": "`batches_per_epoch` should not affect evaluation", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/13", "html_url": "https://github.com/allenai/allennlp/milestone/13", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/13/labels", "id": 5535962, "node_id": "MDk6TWlsZXN0b25lNTUzNTk2Mg==", "number": 13, "title": "1.2", "description": "", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 24, "state": "closed", "created_at": "2020-06-12T16:16:52Z", "updated_at": "2020-11-02T18:45:36Z", "due_on": null, "closed_at": "2020-11-02T18:45:36Z"}, "comments": 5, "created_at": "2020-08-17T16:40:11Z", "updated_at": "2020-10-20T16:13:54Z", "closed_at": "2020-10-20T16:13:54Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "@HarshTrivedi noticed that `batches_per_epoch` affects evaluation, in that it only evaluates on the first `n` batches when this is set. While it's easy to see why this happens, that's almost always wrong. We should ignore that parameter for evaluations. If you want to restrict the dataset size for evaluations, you can do it with the `max_instances` parameter.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4567/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4567/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4564", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4564/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4564/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4564/events", "html_url": "https://github.com/allenai/allennlp/issues/4564", "id": 679663965, "node_id": "MDU6SXNzdWU2Nzk2NjM5NjU=", "number": 4564, "title": "Wrong metrics calculations when running in distributed mode ", "user": {"login": "eladsegal", "id": 13485709, "node_id": "MDQ6VXNlcjEzNDg1NzA5", "avatar_url": "https://avatars.githubusercontent.com/u/13485709?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eladsegal", "html_url": "https://github.com/eladsegal", "followers_url": "https://api.github.com/users/eladsegal/followers", "following_url": "https://api.github.com/users/eladsegal/following{/other_user}", "gists_url": "https://api.github.com/users/eladsegal/gists{/gist_id}", "starred_url": "https://api.github.com/users/eladsegal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eladsegal/subscriptions", "organizations_url": "https://api.github.com/users/eladsegal/orgs", "repos_url": "https://api.github.com/users/eladsegal/repos", "events_url": "https://api.github.com/users/eladsegal/events{/privacy}", "received_events_url": "https://api.github.com/users/eladsegal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-08-16T00:23:56Z", "updated_at": "2020-08-19T21:52:54Z", "closed_at": "2020-08-19T21:52:54Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Version\r\nv1.1.0rc3\r\n\r\n## Description\r\n`BooleanAccuracy` and `CategoricalAccuracy` (and possibly other metrics) are not calculated correctly when running in distributed mode, causing them to return `nan`.\r\n\r\nIt is caused by repeated addition of an accumulated variable with itself with each call to update the metric, resulting in an exponential growth until it gets to a value of `inf` (and when `inf` is divided by `inf` the result is `nan`).\r\nhttps://github.com/allenai/allennlp/blob/v1.1.0rc3/allennlp/training/metrics/categorical_accuracy.py#L102-L108\r\n\r\n## Steps to reproduce\r\nI've encountered the issue when I used `BooleanAccuracy` and `CategoricalAccuracy`, but from quickly looking at the code of other metrics it is possible it can occur for some of them as well.\r\n\r\nClone [allennlp-models](https://github.com/allenai/allennlp-models), switch to tag `v1.1.0rc3` and run the following from it:\r\n```allennlp train training_config/rc/transformer_qa_distributed.jsonnet -s training_dir -o '{\"dataset_reader\": {\"max_instances\": 2000}, \"validation_dataset_reader\": {\"max_instances\": 10}}'```\r\n\r\nAfter less than 200 training steps the metrics `start_acc`, `end_acc` (CategoricalAccuracy) and `span_acc` (BooleanAccuracy) will be `nan`.\r\n\r\n## Fix\r\nA fix for `BooleanAccuracy` and `CategoricalAccuracy` is [here](https://github.com/eladsegal/allennlp/commit/564fbb727b8a7d7b9959fa2ebe9d3f64dbc3e808).\r\nI currently don't have time to verify and fix other metrics, so let me know if you'd like me to create a pull request just for these two.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4564/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4564/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4558", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4558/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4558/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4558/events", "html_url": "https://github.com/allenai/allennlp/issues/4558", "id": 678835129, "node_id": "MDU6SXNzdWU2Nzg4MzUxMjk=", "number": 4558, "title": "Bulk predict for coreference with constant memory usage", "user": {"login": "tanmayag78", "id": 25270661, "node_id": "MDQ6VXNlcjI1MjcwNjYx", "avatar_url": "https://avatars.githubusercontent.com/u/25270661?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tanmayag78", "html_url": "https://github.com/tanmayag78", "followers_url": "https://api.github.com/users/tanmayag78/followers", "following_url": "https://api.github.com/users/tanmayag78/following{/other_user}", "gists_url": "https://api.github.com/users/tanmayag78/gists{/gist_id}", "starred_url": "https://api.github.com/users/tanmayag78/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tanmayag78/subscriptions", "organizations_url": "https://api.github.com/users/tanmayag78/orgs", "repos_url": "https://api.github.com/users/tanmayag78/repos", "events_url": "https://api.github.com/users/tanmayag78/events{/privacy}", "received_events_url": "https://api.github.com/users/tanmayag78/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/13", "html_url": "https://github.com/allenai/allennlp/milestone/13", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/13/labels", "id": 5535962, "node_id": "MDk6TWlsZXN0b25lNTUzNTk2Mg==", "number": 13, "title": "1.2", "description": "", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 24, "state": "closed", "created_at": "2020-06-12T16:16:52Z", "updated_at": "2020-11-02T18:45:36Z", "due_on": null, "closed_at": "2020-11-02T18:45:36Z"}, "comments": 4, "created_at": "2020-08-14T01:34:00Z", "updated_at": "2020-09-28T21:31:11Z", "closed_at": "2020-08-24T17:44:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "- So I want to use coreference resolution on more than 2000 stories. But every time I run the predict method the memory increases. Any way to use this with constant memory usage. I am using CPU for now. I have tried clearing the cache and running garbage collector. Please have a lot at the pseudo-code.\r\n- And also is there a way to reduce the prediction for large data. \r\n- I am also thinking of adding NER and other NLP functionality like relation extraction. Is there a way to create a pipeline in Allennlp.\r\n\r\n```\r\ndef _get_coref():\r\n    if hasattr(_get_coref, \"COREF\"):\r\n        return _get_coref.COREF\r\n\r\n    from allennlp.predictors.predictor import Predictor\r\n    import allennlp_models.coref\r\n\r\n    _get_coref.COREF = Predictor.from_path(\r\n        os.path.join(\r\n            ROOT_DIR,\r\n            'coref-spanbert-large-2020.02.27.tar.gz'\r\n        )\r\n    )\r\n    return _get_coref.COREF\r\n\r\npredictor = _get_coref()\r\nfor story in stories:\r\n    story = entity_info['whole']\r\n    clusters = predictor.predict(document=text).get('clusters')\r\n\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4558/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4558/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4555", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4555/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4555/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4555/events", "html_url": "https://github.com/allenai/allennlp/issues/4555", "id": 678298434, "node_id": "MDU6SXNzdWU2NzgyOTg0MzQ=", "number": 4555, "title": "torch must be imported before import allennlp", "user": {"login": "lixiepeng", "id": 14953806, "node_id": "MDQ6VXNlcjE0OTUzODA2", "avatar_url": "https://avatars.githubusercontent.com/u/14953806?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lixiepeng", "html_url": "https://github.com/lixiepeng", "followers_url": "https://api.github.com/users/lixiepeng/followers", "following_url": "https://api.github.com/users/lixiepeng/following{/other_user}", "gists_url": "https://api.github.com/users/lixiepeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/lixiepeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lixiepeng/subscriptions", "organizations_url": "https://api.github.com/users/lixiepeng/orgs", "repos_url": "https://api.github.com/users/lixiepeng/repos", "events_url": "https://api.github.com/users/lixiepeng/events{/privacy}", "received_events_url": "https://api.github.com/users/lixiepeng/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-13T09:36:29Z", "updated_at": "2020-08-27T16:19:18Z", "closed_at": "2020-08-27T16:19:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nfrom allennlp.common.util import import_module_and_submodules\r\n\r\nD:\\Anaconda3\\lib\\site-packages\\allennlp\\__init__.py in <module>\r\n     16     # On some systems this prevents the dreaded\r\n     17     # ImportError: dlopen: cannot load any more object with static TLS\r\n---> 18     import spacy, torch, numpy  # noqa\r\n     19 \r\n     20 except ModuleNotFoundError:\r\n\r\nD:\\Anaconda3\\lib\\site-packages\\torch\\__init__.py in <module>\r\n    114                 err = ctypes.WinError(last_error)\r\n    115                 err.strerror += ' Error loading \"{}\" or one of its dependencies.'.format(dll)\r\n--> 116                 raise err\r\n    117             elif res is not None:\r\n    118                 is_loaded = True\r\n\r\nOSError: [WinError 127] \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u7a0b\u5e8f\u3002 Error loading \"D:\\Anaconda3\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies.\r\n\r\nIpython Console:\r\nIn [1]: import torch\r\n\r\nIn [2]: import allennlp\r\n\r\nIn [3]:\r\n\r\nCMD:\r\nC:\\Users\\xxx>allennlp\r\nTraceback (most recent call last):\r\n  File \"d:\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"d:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"D:\\Anaconda3\\Scripts\\allennlp.exe\\__main__.py\", line 5, in <module>\r\n  File \"d:\\anaconda3\\lib\\site-packages\\allennlp\\__init__.py\", line 18, in <module>\r\n    import spacy, torch, numpy  # noqa\r\n  File \"d:\\anaconda3\\lib\\site-packages\\torch\\__init__.py\", line 116, in <module>\r\n    raise err\r\nOSError: [WinError 127] \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u7a0b\u5e8f\u3002 Error loading \"d:\\anaconda3\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Win10 64\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: python 3.7.3\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\ntorch==1.6.0\r\nallennlp==1.1.0rc3\r\nallennlp-models==1.1.0rc3\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp.common.util import import_module_and_submodules\r\nor\r\nCMD: allennlp\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4555/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4555/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4550", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4550/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4550/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4550/events", "html_url": "https://github.com/allenai/allennlp/issues/4550", "id": 677373571, "node_id": "MDU6SXNzdWU2NzczNzM1NzE=", "number": 4550, "title": "[Models] BART model output is incorrect shape", "user": {"login": "nitishgupta", "id": 6223213, "node_id": "MDQ6VXNlcjYyMjMyMTM=", "avatar_url": "https://avatars.githubusercontent.com/u/6223213?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nitishgupta", "html_url": "https://github.com/nitishgupta", "followers_url": "https://api.github.com/users/nitishgupta/followers", "following_url": "https://api.github.com/users/nitishgupta/following{/other_user}", "gists_url": "https://api.github.com/users/nitishgupta/gists{/gist_id}", "starred_url": "https://api.github.com/users/nitishgupta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nitishgupta/subscriptions", "organizations_url": "https://api.github.com/users/nitishgupta/orgs", "repos_url": "https://api.github.com/users/nitishgupta/repos", "events_url": "https://api.github.com/users/nitishgupta/events{/privacy}", "received_events_url": "https://api.github.com/users/nitishgupta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 19, "created_at": "2020-08-12T04:29:28Z", "updated_at": "2021-02-05T20:26:27Z", "closed_at": "2020-08-18T11:57:01Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nThe output of the BART model is incorrect here -- https://github.com/allenai/allennlp-models/blob/master/allennlp_models/generation/models/bart.py#L206\r\n\r\nIt should be `(batch_size, seq_len, vocab_size)` but is `(batch_size, 1, vocab_size)`\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n-e git+git@github.com:allenai/allennlp.git@e53d18580807dabff707f618f7e148c98d25da18#egg=allennlp\r\n-e git+git@github.com:allenai/allennlp-models.git@45f85ce67b869e6f33fb0a38bd9ae17bd99f287c#egg=allennlp_models\r\napex @ git+https://github.com/NVIDIA/apex.git@459de22d59c64e30fd4b368c368c5b74e269f3dd\r\nappdirs==1.4.4\r\nattrs==19.3.0\r\nbert-score==0.3.5\r\nblack==19.10b0\r\nbleach==3.1.5\r\nblis==0.4.1\r\nboto3==1.14.29\r\nbotocore==1.17.29\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi==1.14.1\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncodecov==2.1.8\r\ncolorama==0.4.3\r\nconllu==3.1.1\r\ncoverage==5.2.1\r\ncryptography==3.0\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ndateparser==0.7.6\r\ndocutils==0.15.2\r\neditdistance==0.5.3\r\nen-core-web-lg @ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\r\nfilelock==3.0.12\r\nflake8==3.8.3\r\nflaky==3.7.0\r\nftfy==5.8\r\nfuture==0.18.2\r\ngoogledrivedownloader==0.4\r\nh5py==2.10.0\r\nidna==2.10\r\nimportlib-metadata==1.7.0\r\njeepney==0.4.3\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.16.0\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsons==1.2.0\r\nkeyring==21.2.1\r\nkiwisolver==1.2.0\r\nlivereload==2.6.2\r\nlunr==0.5.8\r\nlxml==4.5.2\r\nMarkdown==3.2.2\r\nmarkdown-include==0.5.1\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.3.0\r\nmccabe==0.6.1\r\nmkdocs==1.1.2\r\nmkdocs-material==5.5.5\r\nmkdocs-material-extensions==1.0\r\nmkl-fft==1.1.0\r\nmkl-random==1.1.1\r\nmkl-service==2.3.0\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nmypy==0.782\r\nmypy-extensions==0.4.3\r\nnltk==3.5\r\nnr.collections==0.0.1\r\nnr.databind.core==0.0.16\r\nnr.databind.json==0.0.13\r\nnr.interface==0.0.3\r\nnr.metaclass==0.0.5\r\nnr.parsing.date==0.2.0\r\nnr.pylang.utils==0.0.3\r\nnr.stream==0.0.4\r\nnr.utils.re==0.1.0\r\nnumpy==1.18.5\r\nolefile==0.46\r\noverrides==3.1.0\r\npackaging==20.4\r\npandas==1.1.0\r\npathspec==0.8.0\r\npathtools==0.1.2\r\nPillow @ file:///tmp/build/80754af9/pillow_1594307325547/work\r\npkginfo==1.5.0.1\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprotobuf==3.12.2\r\npy==1.9.0\r\npy-cpuinfo==7.0.0\r\npy-rouge==1.1\r\npycodestyle==2.6.0\r\npycparser==2.20\r\npydoc-markdown @ git+https://github.com/NiklasRosenstein/pydoc-markdown.git@f0bf8af1db4f11581c19d206d4ed1ab34b4854c1\r\npyflakes==2.2.0\r\nPygments==2.6.1\r\npymdown-extensions==7.1\r\npyparsing==2.4.7\r\npytest==5.4.3\r\npytest-benchmark==3.2.3\r\npytest-cov==2.10.0\r\npython-dateutil==2.8.1\r\npytz==2020.1\r\nPyYAML==5.3.1\r\nreadme-renderer==26.0\r\nregex==2020.7.14\r\nrequests==2.24.0\r\nrequests-toolbelt==0.9.1\r\nresponses==0.10.15\r\nrfc3986==1.4.0\r\nruamel.yaml==0.16.10\r\nruamel.yaml.clib==0.2.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nsacrerouge==0.0.4\r\nscikit-learn==0.23.1\r\nscipy==1.5.2\r\nseaborn==0.10.1\r\nSecretStorage==3.1.2\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.3.2\r\nsrsly==1.0.2\r\ntensorboardX==2.1\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.8.1rc1\r\ntoml==0.10.1\r\ntorch==1.5.1\r\ntorchvision==0.6.0a0+82fd1c8\r\ntornado==6.0.4\r\ntqdm==4.48.0\r\ntransformers==3.0.2\r\ntwine==3.2.0\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.2\r\ntypish==1.7.0\r\ntzlocal==2.1\r\nUnidecode==1.1.1\r\nurllib3==1.25.10\r\nwasabi==0.7.1\r\nwatchdog==0.10.3\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nword2number==1.1\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nx = torch.LongTensor([[0, 133, 766, 9]])\r\nm = torch.BoolTensor([[True, True, True, True]])\r\nbart = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\", output_past=True)\r\ny = bart(input_ids=x, attention_mask=m, decoder_input_ids=x, decoder_attention_mask=m)[0]\r\ny.size()   # output == torch.Size([1, 1, 50265])\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4550/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4550/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4549", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4549/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4549/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4549/events", "html_url": "https://github.com/allenai/allennlp/issues/4549", "id": 676920710, "node_id": "MDU6SXNzdWU2NzY5MjA3MTA=", "number": 4549, "title": "RuntimeError: expected device cpu and dtype Float but got device cpu and dtype Bool", "user": {"login": "anjani-dhrangadhariya", "id": 52800702, "node_id": "MDQ6VXNlcjUyODAwNzAy", "avatar_url": "https://avatars.githubusercontent.com/u/52800702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anjani-dhrangadhariya", "html_url": "https://github.com/anjani-dhrangadhariya", "followers_url": "https://api.github.com/users/anjani-dhrangadhariya/followers", "following_url": "https://api.github.com/users/anjani-dhrangadhariya/following{/other_user}", "gists_url": "https://api.github.com/users/anjani-dhrangadhariya/gists{/gist_id}", "starred_url": "https://api.github.com/users/anjani-dhrangadhariya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anjani-dhrangadhariya/subscriptions", "organizations_url": "https://api.github.com/users/anjani-dhrangadhariya/orgs", "repos_url": "https://api.github.com/users/anjani-dhrangadhariya/repos", "events_url": "https://api.github.com/users/anjani-dhrangadhariya/events{/privacy}", "received_events_url": "https://api.github.com/users/anjani-dhrangadhariya/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-11T14:23:55Z", "updated_at": "2020-08-25T16:18:43Z", "closed_at": "2020-08-25T16:18:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ ] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [ ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ ] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-3-415939853a93> in <module>\r\n  7 emissions = torch.randn(seq_length, batch_size, num_tags)\r\n  8 tags = torch.tensor([[0.0, 1.0], [1.0, 1.0], [0.0, 1.0]], dtype=torch.long)  # \r\n(seq_length, batch_size)\r\n----> 9 model(emissions, tags)\r\n\r\n~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py in \r\n__call__(self, *input, **kwargs)\r\n545                     result = (result,)\r\n546                 input = result\r\n--> 547         if torch._C._get_tracing_state():\r\n548             result = self._slow_forward(*input, **kwargs)\r\n549         else:\r\n\r\n<ipython-input-2-2d984bd97cf1> in forward(self, inputs, tags, mask)\r\n329             mask = mask.to(torch.bool)\r\n330 \r\n--> 331         log_denominator = self._input_likelihood(inputs, mask)\r\n332         log_numerator = self._joint_likelihood(inputs, tags, mask)\r\n333 \r\n\r\n<ipython-input-2-2d984bd97cf1> in _input_likelihood(self, logits, mask)\r\n249             # In valid positions (mask == True) we want to take the logsumexp over the \r\ncurrent_tag dimension\r\n250             # of `inner`. Otherwise (mask == False) we want to retain the previous \r\nalpha.\r\n--> 251             alpha = util.logsumexp(inner, 1) * mask[i].view(batch_size, 1) + alpha * \r\n(\r\n252                 ~mask[i]\r\n253             ).view(batch_size, 1)\r\n\r\nRuntimeError: expected device cpu and dtype Float but got device cpu and dtype Bool\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux Ubuntu 18.04.4 LTS \r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.6.9 :: Anaconda, Inc.\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.7.1\r\nalembic==1.0.11\r\nargh==0.26.2\r\nasn1crypto==0.24.0\r\nastor==0.7.1\r\natomicwrites==1.3.0\r\nattrs==19.1.0\r\nbackcall==0.1.0\r\nbcrypt==3.1.6\r\nbert-serving-client==1.9.8\r\nbert-serving-server==1.9.8\r\nbert-tensorflow==1.0.1\r\nbleach==3.1.0\r\nblis==0.2.4\r\nbokeh==1.2.0\r\nboto==2.49.0\r\nboto3==1.13.1\r\nbotocore==1.16.1\r\nbz2file==0.98\r\ncchardet==2.1.4\r\ncertifi==2020.4.5.1\r\ncffi==1.12.3\r\nchainer==6.1.0\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncliff==2.15.0\r\ncmd2==0.9.15\r\ncolorama==0.4.1\r\ncolorlog==4.0.2\r\ncryptography==2.7\r\ncycler==0.10.0\r\ncymem==2.0.2\r\ncysignals==1.10.2\r\nCython==0.29.12\r\ncytoolz==0.9.0.1\r\ndataclasses==0.7\r\ndecorator==4.4.0\r\ndefusedxml==0.6.0\r\ndill==0.2.9\r\nDocumentFeatureSelection==1.5\r\ndocutils==0.15.2\r\neli5==0.10.1\r\nentrypoints==0.3\r\nfastprogress==0.1.21\r\nfasttext==0.9.1\r\nfilelock==3.0.12\r\nfuture==0.17.1\r\ngast==0.2.2\r\ngeniatagger-python==0.1\r\ngensim==3.4.0\r\ngoogle-pasta==0.1.7\r\ngoogleapis-common-protos==1.6.0\r\nGPUtil==1.4.0\r\ngraphviz==0.11\r\ngrpcio==1.16.1\r\nh5py==2.9.0\r\nhyperopt==0.1.2\r\nhypopt==1.0.9\r\nidna==2.9\r\nimageio==2.5.0\r\nimbalanced-learn==0.4.3\r\nimportlib-metadata==0.19\r\nipykernel==5.1.1\r\nipynb==0.5.1\r\nipython==7.5.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.4.2\r\njedi==0.13.3\r\njieba==0.39\r\nJinja2==2.10.1\r\njmespath==0.9.5\r\njoblib==0.13.2\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.0.1\r\njupyter==1.0.0\r\njupyter-client==5.2.4\r\njupyter-console==6.0.0\r\njupyter-core==4.4.0\r\njupyter-tensorboard==0.1.10\r\nKeras==2.2.4\r\nKeras-Applications==1.0.8\r\nkeras-bert==0.79.0\r\nkeras-contrib==2.0.8\r\nkeras-embed-sim==0.7.0\r\nkeras-layer-normalization==0.13.0\r\nkeras-multi-head==0.22.0\r\nkeras-pos-embd==0.11.0\r\nkeras-position-wise-feed-forward==0.6.0\r\nKeras-Preprocessing==1.0.9\r\nkeras-self-attention==0.41.0\r\nkeras-transformer==0.31.0\r\nkiwisolver==1.1.0\r\nktrain==0.4.2\r\nlangdetect==1.0.7\r\nlightgbm==2.2.3\r\nlime==0.1.1.34\r\nllvmlite==0.29.0\r\nlxml==4.3.4\r\nMako==1.1.0\r\nMarkdown==3.1.1\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.1.1\r\nmistune==0.8.4\r\nmkl-fft==1.0.14\r\nmkl-random==1.0.1\r\nmkl-service==2.3.0\r\nmock==3.0.5\r\nmore-itertools==7.2.0\r\nmsgpack==0.6.1\r\nmsgpack-numpy==0.4.3.2\r\nmurmurhash==1.0.2\r\nnbconvert==5.5.0\r\nnbformat==4.4.0\r\nnetworkx==2.3\r\nnltk==3.4.1\r\nnose==1.3.7\r\nnotebook==5.7.8\r\nnumba==0.45.1\r\nnumpy==1.17.1\r\nolefile==0.46\r\nopencv-python==4.1.1.26\r\nopt-einsum==3.1.0\r\noptuna==0.14.0\r\noverrides==3.0.0\r\npackaging==19.0\r\npandas==0.24.2\r\npandocfilters==1.4.2\r\nparamiko==2.5.0\r\nparso==0.4.0\r\npbr==5.1.3\r\npexpect==4.7.0\r\npickleshare==0.7.5\r\npierogi==0.2.0\r\nPillow==6.2.0\r\nplac==0.9.6\r\nplotly==4.0.0\r\npluggy==0.12.0\r\npreshed==2.0.1\r\nprettytable==0.7.2\r\nprometheus-client==0.7.0\r\npromise==2.2.1\r\nprompt-toolkit==2.0.9\r\nprotobuf==3.11.3\r\npsutil==5.6.3\r\nptyprocess==0.6.0\r\npy==1.8.0\r\npybind11==2.3.0\r\npycparser==2.19\r\nPyDispatcher==2.0.5\r\npydot==1.4.1\r\npydotplus==2.0.2\r\npyfasttext==0.4.6\r\nPygments==2.4.0\r\npymongo==3.8.0\r\nPyNaCl==1.3.0\r\npyOpenSSL==19.0.0\r\npypandoc==1.4\r\npyparsing==2.4.0\r\npyperclip==1.7.0\r\npyrsistent==0.14.11\r\nPySocks==1.7.0\r\npytest==5.1.0\r\npython-crfsuite==0.9.7\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npytils==0.3\r\npytorch-crf==0.7.2\r\npytorch-lightning==0.6.0\r\npytorch-pretrained-bert==0.6.2\r\npytorch-transformers==1.2.0\r\npytz==2019.1\r\nPyWavelets==1.0.3\r\nPyYAML==5.1\r\npyzmq==18.0.1\r\nqtconsole==4.5.1\r\nregex==2020.4.4\r\nrequests==2.23.0\r\nretrying==1.3.3\r\nrope==0.16.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-image==0.15.0\r\nscikit-learn==0.21.3\r\nscipy==1.3.1\r\nseaborn==0.9.0\r\nselenium==3.141.0\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.86\r\nseqeval==0.0.12\r\nsix==1.14.0\r\nsklearn-crfsuite==0.3.6\r\nsmart-open==1.8.2\r\nspacy==2.1.6\r\nSQLAlchemy==1.3.6\r\nsqlitedict==1.6.0\r\nsrsly==0.0.7\r\nstevedore==1.30.1\r\ntabulate==0.8.5\r\ntb-nightly==1.15.0a20190806\r\ntensorboard==1.14.0\r\ntensorboardX==2.0+022f060\r\ntensorflow==1.13.1\r\ntensorflow-datasets==1.2.0\r\ntensorflow-estimator==1.14.0\r\ntensorflow-hub==0.4.0\r\ntensorflow-metadata==0.15.0\r\ntermcolor==1.1.0\r\nterminado==0.8.2\r\ntest-tube==0.7.5\r\ntestfixtures==6.8.2\r\ntestpath==0.4.2\r\ntf-estimator-nightly==1.14.0.dev2019080601\r\nthinc==7.0.8\r\ntokenization==1.0.7\r\ntokenizers==0.7.0\r\ntool==0.8.0\r\ntools==0.1.9\r\ntoolz==0.9.0\r\ntorch==1.6.0\r\ntorchvision==0.7.0\r\ntornado==6.0.2\r\ntqdm==4.46.0\r\ntraitlets==4.3.2\r\ntransformers==2.11.0\r\ntyping==3.6.6\r\ntyping-extensions==3.6.6\r\nujson==1.35\r\numap-learn==0.3.10\r\nurllib3==1.25.9\r\nwasabi==0.2.2\r\nwcwidth==0.1.7\r\nwebencodings==0.5.1\r\nwebsockets==8.1\r\nWerkzeug==0.15.2\r\nwget==3.2\r\nwidgetsnbextension==3.4.2\r\nword2vec==0.10.2\r\nwordcloud==1.5.0\r\nwrapt==1.10.11\r\nxlrd==1.2.0\r\nyellowbrick==0.9.1\r\nzipp==0.5.2\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nnum_tags = 2\r\nmodel = ConditionalRandomField(num_tags)\r\nseq_length = 3  # maximum sequence length in a batch\r\nbatch_size = 2  # number of samples in the batch\r\nemissions = torch.randn(seq_length, batch_size, num_tags, dtype=torch.float32)\r\ntags = torch.tensor([[0.0, 1.0], [1.0, 1.0], [0.0, 1.0]])  # (seq_length, batch_size)\r\nmodel(emissions, tags)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4549/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4549/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4530", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4530/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4530/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4530/events", "html_url": "https://github.com/allenai/allennlp/issues/4530", "id": 672466759, "node_id": "MDU6SXNzdWU2NzI0NjY3NTk=", "number": 4530, "title": "Is this a bug of using BERT in version 0.9.0?", "user": {"login": "entslscheia", "id": 15921425, "node_id": "MDQ6VXNlcjE1OTIxNDI1", "avatar_url": "https://avatars.githubusercontent.com/u/15921425?v=4", "gravatar_id": "", "url": "https://api.github.com/users/entslscheia", "html_url": "https://github.com/entslscheia", "followers_url": "https://api.github.com/users/entslscheia/followers", "following_url": "https://api.github.com/users/entslscheia/following{/other_user}", "gists_url": "https://api.github.com/users/entslscheia/gists{/gist_id}", "starred_url": "https://api.github.com/users/entslscheia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/entslscheia/subscriptions", "organizations_url": "https://api.github.com/users/entslscheia/orgs", "repos_url": "https://api.github.com/users/entslscheia/repos", "events_url": "https://api.github.com/users/entslscheia/events{/privacy}", "received_events_url": "https://api.github.com/users/entslscheia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-04T02:55:11Z", "updated_at": "2020-08-04T18:01:51Z", "closed_at": "2020-08-04T18:01:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "First of all, I know the usage of BERT has been changed drastically since 0.9.0. But since I am still working on my old project, I am still sticking to 0.9.0 (updating to 1.0 will make many of my codes totally unusable...).\r\n\r\nIn version 0.9.0, it seems like padding is not handled at all when using `PretrainedTransformerEmbedder`:\r\n```python\r\nclass PretrainedTransformerEmbedder(TokenEmbedder):\r\n    \"\"\"\r\n    Uses a pretrained model from ``pytorch-transformers`` as a ``TokenEmbedder``.\r\n    \"\"\"\r\n    def __init__(self, model_name: str) -> None:\r\n        super().__init__()\r\n        self.transformer_model = AutoModel.from_pretrained(model_name)\r\n        # I'm not sure if this works for all models; open an issue on github if you find a case\r\n        # where it doesn't work.\r\n        self.output_dim = self.transformer_model.config.hidden_size\r\n\r\n    @overrides\r\n    def get_output_dim(self):\r\n        return self.output_dim\r\n\r\n    def forward(self, token_ids: torch.LongTensor) -> torch.Tensor:  # type: ignore\r\n        # pylint: disable=arguments-differ\r\n        return self.transformer_model(token_ids)[0]\r\n```\r\nYou can see in `forward` method, there is only one argument `token_ids`.\r\nAlso, in `forward` of `self.transformer_model`, which I use BERT here, padding is not handled either:\r\n```python\r\n    def forward(self, input_ids, token_type_ids=None, attention_mask=None, position_ids=None, head_mask=None):\r\n        if attention_mask is None:\r\n            attention_mask = torch.ones_like(input_ids)\r\n        if token_type_ids is None:\r\n            token_type_ids = torch.zeros_like(input_ids)\r\n        ...\r\n``` \r\nYou can see that `attention_mask` is required as an explicit input instead of generating from `input_ids`, and since `PretrainedTransformerEmbedder` does not accept an input of `attention_mask` at all, it indicates that paddings input to BERT are not ignored. I didn't notice this issue till this afternoon, which is kinda surprising to me. I expected this kind of stuff to be handled by AllenNLP and made transparent to users, but now it seems I probably need to implement my own `PretrainedTransformerEmbedder` to take care of this.\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4530/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4530/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4523", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4523/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4523/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4523/events", "html_url": "https://github.com/allenai/allennlp/issues/4523", "id": 668383372, "node_id": "MDU6SXNzdWU2NjgzODMzNzI=", "number": 4523, "title": "ConfigurationError: Cannot register evaluate as Subcommand; name already in use for Evaluate", "user": {"login": "ScottishFold007", "id": 36957508, "node_id": "MDQ6VXNlcjM2OTU3NTA4", "avatar_url": "https://avatars.githubusercontent.com/u/36957508?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ScottishFold007", "html_url": "https://github.com/ScottishFold007", "followers_url": "https://api.github.com/users/ScottishFold007/followers", "following_url": "https://api.github.com/users/ScottishFold007/following{/other_user}", "gists_url": "https://api.github.com/users/ScottishFold007/gists{/gist_id}", "starred_url": "https://api.github.com/users/ScottishFold007/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ScottishFold007/subscriptions", "organizations_url": "https://api.github.com/users/ScottishFold007/orgs", "repos_url": "https://api.github.com/users/ScottishFold007/repos", "events_url": "https://api.github.com/users/ScottishFold007/events{/privacy}", "received_events_url": "https://api.github.com/users/ScottishFold007/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-30T05:25:36Z", "updated_at": "2020-07-31T16:12:54Z", "closed_at": "2020-07-31T16:12:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n![image](https://user-images.githubusercontent.com/36957508/88883941-1640d200-d268-11ea-8803-6e15f5b2c985.png)\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4523/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4523/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4520", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4520/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4520/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4520/events", "html_url": "https://github.com/allenai/allennlp/issues/4520", "id": 667973598, "node_id": "MDU6SXNzdWU2Njc5NzM1OTg=", "number": 4520, "title": "Iterators \u2794 DataLoaders v1.0 upgrade: key \"sampler\" is required at location data_loader.batch_sampler", "user": {"login": "iamsaurabhc", "id": 19235748, "node_id": "MDQ6VXNlcjE5MjM1NzQ4", "avatar_url": "https://avatars.githubusercontent.com/u/19235748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iamsaurabhc", "html_url": "https://github.com/iamsaurabhc", "followers_url": "https://api.github.com/users/iamsaurabhc/followers", "following_url": "https://api.github.com/users/iamsaurabhc/following{/other_user}", "gists_url": "https://api.github.com/users/iamsaurabhc/gists{/gist_id}", "starred_url": "https://api.github.com/users/iamsaurabhc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iamsaurabhc/subscriptions", "organizations_url": "https://api.github.com/users/iamsaurabhc/orgs", "repos_url": "https://api.github.com/users/iamsaurabhc/repos", "events_url": "https://api.github.com/users/iamsaurabhc/events{/privacy}", "received_events_url": "https://api.github.com/users/iamsaurabhc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-29T16:24:34Z", "updated_at": "2020-08-05T16:25:08Z", "closed_at": "2020-07-31T16:10:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [ x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n'!! Traceback (most recent call last):\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/params.py\", line 237, in pop\\n    value = self.params.pop(key)\\n!! KeyError: \\'sampler\\'\\n!! \\nDuring handling of the above exception, another exception occurred:\\n\\n!! Traceback (most recent call last):\\n!!   File \"/home/saurabh/botml/botml/common/sherlock.py\", line 43, in wrap\\n    status.result = func(*args, **kwargs)\\n!!   File \"/home/saurabh/botml/botml/botai/api.py\", line 104, in train\\n    model = allentrain.train_model(params, ser_file)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/commands/train.py\", line 230, in train_model\\n    dry_run=dry_run,\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/commands/train.py\", line 418, in _train_worker\\n    params=params, serialization_dir=serialization_dir, local_rank=process_rank,\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\\n    **extras,\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 611, in from_params\\n    return constructor_to_call(**kwargs)  # type: ignore\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/commands/train.py\", line 646, in from_partial_objects\\n    data_loader_ = data_loader.construct(dataset=datasets[\"train\"])\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/lazy.py\", line 46, in construct\\n    return self._constructor(**kwargs)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 446, in constructor\\n    return value_cls.from_params(params=deepcopy(popped_params), **constructor_extras)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\\n    **extras,\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 611, in from_params\\n    return constructor_to_call(**kwargs)  # type: ignore\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/data/dataloader.py\", line 127, in from_partial_objects\\n    batch_sampler_ = batch_sampler.construct(data_source=dataset)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/lazy.py\", line 46, in construct\\n    return self._constructor(**kwargs)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 446, in constructor\\n    return value_cls.from_params(params=deepcopy(popped_params), **constructor_extras)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\\n    **extras,\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 609, in from_params\\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 181, in create_kwargs\\n    cls.__name__, param_name, annotation, param.default, params, **extras\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 280, in pop_and_construct_arg\\n    popped_params = params.pop(name, default) if default != _NO_DEFAULT else params.pop(name)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/params.py\", line 242, in pop\\n    raise ConfigurationError(msg)\\n!! allennlp.common.checks.ConfigurationError: key \"sampler\" is required at location \"data_loader.batch_sampler.\"\\n'\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 18.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.8\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp==3.4.4\r\nallennlp==1.0.0\r\nallennlp-models==1.0.0\r\nAPScheduler==3.6.3\r\nastroid==2.1.0\r\nasync-timeout==3.0.1\r\nattrs==19.3.0\r\nazure-common==1.1.25\r\nazure-cosmosdb-nspkg==2.0.2\r\nazure-cosmosdb-table==1.0.3\r\nazure-nspkg==3.0.2\r\nazure-storage==0.34.3\r\nazure-storage-common==1.1.0\r\nazure-storage-nspkg==3.1.0\r\nbeautifulsoup4==4.9.0\r\nblis==0.4.1\r\n-e git+finons@vs-ssh.visualstudio.com:v3/finons/BMML/botml@cdfaae98ee6019ee90171079d8f3694796cc1bd4#egg=botml\r\nboto==2.49.0\r\nboto3==1.14.28\r\nbotocore==1.17.28\r\nbreadability==0.1.20\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi==1.14.0\r\nchardet==3.0.4\r\nclick==7.1.2\r\nconllu==3.0\r\ncoverage==4.5.1\r\ncryptography==3.0\r\ncssselect==1.1.0\r\ncymem==2.0.3\r\nCython==0.29.16\r\ndill==0.2.7.1\r\ndocopt==0.6.2\r\ndocutils==0.15.2\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nfeedfinder2==0.0.4\r\nfeedparser==5.2.1\r\nfilelock==3.0.12\r\nFlask==1.0.2\r\nFlask-Cors==3.0.8\r\nfuture==0.18.2\r\nfutures==3.1.1\r\ngensim==3.8.2\r\ngevent==1.5.0\r\ngreenlet==0.4.16\r\nh5py==2.10.0\r\nhtml5lib==1.0.1\r\nidna==2.6\r\nimportlib-metadata==1.7.0\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njieba3k==0.35.1\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.11\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\nlazy-object-proxy==1.5.1\r\nlightgbm==2.0.4\r\nlxml==4.5.0\r\nMarkupSafe==1.1.1\r\nmccabe==0.6.1\r\nmore-itertools==8.4.0\r\nmultidict==4.7.6\r\nmurmurhash==1.0.2\r\nnewspaper3k==0.2.8\r\nnltk==3.5\r\nnose==1.3.7\r\nnumpy==1.18.3\r\noverrides==3.0.0\r\npackaging==20.4\r\npandas==1.0.3\r\nPillow==7.2.0\r\npkg-resources==0.0.0\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprotobuf==3.12.2\r\npsutil==5.7.0\r\npy==1.9.0\r\npy-rouge==1.1\r\npycparser==2.20\r\npylint==2.4.4\r\npymongo==3.10.1\r\npyparsing==2.4.7\r\npytest==5.4.1\r\npytest-cov==2.8.1\r\npython-dateutil==2.8.1\r\npytz==2017.3\r\nPyYAML==5.3.1\r\nregex==2020.7.14\r\nrequests==2.18.4\r\nrequests-file==1.5.1\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.20.3\r\nscipy==1.4.1\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nslackclient==1.2.1\r\nsmart-open==2.1.0\r\nsoupsieve==2.0.1\r\nspacy==2.2.4\r\nsrsly==1.0.2\r\nsumy==0.7.0\r\ntensorboardX==2.1\r\nthinc==7.4.0\r\ntinysegmenter==0.3\r\ntldextract==2.2.2\r\ntokenizers==0.7.0\r\ntorch==1.5.0\r\ntqdm==4.45.0\r\ntransformers==2.11.0\r\ntzlocal==2.1\r\nurllib3==1.22\r\nwasabi==0.7.1\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nwebsocket-client==0.57.0\r\nWerkzeug==1.0.1\r\nword2number==1.1\r\nwordninja==0.1.5\r\nwrapt==1.12.1\r\nyarl==1.4.2\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n# Updating from older version to v1.0\r\nUpdated config : \r\n\"data_loader\": {\r\n        \"batch_sampler\": {\r\n        \"type\": \"basic\",\r\n        \"batch_size\": 32\r\n        }\r\n    }\r\nPrevious config: \r\n\"iterator\": {\r\n        \"type\": \"basic\",\r\n        \"batch_size\": 32\r\n    }\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4520/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4520/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4515", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4515/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4515/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4515/events", "html_url": "https://github.com/allenai/allennlp/issues/4515", "id": 666100236, "node_id": "MDU6SXNzdWU2NjYxMDAyMzY=", "number": 4515, "title": "PretrainedTransformerMismatchedIndexer _add_encoding_to_vocabulary_if_needed is broken", "user": {"login": "OhadRubin", "id": 4252994, "node_id": "MDQ6VXNlcjQyNTI5OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/4252994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/OhadRubin", "html_url": "https://github.com/OhadRubin", "followers_url": "https://api.github.com/users/OhadRubin/followers", "following_url": "https://api.github.com/users/OhadRubin/following{/other_user}", "gists_url": "https://api.github.com/users/OhadRubin/gists{/gist_id}", "starred_url": "https://api.github.com/users/OhadRubin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/OhadRubin/subscriptions", "organizations_url": "https://api.github.com/users/OhadRubin/orgs", "repos_url": "https://api.github.com/users/OhadRubin/repos", "events_url": "https://api.github.com/users/OhadRubin/events{/privacy}", "received_events_url": "https://api.github.com/users/OhadRubin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-27T08:39:06Z", "updated_at": "2020-07-28T17:57:41Z", "closed_at": "2020-07-27T10:04:08Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "the tokenizers library doesn't take into account that self._tokenizer might be a dictionary \r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-4-7f51839e03f5> in <module>\r\n      2 for inst in train_dataset:\r\n      3     a = inst\r\n----> 4     res_list = model.forward_on_instances([inst])\r\n      5     print(res_list)\r\n      6 #     break\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/allennlp/models/model.py in forward_on_instances(self, instances)\r\n    168             cuda_device = self._get_prediction_device()\r\n    169             dataset = Batch(instances)\r\n--> 170             dataset.index_instances(self.vocab)\r\n    171             model_input = util.move_to_device(dataset.as_tensor_dict(), cuda_device)\r\n    172             outputs = self.make_output_human_readable(self(**model_input))\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/allennlp/data/batch.py in index_instances(self, vocab)\r\n    157     def index_instances(self, vocab: Vocabulary) -> None:\r\n    158         for instance in self.instances:\r\n--> 159             instance.index_fields(vocab)\r\n    160 \r\n    161     def print_statistics(self) -> None:\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/allennlp/data/instance.py in index_fields(self, vocab)\r\n     73             self.indexed = True\r\n     74             for field in self.fields.values():\r\n---> 75                 field.index(vocab)\r\n     76 \r\n     77     def get_padding_lengths(self) -> Dict[str, Dict[str, int]]:\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/allennlp/data/fields/text_field.py in index(self, vocab)\r\n     66         self._indexed_tokens = {}\r\n     67         for indexer_name, indexer in self._token_indexers.items():\r\n---> 68             self._indexed_tokens[indexer_name] = indexer.tokens_to_indices(self.tokens, vocab)\r\n     69 \r\n     70     @overrides\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/allennlp/data/token_indexers/pretrained_transformer_mismatched_indexer.py in tokens_to_indices(self, tokens, vocabulary)\r\n     61     @overrides\r\n     62     def tokens_to_indices(self, tokens: List[Token], vocabulary: Vocabulary) -> IndexedTokenList:\r\n---> 63         self._matched_indexer._add_encoding_to_vocabulary_if_needed(vocabulary)\r\n     64 \r\n     65         wordpieces, offsets = self._allennlp_tokenizer.intra_word_tokenize([t.text for t in tokens])\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/allennlp/data/token_indexers/pretrained_transformer_indexer.py in _add_encoding_to_vocabulary_if_needed(self, vocab)\r\n     72 \r\n     73         try:\r\n---> 74             vocab_items = self._tokenizer.get_vocab().items()\r\n     75         except NotImplementedError:\r\n     76             vocab_items = (\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/transformers/tokenization_utils.py in get_vocab(self)\r\n   2368 \r\n   2369     def get_vocab(self):\r\n-> 2370         return self._tokenizer.get_vocab(True)\r\n   2371 \r\n   2372     def convert_tokens_to_string(self, tokens: List[int], skip_special_tokens: bool = False) -> str:\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/tokenizers/implementations/base_tokenizer.py in get_vocab(self, with_added_tokens)\r\n     36             The vocabulary\r\n     37         \"\"\"\r\n---> 38         return self._tokenizer.get_vocab(with_added_tokens=with_added_tokens)\r\n     39 \r\n     40     def get_vocab_size(self, with_added_tokens: bool = True) -> int:\r\n\r\nAttributeError: 'dict' object has no attribute 'get_vocab'\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4515/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4515/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4506", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4506/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4506/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4506/events", "html_url": "https://github.com/allenai/allennlp/issues/4506", "id": 665063480, "node_id": "MDU6SXNzdWU2NjUwNjM0ODA=", "number": 4506, "title": "Coreference resolution out of memory error", "user": {"login": "erncnerky", "id": 13177658, "node_id": "MDQ6VXNlcjEzMTc3NjU4", "avatar_url": "https://avatars.githubusercontent.com/u/13177658?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erncnerky", "html_url": "https://github.com/erncnerky", "followers_url": "https://api.github.com/users/erncnerky/followers", "following_url": "https://api.github.com/users/erncnerky/following{/other_user}", "gists_url": "https://api.github.com/users/erncnerky/gists{/gist_id}", "starred_url": "https://api.github.com/users/erncnerky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erncnerky/subscriptions", "organizations_url": "https://api.github.com/users/erncnerky/orgs", "repos_url": "https://api.github.com/users/erncnerky/repos", "events_url": "https://api.github.com/users/erncnerky/events{/privacy}", "received_events_url": "https://api.github.com/users/erncnerky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-07-24T10:06:21Z", "updated_at": "2022-01-06T15:47:50Z", "closed_at": "2020-07-31T16:06:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI am using coreference resolution model (https://demo.allennlp.org/coreference-resolution)\r\n\r\n```Python\r\nclass CoreferenceResolution():\r\n\r\n    def __init__(self):\r\n        self.predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz\", cuda_device=0)\r\n\r\n    def predict(self, text):\r\n        prediction = self.predictor.predict(document=text)\r\n        return prediction\r\n```\r\n\r\nAfter a certain period of time, I get CUDA out of memory error.\r\n\r\n```\r\nERROR:api:Exception on /api/v1/coreference-resolution [POST]\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 2446, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1951, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1820, in handle_user_exception\r\n    reraise(exc_type, exc_value, tb)\r\n  File \"/usr/local/lib/python3.6/dist-packages/flask/_compat.py\", line 39, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1949, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1935, in dispatch_request\r\n    return self.view_functions[rule.endpoint](**req.view_args)\r\n  File \"/app/api.py\", line 43, in coreference_resolution_f\r\n    coreference_prediction = coreference_resolution.predict(text)\r\n  File \"/app/src/coreference.py\", line 12, in predict\r\n    prediction = self.predictor.predict(document=text)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp_models/coref/predictors/coref.py\", line 65, in predict\r\n    return self.predict_json({\"document\": document})\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py\", line 48, in predict_json\r\n    return self.predict_instance(instance)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py\", line 171, in predict_instance\r\n    outputs = self._model.forward_on_instance(instance)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/models/model.py\", line 146, in forward_on_instance\r\n    return self.forward_on_instances([instance])[0]\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/models/model.py\", line 172, in forward_on_instances\r\n    outputs = self.make_output_human_readable(self(**model_input))\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp_models/coref/models/coref.py\", line 206, in forward\r\n    attended_span_embeddings = self._attentive_span_extractor(text_embeddings, spans)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/modules/span_extractors/self_attentive_span_extractor.py\", line 73, in forward\r\n    attended_text_embeddings = util.weighted_sum(span_embeddings, span_attention_weights)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/nn/util.py\", line 692, in weighted_sum\r\n    intermediate = attention.unsqueeze(-1).expand_as(matrix) * matrix\r\nRuntimeError: CUDA out of memory. Tried to allocate 1.69 GiB (GPU 0; 11.17 GiB total capacity; 3.18 GiB already allocated; 1.14 GiB free; 3.19 GiB reserved in total by PyTorch)\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4506/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4506/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4504", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4504/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4504/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4504/events", "html_url": "https://github.com/allenai/allennlp/issues/4504", "id": 664894725, "node_id": "MDU6SXNzdWU2NjQ4OTQ3MjU=", "number": 4504, "title": "After #4470 the output is duplicated and Tqdm effect is lost", "user": {"login": "bratao", "id": 1090152, "node_id": "MDQ6VXNlcjEwOTAxNTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1090152?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bratao", "html_url": "https://github.com/bratao", "followers_url": "https://api.github.com/users/bratao/followers", "following_url": "https://api.github.com/users/bratao/following{/other_user}", "gists_url": "https://api.github.com/users/bratao/gists{/gist_id}", "starred_url": "https://api.github.com/users/bratao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bratao/subscriptions", "organizations_url": "https://api.github.com/users/bratao/orgs", "repos_url": "https://api.github.com/users/bratao/repos", "events_url": "https://api.github.com/users/bratao/events{/privacy}", "received_events_url": "https://api.github.com/users/bratao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-07-24T03:39:47Z", "updated_at": "2020-07-31T16:16:43Z", "closed_at": "2020-07-31T16:16:43Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [X] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [X] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [X] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [X] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [X] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [X] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [X] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [X] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [X] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [X] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nIn PyCharm console in Windows and in the CI ( Ubuntu 18.04) the output is duplicated. The nice Tqdm bars is lost. The output is repeated like that:\r\n\r\n```\r\naccuracy: 0.9193, accuracy3: 0.9219, precision-overall: 0.3077, recall-overall: 0.2727, f1-measure-overall: 0.2892, loss: 95.4325, reg_loss: 6.7843 ||:  33%|###3      | 1/3 [00:02<00:04,  2.14s/it]\r\naccuracy: 0.9211, accuracy3: 0.9237, precision-overall: 0.3571, recall-overall: 0.3191, f1-measure-overall: 0.3371, loss: 37.8299, reg_loss: 7.8506 ||: 100%|##########| 3/3 [00:02<00:00,  1.52s/it]\r\naccuracy: 0.9211, accuracy3: 0.9237, precision-overall: 0.3571, recall-overall: 0.3191, f1-measure-overall: 0.3371, loss: 37.8299, reg_loss: 7.8506 ||: 100%|##########| 3/3 [00:02<00:00,  1.30it/s]\r\n\r\n```\r\nThe #4470 Pull by @epwalsh  checks for sys.stderr.isatty() and in my Pycharm console and in my Gitlab C.I the output is duplicated. Probably because the console is redirected internal. A option to keep the previous behavior would be great\r\n\r\n<details>\r\n\r\n\r\n\r\n\r\n\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\nHappened after the #4470 Pull\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Windows 10 or Ubuntu 18.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\nN/A - Any training code reproduces this error.\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4504/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4504/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4501", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4501/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4501/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4501/events", "html_url": "https://github.com/allenai/allennlp/issues/4501", "id": 664678643, "node_id": "MDU6SXNzdWU2NjQ2Nzg2NDM=", "number": 4501, "title": "When extracting an archive fails half-way through, it corrupts the cache", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/13", "html_url": "https://github.com/allenai/allennlp/milestone/13", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/13/labels", "id": 5535962, "node_id": "MDk6TWlsZXN0b25lNTUzNTk2Mg==", "number": 13, "title": "1.2", "description": "", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 24, "state": "closed", "created_at": "2020-06-12T16:16:52Z", "updated_at": "2020-11-02T18:45:36Z", "due_on": null, "closed_at": "2020-11-02T18:45:36Z"}, "comments": 0, "created_at": "2020-07-23T18:24:11Z", "updated_at": "2020-09-03T16:09:55Z", "closed_at": "2020-09-03T16:09:55Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "`cached_path()` can extract archives, and now even get files from inside the archive. But if the process gets killed during the extraction process, we are left with a directory that contains some of the extracted files, and we never catch back up.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4501/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4501/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4496", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4496/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4496/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4496/events", "html_url": "https://github.com/allenai/allennlp/issues/4496", "id": 662265555, "node_id": "MDU6SXNzdWU2NjIyNjU1NTU=", "number": 4496, "title": "Padding error for two ListFields in Instance object", "user": {"login": "mateuszpieniak", "id": 31375424, "node_id": "MDQ6VXNlcjMxMzc1NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/31375424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mateuszpieniak", "html_url": "https://github.com/mateuszpieniak", "followers_url": "https://api.github.com/users/mateuszpieniak/followers", "following_url": "https://api.github.com/users/mateuszpieniak/following{/other_user}", "gists_url": "https://api.github.com/users/mateuszpieniak/gists{/gist_id}", "starred_url": "https://api.github.com/users/mateuszpieniak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mateuszpieniak/subscriptions", "organizations_url": "https://api.github.com/users/mateuszpieniak/orgs", "repos_url": "https://api.github.com/users/mateuszpieniak/repos", "events_url": "https://api.github.com/users/mateuszpieniak/events{/privacy}", "received_events_url": "https://api.github.com/users/mateuszpieniak/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-07-20T21:08:13Z", "updated_at": "2020-08-04T10:24:38Z", "closed_at": "2020-08-04T10:24:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nIn my custom `DatasetReader` I read pairs of text, where each text is processed with `ListField`. It results in the exception for `batch_size` > 1. It works for `batch_size` == 1. It suggests that the issue is with the padding logic.\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n  0%|          | 0/100 [00:00<?, ?it/s]\r\n2020-07-20 22:48:57,813 - CRITICAL - root - Uncaught exception\r\nTraceback (most recent call last):\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/__main__.py\", line 38, in <module>\r\n    run()\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/commands/train.py\", line 105, in train_model_from_args\r\n    dry_run=args.dry_run,\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/commands/train.py\", line 159, in train_model_from_file\r\n    dry_run=dry_run,\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/commands/train.py\", line 213, in train_model\r\n    dry_run=dry_run,\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/commands/train.py\", line 407, in _train_worker\r\n    metrics = train_loop.run()\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/commands/train.py\", line 469, in run\r\n    return self.trainer.train()\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/training/trainer.py\", line 848, in train\r\n    train_metrics = self._train_epoch(epoch)\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/training/trainer.py\", line 554, in _train_epoch\r\n    for batch_group in batch_group_generator_tqdm:\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/tqdm/std.py\", line 1129, in __iter__\r\n    for obj in iterable:\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/common/util.py\", line 135, in lazy_groups_of\r\n    s = list(islice(iterator, group_size))\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/dataloader.py\", line 119, in __iter__\r\n    yield next(self._data_generator)\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 345, in __next__\r\n    data = self._next_data()\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 385, in _next_data\r\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 35, in fetch\r\n    return self.collate_fn(data)\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/dataloader.py\", line 18, in allennlp_collate\r\n    return batch.as_tensor_dict(batch.get_padding_lengths())\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/batch.py\", line 141, in as_tensor_dict\r\n    for field, tensors in instance.as_tensor_dict(lengths_to_use).items():\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/instance.py\", line 101, in as_tensor_dict\r\n    tensors[field_name] = field.as_tensor(padding_lengths[field_name])\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/fields/list_field.py\", line 99, in as_tensor\r\n    return self.field_list[0].batch_tensors(padded_fields)\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/fields/text_field.py\", line 132, in batch_tensors\r\n    for indexer_name, indexer_outputs in indexer_lists.items()\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/fields/text_field.py\", line 132, in <dictcomp>\r\n    for indexer_name, indexer_outputs in indexer_lists.items()\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/nn/util.py\", line 99, in batch_tensor_dicts\r\n    batched_tensor = torch.stack(tensor_list)\r\nRuntimeError: Expected object of scalar type bool but got scalar type long int for sequence element 16.\r\nreading instances: 3it [00:00,  8.25it/s]\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\nNot a duplicate, but a bit related (address only a single ListField in the returned `Instance` object)\r\n- https://github.com/allenai/allennlp/issues/2839\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 18.04.4 LTS\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.6.9\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.9.0\r\nalabaster==0.7.12\r\nalembic==1.4.2\r\nallennlp @ git+https://github.com/allenai/allennlp.git@478bf46cb676524ee9b74fb271ec0a592d1c4a48\r\nallennlp-models==1.0.0\r\n-e git+https://github.com/allenai/allennlp-server@4901cd9c93b77949d1877e18c6b019615004a6b5#egg=allennlp_server\r\naltgraph==0.17\r\nappdirs==1.4.3\r\nattrs==19.3.0\r\nawscli==1.18.34\r\nBabel==2.8.0\r\nbackcall==0.1.0\r\nbeautifulsoup4==4.8.2\r\nblack==19.10b0\r\nbleach==3.1.4\r\nblis==0.4.1\r\nboto3==1.14.17\r\nbotocore==1.17.19\r\nbravado==10.6.0\r\nbravado-core==5.17.0\r\nbs4==0.0.1\r\ncachetools==4.0.0\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncliff==3.3.0\r\ncloudpickle==1.3.0\r\ncmaes==0.5.1\r\ncmd2==1.1.0\r\ncolorama==0.4.3\r\ncolorlog==4.1.0\r\nConfigArgParse==1.2.3\r\nconfigparser==5.0.0\r\nconllu==3.0\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ndask==2.14.0\r\ndatabricks-cli==0.10.0\r\ndataclasses==0.7\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndill==0.3.1.1\r\ndocker==4.2.0\r\ndocutils==0.15.2\r\neditdistance==0.5.3\r\nen-core-sci-sm @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz\r\nentrypoints==0.3\r\nface-alignment==1.0.0\r\nfasttext==0.9.1\r\nfilelock==3.0.12\r\nflaky==3.6.1\r\nFlask==1.1.1\r\nFlask-Cors==3.0.8\r\nftfy==5.7\r\nfuture==0.18.2\r\ngensim==3.8.1\r\ngevent==1.4.0\r\ngitdb==4.0.4\r\nGitPython==3.1.1\r\ngoogle-api-core==1.16.0\r\ngoogle-auth==1.12.0\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-cloud-core==1.3.0\r\ngoogle-cloud-storage==1.26.0\r\ngoogle-resumable-media==0.5.0\r\ngoogleapis-common-protos==1.51.0\r\ngorilla==0.3.0\r\ngreenlet==0.4.15\r\ngrpcio==1.28.1\r\ngunicorn==20.0.4\r\nh5py==2.10.0\r\nhydra-core==0.11.3\r\nicalendar==4.0.4\r\nidna==2.10\r\nimageio==2.8.0\r\nimagesize==1.2.0\r\nimportlib-metadata==1.7.0\r\nipykernel==5.2.0\r\nipython==7.13.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\nitsdangerous==1.1.0\r\njedi==0.16.0\r\nJinja2==2.11.1\r\njmespath==0.10.0\r\njoblib==0.16.0\r\njson-lines==0.5.0\r\njsonlines==1.2.0\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonpointer==2.0\r\njsonref==0.2\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==6.1.2\r\njupyter-console==6.1.0\r\njupyter-core==4.6.3\r\nkiwisolver==1.1.0\r\nMako==1.1.2\r\nMarkdown==3.2.1\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.2.1\r\nmistune==0.8.4\r\nmlflow==1.8.0\r\nmonotonic==1.5\r\nmore-itertools==8.4.0\r\nmsgpack==1.0.0\r\nmsgpack-python==0.5.6\r\nmurmurhash==1.0.2\r\nnbconvert==5.6.1\r\nnbformat==5.0.4\r\nneptune-client==0.4.113\r\nnetworkx==2.4\r\nnltk==3.5\r\nnmslib==2.0.5\r\nnotebook==6.0.3\r\nnumpy==1.19.0\r\nnumpydoc==0.9.2\r\noauthlib==3.1.0\r\nomegaconf==1.4.1\r\nopencv-python==4.2.0.34\r\noverrides==3.1.0\r\npackaging==20.4\r\npandas==1.0.1\r\npandocfilters==1.4.2\r\nparsimonious==0.8.1\r\nparso==0.6.2\r\npathspec==0.8.0\r\npbr==5.4.5\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.0.0\r\npkg-resources==0.0.0\r\nplac==1.1.3\r\nplotly==4.5.4\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprettytable==0.7.2\r\nprometheus-client==0.7.1\r\nprometheus-flask-exporter==0.13.0\r\nprompt-toolkit==3.0.5\r\nprotobuf==3.12.2\r\npsutil==5.7.0\r\nptyprocess==0.6.0\r\npy==1.9.0\r\npy-rouge==1.1\r\npy3nvml==0.2.6\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npybind11==2.5.0\r\npycparser==2.20\r\npyfakewebcam==0.1.0\r\npygit==0.1\r\nPygments==2.6.1\r\nPyInstaller==3.6\r\nPyJWT==1.7.1\r\npyparsing==2.4.7\r\npyperclip==1.8.0\r\npyrsistent==0.16.0\r\npysbd==0.2.3\r\npyspellchecker==0.5.4\r\npytest==5.4.3\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npython-Levenshtein==0.12.0\r\npytorch-lightning==0.7.5\r\npytorch-pretrained-bert==0.6.2\r\npytorch-transformers==1.1.0\r\npytz==2019.3\r\nPyWavelets==1.1.1\r\nPyYAML==5.3.1\r\npyzmq==19.0.0\r\nqtconsole==4.7.2\r\nQtPy==1.9.0\r\nquerystring-parser==1.2.4\r\nregex==2020.6.8\r\nrequests==2.24.0\r\nrequests-oauthlib==1.3.0\r\nresponses==0.10.12\r\nretrying==1.3.3\r\nrfc3987==1.3.8\r\nrsa==3.4.2\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nSciencePlots==1.0.3\r\nscikit-image==0.16.2\r\nscikit-learn==0.23.1\r\nscipy==1.5.1\r\nseaborn==0.10.0\r\nsemantic-version==2.8.5\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsimplejson==3.17.0\r\nsix==1.15.0\r\nsklearn==0.0\r\nsmart-open==1.10.0\r\nsmmap==3.0.2\r\nsnowballstemmer==2.0.0\r\nsoupsieve==2.0\r\nspacy==2.2.4\r\nSphinx==2.4.4\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nSQLAlchemy==1.3.13\r\nsqlparse==0.3.1\r\nsrsly==1.0.2\r\nstevedore==2.0.1\r\nstrict-rfc3339==0.7\r\nswagger-spec-validator==2.5.0\r\ntabulate==0.8.7\r\ntensorboard==2.2.1\r\ntensorboard-plugin-wit==1.6.0.post3\r\ntensorboardX==2.1\r\nterminado==0.8.3\r\ntest-tube==0.7.5\r\ntestpath==0.4.4\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.8.1rc1\r\ntoml==0.10.0\r\ntoolz==0.10.0\r\ntorch==1.5.1\r\ntorchtext==0.6.0\r\ntorchvision==0.6.0\r\ntornado==6.0.4\r\ntqdm==4.47.0\r\ntraitlets==4.3.3\r\ntransformers==3.0.2\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.2\r\nUnidecode==1.1.1\r\nurllib3==1.25.9\r\nwasabi==0.7.0\r\nwcwidth==0.2.5\r\nwebcolors==1.11.1\r\nwebencodings==0.5.1\r\nwebsocket-client==0.57.0\r\nWerkzeug==1.0.0\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nwordsegment==1.3.1\r\nxmltodict==0.12.0\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n\r\n### Reader\r\n```\r\nimport json\r\nfrom typing import Dict, Iterable, Optional, List\r\n\r\nfrom allennlp.data.dataset_readers.dataset_reader import DatasetReader\r\nfrom allennlp.data.fields import Field, TextField, LabelField, ListField\r\nfrom allennlp.data.instance import Instance\r\nfrom allennlp.data.token_indexers import TokenIndexer\r\nfrom allennlp.data.tokenizers import Tokenizer\r\nfrom allennlp.data.tokenizers.sentence_splitter import SpacySentenceSplitter\r\nfrom overrides import overrides\r\n\r\n\r\n@DatasetReader.register(\"custom_reader\")\r\nclass CustomReader(DatasetReader):\r\n    def __init__(\r\n        self,\r\n        tokenizer: Tokenizer,\r\n        token_indexers: Dict[str, TokenIndexer],\r\n        segment_sentences: bool,\r\n        **kwargs,\r\n    ) -> None:\r\n        super().__init__(**kwargs)\r\n        self._tokenizer = tokenizer\r\n        self._token_indexers = token_indexers\r\n        self._segment_sentences = segment_sentences\r\n        if self._segment_sentences:\r\n            self._sentence_segmenter = SpacySentenceSplitter(language=\"en_core_sci_sm\")\r\n\r\n    @overrides\r\n    def _read(self, file_path: str) -> Iterable[Instance]:\r\n        with open(file_path, \"r\") as file:\r\n            for line in file:\r\n                example = json.loads(line)\r\n\r\n                yield self.text_to_instance(\r\n                    text1=example[\"text1\"],\r\n                    text2=example[\"text2\"],\r\n                    label=example.get(\"label\"),\r\n                )\r\n\r\n    def __get_text_fields(self, text: str, prefix_name: str) -> Dict[str, Field]:\r\n        fields: Dict[str, Field] = {}\r\n\r\n        if not self._segment_sentences:\r\n            tokens = self._tokenizer.tokenize(text)\r\n            fields[f\"{prefix_name}_tokens\"] = TextField(tokens, self._token_indexers)\r\n            return fields\r\n\r\n        sentences: List[Field] = []\r\n        sentence_splits = self._sentence_segmenter.split_sentences(text)\r\n        for sentence in sentence_splits:\r\n            tokens = self._tokenizer.tokenize(sentence)\r\n            sentences.append(TextField(tokens, self._token_indexers))\r\n\r\n        fields[f\"{prefix_name}_tokens\"] = ListField(sentences)\r\n        return fields\r\n\r\n    @overrides\r\n    def text_to_instance(\r\n        self, text1: str, text2: str, label: Optional[int] = None\r\n    ) -> Instance:\r\n        text1_fields = self.__get_text_fields(text1 prefix_name=\"text1\")\r\n        text2_fields = self.__get_text_fields(text2, prefix_name=\"text2\")\r\n        fields = {**text1_fields, **text2_fields}\r\n\r\n        if label is not None:\r\n            fields[\"labels\"] = LabelField(label, skip_indexing=True)\r\n\r\n        return Instance(fields)\r\n```\r\n\r\n### Related Config\r\n```\r\n  dataset_reader: {\r\n    type: 'custom_reader',\r\n    segment_sentences: true,\r\n    tokenizer: {\r\n      type: 'pretrained_transformer',\r\n      model_name: 'allenai/scibert_scivocab_cased',\r\n    },\r\n    token_indexers: {\r\n      tokens: {\r\n        type: 'pretrained_transformer',\r\n        model_name: 'allenai/scibert_scivocab_cased',\r\n        max_length: 512,\r\n      },\r\n    },\r\n\r\n    // DatasetReader's fields\r\n    max_instances: 10,\r\n    lazy: true,\r\n  },\r\n  data_loader: {\r\n    batch_size: 2\r\n  },\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4496/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4496/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4494", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4494/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4494/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4494/events", "html_url": "https://github.com/allenai/allennlp/issues/4494", "id": 660828528, "node_id": "MDU6SXNzdWU2NjA4Mjg1Mjg=", "number": 4494, "title": "[Suggestion] One line change in the comments", "user": {"login": "WweiL", "id": 10248890, "node_id": "MDQ6VXNlcjEwMjQ4ODkw", "avatar_url": "https://avatars.githubusercontent.com/u/10248890?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WweiL", "html_url": "https://github.com/WweiL", "followers_url": "https://api.github.com/users/WweiL/followers", "following_url": "https://api.github.com/users/WweiL/following{/other_user}", "gists_url": "https://api.github.com/users/WweiL/gists{/gist_id}", "starred_url": "https://api.github.com/users/WweiL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WweiL/subscriptions", "organizations_url": "https://api.github.com/users/WweiL/orgs", "repos_url": "https://api.github.com/users/WweiL/repos", "events_url": "https://api.github.com/users/WweiL/events{/privacy}", "received_events_url": "https://api.github.com/users/WweiL/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-19T13:10:20Z", "updated_at": "2020-07-31T16:16:15Z", "closed_at": "2020-07-31T16:16:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nhttps://github.com/allenai/allennlp/blob/master/allennlp/data/dataloader.py#L54\r\nThis line should be deleted as allennlp_collate is moved to the dataloader.py file itself.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nhttps://github.com/allenai/allennlp/blob/master/allennlp/data/dataloader.py#L54\r\nThis line should be deleted as allennlp_collate is moved to the dataloader.py file itself.\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\nN/A\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\nN/A\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n\r\n## Steps to reproduce\r\n\r\nSee the page: https://github.com/allenai/allennlp/blob/master/allennlp/data/dataloader.py#L54", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4494/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4494/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4492", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4492/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4492/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4492/events", "html_url": "https://github.com/allenai/allennlp/issues/4492", "id": 659969907, "node_id": "MDU6SXNzdWU2NTk5Njk5MDc=", "number": 4492, "title": "Getting error while building Allennlp", "user": {"login": "faysalhossain2007", "id": 1239654, "node_id": "MDQ6VXNlcjEyMzk2NTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1239654?v=4", "gravatar_id": "", "url": "https://api.github.com/users/faysalhossain2007", "html_url": "https://github.com/faysalhossain2007", "followers_url": "https://api.github.com/users/faysalhossain2007/followers", "following_url": "https://api.github.com/users/faysalhossain2007/following{/other_user}", "gists_url": "https://api.github.com/users/faysalhossain2007/gists{/gist_id}", "starred_url": "https://api.github.com/users/faysalhossain2007/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/faysalhossain2007/subscriptions", "organizations_url": "https://api.github.com/users/faysalhossain2007/orgs", "repos_url": "https://api.github.com/users/faysalhossain2007/repos", "events_url": "https://api.github.com/users/faysalhossain2007/events{/privacy}", "received_events_url": "https://api.github.com/users/faysalhossain2007/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-18T07:15:17Z", "updated_at": "2020-07-24T15:45:40Z", "closed_at": "2020-07-24T15:45:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n I am using python 3.7 in conda environment. I have installed allenlp using the pip command. Now I want to run the basic function using allennlp:\r\n```    \r\nal = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")\r\n    al.predict(\"my age is 14.\")\r\n```\r\nand it is throwing the following exception:\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```Traceback (most recent call last):\r\n  File \"/home/faysal/code/uiuc/dataprivacy/analyzer/src/detector.py\", line 102, in <module>\r\n    run()\r\n  File \"/home/faysal/code/uiuc/dataprivacy/analyzer/src/detector.py\", line 95, in run\r\n    detect_using_allennlp()\r\n  File \"/home/faysal/code/uiuc/dataprivacy/analyzer/src/detector.py\", line 11, in detect_using_allennlp\r\n    al = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 275, in from_path\r\n    load_archive(archive_path, cuda_device=cuda_device),\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/models/archival.py\", line 199, in load_archive\r\n    opt_level=opt_level,\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/models/model.py\", line 406, in load\r\n    return model_class._load(config, serialization_dir, weights_file, cuda_device, opt_level)\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/models/model.py\", line 303, in _load\r\n    model = Model.from_params(vocab=vocab, params=model_params)\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 609, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 181, in create_kwargs\r\n    cls.__name__, param_name, annotation, param.default, params, **extras\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 287, in pop_and_construct_arg\r\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 321, in construct_arg\r\n    return annotation.from_params(params=popped_params, **subextras)\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 533, in from_params\r\n    \"from_params was passed a `params` object that was not a `Params`. This probably \"\r\nallennlp.common.checks.ConfigurationError: from_params was passed a `params` object that was not a `Params`. This probably indicates malformed parameters in a configuration file, where something that should have been a dictionary was actually a list, or something else. This happened when constructing an object of type <class 'allennlp.nn.regularizers.regularizer_applicator.RegularizerApplicator'>.\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 18.04 LTS\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.7.7 \r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.9.0\r\nallennlp==1.1.0rc2.dev20200717\r\nallennlp-models==1.1.0rc2.dev20200717\r\nasgiref==3.2.7\r\nastor==0.7.1\r\nastunparse==1.6.3\r\nattrs==19.3.0\r\nbeautifulsoup4==4.9.0\r\nblinker==1.4\r\nblis==0.4.1\r\nboto3==1.14.23\r\nbotocore==1.17.23\r\nbrotlipy==0.7.0\r\nbs4==0.0.1\r\ncachetools==4.1.0\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi==1.14.0\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncolorama==0.4.3\r\nconllu==3.0\r\ncryptography==2.9.2\r\ncssselect==1.1.0\r\ncycler==0.10.0\r\ncymem==2.0.3\r\nDjango==3.0.6\r\ndocutils==0.15.2\r\nesprima==4.0.1\r\nfilelock==3.0.12\r\nfire==0.3.1\r\nfuture==0.18.2\r\ngast==0.3.3\r\ngoogle-api-core==1.17.0\r\ngoogle-auth==1.17.2\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-cloud-bigquery==1.24.0\r\ngoogle-cloud-core==1.3.0\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==0.5.0\r\ngoogleapis-common-protos==1.51.0\r\ngraphviz==0.14\r\ngrpcio==1.27.2\r\nh5py==2.10.0\r\nhtml5lib==1.1\r\nidna==2.9\r\nimage==1.5.32\r\nimportlib-metadata==1.6.1\r\njmespath==0.10.0\r\njoblib==0.13.2\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\nKeras==2.3.1\r\nKeras-Applications==1.0.8\r\nkeras-metrics==1.1.0\r\nKeras-Preprocessing==1.1.0\r\nkiwisolver==1.2.0\r\n-e git+https://github.com/lgsvl/PythonAPI.git@183ccdcb1d66fb827c074aaadacc012ec33da306#egg=lgsvl\r\nlxml==4.5.1\r\nMako==1.1.0\r\nMarkdown==3.2.2\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.2.1\r\nmkl-fft==1.0.15\r\nmkl-random==1.1.0\r\nmkl-service==2.3.0\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nneobolt==1.7.17\r\nneotime==1.7.4\r\nnltk==3.5\r\nnumpy==1.18.1\r\noauthlib==3.0.1\r\nopencv-python==4.2.0.34\r\nopt-einsum==0+untagged.56.g2664021.dirty\r\noverrides==3.1.0\r\npackaging==20.4\r\npandas==1.0.3\r\nparse==1.15.0\r\nPillow==7.1.2\r\nplac==1.1.3\r\npluggy==0.13.1\r\nply==3.11\r\npreshed==3.0.2\r\nprompt-toolkit==3.0.5\r\nprotobuf==3.12.3\r\npy==1.9.0\r\npy-rouge==1.1\r\npy2neo==4.2.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\nPygments==2.6.1\r\npygpu==0.7.6\r\nPyJWT==1.7.1\r\npyOpenSSL==19.1.0\r\npyparsing==2.4.7\r\npyquery==1.4.1\r\nPySocks==1.7.1\r\npytest==5.4.3\r\npython-dateutil==2.8.1\r\npytz==2020.1\r\npywebcopy==6.3.0\r\nPyYAML==5.3.1\r\nregex==2020.7.14\r\nrequests==2.24.0\r\nrequests-oauthlib==1.2.0\r\nrsa==4.6\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.22.1\r\nscipy==1.4.1\r\nselenium==3.141.0\r\nsentencepiece==0.1.91\r\nsix==1.14.0\r\nslimit==0.8.1\r\nsoupsieve==2.0.1\r\nspacy==2.2.4\r\nsqlparse==0.3.1\r\nsrsly==1.0.2\r\ntensorboard==2.2.2\r\ntensorboard-plugin-wit==1.6.0.post3\r\ntensorboardX==2.1\r\ntensorflow==2.2.0\r\ntensorflow-estimator==2.2.0\r\ntermcolor==1.1.0\r\nTheano==1.0.4\r\nthinc==7.4.0\r\ntokenizers==0.8.1rc1\r\ntorch==1.5.0\r\ntorchvision==0.6.0\r\ntqdm==4.47.0\r\ntransformers==3.0.2\r\nurllib3==1.25.9\r\nw3lib==1.22.0\r\nwasabi==0.7.1\r\nwcwidth==0.1.9\r\nwebencodings==0.5.1\r\nwebsockets==7.0\r\nWerkzeug==1.0.1\r\nword2number==1.1\r\nwrapt==1.12.1\r\nzipp==3.1.0\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4492/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4492/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4484", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4484/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4484/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4484/events", "html_url": "https://github.com/allenai/allennlp/issues/4484", "id": 657959949, "node_id": "MDU6SXNzdWU2NTc5NTk5NDk=", "number": 4484, "title": "Fix the GPT2 demo", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/13", "html_url": "https://github.com/allenai/allennlp/milestone/13", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/13/labels", "id": 5535962, "node_id": "MDk6TWlsZXN0b25lNTUzNTk2Mg==", "number": 13, "title": "1.2", "description": "", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 24, "state": "closed", "created_at": "2020-06-12T16:16:52Z", "updated_at": "2020-11-02T18:45:36Z", "due_on": null, "closed_at": "2020-11-02T18:45:36Z"}, "comments": 5, "created_at": "2020-07-16T08:07:20Z", "updated_at": "2022-11-16T01:45:36Z", "closed_at": "2020-10-22T18:06:10Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "@pclark425 reports that the GPT2 demo seems to be doing poorly right now. @matt-gardner suspects it has something to do with tokenization.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4484/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4484/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4480", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4480/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4480/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4480/events", "html_url": "https://github.com/allenai/allennlp/issues/4480", "id": 657412500, "node_id": "MDU6SXNzdWU2NTc0MTI1MDA=", "number": 4480, "title": "Inconsistency in answers generated by ELMo-Bidaf( trained on SQuAD) Demo and downloaded ", "user": {"login": "sukeshlaghate", "id": 25061957, "node_id": "MDQ6VXNlcjI1MDYxOTU3", "avatar_url": "https://avatars.githubusercontent.com/u/25061957?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sukeshlaghate", "html_url": "https://github.com/sukeshlaghate", "followers_url": "https://api.github.com/users/sukeshlaghate/followers", "following_url": "https://api.github.com/users/sukeshlaghate/following{/other_user}", "gists_url": "https://api.github.com/users/sukeshlaghate/gists{/gist_id}", "starred_url": "https://api.github.com/users/sukeshlaghate/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sukeshlaghate/subscriptions", "organizations_url": "https://api.github.com/users/sukeshlaghate/orgs", "repos_url": "https://api.github.com/users/sukeshlaghate/repos", "events_url": "https://api.github.com/users/sukeshlaghate/events{/privacy}", "received_events_url": "https://api.github.com/users/sukeshlaghate/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-15T14:48:37Z", "updated_at": "2020-07-20T10:43:59Z", "closed_at": "2020-07-20T10:43:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Describe the bug**\r\nInconsistent answers generated by `bidaf-elmo-model-2020.03.19.tar.gz` model when run in Allennlp demo website and when run on local machine after downloading the model.\r\n\r\n**Steps to reproduce the behavior**\r\nI followed instructions given in the usage section of online demo for reading comprehension \r\n\r\n1. conda create --name allennlp python=3.7\r\n2. conda activate allennlp\r\n3. conda install -c conda-forge jsonnet\r\n4. pip install allennlp==1.0.0 allennlp-models==1.0.0\r\n5. download bidaf-elmo model and store in folder\r\n     5a. download from `https://storage.googleapis.com/allennlp-public-models/bidaf-elmo-model-2020.03.19.tar.gz` \r\n     5b. move it to python notebook location `~/sandbox/python/`\r\n\r\nUsed following python code as given in Usage section of allennlp demo website\r\n~~~~\r\n \r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.rc\r\n\r\nmodel_path = r\"~/sandbox/python/rc_model\"\r\npredictor = Predictor.from_path(model_path)\r\n\r\ntext =\"Becuase Pepsodent is a trusted brand. it has 130% germ attack power.\"\r\n\r\nwhat_benefit = 'What is the benefit?'\r\nwhy_use = 'Why use?'\r\n\r\n\r\nwhy_answer = predictor.predict_json({\r\n    \"passage\": text,\r\n    \"question\": why_use\r\n})\r\n\r\nprint(f\"Answer for why should I use :{why_answer['best_span_str']}\")\r\n# Expected answer is Pepsodent is trusted brand.\r\n\r\nwhat_answer = predictor.predict(\r\n  passage=text,\r\n  question=what_benefit\r\n)\r\n\r\nprint(f\"Answer for what is the benefit: {what_answer['best_span_str']}\")\r\n# Expected answer is 130% germ attack power\r\n\r\n~~~~\r\n\r\n**Expected behavior**\r\nFor why question expected answer is  \"Pepsodent is trusted brand.\"\r\nFor what question expected answer is \"130% germ attack power\"\r\n\r\nActual answer for both cases is \"130% germ attack power\" refer  screen shot below\r\n\r\n![Downloaded_Model_answers](https://user-images.githubusercontent.com/25061957/87558881-3b193f00-c6d7-11ea-8786-7be8b8dd0d55.jpg)\r\n\r\nHowever when same passage and questions are fed into online demo, the model generates expected responses  please refer to the screen shots\r\n\r\nResponse for what is the benefit question\r\n![Allennlp_Demo_What_is_benifit_Answer](https://user-images.githubusercontent.com/25061957/87558621-f1c8ef80-c6d6-11ea-92f9-d65317da9532.jpg)\r\n\r\nResponse for why use question\r\n![Allennlp_Demo_Why_Use_Answer](https://user-images.githubusercontent.com/25061957/87558920-47050100-c6d7-11ea-9f56-7ff5b8654b1c.jpg)\r\n\r\n**System**\r\n\r\n    OS: [ubuntu 20.0.4]\r\n    Python version: [3.7.6]\r\n    AllenNLP version: [ v1.0.0]\r\n\r\nRequest you to help in resolving this inconsistency. \r\nAny pointers/ insights/ solutions are much appreciated.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4480/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4480/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4474", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4474/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4474/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4474/events", "html_url": "https://github.com/allenai/allennlp/issues/4474", "id": 656705502, "node_id": "MDU6SXNzdWU2NTY3MDU1MDI=", "number": 4474, "title": "[Models] Wrong usage of *cls_pooler* in the SST Roberta model", "user": {"login": "dcfidalgo", "id": 15979778, "node_id": "MDQ6VXNlcjE1OTc5Nzc4", "avatar_url": "https://avatars.githubusercontent.com/u/15979778?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dcfidalgo", "html_url": "https://github.com/dcfidalgo", "followers_url": "https://api.github.com/users/dcfidalgo/followers", "following_url": "https://api.github.com/users/dcfidalgo/following{/other_user}", "gists_url": "https://api.github.com/users/dcfidalgo/gists{/gist_id}", "starred_url": "https://api.github.com/users/dcfidalgo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dcfidalgo/subscriptions", "organizations_url": "https://api.github.com/users/dcfidalgo/orgs", "repos_url": "https://api.github.com/users/dcfidalgo/repos", "events_url": "https://api.github.com/users/dcfidalgo/events{/privacy}", "received_events_url": "https://api.github.com/users/dcfidalgo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-07-14T15:33:59Z", "updated_at": "2020-07-24T20:43:58Z", "closed_at": "2020-07-24T20:43:58Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nI think the usage of the *cls_pooler* as `seq2vec_encoder` is not appropriate [in this model](https://github.com/allenai/allennlp-models/blob/888596c8d41fcde755e91ca00474b88009175700/training_config/classification/stanford_sentiment_treebank_roberta.jsonnet#L44). If i am not mistaken the `PretrainedTransformerMismatchedIndexer/Embedder` get rid of the special tokens via the `offsets`, so the *cls_pooler* just takes the embedding of the first \"real text\" token.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 20.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.9.0\r\naiohttp==3.6.2\r\nalembic==1.4.2\r\nallennlp==1.0.0\r\nappdirs==1.4.4\r\nastroid==2.4.2\r\nasync-timeout==3.0.1\r\nattrs==19.3.0\r\nazure-core==1.7.0\r\nazure-storage-blob==12.3.2\r\nbackcall==0.2.0\r\nbeautifulsoup4==4.9.1\r\n-e git+git@github.com:recognai/biome-text.git@7a22136a713f634587702e096f778ea44aa94123#egg=biome_text\r\nblack==19.10b0\r\nbleach==3.1.5\r\nblis==0.4.1\r\nbokeh==2.0.2\r\nboto3==1.14.7\r\nbotocore==1.17.7\r\ncachetools==4.1.1\r\ncachey==0.2.1\r\ncaptum==0.2.0\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi==1.14.0\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncloudpickle==1.4.1\r\ncolorama==0.4.3\r\ncoverage==5.1\r\ncryptography==2.9.2\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ndask==2.17.2\r\ndask-elk==0.4.0\r\ndatabricks-cli==0.11.0\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndistributed==2.19.0\r\ndocker==4.2.2\r\ndocutils==0.15.2\r\nelasticsearch==7.8.0\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nentrypoints==0.3\r\nfastapi==0.55.1\r\nfilelock==3.0.12\r\nFlask==1.1.2\r\nFlask-Cors==3.0.8\r\nflatdict==4.0.1\r\nfsspec==0.7.4\r\nfuture==0.18.2\r\ngevent==1.4.0\r\ngitdb==4.0.5\r\nGitPython==3.1.3\r\ngoogle==2.0.3\r\ngoogle-auth==1.18.0\r\ngoogle-auth-oauthlib==0.4.1\r\ngorilla==0.3.0\r\ngreenlet==0.4.16\r\ngrpcio==1.30.0\r\ngunicorn==20.0.4\r\nh11==0.9.0\r\nh5py==2.10.0\r\nHeapDict==1.0.1\r\nhttptools==0.1.1\r\nidna==2.9\r\nimportlib-metadata==1.6.1\r\nimportlib-resources==2.0.1\r\nipykernel==5.3.0\r\nipython==7.15.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\nisodate==0.6.0\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njedi==0.17.1\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.15.1\r\njson5==0.9.5\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\njupyter-client==6.1.3\r\njupyter-core==4.6.3\r\njupyterlab==2.1.5\r\njupyterlab-server==1.1.5\r\nkiwisolver==1.2.0\r\nlazy-object-proxy==1.4.3\r\nlocket==0.2.0\r\nlxml==4.5.1\r\nMako==1.1.3\r\nMarkdown==3.2.2\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.2.2\r\nmccabe==0.6.1\r\nmemory-profiler==0.57.0\r\nmistune==0.8.4\r\nmkl-fft==1.1.0\r\nmkl-random==1.1.1\r\nmkl-service==2.3.0\r\nmlflow==1.9.1\r\nmore-itertools==8.4.0\r\nmsgpack==0.6.2\r\nmsrest==0.6.17\r\nmultidict==4.7.6\r\nmurmurhash==1.0.2\r\nnbconvert==5.6.1\r\nnbdime==2.0.0\r\nnbformat==5.0.7\r\nnltk==3.5\r\nnotebook==6.0.3\r\nnumpy==1.18.1\r\noauthlib==3.1.0\r\nolefile==0.46\r\noverrides==3.0.0\r\npackaging==20.4\r\npandas==1.0.5\r\npandocfilters==1.4.2\r\nparso==0.7.0\r\npartd==1.1.0\r\npathspec==0.8.0\r\npdoc3==0.8.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.1.2\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprometheus-client==0.8.0\r\nprometheus-flask-exporter==0.14.1\r\nprompt-toolkit==3.0.5\r\nprotobuf==3.12.2\r\npsutil==5.7.0\r\nptyprocess==0.6.0\r\npy==1.8.2\r\npy-spy==0.3.3\r\npyarrow==0.17.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\npydantic==1.5.1\r\nPygments==2.6.1\r\npygraphviz==1.3\r\npylint==2.5.3\r\npyparsing==2.4.7\r\npyrsistent==0.16.0\r\npytest==5.4.3\r\npytest-cov==2.10.0\r\npytest-notebook==0.6.0\r\npytest-pylint==0.14.1\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npytz==2020.1\r\nPyYAML==5.3.1\r\npyzmq==19.0.1\r\nquerystring-parser==1.2.4\r\nray==0.8.6\r\nredis==3.4.1\r\nregex==2020.6.8\r\nrequests==2.24.0\r\nrequests-oauthlib==1.3.0\r\nrsa==4.6\r\ns3fs==0.4.2\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.5.0\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nsmmap==3.0.4\r\nsortedcontainers==2.2.2\r\nsoupsieve==2.0.1\r\nspacy==2.2.4\r\nSQLAlchemy==1.3.13\r\nsqlparse==0.3.1\r\nsrsly==1.0.2\r\nstarlette==0.13.2\r\ntabulate==0.8.7\r\ntblib==1.6.0\r\ntensorboard==2.2.2\r\ntensorboard-plugin-wit==1.7.0\r\ntensorboardX==2.0\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.7.0\r\ntoml==0.10.1\r\ntoolz==0.10.0\r\ntorch==1.5.1\r\ntorchvision==0.6.0a0+35d732a\r\ntornado==6.0.4\r\ntqdm==4.46.1\r\ntraitlets==4.3.3\r\ntransformers==2.11.0\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.2\r\nujson==2.0.3\r\nurllib3==1.25.9\r\nuvicorn==0.11.5\r\nuvloop==0.14.0\r\nwasabi==0.7.0\r\nwcwidth==0.2.4\r\nwebencodings==0.5.1\r\nwebsocket-client==0.57.0\r\nwebsockets==8.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.5.1\r\nwrapt==1.12.1\r\nxlrd==1.2.0\r\nyarl==1.4.2\r\nzict==2.0.0\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp.data.tokenizers import SpacyTokenizer\r\nfrom allennlp.data.token_indexers import PretrainedTransformerMismatchedIndexer\r\nfrom allennlp.data.fields import TextField\r\nfrom allennlp.data.vocabulary import Vocabulary\r\nfrom allennlp.data.instance import Instance\r\nfrom allennlp.data import Batch\r\n\r\nfrom allennlp.modules.token_embedders import PretrainedTransformerMismatchedEmbedder\r\nfrom allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\r\n\r\n\r\ninput_str = \"Check this annoying string!\"\r\n\r\ntokenizer = SpacyTokenizer()\r\ntoken_indexer = {\r\n    \"tokens\": PretrainedTransformerMismatchedIndexer(\r\n        model_name=\"distilroberta-base\"\r\n    )\r\n}\r\n\r\ntf = TextField(tokenizer.tokenize(input_str), token_indexer)\r\ninstance = Instance({\"text\": tf})\r\nvocab = Vocabulary.from_instances([instance])\r\nbatch = Batch([instance])\r\nbatch.index_instances(vocab)\r\npadding_length = batch.get_padding_lengths()\r\n\r\nembedder = PretrainedTransformerMismatchedEmbedder(\r\n    model_name=\"distilroberta-base\"\r\n)\r\ntf_embedder = BasicTextFieldEmbedder({\"tokens\": embedder})\r\n\r\ntensor_dict = batch.as_tensor_dict(padding_length)\r\nembeddings = tf_embedder(tensor_dict[\"text\"])\r\n\r\nprint(tf)\r\nprint(tensor_dict)\r\nprint(embeddings)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4474/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4474/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4464", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4464/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4464/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4464/events", "html_url": "https://github.com/allenai/allennlp/issues/4464", "id": 655658753, "node_id": "MDU6SXNzdWU2NTU2NTg3NTM=", "number": 4464, "title": "not support python3.8", "user": {"login": "linpan", "id": 6077601, "node_id": "MDQ6VXNlcjYwNzc2MDE=", "avatar_url": "https://avatars.githubusercontent.com/u/6077601?v=4", "gravatar_id": "", "url": "https://api.github.com/users/linpan", "html_url": "https://github.com/linpan", "followers_url": "https://api.github.com/users/linpan/followers", "following_url": "https://api.github.com/users/linpan/following{/other_user}", "gists_url": "https://api.github.com/users/linpan/gists{/gist_id}", "starred_url": "https://api.github.com/users/linpan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/linpan/subscriptions", "organizations_url": "https://api.github.com/users/linpan/orgs", "repos_url": "https://api.github.com/users/linpan/repos", "events_url": "https://api.github.com/users/linpan/events{/privacy}", "received_events_url": "https://api.github.com/users/linpan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-13T08:39:27Z", "updated_at": "2020-07-17T12:46:53Z", "closed_at": "2020-07-17T12:46:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "bug: \r\n Downloading http://mirrors.aliyun.com/pypi/packages/c6/27/07b57d22496ed6c98b247e578712122402487f5c265ec70a747900f97060/gluonnlp-0.9.1.tar.gz (252 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 252 kB 317 kB/s \r\n    ERROR: Command errored out with exit status 1:\r\n     command: /Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/pip-install-lev8or49/gluonnlp/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/pip-install-lev8or49/gluonnlp/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/pip-pip-egg-info-z2950nce\r\n         cwd: /private/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/pip-install-lev8or49/gluonnlp/\r\n    Complete output (34 lines):\r\n    WARNING: The wheel package is not available.\r\n    WARNING: The repository located at mirrors.aliyun.com is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host mirrors.aliyun.com'.\r\n    ERROR: Could not find a version that satisfies the requirement cython (from versions: none)\r\n    ERROR: No matching distribution found for cython\r\n    Traceback (most recent call last):\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/setuptools/installer.py\", line 128, in fetch_build_egg\r\n        subprocess.check_call(cmd)\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/lib/python3.8/subprocess.py\", line 364, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/bin/python3', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/tmptdb_jxqw', '--quiet', 'cython']' returned non-zero exit status 1.\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/private/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/pip-install-lev8or49/gluonnlp/setup.py\", line 37, in <module>\r\n        setup(\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/setuptools/__init__.py\", line 143, in setup\r\n        _install_setup_requires(attrs)\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/setuptools/__init__.py\", line 138, in _install_setup_requires\r\n        dist.fetch_build_eggs(dist.setup_requires)\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/setuptools/dist.py\", line 695, in fetch_build_eggs\r\n        resolved_dists = pkg_resources.working_set.resolve(\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 781, in resolve\r\n        dist = best[req.key] = env.best_match(\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 1066, in best_match\r\n        return self.obtain(req, installer)\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 1078, in obtain\r\n        return installer(requirement)\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/setuptools/dist.py\", line 754, in fetch_build_egg\r\n        return fetch_build_egg(self, req)\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/setuptools/installer.py\", line 130, in fetch_build_egg\r\n        raise DistutilsError(str(e))\r\n    distutils.errors.DistutilsError: Command '['/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/bin/python3', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/tmptdb_jxqw', '--quiet', 'cython']' returned non-zero exit status 1.\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4464/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4464/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4463", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4463/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4463/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4463/events", "html_url": "https://github.com/allenai/allennlp/issues/4463", "id": 655439641, "node_id": "MDU6SXNzdWU2NTU0Mzk2NDE=", "number": 4463, "title": "Missing srl-eval.pl in allennlp-models", "user": {"login": "Riccorl", "id": 10062216, "node_id": "MDQ6VXNlcjEwMDYyMjE2", "avatar_url": "https://avatars.githubusercontent.com/u/10062216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Riccorl", "html_url": "https://github.com/Riccorl", "followers_url": "https://api.github.com/users/Riccorl/followers", "following_url": "https://api.github.com/users/Riccorl/following{/other_user}", "gists_url": "https://api.github.com/users/Riccorl/gists{/gist_id}", "starred_url": "https://api.github.com/users/Riccorl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Riccorl/subscriptions", "organizations_url": "https://api.github.com/users/Riccorl/orgs", "repos_url": "https://api.github.com/users/Riccorl/repos", "events_url": "https://api.github.com/users/Riccorl/events{/privacy}", "received_events_url": "https://api.github.com/users/Riccorl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-07-12T17:13:44Z", "updated_at": "2020-08-19T12:48:51Z", "closed_at": "2020-08-19T12:48:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "When installing allennlp-models 1.0.0 through pip with\r\n\r\n```\r\npip install allennlp-models\r\n```\r\n\r\n[srl-eval.pl](https://github.com/allenai/allennlp-models/blob/master/allennlp_models/structured_prediction/tools/srl-eval.pl) file is missing.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4463/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4463/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4452", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4452/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4452/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4452/events", "html_url": "https://github.com/allenai/allennlp/issues/4452", "id": 653237665, "node_id": "MDU6SXNzdWU2NTMyMzc2NjU=", "number": 4452, "title": "Missing 'allennlp.data.fields.production_rule_field' in allennlp-1.0.0", "user": {"login": "madcpt", "id": 33171760, "node_id": "MDQ6VXNlcjMzMTcxNzYw", "avatar_url": "https://avatars.githubusercontent.com/u/33171760?v=4", "gravatar_id": "", "url": "https://api.github.com/users/madcpt", "html_url": "https://github.com/madcpt", "followers_url": "https://api.github.com/users/madcpt/followers", "following_url": "https://api.github.com/users/madcpt/following{/other_user}", "gists_url": "https://api.github.com/users/madcpt/gists{/gist_id}", "starred_url": "https://api.github.com/users/madcpt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/madcpt/subscriptions", "organizations_url": "https://api.github.com/users/madcpt/orgs", "repos_url": "https://api.github.com/users/madcpt/repos", "events_url": "https://api.github.com/users/madcpt/events{/privacy}", "received_events_url": "https://api.github.com/users/madcpt/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-08T11:57:22Z", "updated_at": "2020-07-19T00:28:20Z", "closed_at": "2020-07-08T12:14:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/zihan/.local/bin/allennlp\", line 11, in <module>\r\n    sys.exit(run())\r\n  File \"/home/zihan/.local/lib/python3.6/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/zihan/.local/lib/python3.6/site-packages/allennlp/commands/__init__.py\", line 91, in main\r\n    import_module_and_submodules(package_name)\r\n  File \"/home/zihan/.local/lib/python3.6/site-packages/allennlp/common/util.py\", line 340, in import_module_and_submodules\r\n    module = importlib.import_module(package_name)\r\n  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/mnt/d/projects/spider-schema-gnn-global/dataset_readers/spider.py\", line 10, in <module>\r\n    from allennlp.data.fields.production_rule_field import ProductionRuleField\r\nModuleNotFoundError: No module named 'allennlp.data.fields.production_rule_field'\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.6.1\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp (1.0.0)\r\nasn1crypto (0.24.0)\r\nattrs (17.4.0)\r\nAutomat (0.6.0)\r\nbeautifulsoup4 (4.9.1)\r\nblinker (1.4)\r\nblis (0.4.1)\r\nboto3 (1.14.18)\r\nbotocore (1.17.18)\r\ncatalogue (1.0.0)\r\ncertifi (2020.6.20)\r\nchardet (3.0.4)\r\ncheroot (8.3.0)\r\nCherryPy (18.6.0)\r\nclick (7.1.2)\r\ncloud-init (19.4)\r\ncolorama (0.3.7)\r\ncommand-not-found (0.3)\r\nconfigobj (5.0.6)\r\nconstantly (15.1.0)\r\ncontextvars (2.4)\r\ncryptography (2.1.4)\r\ncymem (2.0.3)\r\ndataclasses (0.7)\r\ndecorator (4.4.2)\r\ndill (0.3.2)\r\ndistro-info (0.18ubuntu0.18.04.1)\r\ndocutils (0.15.2)\r\ndocx (0.2.4)\r\nen-core-web-sm (2.0.0)\r\nfeedparser (5.2.1)\r\nfilelock (3.0.12)\r\nflake8 (3.8.3)\r\nfuture (0.18.2)\r\nh5py (2.10.0)\r\nhttplib2 (0.9.2)\r\nhyperlink (17.3.1)\r\nidna (2.10)\r\nimmutables (0.14)\r\nimportlib-metadata (1.7.0)\r\nimportlib-resources (3.0.0)\r\nincremental (16.10.1)\r\nisodate (0.6.0)\r\njaraco.classes (3.1.0)\r\njaraco.collections (3.0.0)\r\njaraco.functools (3.0.1)\r\njaraco.text (3.2.0)\r\nJinja2 (2.10)\r\njmespath (0.10.0)\r\njoblib (0.16.0)\r\njsonpatch (1.16)\r\njsonpickle (1.4.1)\r\njsonpointer (1.10)\r\njsonschema (2.6.0)\r\nkeyring (10.6.0)\r\nkeyrings.alt (3.0)\r\nlanguage-selector (0.1)\r\nlxml (4.5.1)\r\nMarkupSafe (1.0)\r\nmccabe (0.6.1)\r\nmore-itertools (8.4.0)\r\nmurmurhash (1.0.2)\r\nnetifaces (0.10.4)\r\nnetworkx (2.4)\r\nnltk (3.5)\r\nnumpy (1.19.0)\r\noauthlib (2.0.6)\r\nordered-set (4.0.2)\r\noverrides (3.1.0)\r\npackaging (20.4)\r\nPAM (0.4.2)\r\npandas (1.0.5)\r\npattern3 (3.0.0)\r\npdfminer.six (20200517)\r\npdfminer3k (1.3.4)\r\nPillow (7.2.0)\r\npip (9.0.1)\r\nplac (1.1.3)\r\nply (3.11)\r\nplyfile (0.7.2)\r\nportend (2.6)\r\npreshed (3.0.2)\r\nprotobuf (3.12.2)\r\npyasn1 (0.4.2)\r\npyasn1-modules (0.2.1)\r\npycodestyle (2.6.0)\r\npycrypto (2.6.1)\r\npycryptodome (3.9.8)\r\npydantic (1.5.1)\r\npyflakes (2.2.0)\r\npygobject (3.26.1)\r\nPyJWT (1.5.3)\r\npyOpenSSL (17.5.0)\r\npyparsing (2.4.7)\r\npyserial (3.4)\r\npython-apt (1.6.5+ubuntu0.2)\r\npython-dateutil (2.8.1)\r\npython-debian (0.1.32)\r\npytz (2020.1)\r\npyxdg (0.25)\r\nPyYAML (3.12)\r\nrdflib (5.0.0)\r\nregex (2020.6.8)\r\nrequests (2.24.0)\r\nrequests-unixsocket (0.1.5)\r\ns3transfer (0.3.3)\r\nsacremoses (0.0.43)\r\nscikit-learn (0.23.1)\r\nscipy (1.5.1)\r\nSecretStorage (2.3.1)\r\nsentencepiece (0.1.91)\r\nservice-identity (16.0.0)\r\nsetuptools (49.1.0)\r\nsimplejson (3.17.0)\r\nsix (1.15.0)\r\nsortedcontainers (2.2.2)\r\nsoupsieve (2.0.1)\r\nspacy (3.0.0a0)\r\nsrsly (2.2.0)\r\nssh-import-id (5.7)\r\nsystemd-python (234)\r\ntempora (3.0.0)\r\ntensorboardX (2.1)\r\nthinc (8.0.0a11)\r\nthreadpoolctl (2.1.0)\r\ntokenizers (0.8.1rc1)\r\ntorch (1.5.0+cpu)\r\ntorch-cluster (1.3.0)\r\ntorch-geometric (1.2.1)\r\ntorch-scatter (1.2.0)\r\ntorch-sparse (0.4.3)\r\ntqdm (4.47.0)\r\ntransformers (3.0.2)\r\nTwisted (17.9.0)\r\ntyper (0.3.0)\r\ntyping-extensions (3.7.4.2)\r\nufw (0.36)\r\nunattended-upgrades (0.1)\r\nurllib3 (1.25.9)\r\nwasabi (0.7.0)\r\nwheel (0.30.0)\r\nzc.lockfile (2.0)\r\nzipp (3.1.0)\r\nzope.interface (4.3.2)\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4452/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4452/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4441", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4441/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4441/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4441/events", "html_url": "https://github.com/allenai/allennlp/issues/4441", "id": 651002569, "node_id": "MDU6SXNzdWU2NTEwMDI1Njk=", "number": 4441, "title": "where is part of speech and proper name category label collection?", "user": {"login": "wnnlyf", "id": 43957, "node_id": "MDQ6VXNlcjQzOTU3", "avatar_url": "https://avatars.githubusercontent.com/u/43957?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wnnlyf", "html_url": "https://github.com/wnnlyf", "followers_url": "https://api.github.com/users/wnnlyf/followers", "following_url": "https://api.github.com/users/wnnlyf/following{/other_user}", "gists_url": "https://api.github.com/users/wnnlyf/gists{/gist_id}", "starred_url": "https://api.github.com/users/wnnlyf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wnnlyf/subscriptions", "organizations_url": "https://api.github.com/users/wnnlyf/orgs", "repos_url": "https://api.github.com/users/wnnlyf/repos", "events_url": "https://api.github.com/users/wnnlyf/events{/privacy}", "received_events_url": "https://api.github.com/users/wnnlyf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-05T05:05:52Z", "updated_at": "2020-07-06T15:11:30Z", "closed_at": "2020-07-06T15:11:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "A list like this:\r\nhttps://github.com/baidu/lac\r\n\r\n\u6807\u7b7e | \u542b\u4e49 | \u6807\u7b7e | \u542b\u4e49 | \u6807\u7b7e | \u542b\u4e49 | \u6807\u7b7e | \u542b\u4e49\r\n-- | -- | -- | -- | -- | -- | -- | --\r\nn | \u666e\u901a\u540d\u8bcd | f | \u65b9\u4f4d\u540d\u8bcd | s | \u5904\u6240\u540d\u8bcd | nw | \u4f5c\u54c1\u540d\r\nnz | \u5176\u4ed6\u4e13\u540d | v | \u666e\u901a\u52a8\u8bcd | vd | \u52a8\u526f\u8bcd | vn | \u540d\u52a8\u8bcd\r\na | \u5f62\u5bb9\u8bcd | ad | \u526f\u5f62\u8bcd | an | \u540d\u5f62\u8bcd | d | \u526f\u8bcd\r\nm | \u6570\u91cf\u8bcd | q | \u91cf\u8bcd | r | \u4ee3\u8bcd | p | \u4ecb\u8bcd\r\nc | \u8fde\u8bcd | u | \u52a9\u8bcd | xc | \u5176\u4ed6\u865a\u8bcd | w | \u6807\u70b9\u7b26\u53f7\r\nPER | \u4eba\u540d\r\n\r\nI didn't find such instructions in the AllenNlP's doc\r\nIs it consistent with baidu/lac?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4441/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4441/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4431", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4431/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4431/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4431/events", "html_url": "https://github.com/allenai/allennlp/issues/4431", "id": 649813160, "node_id": "MDU6SXNzdWU2NDk4MTMxNjA=", "number": 4431, "title": "Error loading model using load_archive from local path", "user": {"login": "itsmemala", "id": 8657349, "node_id": "MDQ6VXNlcjg2NTczNDk=", "avatar_url": "https://avatars.githubusercontent.com/u/8657349?v=4", "gravatar_id": "", "url": "https://api.github.com/users/itsmemala", "html_url": "https://github.com/itsmemala", "followers_url": "https://api.github.com/users/itsmemala/followers", "following_url": "https://api.github.com/users/itsmemala/following{/other_user}", "gists_url": "https://api.github.com/users/itsmemala/gists{/gist_id}", "starred_url": "https://api.github.com/users/itsmemala/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/itsmemala/subscriptions", "organizations_url": "https://api.github.com/users/itsmemala/orgs", "repos_url": "https://api.github.com/users/itsmemala/repos", "events_url": "https://api.github.com/users/itsmemala/events{/privacy}", "received_events_url": "https://api.github.com/users/itsmemala/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-02T10:16:47Z", "updated_at": "2020-07-04T05:31:23Z", "closed_at": "2020-07-04T05:31:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Checklist\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nI'm trying to load a model saved to a local path in the Kaggle environment, using the allennlp.models.load_archive() method but I get the below error:\r\n\"ConfigurationError: discourse_classifier is not a registered name for Model. You probably need to use the --include-package flag to load your custom code. Alternatively, you can specify your choices using fully-qualified paths, e.g. {\"model\": \"my_module.models.MyModel\"} in which case they will be automatically imported correctly.\"\r\n\r\nModel location: https://s3-us-west-2.amazonaws.com/pubmed-rct/model.tar.gz\r\n\r\nTraceback:\r\n```\r\n<ipython-input-21-1d9004d63a1a> in <module>\r\n----> 1 archive = load_archive(\"/kaggle/input/modelbase\") ## available at github\r\n      2 predictor = Predictor.from_archive(archive, 'discourse_crf_predictor')\r\n      3 gc.collect()\r\n\r\n/opt/conda/lib/python3.7/site-packages/allennlp/models/archival.py in load_archive(archive_file, cuda_device, opt_level, overrides, weights_file)\r\n    195         serialization_dir=serialization_dir,\r\n    196         cuda_device=cuda_device,\r\n--> 197         opt_level=opt_level,\r\n    198     )\r\n    199 \r\n\r\n/opt/conda/lib/python3.7/site-packages/allennlp/models/model.py in load(cls, config, serialization_dir, weights_file, cuda_device, opt_level)\r\n    389         # This allows subclasses of Model to override _load.\r\n    390 \r\n--> 391         model_class: Type[Model] = cls.by_name(model_type)  # type: ignore\r\n    392         if not isinstance(model_class, type):\r\n    393             # If you're using from_archive to specify your model (e.g., for fine tuning), then you\r\n\r\n/opt/conda/lib/python3.7/site-packages/allennlp/common/registrable.py in by_name(cls, name)\r\n    135         \"\"\"\r\n    136         logger.debug(f\"instantiating registered subclass {name} of {cls}\")\r\n--> 137         subclass, constructor = cls.resolve_class_name(name)\r\n    138         if not constructor:\r\n    139             return subclass\r\n\r\n/opt/conda/lib/python3.7/site-packages/allennlp/common/registrable.py in resolve_class_name(cls, name)\r\n    183             # is not a qualified class name\r\n    184             raise ConfigurationError(\r\n--> 185                 f\"{name} is not a registered name for {cls.__name__}. \"\r\n    186                 \"You probably need to use the --include-package flag \"\r\n    187                 \"to load your custom code. Alternatively, you can specify your choices \"\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Kaggle kernel\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.6\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.9.0\r\nadal==1.2.2\r\naffine==2.3.0\r\naiohttp==3.6.2\r\nalabaster==0.7.12\r\nalbumentations==0.4.5\r\nalembic==1.4.2\r\nallennlp==1.0.0\r\naltair==4.1.0\r\nanaconda-client==1.7.2\r\nanaconda-project==0.8.3\r\nannoy==1.16.3\r\nansiwrap==0.8.4\r\nappdirs==1.4.3\r\nargh==0.26.2\r\narrow==0.15.5\r\narviz==0.8.3\r\nasn1crypto==1.3.0\r\nastroid==2.3.3\r\nastropy==4.0.1.post1\r\nastunparse==1.6.3\r\nasync-generator==1.10\r\nasync-timeout==3.0.1\r\natomicwrites==1.3.0\r\nattrs==19.3.0\r\naudioread==2.1.8\r\nautopep8==1.5.1\r\nBabel==2.8.0\r\nbackcall==0.1.0\r\nbackports.shutil-get-terminal-size==1.0.0\r\nBaker==1.3\r\nbasemap==1.2.1\r\nbayesian-optimization @ git+https://github.com/fmfn/BayesianOptimization.git@cb28df83f757c5c7406b2730eac3a67a2d0270a5\r\nbayespy==0.5.19\r\nbcolz==1.2.1\r\nbeautifulsoup4==4.9.0\r\nbinaryornot==0.4.4\r\nbiopython==1.77\r\nbitarray==1.2.1\r\nbkcharts==0.2\r\nblack==19.10b0\r\nbleach==3.1.4\r\nblinker==1.4\r\nblis==0.4.1\r\nbokeh==2.0.1\r\nBoruta==0.3\r\nboto==2.49.0\r\nboto3==1.14.6\r\nbotocore==1.17.6\r\nBottleneck==1.3.2\r\n-e git+https://github.com/SohierDane/BigQuery_Helper@8615a7f6c1663e7f2d48aa2b32c2dbcb600a440f#egg=bq_helper\r\nbqplot==0.12.12\r\nbranca==0.4.1\r\nbrewer2mpl==1.4.1\r\nbrotlipy==0.7.0\r\ncachetools==3.1.1\r\ncairocffi==1.1.0\r\nCairoSVG==2.4.2\r\nCartopy @ file:///home/conda/feedstock_root/build_artifacts/cartopy_1588596947365/work\r\ncatalogue==1.0.0\r\ncatalyst==20.6\r\ncatboost==0.23.2\r\ncategory-encoders @ git+https://github.com/scikit-learn-contrib/categorical-encoding.git@ea9428a896bef77baf8b26159f7030cee924e916\r\ncertifi==2020.4.5.2\r\ncesium==0.9.12\r\ncffi==1.14.0\r\ncftime==1.1.3\r\nchainer==7.4.0\r\nchainer-chemistry==0.7.0\r\nchainercv==0.13.1\r\nchardet==3.0.4\r\ncleverhans==3.0.1\r\nclick==7.1.1\r\nclick-plugins==1.1.1\r\ncliff==3.3.0\r\ncligj==0.5.0\r\ncloud-tpu-client==0.10\r\ncloudpickle==1.3.0\r\nclyent==1.2.2\r\ncmaes==0.5.0\r\ncmd2==1.1.0\r\ncmdstanpy==0.4.0\r\ncmudict==0.4.4\r\ncolorama==0.4.3\r\ncolorcet==2.0.2\r\ncolorlog==4.1.0\r\ncolorlover==0.3.0\r\nconda==4.8.3\r\nconda-package-handling==1.6.0\r\nConfigArgParse==1.2.3\r\nconfigparser==5.0.0\r\nconfuse==1.1.0\r\ncontextily==1.0.0\r\ncontextlib2==0.6.0.post1\r\nconvertdate==2.2.1\r\nconx==3.7.10\r\ncookiecutter==1.7.0\r\ncoverage==5.1\r\ncrc32c==2.0\r\ncryptography==2.8\r\ncssselect2==0.3.0\r\ncufflinks==0.17.3\r\nCVXcanon==0.1.1\r\ncvxpy==1.1.1\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ncysignals==1.10.2\r\nCython==0.29.20\r\ncytoolz==0.10.1\r\ndask==2.18.1\r\ndask-glm==0.2.0\r\ndask-ml==1.5.0\r\ndask-xgboost==0.1.10\r\ndatashader==0.11.0\r\ndatashape==0.5.2\r\ndeap==1.3.1\r\ndecorator==4.4.2\r\ndeepdish==0.3.6\r\ndefusedxml==0.6.0\r\nDelorean==1.0.0\r\nDeprecated @ file:///home/conda/feedstock_root/build_artifacts/deprecated_1589409885623/work\r\ndeprecation==2.1.0\r\ndescartes==1.1.0\r\ndiff-match-patch==20181111\r\ndill==0.3.2\r\ndipy==1.1.1\r\ndistributed==2.14.0\r\ndlib==19.20.0\r\ndocker==4.2.0\r\ndocker-pycreds==0.4.0\r\ndocopt==0.6.2\r\ndocutils==0.15.2\r\nearthengine-api==0.1.226\r\necos==2.0.7.post1\r\neli5==0.10.1\r\nemoji==0.5.4\r\nen-core-web-lg @ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nentrypoints==0.3\r\nephem==3.7.7.1\r\nessentia==2.1b6.dev234\r\net-xmlfile==1.0.1\r\nfancyimpute==0.5.4\r\nfastai==1.0.61\r\nfastcache==1.1.0\r\nfastprogress==0.2.3\r\nfasttext==0.9.2\r\nfbpca==1.0\r\nfbprophet==0.6\r\nfeather-format==0.4.1\r\nfeaturetools==0.16.0\r\nfilelock==3.0.10\r\nFiona==1.8.13\r\nfitter==1.2.1\r\nflake8==3.7.9\r\nflashtext==2.7\r\nFlask==1.1.2\r\nfolium==0.11.0\r\nfsspec==0.7.2\r\nfuncy==1.14\r\nfury==0.5.1\r\nfuture==0.18.2\r\nfuzzywuzzy==0.18.0\r\ngast==0.3.3\r\ngatspy==0.3\r\ngcsfs==0.6.1\r\nGDAL==3.0.4\r\ngensim==3.8.3\r\ngeographiclib==1.50\r\nGeohash==1.0\r\ngeojson==2.5.0\r\ngeopandas==0.6.3\r\ngeoplot==0.4.1\r\ngeopy==1.22.0\r\ngeoviews==1.8.1\r\ngevent==1.5.0\r\nggplot @ https://github.com/hbasria/ggpy/archive/0.11.5.zip\r\ngitdb==4.0.4\r\nGitPython==3.1.1\r\nglob2==0.7\r\ngluoncv==0.7.0\r\ngluonnlp==0.9.1\r\ngmpy2==2.1.0b1\r\ngoogle==2.0.3\r\ngoogle-api-core==1.17.0\r\ngoogle-api-python-client==1.8.0\r\ngoogle-auth==1.14.0\r\ngoogle-auth-httplib2==0.0.3\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-cloud-automl==0.10.0\r\ngoogle-cloud-bigquery==1.12.1\r\ngoogle-cloud-bigtable==1.2.1\r\ngoogle-cloud-core==1.3.0\r\ngoogle-cloud-dataproc==0.7.0\r\ngoogle-cloud-datastore==1.12.0\r\ngoogle-cloud-firestore==1.6.2\r\ngoogle-cloud-kms==1.4.0\r\ngoogle-cloud-language==1.3.0\r\ngoogle-cloud-logging==1.15.0\r\ngoogle-cloud-pubsub==1.4.3\r\ngoogle-cloud-scheduler==1.2.1\r\ngoogle-cloud-spanner==1.15.1\r\ngoogle-cloud-speech==1.3.2\r\ngoogle-cloud-storage==1.27.0\r\ngoogle-cloud-tasks==1.5.0\r\ngoogle-cloud-translate==2.0.1\r\ngoogle-cloud-videointelligence==1.14.0\r\ngoogle-cloud-vision==1.0.0\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==0.5.0\r\ngoogleapis-common-protos==1.51.0\r\ngplearn==0.4.1\r\ngpxpy==1.4.1\r\ngql==0.2.0\r\ngraphql-core==1.1\r\ngraphviz==0.8.4\r\ngreenlet==0.4.15\r\ngrpc-google-iam-v1==0.12.3\r\ngrpcio==1.29.0\r\ngrpcio-gcp==0.2.2\r\ngym==0.17.2\r\nh2o==3.30.0.5\r\nh5py==2.10.0\r\nhaversine==2.2.0\r\nheamy==0.0.7\r\nHeapDict==1.0.1\r\nhep-ml==0.6.1\r\nhmmlearn==0.2.3\r\nholidays==0.10.2\r\nholoviews==1.13.2\r\nhpsklearn==0.1.0\r\nhtml5lib==1.0.1\r\nhtmlmin==0.1.12\r\nhttplib2==0.17.2\r\nhttplib2shim==0.0.3\r\nhumanize==2.4.0\r\nhunspell==0.5.5\r\nhusl==4.0.3\r\nhyperopt==0.2.4\r\nhypertools==0.6.2\r\nhypothesis==5.10.0\r\nibis-framework==1.3.0\r\nidna==2.9\r\nimagecodecs==2020.5.30\r\nImageHash==4.1.0\r\nimageio==2.8.0\r\nimagesize==1.2.0\r\nimbalanced-learn==0.7.0\r\nimgaug==0.2.6\r\nimplicit==0.4.2\r\nimportlib-metadata==1.6.0\r\nintervaltree==3.0.2\r\nipykernel==5.1.1\r\nipython==7.13.0\r\nipython-genutils==0.2.0\r\nipython-sql==0.3.9\r\nipywidgets==7.5.1\r\niso3166==1.0.1\r\nisort==4.3.21\r\nisoweek==1.3.3\r\nitsdangerous==1.1.0\r\nJanome==0.3.10\r\njdcal==1.4.1\r\njedi==0.15.2\r\njeepney==0.4.3\r\njieba==0.42.1\r\nJinja2==2.11.2\r\njinja2-time==0.2.0\r\njmespath==0.10.0\r\njoblib==0.14.1\r\njson5==0.9.0\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-aihub-deploy-extension==0.1\r\njupyter-client==6.1.3\r\njupyter-console==6.1.0\r\njupyter-core==4.6.3\r\njupyter-http-over-ws==0.0.8\r\njupyterlab==1.2.10\r\njupyterlab-git==0.10.0\r\njupyterlab-server==1.1.1\r\nkaggle==1.5.6\r\nkaggle-environments==1.0.8\r\nKeras==2.4.0\r\nKeras-Preprocessing==1.1.2\r\nkeras-tuner==1.0.1\r\nkeyring==21.1.1\r\nkiwisolver==1.2.0\r\nkmapper==1.2.0\r\nkmeans-smote==0.1.2\r\nkmodes==0.10.2\r\nknnimpute==0.1.0\r\nkorean-lunar-calendar==0.2.1\r\nkornia==0.3.1\r\nkubernetes==10.1.0\r\nlangid==1.1.6\r\nLasagne @ git+git://github.com/Lasagne/Lasagne.git@5d3c63cb315c50b1cbd27a6bc8664b406f34dd99\r\nlazy-object-proxy==1.4.3\r\nlearntools @ git+https://github.com/Kaggle/learntools@886f5c215de079287f21e2d3a92bd852fb95d105\r\nleven==1.0.4\r\nlibarchive-c==2.9\r\nlibrosa==0.7.2\r\nlief==0.9.0\r\nlightfm==1.15\r\nlightgbm==2.3.1\r\nlime==0.2.0.0\r\nline-profiler==3.0.2\r\nllvmlite==0.31.0\r\nlml==0.0.9\r\nlocket==0.2.0\r\nLunarCalendar==0.0.9\r\nlxml==4.5.0\r\nMako==1.1.3\r\nmapclassify==2.3.0\r\nmarisa-trie==0.7.5\r\nMarkdown==3.2.1\r\nmarkovify==0.8.2\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.2.1\r\nmatplotlib-venn==0.11.5\r\nmccabe==0.6.1\r\nmemory-profiler==0.57.0\r\nmercantile==1.1.5\r\nmissingno==0.4.2\r\nmistune==0.8.4\r\nmizani==0.7.1\r\nmkl-fft==1.1.0\r\nmkl-random==1.1.0\r\nmkl-service==2.3.0\r\nml-metrics==0.1.4\r\nmlcrate==0.2.0\r\nmlens==0.2.3\r\nmlxtend==0.17.2\r\nmmh3==2.5.1\r\nmne==0.20.7\r\nmnist==0.2.2\r\nmock==3.0.5\r\nmore-itertools==8.2.0\r\nmpld3==0.5.1\r\nmplleaflet==0.0.5\r\nmpmath==1.1.0\r\nmsgpack==0.6.2\r\nmsgpack-numpy==0.4.6.post0\r\nmultidict==4.7.6\r\nmultipledispatch==0.6.0\r\nmultiprocess==0.70.10\r\nmunch==2.5.0\r\nmurmurhash==1.0.2\r\nmxnet==1.6.0\r\nmypy-extensions==0.4.3\r\nnb-conda==2.2.1\r\nnb-conda-kernels==2.2.3\r\nnbclient==0.2.0\r\nnbconvert==5.6.1\r\nnbdime==2.0.0\r\nnbformat==5.0.6\r\nnbpresent==3.0.2\r\nnervananeon @ file:///usr/local/src/neon\r\nnest-asyncio==1.3.2\r\nnetCDF4==1.5.3\r\nnetworkx==2.4\r\nnibabel==3.1.0\r\nnilearn==0.6.2\r\nnltk==3.2.4\r\nnnabla==1.8.0\r\nnolearn==0.6.1\r\nnose==1.3.7\r\nnotebook==5.5.0\r\nnotebook-executor==0.2\r\nnumba==0.48.0\r\nnumexpr==2.7.1\r\nnumpy==1.18.1\r\nnumpydoc==0.9.2\r\nnvidia-ml-py3==7.352.0\r\noauth2client==4.1.3\r\noauthlib==3.0.1\r\nodfpy==1.4.1\r\nolefile==0.46\r\nonnx==1.7.0\r\nopencv-python==4.2.0.34\r\nopenpyxl==3.0.3\r\nopenslide-python @ git+git://github.com/rosbo/openslide-python.git@6bb6e3dbae448fe9ccf21a5a2078e9d7e890153c\r\nopt-einsum==3.2.1\r\noptuna==1.5.0\r\norderedmultidict==1.0.1\r\nortools==7.7.7810\r\nosmnx==0.14.1\r\nosqp==0.6.1\r\noverrides==3.0.0\r\nOWSLib @ file:///home/conda/feedstock_root/build_artifacts/owslib_1591376955812/work\r\npackaging==20.1\r\npalettable==3.3.0\r\npandas==1.0.3\r\npandas-datareader==0.8.1\r\npandas-profiling==2.6.0\r\npandas-summary==0.0.7\r\npandasql==0.7.3\r\npandoc==1.0.2\r\npandocfilters==1.4.2\r\npanel==0.9.5\r\npapermill==2.1.0\r\nparam==1.9.3\r\nparso==0.5.2\r\npartd==1.1.0\r\npath==13.1.0\r\npath.py==12.4.0\r\npathlib2==2.3.5\r\npathos==0.2.6\r\npathspec==0.8.0\r\npathtools==0.1.2\r\npatsy==0.5.1\r\npbr==5.4.5\r\npdf2image==1.13.1\r\nPDPbox @ git+https://github.com/SauceCat/PDPbox@73c69665f1663b53984e187c7bc8996e25fea18e\r\npep8==1.7.1\r\npexpect==4.8.0\r\nphik==0.9.11\r\npickleshare==0.7.5\r\nPillow==5.4.1\r\npkginfo==1.5.0.1\r\nplac==1.1.3\r\nplotly==4.8.1\r\nplotly-express==0.4.1\r\nplotnine==0.7.0\r\npluggy==0.13.0\r\nply==3.11\r\npolyglot==16.7.4\r\nportalocker==1.7.0\r\nposix-ipc==1.0.4\r\npox==0.2.8\r\npoyo==0.5.0\r\nppca==0.0.4\r\nppft==1.6.6.2\r\npreprocessing==0.1.13\r\npreshed==3.0.2\r\nprettytable==0.7.2\r\nprometheus-client==0.7.1\r\npromise==2.3\r\nprompt-toolkit==3.0.5\r\npronouncing==0.2.0\r\nprotobuf==3.12.2\r\npsutil==5.7.0\r\nptyprocess==0.6.0\r\npudb==2019.2\r\npy==1.8.1\r\npy-cpuinfo==6.0.0\r\npy-lz4framed==0.14.0\r\npy-spy==0.3.3\r\npy-stringmatching==0.4.1\r\npy-stringsimjoin==0.3.1\r\npyahocorasick==1.4.0\r\npyaml==20.4.0\r\nPyArabic==0.6.7\r\npyarrow==0.16.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.7\r\nPyAstronomy==0.15.0\r\npybind11==2.5.0\r\nPyBrain==0.3\r\npycairo==1.19.1\r\npycodestyle==2.5.0\r\npycosat==0.6.3\r\npycountry==19.8.18\r\npycparser==2.20\r\npycrypto==2.6.1\r\npyct==0.4.6\r\npycurl==7.43.0.5\r\npydash==4.8.0\r\npydicom==2.0.0\r\npydocstyle==5.0.2\r\npydot==1.4.1\r\npydub==0.24.1\r\npyemd==0.5.1\r\npyepsg==0.4.0\r\npyexcel-io==0.5.20\r\npyexcel-ods==0.5.6\r\npyfasttext==0.4.6\r\npyflakes==2.1.1\r\npyglet==1.5.0\r\nPygments==2.6.1\r\nPyJWT==1.7.1\r\npykalman==0.9.5\r\npyLDAvis==2.1.2\r\npylint==2.4.4\r\npymc3==3.9.1\r\nPyMeeus==0.3.7\r\npymongo==3.10.1\r\nPympler==0.8\r\npyocr==0.7.2\r\npyodbc==4.0.30\r\npyOpenSSL==19.1.0\r\npypandoc==1.5\r\npyparsing==2.4.7\r\npyPdf==1.13\r\npyperclip==1.8.0\r\nPyPrind==2.11.2\r\npyproj @ file:///home/conda/feedstock_root/build_artifacts/pyproj_1588596070165/work\r\nPyQt5==5.12.3\r\nPyQt5-sip==4.19.18\r\nPyQtWebEngine==5.12.1\r\npyrsistent==0.16.0\r\npysal==2.1.0\r\npyshp==2.1.0\r\nPySocks==1.7.1\r\npystan==2.19.1.1\r\npytagcloud==0.3.5\r\npytesseract==0.3.4\r\npytest==5.4.1\r\npytest-arraydiff==0.3\r\npytest-astropy==0.7.0\r\npytest-astropy-header==0.1.2\r\npytest-cov==2.10.0\r\npytest-doctestplus==0.4.0\r\npytest-mock==3.1.1\r\npytest-openfiles==0.4.0\r\npytest-remotedata==0.3.1\r\npytext-nlp==0.1.2\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npython-igraph @ file:///home/conda/feedstock_root/build_artifacts/python-igraph_1588168236405/work\r\npython-jsonrpc-server==0.3.4\r\npython-language-server==0.31.10\r\npython-Levenshtein==0.12.0\r\npython-louvain==0.14\r\npython-slugify==4.0.0\r\npytorch-ignite==0.3.0\r\npytz==2019.3\r\nPyUpSet==0.1.1.post7\r\npyviz-comms==0.7.5\r\nPyWavelets==1.1.1\r\npyxdg==0.26\r\nPyYAML==5.3.1\r\npyzmq==19.0.0\r\nQDarkStyle==2.8.1\r\nqgrid==1.3.1\r\nQtAwesome==0.7.1\r\nqtconsole==4.7.3\r\nQtPy==1.9.0\r\nrandomgen==1.16.6\r\nrasterio==1.1.5\r\nray==0.8.5\r\nredis==3.4.1\r\nregex==2020.4.4\r\nrequests==2.23.0\r\nrequests-oauthlib==1.2.0\r\nresampy==0.2.2\r\nretrying==1.3.3\r\nrgf-python==3.8.0\r\nrope==0.16.0\r\nrsa==4.0\r\nRtree==0.9.4\r\nruamel-yaml==0.15.80\r\ns2sphere==0.2.5\r\ns3fs==0.4.2\r\ns3transfer==0.3.3\r\nsacred==0.8.1\r\nsacremoses==0.0.43\r\nscattertext==0.0.2.65\r\nscikit-image==0.16.2\r\nscikit-learn==0.23.1\r\nscikit-multilearn==0.2.0\r\nscikit-optimize==0.7.4\r\nscikit-plot==0.3.7\r\nscikit-surprise==1.1.0\r\nscipy==1.4.1\r\nscs==2.1.2\r\nseaborn==0.10.0\r\nSecretStorage==3.1.2\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsentry-sdk==0.15.1\r\nsetuptools-git==1.2\r\nshap==0.35.0\r\nShapely==1.7.0\r\nshortuuid==1.0.1\r\nsimplegeneric==0.8.1\r\nSimpleITK==1.2.4\r\nsimplejson==3.17.0\r\nsingledispatch==3.4.0.3\r\nsip==4.19.20\r\nsix==1.14.0\r\nsklearn==0.0\r\nsklearn-contrib-py-earth @ git+git://github.com/scikit-learn-contrib/py-earth.git@dde5f899255411a7b9cbbabf93a817eff4b02e5e\r\nsklearn-pandas==1.8.0\r\nsmart-open==2.0.0\r\nsmhasher==0.150.1\r\nsmmap==3.0.2\r\nsnowballstemmer==2.0.0\r\nsnuggs==1.4.7\r\nsortedcollections==1.1.2\r\nsortedcontainers==2.1.0\r\nSoundFile==0.10.3.post1\r\nsoupsieve==1.9.4\r\nspacy==2.2.4\r\nspectral==0.21\r\nSphinx==3.0.2\r\nsphinx-rtd-theme==0.2.4\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nsphinxcontrib-websupport==1.2.1\r\nspyder==4.1.2\r\nspyder-kernels==1.9.0\r\nSQLAlchemy==1.3.16\r\nsqlparse==0.3.1\r\nsquarify==0.4.3\r\nsrsly==1.0.2\r\nstatsmodels==0.11.1\r\nstemming==1.0.1\r\nstevedore==2.0.0\r\nstop-words==2018.7.23\r\nstopit==1.1.2\r\nsubprocess32==3.5.4\r\nsvgwrite==1.4\r\nsympy==1.5.1\r\ntables==3.6.1\r\ntabulate==0.8.7\r\ntangled-up-in-unicode==0.0.4\r\ntblib==1.6.0\r\ntenacity==6.1.0\r\ntensorboard==2.2.2\r\ntensorboard-plugin-wit==1.6.0.post3\r\ntensorboardX==2.0\r\ntensorflow @ file:///tmp/tensorflow_cpu/tensorflow-2.2.0-cp37-cp37m-linux_x86_64.whl\r\ntensorflow-addons @ file:///tmp/tfa_cpu/tensorflow_addons-0.10.0-cp37-cp37m-linux_x86_64.whl\r\ntensorflow-datasets==3.1.0\r\ntensorflow-estimator==2.2.0\r\ntensorflow-gcs-config @ file:///tmp/tensorflow_gcs_config/tensorflow_gcs_config-2.1.7-py3-none-any.whl\r\ntensorflow-hub==0.8.0\r\ntensorflow-metadata==0.22.2\r\ntensorflow-probability==0.10.0\r\nTensorforce==0.5.5\r\ntensorpack==0.10.1\r\ntermcolor==1.1.0\r\nterminado==0.8.3\r\nterminalplot==0.3.0\r\nterminaltables==3.1.0\r\ntestpath==0.4.4\r\ntext-unidecode==1.3\r\ntextblob==0.15.3\r\ntexttable==1.6.2\r\ntextwrap3==0.9.2\r\nTheano==1.0.4\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntifffile==2020.6.3\r\ntinycss2==1.0.2\r\ntokenizers==0.7.0\r\ntoml==0.10.0\r\ntoolz==0.10.0\r\ntorch==1.5.0\r\ntorchaudio==0.5.0a0+738ccba\r\ntorchtext==0.6.0\r\ntorchvision==0.6.0a0+35d732a\r\ntornado==5.0.2\r\nTPOT==0.11.5\r\ntqdm==4.45.0\r\ntraitlets==4.3.3\r\ntraittypes==0.2.1\r\ntransformers==2.11.0\r\ntrueskill==0.4.5\r\ntsfresh==0.16.0\r\ntyped-ast==1.4.1\r\ntypeguard==2.9.1\r\ntyping==3.7.4.1\r\ntyping-extensions==3.7.4.1\r\ntzlocal==2.1\r\nujson==1.35\r\numap-learn @ https://api.github.com/repos/lmcinnes/umap/tarball/5f9488a9540d1e0ac149e2dd42ebf03c39706110\r\nunicodecsv==0.14.1\r\nUnidecode==1.1.1\r\nupdate-checker==0.17\r\nuritemplate==3.0.1\r\nurllib3==1.24.3\r\nurwid==2.1.0\r\nvecstack==0.4.0\r\nvisions==0.4.1\r\nvowpalwabbit==8.8.1\r\nvtk==8.1.2\r\nWand==0.5.3\r\nwandb==0.9.1\r\nwasabi==0.6.0\r\nwatchdog==0.10.2\r\nwavio==0.0.4\r\nwcwidth==0.1.9\r\nwebencodings==0.5.1\r\nwebsocket-client==0.57.0\r\nWerkzeug==1.0.1\r\nwfdb==3.0.1\r\nwhichcraft==0.6.1\r\nwidgetsnbextension==3.5.1\r\nWordbatch==1.4.6\r\nwordcloud==1.7.0\r\nwordsegment==1.3.1\r\nwrapt==1.11.2\r\nwurlitzer==2.0.0\r\nxarray==0.15.1\r\nxgboost==1.1.1\r\nxlrd==1.2.0\r\nXlsxWriter==1.2.8\r\nxlwt==1.3.0\r\nxvfbwrapper==0.2.9\r\nyapf==0.29.0\r\nyarl==1.4.2\r\nyellowbrick==1.1\r\nzict==2.0.0\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp.models.archival import load_archive\r\narchive = load_archive(<insert-model-path>)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4431/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4431/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4429", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4429/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4429/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4429/events", "html_url": "https://github.com/allenai/allennlp/issues/4429", "id": 648797463, "node_id": "MDU6SXNzdWU2NDg3OTc0NjM=", "number": 4429, "title": "allowed_start_transitions and allowed_end_transitions don't actually enforce their constraints", "user": {"login": "zhuango", "id": 5491519, "node_id": "MDQ6VXNlcjU0OTE1MTk=", "avatar_url": "https://avatars.githubusercontent.com/u/5491519?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhuango", "html_url": "https://github.com/zhuango", "followers_url": "https://api.github.com/users/zhuango/followers", "following_url": "https://api.github.com/users/zhuango/following{/other_user}", "gists_url": "https://api.github.com/users/zhuango/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhuango/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhuango/subscriptions", "organizations_url": "https://api.github.com/users/zhuango/orgs", "repos_url": "https://api.github.com/users/zhuango/repos", "events_url": "https://api.github.com/users/zhuango/events{/privacy}", "received_events_url": "https://api.github.com/users/zhuango/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-07-01T08:52:50Z", "updated_at": "2020-07-02T11:30:57Z", "closed_at": "2020-07-02T11:05:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "I working on a project that uses [viterbi_decode ](https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py#L403) function in allennlp.nn.util. viterbi_decode function has _allowed_start_transitions_/_allowed_end_transitions_ parameters, which aim to enable viterbi decoding process to take the start/end timestep restriction into account. But how it works confuses me.\r\n\r\nFollows are what I learned from viterbi_decode code. _path_score_ is initialized with tag_sequence[0] which is a zero vector when _has_start_end_restrictions_ is true. When calculating the _score_ for the first time step through a topk op on _path_score_ + _transition_matrix_, the state of previous timestep (_paths_) is depend on _transition_matrix_ and not restricted on \"start\". \r\n\r\nFor an extreme case, the first timestep cannot be any state and _allowed_start_transitions_ are all -inf. Normally, the _score_ of the first timestep is -inf vector because no state is allowed at first timestep. But topk op on _path_score_ + _transition_matrix_  could still get non-inf _score_ and non-start _paths_of previous time step. Because there are potentials bigger than -inf and those corresponding previous states will be append to _paths_ which is not \"start\" state. The _allowed_start_transitions_ is not working ?\r\nSo it confuses me. Please help me to understand how does the _allowed_start_transitions_/_allowed_end_transitions_  actually work.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4429/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4429/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4428", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4428/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4428/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4428/events", "html_url": "https://github.com/allenai/allennlp/issues/4428", "id": 648766247, "node_id": "MDU6SXNzdWU2NDg3NjYyNDc=", "number": 4428, "title": "ModuleNotFoundError when num_workers>0 & DistributeDataParallel & lazy read", "user": {"login": "AutoTemp", "id": 17263752, "node_id": "MDQ6VXNlcjE3MjYzNzUy", "avatar_url": "https://avatars.githubusercontent.com/u/17263752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AutoTemp", "html_url": "https://github.com/AutoTemp", "followers_url": "https://api.github.com/users/AutoTemp/followers", "following_url": "https://api.github.com/users/AutoTemp/following{/other_user}", "gists_url": "https://api.github.com/users/AutoTemp/gists{/gist_id}", "starred_url": "https://api.github.com/users/AutoTemp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AutoTemp/subscriptions", "organizations_url": "https://api.github.com/users/AutoTemp/orgs", "repos_url": "https://api.github.com/users/AutoTemp/repos", "events_url": "https://api.github.com/users/AutoTemp/events{/privacy}", "received_events_url": "https://api.github.com/users/AutoTemp/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-07-01T08:06:24Z", "updated_at": "2020-09-08T20:38:19Z", "closed_at": "2020-09-08T20:38:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nWhen num_workers>0, DistributeDataParallel and lazy read, allennlp report ModuleNotFoundError.\r\n('my_text_classifier' is include-package)\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/xxx/anaconda3/envs/allennlp1.0/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\r\n    exitcode = _main(fd)\r\n  File \"/home/xxx/anaconda3/envs/allennlp1.0/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\r\n    self = reduction.pickle.load(from_parent)\r\nModuleNotFoundError: No module named 'my_text_classifier'\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/xxx/anaconda3/envs/allennlp1.0/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\r\n    exitcode = _main(fd)\r\n  File \"/home/xxx/anaconda3/envs/allennlp1.0/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\r\n    self = reduction.pickle.load(from_parent)\r\nModuleNotFoundError: No module named 'my_text_classifier'\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- #3924\r\n(ModuleNotFoundError also mentioned in the issue but the solution does not work)\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.0\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nrsa==3.4.2\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.20.0\r\nscipy==1.5.0\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.1.9\r\nsqlparse==0.3.1\r\nsrsly==1.0.2\r\ntensorboardX==2.0\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\nthinc==7.0.8\r\ntokenizers==0.7.0\r\ntorch==1.5.1\r\ntqdm==4.47.0\r\ntransformers==2.11.0\r\nUnidecode==1.1.1\r\nurllib3==1.25.9\r\nwasabi==0.6.0\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n1. use the example in [allennlp-guide-examples/quick_start](https://github.com/allenai/allennlp-guide-examples/tree/master/quick_start)\r\n2. In 'my_text_classifier.jsonnet', set lazy=true in reader, add distributed info, and set num_workers=2 in data_loader\r\n(details are as follow)\r\n3. run \"allennlp train my_text_classifier.jsonnet -s demo --include-package my_text_classifier\"\r\n\r\nwhen remove --include-package and turn into .allennlp_plugins (with one line: my_text_classifier)\r\nalso same error\r\n\r\nremove any of num_workers>0 & DistributeDataParallel & lazy read, the project is ok.\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nallennlp train my_text_classifier.jsonnet -s demo --include-package my_text_classifier\r\n(also error when use .allennlp_plugins)\r\n\r\nmy_text_classifier.jsonnet:\r\n\r\n{\r\n    \"dataset_reader\" : {\r\n        \"type\": \"classification-tsv\",\r\n        \"token_indexers\": {\r\n            \"tokens\": {\r\n                \"type\": \"single_id\"\r\n            }\r\n        },\r\n        \"lazy\": true\r\n    },\r\n    \"train_data_path\": \"data/movie_review/train.tsv\",\r\n    \"validation_data_path\": \"data/movie_review/dev.tsv\",\r\n    \"model\": {\r\n        \"type\": \"simple_classifier\",\r\n        \"embedder\": {\r\n            \"token_embedders\": {\r\n                \"tokens\": {\r\n                    \"type\": \"embedding\",\r\n                    \"embedding_dim\": 10\r\n                }\r\n            }\r\n        },\r\n        \"encoder\": {\r\n            \"type\": \"bag_of_embeddings\",\r\n            \"embedding_dim\": 10\r\n        }\r\n    },\r\n    \"data_loader\": {\r\n        \"batch_size\": 8,\r\n        \"num_workers\": 2\r\n\r\n    },\r\n    \"trainer\": {\r\n        \"optimizer\": \"adam\",\r\n        \"num_epochs\": 5\r\n    },\r\n    \"distributed\":{\r\n        \"cuda_devices\": [0,2],\r\n        \"num_nodes\": 1\r\n    }\r\n}\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4428/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4428/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4427", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4427/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4427/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4427/events", "html_url": "https://github.com/allenai/allennlp/issues/4427", "id": 648712712, "node_id": "MDU6SXNzdWU2NDg3MTI3MTI=", "number": 4427, "title": "PretrainedModelInitializer fails to initialize a model with a 0-dim tensor", "user": {"login": "reiyw", "id": 12150295, "node_id": "MDQ6VXNlcjEyMTUwMjk1", "avatar_url": "https://avatars.githubusercontent.com/u/12150295?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reiyw", "html_url": "https://github.com/reiyw", "followers_url": "https://api.github.com/users/reiyw/followers", "following_url": "https://api.github.com/users/reiyw/following{/other_user}", "gists_url": "https://api.github.com/users/reiyw/gists{/gist_id}", "starred_url": "https://api.github.com/users/reiyw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reiyw/subscriptions", "organizations_url": "https://api.github.com/users/reiyw/orgs", "repos_url": "https://api.github.com/users/reiyw/repos", "events_url": "https://api.github.com/users/reiyw/events{/privacy}", "received_events_url": "https://api.github.com/users/reiyw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-01T06:31:01Z", "updated_at": "2020-07-06T14:15:50Z", "closed_at": "2020-07-06T14:15:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 27, in <module>\r\n    applicator(net)\r\n  File \"/Users/reiyw/.ghq/ghq/github.com/allenai/allennlp/allennlp/nn/initializers.py\", line 482, in __call__\r\n    initializer(parameter, parameter_name=name)\r\n  File \"/Users/reiyw/.ghq/ghq/github.com/allenai/allennlp/allennlp/nn/initializers.py\", line 406, in __call__\r\n    tensor.data[:] = source_weights[:]\r\nIndexError: slice() cannot be applied to a 0-dim tensor.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n`PretrainedModelInitializer` fails to initialize a model with 0-dim tensors. The error occurs at:\r\nhttps://github.com/allenai/allennlp/blob/637dbb159082999c546ac2fc64746b88e5c9d1b5/allennlp/nn/initializers.py#L405-L406\r\nThe cause is that slicing cannot be applied to a 0-dim tensor. Instead of slicing a tensor here, we can avoid the error by using `copy_` method:\r\n```\r\ntensor.data.copy_(source_weights.data)\r\n```\r\nI have confirmed that this change will not break the pretrained model initializer test.\r\n\r\nAnother workaround is to use a 1-dim tensor instead of a 0-dim tensor to represent a scalar, but I think it's better to fix it so that others don't face the same problem.\r\n\r\nIf that change is appropriate, I would be happy to submit a PR.\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: OS X\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n-e git+ssh://git@github.com/allenai/allennlp.git@9c4dfa544e85e00d636beb0026a08e40dcdb6404#egg=allennlp\r\napex @ git+https://github.com/NVIDIA/apex.git@44532b30a4fad442f00635a0f4c8f241b06c2315\r\nappdirs==1.4.4\r\nattrs==19.3.0\r\nblack==19.10b0\r\nbleach==3.1.5\r\nblis==0.4.1\r\nboto3==1.14.12\r\nbotocore==1.17.12\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncodecov==2.1.7\r\ncolorama==0.4.3\r\ncoverage==5.1\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ndocutils==0.15.2\r\nfilelock==3.0.12\r\nflake8==3.8.3\r\nflaky==3.6.1\r\nfuture==0.18.2\r\nh5py==2.10.0\r\nidna==2.10\r\nimportlib-metadata==1.7.0\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.15.1\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\nkeyring==21.2.1\r\nkiwisolver==1.2.0\r\nlivereload==2.6.2\r\nlunr==0.5.8\r\nMarkdown==3.2.2\r\nmarkdown-include==0.5.1\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.2.2\r\nmccabe==0.6.1\r\nmkdocs==1.1.2\r\nmkdocs-material==5.3.3\r\nmkdocs-material-extensions==1.0\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nmypy==0.782\r\nmypy-extensions==0.4.3\r\nnltk==3.5\r\nnr.collections==0.0.1\r\nnr.databind.core==0.0.16\r\nnr.databind.json==0.0.11\r\nnr.interface==0.0.3\r\nnr.metaclass==0.0.5\r\nnr.parsing.date==0.1.0\r\nnr.pylang.utils==0.0.3\r\nnr.stream==0.0.4\r\nnumpy==1.19.0\r\noverrides==3.1.0\r\npackaging==20.4\r\npathspec==0.8.0\r\npathtools==0.1.2\r\npkginfo==1.5.0.1\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprotobuf==3.12.2\r\npy==1.9.0\r\npy-cpuinfo==6.0.0\r\npycodestyle==2.6.0\r\npyflakes==2.2.0\r\nPygments==2.6.1\r\npymdown-extensions==7.1\r\npyparsing==2.4.7\r\npytest==5.4.3\r\npytest-benchmark==3.2.3\r\npytest-cov==2.10.0\r\npython-dateutil==2.8.1\r\nPyYAML==5.3.1\r\nreadme-renderer==26.0\r\nregex==2020.6.8\r\nrequests==2.24.0\r\nrequests-toolbelt==0.9.1\r\nresponses==0.10.15\r\nrfc3986==1.4.0\r\nruamel.yaml==0.16.10\r\nruamel.yaml.clib==0.2.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.5.0\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.3.0\r\nsrsly==1.0.2\r\ntensorboardX==2.0\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.7.0\r\ntoml==0.10.1\r\ntorch==1.5.1\r\ntornado==6.0.4\r\ntqdm==4.47.0\r\ntransformers==2.11.0\r\ntwine==3.2.0\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.2\r\nurllib3==1.25.9\r\nwasabi==0.7.0\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nimport tempfile\r\nimport pathlib\r\n\r\nimport torch\r\n\r\nfrom allennlp.nn import InitializerApplicator\r\nfrom allennlp.nn.initializers import PretrainedModelInitializer\r\n\r\n\r\nclass Net(torch.nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        # 0-dim tensor\r\n        self.scalar = torch.nn.Parameter(torch.tensor(1.0))\r\n\r\n\r\nnet = Net()\r\ntemp_dir = pathlib.Path(tempfile.mkdtemp())\r\nweights_file = temp_dir / \"weights.th\"\r\ntorch.save(net.state_dict(), weights_file)\r\n\r\ninitializer = PretrainedModelInitializer(weights_file)\r\napplicator = InitializerApplicator([(\"scalar\", initializer)])\r\napplicator(net)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4427/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4427/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4419", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4419/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4419/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4419/events", "html_url": "https://github.com/allenai/allennlp/issues/4419", "id": 648012359, "node_id": "MDU6SXNzdWU2NDgwMTIzNTk=", "number": 4419, "title": "QANet in allennlp-models still used the old version of regularizer", "user": {"login": "pengshuang", "id": 11802795, "node_id": "MDQ6VXNlcjExODAyNzk1", "avatar_url": "https://avatars.githubusercontent.com/u/11802795?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pengshuang", "html_url": "https://github.com/pengshuang", "followers_url": "https://api.github.com/users/pengshuang/followers", "following_url": "https://api.github.com/users/pengshuang/following{/other_user}", "gists_url": "https://api.github.com/users/pengshuang/gists{/gist_id}", "starred_url": "https://api.github.com/users/pengshuang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pengshuang/subscriptions", "organizations_url": "https://api.github.com/users/pengshuang/orgs", "repos_url": "https://api.github.com/users/pengshuang/repos", "events_url": "https://api.github.com/users/pengshuang/events{/privacy}", "received_events_url": "https://api.github.com/users/pengshuang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "02b8d1", "default": false, "description": ""}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-30T09:17:59Z", "updated_at": "2020-07-01T03:36:11Z", "closed_at": "2020-07-01T03:36:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "As the ``Upgrade guide from v0.9.0`` said:\r\n\r\nRegularization now needs another key in a config file. Instead of specifying regularization as ``\"regularizer\": [[regex1, regularizer_params], [regex2, regularizer_params]]``, it now must be specified as \"regularizer\": ``{\"regexes\": [[regex1, regularizer_params], [regex2, regularizer_params]]}``(https://github.com/allenai/allennlp/releases/tag/v1.0.0).\r\n\r\nBut I find that the training_config of qanet still used the old version of ``regularizer``\r\n\r\nsee:\r\nhttps://github.com/allenai/allennlp-models/blob/37136f8ecbc42d26d9b135d06e4042f22d0d1bee/training_config/rc/qanet.jsonnet#L114.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4419/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4419/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4418", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4418/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4418/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4418/events", "html_url": "https://github.com/allenai/allennlp/issues/4418", "id": 647891680, "node_id": "MDU6SXNzdWU2NDc4OTE2ODA=", "number": 4418, "title": "AugmentedLSTM not working", "user": {"login": "harshnarang8", "id": 14851135, "node_id": "MDQ6VXNlcjE0ODUxMTM1", "avatar_url": "https://avatars.githubusercontent.com/u/14851135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshnarang8", "html_url": "https://github.com/harshnarang8", "followers_url": "https://api.github.com/users/harshnarang8/followers", "following_url": "https://api.github.com/users/harshnarang8/following{/other_user}", "gists_url": "https://api.github.com/users/harshnarang8/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshnarang8/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshnarang8/subscriptions", "organizations_url": "https://api.github.com/users/harshnarang8/orgs", "repos_url": "https://api.github.com/users/harshnarang8/repos", "events_url": "https://api.github.com/users/harshnarang8/events{/privacy}", "received_events_url": "https://api.github.com/users/harshnarang8/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "02b8d1", "default": false, "description": ""}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-30T06:07:48Z", "updated_at": "2021-04-02T01:51:57Z", "closed_at": "2021-04-02T01:51:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nThe AugmentedLSTM class from the pytorch_seq2vec_wrapper module doesn't work, and gives the error as below. This is probably due to the hidden_size argument being assigned to a different variable in the class, namely lstm_dim, in the allennlp/modules/augmented_lstm.py file. \r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/harshn/anaconda3/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/commands/train.py\", line 112, in train_model_from_args\r\n    dry_run=args.dry_run,\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/commands/train.py\", line 171, in train_model_from_file\r\n    dry_run=dry_run,\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/commands/train.py\", line 230, in train_model\r\n    dry_run=dry_run,\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/commands/train.py\", line 418, in _train_worker\r\n    params=params, serialization_dir=serialization_dir, local_rank=process_rank,\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 611, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/commands/train.py\", line 627, in from_partial_objects\r\n    model_ = model.construct(vocab=vocabulary_)\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/common/lazy.py\", line 46, in construct\r\n    return self._constructor(**kwargs)\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 446, in constructor\r\n    return value_cls.from_params(params=deepcopy(popped_params), **constructor_extras)\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 611, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/home/harshn/thesis/allennlp_tests/models/base_classifier.py\", line 75, in __init__\r\n    self._classifier_input_dim = self._seq2vec_encoder.get_output_dim()\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py\", line 60, in get_output_dim\r\n    return self._module.hidden_size * (2 if is_bidirectional else 1)\r\n  File \"/home/harshn/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 594, in __getattr__\r\n    type(self).__name__, name))\r\nAttributeError: 'AugmentedLstm' object has no attribute 'hidden_size'\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\nUbuntu 18.04.4 on WSL\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n3.7.6\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalabaster==0.7.12\r\nallennlp==1.0.0rc5\r\nallennlp-models==1.0.0rc5\r\nanaconda-client==1.7.2\r\nanaconda-navigator==1.9.12\r\nanaconda-project==0.8.3\r\nargh==0.26.2\r\nasn1crypto==1.3.0\r\nastroid==2.3.3\r\nastropy==4.0\r\natomicwrites==1.3.0\r\nattrs==19.3.0\r\nautopep8==1.4.4\r\nBabel==2.8.0\r\nbackcall==0.1.0\r\nbackports.functools-lru-cache==1.6.1\r\nbackports.shutil-get-terminal-size==1.0.0\r\nbackports.tempfile==1.0\r\nbackports.weakref==1.0.post1\r\nbeautifulsoup4==4.8.2\r\nbitarray==1.2.1\r\nbkcharts==0.2\r\nbleach==3.1.0\r\nblis==0.2.4\r\nbokeh==1.4.0\r\nboto==2.49.0\r\nboto3==1.13.11\r\nbotocore==1.16.11\r\nBottleneck==1.3.2\r\ncertifi==2019.11.28\r\ncffi==1.14.0\r\nchardet==3.0.4\r\nClick==7.0\r\ncloudpickle==1.3.0\r\nclyent==1.2.2\r\ncolorama==0.4.3\r\nconda==4.8.2\r\nconda-build==3.18.11\r\nconda-package-handling==1.6.0\r\nconda-verify==3.4.2\r\nconllu==2.3.2\r\ncontextlib2==0.6.0.post1\r\ncryptography==2.8\r\ncycler==0.10.0\r\ncymem==2.0.3\r\nCython==0.29.15\r\ncytoolz==0.10.1\r\ndask==2.11.0\r\ndecorator==4.4.1\r\ndefusedxml==0.6.0\r\ndiff-match-patch==20181111\r\ndistributed==2.11.0\r\ndocutils==0.15.2\r\ndyNET==2.1\r\neditdistance==0.5.3\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz\r\nentrypoints==0.3\r\net-xmlfile==1.0.1\r\nfastcache==1.1.0\r\nfilelock==3.0.12\r\nflake8==3.7.9\r\nflaky==3.6.1\r\nFlask==1.1.1\r\nFlask-Cors==3.0.8\r\nfsspec==0.6.2\r\nftfy==5.7\r\nfuture==0.18.2\r\ngensim==3.8.3\r\ngevent==1.4.0\r\nglob2==0.7\r\ngmpy2==2.0.8\r\ngreenlet==0.4.15\r\nh5py==2.10.0\r\nHeapDict==1.0.1\r\nhtml5lib==1.0.1\r\nhypothesis==5.5.4\r\nidna==2.8\r\nimageio==2.6.1\r\nimagesize==1.2.0\r\nimportlib-metadata==1.5.0\r\nintervaltree==3.0.2\r\nipykernel==5.1.4\r\nipython==7.12.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njdcal==1.4.1\r\njedi==0.14.1\r\njeepney==0.4.2\r\nJinja2==2.11.1\r\njmespath==0.10.0\r\njoblib==0.14.1\r\njson5==0.9.1\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==5.3.4\r\njupyter-console==6.1.0\r\njupyter-core==4.6.1\r\njupyterlab==1.2.6\r\njupyterlab-server==1.0.6\r\nkenlm @ https://github.com/kpu/kenlm/archive/master.zip\r\nkeyring==21.1.0\r\nkiwisolver==1.1.0\r\nlazy-object-proxy==1.4.3\r\nlibarchive-c==2.8\r\nlief==0.9.0\r\nllvmlite==0.31.0\r\nlocket==0.2.0\r\nlxml==4.5.0\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.1.3\r\nmccabe==0.6.1\r\nmistune==0.8.4\r\nmkl-fft==1.0.15\r\nmkl-random==1.1.0\r\nmkl-service==2.3.0\r\nmock==4.0.1\r\nmore-itertools==8.2.0\r\nmpmath==1.1.0\r\nmsgpack==0.6.1\r\nmultipledispatch==0.6.0\r\nmurmurhash==1.0.2\r\nnavigator-updater==0.2.1\r\nnbconvert==5.6.1\r\nnbformat==5.0.4\r\nnetworkx==2.4\r\nnltk==3.4.5\r\nnose==1.3.7\r\nnotebook==6.0.3\r\nnumba==0.48.0\r\nnumexpr==2.7.1\r\nnumpy==1.18.4\r\nnumpydoc==0.9.2\r\noauthlib==3.1.0\r\nolefile==0.46\r\nopenpyxl==3.0.3\r\noverrides==3.0.0\r\npackaging==20.1\r\npandas==1.0.1\r\npandocfilters==1.4.2\r\nparsimonious==0.8.1\r\nparso==0.5.2\r\npartd==1.1.0\r\npath==13.1.0\r\npathlib2==2.3.5\r\npathtools==0.1.2\r\npatsy==0.5.1\r\npbr==2.1.0\r\npep8==1.7.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.0.0\r\npkginfo==1.5.0.1\r\nplac==0.9.6\r\npluggy==0.13.1\r\nply==3.11\r\npreshed==2.0.1\r\nprometheus-client==0.7.1\r\nprompt-toolkit==3.0.3\r\nprotobuf==3.12.1\r\npsutil==5.6.7\r\nptyprocess==0.6.0\r\npy==1.8.1\r\npy-rouge==1.1\r\npycodestyle==2.5.0\r\npycosat==0.6.3\r\npycparser==2.19\r\npycrypto==2.6.1\r\npycurl==7.43.0.5\r\npydocstyle==4.0.1\r\npyenchant==2.0.0\r\npyflakes==2.1.1\r\nPygments==2.5.2\r\npylint==2.4.4\r\npyodbc===4.0.0-unsupported\r\npyOpenSSL==19.1.0\r\npyparsing==2.4.6\r\npyrsistent==0.15.7\r\nPySocks==1.7.1\r\npytest==5.3.5\r\npytest-arraydiff==0.3\r\npytest-astropy==0.8.0\r\npytest-astropy-header==0.1.2\r\npytest-doctestplus==0.5.0\r\npytest-openfiles==0.4.0\r\npytest-remotedata==0.3.2\r\npython-dateutil==2.8.1\r\npython-jsonrpc-server==0.3.4\r\npython-language-server==0.31.7\r\npytorch-pretrained-bert==0.6.2\r\npytorch-transformers==1.1.0\r\npytz==2019.3\r\nPyWavelets==1.1.1\r\npyxdg==0.26\r\nPyYAML==5.3\r\npyzmq==18.1.1\r\nQDarkStyle==2.8\r\nQtAwesome==0.6.1\r\nqtconsole==4.6.0\r\nQtPy==1.9.0\r\nregex==2020.5.14\r\nrequests==2.22.0\r\nrequests-oauthlib==1.3.0\r\nresponses==0.10.14\r\nrope==0.16.0\r\nRtree==0.9.3\r\nruamel-yaml==0.15.87\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-image==0.16.2\r\nscikit-learn==0.22.1\r\nscipy==1.4.1\r\nseaborn==0.10.0\r\nSecretStorage==3.1.2\r\nsemantic-version==2.8.5\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.90\r\nsimplegeneric==0.8.1\r\nsingledispatch==3.4.0.3\r\nsix==1.14.0\r\nsmart-open==2.0.0\r\nsnowballstemmer==2.0.0\r\nsortedcollections==1.1.2\r\nsortedcontainers==2.1.0\r\nsoupsieve==1.9.5\r\nspacy==2.1.9\r\nSphinx==2.4.0\r\nsphinxcontrib-applehelp==1.0.1\r\nsphinxcontrib-devhelp==1.0.1\r\nsphinxcontrib-htmlhelp==1.0.2\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.2\r\nsphinxcontrib-serializinghtml==1.1.3\r\nsphinxcontrib-websupport==1.2.0\r\nspyder==4.0.1\r\nspyder-kernels==1.8.1\r\nSQLAlchemy==1.3.13\r\nsqlparse==0.3.1\r\nsrsly==1.0.2\r\nstatsmodels==0.11.0\r\nsympy==1.5.1\r\ntables==3.6.1\r\ntblib==1.6.0\r\ntensorboardX==2.0\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\nthinc==7.0.8\r\ntokenizers==0.7.0\r\ntoolz==0.10.0\r\ntorch==1.5.0\r\ntorchtext==0.6.0\r\ntornado==6.0.3\r\ntqdm==4.42.1\r\ntraitlets==4.3.3\r\ntransformers==2.9.1\r\ntweepy==3.8.0\r\nujson==1.35\r\nunicodecsv==0.14.1\r\nUnidecode==1.1.1\r\nurllib3==1.25.8\r\nwasabi==0.6.0\r\nwatchdog==0.10.2\r\nwcwidth==0.1.8\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.0\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nwrapt==1.11.2\r\nwurlitzer==2.0.0\r\nwxconv @ https://www.github.com/irshadbhat/indic-wx-converter/archive/master.zip\r\nxlrd==1.2.0\r\nXlsxWriter==1.2.7\r\nxlwt==1.3.0\r\nxmltodict==0.12.0\r\nyapf==0.28.0\r\nzict==1.0.0\r\nzipp==2.2.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\nRun the following code, with a temp_training.txt and temp_validation.txt file, with random examples of the format:\r\nThe fox jumped over the fence 1\r\nThe dog is cute 0\r\n\r\nNote that the code is quite similar to, and inspired from, the tutorial present on the allennlp.org website.\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom typing import Iterator, List, Dict\r\n\r\nimport torch\r\nimport torch.optim as optim\r\nimport numpy as np\r\n\r\nfrom allennlp.data import Instance\r\nfrom allennlp.data.fields import TextField, LabelField\r\n\r\nfrom allennlp.data.dataset_readers import DatasetReader\r\n\r\nfrom allennlp.common.file_utils import cached_path\r\n\r\nfrom allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\r\nfrom allennlp.data.tokenizers import Token\r\n\r\nfrom allennlp.data.vocabulary import Vocabulary\r\n\r\nfrom allennlp.models import Model\r\n\r\nfrom allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\r\nfrom allennlp.modules.token_embedders import Embedding\r\nfrom allennlp.modules.seq2vec_encoders import Seq2VecEncoder\r\nfrom allennlp.modules.seq2vec_encoders.pytorch_seq2vec_wrapper import AugmentedLstmSeq2VecEncoder\r\nfrom allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\r\nfrom allennlp.nn import InitializerApplicator, util\r\n\r\nfrom allennlp.training.metrics import CategoricalAccuracy\r\n\r\n# from allennlp.data.iterators import BucketIterator\r\nfrom allennlp.data.dataloader import DataLoader\r\n\r\nfrom allennlp.training.trainer import Trainer\r\n\r\nfrom allennlp.predictors import SentenceTaggerPredictor\r\n\r\ntorch.manual_seed(1)\r\n\r\nclass PosDatasetReader(DatasetReader):\r\n    \"\"\"\r\n    DatasetReader for PoS tagging data, one sentence per line, like\r\n\r\n        The###DET dog###NN ate###V the###DET apple###NN\r\n    \"\"\"\r\n\r\n    def __init__(self, token_indexers: Dict[str, TokenIndexer] = None) -> None:\r\n        super().__init__(lazy=False)\r\n        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\r\n\r\n    def text_to_instance(self, tokens: List[Token], tag: int = None) -> Instance:\r\n        sentence_field = TextField(tokens, self.token_indexers)\r\n        fields = {\"sentence\": sentence_field}\r\n\r\n        if tag:\r\n            label_field = LabelField(label=tag)\r\n            fields[\"label\"] = label_field\r\n\r\n        return Instance(fields)\r\n\r\n    def _read(self, file_path: str) -> Iterator[Instance]:\r\n        with open(file_path) as f:\r\n            for line in f:\r\n                pairs = line.strip().split()\r\n                sentence = pairs[:-1]\r\n                tag = pairs[-1]\r\n                yield self.text_to_instance([Token(word) for word in sentence], tag)\r\n\r\nclass LstmTagger(Model):\r\n\r\n    def __init__(self,\r\n                 word_embeddings: TextFieldEmbedder,\r\n                 encoder: Seq2VecEncoder,\r\n                 vocab: Vocabulary) -> None:\r\n\r\n        super().__init__(vocab)\r\n        self.word_embeddings = word_embeddings\r\n        self.encoder = encoder\r\n\r\n        self.hidden2tag = torch.nn.Linear(in_features=encoder.get_output_dim(),\r\n                                          out_features=vocab.get_vocab_size('labels'))\r\n        self._classification_layer = torch.nn.Linear(self._classifier_input_dim, self._num_labels)\r\n        self._accuracy = CategoricalAccuracy()\r\n        self._loss = torch.nn.CrossEntropyLoss()\r\n        initializer(self)\r\n        self.accuracy = CategoricalAccuracy()\r\n\r\n    def forward(self,\r\n                sentence: Dict[str, torch.Tensor],\r\n                labels: torch.Tensor = None) -> Dict[str, torch.Tensor]:\r\n\r\n        mask = get_text_field_mask(sentence)\r\n\r\n        embeddings = self.word_embeddings(sentence)\r\n\r\n        encoder_out = self.encoder(embeddings, mask)\r\n\r\n        tag_logits = self._classification_layer(encoder_out)\r\n        \r\n        probs = torch.nn.functional.softmax(logits, dim=-1)\r\n        output_dict = {\"logits\": logits, \"probs\": probs}\r\n        output_dict[\"token_ids\"] = util.get_token_ids_from_text_field_tensors(sentence)\r\n        if label is not None:\r\n            loss = self._loss(logits, label.long().view(-1))\r\n            output_dict[\"loss\"] = loss\r\n            self._accuracy(logits, label)\r\n\r\n        return output_dict\r\n\r\n    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\r\n        return {\"accuracy\": self.accuracy.get_metric(reset)}\r\n\r\nreader = PosDatasetReader()\r\n\r\ntrain_dataset = reader.read(cached_path(\r\n    'temp_training.txt'))\r\nvalidation_dataset = reader.read(cached_path(\r\n    'temp_validation.txt'))\r\n\r\nvocab = Vocabulary.from_instances(train_dataset + validation_dataset)\r\n\r\nEMBEDDING_DIM = 6\r\nHIDDEN_DIM = 6\r\n\r\ntoken_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\r\n                            embedding_dim=EMBEDDING_DIM)\r\nword_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\r\n\r\nlstm = AugmentedLstmSeq2VecEncoder(EMBEDDING_DIM, HIDDEN_DIM)\r\n\r\nmodel = LstmTagger(word_embeddings, lstm, vocab)\r\n\r\nif torch.cuda.is_available():\r\n    cuda_device = 0\r\n\r\n    model = model.cuda(cuda_device)\r\nelse:\r\n\r\n    cuda_device = -1\r\n\r\noptimizer = optim.SGD(model.parameters(), lr=0.1)\r\n\r\n# iterator = BucketIterator(batch_size=2, sorting_keys=[(\"sentence\", \"num_tokens\")])\r\ndata_loader = DataLoader(train_dataset, batch_size=2)\r\nval_data_loader = DataLoader(validation_dataset, batch_size=2)\r\n\r\niterator.index_with(vocab)\r\n\r\n# trainer = Trainer(model=model,\r\n#                   optimizer=optimizer,\r\n#                   iterator=iterator,\r\n#                   train_dataset=train_dataset,\r\n#                   validation_dataset=validation_dataset,\r\n#                   patience=10,\r\n#                   num_epochs=1000,\r\n#                   cuda_device=cuda_device)\r\n\r\ntrainer = Trainer(model=model,\r\n                  optimizer=optimizer,\r\n                  data_loader=data_loader,\r\n                  validation_dataloader=val_data_loader,\r\n                  patience=10,\r\n                  num_epochs=1000,\r\n                  cuda_device=cuda_device)\r\n\r\ntrainer.train()\r\n\r\npredictor = SentenceTaggerPredictor(model, dataset_reader=reader)\r\n\r\ntag_logits = predictor.predict(\"The dog ate the apple\")['tag_logits']\r\n\r\ntag_ids = np.argmax(tag_logits, axis=-1)\r\n\r\nprint([model.vocab.get_token_from_index(i, 'labels') for i in tag_ids])\r\n\r\n# Here's how to save the model.\r\nwith open(\"/tmp/model.th\", 'wb') as f:\r\n    torch.save(model.state_dict(), f)\r\n\r\nvocab.save_to_files(\"/tmp/vocabulary\")\r\n\r\n# And here's how to reload the model.\r\nvocab2 = Vocabulary.from_files(\"/tmp/vocabulary\")\r\n\r\nmodel2 = LstmTagger(word_embeddings, lstm, vocab2)\r\n\r\nwith open(\"/tmp/model.th\", 'rb') as f:\r\n    model2.load_state_dict(torch.load(f))\r\n\r\nif cuda_device > -1:\r\n    model2.cuda(cuda_device)\r\n\r\npredictor2 = SentenceTaggerPredictor(model2, dataset_reader=reader)\r\ntag_logits2 = predictor2.predict(\"The dog ate the apple\")['tag_logits']\r\nnp.testing.assert_array_almost_equal(tag_logits2, tag_logits)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4418/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4418/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4399", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4399/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4399/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4399/events", "html_url": "https://github.com/allenai/allennlp/issues/4399", "id": 645065685, "node_id": "MDU6SXNzdWU2NDUwNjU2ODU=", "number": 4399, "title": "TypeError: can't pickle Tokenizer objects when num_workers > 0 and lazy = true", "user": {"login": "JohnGiorgi", "id": 8917831, "node_id": "MDQ6VXNlcjg5MTc4MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/8917831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JohnGiorgi", "html_url": "https://github.com/JohnGiorgi", "followers_url": "https://api.github.com/users/JohnGiorgi/followers", "following_url": "https://api.github.com/users/JohnGiorgi/following{/other_user}", "gists_url": "https://api.github.com/users/JohnGiorgi/gists{/gist_id}", "starred_url": "https://api.github.com/users/JohnGiorgi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JohnGiorgi/subscriptions", "organizations_url": "https://api.github.com/users/JohnGiorgi/orgs", "repos_url": "https://api.github.com/users/JohnGiorgi/repos", "events_url": "https://api.github.com/users/JohnGiorgi/events{/privacy}", "received_events_url": "https://api.github.com/users/JohnGiorgi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2020-06-25T00:47:30Z", "updated_at": "2020-06-25T19:54:21Z", "closed_at": "2020-06-25T19:54:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discourse forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [X] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [X] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [X] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [X] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [X] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [X] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [X] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [X] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [X] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [X] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nI get a `TypeError: can't pickle Tokenizer objects` when trying to train a model that uses a `PretrainedTransformerTokenizer` tokenizer when `\"dataset_reader.lazy\": true` and `\"data_loader.num_workers\" > 0`. This appears to happen for every version of AllenNLP _after_ 1.0.0rc3 (specifically [this commit](https://github.com/allenai/allennlp/commit/9766eb407e7d83a0bf2150ad054a7c8e2da4ae2b)) including the current master branch. The 1.0.0rc3 release and earlier releases do not have this issue.\r\n\r\nThe notes in #4344 seem to suggest it has been solved, but I can still trigger it with a minimal example (see below).\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/johnmg/t2t/bin/allennlp\", line 33, in <module>\r\n    sys.exit(load_entry_point('allennlp', 'console_scripts', 'allennlp')())\r\n  File \"/scratch/johnmg/allennlp/allennlp/__main__.py\", line 24, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/scratch/johnmg/allennlp/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/scratch/johnmg/allennlp/allennlp/commands/train.py\", line 112, in train_model_from_args\r\n    dry_run=args.dry_run,\r\n  File \"/scratch/johnmg/allennlp/allennlp/commands/train.py\", line 171, in train_model_from_file\r\n    dry_run=dry_run,\r\n  File \"/scratch/johnmg/allennlp/allennlp/commands/train.py\", line 295, in train_model\r\n    nprocs=num_procs,\r\n  File \"/home/johnmg/t2t/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 200, in spawn\r\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n  File \"/home/johnmg/t2t/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 158, in start_processes\r\n    while not context.join():\r\n  File \"/home/johnmg/t2t/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/home/johnmg/t2t/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/scratch/johnmg/allennlp/allennlp/commands/train.py\", line 418, in _train_worker\r\n    params=params, serialization_dir=serialization_dir, local_rank=process_rank,\r\n  File \"/scratch/johnmg/allennlp/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/scratch/johnmg/allennlp/allennlp/common/from_params.py\", line 611, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/scratch/johnmg/allennlp/allennlp/commands/train.py\", line 647, in from_partial_objects\r\n    data_loader_ = data_loader.construct(dataset=datasets[\"train\"])\r\n  File \"/scratch/johnmg/allennlp/allennlp/common/lazy.py\", line 46, in construct\r\n    return self._constructor(**kwargs)\r\n  File \"/scratch/johnmg/allennlp/allennlp/common/from_params.py\", line 446, in constructor\r\n    return value_cls.from_params(params=deepcopy(popped_params), **constructor_extras)\r\n  File \"/scratch/johnmg/allennlp/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/scratch/johnmg/allennlp/allennlp/common/from_params.py\", line 611, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/scratch/johnmg/allennlp/allennlp/data/dataloader.py\", line 151, in from_partial_objects\r\n    batches_per_epoch=batches_per_epoch,\r\n  File \"/scratch/johnmg/allennlp/allennlp/data/dataloader.py\", line 90, in __init__\r\n    self._data_generator = super().__iter__()\r\n  File \"/home/johnmg/t2t/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 279, in __iter__\r\n    return _MultiProcessingDataLoaderIter(self)\r\n  File \"/home/johnmg/t2t/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 719, in __init__\r\n    w.start()\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/process.py\", line 112, in start\r\n    self._popen = self._Popen(self)\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/context.py\", line 223, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/popen_fork.py\", line 20, in __init__\r\n    self._launch(process_obj)\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/popen_spawn_posix.py\", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nTypeError: can't pickle Tokenizer objects\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- #4344\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: \r\n\r\n```\r\nNAME=\"CentOS Linux\"\r\nVERSION=\"7 (Core)\"\r\nID=\"centos\"\r\nID_LIKE=\"rhel fedora\"\r\nVERSION_ID=\"7\"\r\nPRETTY_NAME=\"CentOS Linux 7 (Core)\"\r\nANSI_COLOR=\"0;31\"\r\nCPE_NAME=\"cpe:/o:centos:centos:7\"\r\nHOME_URL=\"https://www.centos.org/\"\r\nBUG_REPORT_URL=\"https://bugs.centos.org/\"\r\n\r\nCENTOS_MANTISBT_PROJECT=\"CentOS-7\"\r\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"\r\nREDHAT_SUPPORT_PRODUCT=\"centos\"\r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\r\n```\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.4\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.7.1\r\naiohttp==3.6.2\r\nalabaster==0.7.12\r\n-e git+https://github.com/allenai/allennlp.git@b6fd6978b507ce6118023e23f3e4dbfa334d39b5#egg=allennlp\r\napex==0.1\r\nappdirs==1.4.3\r\naspy.yaml==1.3.0\r\nastor==0.8.1\r\nasync-timeout==3.0.1\r\natomicwrites==1.3.0\r\nattrs==19.3.0\r\nBabel==2.7.0\r\nbackcall==0.1.0\r\nbeautifulsoup4==4.8.2\r\nblack==19.10b0\r\nbleach==3.1.0\r\nblis==0.2.4\r\nboto==2.49.0\r\nboto3==1.10.9\r\nbotocore==1.13.9\r\ncachetools==3.1.1\r\ncc-net==0.1.0\r\ncertifi==2019.9.11\r\ncffi==1.13.2\r\ncfgv==2.0.1\r\nchardet==3.0.4\r\nclick==7.1.1\r\ncodecov==2.0.15\r\nconllu==2.3.2\r\ncoverage==4.5.4\r\ncryptography==2.8\r\ncycler==0.10.0\r\ncymem==2.0.2\r\n-e git+https://github.com/JohnGiorgi/t2t.git@5cc03ed58253e12bd1060f1fea2b89bae3acdb84#egg=declutr\r\ndecorator==4.4.1\r\ndill==0.3.1.1\r\ndocutils==0.15.2\r\neditdistance==0.5.2\r\nen-core-web-sm==2.1.0\r\nentrypoints==0.3\r\nfastapi==0.58.0\r\nfasttext==0.9.1\r\nfilelock==3.0.12\r\nfire==0.2.1\r\nflake8==3.7.9\r\nflaky==3.6.1\r\nFlask==1.1.1\r\nFlask-Cors==3.0.8\r\nftfy==5.5.1\r\nfunc-argparse==1.1.1\r\nfuture==0.17.1\r\ngast==0.2.2\r\ngensim==3.8.1\r\ngetpy==0.9.9\r\ngevent==1.4.0\r\ngoogle-auth==1.11.0\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-pasta==0.1.8\r\ngreenlet==0.4.15\r\ngrpcio==1.25.0\r\nh11==0.9.0\r\nh5py==2.9.0\r\nhtmlmin==0.1.12\r\nhttptools==0.1.1\r\nhypothesis==5.16.0\r\nidentify==1.4.10\r\nidna==2.8\r\nimagesize==1.1.0\r\nimportlib-metadata==0.23\r\nipython==7.10.1\r\nipython-genutils==0.2.0\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njedi==0.15.1\r\njeepney==0.4.2\r\nJinja2==2.10.3\r\njmespath==0.9.4\r\njoblib==0.14.0\r\njsmin==2.2.2\r\njsonnet==0.10.0\r\njsonpickle==1.2\r\njsonschema==3.0.2\r\nkenlm==0.0.0\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.0\r\nkeyring==21.1.0\r\nkiwisolver==1.1.0\r\nlivereload==2.6.1\r\nlxml==4.4.1\r\nMarkdown==3.1.1\r\nmarkdown-include==0.5.1\r\nMarkupSafe==1.1.1\r\nmathy-pydoc==0.6.7\r\nmatplotlib==3.0.3\r\nmaturin==0.8.1\r\nmccabe==0.6.1\r\nmkdocs==1.0.4\r\nmkdocs-material==4.6.3\r\nmkdocs-minify-plugin==0.2.1\r\nmore-itertools==7.2.0\r\nmultidict==4.5.2\r\nmurmurhash==0.28.0\r\nmypy==0.770\r\nmypy-extensions==0.4.3\r\nnltk==3.4\r\nnodeenv==1.3.4\r\nnumpy==1.16.3\r\nnumpydoc==0.8.0\r\noauthlib==3.1.0\r\nopt-einsum==2.3.2\r\noverrides==3.1.0\r\npackaging==19.2\r\npandas==0.25.3\r\nparsimonious==0.8.0\r\nparso==0.5.1\r\npathspec==0.7.0\r\npep562==1.0\r\npexpect==4.7.0\r\npickleshare==0.7.5\r\nPillow==6.2.1\r\nPillow-SIMD==7.0.0.post3\r\npkginfo==1.5.0.1\r\nplac==0.9.6\r\npluggy==0.13.0\r\npre-commit==2.2.0\r\npreshed==2.0.1\r\nprompt-toolkit==3.0.2\r\nprotobuf==3.10.0\r\nptyprocess==0.6.0\r\npy==1.8.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npybind11==2.4.3\r\npycodestyle==2.5.0\r\npycparser==2.19\r\npydantic==1.5.1\r\npydoc-markdown==2.0.5\r\npyflakes==2.1.1\r\nPygments==2.4.2\r\npymdown-extensions==6.3\r\npyparsing==2.4.3\r\npyrsistent==0.15.3\r\npytest==5.2.2\r\npytest-cov==2.8.1\r\npython-dateutil==2.8.0\r\n-e git+https://github.com/KevinMusgrave/pytorch-metric-learning.git@48de2dd9c4d78873d675f19187c5205075a6a9de#egg=pytorch_metric_learning\r\npytz==2019.3\r\nPyYAML==5.1.2\r\n-e git+https://github.com/JohnGiorgi/QuickThought.git@397b8b18f3cc50a3471fe26f9725401fb2297816#egg=quickthought\r\nreadme-renderer==24.0\r\nregex==2018.1.10\r\nrequests==2.22.0\r\nrequests-oauthlib==1.3.0\r\nrequests-toolbelt==0.9.1\r\nresponses==0.10.6\r\nrsa==4.0\r\nruamel.yaml==0.16.5\r\nruamel.yaml.clib==0.2.0\r\ns3transfer==0.2.1\r\nsacremoses==0.0.35\r\nscikit-learn==0.21.2\r\nscipy==1.4.1\r\nSecretStorage==3.1.2\r\nsemantic-version==2.8.4\r\nsentence-splitter==1.4\r\nsentence-transformers==0.2.6.1\r\nsentencepiece==0.1.82\r\nsetuptools-rust==0.10.6\r\nsingledispatch==3.4.0.3\r\nsix==1.12.0\r\nsmart-open==1.8.4\r\nsnowballstemmer==2.0.0\r\nsortedcontainers==2.2.2\r\nsoupsieve==2.0\r\nspacy==2.1.4\r\nSphinx==2.2.1\r\nsphinxcontrib-applehelp==1.0.1\r\nsphinxcontrib-devhelp==1.0.1\r\nsphinxcontrib-htmlhelp==1.0.2\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.2\r\nsphinxcontrib-serializinghtml==1.1.3\r\nsqlparse==0.3.0\r\nsrsly==0.0.5\r\nstarlette==0.13.4\r\ntensorboard==1.15.0\r\ntensorboardX==1.9\r\ntensorflow-estimator==1.15.1\r\ntensorflow-gpu==1.15.0\r\ntensorflow-hub==0.8.0\r\ntermcolor==1.1.0\r\nTheano==1.0.1\r\nthinc==7.0.4\r\ntokenizers==0.7.0\r\ntoml==0.10.0\r\ntorch==1.5.0\r\ntorchvision==0.6.0+cu101\r\ntornado==6.0.3\r\ntqdm==4.37.0\r\ntraitlets==4.3.3\r\ntransformers==2.11.0\r\ntwine==3.1.1\r\ntyped-ast==1.4.1\r\ntyper==0.2.1\r\ntyping-extensions==3.7.4.1\r\nUnidecode==1.1.1\r\nurllib3==1.25.6\r\nuvicorn==0.11.5\r\nuvloop==0.14.0\r\nvirtualenv==16.7.9\r\nwasabi==0.4.0\r\nwcwidth==0.1.7\r\nwebencodings==0.5.1\r\nwebsockets==8.1\r\nWerkzeug==0.16.0\r\nword2number==1.1\r\nwrapt==1.11.2\r\nyarl==1.4.2\r\nzipp==0.6.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n1. Install a version of AllenNLP and AllenNLP-Models _newer_ than 1.0.0rc3.\r\n2. Train a model which uses a `PretrainedTransformerTokenizer` with `\"dataset_reader.lazy\": true` and `\"data_loader.num_workers\" > 0`. E.g. I used [this config](https://github.com/allenai/allennlp-models/blob/master/training_config/pair_classification/mnli_roberta.jsonnet) with some overrides (see below).\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n \r\n```bash\r\nallennlp train mnli_roberta.jsonnet \\\r\n\t--serialization-dir ./debug \\\r\n        --overrides \"{'dataset_reader.lazy': true, 'data_loader.batch_sampler': null, 'data_loader.num_workers': 1}\" \\\r\n\t-f\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4399/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4399/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4393", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4393/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4393/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4393/events", "html_url": "https://github.com/allenai/allennlp/issues/4393", "id": 643187853, "node_id": "MDU6SXNzdWU2NDMxODc4NTM=", "number": 4393, "title": "Unexpected behavior with DataLoader.batches_per_epoch", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-06-22T15:56:43Z", "updated_at": "2020-07-06T15:26:20Z", "closed_at": "2020-06-25T11:54:54Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "From the discussion in https://github.com/allenai/allennlp/issues/4362.\r\n\r\nIf `batches_per_epochs` is less than the total number of batches in the dataset, there is no guarantee that all unique instances will be seen during training.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4393/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4393/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4392", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4392/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4392/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4392/events", "html_url": "https://github.com/allenai/allennlp/issues/4392", "id": 643109965, "node_id": "MDU6SXNzdWU2NDMxMDk5NjU=", "number": 4392, "title": "Can't reproduce SRL result with allennlp==1.0.0", "user": {"login": "edchengg", "id": 20430102, "node_id": "MDQ6VXNlcjIwNDMwMTAy", "avatar_url": "https://avatars.githubusercontent.com/u/20430102?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edchengg", "html_url": "https://github.com/edchengg", "followers_url": "https://api.github.com/users/edchengg/followers", "following_url": "https://api.github.com/users/edchengg/following{/other_user}", "gists_url": "https://api.github.com/users/edchengg/gists{/gist_id}", "starred_url": "https://api.github.com/users/edchengg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edchengg/subscriptions", "organizations_url": "https://api.github.com/users/edchengg/orgs", "repos_url": "https://api.github.com/users/edchengg/repos", "events_url": "https://api.github.com/users/edchengg/events{/privacy}", "received_events_url": "https://api.github.com/users/edchengg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/11", "html_url": "https://github.com/allenai/allennlp/milestone/11", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/11/labels", "id": 5183675, "node_id": "MDk6TWlsZXN0b25lNTE4MzY3NQ==", "number": 11, "title": "1.1", "description": "A placeholder for work we'd like to do after the 1.0 release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 23, "state": "closed", "created_at": "2020-03-09T17:46:04Z", "updated_at": "2020-09-10T20:00:22Z", "due_on": null, "closed_at": "2020-09-10T20:00:22Z"}, "comments": 5, "created_at": "2020-06-22T14:17:30Z", "updated_at": "2020-09-03T23:27:40Z", "closed_at": "2020-09-03T23:27:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "System (please complete the following information):\r\n\r\nOS: Ubuntu 18.04.3 LTS\r\nPython version: 3.7\r\nAllenNLP version: v1.0.0\r\nPyTorch version: 1.5\r\nAllennlp-models: v1.0.0\r\n\r\nQuestion\r\nHi @DeNeutoy , I try to reproduce the results on the OntoNotes dataset (conll 2012) in the Shi et al., 2019 paper used in the SRL demo. However, I could only get F1 around 0.79.\r\n\r\nCommand I used:\r\n```\r\nallennlp evaluate https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz /data/conll-formatted-ontonotes-5.0/conll-formatted-ontonotes-5.0-12/conll-formatted-ontonotes-5.0/data/conll-2012-test/data/english\r\n```\r\n\r\nI also tried to train the model with config file in allennlp-models but only get to F1=79.\r\n\r\n\r\nI found a related issue #4220 and was able to reproduce the result (86.5) with allennlp==0.9 and an old checkpoint https://s3-us-west-2.amazonaws.com/allennlp/models/bert-base-srl-2019.06.17.tar.gz. But I guess it might be worth reporting the issue since 1.0 is a stable version now. \r\n\r\n\r\nAny help would be appreciated!\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4392/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4392/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4388", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4388/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4388/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4388/events", "html_url": "https://github.com/allenai/allennlp/issues/4388", "id": 643059760, "node_id": "MDU6SXNzdWU2NDMwNTk3NjA=", "number": 4388, "title": "SRL predictor misses Auxiliary verb", "user": {"login": "deanyan7", "id": 30431964, "node_id": "MDQ6VXNlcjMwNDMxOTY0", "avatar_url": "https://avatars.githubusercontent.com/u/30431964?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deanyan7", "html_url": "https://github.com/deanyan7", "followers_url": "https://api.github.com/users/deanyan7/followers", "following_url": "https://api.github.com/users/deanyan7/following{/other_user}", "gists_url": "https://api.github.com/users/deanyan7/gists{/gist_id}", "starred_url": "https://api.github.com/users/deanyan7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deanyan7/subscriptions", "organizations_url": "https://api.github.com/users/deanyan7/orgs", "repos_url": "https://api.github.com/users/deanyan7/repos", "events_url": "https://api.github.com/users/deanyan7/events{/privacy}", "received_events_url": "https://api.github.com/users/deanyan7/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-22T13:11:27Z", "updated_at": "2020-06-29T17:15:57Z", "closed_at": "2020-06-26T16:13:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "System (please complete the following information):\r\n\r\nOS: Linux\r\nPython version: 3.6.9\r\nAllenNLP version: 1.0.0\r\nPyTorch version: 1.5.0\r\n\r\nWhen I used the SRL model to predict sentences, \r\nThe inputs is \u201cThe new rights are nice enough.\u201d\r\n\r\nThe result is:\r\n[{'verbs': [], 'words': ['The', 'new', 'rights', 'are', 'nice', 'enough']}]\r\n\r\nThe Correct  result is\uff1a\r\n[{\"verbs\": [{\"verb\": \"are\", \"description\": \"[ARG1: The new rights] [V: are] [ARG2: nice enough]\", \"tags\": [\"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"B-V\", \"B-ARG2\", \"I-ARG2\"]}]\r\n\r\n\r\nHow can I fix it?  Thank you!\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4388/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4388/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4384", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4384/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4384/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4384/events", "html_url": "https://github.com/allenai/allennlp/issues/4384", "id": 642079473, "node_id": "MDU6SXNzdWU2NDIwNzk0NzM=", "number": 4384, "title": "allennlp.commands.elmo doesn't exists anymore", "user": {"login": "Dastgheyb", "id": 5506911, "node_id": "MDQ6VXNlcjU1MDY5MTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5506911?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dastgheyb", "html_url": "https://github.com/Dastgheyb", "followers_url": "https://api.github.com/users/Dastgheyb/followers", "following_url": "https://api.github.com/users/Dastgheyb/following{/other_user}", "gists_url": "https://api.github.com/users/Dastgheyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dastgheyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dastgheyb/subscriptions", "organizations_url": "https://api.github.com/users/Dastgheyb/orgs", "repos_url": "https://api.github.com/users/Dastgheyb/repos", "events_url": "https://api.github.com/users/Dastgheyb/events{/privacy}", "received_events_url": "https://api.github.com/users/Dastgheyb/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-06-19T16:08:10Z", "updated_at": "2021-05-16T07:42:18Z", "closed_at": "2020-06-19T16:35:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi :)\r\nlast weak my code works on the colab. but now after I install allennlp I get an error on the following line.\r\n`from allennlp.commands.elmo import ElmoEmbedder`\r\nand the error is : ModuleNotFoundError: No module named 'allennlp.commands.elmo'\r\nI searched this repository for ElmoEmbedder but none found.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4384/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4384/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4378", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4378/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4378/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4378/events", "html_url": "https://github.com/allenai/allennlp/issues/4378", "id": 641522424, "node_id": "MDU6SXNzdWU2NDE1MjI0MjQ=", "number": 4378, "title": "PDB++ arrow/tab keys don't work with allennlp", "user": {"login": "successar", "id": 1499824, "node_id": "MDQ6VXNlcjE0OTk4MjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1499824?v=4", "gravatar_id": "", "url": "https://api.github.com/users/successar", "html_url": "https://github.com/successar", "followers_url": "https://api.github.com/users/successar/followers", "following_url": "https://api.github.com/users/successar/following{/other_user}", "gists_url": "https://api.github.com/users/successar/gists{/gist_id}", "starred_url": "https://api.github.com/users/successar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/successar/subscriptions", "organizations_url": "https://api.github.com/users/successar/orgs", "repos_url": "https://api.github.com/users/successar/repos", "events_url": "https://api.github.com/users/successar/events{/privacy}", "received_events_url": "https://api.github.com/users/successar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-06-18T20:16:13Z", "updated_at": "2020-07-01T15:15:24Z", "closed_at": "2020-07-01T15:15:23Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [ ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nI can't use pdb/pdb++ arrow keys or tab key for autocompletion when running `allennlp train` . Possibly related to this issue https://stackoverflow.com/a/56418204\r\n\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- Reopening this issue - https://github.com/allenai/allennlp/issues/2176\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux Ubuntu 18.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==1.0.0\r\nappdirs==1.4.3\r\nastroid==2.4.1\r\nattrs==19.3.0\r\nblack==19.10b0\r\nblis==0.4.1\r\nboto3==1.14.4\r\nbotocore==1.17.4\r\ncatalogue==1.0.0\r\ncertifi==2020.4.5.2\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncymem==2.0.3\r\ndocutils==0.15.2\r\nfancycompleter==0.9.1\r\nfilelock==3.0.12\r\nfuture==0.18.2\r\ngnureadline==8.0.0\r\nh5py==2.10.0\r\nidna==2.9\r\nimportlib-metadata==1.6.1\r\nisort==4.3.21\r\njmespath==0.10.0\r\njoblib==0.15.1\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\nlazy-object-proxy==1.4.3\r\nmccabe==0.6.1\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nmypy-extensions==0.4.3\r\nnltk==3.5\r\nnumpy==1.18.5\r\noverrides==3.0.0\r\npackaging==20.4\r\npathspec==0.7.0\r\npdbpp==0.10.2\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprotobuf==3.12.2\r\npy==1.8.2\r\nPygments==2.6.1\r\npylint==2.5.2\r\npyparsing==2.4.7\r\npyrepl==0.9.0\r\npytest==5.4.3\r\npython-dateutil==2.8.1\r\nregex==2020.6.8\r\nrequests==2.23.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.4.1\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.2.4\r\nsrsly==1.0.2\r\ntensorboardX==2.0\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.7.0\r\ntoml==0.10.0\r\ntorch==1.5.0\r\ntqdm==4.46.1\r\ntransformers==2.11.0\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.1\r\nurllib3==1.25.9\r\nwasabi==0.6.0\r\nwcwidth==0.2.4\r\nwmctrl==0.3\r\nwrapt==1.11.2\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n1. Install allennlp in clean environment\r\n2. Run a short script and try arrow keys\r\n\r\n```python\r\nv = 10\r\nbreakpoint()\r\n```\r\n\r\nArrow keys should work\r\n\r\n3. Next run a `allennlp train` script and again put breakpoint somewhere. Check arrow keys.\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4378/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4378/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4376", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4376/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4376/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4376/events", "html_url": "https://github.com/allenai/allennlp/issues/4376", "id": 641482527, "node_id": "MDU6SXNzdWU2NDE0ODI1Mjc=", "number": 4376, "title": "AllenNLP install failing on jsonnet", "user": {"login": "butoialexandra", "id": 24324620, "node_id": "MDQ6VXNlcjI0MzI0NjIw", "avatar_url": "https://avatars.githubusercontent.com/u/24324620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/butoialexandra", "html_url": "https://github.com/butoialexandra", "followers_url": "https://api.github.com/users/butoialexandra/followers", "following_url": "https://api.github.com/users/butoialexandra/following{/other_user}", "gists_url": "https://api.github.com/users/butoialexandra/gists{/gist_id}", "starred_url": "https://api.github.com/users/butoialexandra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/butoialexandra/subscriptions", "organizations_url": "https://api.github.com/users/butoialexandra/orgs", "repos_url": "https://api.github.com/users/butoialexandra/repos", "events_url": "https://api.github.com/users/butoialexandra/events{/privacy}", "received_events_url": "https://api.github.com/users/butoialexandra/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-06-18T19:04:27Z", "updated_at": "2020-06-26T16:03:06Z", "closed_at": "2020-06-26T16:03:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nRunning setup.py install for jsonnet ... error\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /Library/Frameworks/Python.framework/Versions/3.6/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-record-k7ysxmf7/install-record.txt --single-version-externally-managed --compile --install-headers /Library/Frameworks/Python.framework/Versions/3.6/include/python3.6m/jsonnet\r\n         cwd: /private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/\r\n    Complete output (102 lines):\r\n    running install\r\n    running build\r\n    running build_ext\r\n    make: `core/desugarer.o' is up to date.\r\n    make: `core/formatter.o' is up to date.\r\n    make: `core/libjsonnet.o' is up to date.\r\n    make: `core/lexer.o' is up to date.\r\n    c++ -c -g -O3 -Wall -Wextra -Woverloaded-virtual -pedantic -std=c++0x -fPIC -Iinclude -Ithird_party/md5 -Ithird_party/json core/parser.cpp -o core/parser.o\r\n    In file included from core/parser.cpp:18:\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:317:9: error: no member named 'signbit' in the global namespace\r\n    using ::signbit;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:318:9: error: no member named 'fpclassify' in the global namespace\r\n    using ::fpclassify;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:319:9: error: no member named 'isfinite' in the global namespace; did you mean 'finite'?\r\n    using ::isfinite;\r\n          ~~^\r\n    /usr/local/include/math.h:749:12: note: 'finite' declared here\r\n    extern int finite(double)\r\n               ^\r\n    In file included from core/parser.cpp:18:\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:320:9: error: no member named 'isinf' in the global namespace\r\n    using ::isinf;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:321:9: error: no member named 'isnan' in the global namespace\r\n    using ::isnan;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:322:9: error: no member named 'isnormal' in the global namespace\r\n    using ::isnormal;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:323:9: error: no member named 'isgreater' in the global namespace\r\n    using ::isgreater;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:324:9: error: no member named 'isgreaterequal' in the global namespace\r\n    using ::isgreaterequal;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:325:9: error: no member named 'isless' in the global namespace\r\n    using ::isless;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:326:9: error: no member named 'islessequal' in the global namespace\r\n    using ::islessequal;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:327:9: error: no member named 'islessgreater' in the global namespace\r\n    using ::islessgreater;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:328:9: error: no member named 'isunordered' in the global namespace\r\n    using ::isunordered;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:329:9: error: no member named 'isunordered' in the global namespace\r\n    using ::isunordered;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:640:26: error: no template named 'numeric_limits'\r\n        bool _FloatBigger = (numeric_limits<_FloatT>::digits > numeric_limits<_IntT>::digits),\r\n                             ^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:640:60: error: no template named 'numeric_limits'\r\n        bool _FloatBigger = (numeric_limits<_FloatT>::digits > numeric_limits<_IntT>::digits),\r\n                                                               ^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:641:18: error: no template named 'numeric_limits'\r\n        int _Bits = (numeric_limits<_IntT>::digits - numeric_limits<_FloatT>::digits)>\r\n                     ^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:641:50: error: no template named 'numeric_limits'\r\n        int _Bits = (numeric_limits<_IntT>::digits - numeric_limits<_FloatT>::digits)>\r\n                                                     ^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:646:17: error: no template named 'numeric_limits'\r\n      static_assert(numeric_limits<_FloatT>::radix == 2, \"FloatT has incorrect radix\");\r\n                    ^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:649:25: error: no template named 'numeric_limits'\r\n      return _FloatBigger ? numeric_limits<_IntT>::max() :  (numeric_limits<_IntT>::max() >> _Bits << _Bits);\r\n                            ^\r\n    fatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n    20 errors generated.\r\n    make: *** [core/parser.o] Error 1\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/setup.py\", line 75, in <module>\r\n        test_suite=\"python._jsonnet_test\",\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/setuptools/__init__.py\", line 161, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/dist.py\", line 955, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/dist.py\", line 974, in run_command\r\n        cmd_obj.run()\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/setuptools/command/install.py\", line 61, in run\r\n        return orig.install.run(self)\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/command/install.py\", line 545, in run\r\n        self.run_command('build')\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/dist.py\", line 974, in run_command\r\n        cmd_obj.run()\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/command/build.py\", line 135, in run\r\n        self.run_command(cmd_name)\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/dist.py\", line 974, in run_command\r\n        cmd_obj.run()\r\n      File \"/private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/setup.py\", line 54, in run\r\n        raise Exception('Could not build %s' % (', '.join(LIB_OBJECTS)))\r\n    Exception: Could not build core/desugarer.o, core/formatter.o, core/libjsonnet.o, core/lexer.o, core/parser.o, core/pass.o, core/static_analysis.o, core/string_utils.o, core/vm.o, third_party/md5/md5.o\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.6/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-record-k7ysxmf7/install-record.txt --single-version-externally-managed --compile --install-headers /Library/Frameworks/Python.framework/Versions/3.6/include/python3.6m/jsonnet Check the logs for full command output.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\nI tried the proposed solutions in [#1938](https://github.com/allenai/allennlp/issues/1938), [#1969](https://github.com/allenai/allennlp/issues/1969), [#2779](https://github.com/allenai/allennlp/issues/2779) as well as [this](https://stackoverflow.com/questions/52509602/cant-compile-c-program-on-a-mac-after-upgrade-to-mojave) and [this](https://stackoverflow.com/questions/58278260/cant-compile-a-c-program-on-a-mac-after-upgrading-to-catalina-10-15/58278392#58278392). Also I tried installing with pip, conda and from source and they all fail on jsonnet. I could install jsonnet successfully using Homebrew but allennlp still fails to install. \r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: macOS Catalina 10.15.5\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.6.6\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4376/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4376/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4373", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4373/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4373/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4373/events", "html_url": "https://github.com/allenai/allennlp/issues/4373", "id": 640899713, "node_id": "MDU6SXNzdWU2NDA4OTk3MTM=", "number": 4373, "title": "Predict is not working for pre-trained fine grained NER model", "user": {"login": "MISabic", "id": 20471525, "node_id": "MDQ6VXNlcjIwNDcxNTI1", "avatar_url": "https://avatars.githubusercontent.com/u/20471525?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MISabic", "html_url": "https://github.com/MISabic", "followers_url": "https://api.github.com/users/MISabic/followers", "following_url": "https://api.github.com/users/MISabic/following{/other_user}", "gists_url": "https://api.github.com/users/MISabic/gists{/gist_id}", "starred_url": "https://api.github.com/users/MISabic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MISabic/subscriptions", "organizations_url": "https://api.github.com/users/MISabic/orgs", "repos_url": "https://api.github.com/users/MISabic/repos", "events_url": "https://api.github.com/users/MISabic/events{/privacy}", "received_events_url": "https://api.github.com/users/MISabic/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-06-18T04:36:36Z", "updated_at": "2020-07-02T08:51:04Z", "closed_at": "2020-07-02T08:51:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n\r\nHi. I tried to load the pre-trained model of fine-grained NER model but Predictor.from_path is not working.\r\n\r\nHere's my code \r\n\r\n`!pip3 install allennlp`\r\n`!pip3 install allennlp-models`\r\n`from allennlp.predictors import Predictor`\r\n`al = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")`\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nConfigurationError                        Traceback (most recent call last)\r\n<ipython-input-16-7116a695b09f> in <module>()\r\n      2 get_ipython().system('pip install --pre allennlp-models')\r\n      3 from allennlp.predictors import Predictor\r\n----> 4 al = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")\r\n      5 al.predict(sentence=document)\r\n\r\n9 frames\r\n/usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py in from_path(cls, archive_path, predictor_name, cuda_device, dataset_reader_to_load, frozen, import_plugins)\r\n    273             plugins.import_plugins()\r\n    274         return Predictor.from_archive(\r\n--> 275             load_archive(archive_path, cuda_device=cuda_device),\r\n    276             predictor_name,\r\n    277             dataset_reader_to_load=dataset_reader_to_load,\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/models/archival.py in load_archive(archive_file, cuda_device, opt_level, overrides, weights_file)\r\n    195         serialization_dir=serialization_dir,\r\n    196         cuda_device=cuda_device,\r\n--> 197         opt_level=opt_level,\r\n    198     )\r\n    199 \r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/models/model.py in load(cls, config, serialization_dir, weights_file, cuda_device, opt_level)\r\n    396             # get_model_class method, that recurses whenever it finds a from_archive model type.\r\n    397             model_class = Model\r\n--> 398         return model_class._load(config, serialization_dir, weights_file, cuda_device, opt_level)\r\n    399 \r\n    400     def extend_embedder_vocab(self, embedding_sources_mapping: Dict[str, str] = None) -> None:\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/models/model.py in _load(cls, config, serialization_dir, weights_file, cuda_device, opt_level)\r\n    293         # want the code to look for it, so we remove it from the parameters here.\r\n    294         remove_pretrained_embedding_params(model_params)\r\n--> 295         model = Model.from_params(vocab=vocab, params=model_params)\r\n    296 \r\n    297         # Force model to cpu or gpu, as appropriate, to make sure that the embeddings are\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in from_params(cls, params, constructor_to_call, constructor_to_inspect, **extras)\r\n    578                     constructor_to_call=constructor_to_call,\r\n    579                     constructor_to_inspect=constructor_to_inspect,\r\n--> 580                     **extras,\r\n    581                 )\r\n    582             else:\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in from_params(cls, params, constructor_to_call, constructor_to_inspect, **extras)\r\n    607             else:\r\n    608                 # This class has a constructor, so create kwargs for it.\r\n--> 609                 kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n    610 \r\n    611             return constructor_to_call(**kwargs)  # type: ignore\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in create_kwargs(constructor, cls, params, **extras)\r\n    179 \r\n    180         constructed_arg = pop_and_construct_arg(\r\n--> 181             cls.__name__, param_name, annotation, param.default, params, **extras\r\n    182         )\r\n    183 \r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in pop_and_construct_arg(class_name, argument_name, annotation, default, params, **extras)\r\n    285         return None\r\n    286 \r\n--> 287     return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n    288 \r\n    289 \r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in construct_arg(class_name, argument_name, popped_params, annotation, default, **extras)\r\n    319             elif isinstance(popped_params, dict):\r\n    320                 popped_params = Params(popped_params)\r\n--> 321             return annotation.from_params(params=popped_params, **subextras)\r\n    322         elif not optional:\r\n    323             # Not optional and not supplied, that's an error!\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in from_params(cls, params, constructor_to_call, constructor_to_inspect, **extras)\r\n    531         if not isinstance(params, Params):\r\n    532             raise ConfigurationError(\r\n--> 533                 \"from_params was passed a `params` object that was not a `Params`. This probably \"\r\n    534                 \"indicates malformed parameters in a configuration file, where something that \"\r\n    535                 \"should have been a dictionary was actually a list, or something else. \"\r\n\r\nConfigurationError: from_params was passed a `params` object that was not a `Params`. This probably indicates malformed parameters in a configuration file, where something that should have been a dictionary was actually a list, or something else. This happened when constructing an object of type <class 'allennlp.nn.regularizers.regularizer_applicator.RegularizerApplicator'>.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.6\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalabaster==0.7.12\r\nanaconda-client==1.7.2\r\nanaconda-navigator==1.9.12\r\nanaconda-project==0.8.3\r\nargh==0.26.2\r\nasn1crypto==1.3.0\r\nastroid==2.3.3\r\nastropy==4.0\r\natomicwrites==1.3.0\r\nattrs==19.3.0\r\nautopep8==1.4.4\r\nBabel==2.8.0\r\nbackcall==0.1.0\r\nbackports.functools-lru-cache==1.6.1\r\nbackports.shutil-get-terminal-size==1.0.0\r\nbackports.tempfile==1.0\r\nbackports.weakref==1.0.post1\r\nbcrypt==3.1.7\r\nbeautifulsoup4==4.8.2\r\nbitarray==1.2.1\r\nbkcharts==0.2\r\nbleach==3.1.0\r\nblis==0.4.1\r\nbokeh==1.4.0\r\nboto==2.49.0\r\nBottleneck==1.3.2\r\ncatalogue==1.0.0\r\ncertifi==2019.11.28\r\ncffi==1.14.0\r\nchardet==3.0.4\r\nClick==7.0\r\ncloudpickle==1.3.0\r\nclyent==1.2.2\r\ncolorama==0.4.3\r\ncomtypes==1.1.7\r\nconda==4.8.3\r\nconda-build==3.18.11\r\nconda-package-handling==1.6.0\r\nconda-verify==3.4.2\r\ncontextlib2==0.6.0.post1\r\ncryptography==2.8\r\ncycler==0.10.0\r\ncymem==2.0.3\r\nCython==0.29.15\r\ncytoolz==0.10.1\r\ndask==2.11.0\r\ndecorator==4.4.1\r\ndefusedxml==0.6.0\r\ndiff-match-patch==20181111\r\ndistributed==2.11.0\r\ndocutils==0.16\r\nen-core-web-lg==2.3.0\r\nen-core-web-md==2.3.0\r\nen-core-web-sm==2.3.0\r\nentrypoints==0.3\r\net-xmlfile==1.0.1\r\nfastcache==1.1.0\r\nfilelock==3.0.12\r\nflake8==3.7.9\r\nFlask==1.1.1\r\nfsspec==0.6.2\r\nfuture==0.18.2\r\ngevent==1.4.0\r\nglob2==0.7\r\ngreenlet==0.4.15\r\nh5py==2.10.0\r\nHeapDict==1.0.1\r\nhtml5lib==1.0.1\r\nhypothesis==5.5.4\r\nidna==2.8\r\nimageio==2.6.1\r\nimagesize==1.2.0\r\nimportlib-metadata==1.6.1\r\nintervaltree==3.0.2\r\nipykernel==5.1.4\r\nipython==7.12.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njdcal==1.4.1\r\njedi==0.14.1\r\nJinja2==2.11.1\r\njoblib==0.14.1\r\njson5==0.9.1\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==5.3.4\r\njupyter-console==6.1.0\r\njupyter-core==4.6.1\r\njupyterlab==1.2.6\r\njupyterlab-server==1.0.6\r\nkeyring==21.1.0\r\nkiwisolver==1.1.0\r\nlazy-object-proxy==1.4.3\r\nlibarchive-c==2.8\r\nllvmlite==0.31.0\r\nlocket==0.2.0\r\nlxml==4.5.0\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.1.3\r\nmccabe==0.6.1\r\nmenuinst==1.4.16\r\nmistune==0.8.4\r\nmkl-fft==1.0.15\r\nmkl-random==1.1.0\r\nmkl-service==2.3.0\r\nmock==4.0.1\r\nmore-itertools==8.2.0\r\nmpmath==1.1.0\r\nmsgpack==0.6.1\r\nmultipledispatch==0.6.0\r\nmurmurhash==1.0.0\r\nnavigator-updater==0.2.1\r\nnbconvert==5.6.1\r\nnbformat==5.0.4\r\nnetworkx==2.4\r\nnltk==3.4.5\r\nnose==1.3.7\r\nnotebook==6.0.3\r\nnumba==0.48.0\r\nnumexpr==2.7.1\r\nnumpy==1.18.1\r\nnumpydoc==0.9.2\r\nolefile==0.46\r\nopenpyxl==3.0.3\r\npackaging==20.1\r\npandas==1.0.1\r\npandocfilters==1.4.2\r\nparamiko==2.7.1\r\nparso==0.5.2\r\npartd==1.1.0\r\npath==13.1.0\r\npathlib2==2.3.5\r\npathtools==0.1.2\r\npatsy==0.5.1\r\npep8==1.7.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.0.0\r\npkginfo==1.5.0.1\r\nplac==0.9.6\r\npluggy==0.13.1\r\nply==3.11\r\npreshed==3.0.2\r\nprometheus-client==0.7.1\r\nprompt-toolkit==3.0.3\r\npsutil==5.6.7\r\npy==1.8.1\r\npycodestyle==2.5.0\r\npycosat==0.6.3\r\npycparser==2.19\r\npycrypto==2.6.1\r\npycurl==7.43.0.5\r\npydocstyle==4.0.1\r\npyflakes==2.1.1\r\nPygments==2.5.2\r\npylint==2.4.4\r\nPyNaCl==1.3.0\r\npyodbc===4.0.0-unsupported\r\npyOpenSSL==19.1.0\r\npyparsing==2.4.6\r\npyreadline==2.1\r\npyrsistent==0.15.7\r\nPySocks==1.7.1\r\npytest==5.3.5\r\npytest-arraydiff==0.3\r\npytest-astropy==0.8.0\r\npytest-astropy-header==0.1.2\r\npytest-doctestplus==0.5.0\r\npytest-openfiles==0.4.0\r\npytest-remotedata==0.3.2\r\npython-dateutil==2.8.1\r\npython-jsonrpc-server==0.3.4\r\npython-language-server==0.31.7\r\npytz==2019.3\r\nPyWavelets==1.1.1\r\npywin32==227\r\npywin32-ctypes==0.2.0\r\npywinpty==0.5.7\r\nPyYAML==5.3\r\npyzmq==18.1.1\r\nQDarkStyle==2.8\r\nQtAwesome==0.6.1\r\nqtconsole==4.6.0\r\nQtPy==1.9.0\r\nrequests==2.22.0\r\nrope==0.16.0\r\nRtree==0.9.3\r\nruamel-yaml==0.15.87\r\nscikit-image==0.16.2\r\nscikit-learn==0.22.1\r\nscipy==1.4.1\r\nseaborn==0.10.0\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsimplegeneric==0.8.1\r\nsingledispatch==3.4.0.3\r\nsix==1.14.0\r\nsnowballstemmer==2.0.0\r\nsortedcollections==1.1.2\r\nsortedcontainers==2.1.0\r\nsoupsieve==1.9.5\r\nspacy==2.3.0\r\nSphinx==2.4.0\r\nsphinxcontrib-applehelp==1.0.1\r\nsphinxcontrib-devhelp==1.0.1\r\nsphinxcontrib-htmlhelp==1.0.2\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.2\r\nsphinxcontrib-serializinghtml==1.1.3\r\nsphinxcontrib-websupport==1.2.0\r\nspyder==4.0.1\r\nspyder-kernels==1.8.1\r\nSQLAlchemy==1.3.13\r\nsrsly==1.0.2\r\nstatsmodels==0.11.0\r\nsympy==1.5.1\r\ntables==3.6.1\r\ntblib==1.6.0\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\nthinc==7.4.1\r\ntoolz==0.10.0\r\ntorch==1.5.0\r\ntorchtext==0.6.0\r\ntorchvision==0.6.0\r\ntornado==6.0.3\r\ntqdm==4.42.1\r\ntraitlets==4.3.3\r\nujson==1.35\r\nunicodecsv==0.14.1\r\nurllib3==1.25.8\r\nwasabi==0.6.0\r\nwatchdog==0.10.2\r\nwcwidth==0.1.8\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.0\r\nwidgetsnbextension==3.5.1\r\nwin-inet-pton==1.1.0\r\nwin-unicode-console==0.5\r\nwincertstore==0.2\r\nwrapt==1.11.2\r\nxlrd==1.2.0\r\nXlsxWriter==1.2.7\r\nxlwings==0.17.1\r\nxlwt==1.3.0\r\nxmltodict==0.12.0\r\nyapf==0.28.0\r\nzict==1.0.0\r\nzipp==2.2.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4373/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4373/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4367", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4367/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4367/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4367/events", "html_url": "https://github.com/allenai/allennlp/issues/4367", "id": 640384155, "node_id": "MDU6SXNzdWU2NDAzODQxNTU=", "number": 4367, "title": "Make allennlp work with allentune once again", "user": {"login": "apohllo", "id": 40543, "node_id": "MDQ6VXNlcjQwNTQz", "avatar_url": "https://avatars.githubusercontent.com/u/40543?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apohllo", "html_url": "https://github.com/apohllo", "followers_url": "https://api.github.com/users/apohllo/followers", "following_url": "https://api.github.com/users/apohllo/following{/other_user}", "gists_url": "https://api.github.com/users/apohllo/gists{/gist_id}", "starred_url": "https://api.github.com/users/apohllo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apohllo/subscriptions", "organizations_url": "https://api.github.com/users/apohllo/orgs", "repos_url": "https://api.github.com/users/apohllo/repos", "events_url": "https://api.github.com/users/apohllo/events{/privacy}", "received_events_url": "https://api.github.com/users/apohllo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "kernelmachine", "id": 1164135, "node_id": "MDQ6VXNlcjExNjQxMzU=", "avatar_url": "https://avatars.githubusercontent.com/u/1164135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kernelmachine", "html_url": "https://github.com/kernelmachine", "followers_url": "https://api.github.com/users/kernelmachine/followers", "following_url": "https://api.github.com/users/kernelmachine/following{/other_user}", "gists_url": "https://api.github.com/users/kernelmachine/gists{/gist_id}", "starred_url": "https://api.github.com/users/kernelmachine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kernelmachine/subscriptions", "organizations_url": "https://api.github.com/users/kernelmachine/orgs", "repos_url": "https://api.github.com/users/kernelmachine/repos", "events_url": "https://api.github.com/users/kernelmachine/events{/privacy}", "received_events_url": "https://api.github.com/users/kernelmachine/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "kernelmachine", "id": 1164135, "node_id": "MDQ6VXNlcjExNjQxMzU=", "avatar_url": "https://avatars.githubusercontent.com/u/1164135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kernelmachine", "html_url": "https://github.com/kernelmachine", "followers_url": "https://api.github.com/users/kernelmachine/followers", "following_url": "https://api.github.com/users/kernelmachine/following{/other_user}", "gists_url": "https://api.github.com/users/kernelmachine/gists{/gist_id}", "starred_url": "https://api.github.com/users/kernelmachine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kernelmachine/subscriptions", "organizations_url": "https://api.github.com/users/kernelmachine/orgs", "repos_url": "https://api.github.com/users/kernelmachine/repos", "events_url": "https://api.github.com/users/kernelmachine/events{/privacy}", "received_events_url": "https://api.github.com/users/kernelmachine/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2020-06-17T11:58:00Z", "updated_at": "2020-07-29T10:49:34Z", "closed_at": "2020-07-27T23:46:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nRunning allentune with the latest allennlp master causes the following error:\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 918, in save_global\r\n    obj2, parent = _getattribute(module, name)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 266, in _getattribute\r\n    .format(name, obj))\r\nAttributeError: Can't get local attribute 'wrap_function.<locals>.WrappedFunc' on <function wrap_function at 0x2b6ace9a7d90>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 639, in save_global\r\n    return Pickler.save_global(self, obj, name=name)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 922, in save_global\r\n    (obj, module_name, name))\r\n_pickle.PicklingError: Can't pickle <class 'ray.tune.trainable.wrap_function.<locals>.WrappedFunc'>: it's not found as ray.tune.trainable.wrap_function.<locals>.WrappedFunc\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/net/people/plgapohl/python-albert-pytorch/bin/allentune\", line 11, in <module>\r\n    load_entry_point('allentune', 'console_scripts', 'allentune')()\r\n  File \"/net/people/plgapohl/allentune/allentune/commands/__init__.py\", line 67, in main\r\n    args.func(args)\r\n  File \"/net/people/plgapohl/allentune/allentune/commands/search.py\", line 126, in search_from_args\r\n    executor.run(args)\r\n  File \"/net/people/plgapohl/allentune/allentune/modules/ray_executor.py\", line 94, in run\r\n    self.run_distributed(run_func, args)\r\n  File \"/net/people/plgapohl/allentune/allentune/modules/ray_executor.py\", line 58, in run_distributed\r\n    register_trainable(\"run\", run_func)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/tune/registry.py\", line 49, in register_trainable\r\n    _global_registry.register(TRAINABLE_CLASS, name, trainable)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/tune/registry.py\", line 88, in register\r\n    self._to_flush[(category, key)] = pickle.dumps(value)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 881, in dumps\r\n    cp.dump(obj)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 268, in dump\r\n    return Pickler.dump(self, obj)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 409, in dump\r\n    self.save(obj)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 648, in save_global\r\n    return self.save_dynamic_class(obj)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 495, in save_dynamic_class\r\n    save(clsdict)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n   save(v)                                                                                                                                                                                        [26/1833]\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 410, in save_function\r\n    self.save_function_tuple(obj)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 553, in save_function_tuple\r\n    save(state)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 781, in save_list\r\n    self._batch_appends(obj)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 808, in _batch_appends\r\n    save(tmp[0])\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 410, in save_function\r\n    self.save_function_tuple(obj)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 553, in save_function_tuple\r\n    save(state)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 521, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 634, in save_reduce\r\n    save(state)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 521, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 634, in save_reduce\r\n    save(state)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n  f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 781, in save_list\r\n    self._batch_appends(obj)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 808, in _batch_appends\r\n    save(tmp[0])\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 521, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 634, in save_reduce\r\n    save(state)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 496, in save\r\n    rv = reduce(self.proto)\r\nTypeError: can't pickle _thread.RLock objects\r\n```\r\n\r\nThis error in not present if we switch to:\r\nhttps://github.com/allenai/allennlp/commit/26e313b7d11eacf3a78c09c34608ad1bfd7db120\r\nbut appers when we move to the next commit, i.e.:\r\nhttps://github.com/allenai/allennlp/commit/4a6023b3ee692da50ff27126f331546e7c2f284a\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\nI have reported the issue in allentune, but it's a problem in allennlp:\r\n\r\n- https://github.com/allenai/allentune/issues/11\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\nLinux p2311 3.10.0-1062.9.1.el7.x86_64 #1 SMP Fri Dec 6 15:49:49 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n3.6.5\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.9.0\r\nalabaster==0.7.12\r\nallennlp==1.0.0rc4\r\n-e git+https://github.com/allenai/allentune.git@6ef9a2e38a9bcf944f83f2034dd181f94ff00d9c#egg=allentune\r\napex==0.1\r\nastor==0.8.1\r\nastunparse==1.6.3\r\nattrs==19.3.0\r\nBabel==2.8.0\r\nbackcall==0.1.0\r\nblis==0.2.4\r\nboto3==1.11.12\r\nbotocore==1.14.12\r\ncachetools==4.0.0\r\ncatalogue==1.0.0\r\ncertifi==2019.11.28\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncolorama==0.4.3\r\nconfigparser==5.0.0\r\nconllu==2.3.2\r\ncoverage==5.1\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ndataclasses==0.7\r\ndecorator==4.4.1\r\ndocker-pycreds==0.4.0\r\ndocutils==0.15.2\r\neditdistance==0.5.3\r\nfilelock==3.0.12\r\nfire==0.2.1\r\nflaky==3.6.1\r\nFlask==1.1.2\r\nFlask-Cors==3.0.8\r\nflatbuffers==1.12\r\nftfy==5.7\r\nfuncsigs==1.0.2\r\nfuture==0.18.2\r\ngast==0.2.2\r\ngevent==20.6.2\r\ngitdb==4.0.5\r\nGitPython==3.1.3\r\ngoogle-auth==1.11.0\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-pasta==0.2.0\r\ngql==0.2.0\r\ngraphql-core==1.1\r\ngreenlet==0.4.16\r\ngrpcio==1.26.0\r\nh5py==2.10.0\r\nhtml2text==2020.1.16\r\nidna==2.8\r\nimagesize==1.2.0\r\nimportlib-metadata==1.6.1\r\nipdb==0.12.3\r\nipython==7.12.0\r\nipython-genutils==0.2.0\r\nitsdangerous==1.1.0\r\njedi==0.16.0\r\nJinja2==2.11.2\r\njmespath==0.9.4\r\njoblib==0.15.1\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\nKeras==2.3.1\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.2\r\nkiwisolver==1.2.0\r\nMarkdown==3.1.1\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.2.1\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nnltk==3.4.5\r\nnumpy==1.18.1\r\nnumpydoc==1.0.0\r\nnvidia-ml-py3==7.352.0\r\noauthlib==3.1.0\r\nopt-einsum==3.2.1\r\noverrides==2.8.0\r\npackaging==20.4\r\npandas==1.0.4\r\nparsimonious==0.8.1\r\nparso==0.6.1\r\npathtools==0.1.2\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nplac==0.9.6\r\npluggy==0.13.1\r\npreshed==2.0.1\r\nprogressbar==2.5\r\npromise==2.3\r\nprompt-toolkit==3.0.3\r\nprotobuf==3.11.2\r\npsutil==5.7.0\r\nptyprocess==0.6.0\r\npy==1.8.2\r\npy-rouge==1.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\nPygments==2.5.2\r\npyparsing==2.4.7\r\npytest==5.4.3\r\npytest-cov==2.10.0\r\npython-dateutil==2.8.1\r\npytorch-pretrained-bert==0.6.2\r\npytorch-transformers==1.1.0\r\npytz==2020.1\r\nPyYAML==5.3.1\r\nray==0.6.2\r\nredis==3.5.3\r\nregex==2020.5.14\r\nrequests==2.22.0\r\nrequests-oauthlib==1.3.0\r\nresponses==0.10.15\r\nrsa==4.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.4.1\r\nseaborn==0.10.1\r\nsemantic-version==2.8.5\r\nsentencepiece==0.1.91\r\nsentry-sdk==0.14.4\r\nseqeval==0.0.12\r\nshortuuid==1.0.1\r\nsimpletransformers==0.34.0\r\nsix==1.14.0\r\nsmmap==3.0.4\r\nsnowballstemmer==2.0.0\r\nspacy==2.1.9\r\nSphinx==3.1.1\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nsqlparse==0.3.1\r\nsrsly==1.0.2\r\nsubprocess32==3.5.4\r\ntensorboard==1.15.0\r\ntensorboard-plugin-wit==1.6.0.post3\r\ntensorboardX==2.0\r\ntensorflow==1.15.0\r\ntensorflow-estimator==1.15.1\r\ntermcolor==1.1.0\r\nthinc==7.0.8\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.5.2\r\ntorch==1.5.0\r\ntqdm==4.42.0\r\ntraitlets==4.3.3\r\ntransformers==2.8.0\r\nUnidecode==1.1.1\r\nurllib3==1.25.8\r\nwandb==0.8.36\r\nwasabi==0.6.0\r\nwatchdog==0.10.2\r\nwcwidth==0.1.8\r\nWerkzeug==0.16.1\r\nword2number==1.1\r\nwrapt==1.12.1\r\nzipp==3.1.0\r\nzope.event==4.4\r\nzope.interface==5.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nJust run the example search in allentune:\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nallentune search \\\r\n    --experiment-name classifier_search \\\r\n    --num-cpus 56 \\\r\n    --num-gpus 4 \\\r\n    --cpus-per-trial 1 \\\r\n    --gpus-per-trial 1 \\\r\n    --search-space examples/search_space.json \\\r\n    --num-samples 30 \\\r\n    --base-config examples/classifier.jsonnet\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4367/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4367/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4360", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4360/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4360/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4360/events", "html_url": "https://github.com/allenai/allennlp/issues/4360", "id": 638885319, "node_id": "MDU6SXNzdWU2Mzg4ODUzMTk=", "number": 4360, "title": "Can't get correct output using .saliency_interpret_from_json() from Interpret", "user": {"login": "koren-v", "id": 45794881, "node_id": "MDQ6VXNlcjQ1Nzk0ODgx", "avatar_url": "https://avatars.githubusercontent.com/u/45794881?v=4", "gravatar_id": "", "url": "https://api.github.com/users/koren-v", "html_url": "https://github.com/koren-v", "followers_url": "https://api.github.com/users/koren-v/followers", "following_url": "https://api.github.com/users/koren-v/following{/other_user}", "gists_url": "https://api.github.com/users/koren-v/gists{/gist_id}", "starred_url": "https://api.github.com/users/koren-v/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/koren-v/subscriptions", "organizations_url": "https://api.github.com/users/koren-v/orgs", "repos_url": "https://api.github.com/users/koren-v/repos", "events_url": "https://api.github.com/users/koren-v/events{/privacy}", "received_events_url": "https://api.github.com/users/koren-v/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "matt-gardner", "id": 3291951, "node_id": "MDQ6VXNlcjMyOTE5NTE=", "avatar_url": "https://avatars.githubusercontent.com/u/3291951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matt-gardner", "html_url": "https://github.com/matt-gardner", "followers_url": "https://api.github.com/users/matt-gardner/followers", "following_url": "https://api.github.com/users/matt-gardner/following{/other_user}", "gists_url": "https://api.github.com/users/matt-gardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/matt-gardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matt-gardner/subscriptions", "organizations_url": "https://api.github.com/users/matt-gardner/orgs", "repos_url": "https://api.github.com/users/matt-gardner/repos", "events_url": "https://api.github.com/users/matt-gardner/events{/privacy}", "received_events_url": "https://api.github.com/users/matt-gardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "matt-gardner", "id": 3291951, "node_id": "MDQ6VXNlcjMyOTE5NTE=", "avatar_url": "https://avatars.githubusercontent.com/u/3291951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matt-gardner", "html_url": "https://github.com/matt-gardner", "followers_url": "https://api.github.com/users/matt-gardner/followers", "following_url": "https://api.github.com/users/matt-gardner/following{/other_user}", "gists_url": "https://api.github.com/users/matt-gardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/matt-gardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matt-gardner/subscriptions", "organizations_url": "https://api.github.com/users/matt-gardner/orgs", "repos_url": "https://api.github.com/users/matt-gardner/repos", "events_url": "https://api.github.com/users/matt-gardner/events{/privacy}", "received_events_url": "https://api.github.com/users/matt-gardner/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/15", "html_url": "https://github.com/allenai/allennlp/milestone/15", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/15/labels", "id": 5996193, "node_id": "MDk6TWlsZXN0b25lNTk5NjE5Mw==", "number": 15, "title": "1.4", "description": "", "creator": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 9, "state": "closed", "created_at": "2020-10-15T21:34:47Z", "updated_at": "2021-02-12T00:44:07Z", "due_on": null, "closed_at": "2021-02-12T00:44:07Z"}, "comments": 13, "created_at": "2020-06-15T14:10:01Z", "updated_at": "2020-11-07T01:08:07Z", "closed_at": "2020-11-02T22:21:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I'm trying to get the importance of each word in a sentence while sentiment classification but always get the same result for different inputs. The Code:\r\n```\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.classification\r\nfrom allennlp.interpret.saliency_interpreters import (\r\n    SaliencyInterpreter,\r\n    SimpleGradient,\r\n    SmoothGradient,\r\n    IntegratedGradient,\r\n)\r\n\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/sst-roberta-large-2020.06.08.tar.gz\")\r\nsimple_grad = SimpleGradient(predictor)\r\n\r\ninput_json = {'sentence' : \"a very well-made, funny and entertaining picture.\"}\r\n\r\nsimple_grad.saliency_interpret_from_json(input_json)\r\n```\r\ngives:\r\n```\r\n{'instance_1': {'grad_input_1': [1.0,\r\n   0.0,\r\n   0.0,\r\n   0.0,\r\n   0.0,\r\n   0.0,\r\n   0.0,\r\n   0.0,\r\n   0.0,\r\n   0.0,\r\n   0.0]}}\r\n```\r\nSo what can be the reason of this problem?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4360/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4360/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4358", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4358/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4358/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4358/events", "html_url": "https://github.com/allenai/allennlp/issues/4358", "id": 638786199, "node_id": "MDU6SXNzdWU2Mzg3ODYxOTk=", "number": 4358, "title": "Textual Entailment using roBERTa only predicting one category", "user": {"login": "ud2195", "id": 42403625, "node_id": "MDQ6VXNlcjQyNDAzNjI1", "avatar_url": "https://avatars.githubusercontent.com/u/42403625?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ud2195", "html_url": "https://github.com/ud2195", "followers_url": "https://api.github.com/users/ud2195/followers", "following_url": "https://api.github.com/users/ud2195/following{/other_user}", "gists_url": "https://api.github.com/users/ud2195/gists{/gist_id}", "starred_url": "https://api.github.com/users/ud2195/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ud2195/subscriptions", "organizations_url": "https://api.github.com/users/ud2195/orgs", "repos_url": "https://api.github.com/users/ud2195/repos", "events_url": "https://api.github.com/users/ud2195/events{/privacy}", "received_events_url": "https://api.github.com/users/ud2195/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-15T11:46:24Z", "updated_at": "2020-08-18T16:18:33Z", "closed_at": "2020-08-18T16:18:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I followed the exact config file given here \r\nhttps://github.com/allenai/allennlp-models/blob/master/training_config/pair_classification/snli_roberta.jsonnet\r\njust changed `max_len` in my config file and now it looks like this:-\r\n\r\n```\r\nlocal transformer_model = \"roberta-large\";\r\nlocal transformer_dim = 1024;\r\nlocal cls_is_last_token = false;\r\n\r\n{\r\n  \"dataset_reader\":{\r\n    \"type\": \"snli\",\r\n    \"lazy\": true,\r\n    \"tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": transformer_model,\r\n      \"add_special_tokens\": false\r\n    },\r\n    \"token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": transformer_model,\r\n        \"max_length\": 40\r\n      }\r\n    }\r\n  },\r\n  \"train_data_path\": \"/opt/ml/input/data/training/cnli_sampletrain_5L.jsonl\",\r\n  \"validation_data_path\": \"/opt/ml/input/data/validation/cnli_sampleval_5L.jsonl\",\r\n  \r\n  \"model\": {\r\n    \"type\": \"basic_classifier\",\r\n    \"text_field_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer\",\r\n          \"model_name\": transformer_model,\r\n          \"max_length\": 40\r\n        }\r\n      }\r\n    },\r\n    \"seq2vec_encoder\": {\r\n       \"type\": \"cls_pooler\",\r\n       \"embedding_dim\": transformer_dim,\r\n       \"cls_is_last_token\": cls_is_last_token\r\n    },\r\n    \"feedforward\": {\r\n      \"input_dim\": transformer_dim,\r\n      \"num_layers\": 1,\r\n      \"hidden_dims\": transformer_dim,\r\n      \"activations\": \"tanh\"\r\n    },\r\n    \"dropout\": 0.3,\r\n    \"namespace\": \"tags\"\r\n  },\r\n  \"data_loader\": {\r\n        \"batch_size\": 4,\r\n        \r\n        \"drop_last\": true,\r\n    },\r\n  \"trainer\": {\r\n    \"num_epochs\": 3,\r\n    \"cuda_device\" : 0,\r\n    \"validation_metric\": \"+accuracy\",\r\n    \"learning_rate_scheduler\": {\r\n      \"type\": \"slanted_triangular\",\r\n      \"cut_frac\": 0.06\r\n    },\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"lr\": 2e-5,\r\n      \"weight_decay\": 0.1,\r\n    }\r\n  }\r\n}\r\n```\r\nThe objective is to do Textual entailment using roBERTa , but after training my model for 2 epochs the accuracy(roughly 79%)  hardly changed and then upon trying my model to predict it strangely predicted the same label for all the instances present in the test data. \r\n\r\ni have a few doubts , The `model_type:basic_classifier` mentioned in default config is it right ? doesnt `basic_classifier` implement a normal text classifier ?\r\n\r\n\r\nCode i am using for prediction-\r\n```\r\nimport pandas as pd\r\nfrom allennlp_models import pair_classification\r\nfrom allennlp.predictors.predictor import Predictor \r\nimport numpy as np\r\n\r\ndata=pd.read_csv(r'/home/episourcein.episource.com/espm1854/Downloads/context_3_classes.csv')\r\npredictor=Predictor.from_path(\"/home/episourcein.episource.com/espm1854/Documents/robertaTE/model.tar.gz\",predictor_name=\"textual_entailment\")\r\n\r\nlabels_dict = predictor._model.vocab.get_index_to_token_vocabulary('labels')\r\n\r\ndef get_labels(hypothesis, premise):\r\n    pred = predictor.predict(\r\n      hypothesis=hypothesis,\r\n      premise=premise\r\n    )\r\n    \r\n    label = labels_dict[np.argmax(pred['probs'])]\r\n    return label\r\n\r\ndata['predictions']= data.apply(lambda x: get_labels(x['hypothesis'],x['sentence']),  axis=1)\r\n```\r\nif the `model_type` here is wrong then what `model_type` should i specify inplace of `basic_classifier` to do textual entailment with roBERTa? A sample config file for doing entailment with roBERTa would really be helpful \r\nAny help will be appreciated ! @epwalsh @matt-gardner \r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4358/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4358/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4357", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4357/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4357/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4357/events", "html_url": "https://github.com/allenai/allennlp/issues/4357", "id": 638463439, "node_id": "MDU6SXNzdWU2Mzg0NjM0Mzk=", "number": 4357, "title": "Bug on calculating \"argmax_predictions\". It increases the false positive count for last label.", "user": {"login": "12seetharaman", "id": 53142037, "node_id": "MDQ6VXNlcjUzMTQyMDM3", "avatar_url": "https://avatars.githubusercontent.com/u/53142037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/12seetharaman", "html_url": "https://github.com/12seetharaman", "followers_url": "https://api.github.com/users/12seetharaman/followers", "following_url": "https://api.github.com/users/12seetharaman/following{/other_user}", "gists_url": "https://api.github.com/users/12seetharaman/gists{/gist_id}", "starred_url": "https://api.github.com/users/12seetharaman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/12seetharaman/subscriptions", "organizations_url": "https://api.github.com/users/12seetharaman/orgs", "repos_url": "https://api.github.com/users/12seetharaman/repos", "events_url": "https://api.github.com/users/12seetharaman/events{/privacy}", "received_events_url": "https://api.github.com/users/12seetharaman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "02b8d1", "default": false, "description": ""}], "state": "closed", "locked": true, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/11", "html_url": "https://github.com/allenai/allennlp/milestone/11", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/11/labels", "id": 5183675, "node_id": "MDk6TWlsZXN0b25lNTE4MzY3NQ==", "number": 11, "title": "1.1", "description": "A placeholder for work we'd like to do after the 1.0 release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 23, "state": "closed", "created_at": "2020-03-09T17:46:04Z", "updated_at": "2020-09-10T20:00:22Z", "due_on": null, "closed_at": "2020-09-10T20:00:22Z"}, "comments": 1, "created_at": "2020-06-15T00:26:20Z", "updated_at": "2020-07-13T20:54:55Z", "closed_at": "2020-07-13T20:54:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "File: https://github.com/allenai/allennlp/blob/master/allennlp/training/metrics/fbeta_measure.py\r\nLine no: 132\r\n\r\nPrediction tensor is all zero \"[0, 0, 0, 0, 0, 0]\", when a record is not classified to any of the labels. \r\n\r\n`argmax_predictions = predictions.max(dim=-1)[1].float()`\r\n\r\nHere, we are calculating argmax predictions by a max value index. \r\nIn the case of all zeros tensor, we will get the index of the last label. It increases the false positive count of the last label and affects the F1 score.\r\n\r\n```\r\n>>> prediction =  torch.zeros(6)\r\n>>> prediction\r\ntensor([0., 0., 0., 0., 0., 0.])\r\n>>> prediction.max(dim=-1)\r\n(tensor(0.), tensor(5))\r\n>>> prediction.max(dim=-1)[1]\r\ntensor(5)\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4357/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4357/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4354", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4354/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4354/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4354/events", "html_url": "https://github.com/allenai/allennlp/issues/4354", "id": 637191936, "node_id": "MDU6SXNzdWU2MzcxOTE5MzY=", "number": 4354, "title": "Reported loss is confusing", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 723800354, "node_id": "MDU6TGFiZWw3MjM4MDAzNTQ=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Good%20First%20Issue", "name": "Good First Issue", "color": "e99695", "default": false, "description": "A great place to start for first time contributors"}], "state": "closed", "locked": true, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/11", "html_url": "https://github.com/allenai/allennlp/milestone/11", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/11/labels", "id": 5183675, "node_id": "MDk6TWlsZXN0b25lNTE4MzY3NQ==", "number": 11, "title": "1.1", "description": "A placeholder for work we'd like to do after the 1.0 release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 23, "state": "closed", "created_at": "2020-03-09T17:46:04Z", "updated_at": "2020-09-10T20:00:22Z", "due_on": null, "closed_at": "2020-09-10T20:00:22Z"}, "comments": 2, "created_at": "2020-06-11T17:19:28Z", "updated_at": "2020-07-17T08:44:54Z", "closed_at": "2020-07-17T08:44:54Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The loss we write into tensorboard is the average loss over the epoch. So the first number we get is not averaged at all, while the last number in the epoch is averaged over the entire epoch. Then we start the second epoch, and the next value reported is just the loss of the first batch of the second epoch. As a result, we always see a big drop in loss when the epoch changes. This makes no sense.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4354/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4337", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4337/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4337/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4337/events", "html_url": "https://github.com/allenai/allennlp/issues/4337", "id": 633764491, "node_id": "MDU6SXNzdWU2MzM3NjQ0OTE=", "number": 4337, "title": "SRL predictor misses \"get\" verb.", "user": {"login": "ducalpha", "id": 3000864, "node_id": "MDQ6VXNlcjMwMDA4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/3000864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ducalpha", "html_url": "https://github.com/ducalpha", "followers_url": "https://api.github.com/users/ducalpha/followers", "following_url": "https://api.github.com/users/ducalpha/following{/other_user}", "gists_url": "https://api.github.com/users/ducalpha/gists{/gist_id}", "starred_url": "https://api.github.com/users/ducalpha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ducalpha/subscriptions", "organizations_url": "https://api.github.com/users/ducalpha/orgs", "repos_url": "https://api.github.com/users/ducalpha/repos", "events_url": "https://api.github.com/users/ducalpha/events{/privacy}", "received_events_url": "https://api.github.com/users/ducalpha/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-07T21:07:40Z", "updated_at": "2020-06-08T15:51:31Z", "closed_at": "2020-06-08T15:51:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "SRL Predictor only considers verbs with VERB Universal POS (https://github.com/allenai/allennlp-models/blob/master/allennlp_models/structured_prediction/predictors/srl.py#L108), but \"get\" commonly is tagged as AUX by Spacy. Therefore, the verb \"get\" in sentences is frequently ignored.\r\n\r\nHow to reproduce:\r\nTrying the following sentence on SRL demo (https://demo.allennlp.org/semantic-role-labeling) with Allennlp 1.0 RC5 and BERT SRL yields a dictionary with only \"go\" verb.\r\n\r\n\"we go to the party to get free food.\"\r\n\r\n```\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.structured_prediction.models.srl\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz\")\r\npredictor.predict(\r\n  sentence=\"we go to the party to get free food.\"\r\n)\r\n```\r\n\r\n(P.S. The usage on the demo web page is not updated to AllenNLP 1.0 RC5 but it should be filed on another bug.)", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4337/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4337/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4332", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4332/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4332/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4332/events", "html_url": "https://github.com/allenai/allennlp/issues/4332", "id": 632036763, "node_id": "MDU6SXNzdWU2MzIwMzY3NjM=", "number": 4332, "title": "Predict doesn't work for SNLI on 1.0.0rc5", "user": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 4, "created_at": "2020-06-05T22:57:21Z", "updated_at": "2020-06-11T16:52:09Z", "closed_at": "2020-06-11T16:52:09Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\r\n$ echo '{\"hypothesis\": \"Two women are sitting on a blanket near some rocks talking about politics.\", \"premise\": \"Two women are wandering along the shore drinking iced tea.\"}' | allennlp predict --predictor textual-entailment https://storage.googleapis.com/allennlp-public-models/snli-roberta-large-2020.04.30.tar.gz -\r\n2020-06-05 15:56:14,840 - INFO - transformers.file_utils - PyTorch version 1.5.0 available.\r\n2020-06-05 15:56:15,495 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/snli-roberta-large-2020.04.30.tar.gz from cache at /home/michaels/.allennlp/cache/589d6edb6a58b240ecd4c9fdbe356edf24cc1200ff1fb0c65835bfdc8b05ba1c.90841b7d888cf623f8ffdafbdd06a233a1fa2eb2f2ed42376f3cd690ecd49462\r\n2020-06-05 15:56:15,514 - INFO - allennlp.models.archival - extracting archive file /home/michaels/.allennlp/cache/589d6edb6a58b240ecd4c9fdbe356edf24cc1200ff1fb0c65835bfdc8b05ba1c.90841b7d888cf623f8ffdafbdd06a233a1fa2eb2f2ed42376f3cd690ecd49462 to temp dir /tmp/tmps6xeghmu\r\n2020-06-05 15:56:24,813 - INFO - allennlp.common.params - type = from_instances\r\n2020-06-05 15:56:24,814 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmps6xeghmu/vocabulary.\r\n2020-06-05 15:56:24,814 - INFO - allennlp.common.params - model.type = basic_classifier\r\n2020-06-05 15:56:24,814 - INFO - allennlp.common.params - model.regularizer = None\r\n2020-06-05 15:56:24,814 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\r\n2020-06-05 15:56:24,815 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer\r\n2020-06-05 15:56:24,815 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-large\r\n2020-06-05 15:56:24,815 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512\r\n2020-06-05 15:56:25,129 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:25,129 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:25,177 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /home/michaels/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\r\n2020-06-05 15:56:34,879 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:34,880 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:35,521 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:56:35,521 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:56:35,909 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:35,910 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:36,542 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:56:36,542 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:56:36,629 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\r\n2020-06-05 15:56:36,629 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 1024\r\n2020-06-05 15:56:36,629 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False\r\n2020-06-05 15:56:36,629 - INFO - allennlp.common.params - model.seq2seq_encoder = None\r\n2020-06-05 15:56:36,630 - INFO - allennlp.common.params - model.feedforward.input_dim = 1024\r\n2020-06-05 15:56:36,630 - INFO - allennlp.common.params - model.feedforward.num_layers = 1\r\n2020-06-05 15:56:36,630 - INFO - allennlp.common.params - model.feedforward.hidden_dims = 1024\r\n2020-06-05 15:56:36,630 - INFO - allennlp.common.params - model.feedforward.activations = tanh\r\n2020-06-05 15:56:36,630 - INFO - allennlp.common.params - type = tanh\r\n2020-06-05 15:56:36,630 - INFO - allennlp.common.params - model.feedforward.dropout = 0.0\r\n2020-06-05 15:56:36,636 - INFO - allennlp.common.params - model.dropout = 0.1\r\n2020-06-05 15:56:36,636 - INFO - allennlp.common.params - model.num_labels = None\r\n2020-06-05 15:56:36,637 - INFO - allennlp.common.params - model.label_namespace = labels\r\n2020-06-05 15:56:36,637 - INFO - allennlp.common.params - model.namespace = tags\r\n2020-06-05 15:56:36,637 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f8c862de050>\r\n2020-06-05 15:56:36,637 - INFO - allennlp.nn.initializers - Initializing parameters\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _classification_layer.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _classification_layer.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _feedforward._linear_layers.0.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _feedforward._linear_layers.0.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.type = snli\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.lazy = False\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.max_instances = None\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-large\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = None\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.truncation_strategy = longest_first\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None\r\n2020-06-05 15:56:38,053 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:38,054 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:38,680 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:56:38,680 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:56:39,086 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:39,087 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:39,717 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:56:39,718 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:56:39,797 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer\r\n2020-06-05 15:56:39,797 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0\r\n2020-06-05 15:56:39,798 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-large\r\n2020-06-05 15:56:39,798 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags\r\n2020-06-05 15:56:39,798 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512\r\n2020-06-05 15:56:40,092 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:40,093 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:40,779 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:56:40,780 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:56:41,177 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:41,178 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:41,931 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:56:41,932 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:56:42,014 - INFO - allennlp.common.params - dataset_reader.combine_input_fields = None\r\nTraceback (most recent call last):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 197, in _predict\r\n    predictor = _get_predictor(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 102, in _get_predictor\r\n    archive, args.predictor, dataset_reader_to_load=args.dataset_reader_choice\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 294, in from_archive\r\n    dataset_reader = DatasetReader.from_params(dataset_reader_params)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 611, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp_models/pair_classification/dataset_readers/snli.py\", line 51, in __init__\r\n    assert not self._tokenizer._add_special_tokens\r\nAssertionError\r\n2020-06-05 15:56:42,015 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmps6xeghmu\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4332/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4332/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4331", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4331/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4331/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4331/events", "html_url": "https://github.com/allenai/allennlp/issues/4331", "id": 632035151, "node_id": "MDU6SXNzdWU2MzIwMzUxNTE=", "number": 4331, "title": "Predict doesn't work for Roberta MNLI on 1.0.0rc5", "user": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 7, "created_at": "2020-06-05T22:54:31Z", "updated_at": "2020-06-11T19:03:03Z", "closed_at": "2020-06-11T16:52:18Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\r\n$ echo '{\"hypothesis\": \"Two women are sitting on a blanket near some rocks talking about politics.\", \"premise\": \"Two women are wandering along the shore drinking iced tea.\"}' | allennlp predict --predictor textual-entailment https://storage.googleapis.com/allennlp-public-models/mnli-roberta-large-2020.05.13.tar.gz -\r\n2020-06-05 15:53:08,894 - INFO - transformers.file_utils - PyTorch version 1.5.0 available.\r\n2020-06-05 15:53:09,595 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/mnli-roberta-large-2020.05.13.tar.gz from cache at /home/michaels/.allennlp/cache/6464891350f0d2a96fed729f770a3c95cfdcdfac243c7a016377c0ded406e599.128e3323e8512d3bdda5113ef51fa10fa25624d0213c5c73445832a2f73916f3\r\n2020-06-05 15:53:09,596 - INFO - allennlp.models.archival - extracting archive file /home/michaels/.allennlp/cache/6464891350f0d2a96fed729f770a3c95cfdcdfac243c7a016377c0ded406e599.128e3323e8512d3bdda5113ef51fa10fa25624d0213c5c73445832a2f73916f3 to temp dir /tmp/tmp20uyprv6\r\n2020-06-05 15:53:18,719 - INFO - allennlp.common.params - type = from_instances\r\n2020-06-05 15:53:18,719 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp20uyprv6/vocabulary.\r\n2020-06-05 15:53:18,720 - INFO - allennlp.common.params - model.type = basic_classifier\r\n2020-06-05 15:53:18,720 - INFO - allennlp.common.params - model.regularizer = None\r\n2020-06-05 15:53:18,720 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\r\n2020-06-05 15:53:18,720 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer\r\n2020-06-05 15:53:18,721 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-large\r\n2020-06-05 15:53:18,721 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512\r\n2020-06-05 15:53:19,042 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:19,043 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:19,625 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /home/michaels/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\r\n2020-06-05 15:53:29,290 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:29,291 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:29,904 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:53:29,905 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:53:30,290 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:30,291 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:30,915 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:53:30,916 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 1024\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.seq2seq_encoder = None\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.feedforward.input_dim = 1024\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.feedforward.num_layers = 1\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.feedforward.hidden_dims = 1024\r\n2020-06-05 15:53:31,006 - INFO - allennlp.common.params - model.feedforward.activations = tanh\r\n2020-06-05 15:53:31,006 - INFO - allennlp.common.params - type = tanh\r\n2020-06-05 15:53:31,006 - INFO - allennlp.common.params - model.feedforward.dropout = 0.0\r\n2020-06-05 15:53:31,012 - INFO - allennlp.common.params - model.dropout = 0.1\r\n2020-06-05 15:53:31,012 - INFO - allennlp.common.params - model.num_labels = None\r\n2020-06-05 15:53:31,012 - INFO - allennlp.common.params - model.label_namespace = labels\r\n2020-06-05 15:53:31,012 - INFO - allennlp.common.params - model.namespace = tags\r\n2020-06-05 15:53:31,012 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fa4abe41f50>\r\n2020-06-05 15:53:31,012 - INFO - allennlp.nn.initializers - Initializing parameters\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _classification_layer.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _classification_layer.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _feedforward._linear_layers.0.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _feedforward._linear_layers.0.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias\r\n2020-06-05 15:53:31,023 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight\r\n2020-06-05 15:53:31,023 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias\r\n2020-06-05 15:53:31,023 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight\r\n2020-06-05 15:53:32,133 - INFO - allennlp.common.params - dataset_reader.type = snli\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.lazy = False\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.max_instances = None\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-large\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = None\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.truncation_strategy = longest_first\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None\r\n2020-06-05 15:53:32,437 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:32,438 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:33,058 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:53:33,058 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:53:33,440 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:33,441 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:34,073 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:53:34,074 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:53:34,153 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer\r\n2020-06-05 15:53:34,154 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0\r\n2020-06-05 15:53:34,154 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-large\r\n2020-06-05 15:53:34,154 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags\r\n2020-06-05 15:53:34,154 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512\r\n2020-06-05 15:53:35,462 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:35,463 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:36,086 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:53:36,087 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:53:36,505 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:36,506 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:37,181 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:53:37,181 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:53:37,310 - INFO - allennlp.common.params - dataset_reader.combine_input_fields = None\r\nTraceback (most recent call last):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 197, in _predict\r\n    predictor = _get_predictor(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 102, in _get_predictor\r\n    archive, args.predictor, dataset_reader_to_load=args.dataset_reader_choice\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 294, in from_archive\r\n    dataset_reader = DatasetReader.from_params(dataset_reader_params)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 611, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp_models/pair_classification/dataset_readers/snli.py\", line 51, in __init__\r\n    assert not self._tokenizer._add_special_tokens\r\nAssertionError\r\n2020-06-05 15:53:37,312 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp20uyprv6\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4331/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4331/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4330", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4330/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4330/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4330/events", "html_url": "https://github.com/allenai/allennlp/issues/4330", "id": 632013863, "node_id": "MDU6SXNzdWU2MzIwMTM4NjM=", "number": 4330, "title": "Transformer tokenizers cause deadlocks when dataset reader is lazy and dataloader num_workers > 0", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/12", "html_url": "https://github.com/allenai/allennlp/milestone/12", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/12/labels", "id": 5445272, "node_id": "MDk6TWlsZXN0b25lNTQ0NTI3Mg==", "number": 12, "title": "Performance", "description": "We have a strong commitment to improve the training time of at least 3 of or models by 50%.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 10, "state": "closed", "created_at": "2020-05-20T21:04:27Z", "updated_at": "2020-09-02T16:26:40Z", "due_on": "2020-08-01T07:00:00Z", "closed_at": "2020-09-02T16:26:40Z"}, "comments": 8, "created_at": "2020-06-05T22:18:19Z", "updated_at": "2020-07-09T18:50:13Z", "closed_at": "2020-07-09T18:50:13Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nDataset readers that use a `PretrainedTransformerTokenizer` can cause a deadlock when used lazily and with `num_workers > 0` in the `Dataloader`.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n...\r\n2020-06-05 15:04:14,980 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1\r\n2020-06-05 15:04:14,980 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False\r\n2020-06-05 15:04:14,980 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False\r\n2020-06-05 15:04:14,980 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38\r\n2020-06-05 15:04:14,982 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\r\n2020-06-05 15:04:14,982 - INFO - allennlp.training.trainer - Beginning training.\r\n2020-06-05 15:04:14,982 - INFO - allennlp.training.trainer - Epoch 0/9\r\n2020-06-05 15:04:14,982 - INFO - allennlp.training.trainer - Worker 0 memory usage MB: 3119.212\r\n2020-06-05 15:04:14,989 - INFO - allennlp.common.file_utils - checking cache for https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_dev.jsonl at /home/epwalsh/.allennlp/cache/144d0e8739288dbcde80c238baf94dde44c4ed58da59c92cf48ccce5b649574a.07ccd1720fbe07137833cd627398fb7e2687bdcbad963d71cae8c97a37f76687\r\n2020-06-05 15:04:14,989 - INFO - allennlp.common.file_utils - waiting to acquire lock on /home/epwalsh/.allennlp/cache/144d0e8739288dbcde80c238baf94dde44c4ed58da59c92cf48ccce5b649574a.07ccd1720fbe07137833cd627398fb7e2687bdcbad963d71cae8c97a37f76687\r\n2020-06-05 15:04:14,989 - INFO - filelock - Lock 140643240348696 acquired on /home/epwalsh/.allennlp/cache/144d0e8739288dbcde80c238baf94dde44c4ed58da59c92cf48ccce5b649574a.07ccd1720fbe07137833cd627398fb7e2687bdcbad963d71cae8c97a37f76687.lock\r\n2020-06-05 15:04:14,989 - INFO - allennlp.common.file_utils - cache of https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_dev.jsonl is up-to-date\r\n2020-06-05 15:04:14,989 - INFO - filelock - Lock 140643240348696 released on /home/epwalsh/.allennlp/cache/144d0e8739288dbcde80c238baf94dde44c4ed58da59c92cf48ccce5b649574a.07ccd1720fbe07137833cd627398fb7e2687bdcbad963d71cae8c97a37f76687.lock\r\n2020-06-05 15:04:14,990 - INFO - allennlp_models.pair_classification.dataset_readers.snli - Reading SNLI instances from jsonl dataset at: /home/epwalsh/.allennlp/cache/144d0e8739288dbcde80c238baf94dde44c4ed58da59c92cf48ccce5b649574a.07ccd1720fbe07137833cd627398fb7e2687bdcbad963d71cae8c97a37f76687\r\n2020-06-05 15:04:15,010 - INFO - allennlp.common.file_utils - checking cache for https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl at /home/epwalsh/.allennlp/cache/321a276d553780889b3d4276a1ce372c54c405f8e57917cdfa993feb5a0783a2.02752124e6570073d50876f7f66a32191d9787dcb992c56e79f558cebf5faf92\r\n2020-06-05 15:04:15,011 - INFO - allennlp.common.file_utils - waiting to acquire lock on /home/epwalsh/.allennlp/cache/321a276d553780889b3d4276a1ce372c54c405f8e57917cdfa993feb5a0783a2.02752124e6570073d50876f7f66a32191d9787dcb992c56e79f558cebf5faf92\r\n2020-06-05 15:04:15,011 - INFO - filelock - Lock 140642731300176 acquired on /home/epwalsh/.allennlp/cache/321a276d553780889b3d4276a1ce372c54c405f8e57917cdfa993feb5a0783a2.02752124e6570073d50876f7f66a32191d9787dcb992c56e79f558cebf5faf92.lock\r\n2020-06-05 15:04:15,011 - INFO - allennlp.common.file_utils - cache of https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl is up-to-date\r\n2020-06-05 15:04:15,011 - INFO - filelock - Lock 140642731300176 released on /home/epwalsh/.allennlp/cache/321a276d553780889b3d4276a1ce372c54c405f8e57917cdfa993feb5a0783a2.02752124e6570073d50876f7f66a32191d9787dcb992c56e79f558cebf5faf92.lock\r\n2020-06-05 15:04:15,011 - INFO - allennlp_models.pair_classification.dataset_readers.snli - Reading SNLI instances from jsonl dataset at: /home/epwalsh/.allennlp/cache/321a276d553780889b3d4276a1ce372c54c405f8e57917cdfa993feb5a0783a2.02752124e6570073d50876f7f66a32191d9787dcb992c56e79f558cebf5faf92\r\n2020-06-05 15:04:15,026 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 29\r\n2020-06-05 15:04:15,031 - INFO - allennlp.training.trainer - Training\r\n2020-06-05 15:04:15,133 - INFO - allennlp.common.file_utils - checking cache for https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl at /home/epwalsh/.allennlp/cache/e00019e4314663e308d583b0fce3b28548b1935143669947b5642779f366dce0.a6d9333199c8569c358962009242171183a893a532b6a5267c91fd3ea0ca6484\r\n2020-06-05 15:04:15,133 - INFO - allennlp.common.file_utils - waiting to acquire lock on /home/epwalsh/.allennlp/cache/e00019e4314663e308d583b0fce3b28548b1935143669947b5642779f366dce0.a6d9333199c8569c358962009242171183a893a532b6a5267c91fd3ea0ca6484\r\n2020-06-05 15:04:15,134 - INFO - filelock - Lock 140642730869648 acquired on /home/epwalsh/.allennlp/cache/e00019e4314663e308d583b0fce3b28548b1935143669947b5642779f366dce0.a6d9333199c8569c358962009242171183a893a532b6a5267c91fd3ea0ca6484.lock\r\n2020-06-05 15:04:15,134 - INFO - allennlp.common.file_utils - cache of https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl is up-to-date\r\n2020-06-05 15:04:15,134 - INFO - filelock - Lock 140642730869648 released on /home/epwalsh/.allennlp/cache/e00019e4314663e308d583b0fce3b28548b1935143669947b5642779f366dce0.a6d9333199c8569c358962009242171183a893a532b6a5267c91fd3ea0ca6484.lock\r\n2020-06-05 15:04:15,134 - INFO - allennlp_models.pair_classification.dataset_readers.snli - Reading SNLI instances from jsonl dataset at: /home/epwalsh/.allennlp/cache/e00019e4314663e308d583b0fce3b28548b1935143669947b5642779f366dce0.a6d9333199c8569c358962009242171183a893a532b6a5267c91fd3ea0ca6484\r\n# hangs forever here\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- I'm pretty sure this has to do with https://github.com/huggingface/tokenizers/issues/187\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 18.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.6.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp==3.6.2\r\nalabaster==0.7.11\r\n-e git+git@github.com:epwalsh/allennlp.git@902d36a520dd75fd82ebaa014799ed8fa6d02e2e#egg=allennlp\r\n-e git+git@github.com:allenai/allennlp-beaker.git@d3afc6e23ae22ea434aff6b9296f9d6e17fc2b45#egg=allennlp_beaker\r\n-e git+git@github.com:allenai/allennlp-models.git@efe66bc086c95a78c7779933b82e1382b63a3ee1#egg=allennlp_models\r\napex==0.1\r\nappdirs==1.4.3\r\nargh==0.26.2\r\nasn1crypto==0.24.0\r\naspy.yaml==1.3.0\r\nastroid==2.3.0\r\nasync-timeout==3.0.0\r\natomicwrites==1.1.5\r\nattrs==19.3.0\r\naws-xray-sdk==0.95\r\nawscli==1.18.40\r\nBabel==2.6.0\r\nbackcall==0.1.0\r\nblack==19.10b0\r\nbleach==2.1.3\r\nblis==0.4.1\r\nboto==2.49.0\r\nboto3==1.13.16\r\nbotocore==1.16.16\r\ncatalogue==1.0.0\r\ncattrs==0.9.0\r\ncertifi==2020.4.5.1\r\ncffi==1.11.5\r\ncfgv==2.0.1\r\nchardet==3.0.4\r\nclick==7.1.2\r\nclick-completion==0.5.0\r\nclick-spinner==0.1.10\r\ncodecov==2.1.3\r\ncolorama==0.3.9\r\nconllu==3.0\r\ncookies==2.2.1\r\ncoverage==5.1\r\ncoveralls==1.5.1\r\ncrayons==0.1.2\r\ncryptography==2.3.1\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ncytoolz==0.9.0.1\r\ndash==1.5.1\r\ndash-auth==1.3.2\r\ndash-bootstrap-components==0.7.2\r\ndash-core-components==1.4.0\r\ndash-daq==0.1.4\r\ndash-html-components==1.0.1\r\ndash-renderer==1.2.0\r\ndash-table==4.5.0\r\ndataclasses==0.7\r\ndecorator==4.3.0\r\ndill==0.2.8.2\r\ndocker==3.5.0\r\ndocker-pycreds==0.3.0\r\ndocopt==0.6.2\r\ndocutils==0.15.2\r\necdsa==0.13\r\neditdistance==0.4\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nentrypoints==0.3\r\nfilelock==3.0.12\r\nflake8==3.8.1\r\nflaky==3.6.1\r\nFlask==1.0.2\r\nFlask-Caching==1.7.2\r\nFlask-Compress==1.4.0\r\nFlask-Cors==3.0.7\r\nFlask-Login==0.4.1\r\nFlask-SeaSurf==0.2.2\r\nftfy==5.5.0\r\nfuture==0.18.2\r\ngevent==1.3.6\r\ngreenlet==0.4.14\r\ngunicorn==19.9.0\r\nh5py==2.10.0\r\nhide-code==0.5.2\r\nhtml5lib==1.0.1\r\nidentify==1.4.7\r\nidna==2.9\r\nidna-ssl==1.1.0\r\nimagesize==1.0.0\r\nimportlib-metadata==1.6.0\r\nimportlib-resources==1.0.2\r\ninotify==0.2.10\r\nipykernel==4.8.2\r\nipython==6.5.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.4.0\r\nisort==4.3.4\r\nitsdangerous==0.24\r\njedi==0.16.0\r\njeepney==0.4.3\r\nJinja2==2.11.1\r\njmespath==0.10.0\r\njoblib==0.15.1\r\njsondiff==1.1.1\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==2.6.0\r\njupyter==1.0.0\r\njupyter-client==5.2.3\r\njupyter-console==5.2.0\r\njupyter-contrib-core==0.3.3\r\njupyter-core==4.4.0\r\njupyter-nbextensions-configurator==0.4.0\r\nkeyring==21.2.1\r\nkiwisolver==1.0.1\r\nlazy-object-proxy==1.3.1                                                                                                                                                                                  \r\nlivereload==2.5.2\r\nlunr==0.5.6\r\nMarkdown==3.2.1\r\nmarkdown-include==0.5.1\r\nMarkupSafe==1.0\r\nmathy-pydoc==0.6.7\r\nmatplotlib==3.2.1\r\nmccabe==0.6.1\r\nmistune==0.8.3\r\nmkdocs==1.1\r\nmkdocs-material==5.2.0\r\nmkdocs-material-extensions==1.0\r\nmock==2.0.0\r\nmore-itertools==8.3.0\r\nmoto==1.3.4\r\nmsgpack==0.5.6\r\nmsgpack-numpy==0.4.3.1\r\nmultidict==4.7.6\r\nmurmurhash==1.0.2\r\nmypy==0.770\r\nmypy-extensions==0.4.3\r\nnbconvert==5.3.1\r\nnbformat==4.4.0\r\nneovim==0.2.6\r\n-e git+git@github.com:epwalsh/nlp-models.git@23232ea470503e5a6453aca2bb9a22b84de6848d#egg=nlpete\r\nnltk==3.5\r\nnodeenv==1.3.3\r\nnose==1.3.7\r\nnotebook==5.6.0\r\nnr.collections==0.0.1\r\nnr.databind==0.0.4\r\nnr.databind.core==0.0.14\r\nnr.databind.json==0.0.9\r\nnr.interface==0.0.2\r\nnr.metaclass==0.0.5\r\nnr.parsing.date==0.1.0\r\nnr.pylang.utils==0.0.2\r\nnr.stream==0.0.3\r\nnumpy==1.18.4\r\nnumpydoc==0.8.0\r\nnvidia-ml-py3==7.352.0\r\noverrides==3.0.0\r\npackaging==20.4\r\npandocfilters==1.4.2\r\nparsimonious==0.8.0\r\nparso==0.6.2\r\npathspec==0.7.0\r\npathtools==0.1.2\r\npbr==4.2.0\r\npdfkit==0.6.1\r\npexpect==4.6.0\r\npickleshare==0.7.4\r\npkg-resources==0.0.0\r\npkginfo==1.4.2\r\nplac==1.1.3\r\nplotly==4.2.1                                                                                                                                                                                               [50/1861]\r\npluggy==0.13.1\r\nport-for==0.3.1\r\npre-commit==2.3.0\r\npreshed==3.0.2\r\nprometheus-client==0.3.1\r\nprompt-toolkit==1.0.15\r\nprotobuf==3.12.1\r\nptyprocess==0.6.0\r\npy==1.8.1\r\npy-rouge==1.1\r\npy3nvml==0.2.5\r\npyaml==17.12.1\r\npyasn1==0.4.4\r\npycodestyle==2.6.0\r\npycparser==2.18\r\npycryptodome==3.6.5\r\npycycle==0.0.8\r\npydoc-markdown @ git+https://github.com/NiklasRosenstein/pydoc-markdown.git@f0bf8af1db4f11581c19d206d4ed1ab34b4854c1\r\npydocstyle==5.0.2\r\npyflakes==2.2.0\r\nPygments==2.5.2\r\npylint==2.4.1\r\npymdown-extensions==7.0\r\npypandoc==1.4\r\npyparsing==2.4.7\r\npytest==5.4.2\r\npytest-cov==2.8.1\r\npython-dateutil==2.8.1\r\npython-jose==2.0.2\r\npytorch-pretrained-bert==0.6.1\r\npytz==2017.3\r\nPyYAML==5.3\r\npyzmq==17.1.2\r\nqtconsole==4.3.1\r\nreadme-renderer==26.0\r\nregex==2020.5.14\r\nregistrable==0.0.1\r\nrequests==2.23.0\r\nrequests-toolbelt==0.8.0\r\nresponses==0.10.14\r\nretrying==1.3.3\r\nrsa==3.4.2\r\nruamel.yaml==0.16.10\r\nruamel.yaml.clib==0.2.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.4.1\r\nSecretStorage==3.1.2\r\nsemantic-version==2.8.5\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nshellingham==1.2.8\r\nsimplegeneric==0.8.1\r\nsix==1.15.0\r\nsnowballstemmer==1.2.1\r\nspacy==2.2.4\r\nSphinx==2.2.0\r\nsphinx-autobuild==0.7.1\r\nsphinx-rtd-theme==0.4.1\r\nsphinxcontrib-applehelp==1.0.1\r\nsphinxcontrib-devhelp==1.0.1\r\nsphinxcontrib-htmlhelp==1.0.2\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.2\r\nsphinxcontrib-serializinghtml==1.1.3\r\nsqlparse==0.2.4\r\nsrsly==1.0.2\r\ntensorboardX==2.0\r\nterminado==0.8.1\r\ntestpath==0.3.1\r\nthinc==7.4.0\r\nthreadpoolctl==2.0.0\r\ntokenizers==0.7.0\r\ntoml==0.10.0\r\ntoolz==0.9.0\r\ntorch==1.5.0\r\ntornado==5.1\r\ntqdm==4.46.1\r\ntraitlets==4.3.2\r\ntransformers==2.9.1\r\ntwine==3.1.1\r\ntyped-ast==1.4.0\r\ntyping==3.7.4.1\r\ntyping-extensions==3.7.4\r\nua-parser==0.8.0\r\nujson==1.35\r\nUnidecode==1.0.22\r\nurllib3==1.25.9\r\nvirtualenv==16.7.5\r\nwasabi==0.6.0\r\nwatchdog==0.10.2\r\nwcwidth==0.1.9\r\nwebencodings==0.5.1\r\nwebsocket-client==0.49.0\r\nWerkzeug==0.14.1\r\nwidgetsnbextension==3.4.0\r\nword2number==1.1\r\nwrapt==1.10.11\r\nxmltodict==0.11.0\r\nyarl==1.2.6\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nRun `allennlp train` on this config:\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```jsonnet\r\nlocal transformer_model = \"roberta-large\";\r\nlocal transformer_dim = 1024;\r\nlocal cls_is_last_token = false;\r\n\r\n{\r\n  \"dataset_reader\":{\r\n    \"type\": \"snli\",\r\n    \"lazy\": true,\r\n    \"tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": transformer_model,\r\n      \"add_special_tokens\": false\r\n    },\r\n    \"token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": transformer_model,\r\n        \"max_length\": 40\r\n      }\r\n    }\r\n  },\r\n  \"train_data_path\": \"https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\",\r\n  \"validation_data_path\": \"https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_dev.jsonl\",\r\n  \"test_data_path\": \"https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\",\r\n  \"model\": {\r\n    \"type\": \"basic_classifier\",\r\n    \"text_field_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer\",\r\n          \"model_name\": transformer_model,\r\n          \"max_length\": 512\r\n        }\r\n      }\r\n    },\r\n    \"seq2vec_encoder\": {\r\n       \"type\": \"cls_pooler\",\r\n       \"embedding_dim\": transformer_dim,\r\n       \"cls_is_last_token\": cls_is_last_token\r\n    },\r\n    \"feedforward\": {\r\n      \"input_dim\": transformer_dim,\r\n      \"num_layers\": 1,\r\n      \"hidden_dims\": transformer_dim,\r\n      \"activations\": \"tanh\"\r\n    },\r\n    \"dropout\": 0.1,\r\n    \"namespace\": \"tags\"\r\n  },\r\n  \"data_loader\": {\r\n    \"batch_size\" : 8,\r\n    \"num_workers\": true,\r\n  },\r\n  \"trainer\": {\r\n    \"num_epochs\": 10,\r\n    \"cuda_device\" : -1,\r\n    \"validation_metric\": \"+accuracy\",\r\n    \"learning_rate_scheduler\": {\r\n      \"type\": \"slanted_triangular\",\r\n      \"cut_frac\": 0.06\r\n    },\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"lr\": 2e-5,\r\n      \"weight_decay\": 0.1,\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4330/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4330/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4325", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4325/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4325/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4325/events", "html_url": "https://github.com/allenai/allennlp/issues/4325", "id": 631556515, "node_id": "MDU6SXNzdWU2MzE1NTY1MTU=", "number": 4325, "title": "OpenIE demo not working with 1.0.0rc5", "user": {"login": "FelixLabelle", "id": 23347756, "node_id": "MDQ6VXNlcjIzMzQ3NzU2", "avatar_url": "https://avatars.githubusercontent.com/u/23347756?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FelixLabelle", "html_url": "https://github.com/FelixLabelle", "followers_url": "https://api.github.com/users/FelixLabelle/followers", "following_url": "https://api.github.com/users/FelixLabelle/following{/other_user}", "gists_url": "https://api.github.com/users/FelixLabelle/gists{/gist_id}", "starred_url": "https://api.github.com/users/FelixLabelle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FelixLabelle/subscriptions", "organizations_url": "https://api.github.com/users/FelixLabelle/orgs", "repos_url": "https://api.github.com/users/FelixLabelle/repos", "events_url": "https://api.github.com/users/FelixLabelle/events{/privacy}", "received_events_url": "https://api.github.com/users/FelixLabelle/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-05T12:34:26Z", "updated_at": "2020-06-05T16:01:37Z", "closed_at": "2020-06-05T16:01:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n\r\nI'm trying to run the [OpenIE demo](https://demo.allennlp.org/open-information-extraction) with a more recent release (1.0.0rc5 instead of 1.0.0rc3). There appears to have been a change in the layout of the AllenNLP modules (syntax no longer exists).\r\n\r\nOriginally I got an error to that effect and checked the layout of the files. I replaced \"import allennlp_models.syntax.srl\" with \"allennlp_models.structured_prediction.predictors.srl\", but now get the second error listed below. I'm not familiar with the design of this API, so I figured I would ask what the correct import before going further.\r\n\r\n<details>\r\n<summary><b>Original traceback:</b></summary>\r\n<p>\r\nTraceback (most recent call last):\r\n  File \"qa_models.py\", line 4, in <module>\r\n    import allennlp_models.syntax.srl\r\nModuleNotFoundError: No module named 'allennlp_models.syntax'\r\n\r\n</p>\r\n</details>\r\n\r\n<details>\r\n<summary><b>Latest traceback:</b></summary>\r\n<p>\r\nTraceback (most recent call last):\r\n  File \"qa_models.py\", line 41, in <module>\r\n    main(args)\r\n  File \"qa_models.py\", line 31, in main\r\n    prediction = predictor.prediction(register[-5])\r\nAttributeError: 'SemanticRoleLabelerPredictor' object has no attribute 'prediction'\r\n</p>\r\n</details>\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\nOS: Ubuntu 18.04\r\n\r\nPython version: Python 3.7.3\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\nUsing allennlp 1.0.0rc5 run the demo code.\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4325/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4325/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4324", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4324/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4324/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4324/events", "html_url": "https://github.com/allenai/allennlp/issues/4324", "id": 631415013, "node_id": "MDU6SXNzdWU2MzE0MTUwMTM=", "number": 4324, "title": "Upper limit on dependencies versions", "user": {"login": "jankrepl", "id": 18519371, "node_id": "MDQ6VXNlcjE4NTE5Mzcx", "avatar_url": "https://avatars.githubusercontent.com/u/18519371?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jankrepl", "html_url": "https://github.com/jankrepl", "followers_url": "https://api.github.com/users/jankrepl/followers", "following_url": "https://api.github.com/users/jankrepl/following{/other_user}", "gists_url": "https://api.github.com/users/jankrepl/gists{/gist_id}", "starred_url": "https://api.github.com/users/jankrepl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jankrepl/subscriptions", "organizations_url": "https://api.github.com/users/jankrepl/orgs", "repos_url": "https://api.github.com/users/jankrepl/repos", "events_url": "https://api.github.com/users/jankrepl/events{/privacy}", "received_events_url": "https://api.github.com/users/jankrepl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-05T08:33:10Z", "updated_at": "2020-06-05T15:49:10Z", "closed_at": "2020-06-05T15:49:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "Similar issues:\r\n\r\n- #2650\r\n\r\nI was wondering why do you quite often limit the upper version of your dependencies. See below a list of all examples from the current `setup.py`\r\n\r\n- `\"torch>=1.5.0,<1.6.0\"`\r\n- `\"spacy>=2.1.0,<2.3\"`\r\n- `\"transformers>=2.9,<2.12\"`\r\n- `\"filelock>=3.0,<3.1\"`\r\n\r\nAre you just afraid that the future versions of these packages are going to break `allennlp`? Or you already somehow know they will be incompatible?\r\n\r\nIn my case, I am encountering a lot of issues because of this strategy. I want to use an older version `allennlp==0.9.0` however there you assert `'spacy>=2.1.0,<2.2'`. My other dependencies, however, require more recent `spacy>2.2`.\r\n\r\nThanks for your response!", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4324/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4324/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4322", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4322/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4322/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4322/events", "html_url": "https://github.com/allenai/allennlp/issues/4322", "id": 631154490, "node_id": "MDU6SXNzdWU2MzExNTQ0OTA=", "number": 4322, "title": "Cannot predict with NAQANET on 1.0.0rc5", "user": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 3, "created_at": "2020-06-04T21:18:37Z", "updated_at": "2020-06-12T16:54:01Z", "closed_at": "2020-06-12T16:54:01Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\r\necho '{\"passage\": \"The Matrix is a 1999 science fiction action film written and directed by The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\", \"question\": \"Who stars in The Matrix?\"}' | allennlp predict https://storage.googleapis.com/allennlp-public-models/naqanet-2020.02.19.tar.gz -\r\n\r\n...\r\n\r\n2020-06-04 14:17:42,669 - INFO - transformers.file_utils - PyTorch version 1.5.0 available.\r\n2020-06-04 14:17:43,325 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/naqanet-2020.02.19.tar.gz from cache at /home/michaels/.allennlp/cache/7a9f9036e6aece092be73634db952aed5f466b304b316ad42498404e9553071d.a70ea31258e5d77abb9aca4f2b160e004991c57f41ea30a877774c9e97798e42\r\n2020-06-04 14:17:43,326 - INFO - allennlp.models.archival - extracting archive file /home/michaels/.allennlp/cache/7a9f9036e6aece092be73634db952aed5f466b304b316ad42498404e9553071d.a70ea31258e5d77abb9aca4f2b160e004991c57f41ea30a877774c9e97798e42 to temp dir /tmp/tmpbzru1koa\r\n2020-06-04 14:17:43,720 - INFO - allennlp.common.params - vocabulary.type = from_instances\r\n2020-06-04 14:17:43,720 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpbzru1koa/vocabulary.\r\n2020-06-04 14:17:43,741 - INFO - allennlp.common.params - model.type = naqanet\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.type = character_encoding\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 64\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.weight = None\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None\r\n2020-06-04 14:17:43,743 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn\r\n2020-06-04 14:17:43,743 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 64\r\n2020-06-04 14:17:43,743 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 200\r\n2020-06-04 14:17:43,743 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [5]\r\n2020-06-04 14:17:43,743 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = None\r\n2020-06-04 14:17:43,743 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None\r\n2020-06-04 14:17:43,744 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0\r\n2020-06-04 14:17:43,744 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = embedding\r\n2020-06-04 14:17:43,744 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.embedding_dim = 300\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.num_embeddings = None\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.projection_dim = None\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.weight = None\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.padding_index = None\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.trainable = False\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_norm = None\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.norm_type = 2.0\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.scale_grad_by_freq = False\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sparse = False\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.vocab_namespace = tokens\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.pretrained_file = None\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.num_highway_layers = 2\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.type = qanet_encoder\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.input_dim = 128\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.hidden_dim = 128\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.attention_projection_dim = 128\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.feedforward_hidden_dim = 128\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.num_blocks = 1\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.num_convs_per_block = 4\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.conv_kernel_size = 7\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.num_attention_heads = 8\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.use_positional_encoding = True\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.dropout_prob = 0.1\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.layer_dropout_undecayed_prob = 0.1\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.attention_dropout_prob = 0\r\n2020-06-04 14:17:43,823 - INFO - allennlp.common.params - model.matrix_attention_layer.type = linear\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.matrix_attention_layer.tensor_1_dim = 128\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.matrix_attention_layer.tensor_2_dim = 128\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.matrix_attention_layer.combination = x,y,x*y\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.matrix_attention_layer.activation = None\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.type = qanet_encoder\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.input_dim = 128\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.hidden_dim = 128\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.attention_projection_dim = 128\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.feedforward_hidden_dim = 128\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.num_blocks = 6\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.num_convs_per_block = 2\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.conv_kernel_size = 5\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.num_attention_heads = 8\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.use_positional_encoding = True\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.dropout_prob = 0.1\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.layer_dropout_undecayed_prob = 0.1\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.attention_dropout_prob = 0\r\n2020-06-04 14:17:43,835 - INFO - allennlp.common.params - model.dropout_prob = 0.1\r\n2020-06-04 14:17:43,836 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f3603701ad0>\r\n2020-06-04 14:17:43,836 - INFO - allennlp.common.params - model.regularizer.regexes.0.1.type = l2\r\n2020-06-04 14:17:43,836 - INFO - allennlp.common.params - model.regularizer.regexes.0.1.alpha = 1e-07\r\n2020-06-04 14:17:43,836 - INFO - allennlp.common.params - model.answering_abilities = ['passage_span_extraction', 'question_span_extraction', 'addition_subtraction', 'counting']\r\n2020-06-04 14:17:43,841 - INFO - allennlp.nn.initializers - Initializing parameters\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _embedding_proj_layer.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _embedding_proj_layer.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _encoding_proj_layer.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _encoding_proj_layer.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _highway_layer._layers.0.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _highway_layer._layers.0.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _highway_layer._layers.1.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _highway_layer._layers.1.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _matrix_attention._bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _matrix_attention._weight_vector\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.attention_norm_layer.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.attention_norm_layer.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.attention_norm_layer.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.attention_norm_layer.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.attention_norm_layer.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.attention_norm_layer.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.attention_norm_layer.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.attention_norm_layer.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.attention_norm_layer.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.attention_norm_layer.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.attention_norm_layer.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.attention_norm_layer.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_proj_layer.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_proj_layer.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_weights_predictor.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_weights_predictor.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.2.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.2.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.2.2.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.2.2.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.3.1.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.3.1.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.3.2.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.3.2.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.2.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.2.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.3.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.3.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.attention_norm_layer.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.attention_norm_layer.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_weights_predictor.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_weights_predictor.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_token_characters._embedding._module.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.weight\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.type = drop\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.cache_directory = None\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.manual_distributed_sharding = False\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer = None\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.type = characters\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.namespace = token_characters\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.character_tokenizer = <allennlp.data.tokenizers.character_tokenizer.CharacterTokenizer object at 0x7f360b8897d0>\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.start_tokens = None\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.end_tokens = None\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.min_padding_length = 5\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.token_min_padding_length = 0\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = single_id\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tokens\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.lowercase_tokens = True\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.start_tokens = None\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.end_tokens = None\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.feature_name = text\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.passage_length_limit = 1000\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.question_length_limit = 100\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.skip_when_all_empty = []\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.instance_format = drop\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.relaxed_span_match_for_finding_labels = True\r\nTraceback (most recent call last):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 212, in _predict\r\n    manager.run()\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 186, in run\r\n    for model_input_json, result in zip(batch_json, self._predict_json(batch_json)):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 132, in _predict_json\r\n    results = [self._predictor.predict_json(batch_data[0])]\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 47, in predict_json\r\n    instance = self._json_to_instance(inputs)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 195, in _json_to_instance\r\n    raise NotImplementedError\r\nNotImplementedError\r\n2020-06-04 14:17:44,276 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpbzru1koa\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4322/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4322/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4321", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4321/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4321/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4321/events", "html_url": "https://github.com/allenai/allennlp/issues/4321", "id": 631153622, "node_id": "MDU6SXNzdWU2MzExNTM2MjI=", "number": 4321, "title": "Cannot predict with TransformerQA on 1.0.0rc5", "user": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 7, "created_at": "2020-06-04T21:17:02Z", "updated_at": "2020-06-12T16:54:04Z", "closed_at": "2020-06-12T16:54:04Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\r\n$ echo '{\"passage\": \"The Matrix is a 1999 science fiction action film written and directed by The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\", \"question\": \"Who stars in The Matrix?\"}' | allennlp predict https://storage.googleapis.com/allennlp-public-models/transformer-qa-2020-05-26.tar.gz -\r\n\r\n2020-06-04 14:15:44,818 - INFO - transformers.file_utils - PyTorch version 1.5.0 available.\r\n2020-06-04 14:15:45,477 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/transformer-qa-2020-05-26.tar.gz from cache at /home/michaels/.allennlp/cache/4c6eacd3c5ba190ae88644f866eb35b9e6ca10b01c15848f166fdb1b020d8a35.6bb2b04ba1dc0eb8d7e4172e5d8c72551fe73b45f947d390ba43ed25d9cce60f\r\n2020-06-04 14:15:45,478 - INFO - allennlp.models.archival - extracting archive file /home/michaels/.allennlp/cache/4c6eacd3c5ba190ae88644f866eb35b9e6ca10b01c15848f166fdb1b020d8a35.6bb2b04ba1dc0eb8d7e4172e5d8c72551fe73b45f947d390ba43ed25d9cce60f to temp dir /tmp/tmpkl0n2lie\r\n2020-06-04 14:15:48,296 - INFO - allennlp.common.params - type = from_instances\r\n2020-06-04 14:15:48,296 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpkl0n2lie/vocabulary.\r\n2020-06-04 14:15:48,296 - INFO - allennlp.common.params - model.type = transformer_qa\r\n2020-06-04 14:15:48,296 - INFO - allennlp.common.params - model.regularizer = None\r\n2020-06-04 14:15:48,296 - INFO - allennlp.common.params - model.transformer_model_name = bert-base-cased\r\n2020-06-04 14:15:48,613 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/michaels/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\r\n2020-06-04 14:15:48,614 - INFO - transformers.configuration_utils - Model config BertConfig {\r\n  \"architectures\": [\r\n    \"BertForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 768,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 3072,\r\n  \"layer_norm_eps\": 1e-12,\r\n  \"max_position_embeddings\": 512,\r\n  \"model_type\": \"bert\",\r\n  \"num_attention_heads\": 12,\r\n  \"num_hidden_layers\": 12,\r\n  \"pad_token_id\": 0,\r\n  \"type_vocab_size\": 2,\r\n  \"vocab_size\": 28996\r\n}\r\n\r\n...\r\n\r\n2020-06-04 14:15:55,391 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/michaels/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\r\nTraceback (most recent call last):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 212, in _predict\r\n    manager.run()\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 186, in run\r\n    for model_input_json, result in zip(batch_json, self._predict_json(batch_json)):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 132, in _predict_json\r\n    results = [self._predictor.predict_json(batch_data[0])]\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 47, in predict_json\r\n    instance = self._json_to_instance(inputs)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 195, in _json_to_instance\r\n    raise NotImplementedError\r\nNotImplementedError\r\n2020-06-04 14:15:55,419 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpkl0n2lie\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4321/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4321/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4320", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4320/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4320/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4320/events", "html_url": "https://github.com/allenai/allennlp/issues/4320", "id": 631064745, "node_id": "MDU6SXNzdWU2MzEwNjQ3NDU=", "number": 4320, "title": "Sentiment evaluate command fails on AllenNLP RC5", "user": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 3, "created_at": "2020-06-04T18:43:12Z", "updated_at": "2020-06-10T17:11:15Z", "closed_at": "2020-06-10T17:11:14Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "This code snippet is available on our demo.\r\n\r\n```\r\nallennlp evaluate \\\r\n>     https://storage.googleapis.com/allennlp-public-models/sst-2-basic-classifier-glove-2019.06.27.tar.gz \\\r\n>     https://s3-us-west-2.amazonaws.com/allennlp/datasets/sst/dev.txt\r\n2020-06-04 11:40:50,162 - INFO - transformers.file_utils - PyTorch version 1.5.0 available.\r\n2020-06-04 11:40:50,817 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/sst-2-basic-classifier-glove-2019.06.27.tar.gz from cache at /home/michaels/.allennlp/cache/020023ed51a1aa767d7d2c0fac738b3ac0784eb6db2702ec0e35b3611284a767.bb12d8472ca5c5337beb9ee41ef6ee16ac89136ba0e49091654fb76a9ea7f44f\r\n2020-06-04 11:40:50,818 - INFO - allennlp.models.archival - extracting archive file /home/michaels/.allennlp/cache/020023ed51a1aa767d7d2c0fac738b3ac0784eb6db2702ec0e35b3611284a767.bb12d8472ca5c5337beb9ee41ef6ee16ac89136ba0e49091654fb76a9ea7f44f to temp dir /tmp/tmpzc_b8ch9\r\n2020-06-04 11:40:51,089 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpzc_b8ch9/vocabulary.\r\n2020-06-04 11:40:51,279 - INFO - allennlp.common.checks - Pytorch version: 1.5.0\r\n2020-06-04 11:40:51,280 - INFO - allennlp.commands.evaluate - Reading evaluation data from https://s3-us-west-2.amazonaws.com/allennlp/datasets/sst/dev.txt\r\n0it [00:00, ?it/s]2020-06-04 11:40:51,350 - INFO - allennlp.common.file_utils - https://s3-us-west-2.amazonaws.com/allennlp/datasets/sst/dev.txt not found in cache, downloading to /tmp/tmpmb5jiyiq\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 280825/280825 [00:00<00:00, 5887943.44B/s]\r\n2020-06-04 11:40:51,490 - INFO - allennlp.common.file_utils - copying /tmp/tmpmb5jiyiq to cache at /home/michaels/.allennlp/cache/a7f3236709afd54d8a52df413be2892c0fd15416570a33228b65ee62d354ef82.45cca2e5ec407e60a4e09e08a8be4e1d8457b9a63fa3e2a9c236e7475e92b5cf\r\n2020-06-04 11:40:51,491 - INFO - allennlp.common.file_utils - creating metadata file for /home/michaels/.allennlp/cache/a7f3236709afd54d8a52df413be2892c0fd15416570a33228b65ee62d354ef82.45cca2e5ec407e60a4e09e08a8be4e1d8457b9a63fa3e2a9c236e7475e92b5cf\r\n2020-06-04 11:40:51,491 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpmb5jiyiq\r\n2020-06-04 11:40:51,491 - INFO - allennlp_models.classification.dataset_readers.stanford_sentiment_tree_bank - Reading instances from lines in file at: https://s3-us-west-2.amazonaws.com/allennlp/datasets/sst/dev.txt\r\n872it [00:00, 2535.57it/s]\r\nTraceback (most recent call last):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/common/params.py\", line 237, in pop\r\n    value = self.params.pop(key)\r\nKeyError: 'data_loader'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/evaluate.py\", line 136, in evaluate_from_args\r\n    data_loader_params = config.pop(\"data_loader\")\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/common/params.py\", line 242, in pop\r\n    raise ConfigurationError(msg)\r\nallennlp.common.checks.ConfigurationError: key \"data_loader\" is required\r\n2020-06-04 11:40:51,624 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpzc_b8ch9\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4320/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4320/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4319", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4319/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4319/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4319/events", "html_url": "https://github.com/allenai/allennlp/issues/4319", "id": 630799459, "node_id": "MDU6SXNzdWU2MzA3OTk0NTk=", "number": 4319, "title": "Predictor.from_path not loading my trained model", "user": {"login": "ud2195", "id": 42403625, "node_id": "MDQ6VXNlcjQyNDAzNjI1", "avatar_url": "https://avatars.githubusercontent.com/u/42403625?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ud2195", "html_url": "https://github.com/ud2195", "followers_url": "https://api.github.com/users/ud2195/followers", "following_url": "https://api.github.com/users/ud2195/following{/other_user}", "gists_url": "https://api.github.com/users/ud2195/gists{/gist_id}", "starred_url": "https://api.github.com/users/ud2195/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ud2195/subscriptions", "organizations_url": "https://api.github.com/users/ud2195/orgs", "repos_url": "https://api.github.com/users/ud2195/repos", "events_url": "https://api.github.com/users/ud2195/events{/privacy}", "received_events_url": "https://api.github.com/users/ud2195/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 6, "created_at": "2020-06-04T12:59:48Z", "updated_at": "2020-06-08T16:24:10Z", "closed_at": "2020-06-08T16:24:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi , After training my Textual entailment model successfully using roBERTa, I am unable to load the same:-\r\n\r\nTraceback:-\r\n```\r\n---------------------------------------------------------------------------\r\n---------------------------------------------------------------------------\r\nConfigurationError                        Traceback (most recent call last)\r\n<ipython-input-56-91de5da48e5e> in <module>()\r\n     10 from allennlp.predictors.predictor import Predictor\r\n     11 get_ipython().system('pip install swifter')\r\n---> 12 predictor = Predictor.from_path(\"/content/allenepi/model.tar.gz\")\r\n     13 labels_dict = predictor._model.vocab.get_index_to_token_vocabulary('labels')\r\n     14 \r\n3 frames\r\n/usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py\r\n in from_path(cls, archive_path, predictor_name, cuda_device, dataset_reader_to_load, frozen)\r\n    257             predictor_name,\r\n    258             dataset_reader_to_load=dataset_reader_to_load,\r\n--> 259             frozen=frozen,\r\n    260         )\r\n    261 \r\n/usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py in from_archive(cls, archive, predictor_name, dataset_reader_to_load, frozen)\r\n    292         else:\r\n    293             dataset_reader_params = config[\"dataset_reader\"]\r\n--> 294         dataset_reader = DatasetReader.from_params(dataset_reader_params)\r\n    295 \r\n    296         model = archive.model\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in from_params(cls, params, constructor_to_call, constructor_to_inspect, **extras)\r\n    558                 \"type\",\r\n    559                 choices=as_registrable.list_available(),\r\n--> 560                 default_to_first_choice=default_to_first_choice,\r\n    561             )\r\n    562             subclass, constructor_name = as_registrable.resolve_class_name(choice)\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/params.py in pop_choice(self, key, choices, default_to_first_choice, allow_class_names)\r\n    349                 \"\"\"{\"model\": \"my_module.models.MyModel\"} to have it imported automatically.\"\"\"\r\n    350             )\r\n--> 351             raise ConfigurationError(message)\r\n    352         return value\r\n    353 \r\nConfigurationError: snli not in acceptable choices for dataset_reader.type: ['conll2003', 'interleaving', 'sequence_tagging', 'sharded', 'babi', 'text_classification_json']. You should either use the --include-package flag to make sure the correct module is loaded, or use a fully qualified class name in your config file like {\"model\": \"my_module.models.MyModel\"} to have it imported automatically.```\r\n\r\n\r\n\r\n```\r\n```\r\nmy config.jsonnet:-\r\nlocal transformer_model = \"roberta-large\";\r\nlocal transformer_dim = 1024;\r\nlocal cls_is_last_token = false;\r\n\r\n{\r\n  \"dataset_reader\":{\r\n    \"type\": \"snli\",\r\n    \"tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": transformer_model,\r\n      \"add_special_tokens\": false\r\n    },\r\n    \"token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": transformer_model,\r\n        \"max_length\": 40\r\n      }\r\n    }\r\n  },\r\n  \"train_data_path\": \"/content/cnli_train_5L.jsonl\",\r\n  \"validation_data_path\": \"/content/cnli_val_5L.jsonl\",\r\n  \r\n  \"model\": {\r\n    \"type\": \"basic_classifier\",\r\n    \"text_field_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer\",\r\n          \"model_name\": transformer_model,\r\n          \"max_length\": 40\r\n        }\r\n      }\r\n    },\r\n    \"seq2vec_encoder\": {\r\n       \"type\": \"cls_pooler\",\r\n       \"embedding_dim\": transformer_dim,\r\n       \"cls_is_last_token\": cls_is_last_token\r\n    },\r\n    \"feedforward\": {\r\n      \"input_dim\": transformer_dim,\r\n      \"num_layers\": 1,\r\n      \"hidden_dims\": transformer_dim,\r\n      \"activations\": \"tanh\"\r\n    },\r\n    \"dropout\": 0.1,\r\n    \"namespace\": \"tags\"\r\n  },\r\n  \"data_loader\": {\r\n    \"batch_sampler\": {\r\n      \"type\": \"bucket\",\r\n      \"batch_size\" : 4\r\n    }\r\n  },\r\n  \"trainer\": {\r\n    \"num_epochs\": 10,\r\n    \"cuda_device\" : 0,\r\n    \"validation_metric\": \"+accuracy\",\r\n    \"learning_rate_scheduler\": {\r\n      \"type\": \"slanted_triangular\",\r\n      \"cut_frac\": 0.06\r\n    },\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"lr\": 2e-5,\r\n      \"weight_decay\": 0.1,\r\n    }\r\n  }\r\n}\r\n\r\n``````\r\ncode :-\r\n```\r\nfrom allennlp.predictors.predictor import Predictor \r\npredictor = Predictor.from_path(\"/content/allenepi/model.tar.gz\")\r\n```\r\nallennlp and allennlp-model version is **1.0.0rc5**\r\n\r\nwill really appreciate some help on the same, Thank you", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4319/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4319/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4318", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4318/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4318/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4318/events", "html_url": "https://github.com/allenai/allennlp/issues/4318", "id": 630312985, "node_id": "MDU6SXNzdWU2MzAzMTI5ODU=", "number": 4318, "title": "Peak CPU memory not reported correctly in distributed training", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-03T20:43:11Z", "updated_at": "2020-06-04T22:50:03Z", "closed_at": "2020-06-04T22:50:03Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I noticed this bug while benchmarking some distributed experiments on beaker. I think `allennlp.common.util.peak_memory_mb()` is only called from the master process, and it only reports the memory usage for the master process. This should really report the combined memory used across all workers.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4318/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4318/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4317", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4317/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4317/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4317/events", "html_url": "https://github.com/allenai/allennlp/issues/4317", "id": 630196865, "node_id": "MDU6SXNzdWU2MzAxOTY4NjU=", "number": 4317, "title": "facing  AssertionError when running my textual entailment training using roBERTa", "user": {"login": "ud2195", "id": 42403625, "node_id": "MDQ6VXNlcjQyNDAzNjI1", "avatar_url": "https://avatars.githubusercontent.com/u/42403625?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ud2195", "html_url": "https://github.com/ud2195", "followers_url": "https://api.github.com/users/ud2195/followers", "following_url": "https://api.github.com/users/ud2195/following{/other_user}", "gists_url": "https://api.github.com/users/ud2195/gists{/gist_id}", "starred_url": "https://api.github.com/users/ud2195/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ud2195/subscriptions", "organizations_url": "https://api.github.com/users/ud2195/orgs", "repos_url": "https://api.github.com/users/ud2195/repos", "events_url": "https://api.github.com/users/ud2195/events{/privacy}", "received_events_url": "https://api.github.com/users/ud2195/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-06-03T17:45:27Z", "updated_at": "2020-06-04T16:35:41Z", "closed_at": "2020-06-03T21:13:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi , I am facing assertion error which didnt used to happen earlier while starting my training using roBERTa for textual entailment.\r\n\r\nPlease find the full traceback below:-\r\n```\r\nFile \"/usr/local/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/commands/train.py\", line 112, in train_model_from_args\r\n    dry_run=args.dry_run,\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/commands/train.py\", line 171, in train_model_from_file\r\n    dry_run=dry_run,\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/commands/train.py\", line 230, in train_model\r\n    dry_run=dry_run,\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/commands/train.py\", line 418, in _train_worker\r\n    params=params, serialization_dir=serialization_dir, local_rank=process_rank,\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py\", line 609, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py\", line 181, in create_kwargs\r\n    cls.__name__, param_name, annotation, param.default, params, **extras\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py\", line 287, in pop_and_construct_arg\r\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py\", line 321, in construct_arg\r\n    return annotation.from_params(params=popped_params, **subextras)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py\", line 611, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp_models/pair_classification/dataset_readers/snli.py\", line 51, in __init__\r\n    assert not self._tokenizer._add_special_tokens\r\nAssertionError\r\n```\r\nmy config file:-\r\n```\r\nlocal transformer_model = \"roberta-large\";\r\nlocal transformer_dim = 1024;\r\nlocal cls_is_last_token = false;\r\n\r\n{\r\n  \"dataset_reader\":{\r\n    \"type\": \"snli\",\r\n    \"tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": transformer_model,\r\n      \r\n    },\r\n    \"token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": transformer_model,\r\n        \"max_length\": 512\r\n      }\r\n    }\r\n  },\r\n  \"train_data_path\": \"/content/cnli_train_5L.jsonl\",\r\n  \"validation_data_path\": \"/content/cnli_val_5L.jsonl\",\r\n  \r\n  \"model\": {\r\n    \"type\": \"basic_classifier\",\r\n    \"text_field_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer\",\r\n          \"model_name\": transformer_model,\r\n          \"max_length\": 512\r\n        }\r\n      }\r\n    },\r\n    \"seq2vec_encoder\": {\r\n       \"type\": \"cls_pooler\",\r\n       \"embedding_dim\": transformer_dim,\r\n       \"cls_is_last_token\": cls_is_last_token\r\n    },\r\n    \"feedforward\": {\r\n      \"input_dim\": transformer_dim,\r\n      \"num_layers\": 1,\r\n      \"hidden_dims\": transformer_dim,\r\n      \"activations\": \"tanh\"\r\n    },\r\n    \"dropout\": 0.1,\r\n    \"namespace\": \"tags\"\r\n  },\r\n  \"data_loader\": {\r\n    \"batch_sampler\": {\r\n      \"type\": \"bucket\",\r\n      \"batch_size\" : 16\r\n    }\r\n  },\r\n  \"trainer\": {\r\n    \"num_epochs\": 10,\r\n    \"cuda_device\" : -1,\r\n    \"validation_metric\": \"+accuracy\",\r\n    \"learning_rate_scheduler\": {\r\n      \"type\": \"slanted_triangular\",\r\n      \"cut_frac\": 0.06\r\n    },\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"lr\": 2e-5,\r\n      \"weight_decay\": 0.1,\r\n    }\r\n  }\r\n}\r\n```\r\nthis is the same config.jsonnet given for roBERTa for training on mnli dataset except the fact that i removed\r\n`\"add_special_tokens\": False` from tokenizer field in jsonnet. as it gave me a static error \r\n\r\nsurprising thing is i didnt get the error mentioned above few hours back while initiating training.\r\n\r\nsteps to reproduce:-\r\n```\r\n1) !pip install --pre allennlp-models\r\n2) Training data was already there in jsonl\r\n3) !allennlp train /content/mnliconfig.jsonnet -s /content/allenmodel\r\n\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4317/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4317/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4297", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4297/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4297/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4297/events", "html_url": "https://github.com/allenai/allennlp/issues/4297", "id": 626294966, "node_id": "MDU6SXNzdWU2MjYyOTQ5NjY=", "number": 4297, "title": "reading comprehension: 'Predictor' object has no attribute 'predict'", "user": {"login": "aoleiReiz", "id": 20548202, "node_id": "MDQ6VXNlcjIwNTQ4MjAy", "avatar_url": "https://avatars.githubusercontent.com/u/20548202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aoleiReiz", "html_url": "https://github.com/aoleiReiz", "followers_url": "https://api.github.com/users/aoleiReiz/followers", "following_url": "https://api.github.com/users/aoleiReiz/following{/other_user}", "gists_url": "https://api.github.com/users/aoleiReiz/gists{/gist_id}", "starred_url": "https://api.github.com/users/aoleiReiz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aoleiReiz/subscriptions", "organizations_url": "https://api.github.com/users/aoleiReiz/orgs", "repos_url": "https://api.github.com/users/aoleiReiz/repos", "events_url": "https://api.github.com/users/aoleiReiz/events{/privacy}", "received_events_url": "https://api.github.com/users/aoleiReiz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-28T07:49:03Z", "updated_at": "2020-05-29T15:00:49Z", "closed_at": "2020-05-29T14:14:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ ] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [ ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ ] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [ ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ ] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b>\r\n</summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\npredictor.predict(\r\nAttributeError: 'Predictor' object has no attribute 'predict'\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Windows\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.6.8\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==1.0.0rc1\r\nallennlp-models==1.0.0rc1\r\natomicwrites==1.4.0\r\nattrs==19.3.0\r\nbackcall==0.1.0\r\nblis==0.4.1\r\nboto3==1.13.18\r\nbotocore==1.16.18\r\ncatalogue==1.0.0\r\ncertifi==2020.4.5.1\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncolorama==0.4.3\r\nconllu==2.3.2\r\ncymem==2.0.3\r\ndataclasses==0.7\r\ndecorator==4.4.2\r\ndocutils==0.15.2\r\nen-core-web-sm==2.2.5\r\nfilelock==3.0.12\r\nflaky==3.6.1\r\nh5py==2.10.0\r\nidna==2.9\r\nimportlib-metadata==1.6.0\r\nipython==7.14.0\r\nipython-genutils==0.2.0\r\njedi==0.17.0\r\njmespath==0.10.0\r\njoblib==0.15.1\r\njsonpickle==1.4.1\r\nmore-itertools==8.3.0\r\nmurmurhash==1.0.2\r\nnltk==3.5\r\nnumpy==1.18.4\r\noverrides==2.8.0\r\npackaging==20.4\r\nparso==0.7.0\r\npickleshare==0.7.5\r\nPillow==7.1.2\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprompt-toolkit==3.0.5\r\nprotobuf==3.12.2\r\npy==1.8.1\r\npy-rouge==1.1\r\nPygments==2.6.1\r\npyparsing==2.4.7\r\npytest==5.4.2\r\npython-dateutil==2.8.1\r\nregex==2020.5.14\r\nrequests==2.23.0\r\nresponses==0.10.14\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.4.1\r\nsemantic-version==2.8.5\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.2.4\r\nsrsly==1.0.2\r\ntensorboardX==2.0\r\nthinc==7.4.0\r\nthreadpoolctl==2.0.0\r\ntokenizers==0.5.2\r\ntorch==1.4.0\r\ntorchvision==0.4.2\r\ntqdm==4.46.0\r\ntraitlets==4.3.3\r\ntransformers==2.8.0\r\nurllib3==1.25.9\r\nwasabi==0.6.0\r\nwcwidth==0.1.9\r\nword2number==1.1\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp_models.rc import bidaf\r\nfrom allennlp.predictors.predictor import Predictor\r\n\r\n\r\npredictor = Predictor.from_path(\"bidaf-elmo-model-2020.03.19.tar.gz\")\r\npredictor.predict(\r\n  inputs={\"passage\":\"The Matrix is a 1999 science fiction action film written and directed by The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\",\r\n  \"question\":\"Who stars in The Matrix?\"}\r\n)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4297/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4297/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4281", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4281/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4281/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4281/events", "html_url": "https://github.com/allenai/allennlp/issues/4281", "id": 624211654, "node_id": "MDU6SXNzdWU2MjQyMTE2NTQ=", "number": 4281, "title": "\"TypeError: not a sequence\" on simple coreference resolution", "user": {"login": "arthurdeschamps", "id": 5251641, "node_id": "MDQ6VXNlcjUyNTE2NDE=", "avatar_url": "https://avatars.githubusercontent.com/u/5251641?v=4", "gravatar_id": "", "url": "https://api.github.com/users/arthurdeschamps", "html_url": "https://github.com/arthurdeschamps", "followers_url": "https://api.github.com/users/arthurdeschamps/followers", "following_url": "https://api.github.com/users/arthurdeschamps/following{/other_user}", "gists_url": "https://api.github.com/users/arthurdeschamps/gists{/gist_id}", "starred_url": "https://api.github.com/users/arthurdeschamps/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/arthurdeschamps/subscriptions", "organizations_url": "https://api.github.com/users/arthurdeschamps/orgs", "repos_url": "https://api.github.com/users/arthurdeschamps/repos", "events_url": "https://api.github.com/users/arthurdeschamps/events{/privacy}", "received_events_url": "https://api.github.com/users/arthurdeschamps/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 20, "created_at": "2020-05-25T10:35:28Z", "updated_at": "2020-07-14T07:51:52Z", "closed_at": "2020-06-03T00:04:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Describe the bug**\r\n\r\nI get a `TypeError: not a sequence` when trying to predict this simple string: \"Besides its prominence in sports, Notre Dame is also a large, four-year, highly residential research University, and is consistently ranked among the top twenty universities in the United States  and as a major global university.\"\r\n\r\nFull stacktrace:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/arthur/question-generation/models/sg_dqg.py\", line 156, in <module>\r\n    preprocess(args.ds)\r\n  File \"/home/arthur/question-generation/models/sg_dqg.py\", line 124, in preprocess\r\n    coreferences = coreference_resolution(evidences_list)\r\n  File \"/home/arthur/question-generation/models/sg_dqg.py\", line 74, in coreference_resolution\r\n    document=\"Besides its prominence in sports, Notre Dame is also a large, four-year, highly residential research University, and is consistently ranked among the top twenty universities in the United States  and as a major global university.\"\r\n  File \"/home/arthur/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/allennlp_models/coref/coref_predictor.py\", line 65, in predict\r\n    return self.predict_json({\"document\": document})\r\n  File \"/home/arthur/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/allennlp/predictors/predictor.py\", line 48, in predict_json\r\n    return self.predict_instance(instance)\r\n  File \"/home/arthur/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/allennlp/predictors/predictor.py\", line 171, in predict_instance\r\n    outputs = self._model.forward_on_instance(instance)\r\n  File \"/home/arthur/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/allennlp/models/model.py\", line 142, in forward_on_instance\r\n    return self.forward_on_instances([instance])[0]\r\n  File \"/home/arthur/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/allennlp/models/model.py\", line 167, in forward_on_instances\r\n    model_input = util.move_to_device(dataset.as_tensor_dict(), cuda_device)\r\n  File \"/home/arthur/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/allennlp/data/batch.py\", line 139, in as_tensor_dict\r\n    for field, tensors in instance.as_tensor_dict(lengths_to_use).items():\r\n  File \"/home/arthur/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/allennlp/data/instance.py\", line 99, in as_tensor_dict\r\n    tensors[field_name] = field.as_tensor(padding_lengths[field_name])\r\n  File \"/home/arthur/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/allennlp/data/fields/text_field.py\", line 103, in as_tensor\r\n    self._indexed_tokens[indexer_name], indexer_lengths[indexer_name]\r\n  File \"/home/arthur/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/allennlp/data/token_indexers/pretrained_transformer_mismatched_indexer.py\", line 96, in as_padded_tensor_dict\r\n    offsets_tokens, offsets_padding_lengths, default_value=lambda: (0, 0)\r\nTypeError: not a sequence\r\n```\r\n\r\n**To Reproduce**\r\nRun this simple piece of code :\r\n\r\n```\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz\")\r\npredictor.predict(\r\ndocument=\"Besides its prominence in sports, Notre Dame is also a large, four-year, highly residential research University, and is consistently ranked among the top twenty universities in the United States  and as a major global university.\"\r\n)\r\n```\r\n\r\n**Expected behavior**\r\nThe function should return the proper resolved coreferences.\r\n\r\n**System (please complete the following information):**\r\n - OS: Linux\r\n - Python version: 3.7.7\r\n - AllenNLP version: 1.0.0rc4\r\n - PyTorch version: 1.5.0\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4281/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4281/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4255", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4255/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4255/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4255/events", "html_url": "https://github.com/allenai/allennlp/issues/4255", "id": 620622899, "node_id": "MDU6SXNzdWU2MjA2MjI4OTk=", "number": 4255, "title": "Distributed training bug", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 0, "created_at": "2020-05-19T02:12:52Z", "updated_at": "2020-05-21T22:07:51Z", "closed_at": "2020-05-21T22:07:51Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Currently the train command does the following WRT the vocabulary in the distributed setting:\r\n- initializes the vocab from the main process and serializes it to file,\r\n- spawns the `_train_worker` command for each worker, which themselves re-initialize the vocab from file,\r\n- then the master worker re-serializes the vocab to file after initializing the model in case the model has modified the vocab in some way.\r\n\r\nBut this is potentially really bad because a non-master worker could be initializing their vocab from the files that are currently being written to from the master worker. In fact, I believe this what caused this CI run to fail: https://github.com/allenai/allennlp/pull/4253/checks?check_run_id=687029330.\r\n\r\n---\r\n\r\nPotential solutions:\r\n\r\n1. Only serialize the vocab once, and do it *before* initializing the model.\r\n\r\n    This has a quick fix. See https://github.com/allenai/allennlp/pull/4256 for a draft.\r\n\r\n    The downside here is that model side-effects on the vocab won't be saved to the vocab files. Is this really a downside? I feel like models should not modify the vocab, and I only know of one that does: CopyNet. But it's really not necessary. See https://github.com/allenai/allennlp-models/pull/55.\r\n\r\n2. Refactor the train command so that even in the distributed setting we only serialize the vocab once, but do it *after* initializing the model. This will definitely take more work.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/4255/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/4255/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/3465", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/3465/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/3465/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/3465/events", "html_url": "https://github.com/allenai/allennlp/issues/3465", "id": 524541981, "node_id": "MDU6SXNzdWU1MjQ1NDE5ODE=", "number": 3465, "title": "PretrainedTransformerEmbedder does not pass masks to *transformer models", "user": {"login": "DeNeutoy", "id": 16001974, "node_id": "MDQ6VXNlcjE2MDAxOTc0", "avatar_url": "https://avatars.githubusercontent.com/u/16001974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeNeutoy", "html_url": "https://github.com/DeNeutoy", "followers_url": "https://api.github.com/users/DeNeutoy/followers", "following_url": "https://api.github.com/users/DeNeutoy/following{/other_user}", "gists_url": "https://api.github.com/users/DeNeutoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeNeutoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeNeutoy/subscriptions", "organizations_url": "https://api.github.com/users/DeNeutoy/orgs", "repos_url": "https://api.github.com/users/DeNeutoy/repos", "events_url": "https://api.github.com/users/DeNeutoy/events{/privacy}", "received_events_url": "https://api.github.com/users/DeNeutoy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 0, "created_at": "2019-11-18T18:31:37Z", "updated_at": "2020-01-03T15:36:59Z", "closed_at": "2020-01-03T15:36:59Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The huggingface repo accepts masks, we should definitely be passing them\r\n\r\nhttps://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py#L629\r\n\r\n\r\nhttps://github.com/allenai/allennlp/blob/master/allennlp/modules/token_embedders/pretrained_transformer_embedder.py#L25\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/3465/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/3465/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/3426", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/3426/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/3426/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/3426/events", "html_url": "https://github.com/allenai/allennlp/issues/3426", "id": 517277563, "node_id": "MDU6SXNzdWU1MTcyNzc1NjM=", "number": 3426, "title": "Bug in AutoRegressiveSeqDecoder", "user": {"login": "nicola-decao", "id": 9703100, "node_id": "MDQ6VXNlcjk3MDMxMDA=", "avatar_url": "https://avatars.githubusercontent.com/u/9703100?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nicola-decao", "html_url": "https://github.com/nicola-decao", "followers_url": "https://api.github.com/users/nicola-decao/followers", "following_url": "https://api.github.com/users/nicola-decao/following{/other_user}", "gists_url": "https://api.github.com/users/nicola-decao/gists{/gist_id}", "starred_url": "https://api.github.com/users/nicola-decao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nicola-decao/subscriptions", "organizations_url": "https://api.github.com/users/nicola-decao/orgs", "repos_url": "https://api.github.com/users/nicola-decao/repos", "events_url": "https://api.github.com/users/nicola-decao/events{/privacy}", "received_events_url": "https://api.github.com/users/nicola-decao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-11-04T16:52:29Z", "updated_at": "2020-03-03T02:17:24Z", "closed_at": "2020-03-03T02:17:24Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Here: https://github.com/allenai/allennlp/blob/f3083c8fb9150f07e3ca98bb3ea9368a081df028/allennlp/modules/seq2seq_decoders/auto_regressive_seq_decoder.py#L433\r\n\r\n``target_tokens[\"tokens\"]`` is a ``torch.Tensor`` so its ements do not have the attribute ``text``.\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/3426/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/3426/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/2120", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/2120/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/2120/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/2120/events", "html_url": "https://github.com/allenai/allennlp/issues/2120", "id": 386009690, "node_id": "MDU6SXNzdWUzODYwMDk2OTA=", "number": 2120, "title": "`track_epoch = true` flag for DataIterator does not .... track epochs ", "user": {"login": "DeNeutoy", "id": 16001974, "node_id": "MDQ6VXNlcjE2MDAxOTc0", "avatar_url": "https://avatars.githubusercontent.com/u/16001974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeNeutoy", "html_url": "https://github.com/DeNeutoy", "followers_url": "https://api.github.com/users/DeNeutoy/followers", "following_url": "https://api.github.com/users/DeNeutoy/following{/other_user}", "gists_url": "https://api.github.com/users/DeNeutoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeNeutoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeNeutoy/subscriptions", "organizations_url": "https://api.github.com/users/DeNeutoy/orgs", "repos_url": "https://api.github.com/users/DeNeutoy/repos", "events_url": "https://api.github.com/users/DeNeutoy/events{/privacy}", "received_events_url": "https://api.github.com/users/DeNeutoy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-30T02:24:00Z", "updated_at": "2018-11-30T06:54:18Z", "closed_at": "2018-11-30T06:54:18Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Because we get epochs one at a time from the `Iterator` in `Trainer` and the DataIterator does not track the _number_ of times it is called (it assumes that it is called once, returning a generator which iterates over multiple epochs).\r\n\r\nhttps://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/data_iterator.py#L146\r\n\r\nhttps://github.com/allenai/allennlp/blob/master/allennlp/training/trainer.py#L468\r\n\r\nThis was introduced in #1157 \r\n\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/2120/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/2120/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/1456", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/1456/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/1456/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/1456/events", "html_url": "https://github.com/allenai/allennlp/issues/1456", "id": 338076615, "node_id": "MDU6SXNzdWUzMzgwNzY2MTU=", "number": 1456, "title": "Alternating highway LSTM is broken with pytorch 0.4", "user": {"login": "nijianmo", "id": 13656675, "node_id": "MDQ6VXNlcjEzNjU2Njc1", "avatar_url": "https://avatars.githubusercontent.com/u/13656675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nijianmo", "html_url": "https://github.com/nijianmo", "followers_url": "https://api.github.com/users/nijianmo/followers", "following_url": "https://api.github.com/users/nijianmo/following{/other_user}", "gists_url": "https://api.github.com/users/nijianmo/gists{/gist_id}", "starred_url": "https://api.github.com/users/nijianmo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nijianmo/subscriptions", "organizations_url": "https://api.github.com/users/nijianmo/orgs", "repos_url": "https://api.github.com/users/nijianmo/repos", "events_url": "https://api.github.com/users/nijianmo/events{/privacy}", "received_events_url": "https://api.github.com/users/nijianmo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-07-03T22:40:56Z", "updated_at": "2019-01-10T19:44:23Z", "closed_at": "2019-01-10T19:44:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Describe the bug**\r\nHi, I followed the steps under installing from source section in Readme and the installation went smoothly However, two test cases failed (all the others passed) when I ran ./scripts/verify.py. I am using CUDA 9.1 and PyTorch 0.4. \r\n\r\nI am not clear how the forward_and_backward_outputs_match would cause error in this case. Any suggestion would be appreciated. Thank you!\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior\r\n1. Create a Conda environment with Python 3.6\r\n2. git clone https://github.com/allenai/allennlp.git\r\n3. INSTALL_TEST_REQUIREMENTS=true scripts/install_requirements.sh\r\n4. conda install pytorch torchvision cuda91 -c pytorch\r\n5. ./scripts/verify.py\r\n\r\n**System (please complete the following information):**\r\n - OS: \r\nNo LSB modules are available.\r\nDistributor ID: Ubuntu\r\nDescription:    Ubuntu 16.04.4 LTS\r\nRelease:        16.04\r\nCodename:       xenial\r\n - Python version: 3.6\r\n - AllenNLP version: \"I installed from master\"\r\n - PyTorch version: 0.4.0\r\n\r\n**Additional context**\r\nDetailed logs:\r\nallennlp/tests/training/metrics/wikitables_accuracy_test.py::WikiTablesAccuracyTest::test_accuracy_is_scored_correctly PASSED [100%]\r\n\r\n=========================================================== FAILURES ===========================================================____________________________________________ TestCustomHighwayLSTM.test_large_model ____________________________________________\r\nself = <alternating_highway_lstm_test.TestCustomHighwayLSTM testMethod=test_large_model>\r\n\r\n    def test_large_model(self):\r\n        args = self.get_models_and_inputs(83, 103, 311, 8, 101, 0.0)\r\n>       self.forward_and_backward_outputs_match(*args)\r\n\r\nallennlp/tests/custom_extensions/alternating_highway_lstm_test.py:21:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nbaseline_model = StackedAlternatingLstm(\r\n  (layer_0): AugmentedLstm(\r\n    (input_linearity): Linear(in_features=103, out_features=1866, ...=311, out_features=1866, bias=False)\r\n    (state_linearity): Linear(in_features=311, out_features=1555, bias=True)\r\n  )\r\n)\r\nkernel_model = AlternatingHighwayLSTM()\r\nbaseline_input = tensor([[[ 1.8477e-01, -7.8823e-01, -5.6745e-01,  ...,  6.9146e-01,\r\n          -4.5812e-01, -7.0494e-01],\r\n         [ 9....     [ 9.9837e-01, -3.0278e-01,  6.8073e-01,  ...,  2.9551e+00,\r\n           7.4804e-01, -1.2349e-01]]], device='cuda:0')\r\nkernel_input = tensor([[[ 1.8477e-01, -7.8823e-01, -5.6745e-01,  ...,  6.9146e-01,\r\n          -4.5812e-01, -7.0494e-01],\r\n         [ 9....     [ 9.9837e-01, -3.0278e-01,  6.8073e-01,  ...,  2.9551e+00,\r\n           7.4804e-01, -1.2349e-01]]], device='cuda:0')\r\nlengths = [101, 101, 100, 100, 99, 99, ...]\r\n\r\n    @staticmethod\r\n    def forward_and_backward_outputs_match(baseline_model, kernel_model,\r\n                                           baseline_input, kernel_input, lengths):\r\n\r\n        packed_baseline_input = pack_padded_sequence(baseline_input, lengths, batch_first=True)\r\n        baseline_output, _ = baseline_model(packed_baseline_input)\r\n        baseline_output, _ = pad_packed_sequence(baseline_output, batch_first=True)\r\n\r\n        packed_kernel_input = pack_padded_sequence(kernel_input, lengths, batch_first=True)\r\n        kernel_output, _ = kernel_model(packed_kernel_input)\r\n        kernel_output, _ = pad_packed_sequence(kernel_output, batch_first=True)\r\n\r\n        numpy.testing.assert_array_almost_equal(baseline_output.detach().cpu().numpy(),\r\n>                                               kernel_output.detach().cpu().numpy())\r\nE       AssertionError:\r\nE       Arrays are not almost equal to 6 decimals\r\nE\r\nE       (mismatch 99.99992328679271%)\r\nE        x: array([[[ 0.738039,  0.76647 ,  0.547838, ..., -0.734894,  0.243321,\r\nE                -0.565164],\r\nE               [ 0.566952,  0.336622,  0.420255, ...,  0.510282,  0.800266,...\r\nE        y: array([[[-0.008581, -0.006054,  0.002659, ..., -0.00064 ,  0.00423 ,\r\nE                 0.001915],\r\nE               [-0.013927,  0.000412,  0.000236, ...,  0.004177,  0.008705,...\r\n\r\nallennlp/tests/custom_extensions/alternating_highway_lstm_test.py:50: AssertionError\r\n------------------------------------------------------ Captured log call -------------------------------------------------------22:18:36 - INFO - allennlp.common.checks - Pytorch version: 0.4.0\r\n____________________________________________ TestCustomHighwayLSTM.test_small_model ____________________________________________\r\nself = <alternating_highway_lstm_test.TestCustomHighwayLSTM testMethod=test_small_model>\r\n\r\n    def test_small_model(self):\r\n        args = self.get_models_and_inputs(5, 3, 11, 2, 5, 0.0)\r\n>       self.forward_and_backward_outputs_match(*args)\r\n\r\nallennlp/tests/custom_extensions/alternating_highway_lstm_test.py:17:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nbaseline_model = StackedAlternatingLstm(\r\n  (layer_0): AugmentedLstm(\r\n    (input_linearity): Linear(in_features=3, out_features=66, bias...atures=11, out_features=66, bias=False)\r\n    (state_linearity): Linear(in_features=11, out_features=55, bias=True)\r\n  )\r\n)\r\nkernel_model = AlternatingHighwayLSTM()\r\nbaseline_input = tensor([[[-1.6144,  0.9450,  1.2019],\r\n         [-0.6427, -0.8049,  0.1154],\r\n         [ 1.6382, -0.6258,  1.6959],\r\n    ...4499, -0.6005, -0.3161],\r\n         [-1.1890, -0.9309,  0.8512],\r\n         [ 0.1147,  1.2142,  0.8544]]], device='cuda:0')\r\nkernel_input = tensor([[[-1.6144,  0.9450,  1.2019],\r\n         [-0.6427, -0.8049,  0.1154],\r\n         [ 1.6382, -0.6258,  1.6959],\r\n    ...4499, -0.6005, -0.3161],\r\n         [-1.1890, -0.9309,  0.8512],\r\n         [ 0.1147,  1.2142,  0.8544]]], device='cuda:0')\r\nlengths = [5, 5, 4, 4, 3]\r\n\r\n    @staticmethod\r\n    def forward_and_backward_outputs_match(baseline_model, kernel_model,\r\n                                           baseline_input, kernel_input, lengths):\r\n\r\n        packed_baseline_input = pack_padded_sequence(baseline_input, lengths, batch_first=True)\r\n        baseline_output, _ = baseline_model(packed_baseline_input)\r\n        baseline_output, _ = pad_packed_sequence(baseline_output, batch_first=True)\r\n\r\n        packed_kernel_input = pack_padded_sequence(kernel_input, lengths, batch_first=True)\r\n        kernel_output, _ = kernel_model(packed_kernel_input)\r\n        kernel_output, _ = pad_packed_sequence(kernel_output, batch_first=True)\r\n\r\n        numpy.testing.assert_array_almost_equal(baseline_output.detach().cpu().numpy(),\r\n>                                               kernel_output.detach().cpu().numpy())\r\nE       AssertionError:\r\nE       Arrays are not almost equal to 6 decimals\r\nE\r\nE       (mismatch 64.0%)\r\nE        x: array([[[-1.756360e-01,  2.167678e-02, -7.570671e-02, -1.327346e-01,\r\nE                -2.835389e-01, -3.194964e-01, -2.515155e-01, -1.749502e-01,\r\nE                 5.651265e-04, -2.258561e-01, -1.525716e-01],...\r\nE        y: array([[[-0.175636,  0.021677, -0.075707, -0.132735, -0.283539,\r\nE                -0.319496, -0.251516, -0.17495 ,  0.000565, -0.225856,\r\nE                -0.152572],...\r\n\r\nallennlp/tests/custom_extensions/alternating_highway_lstm_test.py:50: AssertionError\r\n------------------------------------------------------ Captured log call -------------------------------------------------------22:18:42 - INFO - allennlp.common.checks - Pytorch version: 0.4.0\r\n===Flaky Test Report===\r\n\r\ntest_evaluate_from_args passed 1 out of the required 1 times. Success!\r\ntest_batch_predictions_are_consistent passed 1 out of the required 1 times. Success!\r\ntest_batch_predictions_are_consistent passed 1 out of the required 1 times. Success!\r\ntest_model_can_train_save_and_load passed 1 out of the required 1 times. Success!\r\ntest_batch_predictions_are_consistent passed 1 out of the required 1 times. Success!\r\ntest_batch_predictions_are_consistent passed 1 out of the required 1 times. Success!\r\ntest_batch_predictions_are_consistent passed 1 out of the required 1 times. Success!\r\ntest_model_can_train_save_and_load passed 1 out of the required 1 times. Success!\r\ntest_elmo_no_features_can_train_save_and_load passed 1 out of the required 1 times. Success!\r\n\r\n===End Flaky Test Report===\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/1456/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/1456/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/970", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/970/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/970/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/970/events", "html_url": "https://github.com/allenai/allennlp/issues/970", "id": 303786105, "node_id": "MDU6SXNzdWUzMDM3ODYxMDU=", "number": 970, "title": "[Question] spans that have width equals 1", "user": {"login": "MaksymDel", "id": 8141935, "node_id": "MDQ6VXNlcjgxNDE5MzU=", "avatar_url": "https://avatars.githubusercontent.com/u/8141935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MaksymDel", "html_url": "https://github.com/MaksymDel", "followers_url": "https://api.github.com/users/MaksymDel/followers", "following_url": "https://api.github.com/users/MaksymDel/following{/other_user}", "gists_url": "https://api.github.com/users/MaksymDel/gists{/gist_id}", "starred_url": "https://api.github.com/users/MaksymDel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MaksymDel/subscriptions", "organizations_url": "https://api.github.com/users/MaksymDel/orgs", "repos_url": "https://api.github.com/users/MaksymDel/repos", "events_url": "https://api.github.com/users/MaksymDel/events{/privacy}", "received_events_url": "https://api.github.com/users/MaksymDel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "DeNeutoy", "id": 16001974, "node_id": "MDQ6VXNlcjE2MDAxOTc0", "avatar_url": "https://avatars.githubusercontent.com/u/16001974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeNeutoy", "html_url": "https://github.com/DeNeutoy", "followers_url": "https://api.github.com/users/DeNeutoy/followers", "following_url": "https://api.github.com/users/DeNeutoy/following{/other_user}", "gists_url": "https://api.github.com/users/DeNeutoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeNeutoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeNeutoy/subscriptions", "organizations_url": "https://api.github.com/users/DeNeutoy/orgs", "repos_url": "https://api.github.com/users/DeNeutoy/repos", "events_url": "https://api.github.com/users/DeNeutoy/events{/privacy}", "received_events_url": "https://api.github.com/users/DeNeutoy/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "DeNeutoy", "id": 16001974, "node_id": "MDQ6VXNlcjE2MDAxOTc0", "avatar_url": "https://avatars.githubusercontent.com/u/16001974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeNeutoy", "html_url": "https://github.com/DeNeutoy", "followers_url": "https://api.github.com/users/DeNeutoy/followers", "following_url": "https://api.github.com/users/DeNeutoy/following{/other_user}", "gists_url": "https://api.github.com/users/DeNeutoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeNeutoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeNeutoy/subscriptions", "organizations_url": "https://api.github.com/users/DeNeutoy/orgs", "repos_url": "https://api.github.com/users/DeNeutoy/repos", "events_url": "https://api.github.com/users/DeNeutoy/events{/privacy}", "received_events_url": "https://api.github.com/users/DeNeutoy/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-03-09T10:02:07Z", "updated_at": "2018-03-22T18:00:49Z", "closed_at": "2018-03-22T18:00:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Consider span that have width equals 2 (e.g. [0,1]) and combination formula (for EndpointSpanExtractor) 'y-x'. In this case the behavior is clear.\r\n\r\nNow consider span that have width equals 1 (e.g. [1,1]). How will this case be handled? Will the formula 'y-x' be ignored? ", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/970/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/970/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/610", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/610/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/610/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/610/events", "html_url": "https://github.com/allenai/allennlp/issues/610", "id": 281941190, "node_id": "MDU6SXNzdWUyODE5NDExOTA=", "number": 610, "title": "Data pipeline tutorial issues", "user": {"login": "ChristophAlt", "id": 6420705, "node_id": "MDQ6VXNlcjY0MjA3MDU=", "avatar_url": "https://avatars.githubusercontent.com/u/6420705?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ChristophAlt", "html_url": "https://github.com/ChristophAlt", "followers_url": "https://api.github.com/users/ChristophAlt/followers", "following_url": "https://api.github.com/users/ChristophAlt/following{/other_user}", "gists_url": "https://api.github.com/users/ChristophAlt/gists{/gist_id}", "starred_url": "https://api.github.com/users/ChristophAlt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ChristophAlt/subscriptions", "organizations_url": "https://api.github.com/users/ChristophAlt/orgs", "repos_url": "https://api.github.com/users/ChristophAlt/repos", "events_url": "https://api.github.com/users/ChristophAlt/events{/privacy}", "received_events_url": "https://api.github.com/users/ChristophAlt/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "DeNeutoy", "id": 16001974, "node_id": "MDQ6VXNlcjE2MDAxOTc0", "avatar_url": "https://avatars.githubusercontent.com/u/16001974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeNeutoy", "html_url": "https://github.com/DeNeutoy", "followers_url": "https://api.github.com/users/DeNeutoy/followers", "following_url": "https://api.github.com/users/DeNeutoy/following{/other_user}", "gists_url": "https://api.github.com/users/DeNeutoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeNeutoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeNeutoy/subscriptions", "organizations_url": "https://api.github.com/users/DeNeutoy/orgs", "repos_url": "https://api.github.com/users/DeNeutoy/repos", "events_url": "https://api.github.com/users/DeNeutoy/events{/privacy}", "received_events_url": "https://api.github.com/users/DeNeutoy/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "DeNeutoy", "id": 16001974, "node_id": "MDQ6VXNlcjE2MDAxOTc0", "avatar_url": "https://avatars.githubusercontent.com/u/16001974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeNeutoy", "html_url": "https://github.com/DeNeutoy", "followers_url": "https://api.github.com/users/DeNeutoy/followers", "following_url": "https://api.github.com/users/DeNeutoy/following{/other_user}", "gists_url": "https://api.github.com/users/DeNeutoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeNeutoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeNeutoy/subscriptions", "organizations_url": "https://api.github.com/users/DeNeutoy/orgs", "repos_url": "https://api.github.com/users/DeNeutoy/repos", "events_url": "https://api.github.com/users/DeNeutoy/events{/privacy}", "received_events_url": "https://api.github.com/users/DeNeutoy/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2017-12-14T00:16:28Z", "updated_at": "2018-01-08T17:17:35Z", "closed_at": "2018-01-08T17:17:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "While working through the data pipeline tutorial (http://allennlp.org/tutorials/data-pipeline), I noticed a couple of things:\r\n\r\n1. when installing allennlp v0.2.3 via pip (python 3.6.1), the tutorial fails, because at this point Dataset has no as_tensor_dict(..) method.\r\n\r\n2. in the second example, in\r\n```\r\nprint(vocab.get_index_to_token_vocabulary(\"tokens\"), \"\\n\")\r\n.\r\nprint(vocab.get_index_to_token_vocabulary(\"chars\"), \"\\n\")\r\n```\r\n\"vocab\" should be replaced with \"word_and_char_vocab\"\r\n\r\n3. there is a missing comma between \"good\" and \".\" in line\r\n```\r\nreview2 = TextField(list(map(Token, [\"This\", \"movie\", \"was\", \"quite\", \"slow\", \"but\", \"good\" \".\"])), token_indexers={\"tokens\": SingleIdTokenIndexer()})\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/610/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/610/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/608", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/608/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/608/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/608/events", "html_url": "https://github.com/allenai/allennlp/issues/608", "id": 281761775, "node_id": "MDU6SXNzdWUyODE3NjE3NzU=", "number": 608, "title": "Data pipeline tutorial incorrectly describes vocab namespace issues", "user": {"login": "ChristophAlt", "id": 6420705, "node_id": "MDQ6VXNlcjY0MjA3MDU=", "avatar_url": "https://avatars.githubusercontent.com/u/6420705?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ChristophAlt", "html_url": "https://github.com/ChristophAlt", "followers_url": "https://api.github.com/users/ChristophAlt/followers", "following_url": "https://api.github.com/users/ChristophAlt/following{/other_user}", "gists_url": "https://api.github.com/users/ChristophAlt/gists{/gist_id}", "starred_url": "https://api.github.com/users/ChristophAlt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ChristophAlt/subscriptions", "organizations_url": "https://api.github.com/users/ChristophAlt/orgs", "repos_url": "https://api.github.com/users/ChristophAlt/repos", "events_url": "https://api.github.com/users/ChristophAlt/events{/privacy}", "received_events_url": "https://api.github.com/users/ChristophAlt/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "DeNeutoy", "id": 16001974, "node_id": "MDQ6VXNlcjE2MDAxOTc0", "avatar_url": "https://avatars.githubusercontent.com/u/16001974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeNeutoy", "html_url": "https://github.com/DeNeutoy", "followers_url": "https://api.github.com/users/DeNeutoy/followers", "following_url": "https://api.github.com/users/DeNeutoy/following{/other_user}", "gists_url": "https://api.github.com/users/DeNeutoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeNeutoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeNeutoy/subscriptions", "organizations_url": "https://api.github.com/users/DeNeutoy/orgs", "repos_url": "https://api.github.com/users/DeNeutoy/repos", "events_url": "https://api.github.com/users/DeNeutoy/events{/privacy}", "received_events_url": "https://api.github.com/users/DeNeutoy/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "DeNeutoy", "id": 16001974, "node_id": "MDQ6VXNlcjE2MDAxOTc0", "avatar_url": "https://avatars.githubusercontent.com/u/16001974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeNeutoy", "html_url": "https://github.com/DeNeutoy", "followers_url": "https://api.github.com/users/DeNeutoy/followers", "following_url": "https://api.github.com/users/DeNeutoy/following{/other_user}", "gists_url": "https://api.github.com/users/DeNeutoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeNeutoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeNeutoy/subscriptions", "organizations_url": "https://api.github.com/users/DeNeutoy/orgs", "repos_url": "https://api.github.com/users/DeNeutoy/repos", "events_url": "https://api.github.com/users/DeNeutoy/events{/privacy}", "received_events_url": "https://api.github.com/users/DeNeutoy/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2017-12-13T14:08:30Z", "updated_at": "2018-01-08T17:17:35Z", "closed_at": "2018-01-08T17:17:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "Issue:\r\nThe keys of the \"token_indexers\" dict passed to TextField aren't used to create the vocabulary namespace (I'm not entirely sure that this is the intended behavior but the tutorial on http://allennlp.org/tutorials/data-pipeline suggests so). Instead the TokenIndexers internal namespace is used, which leads to the behavior as shown in the example code. The specified namespace is \"some_namespace\" but the index is stored under the namespace \"tokens\", which is the default namespace for SingleIdTokenIndexer.\r\n\r\nExample code:\r\n```\r\nfrom allennlp.data import Token\r\nfrom allennlp.data.fields import TextField\r\nfrom allennlp.data.token_indexers import SingleIdTokenIndexer\r\nfrom allennlp.data import Instance\r\nfrom allennlp.data import Dataset\r\n\r\nfrom allennlp.data import Vocabulary\r\n\r\ntext_field = TextField(list(map(Token, [\"Here\", \"are\", \"some\", \"longer\", \"words\", \".\"])),\r\n                       token_indexers={\"some_namespace\": SingleIdTokenIndexer()})\r\ndataset = Dataset([Instance({\"sentence\": text_field})])\r\n\r\nvocab = Vocabulary.from_dataset(dataset)\r\ndataset.index_instances(vocab)\r\n\r\nprint('Namespaces:', vocab._index_to_token)\r\nprint('Namespace content:', vocab.get_index_to_token_vocabulary(\"some_namespace\"))\r\n```\r\n\r\nOutput:\r\n```\r\nNamespaces: defaultdict(None, {'tokens': {0: '@@PADDING@@', 1: '@@UNKNOWN@@', 2: 'Here', 3: 'are', 4: 'some', 5: 'longer', 6: 'words', 7: '.'}})\r\nNamespace content: {0: '@@PADDING@@', 1: '@@UNKNOWN@@'}\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/608/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/608/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/572", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/572/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/572/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/572/events", "html_url": "https://github.com/allenai/allennlp/issues/572", "id": 279223838, "node_id": "MDU6SXNzdWUyNzkyMjM4Mzg=", "number": 572, "title": "States are not handled correctly when passed to non-stateful Seq2SeqEncoders", "user": {"login": "DeNeutoy", "id": 16001974, "node_id": "MDQ6VXNlcjE2MDAxOTc0", "avatar_url": "https://avatars.githubusercontent.com/u/16001974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeNeutoy", "html_url": "https://github.com/DeNeutoy", "followers_url": "https://api.github.com/users/DeNeutoy/followers", "following_url": "https://api.github.com/users/DeNeutoy/following{/other_user}", "gists_url": "https://api.github.com/users/DeNeutoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeNeutoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeNeutoy/subscriptions", "organizations_url": "https://api.github.com/users/DeNeutoy/orgs", "repos_url": "https://api.github.com/users/DeNeutoy/repos", "events_url": "https://api.github.com/users/DeNeutoy/events{/privacy}", "received_events_url": "https://api.github.com/users/DeNeutoy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "DeNeutoy", "id": 16001974, "node_id": "MDQ6VXNlcjE2MDAxOTc0", "avatar_url": "https://avatars.githubusercontent.com/u/16001974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeNeutoy", "html_url": "https://github.com/DeNeutoy", "followers_url": "https://api.github.com/users/DeNeutoy/followers", "following_url": "https://api.github.com/users/DeNeutoy/following{/other_user}", "gists_url": "https://api.github.com/users/DeNeutoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeNeutoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeNeutoy/subscriptions", "organizations_url": "https://api.github.com/users/DeNeutoy/orgs", "repos_url": "https://api.github.com/users/DeNeutoy/repos", "events_url": "https://api.github.com/users/DeNeutoy/events{/privacy}", "received_events_url": "https://api.github.com/users/DeNeutoy/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "DeNeutoy", "id": 16001974, "node_id": "MDQ6VXNlcjE2MDAxOTc0", "avatar_url": "https://avatars.githubusercontent.com/u/16001974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeNeutoy", "html_url": "https://github.com/DeNeutoy", "followers_url": "https://api.github.com/users/DeNeutoy/followers", "following_url": "https://api.github.com/users/DeNeutoy/following{/other_user}", "gists_url": "https://api.github.com/users/DeNeutoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeNeutoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeNeutoy/subscriptions", "organizations_url": "https://api.github.com/users/DeNeutoy/orgs", "repos_url": "https://api.github.com/users/DeNeutoy/repos", "events_url": "https://api.github.com/users/DeNeutoy/events{/privacy}", "received_events_url": "https://api.github.com/users/DeNeutoy/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2017-12-05T02:31:49Z", "updated_at": "2017-12-06T02:57:25Z", "closed_at": "2017-12-06T02:57:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/572/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/572/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/463", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/463/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/463/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/463/events", "html_url": "https://github.com/allenai/allennlp/issues/463", "id": 271149890, "node_id": "MDU6SXNzdWUyNzExNDk4OTA=", "number": 463, "title": "guard against using unspecified GPUs", "user": {"login": "lucylw", "id": 2721700, "node_id": "MDQ6VXNlcjI3MjE3MDA=", "avatar_url": "https://avatars.githubusercontent.com/u/2721700?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucylw", "html_url": "https://github.com/lucylw", "followers_url": "https://api.github.com/users/lucylw/followers", "following_url": "https://api.github.com/users/lucylw/following{/other_user}", "gists_url": "https://api.github.com/users/lucylw/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucylw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucylw/subscriptions", "organizations_url": "https://api.github.com/users/lucylw/orgs", "repos_url": "https://api.github.com/users/lucylw/repos", "events_url": "https://api.github.com/users/lucylw/events{/privacy}", "received_events_url": "https://api.github.com/users/lucylw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-11-04T00:11:01Z", "updated_at": "2018-03-23T16:21:47Z", "closed_at": "2018-03-23T16:21:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "When transferring data onto GPU, it would be helpful if the library would guard against using unspecified GPUs based on the specified GPU in the config file, i.e.\r\n\r\n```python\r\nwith torch.cuda.device(cuda_device):\r\n   # all cuda data transfers\r\n```\r\notherwise, some data can wind up being transferred onto an unspecified device (default GPU), which could be used by another process at the same time.\r\n\r\nI experienced some related issues, e.g. GPU0 was being used, I specified GPU5, some of the model was transferred onto GPU0, and there was an out of memory error.\r\n\r\nRelated, it would also be nice if the library could check whether the specified GPU is available before loading data rather than after.\r\n", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/463/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/463/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/447", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/447/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/447/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/447/events", "html_url": "https://github.com/allenai/allennlp/issues/447", "id": 268910951, "node_id": "MDU6SXNzdWUyNjg5MTA5NTE=", "number": 447, "title": "Overriding environment variables causes them to be interpreted as a string", "user": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 26, "created_at": "2017-10-26T21:05:11Z", "updated_at": "2018-01-05T21:33:28Z", "closed_at": "2018-01-05T21:33:28Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "From @tusharkhot \r\n\r\nMichael Schmitz So there is one issue with using environment variables as fallback in HOCON. These environment variables are assumed to be strings by default which lead to incompatible type errors in AllenNLP. E.g. when setting cuda_device using environment variables\r\n\r\n```\r\n  File \"/usr/local/lib/python3.6/site-packages/allennlp/training/trainer.py\", line 515, in from_params\r\n    if cuda_device >= 0:\r\nTypeError: '>=' not supported between instances of 'str' and 'int'\r\n```\r\n\r\nI can submit a PR to allennlp to convert every parameter to the right type (or at least the interesting ones) or maybe there is a fancy way to ensure environment variables have the right type ?", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/447/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/447/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/338", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/338/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/338/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/338/events", "html_url": "https://github.com/allenai/allennlp/issues/338", "id": 259064144, "node_id": "MDU6SXNzdWUyNTkwNjQxNDQ=", "number": 338, "title": "Vocabulary token roundtrip bug", "user": {"login": "OyvindTafjord", "id": 6453366, "node_id": "MDQ6VXNlcjY0NTMzNjY=", "avatar_url": "https://avatars.githubusercontent.com/u/6453366?v=4", "gravatar_id": "", "url": "https://api.github.com/users/OyvindTafjord", "html_url": "https://github.com/OyvindTafjord", "followers_url": "https://api.github.com/users/OyvindTafjord/followers", "following_url": "https://api.github.com/users/OyvindTafjord/following{/other_user}", "gists_url": "https://api.github.com/users/OyvindTafjord/gists{/gist_id}", "starred_url": "https://api.github.com/users/OyvindTafjord/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/OyvindTafjord/subscriptions", "organizations_url": "https://api.github.com/users/OyvindTafjord/orgs", "repos_url": "https://api.github.com/users/OyvindTafjord/repos", "events_url": "https://api.github.com/users/OyvindTafjord/events{/privacy}", "received_events_url": "https://api.github.com/users/OyvindTafjord/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-09-20T07:21:34Z", "updated_at": "2017-09-21T00:45:30Z", "closed_at": "2017-09-21T00:45:23Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "On a new dataset, I ran into the tokens `'\\x0b'` (vertical tab) and, weirdly, `'\\x0b '` (with a space behind) which don't roundtrip well when read back from `tokens.txt` (each get read from file as two separate tokens, messing up the indexing).", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/338/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/338/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/292", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/292/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/292/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/292/events", "html_url": "https://github.com/allenai/allennlp/issues/292", "id": 256856685, "node_id": "MDU6SXNzdWUyNTY4NTY2ODU=", "number": 292, "title": "Inconsistent epoch numbering", "user": {"login": "OyvindTafjord", "id": 6453366, "node_id": "MDQ6VXNlcjY0NTMzNjY=", "avatar_url": "https://avatars.githubusercontent.com/u/6453366?v=4", "gravatar_id": "", "url": "https://api.github.com/users/OyvindTafjord", "html_url": "https://github.com/OyvindTafjord", "followers_url": "https://api.github.com/users/OyvindTafjord/followers", "following_url": "https://api.github.com/users/OyvindTafjord/following{/other_user}", "gists_url": "https://api.github.com/users/OyvindTafjord/gists{/gist_id}", "starred_url": "https://api.github.com/users/OyvindTafjord/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/OyvindTafjord/subscriptions", "organizations_url": "https://api.github.com/users/OyvindTafjord/orgs", "repos_url": "https://api.github.com/users/OyvindTafjord/repos", "events_url": "https://api.github.com/users/OyvindTafjord/events{/privacy}", "received_events_url": "https://api.github.com/users/OyvindTafjord/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-09-11T22:05:47Z", "updated_at": "2017-09-14T18:59:26Z", "closed_at": "2017-09-14T18:59:26Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "It's a bit confusing that we display `epoch + 1` in the logger during training, while `epoch` is the number saved in the `model_state_epoch_xx.th` files. More problematic is that when restoring from a checkpoint, the epoch gets set to the number of the loaded file, which then is promptly overwritten at the end of the first epoch of training, which seems like a bug.", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/292/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/292/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/243", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/243/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/243/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/243/events", "html_url": "https://github.com/allenai/allennlp/issues/243", "id": 254479706, "node_id": "MDU6SXNzdWUyNTQ0Nzk3MDY=", "number": 243, "title": "Figure out non-determinism due to PYTHONHASHSEED", "user": {"login": "matt-gardner", "id": 3291951, "node_id": "MDQ6VXNlcjMyOTE5NTE=", "avatar_url": "https://avatars.githubusercontent.com/u/3291951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matt-gardner", "html_url": "https://github.com/matt-gardner", "followers_url": "https://api.github.com/users/matt-gardner/followers", "following_url": "https://api.github.com/users/matt-gardner/following{/other_user}", "gists_url": "https://api.github.com/users/matt-gardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/matt-gardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matt-gardner/subscriptions", "organizations_url": "https://api.github.com/users/matt-gardner/orgs", "repos_url": "https://api.github.com/users/matt-gardner/repos", "events_url": "https://api.github.com/users/matt-gardner/events{/privacy}", "received_events_url": "https://api.github.com/users/matt-gardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-08-31T21:56:18Z", "updated_at": "2017-09-14T15:32:20Z", "closed_at": "2017-09-14T15:32:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Reported by @schmmd.  I'm not really sure what could be causing this, because I didn't think there was any randomness in `model.forward()` after `model.eval()` has been called.  But here are steps to reproduce:\r\n\r\n```\r\n$ git checkout schmmd/weird-bug\r\n$ set -x PYTHONHASHSEED 2157\r\n$ allennlp/run serve\r\n\r\n> \u201cspaceship\u201d\r\n\r\n1.  Navigate to http://localhost:8000.\r\n2.  Click the MC Model tab.\r\n3.  Submit the last example (The Millennium Falcon\u2026)\r\n\r\n$ git checkout schmmd/weird-bug\r\n$ set -x PYTHONHASHSEED 4563123\r\n$ allennlp/run serve\r\n\r\n1.  Navigate to http://localhost:8000.\r\n2.  Click the MC Model tab.\r\n3.  Submit the last example (The Millennium Falcon\u2026)\r\n\r\n> \u201cvariety of Star Wars expanded \u2026\u201d\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/243/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/243/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/236", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/236/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/236/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/236/events", "html_url": "https://github.com/allenai/allennlp/issues/236", "id": 254393031, "node_id": "MDU6SXNzdWUyNTQzOTMwMzE=", "number": 236, "title": "Figure out how to get spacy to tokenize wiki text correctly", "user": {"login": "matt-gardner", "id": 3291951, "node_id": "MDQ6VXNlcjMyOTE5NTE=", "avatar_url": "https://avatars.githubusercontent.com/u/3291951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matt-gardner", "html_url": "https://github.com/matt-gardner", "followers_url": "https://api.github.com/users/matt-gardner/followers", "following_url": "https://api.github.com/users/matt-gardner/following{/other_user}", "gists_url": "https://api.github.com/users/matt-gardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/matt-gardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matt-gardner/subscriptions", "organizations_url": "https://api.github.com/users/matt-gardner/orgs", "repos_url": "https://api.github.com/users/matt-gardner/repos", "events_url": "https://api.github.com/users/matt-gardner/events{/privacy}", "received_events_url": "https://api.github.com/users/matt-gardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-08-31T16:23:40Z", "updated_at": "2017-09-15T04:17:07Z", "closed_at": "2017-09-15T04:17:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "SQuAD has plenty of paragraphs that have wiki notes, formatting like \"This was a protest.[note 4]\".  Spacy for some reason does not tokenize these strings correctly, giving \"protest.[note\" as a single token.  We should be able to improve performance on SQuAD at least a little bit by fixing these issues, as it affects a fair number of our training examples, and some of the dev set.\r\n\r\nA test that currently fails, but should pass (goes in [`word_splitter_test.py`](https://github.com/allenai/allennlp/blob/master/tests/data/tokenizers/word_splitter_test.py)):\r\n\r\n```python\r\n def test_tokenize_handles_wiki_notes(self):\r\n     passage = \"McWhorter writes of Lee, \\\"for a white person from the South to write a \" +\\\r\n             \"book like this in the late 1950s is really unusual\\u2014by its very existence \" +\\\r\n             \"an act of protest.\\\"[note 4] Author James McBride calls Lee brilliant but \" +\\\r\n             \"stops short of calling her brave: \\\"I think by calling Harper Lee brave you \" +\\\r\n             \"kind of absolve yourself of your own racism.\\\"\"\r\n     tokens, offsets = self.word_splitter.split_words(passage)\r\n     assert \"protest\" in tokens\r\n```", "reactions": {"url": "https://api.github.com/repos/allenai/allennlp/issues/236/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/allenai/allennlp/issues/236/timeline", "performed_via_github_app": null, "state_reason": "completed"}]