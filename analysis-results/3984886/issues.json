[{"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2308", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2308/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2308/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2308/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2308", "id": 1635599426, "node_id": "I_kwDOBZhSr85hfURC", "number": 2308, "title": "[Bug] MultivariateNormal samples using Lanczos decomposition look wrong.", "user": {"login": "logan-dunbar", "id": 5948302, "node_id": "MDQ6VXNlcjU5NDgzMDI=", "avatar_url": "https://avatars.githubusercontent.com/u/5948302?v=4", "gravatar_id": "", "url": "https://api.github.com/users/logan-dunbar", "html_url": "https://github.com/logan-dunbar", "followers_url": "https://api.github.com/users/logan-dunbar/followers", "following_url": "https://api.github.com/users/logan-dunbar/following{/other_user}", "gists_url": "https://api.github.com/users/logan-dunbar/gists{/gist_id}", "starred_url": "https://api.github.com/users/logan-dunbar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/logan-dunbar/subscriptions", "organizations_url": "https://api.github.com/users/logan-dunbar/orgs", "repos_url": "https://api.github.com/users/logan-dunbar/repos", "events_url": "https://api.github.com/users/logan-dunbar/events{/privacy}", "received_events_url": "https://api.github.com/users/logan-dunbar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2023-03-22T11:43:15Z", "updated_at": "2023-03-30T15:38:23Z", "closed_at": "2023-03-29T19:17:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nStrange behaviour when generating samples from `MultivariateNormal` when using the Lanczos decomposition vs. `DiagLinearOperator` or Cholesky decomposition. I create a zero mean diagonal covariance MVN three ways (the size triggers Lanczos/Cholesky), and then sample from it, and receive very different looking samples. The Lanczos sample looks incorrect, the small and large `x` values should have larger variance.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport torch as t\r\nimport matplotlib.pyplot as plt\r\nfrom linear_operator.operators import DiagLinearOperator\r\nfrom gpytorch.distributions import MultivariateNormal\r\n\r\nt.manual_seed(0)\r\nx_1000 = t.linspace(0, 10, 1000)\r\nx_500 = t.linspace(0, 10, 500)\r\n\r\nomega_1000 = -0.5 * t.exp(-1 * ((x_1000 - 3.5) ** 2 / (1.4 ** 2)) ** 2) + 0.7\r\nomega_500 = -0.5 * t.exp(-1 * ((x_500 - 3.5) ** 2 / (1.4 ** 2)) ** 2) + 0.7\r\nomega_dist_1 = MultivariateNormal(t.zeros_like(x_1000), DiagLinearOperator(omega_1000 ** 2))\r\nomega_dist_2 = MultivariateNormal(t.zeros_like(x_1000), t.diag(omega_1000 ** 2))\r\nomega_dist_3 = MultivariateNormal(t.zeros_like(x_500), t.diag(omega_500 ** 2))\r\n\r\nsamples = 3\r\nfig, axes = plt.subplots(1, samples + 1, figsize=(15, 4))\r\naxes[0].plot(x_1000, omega_1000 ** 2, label=r'$\\omega_{1000}^2$')\r\naxes[0].plot(x_500, omega_500 ** 2, label=r'$\\omega_{500}^2$')\r\naxes[0].legend()\r\nfor i in range(samples):\r\n  axes[i+1].plot(x_1000, omega_dist_1.sample(), label='DiagLO sample')\r\n  axes[i+1].plot(x_500, omega_dist_3.sample(), label='Cholesky sample')\r\n  axes[i+1].plot(x_1000, omega_dist_2.sample(), label='Lanczos sample')\r\n  axes[i+1].legend()\r\nplt.tight_layout()\r\nplt.show()\r\n```\r\n![mvn_error](https://user-images.githubusercontent.com/5948302/226893276-158af433-ebbc-4f4c-8c59-0b966cdb52bd.png)\r\n\r\n## Expected Behavior\r\n\r\nI expect the distributions to produce samples that have the same distribution.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version - 1.9.1\r\n- PyTorch Version - 1.12.1+rocm5.1.1\r\n- Computer OS - 5.13.0-52-generic 20.04.1-Ubuntu\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2308/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2308/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2266", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2266/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2266/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2266/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2266", "id": 1569244808, "node_id": "I_kwDOBZhSr85diMaI", "number": 2266, "title": "[Bug] Runtime error for indices not on the same device when running VNNGP example", "user": {"login": "yw5aj", "id": 3477741, "node_id": "MDQ6VXNlcjM0Nzc3NDE=", "avatar_url": "https://avatars.githubusercontent.com/u/3477741?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yw5aj", "html_url": "https://github.com/yw5aj", "followers_url": "https://api.github.com/users/yw5aj/followers", "following_url": "https://api.github.com/users/yw5aj/following{/other_user}", "gists_url": "https://api.github.com/users/yw5aj/gists{/gist_id}", "starred_url": "https://api.github.com/users/yw5aj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yw5aj/subscriptions", "organizations_url": "https://api.github.com/users/yw5aj/orgs", "repos_url": "https://api.github.com/users/yw5aj/repos", "events_url": "https://api.github.com/users/yw5aj/events{/privacy}", "received_events_url": "https://api.github.com/users/yw5aj/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2023-02-03T05:27:33Z", "updated_at": "2023-02-03T17:44:00Z", "closed_at": "2023-02-03T17:43:59Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen running the VNNGP example, once we hit output = model(x=None) it will report: `RuntimeError: indices should be either on cpu or on the same device as the indexed tensor (cpu)`. \r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\nSimply run 04_Variational_and_Approximate_GPs/VNNGP.ipynb\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\nCell In[5], line 20\r\n     18 for i in minibatch_iter:\r\n     19     optimizer.zero_grad()\r\n---> 20     output = model(x=None)\r\n     21     # Obtain the indices for mini-batch data\r\n     22     current_training_indices = model.variational_strategy.current_training_indices\r\n\r\nCell In[4], line 34, in GPModel.__call__(self, x, prior, **kwargs)\r\n     32     if x.dim() == 1:\r\n     33         x = x.unsqueeze(-1)\r\n---> 34 return self.variational_strategy(x=x, prior=False, **kwargs)\r\n\r\nFile ~\\AppData\\Local\\mambaforge\\envs\\torch\\lib\\site-packages\\gpytorch\\variational\\nearest_neighbor_variational_strategy.py:129, in NNVariationalStrategy.__call__(self, x, prior, **kwargs)\r\n    127 if self.training:\r\n    128     self._clear_cache()\r\n--> 129     return self.forward(x, self.inducing_points, None, None)\r\n    130 else:\r\n    131     # Ensure inducing_points and x are the same size\r\n    132     inducing_points = self.inducing_points\r\n\r\nFile ~\\AppData\\Local\\mambaforge\\envs\\torch\\lib\\site-packages\\gpytorch\\variational\\nearest_neighbor_variational_strategy.py:168, in NNVariationalStrategy.forward(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\r\n    165     if torch.cuda.is_available():\r\n    166         kl_indices = kl_indices.cuda()\r\n--> 168 kl = self._kl_divergence(kl_indices)\r\n    169 add_to_cache(self, \"kl_divergence_memo\", kl)\r\n    171 return MultivariateNormal(predictive_mean, DiagLinearOperator(predictive_var))\r\n\r\nFile ~\\AppData\\Local\\mambaforge\\envs\\torch\\lib\\site-packages\\gpytorch\\variational\\nearest_neighbor_variational_strategy.py:325, in NNVariationalStrategy._kl_divergence(self, kl_indices, compute_full, batch_size)\r\n    323         kl = self._firstk_kl_helper() * self.M / self.k\r\n    324     else:\r\n--> 325         kl = self._stochastic_kl_helper(kl_indices) * self.M / len(kl_indices)\r\n    326 return kl\r\n\r\nFile ~\\AppData\\Local\\mambaforge\\envs\\torch\\lib\\site-packages\\gpytorch\\variational\\nearest_neighbor_variational_strategy.py:263, in NNVariationalStrategy._stochastic_kl_helper(self, kl_indices)\r\n    261 # Select a mini-batch of inducing points according to kl_indices, and their k-nearest neighbors\r\n    262 inducing_points = self.inducing_points[..., kl_indices, :]\r\n--> 263 nearest_neighbor_indices = self.nn_xinduce_idx[..., kl_indices - self.k, :].to(inducing_points.device)\r\n    264 expanded_inducing_points_all = self.inducing_points.unsqueeze(-2).expand(\r\n    265     *self._inducing_batch_shape, self.M, self.k, self.D\r\n    266 )\r\n    267 expanded_nearest_neighbor_indices = nearest_neighbor_indices.unsqueeze(-1).expand(\r\n    268     *self._inducing_batch_shape, kl_bs, self.k, self.D\r\n    269 )\r\n\r\nRuntimeError: indices should be either on cpu or on the same device as the indexed tensor (cpu)\r\n\r\n```\r\n\r\n## Expected Behavior\r\n\r\nNo error\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> GPyTorch 1.9.1\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> PyTorch 1.13.1\r\n- <!-- Computer OS --> Windows 10 with GPU set up\r\n\r\n## Additional context\r\nThe mat file download needs to be manually done via web browser.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2266/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2266/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2258", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2258/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2258/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2258/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2258", "id": 1551936012, "node_id": "I_kwDOBZhSr85cgKoM", "number": 2258, "title": "[Bug] constraints.Interval is overzealous in forcing GPU synchronizes", "user": {"login": "mrcslws", "id": 364113, "node_id": "MDQ6VXNlcjM2NDExMw==", "avatar_url": "https://avatars.githubusercontent.com/u/364113?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrcslws", "html_url": "https://github.com/mrcslws", "followers_url": "https://api.github.com/users/mrcslws/followers", "following_url": "https://api.github.com/users/mrcslws/following{/other_user}", "gists_url": "https://api.github.com/users/mrcslws/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrcslws/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrcslws/subscriptions", "organizations_url": "https://api.github.com/users/mrcslws/orgs", "repos_url": "https://api.github.com/users/mrcslws/repos", "events_url": "https://api.github.com/users/mrcslws/events{/privacy}", "received_events_url": "https://api.github.com/users/mrcslws/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2023-01-21T23:08:24Z", "updated_at": "2023-01-30T21:43:31Z", "closed_at": "2023-01-30T21:43:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nBy default, if any model parameters use a `constraints.Interval`, fetching these parameters forces a GPU synchronize on every forward pass, due to this line:\r\n\r\nhttps://github.com/cornellius-gp/gpytorch/blob/2e1ccec055dc02e8320e79a77d7a4419e269ede3/gpytorch/constraints/constraints.py#L118\r\n\r\nTrue, this code can be disabled by calling `gpytorch.settings.debug._set_state(False)`, but even with debug enabled this check ought to only happen once, not on every `transform`.\r\n\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport gpytorch\r\nimport torch\r\n\r\ndevice = torch.device(\"cuda\")\r\ninterval = gpytorch.constraints.Interval(0, 1).to(device)\r\nraw = torch.tensor([-0.42], device=device)\r\n\r\n# Arguably it's okay for this check to occur on the first transform.\r\n# If you choose that fix, then uncomment this line to test your fix.\r\n# constrained = interval.transform(raw)\r\n\r\ntorch.cuda.set_sync_debug_mode(2)\r\nconstrained = interval.transform(raw)\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"bug.py\", line 17, in <module>\r\n    constrained = interval.transform(raw)\r\n  File \"/opt/conda/envs/py39/lib/python3.9/site-packages/gpytorch/constraints/constraints.py\", line 118, in transform\r\n    if max_bound == math.inf or min_bound == -math.inf:\r\nRuntimeError: called a synchronizing CUDA operation\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThis sync should happen at most once, since `lower_bound` and `upper_bound` are constant.\r\n\r\n- Easy fix: Add a flag on the `self` to denote whether the check has occurred, and only perform the check on the first call to `transform` or `untransform`\r\n- More elegant fix: this check should happen during `__init__` (but this would require some refactoring)\r\n\r\n## System information\r\n\r\ngpytorch: 1.9.1\r\ntorch: 1.13.1+cu116\r\nLinux\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2258/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2258/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2244", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2244/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2244/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2244/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2244", "id": 1524023926, "node_id": "I_kwDOBZhSr85a1sJ2", "number": 2244, "title": "[Bug] settings.variational_cholesky_jitter does not work in run time ", "user": {"login": "LuhuanWu", "id": 18184608, "node_id": "MDQ6VXNlcjE4MTg0NjA4", "avatar_url": "https://avatars.githubusercontent.com/u/18184608?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LuhuanWu", "html_url": "https://github.com/LuhuanWu", "followers_url": "https://api.github.com/users/LuhuanWu/followers", "following_url": "https://api.github.com/users/LuhuanWu/following{/other_user}", "gists_url": "https://api.github.com/users/LuhuanWu/gists{/gist_id}", "starred_url": "https://api.github.com/users/LuhuanWu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LuhuanWu/subscriptions", "organizations_url": "https://api.github.com/users/LuhuanWu/orgs", "repos_url": "https://api.github.com/users/LuhuanWu/repos", "events_url": "https://api.github.com/users/LuhuanWu/events{/privacy}", "received_events_url": "https://api.github.com/users/LuhuanWu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-01-07T18:00:53Z", "updated_at": "2023-03-06T22:55:53Z", "closed_at": "2023-03-06T22:55:53Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n## To reproduce\r\n\r\nUsing `settings.variational_cholesky_jitter` in the model run time does not change the actual jitter value \r\n\r\n** Code snippet to reproduce **\r\n```python\r\nfrom gpytorch.models import ApproximateGP\r\nfrom gpytorch.variational import CholeskyVariationalDistribution\r\nfrom gpytorch.variational import VariationalStrategy\r\nfrom gpytorch import settings\r\n\r\nclass GPModel(ApproximateGP):\r\n    def __init__(self, inducing_points):\r\n        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\r\n        variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\r\n        super(GPModel, self).__init__(variational_strategy)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\ntrain_x = torch.randn(10)\r\ninducing_points = train_x\r\nmodel = GPModel(inducing_points=inducing_points)\r\n\r\nwith settings.variational_cholesky_jitter(float_value=1e-2):\r\n    print(model.variational_strategy.jitter_val)\r\n```\r\n\r\n** Stack trace/error message **\r\n\r\nThe printed output is 0.0001, which is the default jitter value. \r\n\r\n\r\n## Expected Behavior\r\n\r\nExpected value is 1e-2. \r\n\r\n## Additional context\r\nIn fact, the jitter value can be set through `settings` when instantiating the model: \r\n```\r\nwith settings.variational_cholesky_jitter(float_value=1e-2):\r\n    model = GPModel(inducing_points=inducing_points)\r\n    print(model.variational_strategy.jitter_val)\r\n```\r\nThe printed output is 1e-2, which is expected. However, such way of setting variational_cholesky_jitter value is not consistent with other settings, e.g. `settings.cholesky_jitter`. \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2244/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2244/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2225", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2225/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2225/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2225/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2225", "id": 1496930595, "node_id": "I_kwDOBZhSr85ZOVkj", "number": 2225, "title": "[Bug] torch.float62 raises error in `GridInterpolationKernel`", "user": {"login": "anjawa", "id": 45797941, "node_id": "MDQ6VXNlcjQ1Nzk3OTQx", "avatar_url": "https://avatars.githubusercontent.com/u/45797941?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anjawa", "html_url": "https://github.com/anjawa", "followers_url": "https://api.github.com/users/anjawa/followers", "following_url": "https://api.github.com/users/anjawa/following{/other_user}", "gists_url": "https://api.github.com/users/anjawa/gists{/gist_id}", "starred_url": "https://api.github.com/users/anjawa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anjawa/subscriptions", "organizations_url": "https://api.github.com/users/anjawa/orgs", "repos_url": "https://api.github.com/users/anjawa/repos", "events_url": "https://api.github.com/users/anjawa/events{/privacy}", "received_events_url": "https://api.github.com/users/anjawa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-12-14T15:56:07Z", "updated_at": "2023-01-17T08:40:12Z", "closed_at": "2023-01-17T08:40:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI want to sample from the prior distribution with precision torch.float62 \r\nHowever, during sampling with KISS-GP a dtype error is raised\r\nif I manually design a kernel (very similar to the RBF Kernel)\r\nthat is included in the `GridInterpolationKernel`.\r\n\r\nChanging the test data size from `2500x2` to `100x2`, no error will occur.\r\n```python\r\nx = torch.meshgrid(\r\n    torch.linspace(0, 10 - 1, 10) * 1.,\r\n    torch.linspace(0, 10 - 1, 10) * 1.,\r\n    indexing=\"xy\",\r\n)\r\nx = torch.cat(\r\n    (\r\n        x[0].contiguous().view(x[0].numel(), 1),\r\n        x[1].contiguous().view(x[1].numel(), 1),\r\n    ),\r\n    dim=1,\r\n)\r\n``` \r\n## To reproduce\r\n\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\n\r\ntorch.set_default_dtype(torch.float64)\r\n\r\n\r\ndef postprocess_rot(dist_mat):\r\n    return dist_mat.mul_(-1.0).exp_()\r\n\r\nclass TestKernel(gpytorch.kernels.Kernel):\r\n\r\n    is_stationary = True\r\n\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n\r\n    def forward(self, x1, x2, **params):\r\n        x1_ = x1.div_(torch.tensor([10., 1.]))\r\n        x2_ = x2.div_(torch.tensor([10., 1.]))\r\n        return self.covar_dist(\r\n            x1_, x2_, square_dist=False, dist_postprocess_func=postprocess_rot, **params\r\n        )\r\n\r\nclass ExactGP(gpytorch.models.ExactGP):\r\n\r\n    def __init__(self, **kwargs):\r\n        super().__init__(None, None, gpytorch.likelihoods.GaussianLikelihood())\r\n        self.mean_module = gpytorch.means.ZeroMean()\r\n        self.covar_module = gpytorch.kernels.GridInterpolationKernel(\r\n            TestKernel(ard_num_dims=2, **kwargs),\r\n            grid_size=100,\r\n            num_dims=2\r\n            )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\nx = torch.meshgrid(\r\n    torch.linspace(0, 50 - 1, 50) * 1.,\r\n    torch.linspace(0, 50 - 1, 50) * 1.,\r\n    indexing=\"xy\",\r\n)\r\nx = torch.cat(\r\n    (\r\n        x[0].contiguous().view(x[0].numel(), 1),\r\n        x[1].contiguous().view(x[1].numel(), 1),\r\n    ),\r\n    dim=1,\r\n)\r\n\r\nmodel = ExactGP()\r\nmodel.eval()\r\n\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.settings.max_root_decomposition_size(100):\r\n    with gpytorch.settings.fast_pred_samples():\r\n        samples = model(x).rsample(torch.Size([1]))\r\n\r\n```\r\n\r\n** Error message **\r\n```\r\nexpected scalar type Double but found Float\r\n```\r\n\r\n## System information\r\n\r\ntorch=1.13.0\r\ngpytorch=1.9.0", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2225/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2225/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2220", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2220/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2220/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2220/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2220", "id": 1482640165, "node_id": "I_kwDOBZhSr85YX0sl", "number": 2220, "title": "[Bug] Missing argument to value() in _dtype_value_context __init__()", "user": {"login": "CarloGraziani", "id": 11160521, "node_id": "MDQ6VXNlcjExMTYwNTIx", "avatar_url": "https://avatars.githubusercontent.com/u/11160521?v=4", "gravatar_id": "", "url": "https://api.github.com/users/CarloGraziani", "html_url": "https://github.com/CarloGraziani", "followers_url": "https://api.github.com/users/CarloGraziani/followers", "following_url": "https://api.github.com/users/CarloGraziani/following{/other_user}", "gists_url": "https://api.github.com/users/CarloGraziani/gists{/gist_id}", "starred_url": "https://api.github.com/users/CarloGraziani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/CarloGraziani/subscriptions", "organizations_url": "https://api.github.com/users/CarloGraziani/orgs", "repos_url": "https://api.github.com/users/CarloGraziani/repos", "events_url": "https://api.github.com/users/CarloGraziani/events{/privacy}", "received_events_url": "https://api.github.com/users/CarloGraziani/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-12-07T19:06:21Z", "updated_at": "2023-03-17T17:43:02Z", "closed_at": "2023-03-17T17:43:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nIn the definition of the class '_dtype_value_context' I believe that there is a bug that prevents the minimum noise variance from being changed from the default value.\r\n\r\n## The code:\r\n\r\n\r\n```python\r\n## *** gpytorch.settings ***\r\n##\r\nclass _dtype_value_context:\r\n    _global_float_value = None\r\n    _global_double_value = None\r\n    _global_half_value = None\r\n\r\n    @classmethod\r\n    def value(cls, dtype):  ## <--  *** Expects to be called with a single argument, 'dtype'\r\n        if torch.is_tensor(dtype):\r\n            dtype = dtype.dtype\r\n        if dtype == torch.float:\r\n            return cls._global_float_value\r\n        elif dtype == torch.double:\r\n            return cls._global_double_value\r\n        elif dtype == torch.half:\r\n            return cls._global_half_value\r\n        else:\r\n            raise RuntimeError(f\"Unsupported dtype for {cls.__name__}.\")\r\n##\r\n## skip forward\r\n##\r\n    def __init__(self, float=None, double=None, half=None):\r\n        self._orig_float_value = self.__class__.value() ## <-- *** Called with no argument, fails here\r\n        self._instance_float_value = float\r\n        self._orig_double_value = self.__class__.value() ## <-- *** Also called with no argument.\r\n        self._instance_double_value = double\r\n        self._orig_half_value = self.__class__.value() ## <-- *** Also called with no argument.\r\n        self._instance_half_value = half\r\n\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n## Usual model setup assumed, elided. The key line and stack trace:\r\nnoise_lim = torch.tensor(1.0E-12)\r\nwith gpytorch.settings.min_variance(float=noise_lim, double=None, half=None):\r\n    likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=noise)\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n/tmp/ipykernel_78266/919393755.py in <module>\r\n      5 noise = noise.to(torch.float32)\r\n      6 noise_lim = torch.tensor(1.0E-12)\r\n----> 7 with gpytorch.settings.min_variance(float=noise_lim, double=None, half=None):\r\n      8     likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=noise)\r\n\r\n\r\n~/python_venvs/pytorch.venv/lib/python3.8/site-packages/gpytorch/settings.py in __init__(self, float, double, half)\r\n     58 \r\n     59     def __init__(self, float=None, double=None, half=None):\r\n---> 60         self._orig_float_value = self.__class__.value()\r\n     61         self._instance_float_value = float\r\n     62         self._orig_double_value = self.__class__.value()\r\n\r\nTypeError: value() missing 1 required positional argument: 'dtype'\r\n```\r\n\r\nIt appears to me that the problem is that the call to 'value()' with the empty argument list indicated above is missing the tensor containing the dtype information that 'value()' relies upon to decide which class value to return.\r\n\r\n\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 1.9.0\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> 1.12.1+cu102\r\n- <!-- Computer OS --> Linux Ubuntu 20.03\r\n\r\n## Additional context\r\nI noticed that '_dtype_value_context_', beside being in 'settings.min_variance', is also used in a setting called 'settings.min_fixed_noise', which is not yet in the documentation, but which is used in the fixed noise likelihood. It would be a good idea to add it to the docs.  Doesn't seem worth adding as a separate issue, though.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2220/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2220/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2216", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2216/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2216/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2216/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2216", "id": 1475806048, "node_id": "I_kwDOBZhSr85X9wNg", "number": 2216, "title": "[Bug] VNNGP Example throwing an Error", "user": {"login": "mbelalsh", "id": 55949718, "node_id": "MDQ6VXNlcjU1OTQ5NzE4", "avatar_url": "https://avatars.githubusercontent.com/u/55949718?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mbelalsh", "html_url": "https://github.com/mbelalsh", "followers_url": "https://api.github.com/users/mbelalsh/followers", "following_url": "https://api.github.com/users/mbelalsh/following{/other_user}", "gists_url": "https://api.github.com/users/mbelalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/mbelalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mbelalsh/subscriptions", "organizations_url": "https://api.github.com/users/mbelalsh/orgs", "repos_url": "https://api.github.com/users/mbelalsh/repos", "events_url": "https://api.github.com/users/mbelalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/mbelalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-12-05T06:38:10Z", "updated_at": "2022-12-09T22:49:38Z", "closed_at": "2022-12-09T22:49:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug VNNGP Example throwing an Error\r\n\r\nHello there. I am trying to run Variational Nearest Neighbor Gaussian Process (VNNGP) example from this webpage [VNGPP](https://docs.gpytorch.ai/en/stable/examples/04_Variational_and_Approximate_GPs/VNNGP.html). \r\n\r\nWhen I run this example, it throws an error which is given below. It throws the same error on my dataset as well. \r\nThere are two training modes on the examples webpage to train VNNGP; both are throwing the same error.\r\nI downloaded the elevator dataset from one of the posts here since the link that you provided in the example is broken. \r\n\r\nA little bit about the error:\r\nThis code `nearest_neighbor_indices = self.nn_xinduce_idx[..., kl_indices - self.k, :].to(inducing_points.device)\r\n` is seemingly causing the error. As per my information, `kl_indices` and `self.nn_xinduce_idx` are both on CPU, and I was able to put them on GPU by explicitly calling inside the `GPModel` class\r\n\r\n\r\nThe code is given below:\r\n\r\n``` python\r\nimport tqdm\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\nfrom torch.utils.data import TensorDataset, DataLoader\r\n\r\n# Make plots inline\r\n%matplotlib inline \r\n```\r\n```python\r\nimport urllib.request\r\nimport os\r\nfrom scipy.io import loadmat\r\nfrom math import floor\r\n\r\n\r\ndata = torch.Tensor(loadmat('elevators.mat')['data'])\r\nX = data[:1000, :-1]\r\nX = X - X.min(0)[0]\r\nX = 2 * (X / X.max(0)[0].clamp_min(1e-6)) - 1\r\ny = data[:1000, -1]\r\ny = y.sub(y.mean()).div(y.std())\r\n\r\n\r\ntrain_n = int(floor(0.8 * len(X)))\r\ntrain_x = X[:train_n, :].contiguous()\r\ntrain_y = y[:train_n].contiguous()\r\n\r\ntest_x = X[train_n:, :].contiguous()\r\ntest_y = y[train_n:].contiguous()\r\n\r\nif torch.cuda.is_available():\r\n    train_x, train_y, test_x, test_y = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda()\r\n```\r\n```python\r\nfrom gpytorch.models import ApproximateGP\r\nfrom gpytorch.variational.nearest_neighbor_variational_strategy import NNVariationalStrategy\r\n\r\n\r\nclass GPModel(ApproximateGP):\r\n    def __init__(self, inducing_points, likelihood, k=256, training_batch_size=256):\r\n\r\n        m, d = inducing_points.shape\r\n        self.m = m\r\n        self.k = k\r\n\r\n        variational_distribution = gpytorch.variational.MeanFieldVariationalDistribution(m)\r\n         \r\n        if torch.cuda.is_available():\r\n            inducing_points = inducing_points.cuda()\r\n\r\n        variational_strategy = NNVariationalStrategy(self, inducing_points, variational_distribution, k=k,\r\n                                                     training_batch_size=training_batch_size)\r\n\r\n        # Trying to DEBUG (IT WORKS HERE BUT NOT INSIDE CODEBASE)\r\n        print(variational_strategy.inducing_points.device)\r\n        kl_indices1 = variational_strategy._get_training_indices()\r\n        print(variational_strategy.nn_xinduce_idx[..., kl_indices1 - variational_strategy.k, :].to(variational_strategy.inducing_points.device))\r\n        \r\n        \r\n        super(GPModel, self).__init__(variational_strategy)\r\n        self.mean_module = gpytorch.means.ZeroMean()\r\n        self.covar_module = gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=d)\r\n\r\n        self.likelihood = likelihood\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n    def __call__(self, x, prior=False, **kwargs):\r\n        if x is not None:\r\n            if x.dim() == 1:\r\n                x = x.unsqueeze(-1)\r\n        return self.variational_strategy(x=x, prior=False, **kwargs)\r\n\r\nif smoke_test:\r\n    k = 32\r\n    training_batch_size = 32\r\nelse:\r\n    k = 256\r\n    training_batch_size = 64\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n# Note: one should use full training set as inducing points!\r\nmodel = GPModel(inducing_points=train_x, likelihood=likelihood, k=k, training_batch_size=training_batch_size)\r\n\r\nif torch.cuda.is_available():\r\n    likelihood = likelihood.cuda()\r\n    model = model.cuda()\r\n```\r\nOUTPUT of the above cell \r\n\r\n```\r\ncuda:0\r\ntensor([[457, 475, 435,  ..., 264, 400, 204],\r\n        [266,  79, 309,  ..., 139, 129, 280],\r\n        [228, 269, 150,  ..., 199, 144, 101],\r\n        ...,\r\n        [153,  60, 573,  ..., 403,  57, 564],\r\n        [ 32, 342, 715,  ..., 382, 336, 469],\r\n        [656, 522, 352,  ..., 668, 313, 131]], device='cuda:0')\r\n```\r\n\r\n```python\r\nnum_epochs = 1 if smoke_test else 20\r\nnum_batches = model.variational_strategy._total_training_batches\r\n\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\r\n\r\n# Our loss object. We're using the VariationalELBO\r\nmll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\r\n\r\n\r\nepochs_iter = tqdm.notebook.tqdm(range(num_epochs), desc=\"Epoch\")\r\nfor epoch in epochs_iter:\r\n    minibatch_iter = tqdm.notebook.tqdm(range(num_batches), desc=\"Minibatch\", leave=False)\r\n\r\n    for i in minibatch_iter:\r\n        optimizer.zero_grad()\r\n        output = model(x=None)\r\n        # Obtain the indices for mini-batch data\r\n        current_training_indices = model.variational_strategy.current_training_indices\r\n        # Obtain the y_batch using indices. It is important to keep the same order of train_x and train_y\r\n        y_batch = train_y[...,current_training_indices]\r\n        if torch.cuda.is_available():\r\n            y_batch = y_batch.cuda()\r\n        loss = -mll(output, y_batch)\r\n        minibatch_iter.set_postfix(loss=loss.item())\r\n        loss.backward()\r\n        optimizer.step()\r\n```\r\n\r\nThe ERROR is:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\nInput In [12], in <cell line: 15>()\r\n     18 for i in minibatch_iter:\r\n     19     optimizer.zero_grad()\r\n---> 20     output = model(x=None)\r\n     21     # Obtain the indices for mini-batch data\r\n     22     current_training_indices = model.variational_strategy.current_training_indices\r\n\r\nInput In [11], in GPModel.__call__(self, x, prior, **kwargs)\r\n     32     if x.dim() == 1:\r\n     33         x = x.unsqueeze(-1)\r\n---> 34 return self.variational_strategy(x=x, prior=False, **kwargs)\r\n\r\nFile /work/flemingc/belal/anaconda3/envs/pytorch/lib/python3.10/site-packages/gpytorch/variational/nearest_neighbor_variational_strategy.py:131, in NNVariationalStrategy.__call__(self, x, prior, **kwargs)\r\n    129 if self.training:\r\n    130     self._clear_cache()\r\n--> 131     return self.forward(x, self.inducing_points, None, None)\r\n    132 else:\r\n    133     # Ensure inducing_points and x are the same size\r\n    134     inducing_points = self.inducing_points\r\n\r\nFile /work/flemingc/belal/anaconda3/envs/pytorch/lib/python3.10/site-packages/gpytorch/variational/nearest_neighbor_variational_strategy.py:168, in NNVariationalStrategy.forward(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\r\n    165     # sample a different indices for stochastic estimation of kl\r\n    166     kl_indices = self._get_training_indices()\r\n--> 168 kl = self._kl_divergence(kl_indices)\r\n    169 add_to_cache(self, \"kl_divergence_memo\", kl)\r\n    171 return MultivariateNormal(predictive_mean, DiagLinearOperator(predictive_var))\r\n\r\nFile /work/flemingc/belal/anaconda3/envs/pytorch/lib/python3.10/site-packages/gpytorch/variational/nearest_neighbor_variational_strategy.py:327, in NNVariationalStrategy._kl_divergence(self, kl_indices, compute_full, batch_size)\r\n    325         kl = self._firstk_kl_helper() * self.M / self.k\r\n    326     else:\r\n--> 327         kl = self._stochastic_kl_helper(kl_indices) * self.M / len(kl_indices)\r\n    328 return kl\r\n\r\nFile /work/flemingc/belal/anaconda3/envs/pytorch/lib/python3.10/site-packages/gpytorch/variational/nearest_neighbor_variational_strategy.py:265, in NNVariationalStrategy._stochastic_kl_helper(self, kl_indices)\r\n    263 # Select a mini-batch of inducing points according to kl_indices, and their k-nearest neighbors\r\n    264 inducing_points = self.inducing_points[..., kl_indices, :]\r\n--> 265 nearest_neighbor_indices = self.nn_xinduce_idx[..., kl_indices - self.k, :].to(inducing_points.device)\r\n    266 expanded_inducing_points_all = self.inducing_points.unsqueeze(-2).expand(\r\n    267     *self._inducing_batch_shape, self.M, self.k, self.D\r\n    268 )\r\n    269 expanded_nearest_neighbor_indices = nearest_neighbor_indices.unsqueeze(-1).expand(\r\n    270     *self._inducing_batch_shape, kl_bs, self.k, self.D\r\n    271 )\r\n\r\nRuntimeError: indices should be either on cpu or on the same device as the indexed tensor (cpu)\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2216/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2216/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2211", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2211/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2211/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2211/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2211", "id": 1470137324, "node_id": "I_kwDOBZhSr85XoIPs", "number": 2211, "title": "[Bug] Use of zip leads to silent incomplete evaluation of IndependentModelList", "user": {"login": "saitcakmak", "id": 9263852, "node_id": "MDQ6VXNlcjkyNjM4NTI=", "avatar_url": "https://avatars.githubusercontent.com/u/9263852?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saitcakmak", "html_url": "https://github.com/saitcakmak", "followers_url": "https://api.github.com/users/saitcakmak/followers", "following_url": "https://api.github.com/users/saitcakmak/following{/other_user}", "gists_url": "https://api.github.com/users/saitcakmak/gists{/gist_id}", "starred_url": "https://api.github.com/users/saitcakmak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saitcakmak/subscriptions", "organizations_url": "https://api.github.com/users/saitcakmak/orgs", "repos_url": "https://api.github.com/users/saitcakmak/repos", "events_url": "https://api.github.com/users/saitcakmak/events{/privacy}", "received_events_url": "https://api.github.com/users/saitcakmak/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "saitcakmak", "id": 9263852, "node_id": "MDQ6VXNlcjkyNjM4NTI=", "avatar_url": "https://avatars.githubusercontent.com/u/9263852?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saitcakmak", "html_url": "https://github.com/saitcakmak", "followers_url": "https://api.github.com/users/saitcakmak/followers", "following_url": "https://api.github.com/users/saitcakmak/following{/other_user}", "gists_url": "https://api.github.com/users/saitcakmak/gists{/gist_id}", "starred_url": "https://api.github.com/users/saitcakmak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saitcakmak/subscriptions", "organizations_url": "https://api.github.com/users/saitcakmak/orgs", "repos_url": "https://api.github.com/users/saitcakmak/repos", "events_url": "https://api.github.com/users/saitcakmak/events{/privacy}", "received_events_url": "https://api.github.com/users/saitcakmak/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "saitcakmak", "id": 9263852, "node_id": "MDQ6VXNlcjkyNjM4NTI=", "avatar_url": "https://avatars.githubusercontent.com/u/9263852?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saitcakmak", "html_url": "https://github.com/saitcakmak", "followers_url": "https://api.github.com/users/saitcakmak/followers", "following_url": "https://api.github.com/users/saitcakmak/following{/other_user}", "gists_url": "https://api.github.com/users/saitcakmak/gists{/gist_id}", "starred_url": "https://api.github.com/users/saitcakmak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saitcakmak/subscriptions", "organizations_url": "https://api.github.com/users/saitcakmak/orgs", "repos_url": "https://api.github.com/users/saitcakmak/repos", "events_url": "https://api.github.com/users/saitcakmak/events{/privacy}", "received_events_url": "https://api.github.com/users/saitcakmak/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2022-11-30T19:45:57Z", "updated_at": "2023-01-13T22:17:24Z", "closed_at": "2023-01-13T22:17:24Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nDue to the use of `zip`, when fewer than # of models inputs are passed to `IndependentModelList.__call__/forward` (or even `fantasize`), it will only evaluate the first # of inputs models and ignore the rest. \r\n\r\n## To reproduce\r\n\r\nThis extracted from the unit tests for `IndependentModelList`, which also falls into this bug.\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport gpytorch\r\nfrom gpytorch.models import IndependentModelList\r\n\r\n\r\nclass ExactGPModel(ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super().__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\nN_PTS = 5\r\n\r\n\r\ndef create_test_data():\r\n    return torch.randn(N_PTS, 1)\r\n\r\n\r\ndef create_likelihood_and_labels():\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n    labels = torch.randn(N_PTS) + 2\r\n    return likelihood, labels\r\n\r\n\r\ndef create_model():\r\n    data = create_test_data()\r\n    likelihood, labels = create_likelihood_and_labels()\r\n    return ExactGPModel(data, labels, likelihood)\r\n\r\nmodels = [create_model() for _ in range(2)]\r\nmodel = IndependentModelList(*models)\r\nmodel.eval()\r\nmodel(torch.rand(3))\r\n# This outputs [MultivariateNormal(loc: torch.Size([3]))], which is the evaluation of the first model only.\r\n\r\nmodel(torch.rand(3), torch.rand(3))\r\n# This outputs [MultivariateNormal(loc: torch.Size([3])), MultivariateNormal(loc: torch.Size([3]))], which is both models.\r\n\r\n```\r\n\r\n## Expected Behavior\r\n\r\nEither error out when the # of inputs does not match # of models, or repeat the input if only a single tensor input is given. \r\nI'd be happy to patch this if we agree on a solution.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> GPyTorch: Latest\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> PyTorch: Latest\r\n- <!-- Computer OS --> OS: CentOS8\r\n\r\n## Additional context\r\nOriginally surfaced in https://github.com/pytorch/botorch/issues/1467\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2211/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2211/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2199", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2199/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2199/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2199/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2199", "id": 1458504019, "node_id": "I_kwDOBZhSr85W7wFT", "number": 2199, "title": "[Bug] PiecewisePolynomialKernel fails to put all tensors on the same GPU device", "user": {"login": "c-lyu", "id": 68106447, "node_id": "MDQ6VXNlcjY4MTA2NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/68106447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/c-lyu", "html_url": "https://github.com/c-lyu", "followers_url": "https://api.github.com/users/c-lyu/followers", "following_url": "https://api.github.com/users/c-lyu/following{/other_user}", "gists_url": "https://api.github.com/users/c-lyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/c-lyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/c-lyu/subscriptions", "organizations_url": "https://api.github.com/users/c-lyu/orgs", "repos_url": "https://api.github.com/users/c-lyu/repos", "events_url": "https://api.github.com/users/c-lyu/events{/privacy}", "received_events_url": "https://api.github.com/users/c-lyu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-11-21T20:04:17Z", "updated_at": "2022-12-09T23:16:07Z", "closed_at": "2022-12-09T23:16:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI was experimenting with the [tutorial of Exact GP multiple GPUs here](https://docs.gpytorch.ai/en/stable/examples/02_Scalable_Exact_GPs/Simple_MultiGPU_GP_Regression.html). However, when the base kernel was changed from **RBF kernel** to **piecewise polynomial kernel**, an error showed up that **tensors are not on the same device**.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nimport gpytorch\r\nfrom LBFGS import FullBatchLBFGS\r\n\r\nimport os\r\nimport numpy as np\r\nimport urllib.request\r\nfrom scipy.io import loadmat\r\ndataset = 'protein'\r\nif not os.path.isfile(f'../../datasets/UCI/{dataset}.mat'):\r\n    print(f'Downloading \\'{dataset}\\' UCI dataset...')\r\n    urllib.request.urlretrieve('https://drive.google.com/uc?export=download&id=1nRb8e7qooozXkNghC5eQS0JeywSXGX2S',\r\n                               f'../../datasets/UCI/{dataset}.mat')\r\n\r\ndata = torch.Tensor(loadmat(f'../../datasets/UCI/{dataset}.mat')['data'])\r\n\r\nn_train = 4000\r\ntrain_x, train_y = data[:n_train, :-1], data[:n_train, -1]\r\n\r\nn_devices = torch.cuda.device_count()\r\noutput_device = torch.device('cuda:0')\r\ntrain_x, train_y = train_x.contiguous().to(output_device), train_y.contiguous().to(output_device)\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood, n_devices):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        # change kernel here ----------------------------------------------------|\r\n        base_covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.PiecewisePolynomialKernel())\r\n\r\n        self.covar_module = gpytorch.kernels.MultiDeviceKernel(\r\n            base_covar_module, device_ids=range(n_devices),\r\n            output_device=output_device\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\ndef train(train_x,\r\n          train_y,\r\n          n_devices,\r\n          output_device,\r\n          checkpoint_size,\r\n          preconditioner_size,\r\n):\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood().to(output_device)\r\n    model = ExactGPModel(train_x, train_y, likelihood, n_devices).to(output_device)\r\n    model.train()\r\n    likelihood.train()\r\n\r\n    optimizer = FullBatchLBFGS(model.parameters(), lr=0.1)\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\n    with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\r\n         gpytorch.settings.max_preconditioner_size(preconditioner_size):\r\n\r\n        def closure():\r\n            optimizer.zero_grad()\r\n            output = model(train_x)\r\n            loss = -mll(output, train_y)\r\n            return loss\r\n\r\n        loss = closure()\r\n        loss.backward()\r\n\r\n        options = {'closure': closure, 'current_loss': loss, 'max_ls': 10}\r\n        loss, _, _, _, _, _, _, fail = optimizer.step(options)\r\n\r\n        print(loss.item())\r\n        \r\n    return model, likelihood\r\n\r\n_, _ = train(train_x, train_y,\r\n             n_devices=n_devices, output_device=output_device,\r\n             checkpoint_size=0, preconditioner_size=100)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\nInput In [4], in <cell line: 1>()\r\n----> 1 _, _ = train(train_x, train_y,\r\n      2              n_devices=n_devices, output_device=output_device,\r\n      3              checkpoint_size=0, preconditioner_size=100)\r\n\r\nInput In [3], in train(train_x, train_y, n_devices, output_device, checkpoint_size, preconditioner_size)\r\n     41     return loss\r\n     43 loss = closure()\r\n---> 44 loss.backward()\r\n     46 options = {'closure': closure, 'current_loss': loss, 'max_ls': 10}\r\n     47 loss, _, _, _, _, _, _, fail = optimizer.step(options)\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/torch/_tensor.py:396, in Tensor.backward(self, gradient, retain_graph, create_graph, inputs)\r\n    387 if has_torch_function_unary(self):\r\n    388     return handle_torch_function(\r\n    389         Tensor.backward,\r\n    390         (self,),\r\n   (...)\r\n    394         create_graph=create_graph,\r\n    395         inputs=inputs)\r\n--> 396 torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/torch/autograd/__init__.py:173, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\r\n    168     retain_graph = create_graph\r\n    170 # The reason we repeat same the comment below is that\r\n    171 # some Python versions print out the first line of a multi-line function\r\n    172 # calls in the traceback and some print out the last line\r\n--> 173 Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\r\n    174     tensors, grad_tensors_, retain_graph, create_graph, inputs,\r\n    175     allow_unreachable=True, accumulate_grad=True)\r\n\r\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu!\r\n```\r\n\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version: 1.9.0\r\n- PyTorch Version: 1.12.1\r\n- Computer OS: Ubuntu 16.04.5 LTS\r\n- CUDA version: 11.3\r\n- CUDA devices: two NVIDIA 3090\r\n\r\n## Additional context\r\nI further experimented with training size and similar issue showed up when `n_train = 100` using **RBF kernel**. Please see the error message below. \r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\nInput In [4], in <cell line: 1>()\r\n----> 1 _, _ = train(train_x, train_y,\r\n      2              n_devices=n_devices, output_device=output_device,\r\n      3              checkpoint_size=0, preconditioner_size=100)\r\n\r\nInput In [3], in train(train_x, train_y, n_devices, output_device, checkpoint_size, preconditioner_size)\r\n     40     loss = -mll(output, train_y)\r\n     41     return loss\r\n---> 43 loss = closure()\r\n     44 loss.backward()\r\n     46 options = {'closure': closure, 'current_loss': loss, 'max_ls': 10}\r\n\r\nInput In [3], in train.<locals>.closure()\r\n     38 optimizer.zero_grad()\r\n     39 output = model(train_x)\r\n---> 40 loss = -mll(output, train_y)\r\n     41 return loss\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/gpytorch/module.py:30, in Module.__call__(self, *inputs, **kwargs)\r\n     29 def __call__(self, *inputs, **kwargs):\r\n---> 30     outputs = self.forward(*inputs, **kwargs)\r\n     31     if isinstance(outputs, list):\r\n     32         return [_validate_module_outputs(output) for output in outputs]\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py:64, in ExactMarginalLogLikelihood.forward(self, function_dist, target, *params)\r\n     62 # Get the log prob of the marginal distribution\r\n     63 output = self.likelihood(function_dist, *params)\r\n---> 64 res = output.log_prob(target)\r\n     65 res = self._add_other_terms(res, params)\r\n     67 # Scale by the amount of data we have\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:169, in MultivariateNormal.log_prob(self, value)\r\n    167 # Get log determininant and first part of quadratic form\r\n    168 covar = covar.evaluate_kernel()\r\n--> 169 inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n    171 res = -0.5 * sum([inv_quad, logdet, diff.size(-1) * math.log(2 * math.pi)])\r\n    172 return res\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/linear_operator/operators/_linear_operator.py:1594, in LinearOperator.inv_quad_logdet(self, inv_quad_rhs, logdet, reduce_inv_quad)\r\n   1592             will_need_cholesky = False\r\n   1593     if will_need_cholesky:\r\n-> 1594         cholesky = CholLinearOperator(TriangularLinearOperator(self.cholesky()))\r\n   1595     return cholesky.inv_quad_logdet(\r\n   1596         inv_quad_rhs=inv_quad_rhs,\r\n   1597         logdet=logdet,\r\n   1598         reduce_inv_quad=reduce_inv_quad,\r\n   1599     )\r\n   1601 # Short circuit to inv_quad function if we're not computing logdet\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/linear_operator/operators/_linear_operator.py:1229, in LinearOperator.cholesky(self, upper)\r\n   1221 @_implements(torch.linalg.cholesky)\r\n   1222 def cholesky(self, upper: bool = False) -> \"TriangularLinearOperator\":  # noqa F811\r\n   1223     \"\"\"\r\n   1224     Cholesky-factorizes the LinearOperator.\r\n   1225 \r\n   1226     :param upper: Upper triangular or lower triangular factor (default: False).\r\n   1227     :return: Cholesky factor (lower or upper triangular)\r\n   1228     \"\"\"\r\n-> 1229     chol = self._cholesky(upper=False)\r\n   1230     if upper:\r\n   1231         chol = chol._transpose_nonbatch()\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/linear_operator/utils/memoize.py:59, in _cached.<locals>.g(self, *args, **kwargs)\r\n     57 kwargs_pkl = pickle.dumps(kwargs)\r\n     58 if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59     return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60 return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/linear_operator/operators/_linear_operator.py:483, in LinearOperator._cholesky(self, upper)\r\n    480 if any(isinstance(sub_mat, KeOpsLinearOperator) for sub_mat in evaluated_kern_mat._args):\r\n    481     raise RuntimeError(\"Cannot run Cholesky with KeOps: it will either be really slow or not work.\")\r\n--> 483 evaluated_mat = evaluated_kern_mat.to_dense()\r\n    485 # if the tensor is a scalar, we can just take the square root\r\n    486 if evaluated_mat.size(-1) == 1:\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/linear_operator/utils/memoize.py:59, in _cached.<locals>.g(self, *args, **kwargs)\r\n     57 kwargs_pkl = pickle.dumps(kwargs)\r\n     58 if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59     return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60 return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/linear_operator/operators/sum_linear_operator.py:68, in SumLinearOperator.to_dense(self)\r\n     66 @cached\r\n     67 def to_dense(self):\r\n---> 68     return (sum(linear_op.to_dense() for linear_op in self.linear_ops)).contiguous()\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/linear_operator/operators/sum_linear_operator.py:68, in <genexpr>(.0)\r\n     66 @cached\r\n     67 def to_dense(self):\r\n---> 68     return (sum(linear_op.to_dense() for linear_op in self.linear_ops)).contiguous()\r\n\r\nFile ~/anaconda3/envs/pyg/lib/python3.8/site-packages/linear_operator/operators/cat_linear_operator.py:378, in CatLinearOperator.to_dense(self)\r\n    377 def to_dense(self):\r\n--> 378     return torch.cat([to_dense(L) for L in self.linear_ops], dim=self.cat_dim)\r\n\r\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1! (when checking argument for argument tensors in method wrapper_cat)\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2199/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2199/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2197", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2197/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2197/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2197/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2197", "id": 1456047678, "node_id": "I_kwDOBZhSr85WyYY-", "number": 2197, "title": "[Bug] Bug Name won't fit in description (Runtime Error)", "user": {"login": "ajohnson114", "id": 67026227, "node_id": "MDQ6VXNlcjY3MDI2MjI3", "avatar_url": "https://avatars.githubusercontent.com/u/67026227?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ajohnson114", "html_url": "https://github.com/ajohnson114", "followers_url": "https://api.github.com/users/ajohnson114/followers", "following_url": "https://api.github.com/users/ajohnson114/following{/other_user}", "gists_url": "https://api.github.com/users/ajohnson114/gists{/gist_id}", "starred_url": "https://api.github.com/users/ajohnson114/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ajohnson114/subscriptions", "organizations_url": "https://api.github.com/users/ajohnson114/orgs", "repos_url": "https://api.github.com/users/ajohnson114/repos", "events_url": "https://api.github.com/users/ajohnson114/events{/privacy}", "received_events_url": "https://api.github.com/users/ajohnson114/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-11-19T00:37:09Z", "updated_at": "2022-11-28T20:41:47Z", "closed_at": "2022-11-28T20:41:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was following the gpr tutorial but I didn't do the sin function for my train_y as opposed to a custom function.\r\nTutorial found here: https://docs.gpytorch.ai/en/latest/examples/01_Exact_GPs/Simple_GP_Regression.html\r\n\r\n**Potentially Important note: I'm on a Mac M1 2020 so I'm not using a cuda gpu but I'm not sure if that's part of the issue.**\r\n\r\n**Code to reproduce:**\r\n\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\n%matplotlib inline\r\n%load_ext autoreload\r\n%autoreload 2\r\n\r\n# Training data is 100 points in [0,1] inclusive regularly spaced\r\ntrain_x = torch.linspace(-10, 10, 1000,dtype=float)\r\n# True function is sin(2*pi*x) with Gaussian noise\r\ntrain_y = train_x**3 - 2*train_x + 7 + torch.normal(0,100,(1000,))\r\ntrain_y = torch.tensor(train_y,dtype=float) # I added this in to try to fix the issue but the bug occurs with or without this \r\n\r\n# We will use the simplest form of GP model, exact inference\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n# initialize likelihood and model\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n\r\ntraining_iter = 100\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iter):\r\n    # Zero gradients from previous iteration\r\n    optimizer.zero_grad()\r\n    # Output from model\r\n    output = model(train_x)\r\n    # Calc loss and backprop gradients\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\r\n        i + 1, training_iter, loss.item(),\r\n        model.covar_module.base_kernel.lengthscale.item(),\r\n        model.likelihood.noise.item()\r\n    ))\r\n    optimizer.step()\r\n\r\n**The bug that I was told to report:**\r\n\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\nInput In [129], in <cell line: 13>()\r\n     17 output = model(train_x)\r\n     18 # Calc loss and backprop gradients\r\n---> 19 loss = -mll(output, train_y)\r\n     20 loss.backward()\r\n     21 print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\r\n     22     i + 1, training_iter, loss.item(),\r\n     23     model.covar_module.base_kernel.lengthscale.item(),\r\n     24     model.likelihood.noise.item()\r\n     25 ))\r\n\r\nFile ~/miniforge3/envs/tf_m1/lib/python3.9/site-packages/gpytorch/module.py:30, in Module.__call__(self, *inputs, **kwargs)\r\n     29 def __call__(self, *inputs, **kwargs):\r\n---> 30     outputs = self.forward(*inputs, **kwargs)\r\n     31     if isinstance(outputs, list):\r\n     32         return [_validate_module_outputs(output) for output in outputs]\r\n\r\nFile ~/miniforge3/envs/tf_m1/lib/python3.9/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py:64, in ExactMarginalLogLikelihood.forward(self, function_dist, target, *params)\r\n     62 # Get the log prob of the marginal distribution\r\n     63 output = self.likelihood(function_dist, *params)\r\n---> 64 res = output.log_prob(target)\r\n     65 res = self._add_other_terms(res, params)\r\n     67 # Scale by the amount of data we have\r\n\r\nFile ~/miniforge3/envs/tf_m1/lib/python3.9/site-packages/gpytorch/distributions/multivariate_normal.py:169, in MultivariateNormal.log_prob(self, value)\r\n    167 # Get log determininant and first part of quadratic form\r\n    168 covar = covar.evaluate_kernel()\r\n--> 169 inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n    171 res = -0.5 * sum([inv_quad, logdet, diff.size(-1) * math.log(2 * math.pi)])\r\n    172 return res\r\n\r\nFile ~/miniforge3/envs/tf_m1/lib/python3.9/site-packages/linear_operator/operators/_linear_operator.py:1657, in LinearOperator.inv_quad_logdet(self, inv_quad_rhs, logdet, reduce_inv_quad)\r\n   1654 probe_vectors, probe_vector_norms = self._probe_vectors_and_norms()\r\n   1656 func = InvQuadLogdet.apply\r\n-> 1657 inv_quad_term, pinvk_logdet = func(\r\n   1658     self.representation_tree(),\r\n   1659     precond_lt.representation_tree(),\r\n   1660     preconditioner,\r\n   1661     len(precond_args),\r\n   1662     (inv_quad_rhs is not None),\r\n   1663     probe_vectors,\r\n   1664     probe_vector_norms,\r\n   1665     *(list(args) + list(precond_args)),\r\n   1666 )\r\n   1667 logdet_term = pinvk_logdet\r\n   1668 logdet_term = logdet_term + logdet_p\r\n\r\nFile ~/miniforge3/envs/tf_m1/lib/python3.9/site-packages/linear_operator/functions/_inv_quad_logdet.py:132, in InvQuadLogdet.forward(ctx, representation_tree, precond_representation_tree, preconditioner, num_precond_args, inv_quad, probe_vectors, probe_vector_norms, *args)\r\n    130 # Perform solves (for inv_quad) and tridiagonalization (for estimating logdet)\r\n    131 rhs = torch.cat(rhs_list, -1)\r\n--> 132 solves, t_mat = linear_op._solve(rhs, preconditioner, num_tridiag=num_random_probes)\r\n    134 # Final values to return\r\n    135 logdet_term = torch.zeros(linear_op.batch_shape, dtype=ctx.dtype, device=ctx.device)\r\n\r\nFile ~/miniforge3/envs/tf_m1/lib/python3.9/site-packages/linear_operator/operators/_linear_operator.py:735, in LinearOperator._solve(self, rhs, preconditioner, num_tridiag)\r\n    731 def _solve(self, rhs: torch.Tensor, preconditioner: Callable, num_tridiag: int = 0) -> torch.Tensor:\r\n    732     r\"\"\"\r\n    733     TODO\r\n    734     \"\"\"\r\n--> 735     return utils.linear_cg(\r\n    736         self._matmul,\r\n    737         rhs,\r\n    738         n_tridiag=num_tridiag,\r\n    739         max_iter=settings.max_cg_iterations.value(),\r\n    740         max_tridiag_iter=settings.max_lanczos_quadrature_iterations.value(),\r\n    741         preconditioner=preconditioner,\r\n    742     )\r\n\r\nFile ~/miniforge3/envs/tf_m1/lib/python3.9/site-packages/linear_operator/utils/linear_cg.py:176, in linear_cg(matmul_closure, rhs, n_tridiag, tolerance, eps, stop_updating_after, max_iter, max_tridiag_iter, initial_guess, preconditioner)\r\n    173 rhs = rhs.div(rhs_norm)\r\n    175 # residual: residual_{0} = b_vec - lhs x_{0}\r\n--> 176 residual = rhs - matmul_closure(initial_guess)\r\n    177 batch_shape = residual.shape[:-2]\r\n    179 # result <- x_{0}\r\n\r\nFile ~/miniforge3/envs/tf_m1/lib/python3.9/site-packages/linear_operator/operators/added_diag_linear_operator.py:71, in AddedDiagLinearOperator._matmul(self, rhs)\r\n     70 def _matmul(self, rhs: Tensor) -> Tensor:\r\n---> 71     return torch.addcmul(self._linear_op._matmul(rhs), self._diag_tensor._diag.unsqueeze(-1), rhs)\r\n\r\nRuntimeError: !(has_different_input_dtypes && !config.promote_inputs_to_common_dtype_ && (has_undefined_outputs || config.enforce_safe_casting_to_output_ || config.cast_common_dtype_to_outputs_)) INTERNAL ASSERT FAILED at \"/Users/runner/miniforge3/conda-bld/pytorch-recipe_1660136169395/work/aten/src/ATen/TensorIterator.cpp\":407, please report a bug to PyTorch.\r\n\r\n\r\n**Software Versions**\r\npython = 3.9\r\ntorch.version = 1.12.1\r\ngpytorch.version = 1.9.0", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2197/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2197/timeline", "performed_via_github_app": null, "state_reason": "not_planned"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2196", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2196/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2196/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2196/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2196", "id": 1453871493, "node_id": "I_kwDOBZhSr85WqFGF", "number": 2196, "title": "[Bug] Fixing the lengthscale of a kernel. MaternKernel object has no attribute base_kernel", "user": {"login": "aegonwolf", "id": 34473476, "node_id": "MDQ6VXNlcjM0NDczNDc2", "avatar_url": "https://avatars.githubusercontent.com/u/34473476?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aegonwolf", "html_url": "https://github.com/aegonwolf", "followers_url": "https://api.github.com/users/aegonwolf/followers", "following_url": "https://api.github.com/users/aegonwolf/following{/other_user}", "gists_url": "https://api.github.com/users/aegonwolf/gists{/gist_id}", "starred_url": "https://api.github.com/users/aegonwolf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aegonwolf/subscriptions", "organizations_url": "https://api.github.com/users/aegonwolf/orgs", "repos_url": "https://api.github.com/users/aegonwolf/repos", "events_url": "https://api.github.com/users/aegonwolf/events{/privacy}", "received_events_url": "https://api.github.com/users/aegonwolf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-11-17T19:30:13Z", "updated_at": "2022-11-28T20:48:58Z", "closed_at": "2022-11-28T20:48:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Question\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nHi all, \r\n\r\nI tried this https://github.com/cornellius-gp/gpytorch/issues/689 to fix my lengthscale of a MaternKernel.\r\n\r\n_Originally I got an attribute error but that probably was something on my part as it has miraculously vanished._\r\nWhen I fix the lengthscale as mentioned above and remove the parameter from training the model doesn't learn anything anymore and just outputs the same mean and sigma for the whole domain.\r\n\r\n\r\nIn addition, I would also like to add a fixed variance which I now do with the fixed noise likelihood. Can one use the deprecated White Noise Kernel?\r\n\r\nMany thanks in advance!\r\n\r\nSorry for closing and opening again, I saw that there was a question label and I thought it would be more fitting but it seems I can't add it from my end.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2196/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2196/timeline", "performed_via_github_app": null, "state_reason": "not_planned"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2187", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2187/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2187/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2187/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2187", "id": 1437522871, "node_id": "I_kwDOBZhSr85Vrtu3", "number": 2187, "title": "[Bug] VNNGP with additive kernel gives error", "user": {"login": "danieliong", "id": 46586080, "node_id": "MDQ6VXNlcjQ2NTg2MDgw", "avatar_url": "https://avatars.githubusercontent.com/u/46586080?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danieliong", "html_url": "https://github.com/danieliong", "followers_url": "https://api.github.com/users/danieliong/followers", "following_url": "https://api.github.com/users/danieliong/following{/other_user}", "gists_url": "https://api.github.com/users/danieliong/gists{/gist_id}", "starred_url": "https://api.github.com/users/danieliong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danieliong/subscriptions", "organizations_url": "https://api.github.com/users/danieliong/orgs", "repos_url": "https://api.github.com/users/danieliong/repos", "events_url": "https://api.github.com/users/danieliong/events{/privacy}", "received_events_url": "https://api.github.com/users/danieliong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-11-06T20:03:58Z", "updated_at": "2022-11-06T20:39:57Z", "closed_at": "2022-11-06T20:39:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "Nevermind! Please help me delete this. ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2187/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2187/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2186", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2186/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2186/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2186/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2186", "id": 1437453924, "node_id": "I_kwDOBZhSr85Vrc5k", "number": 2186, "title": "[Bug]", "user": {"login": "neuronphysics", "id": 6558617, "node_id": "MDQ6VXNlcjY1NTg2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/6558617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neuronphysics", "html_url": "https://github.com/neuronphysics", "followers_url": "https://api.github.com/users/neuronphysics/followers", "following_url": "https://api.github.com/users/neuronphysics/following{/other_user}", "gists_url": "https://api.github.com/users/neuronphysics/gists{/gist_id}", "starred_url": "https://api.github.com/users/neuronphysics/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neuronphysics/subscriptions", "organizations_url": "https://api.github.com/users/neuronphysics/orgs", "repos_url": "https://api.github.com/users/neuronphysics/repos", "events_url": "https://api.github.com/users/neuronphysics/events{/privacy}", "received_events_url": "https://api.github.com/users/neuronphysics/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-11-06T16:03:54Z", "updated_at": "2022-11-08T00:31:28Z", "closed_at": "2022-11-08T00:31:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n\r\nHi,\r\n\r\nI have been trying to build a model to learn the transition function for environment. I combined RNN with a multitask Gaussian process layer but unfortunately they won't work together. Here is my code: \r\n```\r\nclass MlpRnnEncoder(nn.Module):\r\n    def __init__(self, seq_len, input_dim, encoder_hidden_size, rnn_hidden_size, num_layers, n_action=0, embed_dim=4, batch_size=200, dropout_rate=0.25, rnn_cell_type='GRU',  normalize=False):\r\n\r\n        super(MlpRnnEncoder, self).__init__()\r\n        self.normalize = normalize\r\n        self.seq_len = seq_len\r\n        self.input_dim = input_dim\r\n        self.encoder_hidden_dim = encoder_hidden_size\r\n        self.rnn_hidden_dim = rnn_hidden_size\r\n        self.num_layers = num_layers\r\n        self.rnn_cell_type = rnn_cell_type\r\n        self.n_action = n_action\r\n        if n_action != 0:\r\n            self.act_embedding = nn.Embedding(n_action, embed_dim)\r\n        self._batch_size = batch_size\r\n        self.encoder = nn.Sequential()\r\n        self.encoder.add_module('mlp_0', nn.Linear(input_dim, encoder_hidden_size))\r\n        self.encoder.add_module('relu', nn.ReLU())\r\n        self.encoder.add_module('dropout', nn.Dropout(dropout_rate))\r\n        self.encoder.add_module('mlp_1', nn.Linear( encoder_hidden_size, rnn_hidden_size))\r\n        self.encoder.add_module('relu', nn.ReLU())\r\n        self.encoder.add_module('dropout', nn.Dropout(dropout_rate))\r\n        #weight initialize\r\n        weights_init(self.encoder, type='xavier')\r\n\r\n        if self.rnn_cell_type == 'GRU':\r\n            print('Using GRU as the recurrent layer.')\r\n            self.rnn = nn.GRU(input_size=rnn_hidden_size, hidden_size=rnn_hidden_size, num_layers =num_layers, batch_first=True)\r\n        elif self.rnn_cell_type == 'LSTM':\r\n            print('Using LSTM as the recurrent layer.')\r\n            self.c0 = torch.zeros(self.num_layers, batch_size , self.rnn_hidden_dim, device=device, requires_grad=False )\r\n            self.rnn = nn.LSTM(input_size=rnn_hidden_size, hidden_size=rnn_hidden_size, num_layers =num_layers, batch_first=True)\r\n        else:\r\n            print('Using the default recurrent layer: RNN.')\r\n            self.rnn = nn.RNN(input_size=rnn_hidden_size, hidden_size=rnn_hidden_size, num_layers =num_layers, batch_first=True)\r\n            self.rnn_cell_type = 'RNN'\r\n        self.init_params() #initialize RNN layer \r\n        #using information from all hidden states \r\n        self.h0 = torch.zeros(self.num_layers, batch_size, self.rnn_hidden_dim, device=device, requires_grad=False )\r\n\r\n        self.traj_embed_layer = nn.Linear(2*rnn_hidden_size, rnn_hidden_size)\r\n        self.traj_embed_layer.weight = torch.nn.init.xavier_normal_(self.traj_embed_layer.weight, gain=1)\r\n\r\n        self.to(device)\r\n\r\n    def init_params(self):\r\n        for i in range(self.rnn.num_layers):\r\n            nn.init.orthogonal_(getattr(self.rnn, f'weight_hh_l{i}'))\r\n            nn.init.kaiming_normal_(getattr(self.rnn, f'weight_ih_l{i}'))\r\n            nn.init.constant_(getattr(self.rnn, f'bias_hh_l{i}'), val=0)\r\n            nn.init.constant_(getattr(self.rnn, f'bias_ih_l{i}'), val=0)\r\n            \r\n\r\n    def forward(self, x, y):\r\n\r\n\r\n        if self.n_action != 0:\r\n            y = self.act_embedding(y)\r\n        if len(x.shape) != len(y.shape):\r\n            y = torch.unsqueeze(y,-1)\r\n        \r\n        max_seq_lengths=x.shape[1]\r\n        input = torch.cat((x, y), -1).float()\r\n        \r\n        state_size =input.shape[-1]\r\n        mlp_encoded = self.encoder(input) # (N, T, Hiddens[-2]) get the hidden representation of every time step.\r\n        \r\n        sequence_length=[estimate_sequence_length(x[i,:,:]).item() if estimate_sequence_length(x[i,:,:]).numel()!=0 else max_seq_lengths for i in range(x.shape[0]) ]\r\n        #print(f\" Seq. Length:{sequence_length}\")\r\n\r\n        pad_embed_packoutput = torch.nn.utils.rnn.pack_padded_sequence(mlp_encoded, lengths=sequence_length, enforce_sorted=False,batch_first=True)\r\n        \r\n        #print(f\"pad input rnn {pad_embed_packoutput[0].shape}\")\r\n        #forward prop\r\n        if self.rnn_cell_type in ['GRU', 'RNN']:\r\n           \r\n            step_embed, traj_embed = self.rnn(pad_embed_packoutput, self.h0) #the first one is important and secound one is the hidden state\r\n        else:\r\n            \r\n            step_embed, (traj_embed, _) = self.rnn(pad_embed_packoutput, (self.h0, self.c0))\r\n        \r\n\r\n        \r\n        unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(step_embed, batch_first=True, total_length=max_seq_lengths)\r\n\r\n        last_hidden_layer=traj_embed[-1,:,:]\r\n        last_hidden_layer = last_hidden_layer[:, None, :].repeat(1, max_seq_lengths, 1) # (N, D) -> (N, T, D)\r\n\r\n        features = torch.cat([unpacked, last_hidden_layer], dim=-1) # (N, T, 2D)\r\n        \r\n        features_reshaped = features.view(x.size(0)*x.size(1), features.size(-1))\r\n        \r\n                \r\n        traj_embed = self.traj_embed_layer(features_reshaped) # (batch_size, hidden_dim)\r\n\r\n        return  traj_embed\r\n\r\nclass DGPHiddenLayer(DeepGPLayer):\r\n    def __init__(self, input_dims, output_dims, num_tasks, num_inducing=128, Matern_kernel_nu=2.5, mean_type = None):\r\n        inducing_points = torch.randn(output_dims, num_inducing, input_dims)\r\n        batch_shape = torch.Size([output_dims])\r\n\r\n        variational_distribution = TrilNaturalVariationalDistribution(\r\n            num_inducing_points=num_inducing,\r\n            batch_shape=batch_shape,\r\n            mean_init_std=0.\r\n        )\r\n        \r\n        \r\n        variational_strategy = gpytorch.variational.MultitaskVariationalStrategy(\r\n            gpytorch.variational.VariationalStrategy(\r\n              self, \r\n              inducing_points,\r\n              variational_distribution,\r\n              learn_inducing_locations=True), num_tasks=num_tasks, task_dim=-1)\r\n\r\n        super().__init__(variational_strategy, input_dims, output_dims)\r\n        if mean_type is None or mean_type=='constant':\r\n          self.base_mean_module = ConstantMean(batch_shape=batch_shape) \r\n        elif mean_type=='linear':\r\n           self.base_mean_module = gpytorch.means.LinearMean(input_dims, batch_shape=batch_shape)\r\n        elif mean_type=='zero':\r\n          self.base_mean_module = gpytorch.means.ZeroMean(batch_shape=batch_shape)\r\n\r\n        self.mean_module = gpytorch.means.MultitaskMean(self.base_mean_module, num_tasks=num_tasks)\r\n        lengthscale_prior = gpytorch.priors.NormalPrior(0.0, 1.0)\r\n        lengthscale_constraint = None\r\n\r\n        self.covar_module = gpytorch.kernels.MultitaskKernel(\r\n            RBFKernel(batch_shape=batch_shape, # to set separate lengthscale for each eventuall batch\r\n                      ard_num_dims=input_dims,\r\n                      #active_dims=(0), # set input dims to compute covariance for, tuple of ints corresponding to indices of dimensions\r\n                      lengthscale_constraint=lengthscale_constraint,\r\n                      lengthscale_prior=lengthscale_prior), num_tasks=num_tasks, rank=1\r\n        )\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\r\n    def __call__(self, inputs, are_samples=False, **kwargs):\r\n        \"\"\"\r\n        Slightly adapted from original GPyTorch code to allow LMC in deep layer\r\n        \"\"\"\r\n        deterministic_inputs = not are_samples\r\n        if isinstance(inputs, MultitaskMultivariateNormal):\r\n            inputs = torch.distributions.Normal(loc=inputs.mean, scale=inputs.variance.sqrt()).rsample()\r\n            deterministic_inputs = False\r\n\r\n        if gpytorch.settings.debug.on():\r\n            if not torch.is_tensor(inputs):\r\n                raise ValueError(\r\n                    \"`inputs` should either be a MultitaskMultivariateNormal or a Tensor, got \"\r\n                    f\"{inputs.__class__.__Name__}\"\r\n                )\r\n\r\n            if inputs.size(-1) != self.input_dims:\r\n                raise RuntimeError(\r\n                    f\"Input shape did not match self.input_dims. Got total feature dims [{inputs.size(-1)}],\"\r\n                    f\" expected [{self.input_dims}]\"\r\n                )\r\n\r\n        # Repeat the input for all possible outputs\r\n        if self.output_dims is not None:\r\n            inputs = inputs.unsqueeze(-3)\r\n            inputs = inputs.expand(*inputs.shape[:-3], self.output_dims, *inputs.shape[-2:])\r\n\r\n\r\n        # Now run samples through the GP\r\n        output = ApproximateGP.__call__(self, inputs)\r\n\r\n        ###############################################\r\n        # Removed block diagonalization of batched GPs\r\n        ###############################################\r\n        return output\r\nclass DeepLMC(DeepGP):\r\n    def __init__(self, \r\n                 train_input_dim, \r\n                 seq_len, \r\n                 embed_dim, \r\n                 encoder_hidden_size, \r\n                 rnn_hidden_size,\r\n                 num_layers,\r\n                 state_dims,\r\n                 action_dims,\r\n                 batch_size,\r\n                 normalize=False,\r\n                 n_action=0, \r\n                 num_tasks=129, \r\n                 num_hidden_dgp_dims=5, \r\n                 num_inducing1=128, \r\n                 Matern_kernel_nu=1.5, \r\n                 mean_type=None,\r\n                 rnn_cell_type='GRU',\r\n                 dropout_rate=0.25,\r\n                 clip_gradient_norm=2.0,              \r\n                 ):\r\n\r\n        super(DeepLMC,self).__init__()\r\n        self.seq_len = seq_len\r\n        self._clip_gradient_norm =clip_gradient_norm\r\n        self.encoderRNN = MlpRnnEncoder(seq_len, train_input_dim, encoder_hidden_size, rnn_hidden_size, num_layers, n_action, embed_dim, batch_size, dropout_rate, rnn_cell_type, normalize)\r\n        print(f\"size of input:{self.encoderRNN.traj_embed_layer.out_features}\")\r\n        hidden_layer1 = DGPHiddenLayer(\r\n            input_dims= self.encoderRNN.traj_embed_layer.out_features,\r\n            output_dims=num_hidden_dgp_dims,\r\n            num_tasks=num_tasks,\r\n            num_inducing=num_inducing1,\r\n            Matern_kernel_nu=Matern_kernel_nu,\r\n            mean_type=mean_type\r\n        )\r\n\r\n        self.state_dims= state_dims\r\n        self.action_dims= action_dims\r\n        self.hidden_layer1 = hidden_layer1\r\n        self.last_layer = last_layer\r\n\r\n        self.likelihood = MultitaskGaussianLikelihood(num_tasks=num_tasks, rank=0)\r\n\r\n    def forward(self, input):\r\n\r\n        x = input[:,:,:self.state_dims]\r\n        y = input[:,:, self.state_dims:]\r\n        #print(f\"shape of state {x.shape} and action {y.shape}\")\r\n        assert (y.shape[-1]==self.action_dims, f\"number of dimension y {y.shape[-1]} expected to be equal with: {self.action_dims}\")\r\n        traj_embedding = self.encoderRNN(x, y)  # (Batch, SeqLength, P) -> (Batch, SeqLength, HiddenDim), ( Batch, HiddenDim)\r\n        \r\n        # features_reshaped = self.batch_norm(features_reshaped)\r\n        print(traj_embedding.shape)\r\n       output = self.hidden_layer1(traj_embedding)\r\n\r\n        return output\r\nmodel = DeepLMC(train_input_dim=train_x.shape[-1],\r\n                seq_len=seq_lens, \r\n                embed_dim=10,\r\n                encoder_hidden_size=64, \r\n                rnn_hidden_size=num_tasks,\r\n                num_layers=2,\r\n                state_dims= 11,\r\n                action_dims=3,\r\n                batch_size=batch_size,\r\n                num_tasks=num_tasks, \r\n                num_hidden_dgp_dims=num_tasks,\r\n                num_inducing1=num_inducing1,\r\n                mean_type='constant')\r\nmodel.to(device)\r\n\r\nmll = DeepApproximateMLL(gpytorch.mlls.PredictiveLogLikelihood(model.likelihood, model, num_data=train_y.size(0), beta = 0.75))\r\n\r\nhistory = []\r\n\r\nvariational_lrs =   1e-3 \r\nhyperparam_lrs =  1e-3\r\nvariational_ngd_optimizer = gpytorch.optim.NGD(model.variational_parameters(), num_data=train_y.size(0), lr=variational_lrs)\r\nhyperparameter_optimizer = torch_optimizer.AdaBound([\r\n                    {'params': model.encoderRNN.encoder.parameters()},\r\n                    {'params': model.encoderRNN.rnn.parameters(), 'weight_decay': 5e-4},\r\n                    {'params': model.encoderRNN.traj_embed_layer.parameters()},\r\n                    {'params': model.hidden_layer1.hyperparameters()},\r\n                    {'params': model.likelihood.parameters()}, ], lr=hyperparam_lrs, betas=(0.75,0.999), weight_decay=0)\r\nscheduler_optimizer = torch.optim.lr_scheduler.MultiStepLR(hyperparameter_optimizer, milestones=[30, 80, 140, 210, 290, 350], gamma=0.5)\r\nabort = False\r\n\r\nnum_epochs = 401\r\nmin_loss = 1e10\r\nhistory = []\r\nmodel.train()\r\nmodel.likelihood.train()\r\nepochs_iter = tqdm.notebook.tqdm(range(num_epochs), desc=\"GP training Epoch\")\r\nlosses=[]\r\nfor i in epochs_iter:\r\n    loss_avg = 0.\r\n    batch_counter = 0.\r\n    minibatch_iter = tqdm.notebook.tqdm(train_loader, desc=\"Minibatch\", total=len(train_loader),leave=False)  \r\n    for x_batch, y_batch in train_loader:\r\n        true_output=y_batch.view(y_batch.size(0)*y_batch.size(1),-1)\r\n        variational_ngd_optimizer.zero_grad()\r\n        print(f\"input shape: {x_batch.shape}\")\r\n        pred = model(x_batch)    \r\n        loss = -mll(pred, true_output )\r\n        batch_counter += 1.\r\n        loss.backward()        \r\n        variational_ngd_optimizer.step()\r\n        ### Perform Adam step to optimize hyperparameters\r\n        hyperparameter_optimizer.zero_grad()\r\n        pred = model(x_batch)\r\n        loss = -mll(pred, true_output )\r\n        history.append(loss.item())\r\n        loss_avg += loss.item()\r\n        if model._clip_gradient_norm > 0:\r\n           torch.nn.utils.clip_grad_norm_(model.encoderRNN.parameters(), model._clip_gradient_norm)\r\n        hyperparameter_optimizer.step()\r\n \r\n        minibatch_iter.set_postfix(loss=loss.item())\r\n    scheduler_optimizer.step()\r\n    loss_avg = loss_avg / batch_counter\r\n    losses.append(loss_avg)\r\n\r\n```\r\n\r\nThis is my error message\r\n```\r\n     28 \r\n     29     def __call__(self, *inputs, **kwargs):\r\n---> 30         outputs = self.forward(*inputs, **kwargs)\r\n     31         if isinstance(outputs, list):\r\n     32             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n<ipython-input-23-23921a6140e3> in forward(self, input)\r\n    529         # features_reshaped = self.batch_norm(features_reshaped)\r\n    530         print(traj_embedding.shape)\r\n--> 531         output = self.hidden_layer1(traj_embedding)\r\n    532         \r\n    533         return output\r\n\r\n<ipython-input-23-23921a6140e3> in __call__(self, inputs, are_samples, **kwargs)\r\n    354 \r\n    355         # Now run samples through the GP\r\n--> 356         output = ApproximateGP.__call__(self, inputs)\r\n    357 \r\n    358         ###############################################\r\n\r\n/usr/local/lib/python3.7/dist-packages/gpytorch/models/approximate_gp.py in __call__(self, inputs, prior, **kwargs)\r\n    106         if inputs.dim() == 1:\r\n    107             inputs = inputs.unsqueeze(-1)\r\n--> 108         return self.variational_strategy(inputs, prior=prior, **kwargs)\r\n\r\n/usr/local/lib/python3.7/dist-packages/gpytorch/variational/lmc_variational_strategy.py in __call__(self, x, task_indices, prior, **kwargs)\r\n    186             or ~gpytorch.distributions.MultivariateNormal (... x N)\r\n    187         \"\"\"\r\n--> 188         latent_dist = self.base_variational_strategy(x, prior=prior, **kwargs)\r\n    189         num_batch = len(latent_dist.batch_shape)\r\n    190         latent_dim = num_batch + self.latent_dim\r\n\r\n/usr/local/lib/python3.7/dist-packages/gpytorch/variational/variational_strategy.py in __call__(self, x, prior, **kwargs)\r\n    240                 self.updated_strategy.fill_(True)\r\n    241 \r\n--> 242         return super().__call__(x, prior=prior, **kwargs)\r\n\r\n/usr/local/lib/python3.7/dist-packages/gpytorch/variational/_variational_strategy.py in __call__(self, x, prior, **kwargs)\r\n    305                 inducing_values=variational_dist_u.mean,\r\n    306                 variational_inducing_covar=variational_dist_u.lazy_covariance_matrix,\r\n--> 307                 **kwargs,\r\n    308             )\r\n    309         elif isinstance(variational_dist_u, Delta):\r\n\r\n/usr/local/lib/python3.7/dist-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     28 \r\n     29     def __call__(self, *inputs, **kwargs):\r\n---> 30         outputs = self.forward(*inputs, **kwargs)\r\n     31         if isinstance(outputs, list):\r\n     32             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n/usr/local/lib/python3.7/dist-packages/gpytorch/variational/variational_strategy.py in forward(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\r\n    187         # Compute the mean of q(f)\r\n    188         # k_XZ K_ZZ^{-1/2} (m - K_ZZ^{-1/2} \\mu_Z) + \\mu_X\r\n--> 189         predictive_mean = (interp_term.transpose(-1, -2) @ inducing_values.unsqueeze(-1)).squeeze(-1) + test_mean\r\n    190 \r\n    191         # Compute the covariance of q(f)\r\n\r\nRuntimeError: The size of tensor a (24655) must match the size of tensor b (0) at non-singleton dimension 2\r\n```\r\n\r\nI also used [this model](https://docs.gpytorch.ai/en/v1.6.0/examples/04_Variational_and_Approximate_GPs/SVGP_Multitask_GP_Regression.html) before  building a layer with multitask mean and covariances. However, the performance of the model was very disappointing. It seems the model wasn't able to infer different means and it didn't learn different structures of data. The input dimension of data is 14 and the output has 11 dimensions. \r\n\r\nI was searching to find a solution for this error. However, it is not clear where is the source of this input size and make it difficult to be able to debug it. I will appreciate if anyone can clarify whether it is a model problem or my implementation? Thanks. \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2186/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2186/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2174", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2174/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2174/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2174/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2174", "id": 1420728634, "node_id": "I_kwDOBZhSr85Urpk6", "number": 2174, "title": "[Bug]  The formula of MSLL, one of the evaluation indicators of GP, is implemented incorrectly.", "user": {"login": "jongwonKim-1997", "id": 77820101, "node_id": "MDQ6VXNlcjc3ODIwMTAx", "avatar_url": "https://avatars.githubusercontent.com/u/77820101?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jongwonKim-1997", "html_url": "https://github.com/jongwonKim-1997", "followers_url": "https://api.github.com/users/jongwonKim-1997/followers", "following_url": "https://api.github.com/users/jongwonKim-1997/following{/other_user}", "gists_url": "https://api.github.com/users/jongwonKim-1997/gists{/gist_id}", "starred_url": "https://api.github.com/users/jongwonKim-1997/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jongwonKim-1997/subscriptions", "organizations_url": "https://api.github.com/users/jongwonKim-1997/orgs", "repos_url": "https://api.github.com/users/jongwonKim-1997/repos", "events_url": "https://api.github.com/users/jongwonKim-1997/events{/privacy}", "received_events_url": "https://api.github.com/users/jongwonKim-1997/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-10-24T12:10:36Z", "updated_at": "2023-04-22T07:00:52Z", "closed_at": "2023-04-22T07:00:52Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nThe Gaussian process for machine learning cited in the GPytorch documentation expresses MSLL as follows;\r\n\r\n![image](https://user-images.githubusercontent.com/77820101/197520662-86d084e5-a179-403f-8bc5-8465f404c7cc.png)\r\n\r\n\r\nThe current implementation code in GPytorch is below and I think 0.5 should be multiplied in parentheses.\r\n\r\n```python\r\ndef mean_standardized_log_loss(\r\n    pred_dist: MultivariateNormal,\r\n    test_y: torch.Tensor,\r\n):\r\n    \"\"\"\r\n    Mean Standardized Log Loss.\r\n    Reference: Page No. 23,\r\n    Gaussian Processes for Machine Learning,\r\n    Carl Edward Rasmussen and Christopher K. I. Williams,\r\n    The MIT Press, 2006. ISBN 0-262-18253-X\r\n    \"\"\"\r\n    combine_dim = -2 if isinstance(pred_dist, MultitaskMultivariateNormal) else -1\r\n    f_mean = pred_dist.mean\r\n    f_var = pred_dist.variance\r\n    return 0.5 * (torch.log(2 * pi * f_var) + torch.square(test_y - f_mean) / (2 * f_var)).mean(dim=combine_dim)\r\n\r\n```\r\n\r\nI don't know where to report this little error, so I'm posting it here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2174/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2174/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2172", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2172/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2172/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2172/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/2172", "id": 1419541964, "node_id": "PR_kwDOBZhSr85BWUgg", "number": 2172, "title": "MMVN.to_data_independent_dist returns correct variance for non-interleaved MMVN distributions.", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1607679275, "node_id": "MDU6TGFiZWwxNjA3Njc5Mjc1", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/multitask", "name": "multitask", "color": "ffffff", "default": false, "description": "For questions about multitask models"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-10-22T23:01:17Z", "updated_at": "2022-10-23T05:18:36Z", "closed_at": "2022-10-23T05:18:33Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/2172", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/2172", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/2172.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/2172.patch", "merged_at": "2022-10-23T05:18:33Z"}, "body": "This PR is critical to have correct variances for multi-output Deep GP models.\r\n\r\nPreviously, MMVN.to_data_independent_dist ewas written to only work with interleaved MMVN distributions. This PR makes MMVN.to_data_independent_dist work with non-interleaved distributions as well.\r\n\r\n[Fixes #2072]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2172/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2172/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2170", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2170/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2170/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2170/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2170", "id": 1418438793, "node_id": "I_kwDOBZhSr85Ui6iJ", "number": 2170, "title": "[Bug] The '+=' operator doesn't work on a lazy tensor when executed out of scope ", "user": {"login": "trbedwards", "id": 1222553, "node_id": "MDQ6VXNlcjEyMjI1NTM=", "avatar_url": "https://avatars.githubusercontent.com/u/1222553?v=4", "gravatar_id": "", "url": "https://api.github.com/users/trbedwards", "html_url": "https://github.com/trbedwards", "followers_url": "https://api.github.com/users/trbedwards/followers", "following_url": "https://api.github.com/users/trbedwards/following{/other_user}", "gists_url": "https://api.github.com/users/trbedwards/gists{/gist_id}", "starred_url": "https://api.github.com/users/trbedwards/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/trbedwards/subscriptions", "organizations_url": "https://api.github.com/users/trbedwards/orgs", "repos_url": "https://api.github.com/users/trbedwards/repos", "events_url": "https://api.github.com/users/trbedwards/events{/privacy}", "received_events_url": "https://api.github.com/users/trbedwards/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-10-21T14:36:35Z", "updated_at": "2022-10-22T22:27:54Z", "closed_at": "2022-10-22T22:27:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nApplying the `+=` operator to a `LazyTensor` doesn't work when applied in a function call. This is unexpected behaviour as one would expect it to work the same as it does with regular pytorch tensors or numpy arrays. It only works if the `LazyTensor` is evaluated in the same scope that the `+=` operation is applied. \r\n\r\nPerhaps one needs to implement the `__iadd__` method for `LazyTensor`s?\r\n\r\n## To reproduce\r\n```\r\nimport torch\r\nfrom gpytorch.lazy import lazify\r\n\r\nt2 = torch.eye(2)\r\nl2 = lazify(t2)\r\n\r\ndef add1(lazy_tensor):\r\n    lazy_tensor += torch.eye(2)\r\n\r\nadd1(l2)\r\nassert (l2.evaluate() == torch.tensor([[2., 0],[0., 2.]]).all() \r\n```\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version 1.6.0\r\n- PyTorch Version 1.10.2\r\n- Ubuntu 18.04.3", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2170/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2170/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2139", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2139/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2139/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2139/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2139", "id": 1374141958, "node_id": "I_kwDOBZhSr85R574G", "number": 2139, "title": "[Bug]", "user": {"login": "jmunozmendi", "id": 55241761, "node_id": "MDQ6VXNlcjU1MjQxNzYx", "avatar_url": "https://avatars.githubusercontent.com/u/55241761?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jmunozmendi", "html_url": "https://github.com/jmunozmendi", "followers_url": "https://api.github.com/users/jmunozmendi/followers", "following_url": "https://api.github.com/users/jmunozmendi/following{/other_user}", "gists_url": "https://api.github.com/users/jmunozmendi/gists{/gist_id}", "starred_url": "https://api.github.com/users/jmunozmendi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jmunozmendi/subscriptions", "organizations_url": "https://api.github.com/users/jmunozmendi/orgs", "repos_url": "https://api.github.com/users/jmunozmendi/repos", "events_url": "https://api.github.com/users/jmunozmendi/events{/privacy}", "received_events_url": "https://api.github.com/users/jmunozmendi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-09-15T08:31:13Z", "updated_at": "2022-09-15T13:50:24Z", "closed_at": "2022-09-15T13:50:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI get the following error:\r\n\r\n'VariationalStrategy' object has no attribute 'get_fantasy_model'\r\n\r\nwhen running the SVGP_Model_Updating.ipynb example notebook.\r\n\r\n\r\n## System information\r\n\r\n- GPyTorch Version 1.6.0\r\n- PyTorch Version 1.10.2\r\n- Windows10\r\n\r\n## Additional context\r\nI got the error when trying to update a PolyGamma ApproximateGP. I thought the error was on my part so I ran the example to find out it isn't working either.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2139/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2139/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2132", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2132/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2132/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2132/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/2132", "id": 1368206261, "node_id": "PR_kwDOBZhSr84-sswu", "number": 2132, "title": "fix custom dtype_value_context setting", "user": {"login": "sdaulton", "id": 8037929, "node_id": "MDQ6VXNlcjgwMzc5Mjk=", "avatar_url": "https://avatars.githubusercontent.com/u/8037929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sdaulton", "html_url": "https://github.com/sdaulton", "followers_url": "https://api.github.com/users/sdaulton/followers", "following_url": "https://api.github.com/users/sdaulton/following{/other_user}", "gists_url": "https://api.github.com/users/sdaulton/gists{/gist_id}", "starred_url": "https://api.github.com/users/sdaulton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sdaulton/subscriptions", "organizations_url": "https://api.github.com/users/sdaulton/orgs", "repos_url": "https://api.github.com/users/sdaulton/repos", "events_url": "https://api.github.com/users/sdaulton/events{/privacy}", "received_events_url": "https://api.github.com/users/sdaulton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-09-09T18:51:08Z", "updated_at": "2022-09-09T19:22:45Z", "closed_at": "2022-09-09T19:21:55Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/2132", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/2132", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/2132.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/2132.patch", "merged_at": "2022-09-09T19:21:55Z"}, "body": "Previously, setting custom values in `dtype_value_context` was broken because `dtype_value_context.value` requires a `dtype` argument and no `dtype` argument was provided in the calls in `dtype_value_context.__init__`.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2132/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2132/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2123", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2123/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2123/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2123/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/2123", "id": 1363542938, "node_id": "PR_kwDOBZhSr84-dAvA", "number": 2123, "title": "Fix bug with Multitask DeepGP predictive variances.", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1607679275, "node_id": "MDU6TGFiZWwxNjA3Njc5Mjc1", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/multitask", "name": "multitask", "color": "ffffff", "default": false, "description": "For questions about multitask models"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-09-06T16:32:10Z", "updated_at": "2022-10-03T20:21:08Z", "closed_at": "2022-09-07T14:12:47Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/2123", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/2123", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/2123.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/2123.patch", "merged_at": "2022-09-07T14:12:47Z"}, "body": "The latent variances of multitask DeepGP models are stored in non-interleaved covariance matrices.\r\nPreviously, the MultitaskMultivariateNormal.marginal method implicitly assumed that the function\r\ncovariance matrices were interleaved.\r\n\r\nIn particular, this affects multitask DeepGP models which use a\r\nnon-interleaved latent covariance matrix.\r\n\r\nWith this PR, MultitaskMultivariateNormal.marginal now checks if the input covariance matrix is\r\ninterleaved, and makes sure that the returned predictive covariance matrix matches the\r\ninterleaved/non-interleaved pattern of the latent covariance matrix.\r\n\r\n[Fixes #2702]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2123/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2123/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2121", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2121/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2121/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2121/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/2121", "id": 1363386409, "node_id": "PR_kwDOBZhSr84-cfNI", "number": 2121, "title": "Fix multitask/added_loss_term bugs in SGPR regression", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1607679275, "node_id": "MDU6TGFiZWwxNjA3Njc5Mjc1", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/multitask", "name": "multitask", "color": "ffffff", "default": false, "description": "For questions about multitask models"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-09-06T14:33:45Z", "updated_at": "2022-10-03T20:19:29Z", "closed_at": "2022-10-03T20:19:29Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/2121", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/2121", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/2121.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/2121.patch", "merged_at": "2022-10-03T20:19:29Z"}, "body": "This PR addresses two bugs\r\n\r\n1. **Enable InducingPoint kernel to work with multitask regression** (As pointed out by @GHU2021, there's currently an error when trying to use MultitaskKernel in conjunction with InducingPointKernel)\r\n\r\n2. **Fix broadcasting for SGPR added loss term** (Previously, the added loss term was summing over data dimensions and batch dimensions, which would artificially inflate this term for batch SGPR models. This PR ensures that we are only summing over data dimensions and not batch dimensions.)\r\n\r\n[Fixes #2113]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2121/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2121/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2113", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2113/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2113/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2113/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2113", "id": 1356768417, "node_id": "I_kwDOBZhSr85Q3qSh", "number": 2113, "title": "[Bug] Multitask GP + Sparse GP", "user": {"login": "GHU2021", "id": 78105850, "node_id": "MDQ6VXNlcjc4MTA1ODUw", "avatar_url": "https://avatars.githubusercontent.com/u/78105850?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GHU2021", "html_url": "https://github.com/GHU2021", "followers_url": "https://api.github.com/users/GHU2021/followers", "following_url": "https://api.github.com/users/GHU2021/following{/other_user}", "gists_url": "https://api.github.com/users/GHU2021/gists{/gist_id}", "starred_url": "https://api.github.com/users/GHU2021/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GHU2021/subscriptions", "organizations_url": "https://api.github.com/users/GHU2021/orgs", "repos_url": "https://api.github.com/users/GHU2021/repos", "events_url": "https://api.github.com/users/GHU2021/events{/privacy}", "received_events_url": "https://api.github.com/users/GHU2021/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-08-31T04:49:19Z", "updated_at": "2022-10-03T20:19:30Z", "closed_at": "2022-10-03T20:19:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nIn implementing multitask sparse Gaussian processes, I got the index error message \"tuple index out of range\" in calculating loss using mll function. \r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\n\r\ntrain_x = torch.linspace(0, 1, 100)\r\n\r\ntrain_y = torch.stack([\r\n    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n    torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n], -1)\r\n\r\nclass MultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.MultitaskMean(gpytorch.means.ConstantMean(), num_tasks=2)\r\n        self.covar_module = gpytorch.kernels.MultitaskKernel(gpytorch.kernels.InducingPointKernel(gpytorch.kernels.LinearKernel(), inducing_points=train_x[range(0,100,10)], likelihood=likelihood), num_tasks=2, rank=1)\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\r\n\r\n\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\r\nmodel = MultitaskGPModel(train_x, train_y, likelihood)\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\r\n\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\noptimizer.zero_grad()\r\noutput = model(train_x)\r\nloss = -mll(output, train_y)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\code.py\", line 36, in <module>\r\n    loss = -mll(output, train_y)\r\n\r\n  File \"C:\\...\\anaconda3\\lib\\site-packages\\gpytorch\\module.py\", line 30, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n\r\n  File \"C:\\...\\anaconda3\\lib\\site-packages\\gpytorch\\mlls\\exact_marginal_log_likelihood.py\", line 63, in forward\r\n    res = self._add_other_terms(res, params)\r\n\r\n  File \"C:\\...\\anaconda3\\lib\\site-packages\\gpytorch\\mlls\\exact_marginal_log_likelihood.py\", line 39, in _add_other_terms\r\n    res = res.add(added_loss_term.loss(*params))\r\n\r\n  File \"C:\\...\\anaconda3\\lib\\site-packages\\gpytorch\\mlls\\inducing_point_kernel_added_loss_term.py\", line 17, in loss\r\n    noise_diag = self.likelihood._shaped_noise_covar(shape, *params).diag()\r\n\r\n  File \"C:\\...\\anaconda3\\lib\\site-packages\\gpytorch\\likelihoods\\multitask_gaussian_likelihood.py\", line 117, in _shaped_noise_covar\r\n    eye_lt = ConstantDiagLazyTensor(torch.ones(*shape[:-2], 1, dtype=dtype, device=device), diag_shape=shape[-2])\r\n\r\nIndexError: tuple index out of range\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nIt should calculate loss.\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGPyTorch 1.7.0\r\nPyTorch 1.12.0\r\nWindows 10\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2113/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2113/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2098", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2098/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2098/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2098/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2098", "id": 1341194782, "node_id": "I_kwDOBZhSr85P8QIe", "number": 2098, "title": "Potential bug in documentation examples[Bug]", "user": {"login": "Chengwei94", "id": 61018420, "node_id": "MDQ6VXNlcjYxMDE4NDIw", "avatar_url": "https://avatars.githubusercontent.com/u/61018420?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Chengwei94", "html_url": "https://github.com/Chengwei94", "followers_url": "https://api.github.com/users/Chengwei94/followers", "following_url": "https://api.github.com/users/Chengwei94/following{/other_user}", "gists_url": "https://api.github.com/users/Chengwei94/gists{/gist_id}", "starred_url": "https://api.github.com/users/Chengwei94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Chengwei94/subscriptions", "organizations_url": "https://api.github.com/users/Chengwei94/orgs", "repos_url": "https://api.github.com/users/Chengwei94/repos", "events_url": "https://api.github.com/users/Chengwei94/events{/privacy}", "received_events_url": "https://api.github.com/users/Chengwei94/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-08-17T05:40:19Z", "updated_at": "2022-08-17T06:06:53Z", "closed_at": "2022-08-17T06:01:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was running the tutorial. https://docs.gpytorch.ai/en/latest/examples/07_Pyro_Integration/Pyro_GPyTorch_Low_Level.html , and my results were very different from the example listed. I didnt change anything on my run \r\n\r\nMine\r\n![image](https://user-images.githubusercontent.com/61018420/185042895-cf575dbc-007c-4d6a-a82c-bb82c95e4044.png)\r\n\r\nExpected\r\n![image](https://user-images.githubusercontent.com/61018420/185042927-04e0b9d4-9836-4faf-8186-2b95b916ae06.png)\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2098/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2098/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2090", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2090/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2090/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2090/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/2090", "id": 1331092225, "node_id": "PR_kwDOBZhSr848xgGD", "number": 2090, "title": "Fix bug in preconditioned KISS-GP / Hadamard Multitask GPs", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}, {"id": 1607679275, "node_id": "MDU6TGFiZWwxNjA3Njc5Mjc1", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/multitask", "name": "multitask", "color": "ffffff", "default": false, "description": "For questions about multitask models"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-08-07T18:44:14Z", "updated_at": "2022-08-07T19:17:14Z", "closed_at": "2022-08-07T19:17:11Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/2090", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/2090", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/2090.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/2090.patch", "merged_at": "2022-08-07T19:17:11Z"}, "body": "Previously in PyTorch, calling  on a int/long matrix was a no-op.\r\nAt some point in the PyTorch releases, this line started throwing an error (since only\r\nfloating point operations can have gradients).\r\n\r\nOur implementation of pivoted cholesky previously called\r\n`matrix_arg.requires_grad_(True)` on all LazyTensor/LinearOperator\r\narguments, without first checking whether `matrix_arg` was a floating\r\npoint dtype.\r\n\r\nKISS-GP makes use of InterpolatedLazyTensor (to become InterpolatedLinearOperator), which\r\nhas integer matrices (the index matrices for interpolation). This\r\ntherefore produced an error message when it was used in conjunction with\r\nthe pivoted cholesky preconditioner. A similar bug exists for\r\npreconditioned Hadamard Multitask GPs.\r\n\r\n(The reason this bug went undetected is because our tests for KISS-GP\r\nmodels and multitask models all use small datasets (N < 100).\r\nPreconditioners are not used until N > 2000 or so.)\r\n\r\n[Fixes #2056]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2090/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2090/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2089", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2089/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2089/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2089/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2089", "id": 1328638091, "node_id": "I_kwDOBZhSr85PMWiL", "number": 2089, "title": "[Question] Custom Likelihood function", "user": {"login": "jtm44", "id": 45065694, "node_id": "MDQ6VXNlcjQ1MDY1Njk0", "avatar_url": "https://avatars.githubusercontent.com/u/45065694?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jtm44", "html_url": "https://github.com/jtm44", "followers_url": "https://api.github.com/users/jtm44/followers", "following_url": "https://api.github.com/users/jtm44/following{/other_user}", "gists_url": "https://api.github.com/users/jtm44/gists{/gist_id}", "starred_url": "https://api.github.com/users/jtm44/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jtm44/subscriptions", "organizations_url": "https://api.github.com/users/jtm44/orgs", "repos_url": "https://api.github.com/users/jtm44/repos", "events_url": "https://api.github.com/users/jtm44/events{/privacy}", "received_events_url": "https://api.github.com/users/jtm44/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-08-04T13:29:53Z", "updated_at": "2022-08-10T15:45:40Z", "closed_at": "2022-08-07T18:05:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nHi.\r\n\r\n I am trying to implement a custom likelihood function for use in SVGP. The aim is to train the following model: y=g(f(x))+noise. Here f(x) is the output of the GP and is a latent variable. g(.) is a known function.\r\n\r\nTo begin, I have tried to implement a basic Gaussian likelihood function. The GPytorch inbuilt function appears to use the function distribution of f(x) directly rather than obtaining samples from it. To extend this to the model above, I need this to work by obtaining samples from f(x) so I can then pass them through g(.). However, the simple version shown below seems to have PSD issues. Can you spot any issues with my code? Thank you.\r\n\r\n```python\r\nclass LikelihoodTest(Likelihood):\r\n    def __init__(self):\r\n        \r\n        super(LikelihoodTest,self).__init__()\r\n        self.noise_covar=HomoskedasticNoise()\r\n     \r\n    def _shaped_noise_covar(self, base_shape):\r\n        return self.noise_covar(shape=base_shape)\r\n    def forward(self, function_samples):\r\n        noise = self._shaped_noise_covar(function_samples.shape).diag()\r\n        return base_distributions.Normal(function_samples, noise.sqrt())\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nNotPSDError: Matrix not positive definite after repeatedly adding jitter up to 1.0e-04.\r\n```\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2089/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2089/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2075", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2075/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2075/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2075/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2075", "id": 1313738663, "node_id": "I_kwDOBZhSr85OTg-n", "number": 2075, "title": "[Bug] Multivariable Multivariate Regression", "user": {"login": "adamjstewart", "id": 12021217, "node_id": "MDQ6VXNlcjEyMDIxMjE3", "avatar_url": "https://avatars.githubusercontent.com/u/12021217?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adamjstewart", "html_url": "https://github.com/adamjstewart", "followers_url": "https://api.github.com/users/adamjstewart/followers", "following_url": "https://api.github.com/users/adamjstewart/following{/other_user}", "gists_url": "https://api.github.com/users/adamjstewart/gists{/gist_id}", "starred_url": "https://api.github.com/users/adamjstewart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adamjstewart/subscriptions", "organizations_url": "https://api.github.com/users/adamjstewart/orgs", "repos_url": "https://api.github.com/users/adamjstewart/repos", "events_url": "https://api.github.com/users/adamjstewart/events{/privacy}", "received_events_url": "https://api.github.com/users/adamjstewart/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-07-21T20:00:51Z", "updated_at": "2022-07-21T20:22:16Z", "closed_at": "2022-07-21T20:22:16Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nGPyTorch supports inputs that are _multivariable_ (e.g., a model that is a function of latitude and longitude)\r\n\r\nGPyTorch supports outputs that are _multivariate_ (e.g., a multitask modeling problem)\r\n\r\nHowever, it seems that multivariable AND multivariate models currently don't work. If the number of variables and the number of tasks don't match, GPyTorch experiences dimension mismatch issues.\r\n\r\n## To reproduce\r\n\r\n**Code snippet to reproduce**\r\n\r\nFirst, start with the [Multitask GP Regression](https://docs.gpytorch.ai/en/stable/examples/03_Multitask_Exact_GPs/Multitask_GP_Regression.html) tutorial. Then, make the following changes (diff of `.ipynb` after converting to `.py` file):\r\n```diff\r\n--- a/Multitask_GP_Regression.py\t2022-07-21 12:19:51.000000000 -0700\r\n+++ b/Multitask_GP_Regression.py\t2022-07-21 12:41:26.000000000 -0700\r\n@@ -39,11 +39,16 @@\r\n # In[ ]:\r\n \r\n \r\n-train_x = torch.linspace(0, 1, 100)\r\n+train_x = torch.stack([\r\n+    torch.linspace(0, 1, 100),\r\n+    torch.linspace(0, 1, 100),\r\n+], -1)\r\n \r\n train_y = torch.stack([\r\n-    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n-    torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n+    torch.sin(train_x[:, 0] * (2 * math.pi)) + torch.randn(train_x.size()[0]) * 0.2,\r\n+    torch.cos(train_x[:, 0] * (2 * math.pi)) + torch.randn(train_x.size()[0]) * 0.2,\r\n+    torch.sin(train_x[:, 1] * (2 * math.pi)) + torch.randn(train_x.size()[0]) * 0.2,\r\n+    torch.cos(train_x[:, 1] * (2 * math.pi)) + torch.randn(train_x.size()[0]) * 0.2,\r\n ], -1)\r\n \r\n \r\n@@ -125,7 +130,10 @@\r\n \r\n # Make predictions\r\n with torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n-    test_x = torch.linspace(0, 1, 51)\r\n+    test_x = torch.stack([\r\n+        torch.linspace(0, 1, 51),\r\n+        torch.linspace(0, 1, 51),\r\n+    ], -1)\r\n     predictions = likelihood(model(test_x))\r\n     mean = predictions.mean\r\n     lower, upper = predictions.confidence_region()\r\n```\r\n\r\n**Stack trace/error message**\r\n\r\nRunning this modified notebook results in the following errors:\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n~/Downloads/b/Multitask_GP_Regression.py in <module>\r\n    111     optimizer.zero_grad()\r\n    112     output = model(train_x)\r\n--> 113     loss = -mll(output, train_y)\r\n    114     loss.backward()\r\n    115     print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n\r\n~/.spack/.spack-env/view/lib/python3.9/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     28 \r\n     29     def __call__(self, *inputs, **kwargs):\r\n---> 30         outputs = self.forward(*inputs, **kwargs)\r\n     31         if isinstance(outputs, list):\r\n     32             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/.spack/.spack-env/view/lib/python3.9/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, function_dist, target, *params)\r\n     60         # Get the log prob of the marginal distribution\r\n     61         output = self.likelihood(function_dist, *params)\r\n---> 62         res = output.log_prob(target)\r\n     63         res = self._add_other_terms(res, params)\r\n     64 \r\n\r\n~/.spack/.spack-env/view/lib/python3.9/site-packages/gpytorch/distributions/multitask_multivariate_normal.py in log_prob(self, value)\r\n    209             new_shape = value.shape[:-2] + value.shape[:-3:-1]\r\n    210             value = value.view(new_shape).transpose(-1, -2).contiguous()\r\n--> 211         return super().log_prob(value.view(*value.shape[:-2], -1))\r\n    212 \r\n    213     @property\r\n\r\n~/.spack/.spack-env/view/lib/python3.9/site-packages/gpytorch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    151 \r\n    152         mean, covar = self.loc, self.lazy_covariance_matrix\r\n--> 153         diff = value - mean\r\n    154 \r\n    155         # Repeat the covar to match the batch shape of diff\r\n\r\nRuntimeError: The size of tensor a (400) must match the size of tensor b (200) at non-singleton dimension 0\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI would expect to be able to model a multivariable multivariate problem even if the number of variables and tasks do not match.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch 1.8.0\r\n- PyTorch 1.12.0\r\n- macOS 12.4 (Apple M1 Pro)", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2075/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2075/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2056", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2056/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2056/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2056/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2056", "id": 1296610660, "node_id": "I_kwDOBZhSr85NSLVk", "number": 2056, "title": "[Bug] Exact DKL (Deep Kernel Learning) Regression w/ KISS-GP: only Tensors of floating point dtype can require gradients", "user": {"login": "stevenstetzler", "id": 11035971, "node_id": "MDQ6VXNlcjExMDM1OTcx", "avatar_url": "https://avatars.githubusercontent.com/u/11035971?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stevenstetzler", "html_url": "https://github.com/stevenstetzler", "followers_url": "https://api.github.com/users/stevenstetzler/followers", "following_url": "https://api.github.com/users/stevenstetzler/following{/other_user}", "gists_url": "https://api.github.com/users/stevenstetzler/gists{/gist_id}", "starred_url": "https://api.github.com/users/stevenstetzler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stevenstetzler/subscriptions", "organizations_url": "https://api.github.com/users/stevenstetzler/orgs", "repos_url": "https://api.github.com/users/stevenstetzler/repos", "events_url": "https://api.github.com/users/stevenstetzler/events{/privacy}", "received_events_url": "https://api.github.com/users/stevenstetzler/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2022-07-06T23:56:58Z", "updated_at": "2022-08-07T19:17:12Z", "closed_at": "2022-08-07T19:17:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI am trying to use Exact Deep Kernel Learning with KISS-GP, following the example from the [docs](https://docs.gpytorch.ai/en/stable/examples/06_PyTorch_NN_Integration_DKL/KISSGP_Deep_Kernel_Regression_CUDA.html#Overview). I am running into the error error `only Tensors of floating point dtype can require gradients` when I try to train using the Adam optimizer. It looks like it comes during back propagation through the Cholesky decomposition. I put in a print statement in [_pivoted_cholesky.py](https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/functions/_pivoted_cholesky.py#L94-L101) to print out `_matrix_args`\r\n```python\r\n...\r\n    def backward(ctx, grad_output, _):\r\n        full_permutation, short_permutation, *_matrix_args = ctx.saved_tensors\r\n        _inverse_permutation = inverse_permutation(full_permutation)\r\n        m = short_permutation.size(-1)  # The rank of the pivoted Cholesky factor\r\n\r\n        with torch.enable_grad():\r\n            # Create a new set of matrix args that we can backpropagate through\r\n            [print(m, m.dtype, m.shape) for m in _matrix_args]\r\n            matrix_args = [matrix_arg.detach().requires_grad_(True) for matrix_arg in _matrix_args]\r\n```\r\nwhich shows the output:\r\n```\r\ntensor([0.6931, 0.6725, 0.6141, 0.5279, 0.4271, 0.3252, 0.2331, 0.1573, 0.0999,\r\n        0.0597, 0.0336, 0.0178, 0.0089, 0.0042, 0.0018, 0.0008],\r\n       dtype=torch.float64, grad_fn=<ExpandBackward0>) torch.float64 torch.Size([16])\r\ntensor([0.6931, 0.6761, 0.6274, 0.5539, 0.4653, 0.3718, 0.2827, 0.2045, 0.1407,\r\n        0.0921, 0.0574, 0.0340, 0.0192, 0.0103, 0.0052, 0.0025],\r\n       dtype=torch.float64, grad_fn=<ExpandBackward0>) torch.float64 torch.Size([16])\r\ntensor([[ 85,  86,  87,  ..., 134, 135, 136],\r\n        [103, 104, 105,  ..., 152, 153, 154],\r\n        [134, 135, 136,  ..., 183, 184, 185],\r\n        ...,\r\n        [136, 137, 138,  ..., 185, 186, 187],\r\n        [ 85,  86,  87,  ..., 134, 135, 136],\r\n        [138, 139, 140,  ..., 187, 188, 189]]) torch.int64 torch.Size([30944, 16])\r\ntensor([[ 1.1035e-03, -9.7422e-03, -1.5181e-02,  ..., -3.0474e-02,\r\n         -4.7487e-02,  4.9617e-03],\r\n        [ 3.3665e-03, -3.3772e-02, -1.7328e-02,  ..., -4.5008e-03,\r\n         -2.3093e-03,  2.5992e-04],\r\n        [ 9.1307e-04, -2.5656e-02, -1.4260e-03,  ..., -7.0527e-02,\r\n         -3.9200e-03,  2.2810e-04],\r\n        ...,\r\n        [ 1.7785e-03, -7.3554e-02, -2.3944e-03,  ..., -3.6257e-02,\r\n         -1.1803e-03,  4.9666e-05],\r\n        [ 2.5766e-04, -1.4614e-02, -3.1947e-04,  ..., -6.2168e-02,\r\n         -1.3590e-03,  4.3256e-05],\r\n        [ 6.9518e-05, -9.5303e-04, -1.9168e-04,  ..., -1.9286e-02,\r\n         -3.8789e-03,  3.7815e-04]], dtype=torch.float64,\r\n       grad_fn=<ExpandBackward0>) torch.float64 torch.Size([30944, 16])\r\ntensor([[ 85,  86,  87,  ..., 134, 135, 136],\r\n        [103, 104, 105,  ..., 152, 153, 154],\r\n        [134, 135, 136,  ..., 183, 184, 185],\r\n        ...,\r\n        [136, 137, 138,  ..., 185, 186, 187],\r\n        [ 85,  86,  87,  ..., 134, 135, 136],\r\n        [138, 139, 140,  ..., 187, 188, 189]]) torch.int64 torch.Size([30944, 16])\r\ntensor([[ 1.1035e-03, -9.7422e-03, -1.5181e-02,  ..., -3.0474e-02,\r\n         -4.7487e-02,  4.9617e-03],\r\n        [ 3.3665e-03, -3.3772e-02, -1.7328e-02,  ..., -4.5008e-03,\r\n         -2.3093e-03,  2.5992e-04],\r\n        [ 9.1307e-04, -2.5656e-02, -1.4260e-03,  ..., -7.0527e-02,\r\n         -3.9200e-03,  2.2810e-04],\r\n        ...,\r\n        [ 1.7785e-03, -7.3554e-02, -2.3944e-03,  ..., -3.6257e-02,\r\n         -1.1803e-03,  4.9666e-05],\r\n        [ 2.5766e-04, -1.4614e-02, -3.1947e-04,  ..., -6.2168e-02,\r\n         -1.3590e-03,  4.3256e-05],\r\n        [ 6.9518e-05, -9.5303e-04, -1.9168e-04,  ..., -1.9286e-02,\r\n         -3.8789e-03,  3.7815e-04]], dtype=torch.float64,\r\n       grad_fn=<ExpandBackward0>) torch.float64 torch.Size([30944, 16])\r\n```\r\n\r\nYou can see there are two tensors of size [30944, 16] that have integer dtype being used. 16 is the grid size for the Grid Interpolation Kernel, so I think it has something to do with how that kernel is computing the covariance matrix. I don't know what those matrices are though.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n\r\nHere is my code minus data loading.\r\n\r\n```python\r\nimport gpytorch\r\nimport torch\r\nclass LargeFeatureExtractor(torch.nn.Sequential):\r\n    def __init__(self, dim, latent_dim):\r\n        super(LargeFeatureExtractor, self).__init__()\r\n        self.latent_dim = latent_dim\r\n        self.dim = dim\r\n        self.add_module('linear1', torch.nn.Linear(dim, 1000))\r\n        self.add_module('relu1', torch.nn.ReLU())\r\n        self.add_module('linear2', torch.nn.Linear(1000, 500))\r\n        self.add_module('relu2', torch.nn.ReLU())\r\n        self.add_module('linear3', torch.nn.Linear(500, 50))\r\n        self.add_module('relu3', torch.nn.ReLU())\r\n        self.add_module('linear4', torch.nn.Linear(50, latent_dim))\r\n\r\nclass DeepKernelGP(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood, feature_extractor, grid_size):\r\n        super(DeepKernelGP, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.GridInterpolationKernel(\r\n            gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=feature_extractor.latent_dim)),\r\n            num_dims=feature_extractor.latent_dim, grid_size=grid_size\r\n        )\r\n        \r\n        self.feature_extractor = feature_extractor\r\n\r\n        # This module will scale the NN features so that they're nice values\r\n        self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\r\n\r\n    def forward(self, x):\r\n        # We're first putting our data through a deep net (feature extractor)\r\n        projected_x = self.feature_extractor(x)\r\n        projected_x = self.scale_to_bounds(projected_x)  # Make the NN values \"nice\"\r\n\r\n        mean_x = self.mean_module(projected_x)\r\n        covar_x = self.covar_module(projected_x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n# I have a data set X of shape [30944, 14] and y of shape [30944, 1]\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood(\r\n     noise_prior=gpytorch.priors.SmoothedBoxPrior(0.1, 1.5, sigma=0.001)\r\n)\r\nlatent_dim = 2\r\ngrid_size = 16\r\nfeature_extractor = LargeFeatureExtractor(X.shape[1], latent_dim)\r\nmodel = DeepKernelGP(X, y, likelihood, feature_extractor, grid_size)\r\nloss = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\noptimizer = torch.optim.Adam(\r\n    [\r\n        {'params': model.feature_extractor.parameters()},\r\n        {'params': model.covar_module.parameters()},\r\n        {'params': model.mean_module.parameters()},\r\n        {'params': model.likelihood.parameters()},\r\n    ], \r\n    lr=args.lr\r\n)\r\n\r\ndef closure():\r\n    optimizer.zero_grad()\r\n    output = model(x)\r\n    nll = -loss(output, y)\r\n    nll.backward()\r\n    return nll\r\n\r\nwhile True:\r\n    optimizer.step(closure=closure)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"/vast/home/stetzler/nuclei_summer/nuclei/nuclei/train/train.py\", line 87, in _train\r\n    curr_loss = optimizer.step(closure=closure)\r\n  File \"/vast/home/stetzler/.conda/envs/nuclei/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 109, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/vast/home/stetzler/.conda/envs/nuclei/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/vast/home/stetzler/.conda/envs/nuclei/lib/python3.10/site-packages/torch/optim/adam.py\", line 118, in step\r\n    loss = closure()\r\n  File \"/vast/home/stetzler/nuclei_summer/nuclei/nuclei/train/train.py\", line 58, in closure\r\n    nll.backward()\r\n  File \"/vast/home/stetzler/.conda/envs/nuclei/lib/python3.10/site-packages/torch/_tensor.py\", line 396, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\r\n  File \"/vast/home/stetzler/.conda/envs/nuclei/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 173, in backward\r\n    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\r\n  File \"/vast/home/stetzler/.conda/envs/nuclei/lib/python3.10/site-packages/torch/autograd/function.py\", line 253, in apply\r\n    return user_fn(self, *args)\r\n  File \"/vast/home/stetzler/.conda/envs/nuclei/lib/python3.10/site-packages/gpytorch/functions/_pivoted_cholesky.py\", line 102, in backward\r\n    matrix_args = [matrix_arg.detach().requires_grad_(True) for matrix_arg in _matrix_args]\r\n  File \"/vast/home/stetzler/.conda/envs/nuclei/lib/python3.10/site-packages/gpytorch/functions/_pivoted_cholesky.py\", line 102, in <listcomp>\r\n    matrix_args = [matrix_arg.detach().requires_grad_(True) for matrix_arg in _matrix_args]\r\nRuntimeError: only Tensors of floating point dtype can require gradients```\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI expect the training to run.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> python -c \"import gpytorch; print(gpytorch.__version__)\"\r\n1.7.0\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> python -c \"import torch; print(torch.__version__)\"\r\n1.12.0+cu102\r\n- <!-- Computer OS --> cat /etc/os-release | head -n 2\r\nNAME=\"Red Hat Enterprise Linux\"\r\nVERSION=\"8.4 (Ootpa)\"\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2056/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2056/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2045", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2045/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2045/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2045/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2045", "id": 1280420139, "node_id": "I_kwDOBZhSr85MUakr", "number": 2045, "title": "[Bug] CG terminated in 1000 iterations with average residual norm XXX which is larger than the tolerance of 1 specified by gpytorch.settings.cg_tolerance.", "user": {"login": "Songloading", "id": 34990525, "node_id": "MDQ6VXNlcjM0OTkwNTI1", "avatar_url": "https://avatars.githubusercontent.com/u/34990525?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Songloading", "html_url": "https://github.com/Songloading", "followers_url": "https://api.github.com/users/Songloading/followers", "following_url": "https://api.github.com/users/Songloading/following{/other_user}", "gists_url": "https://api.github.com/users/Songloading/gists{/gist_id}", "starred_url": "https://api.github.com/users/Songloading/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Songloading/subscriptions", "organizations_url": "https://api.github.com/users/Songloading/orgs", "repos_url": "https://api.github.com/users/Songloading/repos", "events_url": "https://api.github.com/users/Songloading/events{/privacy}", "received_events_url": "https://api.github.com/users/Songloading/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-06-22T15:52:16Z", "updated_at": "2022-09-22T20:55:47Z", "closed_at": "2022-09-22T20:55:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI am not sure this is a bug or something I just made a mistake. I do notice there was a post (issue #1129) very similar to my scenario. In short, the error pops whenever I want to do validation, specifically line \r\n```\r\nvalid_loss = -mll(prediction_val, torch.tensor(Y_val))\r\n````\r\nI've also checked my input as mentioned in #1129 and I think both the train and validation set are well-conditioned.  Two things came to my mind: \r\n1. I've used the same loss function for both train and validation, though I didn't think it should cause any error.\r\n2. I used ```sklearn PolynomialFeatures``` to create interactions between inputs, which might be an issue mentioned in #1129 (duplicate/highly similar data).\r\n\r\n## To reproduce\r\n```python\r\n\tmin_valid_loss = np.inf\r\n\t\r\n\tfor j in range(opt.epoch):\r\n\t\tmodel.train()\r\n\t\tlikelihood.train()\r\n\t\toptimizer.zero_grad()\r\n\t\toutput = model(torch.tensor(np.float32(X_train.values)))\r\n\t\tloss = -mll(output, torch.tensor(Y_train).contiguous())\r\n\t\tloss.backward()\r\n\t\tif j % 10 == 0:\r\n\t\t\tprint(f'{site}: Iter{j}/{opt.epoch} {j} trainning day Finished - Loss: {loss.item()}')\r\n\t\toptimizer.step()\r\n\t\t\r\n\t\tif j >= int(opt.epoch*0.9):\r\n\t\t\twith torch.no_grad():\r\n\t\t\t\tmodel.eval()\r\n\t\t\t\tlikelihood.eval()\r\n\t\t\t\tvalid_loss = 0.0\r\n\t\t\t\tprediction_val = model(torch.tensor(np.float32(X_val.values)))\r\n\t\t\t\tvalid_loss = -mll(prediction_val, torch.tensor(Y_val))\r\n\t\t\t\tif min_valid_loss > valid_loss:\r\n                                  ## make prediction\r\n\r\n\r\n```\r\n\r\n\r\n** Stack trace/error message **\r\n````\r\nNumericalWarning: CG terminated in 1000 iterations with average residual norm 36.0455322265625 which is larger than the tolerance of 1 specified by gpytorch.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a gpytorch.settings.max_cg_iterations(value) context.\r\n  warnings.warn(\r\n````\r\n\r\n## Expected Behavior\r\n\r\nI expect the loss being calculated without any error in validation.\r\n\r\n## System information\r\nGPyTorch Version - 1.6.0\r\n PyTorch Version - 1.11.0\r\nComputer OS - Ubuntu 18.04\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2045/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2045/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2036", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2036/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2036/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2036/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2036", "id": 1264348410, "node_id": "I_kwDOBZhSr85LXGz6", "number": 2036, "title": "[Bug] : RuntimeError: The expected shape of the kernel was torch.Size([60, 60]), but got torch.Size([360, 360]). This is likely a bug in GPyTorch.", "user": {"login": "CecileLeSueur", "id": 43442886, "node_id": "MDQ6VXNlcjQzNDQyODg2", "avatar_url": "https://avatars.githubusercontent.com/u/43442886?v=4", "gravatar_id": "", "url": "https://api.github.com/users/CecileLeSueur", "html_url": "https://github.com/CecileLeSueur", "followers_url": "https://api.github.com/users/CecileLeSueur/followers", "following_url": "https://api.github.com/users/CecileLeSueur/following{/other_user}", "gists_url": "https://api.github.com/users/CecileLeSueur/gists{/gist_id}", "starred_url": "https://api.github.com/users/CecileLeSueur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/CecileLeSueur/subscriptions", "organizations_url": "https://api.github.com/users/CecileLeSueur/orgs", "repos_url": "https://api.github.com/users/CecileLeSueur/repos", "events_url": "https://api.github.com/users/CecileLeSueur/events{/privacy}", "received_events_url": "https://api.github.com/users/CecileLeSueur/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-06-08T07:57:06Z", "updated_at": "2022-08-07T19:03:33Z", "closed_at": "2022-08-07T19:03:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nAs posted [here](https://github.com/cornellius-gp/gpytorch/issues/996#issuecomment-1148872594) I'm trying to build a  hierarchical GP regression model. I used Multitask GP Regression.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\n%matplotlib inline\r\n%load_ext autoreload\r\n%autoreload 2\r\n\r\n# define the HierarchicalGPModel\r\nclass HierarchicalGPModel(gpytorch.kernels.Kernel):\r\n    \r\n    # We will register the parameter when initializing the kernel\r\n    def __init__(self, NTask, **kwargs):\r\n        super(HierarchicalGPModel, self).__init__()\r\n        self.kern_lower = gpytorch.kernels.RBFKernel()\r\n        self.kern_upper = gpytorch.kernels.RBFKernel()\r\n        self.NTask = NTask\r\n\r\n    # this is the kernel function\r\n    def forward(self, time, task):\r\n        #import pdb; pdb.set_trace()\r\n        return gpytorch.lazy.SumLazyTensor(\r\n            gpytorch.lazy.KroneckerProductLazyTensor(self.kern_lower(task), torch.ones(self.NTask, self.NTask)),\r\n            gpytorch.lazy.KroneckerProductLazyTensor(self.kern_upper(task), torch.eye(self.NTask))\r\n        )\r\n\r\n# create a MultitaskGPModel\r\nclass MultitaskGPModel(gpytorch.models.ExactGP):\r\n    \r\n    def __init__(self, train_x, train_y, likelihood, NTask):\r\n        \r\n        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\r\n        \r\n        self.mean_module = gpytorch.means.MultitaskMean(\r\n            gpytorch.means.ConstantMean(), num_tasks= NTask\r\n        )\r\n        \r\n        self.covar_module = gpytorch.kernels.MultitaskKernel(\r\n            HierarchicalGPModel(NTask=NTask), num_tasks= NTask, rank=1\r\n        )\r\n        \r\n        \r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\r\n\r\n# I generate random observations to mimic my 6 replicates of 10 observations\r\ntrain_x = torch.range(1,10)\r\ntrain_y = []\r\nfor i in range(10):\r\n    train_y.append(torch.normal(mean=torch.arange(1., 7.), std=torch.arange(7, 1, -1)))\r\n\r\ntrain_y = torch.stack(train_y, -1).T\r\n\r\n# create the model and train it\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks = 6)\r\nmodel = MultitaskGPModel(train_x, train_y, likelihood, 6 )\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\ntraining_iterations=50\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iterations):\r\n    optimizer.zero_grad()\r\n    output = model(train_x.float())\r\n    loss = -mll(output, train_y.float())\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n    optimizer.step()\r\n\r\n        \r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n/var/folders/zk/1586qm5x6y9_qzjhf8f311h00000gn/T/ipykernel_38861/2885976473.py in <module>\r\n     13     optimizer.zero_grad()\r\n     14     output = model(train_x.float())\r\n---> 15     loss = -mll(output, train_y.float())\r\n     16     loss.backward()\r\n     17     print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n\r\n~/lib/python3.9/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     28 \r\n     29     def __call__(self, *inputs, **kwargs):\r\n---> 30         outputs = self.forward(*inputs, **kwargs)\r\n     31         if isinstance(outputs, list):\r\n     32             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/lib/python3.9/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, function_dist, target, *params)\r\n     59 \r\n     60         # Get the log prob of the marginal distribution\r\n---> 61         output = self.likelihood(function_dist, *params)\r\n     62         res = output.log_prob(target)\r\n     63         res = self._add_other_terms(res, params)\r\n\r\n~/lib/python3.9/site-packages/gpytorch/likelihoods/likelihood.py in __call__(self, input, *args, **kwargs)\r\n     63         # Marginal\r\n     64         elif isinstance(input, MultivariateNormal):\r\n---> 65             return self.marginal(input, *args, **kwargs)\r\n     66         # Error\r\n     67         else:\r\n\r\n~/lib/python3.9/site-packages/gpytorch/likelihoods/multitask_gaussian_likelihood.py in marginal(self, function_dist, *params, **kwargs)\r\n     92         # ensure that sumKroneckerLT is actually called\r\n     93         if isinstance(covar, LazyEvaluatedKernelTensor):\r\n---> 94             covar = covar.evaluate_kernel()\r\n     95 \r\n     96         covar_kron_lt = self._shaped_noise_covar(mean.shape, add_noise=self.has_global_noise)\r\n\r\n~/lib/python3.9/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n~/lib/python3.9/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)\r\n    344         if settings.debug.on():\r\n    345             if res.shape != self.shape:\r\n--> 346                 raise RuntimeError(\r\n    347                     f\"The expected shape of the kernel was {self.shape}, but got {res.shape}. \"\r\n    348                     \"This is likely a bug in GPyTorch.\"\r\n\r\nRuntimeError: The expected shape of the kernel was torch.Size([60, 60]), but got torch.Size([360, 360]). This is likely a bug in GPyTorch.\r\n```\r\n\r\n## Expected Behavior\r\n\r\nA kernel of size torch.Size([60, 60]).\r\n\r\n## System information\r\n\r\n-  GPyTorch Version 1.6.0 \r\n- PyTorch Version 1.10.2\r\n-  Computer OS : macOS Big Sur, Version 11.5.2 \r\n\r\n\r\nThanks a lot for your help!\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2036/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2036/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2031", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2031/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2031/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2031/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2031", "id": 1261037085, "node_id": "I_kwDOBZhSr85LKeYd", "number": 2031, "title": "[Bug]  Matrix not positive definite error when using PseudoLikelihoodLoss(LOO_CV)", "user": {"login": "pok99", "id": 55046754, "node_id": "MDQ6VXNlcjU1MDQ2NzU0", "avatar_url": "https://avatars.githubusercontent.com/u/55046754?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pok99", "html_url": "https://github.com/pok99", "followers_url": "https://api.github.com/users/pok99/followers", "following_url": "https://api.github.com/users/pok99/following{/other_user}", "gists_url": "https://api.github.com/users/pok99/gists{/gist_id}", "starred_url": "https://api.github.com/users/pok99/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pok99/subscriptions", "organizations_url": "https://api.github.com/users/pok99/orgs", "repos_url": "https://api.github.com/users/pok99/repos", "events_url": "https://api.github.com/users/pok99/events{/privacy}", "received_events_url": "https://api.github.com/users/pok99/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-06-05T12:25:34Z", "updated_at": "2022-06-29T17:34:35Z", "closed_at": "2022-06-29T17:34:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI get the error `NotPSDError: Matrix not positive definite after repeatedly adding jitter up to 1.0e-04.` when training a regular ExactGP with the PseudoLikelihoodLoss (LOO_CV). The code below works when I use the MLL but not when I use the LOO-CV loss. \r\n\r\n\r\nI am using this definition of the LeaveOneOutPseudoLikelihood:\r\n\r\n\r\n```\r\nimport math\r\n\r\nimport torch\r\nfrom torch import Tensor\r\n\r\nfrom torch.distributions import MultivariateNormal\r\nfrom gpytorch.mlls import ExactMarginalLogLikelihood\r\n\r\nclass LeaveOneOutPseudoLikelihood(ExactMarginalLogLikelihood):\r\n    \"\"\"\r\n    The leave one out cross-validation (LOO-CV) likelihood from RW 5.4.2 for an exact Gaussian process with a\r\n    Gaussian likelihood. This offers an alternative to the exact marginal log likelihood where we\r\n    instead maximize the sum of the leave one out log probabilities :math:`\\log p(y_i | X, y_{-i}, \\theta)`.\r\n    Naively, this will be O(n^4) with Cholesky as we need to compute `n` Cholesky factorizations. Fortunately,\r\n    given the Cholesky factorization of the full kernel matrix (without any points removed), we can compute\r\n    both the mean and variance of each removed point via a bordered system formulation making the total\r\n    complexity O(n^3).\r\n    The LOO-CV approach can be more robust against model mis-specification as it gives an estimate for the\r\n    (log) predictive probability, whether or not the assumptions of the model is fulfilled.\r\n    .. note::\r\n        This module will not work with anything other than a :obj:`~gpytorch.likelihoods.GaussianLikelihood`\r\n        and a :obj:`~gpytorch.models.ExactGP`. It also cannot be used in conjunction with\r\n        stochastic optimization.\r\n    :param ~gpytorch.likelihoods.GaussianLikelihood likelihood: The Gaussian likelihood for the model\r\n    :param ~gpytorch.models.ExactGP model: The exact GP model\r\n    Example:\r\n        >>> # model is a gpytorch.models.ExactGP\r\n        >>> # likelihood is a gpytorch.likelihoods.Likelihood\r\n        >>> loocv = gpytorch.mlls.LeaveOneOutPseudoLikelihood(likelihood, model)\r\n        >>>\r\n        >>> output = model(train_x)\r\n        >>> loss = -loocv(output, train_y)\r\n        >>> loss.backward()\r\n    \"\"\"\r\n\r\n    def __init__(self, likelihood, model):\r\n        super().__init__(likelihood=likelihood, model=model)\r\n        self.likelihood = likelihood\r\n        self.model = model\r\n\r\n    def forward(self, function_dist: MultivariateNormal, target: Tensor, *params) -> Tensor:\r\n        r\"\"\"\r\n        Computes the leave one out likelihood given :math:`p(\\mathbf f)` and `\\mathbf y`\r\n        :param ~gpytorch.distributions.MultivariateNormal output: the outputs of the latent function\r\n            (the :obj:`~gpytorch.models.GP`)\r\n        :param torch.Tensor target: :math:`\\mathbf y` The target values\r\n        :param dict kwargs: Additional arguments to pass to the likelihood's :attr:`forward` function.\r\n        \"\"\"\r\n        output = self.likelihood(function_dist, *params)\r\n        m, L = output.mean, output.lazy_covariance_matrix.cholesky(upper=False)\r\n        m = m.reshape(*target.shape)\r\n        identity = torch.eye(*L.shape[-2:], dtype=m.dtype, device=m.device)\r\n        sigma2 = 1.0 / L._cholesky_solve(identity, upper=False).diagonal(dim1=-1, dim2=-2)  # 1 / diag(inv(K))\r\n        mu = target - L._cholesky_solve((target - m).unsqueeze(-1), upper=False).squeeze(-1) * sigma2\r\n        term1 = -0.5 * sigma2.log()\r\n        term2 = -0.5 * (target - mu).pow(2.0) / sigma2\r\n        res = (term1 + term2).sum(dim=-1)\r\n\r\n        res = self._add_other_terms(res, params)\r\n\r\n        # Scale by the amount of data we have and then add on the scaled constant\r\n        num_data = target.size(-1)\r\n        return res.div_(num_data) - 0.5 * math.log(2 * math.pi)\r\n```\r\n\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_X, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_X, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ZeroMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=81))\r\n        \r\n    def forward(self, x):\r\n        mean = self.mean_module(x)\r\n        covar = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean, covar)\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel= ExactGPModel(train_x, train_y, likelihood)\r\n\r\n\r\n\r\n#set to training mode\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\r\ntraining_iter = 50\r\n\r\n# \"Loss\" for GPs - loo_train_loss\r\nloo_train_loss = gpytorch.mlls.LeaveOneOutPseudoLikelihood(likelihood, model)\r\n\r\n\r\nfor i in range(training_iter):\r\n    # Zero gradients from previous iteration\r\n    optimizer.zero_grad()\r\n    # Output from model\r\n    output = model(train_x)\r\n    # Calc loss and backprop gradients\r\n    loss = -loo_train_loss(output, train_y)\r\n    loss.backward()\r\n    #print('Iter %d/%d - Loss: %.3f ' % (\r\n        #i + 1, training_iter, loss.item()))\r\n    \r\n    #print(model.covar_module.base_kernel.lengthscale, model.likelihood.noise)\r\n  \r\n    optimizer.step()\r\n\r\n\r\n\r\n\r\n\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nNotPSDError                               Traceback (most recent call last)\r\n<ipython-input-256-74b03dbb6431> in <module>\r\n     33     output = model(train_x)\r\n     34     # Calc loss and backprop gradients\r\n---> 35     loss = -loo_train_loss(output, train_y)\r\n     36     loss.backward()\r\n     37     #print('Iter %d/%d - Loss: %.3f ' % (\r\n\r\n~/opt/anaconda3/lib/python3.7/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     28 \r\n     29     def __call__(self, *inputs, **kwargs):\r\n---> 30         outputs = self.forward(*inputs, **kwargs)\r\n     31         if isinstance(outputs, list):\r\n     32             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/opt/anaconda3/lib/python3.7/site-packages/gpytorch/mlls/leave_one_out_pseudo_likelihood.py in forward(self, function_dist, target, *params)\r\n     56         \"\"\"\r\n     57         output = self.likelihood(function_dist, *params)\r\n---> 58         m, L = output.mean, output.lazy_covariance_matrix.cholesky(upper=False)\r\n     59         m = m.reshape(*target.shape)\r\n     60         identity = torch.eye(*L.shape[-2:], dtype=m.dtype, device=m.device)\r\n\r\n~/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in cholesky(self, upper)\r\n    960             (LazyTensor) Cholesky factor (triangular, upper/lower depending on \"upper\" arg)\r\n    961         \"\"\"\r\n--> 962         chol = self._cholesky(upper=False)\r\n    963         if upper:\r\n    964             chol = chol._transpose_nonbatch()\r\n\r\n~/opt/anaconda3/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n~/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in _cholesky(self, upper)\r\n    423 \r\n    424         # contiguous call is necessary here\r\n--> 425         cholesky = psd_safe_cholesky(evaluated_mat, upper=upper).contiguous()\r\n    426         return TriangularLazyTensor(cholesky, upper=upper)\r\n    427 \r\n\r\n~/opt/anaconda3/lib/python3.7/site-packages/gpytorch/utils/cholesky.py in psd_safe_cholesky(A, upper, out, jitter, max_tries)\r\n    106                 Number of attempts (with successively increasing jitter) to make before raising an error.\r\n    107         \"\"\"\r\n--> 108     L = _psd_safe_cholesky(A, out=out, jitter=jitter, max_tries=max_tries)\r\n    109     if upper:\r\n    110         if out is not None:\r\n\r\n~/opt/anaconda3/lib/python3.7/site-packages/gpytorch/utils/cholesky.py in _psd_safe_cholesky(A, out, jitter, max_tries)\r\n     46             if not torch.any(info):\r\n     47                 return L\r\n---> 48         raise NotPSDError(f\"Matrix not positive definite after repeatedly adding jitter up to {jitter_new:.1e}.\")\r\n     49 \r\n     50 \r\n\r\nNotPSDError: Matrix not positive definite after repeatedly adding jitter up to 1.0e-04.\r\n```\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2031/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2031/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2030", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2030/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2030/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2030/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2030", "id": 1261034641, "node_id": "I_kwDOBZhSr85LKdyR", "number": 2030, "title": "[Bug]  Matrix not positive definite error when using PseudoLikelihoodLoss(LOO_CV)", "user": {"login": "pok99", "id": 55046754, "node_id": "MDQ6VXNlcjU1MDQ2NzU0", "avatar_url": "https://avatars.githubusercontent.com/u/55046754?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pok99", "html_url": "https://github.com/pok99", "followers_url": "https://api.github.com/users/pok99/followers", "following_url": "https://api.github.com/users/pok99/following{/other_user}", "gists_url": "https://api.github.com/users/pok99/gists{/gist_id}", "starred_url": "https://api.github.com/users/pok99/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pok99/subscriptions", "organizations_url": "https://api.github.com/users/pok99/orgs", "repos_url": "https://api.github.com/users/pok99/repos", "events_url": "https://api.github.com/users/pok99/events{/privacy}", "received_events_url": "https://api.github.com/users/pok99/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-06-05T12:13:00Z", "updated_at": "2022-06-05T12:30:32Z", "closed_at": "2022-06-05T12:30:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n# Your code goes here\r\n# Please make sure it does not require any external dependencies (other than PyTorch!)\r\n# (We much prefer small snippets rather than links to existing libraries!)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n// Paste the bad output here!\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` -->\r\n- <!-- PyTorch Version (run `print(torch.__version__)` -->\r\n- <!-- Computer OS -->\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2030/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2030/timeline", "performed_via_github_app": null, "state_reason": "not_planned"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2013", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2013/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2013/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2013/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2013", "id": 1241963798, "node_id": "I_kwDOBZhSr85KBt0W", "number": 2013, "title": "[Bug]", "user": {"login": "920039", "id": 57096283, "node_id": "MDQ6VXNlcjU3MDk2Mjgz", "avatar_url": "https://avatars.githubusercontent.com/u/57096283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/920039", "html_url": "https://github.com/920039", "followers_url": "https://api.github.com/users/920039/followers", "following_url": "https://api.github.com/users/920039/following{/other_user}", "gists_url": "https://api.github.com/users/920039/gists{/gist_id}", "starred_url": "https://api.github.com/users/920039/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/920039/subscriptions", "organizations_url": "https://api.github.com/users/920039/orgs", "repos_url": "https://api.github.com/users/920039/repos", "events_url": "https://api.github.com/users/920039/events{/privacy}", "received_events_url": "https://api.github.com/users/920039/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-05-19T15:31:49Z", "updated_at": "2022-05-19T21:24:13Z", "closed_at": "2022-05-19T21:24:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n When trying to use gpytorch.metrics  : AttributeError: module 'gpytorch' has no attribute 'metrics'\r\n\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n##Using the basic usage example - but I've copied it in just incase##\r\n\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n%matplotlib inline\r\n%load_ext autoreload\r\n%autoreload 2\r\n# Training data is 100 points in [0,1] inclusive regularly spaced\r\ntrain_x = torch.linspace(0, 1, 100)\r\n# True function is sin(2*pi*x) with Gaussian noise\r\ntrain_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)\r\n\r\ntest_x = torch.linspace(0, 1, 51)\r\ntest_y = torch.sin(test_x * (2 * math.pi)) + torch.randn(test_x.size()) * math.sqrt(0.04)\r\nIn the next cell, we define a simple GP regression model.\r\n\r\n# We will use the simplest form of GP model, exact inference\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n    \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n# initialize likelihood and model\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n\r\n# this is for running the notebook in our testing framework\r\nimport os\r\nsmoke_test = ('CI' in os.environ)\r\ntraining_iter = 2 if smoke_test else 50\r\n\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iter):\r\n    # Zero gradients from previous iteration\r\n    optimizer.zero_grad()\r\n    # Output from model\r\n    output = model(train_x)\r\n    # Calc loss and backprop gradients\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\r\n        i + 1, training_iter, loss.item(),\r\n        model.covar_module.base_kernel.lengthscale.item(),\r\n        model.likelihood.noise.item()\r\n    ))\r\n    optimizer.step()\r\n\r\nmodel.eval()\r\nwith torch.no_grad():\r\n    trained_pred_dist = likelihood(model(test_x))\r\n    predictive_mean = trained_pred_dist.mean\r\n    lower, upper = trained_pred_dist.confidence_region()\r\n    \r\nf, ax = plt.subplots(1, 1, figsize=(4, 3))\r\n# Plot training data as black stars\r\nax.plot(train_x, train_y, 'k*')\r\n# Plot predictive means as blue line\r\nax.plot(test_x, predictive_mean, 'b')\r\n# Shade between the lower and upper confidence bounds\r\nax.fill_between(test_x, lower, upper, alpha=0.5)\r\nax.set_ylim([-3, 3])\r\nax.legend(['Observed Data', 'Mean', 'Confidence'], bbox_to_anchor=(1.6,1));\r\n\r\ninit_msll = gpytorch.metrics.mean_standardized_log_loss(untrained_pred_dist, test_y)\r\nfinal_msll = gpytorch.metrics.mean_standardized_log_loss(trained_pred_dist, test_y)\r\n\r\nprint(f'Untrained model MSLL: {init_msll:.2f}, \\nTrained model MSLL: {final_msll:.2f}')\r\n```\r\n\r\n** Stack trace/error message **\r\n``` \r\nAttributeError: module 'gpytorch' has no attribute 'metrics'\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-7-17fe57f9f4e9> in <module>\r\n----> 1 init_msll = gpytorch.metrics.mean_standardized_log_loss(untrained_pred_dist, test_y)\r\n      2 final_msll = gpytorch.metrics.mean_standardized_log_loss(trained_pred_dist, test_y)\r\n      3 \r\n      4 print(f'Untrained model MSLL: {init_msll:.2f}, \\nTrained model MSLL: {final_msll:.2f}')\r\n\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\nFor the .metrics to be called and for the log-loss to be given\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` -->1.6.0\r\n\r\n- <!-- PyTorch Version (run `print(torch.__version__)` -->1.11.0+cpu\r\n- <!-- Computer OS --> windows\r\n\r\n## Additional context\r\nUnsure if I'm missing something like ' from gpytorch import metrics ' ? \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2013/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2013/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2001", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2001/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2001/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2001/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/2001", "id": 1225154979, "node_id": "I_kwDOBZhSr85JBmGj", "number": 2001, "title": "[Bug]", "user": {"login": "920039", "id": 57096283, "node_id": "MDQ6VXNlcjU3MDk2Mjgz", "avatar_url": "https://avatars.githubusercontent.com/u/57096283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/920039", "html_url": "https://github.com/920039", "followers_url": "https://api.github.com/users/920039/followers", "following_url": "https://api.github.com/users/920039/following{/other_user}", "gists_url": "https://api.github.com/users/920039/gists{/gist_id}", "starred_url": "https://api.github.com/users/920039/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/920039/subscriptions", "organizations_url": "https://api.github.com/users/920039/orgs", "repos_url": "https://api.github.com/users/920039/repos", "events_url": "https://api.github.com/users/920039/events{/privacy}", "received_events_url": "https://api.github.com/users/920039/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-05-04T09:55:13Z", "updated_at": "2022-05-04T14:05:28Z", "closed_at": "2022-05-04T14:05:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nRuntimeError: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 1\r\n\r\n## To reproduce\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\ndef Branin(X,Y):\r\n\r\n    PI = 3.14159265359\r\n    a = 1\r\n    b = 5.1 / (4 * pow(PI, 2))\r\n    c = 5 / PI\r\n    r = 6\r\n    s = 10\r\n    t = 1 / (8 * PI)\r\n    \r\n    train_y = a * (X - b * Y ** 2 + c * Y - r) ** 2 + s * (1 - t) * torch.cos(Y) + s\r\n    \r\n    return train_y\r\n\r\nxv, yv = torch.meshgrid([torch.linspace(-5, 10, 100), torch.linspace(0, 15, 100)])\r\ntrain_x = torch.cat((\r\n    xv.contiguous().view(xv.numel(), 1),\r\n    yv.contiguous().view(yv.numel(), 1)),\r\n    dim=1\r\n).repeat(4,1,1)\r\ntrain_y = Branin(train_x[:, 0], train_x[:, 1]).unsqueeze(-1)\r\n\r\nprint(train_x.shape)\r\nprint(train_y.shape)\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([4]))\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.MaternKernel(batch_shape=torch.Size([4])),\r\n            batch_shape=torch.Size([4])\r\n        )\r\n    \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n## initialize likelihood and model\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood(batch_shape=torch.Size([4]))\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n# this is for running the notebook in our testing framework\r\nimport os\r\nsmoke_test = ('CI' in os.environ)\r\ntraining_iter = 2 if smoke_test else 50\r\n\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iter):\r\n    # Zero gradients from previous iteration\r\n    optimizer.zero_grad()\r\n    # Output from model\r\n    output = model(train_x)\r\n    # Calc loss and backprop gradients\r\n    loss = -mll(output, train_y).sum()\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iter, loss.item()))\r\n    optimizer.step()\r\n\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-82-1f88bf10d4b6> in <module>\r\n     21     output = model(train_x)\r\n     22     # Calc loss and backprop gradients\r\n---> 23     loss = -mll(output, train_y).sum()\r\n     24     loss.backward()\r\n     25     print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iter, loss.item()))\r\n\r\n~\\anaconda3\\lib\\site-packages\\gpytorch\\module.py in __call__(self, *inputs, **kwargs)\r\n     28 \r\n     29     def __call__(self, *inputs, **kwargs):\r\n---> 30         outputs = self.forward(*inputs, **kwargs)\r\n     31         if isinstance(outputs, list):\r\n     32             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~\\anaconda3\\lib\\site-packages\\gpytorch\\mlls\\exact_marginal_log_likelihood.py in forward(self, function_dist, target, *params)\r\n     60         # Get the log prob of the marginal distribution\r\n     61         output = self.likelihood(function_dist, *params)\r\n---> 62         res = output.log_prob(target)\r\n     63         res = self._add_other_terms(res, params)\r\n     64 \r\n\r\n~\\anaconda3\\lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py in log_prob(self, value)\r\n    151 \r\n    152         mean, covar = self.loc, self.lazy_covariance_matrix\r\n--> 153         diff = value - mean\r\n    154 \r\n    155         # Repeat the covar to match the batch shape of diff\r\n\r\nRuntimeError: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 1\r\n\r\n\u200b\r\n```\r\n\r\n## Expected Behavior\r\n\r\nExpected the model to run ok. The tensor for my train_y is not the same shape as train_x, I'm fairly new to python and I cant work out how to get them the same size when using this batch method. How can I get the size of my train_y to match train_x please? \r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n1.6.0\r\n1.11.0+cpu\r\nwindows\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2001/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/2001/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1995", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1995/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1995/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1995/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1995", "id": 1217158484, "node_id": "I_kwDOBZhSr85IjF1U", "number": 1995, "title": "[Bug] / RuntimeError: Shapes are not broadcastable for mul operation", "user": {"login": "920039", "id": 57096283, "node_id": "MDQ6VXNlcjU3MDk2Mjgz", "avatar_url": "https://avatars.githubusercontent.com/u/57096283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/920039", "html_url": "https://github.com/920039", "followers_url": "https://api.github.com/users/920039/followers", "following_url": "https://api.github.com/users/920039/following{/other_user}", "gists_url": "https://api.github.com/users/920039/gists{/gist_id}", "starred_url": "https://api.github.com/users/920039/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/920039/subscriptions", "organizations_url": "https://api.github.com/users/920039/orgs", "repos_url": "https://api.github.com/users/920039/repos", "events_url": "https://api.github.com/users/920039/events{/privacy}", "received_events_url": "https://api.github.com/users/920039/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-04-27T10:34:06Z", "updated_at": "2022-04-27T14:09:03Z", "closed_at": "2022-04-27T14:09:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n#<RuntimeError: Shapes are not broadcastable for mul operation>\r\n\r\nimport os\r\nsmoke_test = ('CI' in os.environ)\r\ntraining_iter = 2 if smoke_test else 50\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.05)  # Includes GaussianLikelihood parameters\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iter):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    print(output)\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print(\"Iter %d/%d - Loss: %.3f   lengthscales: %.3f, %.3f   noise: %.3f\" % (\r\n        i + 1, training_iter, loss.item(),\r\n        model.covar_module.base_kernel.lengthscale.squeeze()[0],\r\n        model.covar_module.base_kernel.lengthscale.squeeze()[1],\r\n        model.likelihood.noise.item()\r\n    ))\r\n    optimizer.step()\r\n```\r\n\r\n**MultivariateNormal(loc: torch.Size([100, 3]))\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-52-c9b31d0fedd9> in <module>\r\n     19     output = model(train_x)\r\n     20     print(output)\r\n---> 21     loss = -mll(output, train_y)\r\n     22     loss.backward()\r\n     23     print(\"Iter %d/%d - Loss: %.3f   lengthscales: %.3f, %.3f   noise: %.3f\" % (\r\n\r\n~\\anaconda3\\lib\\site-packages\\gpytorch\\module.py in __call__(self, *inputs, **kwargs)\r\n     28 \r\n     29     def __call__(self, *inputs, **kwargs):\r\n---> 30         outputs = self.forward(*inputs, **kwargs)\r\n     31         if isinstance(outputs, list):\r\n     32             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~\\anaconda3\\lib\\site-packages\\gpytorch\\mlls\\exact_marginal_log_likelihood.py in forward(self, function_dist, target, *params)\r\n     59 \r\n     60         # Get the log prob of the marginal distribution\r\n---> 61         output = self.likelihood(function_dist, *params)\r\n     62         res = output.log_prob(target)\r\n     63         res = self._add_other_terms(res, params)\r\n\r\n~\\anaconda3\\lib\\site-packages\\gpytorch\\likelihoods\\likelihood.py in __call__(self, input, *args, **kwargs)\r\n     63         # Marginal\r\n     64         elif isinstance(input, MultivariateNormal):\r\n---> 65             return self.marginal(input, *args, **kwargs)\r\n     66         # Error\r\n     67         else:\r\n\r\n~\\anaconda3\\lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py in marginal(self, function_dist, *params, **kwargs)\r\n     70         mean, covar = function_dist.mean, function_dist.lazy_covariance_matrix\r\n     71         noise_covar = self._shaped_noise_covar(mean.shape, *params, **kwargs)\r\n---> 72         full_covar = covar + noise_covar\r\n     73         return function_dist.__class__(mean, full_covar)\r\n     74 \r\n\r\n~\\anaconda3\\lib\\site-packages\\gpytorch\\lazy\\lazy_tensor.py in __add__(self, other)\r\n   2101             return self\r\n   2102         elif isinstance(other, DiagLazyTensor):\r\n-> 2103             return AddedDiagLazyTensor(self, other)\r\n   2104         elif isinstance(other, RootLazyTensor):\r\n   2105             return self.add_low_rank(other.root)\r\n\r\n~\\anaconda3\\lib\\site-packages\\gpytorch\\lazy\\added_diag_lazy_tensor.py in __init__(self, preconditioner_override, *lazy_tensors)\r\n     30             raise RuntimeError(\"An AddedDiagLazyTensor can only have two components\")\r\n     31 \r\n---> 32         broadcasting._mul_broadcast_shape(lazy_tensors[0].shape, lazy_tensors[1].shape)\r\n     33 \r\n     34         if isinstance(lazy_tensors[0], DiagLazyTensor) and isinstance(lazy_tensors[1], DiagLazyTensor):\r\n\r\n~\\anaconda3\\lib\\site-packages\\gpytorch\\utils\\broadcasting.py in _mul_broadcast_shape(error_msg, *shapes)\r\n     18             if any(size != non_singleton_sizes[0] for size in non_singleton_sizes):\r\n     19                 if error_msg is None:\r\n---> 20                     raise RuntimeError(\"Shapes are not broadcastable for mul operation\")\r\n     21                 else:\r\n     22                     raise RuntimeError(error_msg)\r\n\r\nRuntimeError: Shapes are not broadcastable for mul operation **\r\n\r\n```\r\n\r\n## Expected the model to iterate through the train_x data to give the loss/ noise. Fairly new to gpytorch \r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 1.6.0\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> 1.11.0+cpu\r\n- <!-- Computer OS -->\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n\r\nI am trying to run a basic exact regression using a 2D tensor for my train_x data (25,2) tensor and train_y is branin function 25x1 tensor \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1995/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1995/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1964", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1964/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1964/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1964/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1964", "id": 1191998628, "node_id": "I_kwDOBZhSr85HDHSk", "number": 1964, "title": "[Bug] IF-construction leads to RuntimeError in polynomial kernel ", "user": {"login": "queen-s0", "id": 36987177, "node_id": "MDQ6VXNlcjM2OTg3MTc3", "avatar_url": "https://avatars.githubusercontent.com/u/36987177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/queen-s0", "html_url": "https://github.com/queen-s0", "followers_url": "https://api.github.com/users/queen-s0/followers", "following_url": "https://api.github.com/users/queen-s0/following{/other_user}", "gists_url": "https://api.github.com/users/queen-s0/gists{/gist_id}", "starred_url": "https://api.github.com/users/queen-s0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/queen-s0/subscriptions", "organizations_url": "https://api.github.com/users/queen-s0/orgs", "repos_url": "https://api.github.com/users/queen-s0/repos", "events_url": "https://api.github.com/users/queen-s0/events{/privacy}", "received_events_url": "https://api.github.com/users/queen-s0/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-04-04T15:58:41Z", "updated_at": "2022-04-13T15:19:22Z", "closed_at": "2022-04-13T15:19:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI wanted to train a gp-model, so I made everything like in [tutorials](https://docs.gpytorch.ai/en/stable/examples/04_Variational_and_Approximate_GPs/SVGP_Multitask_GP_Regression.html). The code works with Linear and RBF kernels, but it does not work with Polynomial kernel.\r\nIt crushes with RuntimeError while inference. And from what I see in the code there might be several reasons why:\r\n- misprint (if and else should be vice versa)\r\n- pytorch changed the behavior of `torch.addmm`\r\n- or maybe there is smth I do not understand :)\r\n\r\nPlease, look at the text below.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\nclass MultitaskGPModel(gpytorch.models.ApproximateGP):\r\n    def __init__(self, grid_size=4, num_latents=2, grid_bounds=[(0., 31.)], num_tasks=256):\r\n        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\r\n            grid_size, batch_shape=torch.Size([num_latents])\r\n        )\r\n        variational_strategy = gpytorch.variational.LMCVariationalStrategy(\r\n            gpytorch.variational.GridInterpolationVariationalStrategy(self, grid_size, grid_bounds, variational_distribution),\r\n            num_tasks=num_tasks,\r\n            num_latents=num_latents,\r\n            latent_dim=-1\r\n        )\r\n        super().__init__(variational_strategy)\r\n\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([num_latents]))\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.PolynomialKernel(batch_shape=torch.Size([num_latents]), power=2),\r\n            batch_shape=torch.Size([num_latents])\r\n        )\r\n        \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n    \r\ngp_layer = MultitaskGPModel()\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=256)\r\n\r\nx = torch.randint(32, size=(1,), dtype=torch.float32).unsqueeze(1)\r\n\r\nnoise = gp_layer(x)\r\nnoise = likelihood(noise)\r\nnoise = noise.rsample((2, 2))\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n/tmp/ipykernel_15909/3264522926.py in <module>\r\n     31 x = torch.randint(32, size=(1,), dtype=torch.float32).unsqueeze(1)\r\n     32 \r\n---> 33 noise = gp_layer(x)\r\n     34 noise = likelihood(noise)\r\n     35 noise = noise.rsample((2, 2))\r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/models/approximate_gp.py in __call__(self, inputs, prior, **kwargs)\r\n     79         if inputs.dim() == 1:\r\n     80             inputs = inputs.unsqueeze(-1)\r\n---> 81         return self.variational_strategy(inputs, prior=prior, **kwargs)\r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/variational/lmc_variational_strategy.py in __call__(self, x, task_indices, prior, **kwargs)\r\n    186             or ~gpytorch.distributions.MultivariateNormal (... x N)\r\n    187         \"\"\"\r\n--> 188         latent_dist = self.base_variational_strategy(x, prior=prior, **kwargs)\r\n    189         num_batch = len(latent_dist.batch_shape)\r\n    190         latent_dim = num_batch + self.latent_dim\r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/variational/_variational_strategy.py in __call__(self, x, prior, **kwargs)\r\n    108         # (Maybe) initialize variational distribution\r\n    109         if not self.variational_params_initialized.item():\r\n--> 110             prior_dist = self.prior_distribution\r\n    111             self._variational_distribution.initialize_variational_distribution(prior_dist)\r\n    112             self.variational_params_initialized.fill_(1)\r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/variational/grid_interpolation_variational_strategy.py in prior_distribution(self)\r\n     74     def prior_distribution(self):\r\n     75         out = self.model.forward(self.inducing_points)\r\n---> 76         res = MultivariateNormal(out.mean, out.lazy_covariance_matrix.add_jitter())\r\n     77         return res\r\n     78 \r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in add_jitter(self, jitter_val)\r\n    275 \r\n    276     def add_jitter(self, jitter_val=1e-3):\r\n--> 277         return self.evaluate_kernel().add_jitter(jitter_val)\r\n    278 \r\n    279     def _unsqueeze_batch(self, dim):\r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)\r\n    330             temp_active_dims = self.kernel.active_dims\r\n    331             self.kernel.active_dims = None\r\n--> 332             res = self.kernel(\r\n    333                 x1,\r\n    334                 x2,\r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, last_dim_is_batch, **params)\r\n    400                 res = LazyEvaluatedKernelTensor(x1_, x2_, kernel=self, last_dim_is_batch=last_dim_is_batch, **params)\r\n    401             else:\r\n--> 402                 res = lazify(super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\r\n    403             return res\r\n    404 \r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     28 \r\n     29     def __call__(self, *inputs, **kwargs):\r\n---> 30         outputs = self.forward(*inputs, **kwargs)\r\n     31         if isinstance(outputs, list):\r\n     32             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/kernels/scale_kernel.py in forward(self, x1, x2, last_dim_is_batch, diag, **params)\r\n    101 \r\n    102     def forward(self, x1, x2, last_dim_is_batch=False, diag=False, **params):\r\n--> 103         orig_output = self.base_kernel.forward(x1, x2, diag=diag, last_dim_is_batch=last_dim_is_batch, **params)\r\n    104         outputscales = self.outputscale\r\n    105         if last_dim_is_batch:\r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/kernels/polynomial_kernel.py in forward(self, x1, x2, diag, last_dim_is_batch, **params)\r\n     95 \r\n     96         if x1.dim() == 2 and x2.dim() == 2:\r\n---> 97             return torch.addmm(offset, x1, x2.transpose(-2, -1)).pow(self.power)\r\n     98         else:\r\n     99             return (torch.matmul(x1, x2.transpose(-2, -1)) + offset).pow(self.power)\r\n\r\nRuntimeError: expand(torch.FloatTensor{[2, 1, 1]}, size=[4, 4]): the number of sizes provided (2) must be greater or equal to the number of dimensions in the tensor (3)\r\n```\r\n\r\n## System information\r\n\r\nGPyTorch Version: 1.6.0\r\nPyTorch Version : 1.11.0+cu113\r\nComputer OS: Ubuntu 18.04.6 LTS \r\n\r\n## Additional context\r\nI see in [`polynomial_kernel.py`](https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/kernels/polynomial_kernel.py) this piece of code:\r\n\r\n```python\r\noffset = self.offset.view(*self.batch_shape, 1, 1)\r\n...\r\nif x1.dim() == 2 and x2.dim() == 2:\r\n    return torch.addmm(offset, x1, x2.transpose(-2, -1)).pow(self.power)\r\n```\r\n\r\nSo the tensor `offset` has at least 3 dimensions or more, while `x1` and `x2` have exactly 2 dimensions, but `torch.addmm` will not work with such sizes. I do not know why such construction is needed, because the code from else-part would do the same but without an error.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1964/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1964/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1956", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1956/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1956/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1956/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1956", "id": 1179545211, "node_id": "I_kwDOBZhSr85GTm57", "number": 1956, "title": "[Bug] Multi-Class Classification", "user": {"login": "borishamlin", "id": 94037340, "node_id": "U_kgDOBZrlXA", "avatar_url": "https://avatars.githubusercontent.com/u/94037340?v=4", "gravatar_id": "", "url": "https://api.github.com/users/borishamlin", "html_url": "https://github.com/borishamlin", "followers_url": "https://api.github.com/users/borishamlin/followers", "following_url": "https://api.github.com/users/borishamlin/following{/other_user}", "gists_url": "https://api.github.com/users/borishamlin/gists{/gist_id}", "starred_url": "https://api.github.com/users/borishamlin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/borishamlin/subscriptions", "organizations_url": "https://api.github.com/users/borishamlin/orgs", "repos_url": "https://api.github.com/users/borishamlin/repos", "events_url": "https://api.github.com/users/borishamlin/events{/privacy}", "received_events_url": "https://api.github.com/users/borishamlin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-03-24T13:48:24Z", "updated_at": "2022-10-22T21:53:09Z", "closed_at": "2022-10-22T21:53:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Error when performing simple multi-class classification\r\n\r\nFirst-timer here--- apologies if my report is not standard format!\r\n\r\nI am simply trying to do a vanilla multi-class classification, and from #1423 the advice is simply to follow [this tutorial](https://docs.gpytorch.ai/en/stable/examples/04_Variational_and_Approximate_GPs/SVGP_Multitask_GP_Regression.html), but replace `gpytorch.likelihoods.MultitaskGaussianLikelihood` with `gpytorch.likelihoods.SoftmaxLikelihood`.\r\n\r\nAs a first attempt, I am simply using **two classes** for the label space. I understand that there is technically no need to use softmax in this scenario, but I wanted to make this work for two classes before I increase to three or more. Hence, I have first produced a working example for **not** using softmax:\r\n\r\n## Not Using Softmax\r\n\r\nThe following works fine:\r\n\r\n```python\r\nimport math\r\nimport torch\r\nimport random\r\nimport numpy as np\r\nimport gpytorch as gp\r\n\r\nfrom matplotlib import pyplot as plt\r\n\r\nrandom.seed(0)\r\nnp.random.seed(0)\r\ntorch.manual_seed(0)\r\n\r\nfrom sklearn.datasets import make_moons\r\n\r\nX, y = make_moons(noise = 0.3)\r\nX_train = torch.from_numpy(X).float()\r\ny_train = torch.from_numpy(y).float()\r\n\r\nclass GPClassificationModel(gp.models.ApproximateGP):\r\n    def __init__(self, X_train):\r\n        variational_distribution = gp.variational.CholeskyVariationalDistribution(\r\n            X_train.size(0)\r\n        )\r\n        variational_strategy = gp.variational.VariationalStrategy(\r\n            self, X_train, variational_distribution, learn_inducing_locations = True\r\n        )\r\n\r\n        super(GPClassificationModel, self).__init__(variational_strategy)\r\n\r\n        self.mean_module = gp.means.ConstantMean()\r\n        self.covar_module = gp.kernels.ScaleKernel(gp.kernels.RBFKernel())\r\n\r\n    def forward(self, X):\r\n        mean_X = self.mean_module(X)\r\n        covar_X = self.covar_module(X)\r\n\r\n        return gp.distributions.MultivariateNormal(mean_X, covar_X)\r\n\r\nlikelihood = gp.likelihoods.BernoulliLikelihood()\r\nmodel = GPClassificationModel(X_train)\r\n\r\nlikelihood.train()\r\nmodel.train()\r\n\r\ntrain_iter = 50\r\n\r\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\r\n\r\nmarginal_log_likelihood = gp.mlls.VariationalELBO(likelihood, model, y_train.numel())\r\n\r\nfor i in range(train_iter):\r\n    optimizer.zero_grad()\r\n\r\n    f_post = model(X_train)\r\n    loss = - marginal_log_likelihood(f_post, y_train)\r\n    loss.backward()\r\n\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, train_iter, loss.item()))\r\n    optimizer.step()\r\n```\r\n\r\nThen I can plot the result:\r\n\r\n```python\r\nlikelihood.eval()\r\nmodel.eval()\r\n\r\nh = 0.05\r\nx1_min, x1_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\r\nx2_min, x2_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\r\nxx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, h), np.arange(x2_min, x2_max, h))\r\n\r\nwith torch.no_grad():\r\n    X_test = torch.from_numpy(np.vstack((xx1.reshape(-1), xx2.reshape(-1))).T).float()\r\n    f_pred = model(X_test)\r\n    y_pred = likelihood(f_pred)\r\n\r\nwith torch.no_grad():\r\n    fg, ax = plt.subplots(1, 1, figsize = (4, 3))\r\n\r\n    ax.contourf(xx1, xx2, y_pred.mean.numpy().reshape(xx1.shape), levels = 16)\r\n    ax.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1])\r\n    ax.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1])\r\n\r\n    plt.show()\r\n```\r\n\r\n![Figure_1](https://user-images.githubusercontent.com/94037340/159929778-d579b4d1-2e72-4017-8cef-283907ed4074.png)\r\n\r\n## Using Softmax\r\n\r\nNext, now I want to use softmax, but basically obtain the same result. (If this works, then I can easily generalize to three or more classes). However, the following does not work, even though I follow exactly the instructions given in #1423:\r\n\r\n```python\r\nimport math\r\nimport torch\r\nimport random\r\nimport numpy as np\r\nimport gpytorch as gp\r\n\r\nfrom matplotlib import pyplot as plt\r\n\r\nrandom.seed(0)\r\nnp.random.seed(0)\r\ntorch.manual_seed(0)\r\n\r\nfrom sklearn.datasets import make_moons\r\n\r\nX, y = make_moons(noise = 0.3)\r\nX_train = torch.from_numpy(X).float()\r\none_hot = np.zeros((len(y), y.max() + 1))\r\none_hot[np.arange(len(y)), y] = 1\r\ny_train = torch.from_numpy(one_hot).float()\r\n\r\nnum_classes = 2\r\nnum_latents = 3\r\n\r\nclass GPClassificationModel(gp.models.ApproximateGP):\r\n    def __init__(self):\r\n        inducing_points = torch.rand(num_latents, 16, 2)\r\n\r\n        variational_distribution = gp.variational.CholeskyVariationalDistribution(\r\n            inducing_points.size(-2), batch_shape = torch.Size([num_latents])\r\n        )\r\n        variational_strategy = gp.variational.LMCVariationalStrategy(\r\n            gp.variational.VariationalStrategy(\r\n                self, inducing_points, variational_distribution, learn_inducing_locations = True\r\n            ),\r\n            num_tasks = num_classes,\r\n            num_latents = num_latents,\r\n            latent_dim = -1\r\n        )\r\n\r\n        super(GPClassificationModel, self).__init__(variational_strategy)\r\n\r\n        self.mean_module = gp.means.ConstantMean(\r\n            batch_shape = torch.Size([num_latents])\r\n        )\r\n        self.covar_module = gp.kernels.ScaleKernel(\r\n            gp.kernels.RBFKernel(batch_shape = torch.Size([num_latents])),\r\n            batch_shape = torch.Size([num_latents])\r\n        )\r\n\r\n    def forward(self, X):\r\n        mean_X = self.mean_module(X)\r\n        covar_X = self.covar_module(X)\r\n\r\n        return gp.distributions.MultivariateNormal(mean_X, covar_X)\r\n\r\nlikelihood = gp.likelihoods.SoftmaxLikelihood(num_classes = num_classes, mixing_weights = False)\r\nmodel = GPClassificationModel()\r\n\r\nlikelihood.train()\r\nmodel.train()\r\n\r\ntrain_iter = 50\r\n\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},\r\n    {'params': likelihood.parameters()},\r\n], lr = 0.1)\r\n\r\nmarginal_log_likelihood = gp.mlls.VariationalELBO(likelihood, model, y_train.size(0))\r\n\r\nfor i in range(train_iter):\r\n    optimizer.zero_grad()\r\n\r\n    f_post = model(X_train)\r\n    loss = - marginal_log_likelihood(f_post, y_train)\r\n    loss.backward()\r\n\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, train_iter, loss.item()))\r\n    optimizer.step()\r\n```\r\n\r\nThis gives the following stack trace/error message:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"gps.py\", line 75, in <module>\r\n    loss = - marginal_log_likelihood(f_post, y_train)\r\n  File \"~/miniconda/envs/supp/lib/python3.8/site-packages/gpytorch/module.py\", line 30, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"~/miniconda/envs/supp/lib/python3.8/site-packages/gpytorch/mlls/variational_elbo.py\", line 77, in forward\r\n    return super().forward(variational_dist_f, target, **kwargs)\r\n  File \"~/miniconda/envs/supp/lib/python3.8/site-packages/gpytorch/mlls/_approximate_mll.py\", line 57, in forward\r\n    log_likelihood = self._log_likelihood_term(approximate_dist_f, target, **kwargs).div(num_batch)\r\n  File \"~/miniconda/envs/supp/lib/python3.8/site-packages/gpytorch/mlls/variational_elbo.py\", line 61, in _log_likelihood_term\r\n    return self.likelihood.expected_log_prob(target, variational_dist_f, **kwargs).sum(-1)\r\n  File \"~/miniconda/envs/supp/lib/python3.8/site-packages/gpytorch/likelihoods/likelihood.py\", line 39, in expected_log_prob\r\n    res = likelihood_samples.log_prob(observations).mean(dim=0)\r\n  File \"~/miniconda/envs/supp/lib/python3.8/site-packages/torch/distributions/categorical.py\", line 117, in log_prob\r\n    self._validate_sample(value)\r\n  File \"~/miniconda/envs/supp/lib/python3.8/site-packages/torch/distributions/distribution.py\", line 274, in _validate_sample\r\n    raise ValueError('Value is not broadcastable with batch_shape+event_shape: {} vs {}.'.\r\nValueError: Value is not broadcastable with batch_shape+event_shape: torch.Size([100, 2]) vs torch.Size([10, 100]).\r\n```\r\n\r\n## System Information\r\n\r\n```\r\nblas                      1.0                         mkl\r\nbrotli                    1.0.9                h0d85af4_6    conda-forge\r\nbrotli-bin                1.0.9                h0d85af4_6    conda-forge\r\nbrotlipy                  0.7.0           py38h9ed2024_1003\r\nbzip2                     1.0.8                h1de35cc_0\r\nca-certificates           2021.10.8            h033912b_0    conda-forge\r\ncertifi                   2021.10.8        py38h50d1736_1    conda-forge\r\ncffi                      1.15.0           py38hc55c11b_1\r\ncharset-normalizer        2.0.4              pyhd3eb1b0_0\r\ncryptography              36.0.0           py38hf6deb26_0\r\ncycler                    0.11.0             pyhd8ed1ab_0    conda-forge\r\nffmpeg                    4.3                  h0a44026_0    pytorch\r\nfonttools                 4.31.2           py38hed1de0f_0    conda-forge\r\nfreetype                  2.11.0               hd8bbffd_0\r\ngettext                   0.21.0               h7535e17_0\r\ngiflib                    5.2.1                haf1e3a3_0\r\ngmp                       6.2.1                h23ab428_2\r\ngnutls                    3.6.15               hed9c0bf_0\r\ngpytorch                  1.6.0                         0    gpytorch\r\nicu                       58.2                 h0a44026_3\r\nidna                      3.3                pyhd3eb1b0_0\r\nintel-openmp              2021.4.0          hecd8cb5_3538\r\njoblib                    1.1.0              pyhd3eb1b0_0\r\njpeg                      9d                   h9ed2024_0\r\nkiwisolver                1.3.2            py38he9d5cce_0\r\nlame                      3.100                h1de35cc_0\r\nlcms2                     2.12                 hf1fd2bf_0\r\nlibbrotlicommon           1.0.9                h0d85af4_6    conda-forge\r\nlibbrotlidec              1.0.9                h0d85af4_6    conda-forge\r\nlibbrotlienc              1.0.9                h0d85af4_6    conda-forge\r\nlibcxx                    12.0.0               h2f01273_0\r\nlibffi                    3.3                  hb1e8313_2\r\nlibgfortran               3.0.1                h93005f0_2\r\nlibiconv                  1.16                 h1de35cc_0\r\nlibidn2                   2.3.2                h9ed2024_0\r\nlibpng                    1.6.37               ha441bb4_0\r\nlibtasn1                  4.16.0               h9ed2024_0\r\nlibtiff                   4.2.0                h87d7836_0\r\nlibunistring              0.9.10               h9ed2024_0\r\nlibuv                     1.40.0               haf1e3a3_0\r\nlibwebp                   1.2.2                h56c3ce4_0\r\nlibwebp-base              1.2.2                hca72f7f_0\r\nlibxml2                   2.9.12               hcdb78fc_0\r\nllvm-openmp               12.0.0               h0dcd299_1\r\nlz4-c                     1.9.3                h23ab428_1\r\nmatplotlib                3.5.1            py38h50d1736_0    conda-forge\r\nmatplotlib-base           3.5.1            py38hc7d2367_0    conda-forge\r\nmkl                       2021.4.0           hecd8cb5_637\r\nmkl-service               2.4.0            py38h9ed2024_0\r\nmkl_fft                   1.3.1            py38h4ab4a9b_0\r\nmkl_random                1.2.2            py38hb2f4e1b_0\r\nmunkres                   1.1.4              pyh9f0ad1d_0    conda-forge\r\nncurses                   6.3                  hca72f7f_2\r\nnettle                    3.7.3                h230ac6f_1\r\nnumpy                     1.21.2           py38h4b4dc7a_0\r\nnumpy-base                1.21.2           py38he0bd621_0\r\nopenh264                  2.1.1                h8346a28_0\r\nopenssl                   1.1.1l               h0d85af4_0    conda-forge\r\npackaging                 21.3               pyhd8ed1ab_0    conda-forge\r\npillow                    9.0.1            py38hde71d04_0\r\npip                       21.2.4           py38hecd8cb5_0\r\npycparser                 2.21               pyhd3eb1b0_0\r\npyopenssl                 22.0.0             pyhd3eb1b0_0\r\npyparsing                 3.0.7              pyhd8ed1ab_0    conda-forge\r\npysocks                   1.7.1                    py38_1\r\npython                    3.8.12               h88f2d9e_0\r\npython-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\r\npython_abi                3.8                      2_cp38    conda-forge\r\npytorch                   1.11.0                  py3.8_0    pytorch\r\nreadline                  8.1.2                hca72f7f_1\r\nrequests                  2.27.1             pyhd3eb1b0_0\r\nscikit-learn              1.0.2            py38hae1ba45_1\r\nscipy                     1.7.3            py38h8c7af03_0\r\nsetuptools                58.0.4           py38hecd8cb5_0\r\nsix                       1.16.0             pyhd3eb1b0_1\r\nsqlite                    3.37.2               h707629a_0\r\nthreadpoolctl             2.2.0              pyh0d69192_0\r\ntk                        8.6.11               h7bc2e8c_0\r\ntorchaudio                0.11.0                 py38_cpu    pytorch\r\ntorchvision               0.12.0                 py38_cpu    pytorch\r\ntornado                   6.1              py38h96a0964_2    conda-forge\r\ntyping_extensions         4.1.1              pyh06a4308_0\r\nunicodedata2              14.0.0           py38h96a0964_0    conda-forge\r\nurllib3                   1.26.8             pyhd3eb1b0_0\r\nwheel                     0.37.1             pyhd3eb1b0_0\r\nxz                        5.2.5                h1de35cc_0\r\nzlib                      1.2.11               h4dc903c_4\r\nzstd                      1.4.9                h322a384_0\r\n```\r\n\r\n## Context\r\n\r\nI am simply trying to do the most basic task: Classification with GPs. Sorry if my question is silly, but I have tried to investigate myself for a while, and cannot figure out what is the issue!\r\n\r\nThank you so much!!!\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1956/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1956/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1955", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1955/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1955/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1955/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1955", "id": 1178190029, "node_id": "I_kwDOBZhSr85GOcDN", "number": 1955, "title": "[Bug] BetaLikelihood behaviour is inconsistent with the other _OneDimensionalLikelihood subclasses.", "user": {"login": "wbeardall", "id": 37509266, "node_id": "MDQ6VXNlcjM3NTA5MjY2", "avatar_url": "https://avatars.githubusercontent.com/u/37509266?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wbeardall", "html_url": "https://github.com/wbeardall", "followers_url": "https://api.github.com/users/wbeardall/followers", "following_url": "https://api.github.com/users/wbeardall/following{/other_user}", "gists_url": "https://api.github.com/users/wbeardall/gists{/gist_id}", "starred_url": "https://api.github.com/users/wbeardall/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wbeardall/subscriptions", "organizations_url": "https://api.github.com/users/wbeardall/orgs", "repos_url": "https://api.github.com/users/wbeardall/repos", "events_url": "https://api.github.com/users/wbeardall/events{/privacy}", "received_events_url": "https://api.github.com/users/wbeardall/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2022-03-23T14:18:36Z", "updated_at": "2023-03-08T20:09:27Z", "closed_at": "2023-03-08T20:09:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\ngpytorch.likelihoods.BetaLikelihood returns incorrect distributions when called. Instead of returning a Beta distribution of the same shape as the input distribution, it returns a Beta with size [gpytorch.settings.num_likelihood_samples.value(), input_shape]\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\ndata_size=50\r\n\r\nf = gpytorch.distributions.MultivariateNormal(torch.rand(data_size),\r\n                                              torch.eye(data_size))\r\n\r\nprint(f.shape())\r\n\r\nlikelihood = gpytorch.likelihoods.BetaLikelihood()\r\n\r\ny = likelihood(f)\r\n\r\nprint(y.shape())\r\n\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\ntorch.Size([50])\r\ntorch.Size([10, 50])\r\n```\r\n\r\n## Expected Behavior\r\n\r\nWe should expect the return shape to match the input shape, as it is for the other subclasses of _OneDimensionalLikelihood.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGPyTorch v.1.6.0\r\nTorch v.1.10.0\r\nOS Ubuntu 20.04\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1955/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1955/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1925", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1925/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1925/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1925/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1925", "id": 1157278967, "node_id": "I_kwDOBZhSr85E-qz3", "number": 1925, "title": "Can't Modify a LazyEvaluatedKernelTensor for a MultiOutput GP", "user": {"login": "s-a-barnett", "id": 29710882, "node_id": "MDQ6VXNlcjI5NzEwODgy", "avatar_url": "https://avatars.githubusercontent.com/u/29710882?v=4", "gravatar_id": "", "url": "https://api.github.com/users/s-a-barnett", "html_url": "https://github.com/s-a-barnett", "followers_url": "https://api.github.com/users/s-a-barnett/followers", "following_url": "https://api.github.com/users/s-a-barnett/following{/other_user}", "gists_url": "https://api.github.com/users/s-a-barnett/gists{/gist_id}", "starred_url": "https://api.github.com/users/s-a-barnett/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/s-a-barnett/subscriptions", "organizations_url": "https://api.github.com/users/s-a-barnett/orgs", "repos_url": "https://api.github.com/users/s-a-barnett/repos", "events_url": "https://api.github.com/users/s-a-barnett/events{/privacy}", "received_events_url": "https://api.github.com/users/s-a-barnett/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-03-02T14:35:06Z", "updated_at": "2022-03-22T17:16:36Z", "closed_at": "2022-03-22T17:16:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "I would like to implement the [semi-parametric latent factor model](http://proceedings.mlr.press/r5/teh05a/teh05a.pdf) in gpytorch to express a high-dimensional multi-output GP as a linear mixture of a smaller number of GPs. To achieve this within gpytorch, I believe the best approach would be to define a linear model, and then use it to make modifications to the mean and covariance of the GP model within its `forward()` method. \r\n\r\nFor the covariance matrix, this requires a `tensordot` operation not available for the `LazyEvaluatedKernelTensor` class, and so I plan to change the matrix to a regular PyTorch tensor, make the modifications, and then change it back to a LazyTensor. However, I run into a bug when this model is run in `eval` mode:\r\n\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\n\r\ntrain_x = torch.linspace(0, 1, 100)\r\n\r\ntrain_y = torch.stack([\r\n    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n    torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n], -1)\r\n\r\nclass BatchIndependentMultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super().__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([2]))\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([2])),\r\n            batch_shape=torch.Size([2])\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        covar_x = covar_x.evaluate() # added line\r\n        # --- TENSORDOT OPERATION WOULD GO HERE ---\r\n        covar_x = gpytorch.lazify(covar_x) # added line\r\n        return gpytorch.distributions.MultitaskMultivariateNormal.from_batch_mvn(\r\n            gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n        )\r\n\r\n\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\r\nmodel = BatchIndependentMultitaskGPModel(train_x, train_y, likelihood)\r\n\r\n# Set into eval mode\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\n# Make predictions\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    test_x = torch.linspace(0, 1, 51)\r\n    predictions = likelihood(model(test_x))\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nRuntimeError: BlockInterleavedLazyTensor.__getitem__ failed! Expected a final shape of size torch.Size([102, 302]), got torch.Size([0, 0]). This is a bug with GPyTorch, or your custom LazyTensor.\r\n```\r\n\r\nThe output from this example should be equivalent to one in which the additions to the `forward` method have been removed. \r\n\r\nThis example comes from a Colab notebook with gpytorch version 1.6.0 and PyTorch version 1.10.0+cu111.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1925/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1925/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1919", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1919/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1919/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1919/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1919", "id": 1141580872, "node_id": "PR_kwDOBZhSr84zAMMF", "number": 1919, "title": "Fix bug with PeriodicKernel.diag()", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-02-17T16:40:41Z", "updated_at": "2022-04-10T15:59:21Z", "closed_at": "2022-04-10T15:59:18Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1919", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1919", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1919.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1919.patch", "merged_at": "2022-04-10T15:59:18Z"}, "body": "- Refactor PerodicKernel + docs\r\n- Improve tests\r\n\r\n[Fixes #1915]\r\n[Fixes #1926]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1919/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 1, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1919/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1916", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1916/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1916/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1916/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1916", "id": 1139614338, "node_id": "I_kwDOBZhSr85D7SKC", "number": 1916, "title": "[Bug] forward() missing input during inference, with a hybrid GP-MLP model", "user": {"login": "gsimchoni", "id": 9554580, "node_id": "MDQ6VXNlcjk1NTQ1ODA=", "avatar_url": "https://avatars.githubusercontent.com/u/9554580?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gsimchoni", "html_url": "https://github.com/gsimchoni", "followers_url": "https://api.github.com/users/gsimchoni/followers", "following_url": "https://api.github.com/users/gsimchoni/following{/other_user}", "gists_url": "https://api.github.com/users/gsimchoni/gists{/gist_id}", "starred_url": "https://api.github.com/users/gsimchoni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gsimchoni/subscriptions", "organizations_url": "https://api.github.com/users/gsimchoni/orgs", "repos_url": "https://api.github.com/users/gsimchoni/repos", "events_url": "https://api.github.com/users/gsimchoni/events{/privacy}", "received_events_url": "https://api.github.com/users/gsimchoni/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2022-02-16T06:58:34Z", "updated_at": "2022-03-28T18:33:38Z", "closed_at": "2022-03-28T18:33:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n\r\nI am training a multiple-input model, so-called hybrid, that should handle this hybrid model:\r\n\r\n$y = f(X) + \\eta(D) +\\varepsilon$\r\n\r\nwhere f() is some non-linear function of X (n X p), eta() is a GP(0, K) where K is a standard RBF kernel on 2D grid of locations D (n X 2), and varepsilon is a standard N(0, sig2e) noise. So y marginally is a GP(f(X), K):\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nfrom scipy.spatial.distance import pdist, squareform\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nimport torch\r\nimport gpytorch\r\nimport tqdm\r\n\r\np = 10\r\nN = 10000\r\nsig2e = 1.0\r\nlengthscale = 1\r\nq = 1000\r\nn_per_cat = 30\r\n\r\nX = np.random.uniform(-1, 1, N * p).reshape((N, p))\r\nbetas = np.ones(p)\r\nXbeta = 1.0 + X @ betas\r\nfX = Xbeta * np.cos(Xbeta) + 2 * X[:, 0] * X[:, 1]\r\ne = np.random.normal(0, np.sqrt(sig2e), N)\r\n\r\ncoords = np.stack([np.random.uniform(-10, 10, q), np.random.uniform(-10, 10, q)], axis=1)\r\ndist_matrix = squareform(pdist(coords)) ** 2\r\nD = np.exp(-dist_matrix / (2 * lengthscale))\r\nb = np.random.multivariate_normal(np.zeros(q), D, 1)[0]\r\nfs = np.random.poisson(n_per_cat, q) + 1\r\nfs_sum = fs.sum()\r\nps = fs/fs_sum\r\nns = np.random.multinomial(N, ps)\r\nZ_idx = np.repeat(range(q), ns)\r\ngZb = np.repeat(b, ns)\r\n\r\ny = fX + gZb + e\r\n\r\nx_cols = ['X' + str(i) for i in range(p)]\r\nx_cols.extend(['D1', 'D2'])\r\ndf = pd.concat([pd.DataFrame(X), pd.DataFrame(coords[Z_idx])], axis=1)\r\ndf.columns = x_cols\r\ndf['y'] = y\r\n\r\nX_train, X_test, y_train, y_test = train_test_split(df.drop('y', axis=1), df['y'], test_size=0.2)\r\n```\r\n\r\nSo my model has two inputs: perform a standard MLP on the `p = 10` X features input (`X0`, ..., `X9`), a standard GP with a RBF kernel on the 2-D \"locations\" features input (`D1`, `D2`), sum those and train via marginal log-likelihood:\r\n\r\n```python\r\nx_cols_mlp = X_train.columns[X_train.columns.str.startswith('X')]\r\nx_cols_gp = X_train.columns[X_train.columns.str.startswith('D')]\r\n\r\ntrain_x_mlp = torch.Tensor(X_train[x_cols_mlp].values)\r\ntrain_x_gp = torch.Tensor(X_train[x_cols_gp].values)\r\ntrain_y = torch.Tensor(y_train.values)\r\ntest_x_mlp = torch.Tensor(X_test[x_cols_mlp].values)\r\ntest_x_gp = torch.Tensor(X_test[x_cols_gp].values)\r\ntest_y = torch.Tensor(y_test.values)\r\n\r\nif torch.cuda.is_available():\r\n    train_x_mlp, train_x_gp, train_y, test_x_mlp, test_x_gp, test_y = train_x_mlp.cuda(), train_x_gp.cuda(), train_y.cuda(), test_x_mlp.cuda(), test_x_gp.cuda(), test_y.cuda()\r\n\r\nclass GPMLPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x_gp, train_y, likelihood, mlp):\r\n        super(GPMLPModel, self).__init__(train_x_gp, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.GridInterpolationKernel(\r\n            gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()),\r\n            num_dims=2, grid_size=100\r\n        )\r\n        self.mlp = mlp\r\n\r\n    def forward(self, x_gp, x_mlp):\r\n        projected_x = self.mlp(x_mlp)\r\n        mean_x = self.mean_module(x_gp) + projected_x.view(1, -1) #notice the mlp input and GP input are summed in the mean\r\n        covar_x = self.covar_module(x_gp)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nclass MLP(torch.nn.Module):\r\n    def __init__(self):\r\n        super(MLP, self).__init__()\r\n        self.nn = torch.nn.Sequential(\r\n            torch.nn.Linear(p, 100),\r\n            torch.nn.ReLU(),\r\n            torch.nn.Dropout(0.25),\r\n            torch.nn.Linear(100, 50),\r\n            torch.nn.ReLU(),\r\n            torch.nn.Dropout(0.25),\r\n            torch.nn.Linear(50, 25),\r\n            torch.nn.ReLU(),\r\n            torch.nn.Dropout(0.25),\r\n            torch.nn.Linear(25, 12),\r\n            torch.nn.ReLU(),\r\n            torch.nn.Linear(12, 1)\r\n        )\r\n\r\n    def forward(self, x):\r\n        logits = self.nn(x)\r\n        return logits\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = GPMLPModel(train_x_gp, train_y, likelihood, MLP())\r\n\r\nif torch.cuda.is_available():\r\n    model = model.cuda()\r\n    likelihood = likelihood.cuda()\r\n```\r\n\r\nAll goes well during training:\r\n\r\n```python\r\nepochs = 100\r\nmodel.train()\r\nlikelihood.train()\r\n\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.mlp.parameters()},\r\n    {'params': model.covar_module.base_kernel.parameters()},\r\n    {'params': model.mean_module.parameters()},\r\n    {'params': likelihood.parameters()},\r\n], lr=0.01)\r\n\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ndef train():\r\n    iterator = tqdm.notebook.tqdm(range(epochs))\r\n    train_loss = []\r\n    for i in iterator:\r\n        optimizer.zero_grad()\r\n        output = model(train_x_gp, train_x_mlp) # notice the two inputs entering here\r\n        loss = -mll(output, train_y)\r\n        loss.backward()\r\n        iterator.set_postfix(loss=loss.item())\r\n        train_loss.append(loss.item())\r\n        optimizer.step()\r\n    return output, train_loss\r\n        \r\n%time train_out, train_loss = train()\r\n```\r\nI can see the MLL loss decreasing nicely:\r\n\r\n```python\r\nplt.plot(np.arange(epochs), train_loss)\r\nplt.show()\r\n```\r\n![image](https://user-images.githubusercontent.com/9554580/154210802-c626d2da-e063-40a5-a22e-06ec00317ae1.png)\r\n\r\nAnd I can see a reasonable fit on training data, a reasonable MSE, a reasonable likelihood noise:\r\n\r\n```python\r\npred_y_train = train_out.loc.view(-1,1)\r\nplt.scatter(train_y, pred_y_train.detach().numpy())\r\nplt.show()\r\nprint('Train MSE: {}'.format(torch.mean(torch.square(pred_y_train.flatten() - train_y))))\r\nprint(f'Actual noise value: {likelihood.noise}')\r\n```\r\n![image](https://user-images.githubusercontent.com/9554580/154210938-61559ef3-11db-4380-8393-ea97ec4a3139.png)\r\n\r\nBut when it comes to inference on the testing data...\r\n\r\n```python\r\nmodel.eval()\r\nlikelihood.eval()\r\nwith torch.no_grad(), gpytorch.settings.use_toeplitz(False), gpytorch.settings.fast_pred_var():\r\n    out_test = model(test_x_gp, test_x_mlp)\r\n```\r\nSee stack trace. Apparently GPytorch is going straight to the `ExactGP` constructor with only the first input, and `forward()` is missing the second input. If not a bug is there any way to circumvent this?\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n[<ipython-input-27-08f4c5bb5b1e>](https://localhost:8080/#) in <module>()\r\n      2 likelihood.eval()\r\n      3 with torch.no_grad(), gpytorch.settings.use_toeplitz(False), gpytorch.settings.fast_pred_var():\r\n----> 4     out_test = model(test_x_gp, test_x_mlp)\r\n\r\n1 frames\r\n[/usr/local/lib/python3.7/dist-packages/gpytorch/models/exact_gp.py](https://localhost:8080/#) in __call__(self, *args, **kwargs)\r\n    278             # Get the terms that only depend on training data\r\n    279             if self.prediction_strategy is None:\r\n--> 280                 train_output = super().__call__(*train_inputs, **kwargs)\r\n    281 \r\n    282                 # Create the prediction strategy for\r\n\r\n[/usr/local/lib/python3.7/dist-packages/gpytorch/module.py](https://localhost:8080/#) in __call__(self, *inputs, **kwargs)\r\n     28 \r\n     29     def __call__(self, *inputs, **kwargs):\r\n---> 30         outputs = self.forward(*inputs, **kwargs)\r\n     31         if isinstance(outputs, list):\r\n     32             return [_validate_module_outputs(output) for output in outputs]\r\n\r\nTypeError: forward() missing 1 required positional argument: 'x_mlp'\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThe `model()` call should work seamlessly on standard testing data. If there's something inherently wrong in the model - it's probably best it shouldn't train at all. But I'd expect any model which is good to compute on training set should be good to predict on testing set.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version `1.6.0`\r\n- PyTorch Version `1.10.0+cu111`\r\n- Linux on Google Colab\r\n\r\n## Additional context\r\nI just want to say how much I appreciate GPytorch and that I apologize if this isn't in fact a bug but something wrong with my code.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1916/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1916/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1915", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1915/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1915/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1915/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1915", "id": 1138695305, "node_id": "I_kwDOBZhSr85D3xyJ", "number": 1915, "title": "[Bug] gpytorch PeriodicKernel, diag() method yields to RuntimeError message", "user": {"login": "LeoL135", "id": 64774109, "node_id": "MDQ6VXNlcjY0Nzc0MTA5", "avatar_url": "https://avatars.githubusercontent.com/u/64774109?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LeoL135", "html_url": "https://github.com/LeoL135", "followers_url": "https://api.github.com/users/LeoL135/followers", "following_url": "https://api.github.com/users/LeoL135/following{/other_user}", "gists_url": "https://api.github.com/users/LeoL135/gists{/gist_id}", "starred_url": "https://api.github.com/users/LeoL135/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LeoL135/subscriptions", "organizations_url": "https://api.github.com/users/LeoL135/orgs", "repos_url": "https://api.github.com/users/LeoL135/repos", "events_url": "https://api.github.com/users/LeoL135/events{/privacy}", "received_events_url": "https://api.github.com/users/LeoL135/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-02-15T13:27:36Z", "updated_at": "2022-04-10T15:59:18Z", "closed_at": "2022-04-10T15:59:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nHello, \r\nI have a problem with the gpytorch Periodickernel.\r\nWhen triying to call the diag() method, it yiels to a runtime error.\r\nThis leads to the problem that no confidence region or predictive variance can be computed later for predictions.\r\nThat happens both for few and large data.\r\nI am not sure if this is a bug or am I doing something wrong here?\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\ncovar_module = gpytorch.kernels.PeriodicKernel()\r\nx1 = torch.randn(50)\r\nlazy_covar_matrix = covar_module(x1) # Returns a RootLazyTensor\r\nlazy_covar_matrix.diag()\r\n\r\n** Stack trace/error message **\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n/tmp/ipykernel_43664/910117771.py in <module>\r\n      3 x1 = torch.randn(50)\r\n      4 lazy_covar_matrix = covar_module(x1) # Returns a RootLazyTensor\r\n----> 5 lazy_covar_matrix.diag()\r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n~/anaconda3/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in diag(self)\r\n    309             expected_shape = self.shape[:-1]\r\n    310             if res.shape != expected_shape:\r\n--> 311                 raise RuntimeError(\r\n    312                     \"The kernel {} is not equipped to handle and diag. Expected size {}. \"\r\n    313                     \"Got size {}\".format(self.kernel.__class__.__name__, expected_shape, res.shape)\r\n\r\nRuntimeError: The kernel PeriodicKernel is not equipped to handle and diag. Expected size torch.Size([50]). Got size torch.Size([50, 50])\r\n\r\n## Expected Behavior\r\n\r\nShould return the diagonal of the kernel.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGPyTorch Version (run `print(gpytorch.__version__)` \r\n1.6.0\r\nPyTorch Version (run `print(torch.__version__)` \r\n1.10.0\r\nComputer OS\r\nWindows 10\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1915/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1915/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1907", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1907/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1907/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1907/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1907", "id": 1125023278, "node_id": "I_kwDOBZhSr85DDn4u", "number": 1907, "title": "[Bug] in  lazy_evaluated_kernel_tensor.py [__call__ vs. forward method]", "user": {"login": "vr308", "id": 17442913, "node_id": "MDQ6VXNlcjE3NDQyOTEz", "avatar_url": "https://avatars.githubusercontent.com/u/17442913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vr308", "html_url": "https://github.com/vr308", "followers_url": "https://api.github.com/users/vr308/followers", "following_url": "https://api.github.com/users/vr308/following{/other_user}", "gists_url": "https://api.github.com/users/vr308/gists{/gist_id}", "starred_url": "https://api.github.com/users/vr308/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vr308/subscriptions", "organizations_url": "https://api.github.com/users/vr308/orgs", "repos_url": "https://api.github.com/users/vr308/repos", "events_url": "https://api.github.com/users/vr308/events{/privacy}", "received_events_url": "https://api.github.com/users/vr308/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-02-05T20:25:43Z", "updated_at": "2022-02-06T03:39:40Z", "closed_at": "2022-02-06T03:39:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nMy custom kernel bumps into this internal Runtime error with a flag that says 'This is likely a bug in GPyTorch.'\r\n\r\n## To reproduce\r\n\r\n```\r\nimport gpytorch \r\nimport gpytorch.priors as priors\r\nimport torch\r\nimport numpy as np\r\nfrom gpytorch.kernels.kernel import Distance\r\nfrom kernels.latent_priors import LatentGpPrior, MatrixVariateNormalPrior\r\n\r\ngpytorch.settings.cholesky_jitter(1e-5)\r\n\r\nclass CustomKernel(gpytorch.kernels.Kernel):\r\n    \r\n    ''' 1d Gibbs product kernel as per eq 4.32 in Rasmussen & Williams'''\r\n\r\n    def __init__(self, x, input_dim):\r\n        super().__init__()\r\n        self.input_dim = input_dim\r\n      \r\n    def compute_square_term_per_dim(self, ls1, ls2):\r\n        \r\n          square_term = (ls1).pow(2).unsqueeze(-2) + (ls2).pow(2).unsqueeze(-3)\r\n          return square_term\r\n\r\n    def compute_prefactor_term_per_dim(self, ls_processes):\r\n        \r\n            ls1 = ls_processes[:,None]\r\n            ls2 = ls_processes[:,None]\r\n            \r\n            square_term = self.compute_square_term_per_dim(ls1, ls2)\r\n            prod_term = 2 * np.outer(ls1, ls2)[:,:,None]\r\n            prefactor = (prod_term / square_term).pow(0.5).prod(dim=-1) \r\n            return prefactor \r\n              \r\n    def compute_prefactor(self, ls_processes):\r\n                    \r\n            prefactor = self.compute_prefactor_term_per_dim(ls_processes)\r\n            return prefactor\r\n             \r\n    def forward(self, x1, x2, diag=False, **params):\r\n        \r\n            self.ls_process = torch.exp(torch.randn(1000))\r\n            self.prefactor_term = self.compute_prefactor(self.ls_process)\r\n    \r\n            ls1 = self.ls_process[:,None]\r\n            ls2 = self.ls_process[:,None]\r\n            \r\n            x1_ = x1[:,None]\r\n            x2_ = x2[:,None]\r\n            diff = (x1_.unsqueeze(-2) - x2_.unsqueeze(-3)).pow(2) ## N x N x D\r\n            square_term = self.compute_square_term_per_dim(ls1, ls2)\r\n            prod_term = 2 * np.outer(ls1, ls2)[:,:,None]\r\n            res = (prod_term / square_term).pow(0.5).prod(dim=-1) * ((-(diff / square_term).sum(dim=-1)).exp_())\r\n            if diag:\r\n                res = res.squeeze(0)\r\n            return res\r\n```\r\n## Testing\r\n```\r\nif __name__ == \"__main__\":\r\n\r\n    import matplotlib.pylab as plt\r\n    \r\n    x = torch.linspace(-10, 10, 1000)\r\n    gpk1 = CustomKernel(x, 1)\r\n    \r\n    K_gibbs = gpk1.forward(x,x) --> works ok, correct shape 1000 x 1000\r\n    K_gibbs = gpk1(x,x).evaluate() --> fails\r\n\r\n```\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"/tmp/ipykernel_74418/1098342891.py\", line 1, in <module>\r\n    gpk1(x,x).evaluate()\r\n\r\n  File \"/home/vr308/anaconda3/lib/python3.8/site-packages/gpytorch/utils/memoize.py\", line 59, in g\r\n    return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n\r\n  File \"/home/vr308/anaconda3/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 299, in evaluate\r\n    return self.evaluate_kernel().evaluate()\r\n\r\n  File \"/home/vr308/anaconda3/lib/python3.8/site-packages/gpytorch/utils/memoize.py\", line 59, in g\r\n    return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n\r\n  File \"/home/vr308/anaconda3/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 290, in evaluate_kernel\r\n    raise RuntimeError(\r\n\r\nRuntimeError: The expected shape of the kernel was torch.Size([1000, 1000]), but got torch.Size([1000, 1000, 1000]). This is likely a bug in GPyTorch.\r\n```\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1907/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1907/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1886", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1886/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1886/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1886/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1886", "id": 1104117889, "node_id": "I_kwDOBZhSr85Bz4CB", "number": 1886, "title": "[Bug] issue to compute SpectralMixtureKernel when tensors are loaded into cuda device", "user": {"login": "ivan-marroquin", "id": 28459534, "node_id": "MDQ6VXNlcjI4NDU5NTM0", "avatar_url": "https://avatars.githubusercontent.com/u/28459534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ivan-marroquin", "html_url": "https://github.com/ivan-marroquin", "followers_url": "https://api.github.com/users/ivan-marroquin/followers", "following_url": "https://api.github.com/users/ivan-marroquin/following{/other_user}", "gists_url": "https://api.github.com/users/ivan-marroquin/gists{/gist_id}", "starred_url": "https://api.github.com/users/ivan-marroquin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ivan-marroquin/subscriptions", "organizations_url": "https://api.github.com/users/ivan-marroquin/orgs", "repos_url": "https://api.github.com/users/ivan-marroquin/repos", "events_url": "https://api.github.com/users/ivan-marroquin/events{/privacy}", "received_events_url": "https://api.github.com/users/ivan-marroquin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-01-14T20:57:54Z", "updated_at": "2022-01-17T15:00:03Z", "closed_at": "2022-01-17T15:00:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\nMany thanks for making available such great package!\r\n\r\nIn order to reproduce this issue, I attached a Python script (see zip file).\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"test_issue.py\", line 58, in <module>\r\n    model= SpectralMixtureGPModel(support_x, support_label, likelihood)\r\n  File \"test_issue.py\", line 24, in __init__\r\n    self.covar_module.initialize_from_data(support_x, support_label)\r\n  File \"C:\\Temp\\Python\\Python3.6.5\\lib\\site-packages\\gpytorch\\kernels\\spectral_mixture_kernel.py\", line 264, in initialize_from_data\r\n    self.mixture_scales = torch.randn_like(self.raw_mixture_scales).mul_(max_dist).abs_().reciprocal_()\r\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThe SpectralMixtureKernel should be able to initialize the covariance from data, when the input tensors are loaded into cuda device\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 1.6.0\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> 1.10.0+cu102\r\n- <!-- Computer OS --> Windows 10\r\n- <!-- Python version --> 3.6.5\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n\r\n[test_issue.zip](https://github.com/cornellius-gp/gpytorch/files/7873166/test_issue.zip)\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1886/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1886/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1885", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1885/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1885/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1885/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1885", "id": 1101931872, "node_id": "I_kwDOBZhSr85BriVg", "number": 1885, "title": "[Bug] Gradient computation with KeOps kernel only works with low number of training data, fails otherwise", "user": {"login": "abdolrezat", "id": 19935130, "node_id": "MDQ6VXNlcjE5OTM1MTMw", "avatar_url": "https://avatars.githubusercontent.com/u/19935130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abdolrezat", "html_url": "https://github.com/abdolrezat", "followers_url": "https://api.github.com/users/abdolrezat/followers", "following_url": "https://api.github.com/users/abdolrezat/following{/other_user}", "gists_url": "https://api.github.com/users/abdolrezat/gists{/gist_id}", "starred_url": "https://api.github.com/users/abdolrezat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abdolrezat/subscriptions", "organizations_url": "https://api.github.com/users/abdolrezat/orgs", "repos_url": "https://api.github.com/users/abdolrezat/repos", "events_url": "https://api.github.com/users/abdolrezat/events{/privacy}", "received_events_url": "https://api.github.com/users/abdolrezat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2022-01-13T15:23:21Z", "updated_at": "2022-02-04T17:16:40Z", "closed_at": "2022-02-04T15:45:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nHi,\r\n\r\nFirst of all, I would like to extend my thanks to all the developers for all the efforts you have put into both the research and this great package. \r\n\r\nConsider a GP with a KeOps kernel (e.g. gpytorch.kernels.keops.RBFKernel). If I train it with N=100 number of points, then the gradient of predictive mean can be obtained by torch.autograd.grad or .backward(), but set N=500 and an error will be thrown that the input tensor was not used in the graph. I have tested the script on two separate machines and a colab instance. Using the GPyTorch standard kernels will not run into this issue. I spent a good deal of time pinpointing what was wrong from bigger chunks of code and this seemed to be the issue. The gradient link seems to cut off between the covariance output of the KeOps kernel and the input (covar.x1).  \r\n\r\nI have provided a minimal code right below that should quickly give you an idea of this somewhat strange behavior. It contains two test cases with N=100 (which passes) and 500 (fails). The code is from GPyTorch regression examples, I have only added the GP kernel and a few lines for calculating gradients at the end. \r\n\r\n## To reproduce\r\n\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nimport time\r\n\r\n# We will use the simplest form of GP model, exact inference with gpytorch.kernels.keops.RBFKernel\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.keops.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\ndef train_and_eval_GP(N = 100):\r\n    \"\"\"\r\n    inputs:\r\n    N (int): Number of training points\r\n    \"\"\"\r\n    # make train/val/test\r\n    # Training data is 100 points in [0,1] inclusive regularly spaced\r\n    train_x = torch.linspace(0, 1, N)\r\n    # True function is sin(2*pi*x) with Gaussian noise\r\n    train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)\r\n    # normalize features\r\n    mean = train_x.mean()\r\n    std = train_x.std() + 1e-6 # prevent dividing by 0\r\n    train_x = (train_x - mean) / std\r\n\r\n    # normalize labels\r\n    mean, std = train_y.mean(),train_y.std()\r\n    train_y = (train_y - mean) / std\r\n\r\n    # make continguous\r\n    train_x, train_y = train_x.contiguous(), train_y.contiguous()\r\n\r\n    output_device = torch.device('cuda:0')\r\n\r\n    train_x, train_y = train_x.to(output_device), train_y.to(output_device)\r\n\r\n    # initialize likelihood and model\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood().to(output_device)\r\n    model = ExactGPModel(train_x, train_y, likelihood).to(output_device)\r\n\r\n    # Find optimal model hyperparameters\r\n    model.train()\r\n    likelihood.train()\r\n\r\n    # Use the adam optimizer\r\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\r\n\r\n    # \"Loss\" for GPs - the marginal log likelihood\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\n    training_iter = 20\r\n    for i in range(training_iter):\r\n        # Zero gradients from previous iteration\r\n        optimizer.zero_grad()\r\n        # Output from model\r\n        output = model(train_x)\r\n        # Calc loss and backprop gradients\r\n        loss = -mll(output, train_y)\r\n        loss.backward()\r\n        optimizer.step()\r\n    print(f'GP model trained.')\r\n\r\n    # Get into evaluation (predictive posterior) mode\r\n    model.eval()\r\n    likelihood.eval()\r\n\r\n    # Test points are regularly spaced along [0,1]\r\n    test_x = torch.linspace(0, 1, 51, requires_grad=True).to(output_device).contiguous()\r\n    \r\n    # Make predictions by feeding model through likelihood\r\n    with gpytorch.settings.fast_pred_var():\r\n        observed_pred = likelihood(model(test_x))\r\n        assert torch.autograd.grad(observed_pred.mean.sum(), test_x, retain_graph=True) is not None\r\n        print('gradient exists:')\r\n        print(torch.autograd.grad(observed_pred.mean.sum(), test_x, retain_graph=True))\r\n\r\nif __name__ == \"__main__\":\r\n    Ns = [100, 500] #test cases\r\n    for n in Ns:\r\n        try:\r\n            print(f'testing with {n} points...')\r\n            train_and_eval_GP(N = n) \r\n            print('success!')\r\n        except Exception as e:\r\n            print('failed.')\r\n            print(e)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\ntesting with 100 points...\r\nGP model trained.\r\ngradient exists:\r\n(tensor([-2.6629e+00, -2.6507e+00, -2.6344e+00, -2.6138e+00, -2.5891e+00,\r\n        ...,\r\n         9.1844e-01], device='cuda:0'),)\r\nsuccess!\r\ntesting with 500 points...\r\nGP model trained.\r\nfailed.\r\nOne of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.\r\n```\r\n\r\n## Expected Behavior\r\n\r\nSetting the kernel to the standard, non-KeOps kernel (gpytorch.kernels.RBFKernel) we get the gradients for the second case, shown below. However, I can't simply use it since I'm working on a larger dataset that will run out of memory if I do so.\r\n\r\n```\r\ntesting with 100 points...\r\nGP model trained.\r\ngradient exists:\r\n(tensor([-2.5885, -2.5870, -2.5819, -2.5732, -2.5609, -2.5449, -2.5254, -2.5022,\r\n        ...,\r\n         0.6977,  0.7880,  0.8762], device='cuda:0'),)\r\nsuccess!\r\ntesting with 500 points...\r\nGP model trained.\r\ngradient exists:\r\n(tensor([-2.4751, -2.4741, -2.4698, -2.4622, -2.4514, -2.4373, -2.4199, -2.3993,\r\n        ...,\r\n         0.4727,  0.5600,  0.6462], device='cuda:0'),)\r\nsuccess!\r\n```\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> GPyTorch 1.6.0\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> PyTorch  1.10.1\r\n- <!-- KeOps Version --> KeOps 1.5\r\n- <!-- Computer OS --> Ubuntu 20.04.3 LTS\r\n\r\n## Additional context\r\nI know that the issue might be unrelated to GPyTorch as this clearly stems from the keops kernel. It is however difficult to track, so I thought I'd report it here. \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1885/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1885/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1884", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1884/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1884/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1884/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1884", "id": 1101101232, "node_id": "I_kwDOBZhSr85BoXiw", "number": 1884, "title": "[Bug] SVGP based model yields negative predictive variances (also seen in some other issue threads)", "user": {"login": "vr308", "id": 17442913, "node_id": "MDQ6VXNlcjE3NDQyOTEz", "avatar_url": "https://avatars.githubusercontent.com/u/17442913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vr308", "html_url": "https://github.com/vr308", "followers_url": "https://api.github.com/users/vr308/followers", "following_url": "https://api.github.com/users/vr308/following{/other_user}", "gists_url": "https://api.github.com/users/vr308/gists{/gist_id}", "starred_url": "https://api.github.com/users/vr308/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vr308/subscriptions", "organizations_url": "https://api.github.com/users/vr308/orgs", "repos_url": "https://api.github.com/users/vr308/repos", "events_url": "https://api.github.com/users/vr308/events{/privacy}", "received_events_url": "https://api.github.com/users/vr308/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-01-13T02:54:42Z", "updated_at": "2022-01-15T17:27:06Z", "closed_at": "2022-01-15T17:27:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI am attaching my code, it is based on SVGP with a small extension where I am additionally learning the variational distribution around the hyperparameters. I'm quite confident that my \"variational extension\" part where I learn q(theta) is correct, I get a reasonable fit but unfortunately a large number of predictive variances are negative **especially around the training data.** (code and plot attached below) \r\n\r\n## To reproduce\r\n\r\n```\r\nimport gpytorch as gpytorch\r\nimport torch as torch\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nfrom math import floor\r\nimport matplotlib.pyplot as plt\r\nfrom gpytorch.models import ApproximateGP\r\nfrom torch.distributions import kl_divergence\r\nfrom gpytorch.variational import CholeskyVariationalDistribution\r\nfrom gpytorch.variational import VariationalStrategy\r\nfrom gpytorch.kernels import ScaleKernel, RBFKernel\r\nfrom gpytorch.means import ZeroMean\r\nfrom gpytorch.priors import NormalPrior\r\nfrom torch.utils.data import TensorDataset, DataLoader\r\nfrom gpytorch.mlls.added_loss_term import AddedLossTerm\r\n\r\ndef func(x):\r\n    return np.sin(x * 3) + 0.3 * np.cos(x * 4 * 3.14) \r\n\r\nclass LogHyperVariationalDist(gpytorch.Module):\r\n    \r\n     def __init__(self, hyper_dim, hyper_prior, n, data_dim):\r\n        super().__init__()\r\n        \r\n        self.hyper_dim = hyper_dim\r\n        self.hyper_prior = hyper_prior\r\n        self.n = n\r\n        self.data_dim = data_dim\r\n\r\n        # Global variational params\r\n        self.q_mu = torch.nn.Parameter(torch.randn(hyper_dim))\r\n        self.q_log_sigma = torch.nn.Parameter(torch.randn(hyper_dim))     \r\n        # This will add the KL divergence KL(q(theta) || p(theta)) to the loss\r\n        self.register_added_loss_term(\"theta_kl\")\r\n\r\n     def forward(self, num_samples):\r\n        # Variational distribution over the hyper variable q(theta)\r\n        q_theta = torch.distributions.Normal(self.q_mu, self.q_log_sigma.exp())\r\n        theta_kl = kl_gaussian_loss_term(q_theta, self.hyper_prior, self.n, self.data_dim)\r\n        self.update_added_loss_term('theta_kl', theta_kl)  # Update the KL term\r\n        return q_theta.rsample(sample_shape=torch.Size([num_samples]))\r\n    \r\nclass kl_gaussian_loss_term(AddedLossTerm):\r\n    \r\n    def __init__(self, q_theta, hyper_prior, n, data_dim):\r\n        self.q_theta = q_theta\r\n        self.p_theta = hyper_prior\r\n        self.n = n\r\n        self.data_dim = data_dim\r\n        \r\n    def loss(self): \r\n        kl_per_latent_dim = kl_divergence(self.q_theta, self.p_theta).sum(axis=0) # vector of size latent_dim\r\n        kl_per_point = kl_per_latent_dim.sum()/self.n # scalar\r\n        # inside the forward method of variational ELBO, \r\n        # the added loss terms are expanded (using add_) to take the same \r\n        # shape as the log_lik term (has shape data_dim)\r\n        # so they can be added together. Hence, we divide by data_dim to avoid \r\n        # overcounting the kl term\r\n        return (kl_per_point/self.data_dim)\r\n```\r\n\r\n\r\n```\r\nclass BayesianStochasticVariationalGP(ApproximateGP):\r\n    \r\n    \"\"\" The sparse GP class for regression with the uncollapsed stochastic bound.\r\n         The parameters of q(u) \\sim N(m, S) are learnt explicitly. \r\n    \"\"\"\r\n      \r\n    def __init__(self, train_x, train_y, likelihood, Z_init): \r\n        \r\n        # Locations Z corresponding to u, they can be randomly initialized or \r\n        # regularly placed.\r\n        self.inducing_inputs = Z_init\r\n        self.num_inducing = len(Z_init)\r\n        self.n = len(train_y)\r\n        self.data_dim = train_x.shape[1]\r\n        # Sparse Variational Formulation\r\n        q_u = CholeskyVariationalDistribution(self.num_inducing) \r\n        q_f = VariationalStrategy(self, self.inducing_inputs, q_u, learn_inducing_locations=True)\r\n        super(BayesianStochasticVariationalGP, self).__init__(q_f)\r\n        \r\n        self.likelihood = likelihood\r\n        self.train_x = train_x\r\n        self.train_y = train_y\r\n       \r\n        self.mean_module = ZeroMean()\r\n        self.covar_module = ScaleKernel(RBFKernel(ard_num_dims=train_x.shape[-1]))\r\n        \r\n        # Hyperparameter variational distribution\r\n        \r\n        hyper_dim = self.data_dim + 2 # lengthscale per dim, sig var and noise var\r\n        hyper_prior_mean = torch.zeros(hyper_dim)\r\n        log_hyper_prior = NormalPrior(hyper_prior_mean, torch.ones_like(hyper_prior_mean)*0.4) ## no correlation between hypers\r\n\r\n        self.log_theta = LogHyperVariationalDist(hyper_dim, log_hyper_prior, self.n, self.data_dim)\r\n        \r\n    def forward(self, x, log_theta=1.0):\r\n        mean_x = self.mean_module(x)\r\n        theta = torch.exp(log_theta)\r\n        self.update_covar_module_at_theta(theta)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n    \r\n    def update_covar_module_at_theta(self, theta):\r\n        self.covar_module.outputscale = theta[0]\r\n        self.covar_module.base_kernel.lengthscale = theta[1:self.data_dim+1]\r\n        self.likelihood.noise_covar.noise = theta[-1]\r\n        return self.covar_module\r\n    \r\n    def sample_variational_log_hyper(self, num_samples):\r\n        \r\n        return self.log_theta(num_samples)\r\n    \r\n    def get_inducing_prior(self):\r\n        \r\n        Kmm = self.covar_module._inducing_mat\r\n        return torch.distributions.MultivariateNormal(ZeroMean(), Kmm)\r\n            \r\n    def train_model(self, optimizer, train_loader, minibatch_size=100, num_epochs=25, combine_terms=True):\r\n        \r\n        self.train()\r\n        self.likelihood.train()\r\n        elbo = gpytorch.mlls.VariationalELBO(self.likelihood, self, num_data=len(self.train_y))\r\n        \r\n        losses = []\r\n        #iterator = trange(1000, leave=True)\r\n        for i in range(num_epochs):\r\n            with tqdm(train_loader, unit=\"batch\", leave=True) as minibatch_iter:\r\n                for x_batch, y_batch in minibatch_iter:\r\n\r\n                    optimizer.zero_grad()\r\n                    log_hyper_sample = self.sample_variational_log_hyper(num_samples=1)\r\n                    output = self(x_batch, log_theta=log_hyper_sample.flatten())\r\n                    loss = -elbo(output, y_batch).sum()\r\n                    \r\n                    if i%100 == 0:\r\n                        minibatch_iter.set_description(f\"Epoch {i}\")\r\n                        minibatch_iter.set_postfix(loss=loss.item())\r\n                        \r\n                        #print(self.log_theta.q_mu.detach())\r\n                        #print('hyper_sample :' + str(log_hyper_sample))\r\n                        #print(self.covar_module.base_kernel.lengthscale)    \r\n                        \r\n                    losses.append(loss.item())\r\n                    loss.backward()\r\n                    optimizer.step()\r\n                    \r\n        return losses\r\n```\r\n### Running part \r\n\r\n```\r\nif __name__ == '__main__':\r\n\r\n    N = 1000  # Number of training observations\r\n\r\n    X = torch.randn(N) * 2 - 1  # X values\r\n    Y = func(X) + 0.2 * torch.randn(N)  # Noisy Y values\r\n    \r\n    #train_index = np.where((X < -2) | (X > 2))\r\n\r\n    #train_x = X[train_index][:,None]\r\n    #train_y = Y[train_index]\r\n\r\n    train_n = int(floor(0.8 * len(X)))\r\n    train_x = X[:train_n][:,None].double()\r\n    train_y = Y[:train_n].contiguous().double()\r\n    \r\n    test_x = X[train_n:][:,None].double()\r\n    test_y = Y[train_n:].contiguous().double()\r\n        \r\n    train_dataset = TensorDataset(train_x, train_y)\r\n    train_loader = DataLoader(train_dataset, batch_size=200, shuffle=True)\r\n    \r\n    test_dataset = TensorDataset(test_x, test_y)\r\n    test_loader = DataLoader(test_dataset, batch_size=200, shuffle=False)\r\n    \r\n    # Initial inducing points\r\n    index_inducing = np.random.randint(0,len(train_x), 25)\r\n    Z_init = train_x[index_inducing].double()\r\n        \r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood().double()\r\n    model = BayesianStochasticVariationalGP(train_x, train_y, likelihood, Z_init)\r\n    \r\n    model = model.double()\r\n    \r\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\r\n    # Train\r\n    losses = model.train_model(optimizer, train_loader, \r\n                              minibatch_size=100, num_epochs=350,  combine_terms=True)\r\n        \r\n    # Test \r\n    test_x = torch.linspace(-8, 8, 1000).double()\r\n    test_y = func(test_x).double()\r\n    \r\n    ####\r\n    log_hyper_samples = model.sample_variational_log_hyper(num_samples=100)\r\n    \r\n# Get predictive distributions by feeding model through likelihood\r\n    \r\n    list_of_y_pred_dists = []\r\n    \r\n    model.eval()\r\n    model.likelihood.eval()\r\n    \r\n    for i in range(len(log_hyper_samples)):\r\n    \r\n        #theta = torch.nn.functional.softplus(log_hyper_samples[i])\r\n    \r\n        #self.update_covar_module_at_theta(theta)\r\n    \r\n        with torch.no_grad():\r\n            list_of_y_pred_dists.append(likelihood(model(test_x, log_theta=log_hyper_samples[i], prior=False)))\r\n            \r\n    \r\n    y_mix_loc = np.array([np.array(dist.loc) for dist in list_of_y_pred_dists])\r\n    y_mix_var = np.array([np.array(dist.covariance_matrix.diag()) for dist in list_of_y_pred_dists])\r\n    \r\n    plt.figure()\r\n    plt.plot(y_mix_var.T)\r\n```\r\nEach line is the predictive variance corresponding to a hyperparameter sample\r\n\r\n![image](https://user-images.githubusercontent.com/17442913/149257208-bf80e71a-5898-4d6c-8aec-786e8e06a5a0.png)\r\n\r\nThe mean fit seems ok though...\r\n\r\n```\r\nplt.figure()\r\nplt.plot(test_x, np.mean(y_mix_loc, axis=0),color='r')\r\nplt.plot(test_x, test_y)\r\n#plt.plot(test_x, np.array(y_mix_loc).T, alpha=0.4, color='b')\r\nplt.plot(train_x, train_y, 'bo')\r\nplt.scatter(model.variational_strategy.inducing_points.detach(), [-2.0]*model.num_inducing, c='g', marker='x', label='Inducing')\r\n\r\n```\r\n![image](https://user-images.githubusercontent.com/17442913/149257262-04a233e3-a513-4d49-8030-1621e6ec048c.png)\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1884/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1884/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1865", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1865/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1865/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1865/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1865", "id": 1083678951, "node_id": "I_kwDOBZhSr85Al6Dn", "number": 1865, "title": "[Bug] The change in one model might change another independent model", "user": {"login": "shichao2023", "id": 66776990, "node_id": "MDQ6VXNlcjY2Nzc2OTkw", "avatar_url": "https://avatars.githubusercontent.com/u/66776990?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shichao2023", "html_url": "https://github.com/shichao2023", "followers_url": "https://api.github.com/users/shichao2023/followers", "following_url": "https://api.github.com/users/shichao2023/following{/other_user}", "gists_url": "https://api.github.com/users/shichao2023/gists{/gist_id}", "starred_url": "https://api.github.com/users/shichao2023/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shichao2023/subscriptions", "organizations_url": "https://api.github.com/users/shichao2023/orgs", "repos_url": "https://api.github.com/users/shichao2023/repos", "events_url": "https://api.github.com/users/shichao2023/events{/privacy}", "received_events_url": "https://api.github.com/users/shichao2023/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-12-17T23:21:22Z", "updated_at": "2021-12-21T01:03:20Z", "closed_at": "2021-12-21T01:02:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\n\r\n** This is the code which has normal behavior **\r\n```python\r\n\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\nfrom gpytorch.means import ConstantMean\r\nfrom gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\r\nfrom gpytorch.distributions import MultivariateNormal\r\nfrom torch.distributions.uniform import Uniform\r\nfrom torch.distributions.normal import Normal\r\n\r\n\r\n\r\nN = 1000\r\nX = Uniform(0.0, 1.0).sample(sample_shape=(N,10))\r\ny = 100 * torch.sin(3*torch.mean(X, dim = 1)) + Normal(0.0, 0.2).sample(sample_shape=(N,))\r\n\r\nX1 = Uniform(0.0, 1.0).sample(sample_shape=(N,10))\r\ny1 = 100 * torch.sin(3*torch.mean(X1, dim = 1)) + Normal(0.0, 0.2).sample(sample_shape=(N,))\r\n\r\n\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = ConstantMean()\r\n        self.base_covar_module = ScaleKernel(RBFKernel())\r\n        self.covar_module = InducingPointKernel(self.base_covar_module, inducing_points=torch.randn(100, 10)\r\n, likelihood=likelihood)\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return MultivariateNormal(mean_x, covar_x)\r\n\r\n    \r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = GPRegressionModel(X, y, likelihood)\r\n\r\nlikelihood1 = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel1 = GPRegressionModel(X, y, likelihood1)\r\n\r\nif torch.cuda.is_available():\r\n    model = model.cuda()\r\n    likelihood = likelihood.cuda()\r\n\r\n    model1 = model1.cuda()\r\n    likelihood1 = likelihood1.cuda()\r\n\r\n\r\n\r\ndef train(model, likelihood, training_iterations = 500):\r\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\r\n\r\n    # \"Loss\" for GPs - the marginal log likelihood\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n    for i in range(training_iterations):\r\n        # Zero backprop gradients\r\n        optimizer.zero_grad()\r\n        # Get output from model\r\n        output = model(X)\r\n        # Calc loss and backprop derivatives\r\n        loss = -mll(output, y)\r\n        loss.backward()\r\n        #print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n        optimizer.step()\r\n        torch.cuda.empty_cache()\r\n\r\n\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\nmodel1.train()\r\nlikelihood1.train()\r\n\r\ntrain(model1, likelihood1, training_iterations = 1)\r\ntrain(model, likelihood, training_iterations = 200)\r\n\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\nmodel1.eval()\r\nlikelihood1.eval()\r\nwith gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\r\n    preds = model(X1)\r\n    preds1 = model1(X1)\r\n\r\nprint('Test model MAE1: {}'.format(torch.mean(torch.abs(preds.mean - y1))))\r\nprint('Test model1 MAE1: {}'.format(torch.mean(torch.abs(preds1.mean - y1))))\r\n\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n\r\ntrain(model, likelihood, training_iterations = 200)\r\n\r\nmodel.eval()\r\nlikelihood.eval()\r\nmodel1.eval()\r\nlikelihood1.eval()\r\n\r\n\r\nwith gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\r\n    preds = model(X1)\r\n    preds1 = model1(X1)\r\nprint('================')\r\nprint('Test model MAE2: {}'.format(torch.mean(torch.abs(preds.mean - y1))))\r\nprint('Test model1 MAE2: {}'.format(torch.mean(torch.abs(preds1.mean - y1))))\r\n\r\n\r\n```\r\n\r\n** The output is **\r\n```\r\nTest model MAE1: 3.1189992427825928\r\nTest model1 MAE1: 25.073593139648438\r\n================\r\nTest model MAE2: 2.32558012008667\r\nTest model1 MAE2: 25.073593139648438\r\n```\r\n** This is the desired output as the Test model1 MAE1 equals to Test model1 MAE2, the training of model will not affect model1 **\r\n\r\n\r\n\r\n** This is the code have abnormal behavior **\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\nfrom gpytorch.means import ConstantMean\r\nfrom gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\r\nfrom gpytorch.distributions import MultivariateNormal\r\nfrom torch.distributions.uniform import Uniform\r\nfrom torch.distributions.normal import Normal\r\n\r\n\r\n\r\nN = 1000\r\nX = Uniform(0.0, 1.0).sample(sample_shape=(N,10))\r\ny = 100 * torch.sin(3*torch.mean(X, dim = 1)) + Normal(0.0, 0.2).sample(sample_shape=(N,))\r\n\r\nX1 = Uniform(0.0, 1.0).sample(sample_shape=(N,10))\r\ny1 = 100 * torch.sin(3*torch.mean(X1, dim = 1)) + Normal(0.0, 0.2).sample(sample_shape=(N,))\r\n\r\n\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = ConstantMean()\r\n        self.base_covar_module = ScaleKernel(RBFKernel())\r\n        self.covar_module = InducingPointKernel(self.base_covar_module, \r\n```\r\n\r\n** This is what we changed **\r\n```python\r\n        #inducing_points=torch.randn(100, 10)\r\n        inducing_points=train_x[:100]\r\n```\r\n\r\n```python\r\n        , likelihood=likelihood)\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return MultivariateNormal(mean_x, covar_x)\r\n\r\n    \r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = GPRegressionModel(X, y, likelihood)\r\n\r\nlikelihood1 = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel1 = GPRegressionModel(X, y, likelihood1)\r\n\r\nif torch.cuda.is_available():\r\n    model = model.cuda()\r\n    likelihood = likelihood.cuda()\r\n\r\n    model1 = model1.cuda()\r\n    likelihood1 = likelihood1.cuda()\r\n\r\n\r\n\r\ndef train(model, likelihood, training_iterations = 500):\r\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\r\n\r\n    # \"Loss\" for GPs - the marginal log likelihood\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n    for i in range(training_iterations):\r\n        # Zero backprop gradients\r\n        optimizer.zero_grad()\r\n        # Get output from model\r\n        output = model(X)\r\n        # Calc loss and backprop derivatives\r\n        loss = -mll(output, y)\r\n        loss.backward()\r\n        #print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n        optimizer.step()\r\n        torch.cuda.empty_cache()\r\n\r\n\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\nmodel1.train()\r\nlikelihood1.train()\r\n\r\ntrain(model1, likelihood1, training_iterations = 1)\r\ntrain(model, likelihood, training_iterations = 200)\r\n\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\nmodel1.eval()\r\nlikelihood1.eval()\r\nwith gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\r\n    preds = model(X1)\r\n    preds1 = model1(X1)\r\n\r\nprint('Test model MAE1: {}'.format(torch.mean(torch.abs(preds.mean - y1))))\r\nprint('Test model1 MAE1: {}'.format(torch.mean(torch.abs(preds1.mean - y1))))\r\n\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n\r\ntrain(model, likelihood, training_iterations = 200)\r\n\r\nmodel.eval()\r\nlikelihood.eval()\r\nmodel1.eval()\r\nlikelihood1.eval()\r\n\r\n\r\nwith gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\r\n    preds = model(X1)\r\n    preds1 = model1(X1)\r\nprint('================')\r\nprint('Test model MAE2: {}'.format(torch.mean(torch.abs(preds.mean - y1))))\r\nprint('Test model1 MAE2: {}'.format(torch.mean(torch.abs(preds1.mean - y1))))\r\n\r\n```\r\n\r\n**The abnormal output, notice that we have done nothing for model1, but Test model1 MAE1 changed.**\r\n```\r\nTest model MAE1: 3.0421714782714844\r\nTest model1 MAE1: 8.197845458984375\r\n================\r\nTest model MAE2: 3.6370463371276855\r\nTest model1 MAE2: 95.91376495361328\r\n```\r\n\r\n\r\n\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version  1.1.1\r\n\r\n- PyTorch Version 1.10.1+cpu\r\n- \r\n- Computer OS Win10\r\n\r\n## Additional context\r\nDo you know why this happens? \r\nBesides, I am trying to implement the Q learning by using GP to estimate the Q function, and it requires a multi-dimensional output for GP.  I planed to use n GP models for n-dimensional output, but is there any simpler way to do that? Thanks!\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1865/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1865/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1854", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1854/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1854/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1854/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1854", "id": 1073510815, "node_id": "I_kwDOBZhSr84__Hmf", "number": 1854, "title": "[Bug] remove your test folder from pkg", "user": {"login": "ngam", "id": 67342040, "node_id": "MDQ6VXNlcjY3MzQyMDQw", "avatar_url": "https://avatars.githubusercontent.com/u/67342040?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngam", "html_url": "https://github.com/ngam", "followers_url": "https://api.github.com/users/ngam/followers", "following_url": "https://api.github.com/users/ngam/following{/other_user}", "gists_url": "https://api.github.com/users/ngam/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngam/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngam/subscriptions", "organizations_url": "https://api.github.com/users/ngam/orgs", "repos_url": "https://api.github.com/users/ngam/repos", "events_url": "https://api.github.com/users/ngam/events{/privacy}", "received_events_url": "https://api.github.com/users/ngam/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-12-07T15:51:34Z", "updated_at": "2021-12-08T13:16:53Z", "closed_at": "2021-12-08T13:16:52Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\n\r\nsee this issue for reference: https://github.com/conda-forge/botorch-feedstock/issues/9\r\n\r\n** Code snippet to reproduce **\r\n```\r\nconda install botorch gpytorch\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n// Paste the bad output here!\r\nClobberWarning: This transaction has incompatible packages due to a shared path.\r\n  packages: conda-forge/noarch::gpytorch-1.5.1-pyhd8ed1ab_0, conda-forge/noarch::botorch-0.2.2-py_0\r\n  path: 'lib/python3.9/site-packages/test/optim/__pycache__/__init__.cpython-39.pyc'\r\n\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- BoTorch Version (run `print(botorch.__version__)` -->\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` -->\r\n- <!-- PyTorch Version (run `print(torch.__version__)` -->\r\n- <!-- Computer OS -->\r\n\r\n\r\n## Additional context\r\n\r\nYou can add `recursive-exclude test *` or something to your `MANIFEST.in`. As a workaround, we have simply force-deleted the tests folder on the conda-forge's botorch side for now, pending a fix from you.\r\n\r\nxref: https://github.com/pytorch/botorch/issues/1019", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1854/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1854/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1838", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1838/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1838/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1838/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1838", "id": 1062655020, "node_id": "I_kwDOBZhSr84_VtQs", "number": 1838, "title": "[Bug] UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11]", "user": {"login": "eloygeenjaar", "id": 55933473, "node_id": "MDQ6VXNlcjU1OTMzNDcz", "avatar_url": "https://avatars.githubusercontent.com/u/55933473?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eloygeenjaar", "html_url": "https://github.com/eloygeenjaar", "followers_url": "https://api.github.com/users/eloygeenjaar/followers", "following_url": "https://api.github.com/users/eloygeenjaar/following{/other_user}", "gists_url": "https://api.github.com/users/eloygeenjaar/gists{/gist_id}", "starred_url": "https://api.github.com/users/eloygeenjaar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eloygeenjaar/subscriptions", "organizations_url": "https://api.github.com/users/eloygeenjaar/orgs", "repos_url": "https://api.github.com/users/eloygeenjaar/repos", "events_url": "https://api.github.com/users/eloygeenjaar/events{/privacy}", "received_events_url": "https://api.github.com/users/eloygeenjaar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-11-24T16:48:49Z", "updated_at": "2021-11-29T15:42:34Z", "closed_at": "2021-11-29T15:42:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nI am getting the exact same UserWarning as @ishank-juneja in [Issue 1834](https://github.com/cornellius-gp/gpytorch/issues/1834), namely: ```UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)```, it seems to be raised in this line: `loss = -mll(output, train_y)`.\r\nI will share their code snippet, since it produces the exact same UserWarning, in my case it starts flushing my terminal since I am doing cross-validation so I am training multiple models and receiving the same UserWarning for each training session.\r\n\r\n## To reproduce\r\n```\r\nimport torch\r\nimport gpytorch\r\nimport numpy as np\r\n\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super().__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=4))\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\nclass MultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\r\n        # https://docs.gpytorch.ai/en/stable/means.html#multitaskmean\r\n        self.mean_module = gpytorch.means.MultitaskMean(\r\n            gpytorch.means.ConstantMean(), num_tasks=2\r\n        )\r\n        # Composition of index kernel and RBF kernel\r\n        self.covar_module = gpytorch.kernels.MultitaskKernel(\r\n            gpytorch.kernels.RBFKernel(ard_num_dims=4), num_tasks=2, rank=2\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        # https://docs.gpytorch.ai/en/stable/distributions.html#multitaskmultivariatenormal\r\n        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, interleaved=False)\r\n\r\n\r\n# Number of train samples\r\nnsamps = 1000\r\n# Fix seed for reproducability\r\nnp.random.seed(10)\r\n# Joint input space tensor (u_t, x_t) to hold all inputs and trajectories\r\ntrain_x = torch.tensor(np.random.uniform(low=-1.0, high=1.0, size=(nsamps, 4))).float()\r\n\r\n# Generate output samples\r\n# A and B matrices\r\nA = torch.tensor([[1., 0.],\r\n                  [0., 1.]])\r\nB = torch.tensor([[-0.2, 0.1],\r\n                 [0.15, 0.15]])\r\n# Output states starting time index 1, no observation noise\r\ntrain_y = torch.zeros(nsamps, 2)\r\n# Obtain the output states $(x_{t+1, 1}, x_{t+1, 2})$\r\nfor i in range(nsamps):\r\n    # Get the output next state\r\n    x_next = torch.matmul(A, train_x[i, 2:4]) + torch.matmul(B, train_x[i, 0:2])\r\n    # No observation noise added\r\n    train_y[i, :] = x_next\r\n\r\n# dataset = torch.cat([train_x, train_y], dim=1)\r\n\r\nlikelihood1 = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel1 = ExactGPModel(train_x, train_y[:, 0], likelihood1)\r\n\r\nlikelihood2 = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel2 = ExactGPModel(train_x, train_y[:, 1], likelihood2)\r\n\r\n# Collect the sub-models in an IndependentMultiOutputGP, and the respective likelihoods in a MultiOutputLikelihood\r\nmodel = gpytorch.models.IndependentModelList(model1, model2)\r\nlikelihood = gpytorch.likelihoods.LikelihoodList(model1.likelihood, model2.likelihood)\r\n\r\nmll = gpytorch.mlls.SumMarginalLogLikelihood(likelihood, model)\r\n\r\n# Perform Ind. Model List Training\r\ntraining_iterations = 50\r\n# Find optimal model hyper-parameters\r\nmodel.train()\r\nlikelihood.train()\r\n# Use the Adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes all submodel and all likelihood parameters\r\n], lr=0.1)\r\nprint(\"Training Ind. Model List\\n- - - - - - - - - - \")\r\nfor i in range(training_iterations):\r\n    optimizer.zero_grad()\r\n    output = model(*model.train_inputs)\r\n    loss = -mll(output, model.train_targets)\r\n    loss.backward()\r\n    if (i + 1) % 5 == 0:\r\n        print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n    optimizer.step()\r\nprint(\"- - - - - - - - - - \")\r\n\r\n# MTGaussianLikelihood allows for modelling a full 2x2 Noise Cov. Prior\r\nMTlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\r\nMTmodel = MultitaskGPModel(train_x, train_y, MTlikelihood)\r\n\r\ntraining_iterations = 50\r\n\r\n# Find optimal MTmodel hyperparameters\r\nMTmodel.train()\r\nMTlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': MTmodel.parameters()},  # Includes GaussianLikelihood parameters\r\n], lr=0.1)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(MTlikelihood, MTmodel)\r\nprint(\"Training MT Model\\n- - - - - - - - - - \")\r\nfor i in range(training_iterations):\r\n    optimizer.zero_grad()\r\n    output = MTmodel(train_x)\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    if (i + 1) % 5 == 0:\r\n        print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n    optimizer.step()\r\nprint(\"- - - - - - - - - - \")\r\n\r\n# View the parameters (and others specific to MT)-\r\n# (1) Learned value of observation-noise covariance\r\n# (2) Learned constant mean prior\r\n# (3) Learned kernel scale parameter (\\sigma)\r\n# (4) Learned kernel length scale (\\ell)\r\n\r\n# Output 1 y_{a}\r\nprint(\"- - - - - - - - - \\nModel 1a\\n- - - - - - - - - \")\r\nprint(\"Learned Noise Covariance\")\r\nprint(model.models[0].likelihood.noise_covar.noise)\r\nprint(\"Learned constant mean for the prior\")\r\nprint(model.models[0].mean_module.constant)\r\nprint(\"Learned kernel scale (variance of kernel sigma)\")\r\nprint(model.models[0].covar_module.outputscale)\r\nprint(\"Learned kernel length scales (one for each input) \\ell\")\r\nprint(model.models[0].covar_module.base_kernel.lengthscale)\r\n\r\n# Output 2 y_{b}\r\nprint(\"- - - - - - - - - \\nModel 1b\\n- - - - - - - - - \")\r\nprint(\"Learned Noise Covariance\")\r\nprint(model.models[1].likelihood.noise_covar.noise)\r\nprint(\"Learned constant mean for the prior\")\r\nprint(model.models[1].mean_module.constant)\r\nprint(\"Learned kernel scale (variance of kernel sigma)\")\r\nprint(model.models[1].covar_module.outputscale)\r\nprint(\"Learned kernel length scales (one for each input) \\ell\")\r\nprint(model.models[1].covar_module.base_kernel.lengthscale)\r\n\r\n# MT Model\r\nprint(\"- - - - - - - - - \\nModel 2 (MultiTask=MT)\\n- - - - - - - - - \")\r\nprint(\"Learned Noise Covariance\")\r\nprint(MTmodel.likelihood.noise)\r\nprint(\"Learned constant mean for the prior comp. 1\")\r\nprint(MTmodel.mean_module.base_means[0].constant)\r\nprint(\"Learned constant mean for the prior comp. 2\")\r\nprint(MTmodel.mean_module.base_means[1].constant)\r\nprint(\"Learned static Index Kernel/Fixed Covariance K_{TT} matrix\")\r\nprint(MTmodel.covar_module.task_covar_module.covar_factor)\r\nprint(\"Learned kernel length scales (one for each input) \\ell\")\r\nprint(MTmodel.covar_module.data_covar_module.lengthscale)\r\n\r\n# Set models into eval mode\r\nmodel.eval()\r\nMTmodel.eval()\r\nlikelihood.eval()\r\nMTlikelihood.eval()\r\n\r\n# Shift this distance away from a train data point\r\nshift = 0.05\r\n\r\n# Train data-point\r\nux1 = train_x[1:2, :]\r\nux2 = train_x[1:2, :] + shift\r\n# Performing inference on the training data points themselves\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    # Get distributions of type multivariate-normal\r\n    prediction_dist1 = likelihood(*model(ux1, ux1))\r\n    prediction_dist2 = likelihood(*model(ux2, ux2))\r\n    # Get distribution of type multi-task multi-variate normal\\\r\n    prediction_dist3 = MTlikelihood(MTmodel(ux1))\r\n    prediction_dist4 = MTlikelihood(MTmodel(ux2))\r\n\r\n\r\nprint(\"Indp Model List Mean and Variance on a Train Point\")\r\nprint('mean: ', prediction_dist1[0].mean.detach().numpy(), prediction_dist1[1].mean.detach().numpy())\r\nprint('vars: ', prediction_dist1[0].covariance_matrix.detach().numpy(), prediction_dist1[1].covariance_matrix.detach().numpy())\r\nprint('------')\r\nprint(\"Indp Model List Mean and Variance Nearby a Train Point\")\r\nprint('mean: ', prediction_dist2[0].mean.detach().numpy(), prediction_dist2[1].mean.detach().numpy())\r\nprint('vars: ', prediction_dist2[0].covariance_matrix.detach().numpy(), prediction_dist2[1].covariance_matrix.detach().numpy())\r\nprint('------')\r\nprint(\"MT-Model Mean and Variance on a Train Point\")\r\nprint('mean: ', prediction_dist3.mean.detach().numpy())\r\nprint('vars:\\n', prediction_dist3.covariance_matrix.detach().numpy())\r\nprint('------')\r\nprint(\"MT-Model Mean and Variance Nearby a Train Point\")\r\nprint('mean: ', prediction_dist4.mean.detach().numpy())\r\nprint('vars:\\n', prediction_dist4.covariance_matrix.detach().numpy())\r\nprint('------')\r\nprint(\"Actual Data Point (True Label)\")\r\nprint(train_y[1:2, :])\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n/home/ishank/Desktop/Gaussian-Process-Dynamics/venv/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py:266: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\r\n  _jit_linear_cg_updates_no_precond(\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI expected there to be no UserWarning.\r\n\r\n## System information\r\n\r\ngpytorch 1.5.1\r\npytorch 1.10.0+cu102\r\nUbuntu 20.04\r\n\r\n## Additional context\r\nI have copied the system information, stack trace, and code snippet from [Issue 1834](https://github.com/cornellius-gp/gpytorch/issues/1834).\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1838/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1838/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1827", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1827/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1827/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1827/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1827", "id": 1055290810, "node_id": "I_kwDOBZhSr84-5nW6", "number": 1827, "title": "[Bug] GetItem in BatchRepeated LazyEvaluatedKernelTensor Fails", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-11-16T20:28:01Z", "updated_at": "2021-12-04T21:48:03Z", "closed_at": "2021-12-04T21:47:51Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThis is seemingly directly caused by #1813 and causes downstream botorch errors (especially https://github.com/pytorch/botorch/issues/980). I've tracked it down to the\r\n\r\n```python\r\nfrom gpytorch.kernels import MaternKernel\r\nfrom gpytorch.lazy import KroneckerProductLazyTensor, BatchRepeatLazyTensor\r\n\r\nkernel = MaternKernel()\r\nBatchRepeatLazyTensor(kernel(torch.randn(30)), torch.Size((10,))).diag()\r\n```\r\n\r\nproduces an indexing error.\r\n\r\n## To reproduce\r\n\r\n** Stack trace/error message **\r\n```\r\nIndexError                                Traceback (most recent call last)\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in _getitem(self, row_index, col_index, *batch_indices)\r\n    111         try:\r\n--> 112             x2 = x2[(*batch_indices, col_index, dim_index)]\r\n    113         # We're going to handle multi-batch indexing with a try-catch loop\r\n\r\nIndexError: too many indices for tensor of dimension 2\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nRuntimeError                              Traceback (most recent call last)\r\n/var/folders/ms/lbkrq70x7lnbnztclff1ln6r0000gn/T/ipykernel_8975/568402408.py in <module>\r\n      6 \r\n      7 kernel = MaternKernel()\r\n----> 8 BatchRepeatLazyTensor(kernel(torch.randn(30)), torch.Size((10,))).diag()\r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/lazy_tensor.py in diag(self)\r\n   1065 \r\n   1066         row_col_iter = torch.arange(0, self.matrix_shape[-1], dtype=torch.long, device=self.device)\r\n-> 1067         return self[..., row_col_iter, row_col_iter]\r\n   1068 \r\n   1069     def dim(self):\r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/lazy_tensor.py in __getitem__(self, index)\r\n   2144                 self, (*batch_indices, row_index, col_index)\r\n   2145             )\r\n-> 2146             res = self._get_indices(row_index, col_index, *batch_indices)\r\n   2147         else:\r\n   2148             res = self._getitem(row_index, col_index, *batch_indices)\r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/batch_repeat_lazy_tensor.py in _get_indices(self, row_index, col_index, *batch_indices)\r\n     81 \r\n     82         # Now call the sub _get_indices method\r\n---> 83         res = self.base_lazy_tensor._get_indices(row_index, col_index, *batch_indices)\r\n     84         return res\r\n     85 \r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/lazy_tensor.py in _get_indices(self, row_index, col_index, *batch_indices)\r\n    305         batch_indices = tuple(index.expand(final_shape) for index in batch_indices)\r\n    306 \r\n--> 307         base_lazy_tensor = self._getitem(_noop_index, _noop_index, *batch_indices)._expand_batch(final_shape)\r\n    308 \r\n    309         # Create some interoplation indices and values\r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in _getitem(self, row_index, col_index, *batch_indices)\r\n    115         except IndexError:\r\n    116             if any(not isinstance(bi, slice) for bi in batch_indices):\r\n--> 117                 raise RuntimeError(\r\n    118                     \"Attempting to tensor index a non-batch matrix's batch dimensions. \"\r\n    119                     f\"Got batch index {batch_indices} but my shape was {self.shape}\"\r\n\r\nRuntimeError: Attempting to tensor index a non-batch matrix's batch dimensions. Got batch index (tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ....\r\n```\r\n\r\n## Expected Behavior\r\n\r\nSimilar behavior to pre-#1813. \r\n\r\nWondering if this is even possible to do without evaluating the kernel at all because we'd need to a) batch repeat the data (which is slow but possible) or b) evaluate the kernel and then batch unsqueeze it.\r\n\r\nI'll try to put up a PR for fixing this soon, but am stuck currently.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch master\r\n\r\n## Additional context\r\n\r\nUnit test for BatchRepeatLazyTensor doesn't check the LazyEvaluatedKernelTensor case, but does check ToeplitzLazyTensor. Maybe should also update unit test.\r\n\r\ncc @valtron @Balandat @saitcakmak @gpleiss for visibility\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1827/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1827/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1821", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1821/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1821/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1821/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1821", "id": 1053287301, "node_id": "I_kwDOBZhSr84-x-OF", "number": 1821, "title": "[Bug?] Non zero variance of output distribution on performing inference on training-data", "user": {"login": "ishank-juneja", "id": 24539556, "node_id": "MDQ6VXNlcjI0NTM5NTU2", "avatar_url": "https://avatars.githubusercontent.com/u/24539556?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ishank-juneja", "html_url": "https://github.com/ishank-juneja", "followers_url": "https://api.github.com/users/ishank-juneja/followers", "following_url": "https://api.github.com/users/ishank-juneja/following{/other_user}", "gists_url": "https://api.github.com/users/ishank-juneja/gists{/gist_id}", "starred_url": "https://api.github.com/users/ishank-juneja/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ishank-juneja/subscriptions", "organizations_url": "https://api.github.com/users/ishank-juneja/orgs", "repos_url": "https://api.github.com/users/ishank-juneja/repos", "events_url": "https://api.github.com/users/ishank-juneja/events{/privacy}", "received_events_url": "https://api.github.com/users/ishank-juneja/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-11-15T07:05:46Z", "updated_at": "2021-11-15T17:03:28Z", "closed_at": "2021-11-15T17:03:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nAfter training a model with train-data `train_x` as a sanity check on the model I am performing inference on the training data itself. I was expecting the means to be precisely my `train_y` labels and the covariance_matrix to be a matrix full of zeros (I am using an RBF kernel so variance at train-points should be 0).\r\n\r\n## To reproduce\r\n\r\n```python\r\n# Number of train samples\r\nnsamps = 1000\r\n# Fix seed for reproducability\r\nnp.random.seed(10)\r\n# Joint input space tensor (u_t, x_t) to hold all inputs and trajectories\r\ntrain_x = torch.tensor(np.random.uniform(low=-1.0, high=1.0, size=(nsamps, 4))).float()\r\n# A and B matrices\r\nA = torch.tensor([[1., 0.],\r\n                  [0., 1.]])\r\nB = torch.tensor([[-0.2, 0.1],\r\n                 [0.2, -0.1]])\r\ntorch.manual_seed(0)\r\n\r\n# 1D Output states starting time index 1, no observation noise\r\ntrain_y = torch.zeros(nsamps, 2)\r\n\r\n# Obtain the output states $(x_{t+1, 1}, x_{t+1, 2})$\r\nfor i in range(nsamps):\r\n    # Get the output next state\r\n    x_next = torch.matmul(A, train_x[i, 2:4]) + torch.matmul(B, train_x[i, 0:2])\r\n    # No observation noise added\r\n    train_y[i, :] = x_next\r\n\r\ndataset = torch.cat([train_x, train_y], dim=1)\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super().__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=4))\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\nlikelihood1 = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel1 = ExactGPModel(train_x, train_y[:, 0], likelihood1)\r\n\r\nlikelihood2 = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel2 = ExactGPModel(train_x, train_y[:, 1], likelihood2)\r\n\r\n# Collect the submodels in an IndependentMultiOutputGP, and the respective likelihoods in a MultiOutputLikelihood\r\nmodel = gpytorch.models.IndependentModelList(model1, model2)\r\nlikelihood = gpytorch.likelihoods.LikelihoodList(model1.likelihood, model2.likelihood)\r\nmll = gpytorch.mlls.SumMarginalLogLikelihood(likelihood, model)\r\n\r\n# Perform Model Traning\r\ntraining_iterations = 50\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the Adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes all submodel and all likelihood parameters\r\n], lr=0.1)\r\n\r\nfor i in range(training_iterations):\r\n    optimizer.zero_grad()\r\n    output = model(*model.train_inputs)\r\n    loss = -mll(output, model.train_targets)\r\n    loss.backward()\r\n    if((i + 1) % 5 == 0):\r\n      print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n    optimizer.step()\r\n\r\n# Performing inference on the training data points themselves\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n  # Inference outputs 2 seperate distributions \r\n  # one for output 1 and the other for output 2\r\n  prediction_dist1 = likelihood(model.models[0](train_x))\r\n  prediction_dist2 = likelihood(model.models[1](train_x))\r\n\r\nprint(prediction_dist1[0].mean)\r\nprint(prediction_dist1[0].covariance_matrix)\r\nprint(prediction_dist2[0].mean)\r\nprint(prediction_dist2[0].covariance_matrix)\r\nprint(train_x)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n/usr/local/lib/python3.7/dist-packages/gpytorch/utils/linear_cg.py:278: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\r\n  curr_conjugate_vec,\r\nIter 5/50 - Loss: 0.649\r\nIter 10/50 - Loss: 0.424\r\nIter 15/50 - Loss: 0.197\r\nIter 20/50 - Loss: -0.037\r\nIter 25/50 - Loss: -0.285\r\nIter 30/50 - Loss: -0.532\r\nIter 35/50 - Loss: -0.790\r\nIter 40/50 - Loss: -1.052\r\nIter 45/50 - Loss: -1.298\r\nIter 50/50 - Loss: -1.557\r\n\r\nModel 1 Mean and Variance\r\ntensor([-0.0006, -0.0006, -0.0006, ... ,-0.0006],\r\n       requires_grad=True)\r\ntensor([[0.3574, 0.3142, 0.3275,  ..., 0.2934, 0.3189, 0.2843],\r\n        [0.3142, 0.3574, 0.3045,  ..., 0.3240, 0.3275, 0.2961],\r\n        [0.3275, 0.3045, 0.3574,  ..., 0.2697, 0.3163, 0.2545],\r\n        ...,\r\n        [0.2934, 0.3240, 0.2697,  ..., 0.3574, 0.3367, 0.2992],\r\n        [0.3189, 0.3275, 0.3163,  ..., 0.3367, 0.3574, 0.2863],\r\n        [0.2843, 0.2961, 0.2545,  ..., 0.2992, 0.2863, 0.3574]],\r\n       grad_fn=<AddBackward0>)\r\n\r\nModel 2 Mean and Variance\r\ntensor([-0.0011, -0.0011, -0.0011, ..., -0.0011],\r\n       requires_grad=True)\r\ntensor([[0.3833, 0.3587, 0.3453,  ..., 0.2573, 0.3124, 0.2836],\r\n        [0.3587, 0.3833, 0.3463,  ..., 0.2657, 0.3188, 0.2918],\r\n        [0.3453, 0.3463, 0.3833,  ..., 0.2021, 0.2769, 0.2286],\r\n        ...,\r\n        [0.2573, 0.2657, 0.2021,  ..., 0.3833, 0.3549, 0.3162],\r\n        [0.3124, 0.3188, 0.2769,  ..., 0.3549, 0.3833, 0.3115],\r\n        [0.2836, 0.2918, 0.2286,  ..., 0.3162, 0.3115, 0.3833]],\r\n       grad_fn=<AddBackward0>)\r\nOriginal Train Data different from means\r\ntensor([[ 0.0629,  0.7020],\r\n        [-0.6583,  0.5755],\r\n        [ 0.4207,  0.8568],\r\n        ...,\r\n        [-0.6610, -0.8443],\r\n        [-0.1676, -0.4164],\r\n        [-0.2469, -0.3353]])\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI expected the first column of train_y to be identical to the means output by Model 1 and the second column of train_y to be identical to the means output by the Model 2. Instead the means output by the models in these cases are just constant values (the sonstant values -0.0006 and -0.0011 output here are same as the mean value learned by the model for the constant_mean prior as confirmed by running `model.mean_module.constant`)\r\n\r\nAlso I expected the covariance matrices associated with the inferred posterior to have all entries close to or equal to 0.0 since for an RBF kernel and for GPs more generally, variance at test points is 0. Instead, the variance entries here are finite values (near about 0.3) that I am unable to interpret.  \r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version (1.5.1)` \r\n- PyTorch Version (1.10.0+cu111)`\r\n- Google colab notebook: [https://colab.research.google.com/drive/1R-kLiPOwfyTra8MvupQ7tkAoJyjCI77_?usp=sharing](https://colab.research.google.com/drive/1R-kLiPOwfyTra8MvupQ7tkAoJyjCI77_?usp=sharing)\r\n\r\n## Additional context\r\nI am working on a linear-dynamics regression toy-example with Gaussian Processes and was getting larger than expected variance values on performing inference on a test trajectory (despite the fact that training seems to go through correctly based on loss values), so I decided to do this sanity check (inference on train data) on the trained GP model.  \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1821/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1821/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1817", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1817/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1817/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1817/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1817", "id": 1050081428, "node_id": "I_kwDOBZhSr84-lviU", "number": 1817, "title": "[Bug] Matern Kernel does not work", "user": {"login": "umt0", "id": 63372632, "node_id": "MDQ6VXNlcjYzMzcyNjMy", "avatar_url": "https://avatars.githubusercontent.com/u/63372632?v=4", "gravatar_id": "", "url": "https://api.github.com/users/umt0", "html_url": "https://github.com/umt0", "followers_url": "https://api.github.com/users/umt0/followers", "following_url": "https://api.github.com/users/umt0/following{/other_user}", "gists_url": "https://api.github.com/users/umt0/gists{/gist_id}", "starred_url": "https://api.github.com/users/umt0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/umt0/subscriptions", "organizations_url": "https://api.github.com/users/umt0/orgs", "repos_url": "https://api.github.com/users/umt0/repos", "events_url": "https://api.github.com/users/umt0/events{/privacy}", "received_events_url": "https://api.github.com/users/umt0/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-11-10T17:00:09Z", "updated_at": "2021-11-10T17:23:42Z", "closed_at": "2021-11-10T17:23:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nUsing **gpytorch.kernels.MaternKernel** , the results are not the same as for:\r\n\r\n- the formal result https://en.wikipedia.org/wiki/Mat%C3%A9rn_covariance_function\r\n- the Matern kernel from sklearn ( **sklearn.gaussian_process.kernels** ), which coincides with formal result.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport gpytorch.kernels\r\nimport torch\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom sklearn.gaussian_process.kernels import Matern\r\n\r\nnus = np.array([0.5,1.5,2.5])\r\n\r\nfor nu in nus:\r\n    lengthscale = 1\r\n\r\n    K = gpytorch.kernels.MaternKernel(lengthscale=lengthscale,nu = nu)\r\n    x1 = torch.arange(0,1,0.01)\r\n    x2 = torch.zeros(1)\r\n    K_eval = K(x1,x2)\r\n    K_vec = torch.zeros(len(x1))\r\n    K_vec[:] = K_eval[:,0]\r\n\r\n    print(K_vec.size())\r\n\r\n    K_sk = Matern(length_scale=lengthscale, nu=nu)\r\n\r\n    x1 = np.arange(0,1,0.01)\r\n    x1arr = np.zeros((len(x1),1))\r\n    x1arr[:,0] = x1\r\n\r\n    x2 = np.zeros(1)\r\n    x2arr = np.zeros((len(x2),1))\r\n    x2arr[:,0] = x2\r\n\r\n    K_call = K_sk(x1arr,x2arr)\r\n\r\n    K_vec1 = np.zeros(len(x1))\r\n    K_vec1[:] = K_call[:,0]\r\n\r\n    print(np.shape(K_vec1))\r\n\r\n\r\n    plt.xlabel(r'$x$', fontsize=16)\r\n    plt.ylabel(r'$K(x,0)$', fontsize=16, rotation =90)\r\n    plt.plot(x1,K_vec.detach().numpy(),\":\",label=r\"gpytorch, $\\nu=%.1f$\"%nu)\r\n    plt.plot(x1,K_vec1,\"-\",label=r\"sklearn, $\\nu=%.1f$\"%nu)\r\n    if nu ==2.5:\r\n        plt.plot(x1,(1+np.sqrt(5)*x1+(5/3)*x1**2)*np.exp(-np.sqrt(5)*x1),\"--\",label=r\"truth, $\\nu=%.1f$\"%nu,color=\"black\")\r\n    elif nu==1.5:\r\n        plt.plot(x1,(1+np.sqrt(3)*x1)*np.exp(-np.sqrt(3)*x1),\"--\",label=r\"truth, $\\nu=%.1f$\"%nu,color=\"black\")\r\n    elif nu==0.5:\r\n        plt.plot(x1,(1)*np.exp(-np.sqrt(1)*x1),\"--\",label=r\"truth, $\\nu=%.1f$\"%nu,color=\"black\")    \r\n        \r\nlegend = plt.legend(loc='best', ncol=1,shadow=False,prop={'size': 12}, bbox_to_anchor=(1.05, 1))\r\nplt.show()\r\n```\r\n\r\n\r\n\r\n## Expected Behavior\r\n\r\n- The label \"truth\" stands for formal result: https://en.wikipedia.org/wiki/Mat%C3%A9rn_covariance_function\r\n- The label \"sklearn\" stands for sklearn Matern kernel\r\n- The label \"gpytorch\" stands for gpytorch Matern kernel\r\n\r\nI am using \\nu = 1/2, 3/2 and 5/2. \r\nI am using lengthscale =1.\r\n\r\n**The sklearn captures the formal result, while gpytorch not.**\r\n\r\n![image](https://user-images.githubusercontent.com/63372632/141157658-63f7f91b-498a-4f88-b90c-c7617e655fa7.png)\r\n\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n-  I am using gpytorch-1.5.1\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1817/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1817/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1810", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1810/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1810/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1810/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1810", "id": 1046798068, "node_id": "I_kwDOBZhSr84-ZN70", "number": 1810, "title": "[Bug] Segfault on Spectral mixture GP regression test (MacOS)", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2021-11-07T17:01:46Z", "updated_at": "2022-05-28T18:13:48Z", "closed_at": "2022-05-28T18:13:47Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nRunning the `test/examples/test_spectral_mixture_gp_regression.py` reliably produces a segfault on my Mac, even when installing into a virgin conda env. This happens on master but also on commits a few months old (I haven't run tests locally in a while though, so not sure when this broke).\r\n\r\nI don't see this issue on Linux. \r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nconda create -n gptt python=3.8\r\nconda activate gptt\r\nconda install -c pytorch pytorch\r\nconda install scipy scikit-learn\r\n\r\ncd gpytorch\r\npip install -e .\r\n\r\n(gptt) balandat@balandat-mbp gpytorch % pytest test/examples/test_spectral_mixture_gp_regression.py\r\n==================================================================================================================== test session starts =====================================================================================================================\r\nplatform darwin -- Python 3.8.12, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\r\nrootdir: /Users/balandat/Code/gpytorch\r\ncollected 2 items\r\n\r\ntest/examples/test_spectral_mixture_gp_regression.py Fatal Python error: Segmentation fault\r\n\r\nThread 0x000000011e4aee00 (most recent call first):\r\n  File \"/Usezsh: segmentation fault  pytest test/examples/test_spectral_mixture_gp_regression.py\r\n\r\n```\r\n\r\nHere is the conda env:\r\n```\r\n# packages in environment at /Users/balandat/miniconda3/envs/gptt:\r\n#\r\n# Name                    Version                   Build  Channel\r\nattrs                     21.2.0             pyhd3eb1b0_0\r\nblas                      1.0                         mkl\r\nca-certificates           2021.10.26           hecd8cb5_2\r\ncertifi                   2021.10.8        py38hecd8cb5_0\r\ngpytorch                  1.5.1                     dev_0    <develop>\r\niniconfig                 1.1.1              pyhd3eb1b0_0\r\nintel-openmp              2021.4.0          hecd8cb5_3538\r\njoblib                    1.1.0              pyhd3eb1b0_0\r\nlibcxx                    12.0.0               h2f01273_0\r\nlibffi                    3.3                  hb1e8313_2\r\nlibgfortran               3.0.1                h93005f0_2\r\nlibuv                     1.40.0               haf1e3a3_0\r\nllvm-openmp               12.0.0               h0dcd299_1\r\nmkl                       2021.4.0           hecd8cb5_637\r\nmkl-service               2.4.0            py38h9ed2024_0\r\nmkl_fft                   1.3.1            py38h4ab4a9b_0\r\nmkl_random                1.2.2            py38hb2f4e1b_0\r\nmore-itertools            8.10.0             pyhd3eb1b0_0\r\nncurses                   6.3                  hca72f7f_1\r\nnumpy                     1.21.2           py38h4b4dc7a_0\r\nnumpy-base                1.21.2           py38he0bd621_0\r\nopenssl                   1.1.1l               h9ed2024_0\r\npackaging                 21.0               pyhd3eb1b0_0\r\npip                       21.2.4           py38hecd8cb5_0\r\npluggy                    0.13.1           py38hecd8cb5_0\r\npy                        1.10.0             pyhd3eb1b0_0\r\npyparsing                 3.0.4              pyhd3eb1b0_0\r\npytest                    6.2.4            py38hecd8cb5_2\r\npython                    3.8.12               h88f2d9e_0\r\npytorch                   1.10.0                  py3.8_0    pytorch\r\nreadline                  8.1                  h9ed2024_0\r\nscikit-learn              1.0.1            py38hae1ba45_0\r\nscipy                     1.7.1            py38h88652d9_2\r\nsetuptools                58.0.4           py38hecd8cb5_0\r\nsix                       1.16.0             pyhd3eb1b0_0\r\nsqlite                    3.36.0               hce871da_0\r\nthreadpoolctl             2.2.0              pyh0d69192_0\r\ntk                        8.6.11               h7bc2e8c_0\r\ntoml                      0.10.2             pyhd3eb1b0_0\r\ntyping_extensions         3.10.0.2           pyh06a4308_0\r\nwheel                     0.37.0             pyhd3eb1b0_1\r\nxz                        5.2.5                h1de35cc_0\r\nzlib                      1.2.11               h1de35cc_3\r\n```\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- master\r\n- 1.10\r\n- MacOS 11.6.1\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1810/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1810/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1809", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1809/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1809/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1809/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1809", "id": 1046669735, "node_id": "I_kwDOBZhSr84-Yumn", "number": 1809, "title": "[Bug] `Kernel.__getitem__` modifies `self`", "user": {"login": "valtron", "id": 123696, "node_id": "MDQ6VXNlcjEyMzY5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/123696?v=4", "gravatar_id": "", "url": "https://api.github.com/users/valtron", "html_url": "https://github.com/valtron", "followers_url": "https://api.github.com/users/valtron/followers", "following_url": "https://api.github.com/users/valtron/following{/other_user}", "gists_url": "https://api.github.com/users/valtron/gists{/gist_id}", "starred_url": "https://api.github.com/users/valtron/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/valtron/subscriptions", "organizations_url": "https://api.github.com/users/valtron/orgs", "repos_url": "https://api.github.com/users/valtron/repos", "events_url": "https://api.github.com/users/valtron/events{/privacy}", "received_events_url": "https://api.github.com/users/valtron/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-11-07T06:06:28Z", "updated_at": "2021-11-08T14:47:06Z", "closed_at": "2021-11-08T14:47:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nEven though `Kernel.__getitem__` returns a copy, it still [modifies itself](https://github.com/cornellius-gp/gpytorch/blob/c96965c8aefac1874652fb44321541f5972eaa88/gpytorch/kernels/kernel.py#L436). That looks like a bug to me, and causes the issue below.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport torch\r\nfrom gpytorch.kernels import Kernel, MaternKernel, ScaleKernel\r\nfrom gpytorch.priors.torch_priors import GammaPrior\r\n\r\nX = torch.zeros((5, 4))\r\nY = torch.zeros((5, 3))\r\nkernel = ScaleKernel(\r\n\tMaternKernel(\r\n\t\tnu = 2.5,\r\n\t\tard_num_dims = X.shape[-1],\r\n\t\tbatch_shape = (Y.shape[-1],),\r\n\t\tlengthscale_prior = GammaPrior(3, 6),\r\n\t),\r\n\tbatch_shape = (Y.shape[-1],),\r\n\toutputscale_prior = GammaPrior(2, 0.15),\r\n)\r\n\r\nk1 = kernel[0]\r\nprint(k1.batch_shape) # torch.Size([3])\r\nk2 = kernel[0]\r\nprint(k2.batch_shape) # torch.Size([])\r\n```\r\n\r\nIn other words, `kernel[i] != kernel[i]`.\r\n\r\n## Expected Behavior\r\n\r\nBoth printed lines should be `torch.Size([])`.\r\n\r\n## System information\r\n\r\n- `gpytorch==1.5.1`\r\n- `torch==1.9.0+cu111`\r\n- Win10 x64\r\n\r\n## Additional context\r\n\r\nChanging [this line](https://github.com/cornellius-gp/gpytorch/blob/c96965c8aefac1874652fb44321541f5972eaa88/gpytorch/kernels/kernel.py#L436)...\r\n```diff\r\n- self._modules[sub_module_name] = sub_module.__getitem__(index)\r\n+ new_kernel._modules[sub_module_name] = sub_module.__getitem__(index)\r\n```\r\n...appears to fix it.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1809/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1809/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1808", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1808/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1808/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1808/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1808", "id": 1046537633, "node_id": "I_kwDOBZhSr84-YOWh", "number": 1808, "title": "[Bug]  (SVDKL)  Shapes are not broadcastable for mul operation", "user": {"login": "NeelKanwal", "id": 52494244, "node_id": "MDQ6VXNlcjUyNDk0MjQ0", "avatar_url": "https://avatars.githubusercontent.com/u/52494244?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NeelKanwal", "html_url": "https://github.com/NeelKanwal", "followers_url": "https://api.github.com/users/NeelKanwal/followers", "following_url": "https://api.github.com/users/NeelKanwal/following{/other_user}", "gists_url": "https://api.github.com/users/NeelKanwal/gists{/gist_id}", "starred_url": "https://api.github.com/users/NeelKanwal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NeelKanwal/subscriptions", "organizations_url": "https://api.github.com/users/NeelKanwal/orgs", "repos_url": "https://api.github.com/users/NeelKanwal/repos", "events_url": "https://api.github.com/users/NeelKanwal/events{/privacy}", "received_events_url": "https://api.github.com/users/NeelKanwal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2021-11-06T15:51:07Z", "updated_at": "2021-11-10T15:00:27Z", "closed_at": "2021-11-09T10:03:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI am trying SVDKL model for multiclass classification. I am trying the example mentioned in NN_intergration which works fine for CIFAR-10.\r\n \r\nbut when I change the data to another custom dataset it again gives the same issue with both versions of DenseNet. Every other setting is pretty the same. I have resized the input images to 224*224.\r\n\r\nI saw some similar issues open [#1144](https://github.com/cornellius-gp/gpytorch/issues/1144), I am not able to figure out how to solve it.\r\n \r\nDid someone find a fix to this? It would be very helpful to hear the insight on this issue. \r\n\r\nHere is the trace. \r\n\r\nFile \"/home/neel/DKLModel/my_functions.py\", line 104, in train\r\n    output = model(data)\r\n  File \"/home/neel/miniconda3/envs/DKL/lib/python3.6/site-packages/gpytorch/module.py\", line 30, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/neel/DKLModel/my_functions.py\", line 73, in forward\r\n    res = self.gp_layer(features)\r\n  File \"/home/neel/miniconda3/envs/DKL/lib/python3.6/site-packages/gpytorch/models/approximate_gp.py\", line 81, in __call__\r\n    return self.variational_strategy(inputs, prior=prior, **kwargs)\r\n  File \"/home/neel/miniconda3/envs/DKL/lib/python3.6/site-packages/gpytorch/variational/independent_multitask_variational_strategy.py\", line 56, in __call__\r\n    function_dist = self.base_variational_strategy(x, prior=prior, **kwargs)\r\n  File \"/home/neel/miniconda3/envs/DKL/lib/python3.6/site-packages/gpytorch/variational/_variational_strategy.py\", line 129, in __call__\r\n    **kwargs,\r\n  File \"/home/neel/miniconda3/envs/DKL/lib/python3.6/site-packages/gpytorch/module.py\", line 30, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/neel/miniconda3/envs/DKL/lib/python3.6/site-packages/gpytorch/variational/grid_interpolation_variational_strategy.py\", line 93, in forward\r\n    predictive_mean = left_interp(interp_indices, interp_values, inducing_values.unsqueeze(-1))\r\n  File \"/home/neel/miniconda3/envs/DKL/lib/python3.6/site-packages/gpytorch/utils/interpolation.py\", line 183, in left_interp\r\n    output_shape = _matmul_broadcast_shape(interp_shape, rhs.shape)\r\n  File \"/home/neel/miniconda3/envs/DKL/lib/python3.6/site-packages/gpytorch/utils/broadcasting.py\", line 57, in _matmul_broadcast_shape\r\n    bc_shape = _mul_broadcast_shape(batch_shape_a, batch_shape_b)\r\n  File \"/home/neel/miniconda3/envs/DKL/lib/python3.6/site-packages/gpytorch/utils/broadcasting.py\", line 20, in _mul_broadcast_shape\r\n    raise RuntimeError(\"Shapes are not broadcastable for mul operation\")\r\nRuntimeError: Shapes are not broadcastable for mul operation\r\nProcess finished with exit code 137", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1808/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1808/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1807", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1807/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1807/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1807/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1807", "id": 1045712312, "node_id": "I_kwDOBZhSr84-VE24", "number": 1807, "title": "[Bug] Data size dependent RuntimeError when calculating loss for simple ExactGPModel, with \"...please report a bug to PyTorch\"", "user": {"login": "ardilullo", "id": 47837143, "node_id": "MDQ6VXNlcjQ3ODM3MTQz", "avatar_url": "https://avatars.githubusercontent.com/u/47837143?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ardilullo", "html_url": "https://github.com/ardilullo", "followers_url": "https://api.github.com/users/ardilullo/followers", "following_url": "https://api.github.com/users/ardilullo/following{/other_user}", "gists_url": "https://api.github.com/users/ardilullo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ardilullo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ardilullo/subscriptions", "organizations_url": "https://api.github.com/users/ardilullo/orgs", "repos_url": "https://api.github.com/users/ardilullo/repos", "events_url": "https://api.github.com/users/ardilullo/events{/privacy}", "received_events_url": "https://api.github.com/users/ardilullo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-11-05T11:05:17Z", "updated_at": "2023-02-20T12:54:45Z", "closed_at": "2021-11-09T14:09:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\nA script modeled on the ExactGPModel fails with errors thrown in squeeze()/unsqueeze() for some datasets but not others. Tutorial taken from https://docs.gpytorch.ai/en/latest/examples/01_Exact_GPs/Simple_GP_Regression.html#.  Failures also occur for the same data when following https://docs.gpytorch.ai/en/latest/examples/02_Scalable_Exact_GPs/index.html, with errors starting when find_best_gpu_setting() calls train() which calls closure() which calls mll() which eventually lands on squeeze()/unsqueeze().\r\n\r\nData with the following structure works for ExactGPModel\r\ntrain_y.shape = torch.Size([544])\r\ntrain_y.type() = torch.DoubleTensor\r\ntrain_x.shape = torch.Size([544, 42])\r\ntrain_x.type() = torch.DoubleTensor\r\n\r\nData with the following structure returns a runtime error when calculating loss for ExactGPModel\r\ntrain_y.shape = torch.Size([8158])\r\ntrain_y.type() = torch.DoubleTensor\r\ntrain_x.shape = torch.Size([8158, 138])\r\ntrain_x.type() = torch.DoubleTensor\r\n\r\n## To reproduce\r\n\r\n```python\r\n# I'm unable to create a self-contained test for this, and I can not share the failing data.\r\n# This follows the simple tutorial example provided in gpytorch docs\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n# def training_data_import(...):.....\r\n\r\n# training_data_path = .........\r\n# train_x, train_y, test_x, test_y = training_data_import(training_data_path)\r\n\r\ntrain_x = torch.from_numpy(train_x)\r\ntrain_y = torch.from_numpy(train_y)\r\ntest_x = torch.from_numpy(test_x)\r\ntest_y = torch.from_numpy(test_y)\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\r\n\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ntraining_iter = 50\r\nfor i in range(training_iter):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)  # <-- failing here\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\r\n        i + 1, training_iter, loss.item(),\r\n        model.covar_module.base_kernel.lengthscale.item(),\r\n        model.likelihood.noise.item()))\r\n    optimizer.step()\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n/tmp/ipykernel_12934/3384571686.py in <module>\r\n     16     output = model(train_x)\r\n     17     # Calc loss and backprop gradients\r\n---> 18     loss = -mll(output, train_y)\r\n     19     loss.backward()\r\n     20     print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\r\n\r\n/usr/local/lib/python3.8/dist-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     28 \r\n     29     def __call__(self, *inputs, **kwargs):\r\n---> 30         outputs = self.forward(*inputs, **kwargs)\r\n     31         if isinstance(outputs, list):\r\n     32             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n/usr/local/lib/python3.8/dist-packages/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, function_dist, target, *params)\r\n     60         # Get the log prob of the marginal distribution\r\n     61         output = self.likelihood(function_dist, *params)\r\n---> 62         res = output.log_prob(target)\r\n     63         res = self._add_other_terms(res, params)\r\n     64 \r\n\r\n/usr/local/lib/python3.8/dist-packages/gpytorch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    167         # Get log determininant and first part of quadratic form\r\n    168         covar = covar.evaluate_kernel()\r\n--> 169         inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n    170 \r\n    171         res = -0.5 * sum([inv_quad, logdet, diff.size(-1) * math.log(2 * math.pi)])\r\n\r\n/usr/local/lib/python3.8/dist-packages/gpytorch/lazy/lazy_tensor.py in inv_quad_logdet(self, inv_quad_rhs, logdet, reduce_inv_quad)\r\n   1280         func = InvQuadLogDet.apply\r\n   1281 \r\n-> 1282         inv_quad_term, logdet_term = func(\r\n   1283             self.representation_tree(),\r\n   1284             self.dtype,\r\n\r\n/usr/local/lib/python3.8/dist-packages/gpytorch/functions/_inv_quad_log_det.py in forward(ctx, representation_tree, dtype, device, matrix_shape, batch_shape, inv_quad, logdet, probe_vectors, probe_vector_norms, *args)\r\n    155         t_mat = None\r\n    156         if ctx.logdet and settings.skip_logdet_forward.off():\r\n--> 157             solves, t_mat = lazy_tsr._solve(rhs, preconditioner, num_tridiag=num_random_probes)\r\n    158 \r\n    159         else:\r\n\r\n/usr/local/lib/python3.8/dist-packages/gpytorch/lazy/lazy_tensor.py in _solve(self, rhs, preconditioner, num_tridiag)\r\n    656 \r\n    657     def _solve(self, rhs, preconditioner, num_tridiag=0):\r\n--> 658         return utils.linear_cg(\r\n    659             self._matmul,\r\n    660             rhs,\r\n\r\n/usr/local/lib/python3.8/dist-packages/gpytorch/utils/linear_cg.py in linear_cg(matmul_closure, rhs, n_tridiag, tolerance, eps, stop_updating_after, max_iter, max_tridiag_iter, initial_guess, preconditioner)\r\n    172 \r\n    173     # residual: residual_{0} = b_vec - lhs x_{0}\r\n--> 174     residual = rhs - matmul_closure(initial_guess)\r\n    175     batch_shape = residual.shape[:-2]\r\n    176 \r\n\r\n/usr/local/lib/python3.8/dist-packages/gpytorch/lazy/added_diag_lazy_tensor.py in _matmul(self, rhs)\r\n     55 \r\n     56     def _matmul(self, rhs):\r\n---> 57         return torch.addcmul(self._lazy_tensor._matmul(rhs), self._diag_tensor._diag.unsqueeze(-1), rhs)\r\n     58 \r\n     59     def add_diag(self, added_diag):\r\n\r\nRuntimeError: !(has_different_input_dtypes && !config.promote_inputs_to_common_dtype_ && (has_undefined_outputs || config.enforce_safe_casting_to_output_ || config.cast_common_dtype_to_outputs_))INTERNAL ASSERT FAILED at \"../aten/src/ATen/TensorIterator.cpp\":331, please report a bug to PyTorch. \r\n```\r\n\r\n## Expected Behavior\r\n\r\nData processed similarly to working sets should also work without RuntimeError, within reason.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` -->GPyTorch 1.5.1\r\n- <!-- PyTorch Version (run `print(torch.__version__)` -->PyTorch 1.10.0+cu102\r\n- <!-- Computer OS --> OS  CentOS Linux release 7.5.1804 (Core)  ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1807/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1807/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1806", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1806/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1806/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1806/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1806", "id": 1043135495, "node_id": "I_kwDOBZhSr84-LPwH", "number": 1806, "title": "[Bug] High GPU memory consumption of ```ProductKernel``` compared to its equivalent variant", "user": {"login": "patel-zeel", "id": 59758528, "node_id": "MDQ6VXNlcjU5NzU4NTI4", "avatar_url": "https://avatars.githubusercontent.com/u/59758528?v=4", "gravatar_id": "", "url": "https://api.github.com/users/patel-zeel", "html_url": "https://github.com/patel-zeel", "followers_url": "https://api.github.com/users/patel-zeel/followers", "following_url": "https://api.github.com/users/patel-zeel/following{/other_user}", "gists_url": "https://api.github.com/users/patel-zeel/gists{/gist_id}", "starred_url": "https://api.github.com/users/patel-zeel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/patel-zeel/subscriptions", "organizations_url": "https://api.github.com/users/patel-zeel/orgs", "repos_url": "https://api.github.com/users/patel-zeel/repos", "events_url": "https://api.github.com/users/patel-zeel/events{/privacy}", "received_events_url": "https://api.github.com/users/patel-zeel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2021-11-03T06:42:29Z", "updated_at": "2021-11-22T14:06:46Z", "closed_at": "2021-11-08T14:58:19Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nI want to apply different kernels on different dimensions for a specific problem, but, I am running out of GPU memory when using GPyTorch. Narrowing down the problem to its simplest version: \r\n* Using products of multiple ```RBFKernel``` on each dimension takes more GPU memory compared to a single ```RBFKernel``` with ```active_dims``` argument.\r\n* Memory consumption difference increases with more dimensions.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood, kernel):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = kernel\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood().cuda()\r\n\r\nn_observations = 10000\r\ndims = 3\r\n\r\ntrain_x = torch.rand(n_observations, dims).cuda()\r\ntrain_y = (\r\n    torch.sin(train_x[:, 0] * 5)\r\n    + torch.sin(train_x[:, 1] * 10)\r\n    + torch.sin(train_x[:, 2] * 15)\r\n).cuda()\r\n\r\n### Version 1\r\n# K = None\r\n# for i in range(dims):\r\n#     if K is None:\r\n#         K = gpytorch.kernels.RBFKernel(ard_num_dims=1, active_dims=[i])\r\n#     else:\r\n#         K = K * gpytorch.kernels.RBFKernel(ard_num_dims=1, active_dims=[i])\r\n\r\n### Version 2\r\nK = gpytorch.kernels.RBFKernel(ard_num_dims=dims, active_dims=[0, 1, 2])\r\n\r\nmodel = ExactGPModel(\r\n    train_x, train_y, likelihood, kernel=gpytorch.kernels.ScaleKernel(K)\r\n).cuda()\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\r\n\r\ntraining_iter = 100\r\nfor i in range(training_iter):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print(\r\n        i + 1,\r\n        training_iter,\r\n        loss.item(),\r\n        model.covar_module.base_kernel.lengthscale,\r\n        model.likelihood.noise.item(),\r\n    )\r\n    optimizer.step()\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nFor ```### Version 1``` and ```### Version 2``` kernels, GPU should consume the same amount of GPU memory but currently, it consumes 5069 MB for ```### Version 1``` and 3161 MB for ```### Version 2```.\r\n\r\n## System information\r\n\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> GPyTorch 1.5.1\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> PyTorch 1.9.0+cu102\r\n- <!-- Computer OS --> Ubuntu 18.04\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1806/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1806/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1800", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1800/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1800/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1800/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1800", "id": 1036321912, "node_id": "I_kwDOBZhSr849xQR4", "number": 1800, "title": "[Bug] RBF kernel computation wrongly", "user": {"login": "CliffBao", "id": 22443925, "node_id": "MDQ6VXNlcjIyNDQzOTI1", "avatar_url": "https://avatars.githubusercontent.com/u/22443925?v=4", "gravatar_id": "", "url": "https://api.github.com/users/CliffBao", "html_url": "https://github.com/CliffBao", "followers_url": "https://api.github.com/users/CliffBao/followers", "following_url": "https://api.github.com/users/CliffBao/following{/other_user}", "gists_url": "https://api.github.com/users/CliffBao/gists{/gist_id}", "starred_url": "https://api.github.com/users/CliffBao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/CliffBao/subscriptions", "organizations_url": "https://api.github.com/users/CliffBao/orgs", "repos_url": "https://api.github.com/users/CliffBao/repos", "events_url": "https://api.github.com/users/CliffBao/events{/privacy}", "received_events_url": "https://api.github.com/users/CliffBao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-10-26T13:45:29Z", "updated_at": "2021-10-26T23:48:27Z", "closed_at": "2021-10-26T23:48:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nI want to verify the calculation result of RBFKernel while they do not match with matlab result\r\nA simple [3,1] randn tensor.\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nimport gpytorch\r\na=torch.randn(3,1)\r\nker = gpytorch.kernels.RBFKernel()\r\n# I want to view result directly but I can not find a way\r\n# So I matmul an identity matrix\r\nresult = ker(a).matmul(torch.eye(3))\r\n```\r\nwhile in matlab, I simply create a matrix as the a tensor\r\n```\r\ntmp = [0.2342;0.7853;0.7670]\r\ndis=squareform(pdist(tmp));\r\nexp_dis=exp(-0.5*dis.^2)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nexp_dis = \r\n1.0000    0.8591    0.8677\r\n    0.8591    1.0000    0.9998\r\n    0.8677    0.9998    1.0000\r\n\r\nwhile result = \r\ntensor([[1.0000, 0.7290, 0.7442],\r\n        [0.7290, 1.0000, 0.9997],\r\n        [0.7442, 0.9997, 1.0000]], grad_fn=<MatmulBackward>)\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nWhy result is not equal to exp_dis calculated by matlab\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version 1.5.1` -->\r\n- <!-- PyTorch Version 1.7.1` -->\r\n- <!-- Computer OS linux 16.04 -->\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1800/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1800/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1792", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1792/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1792/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1792/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1792", "id": 1033744026, "node_id": "I_kwDOBZhSr849na6a", "number": 1792, "title": "[Bug]Multitask Fully Bayesian GP", "user": {"login": "vcharvet", "id": 25750748, "node_id": "MDQ6VXNlcjI1NzUwNzQ4", "avatar_url": "https://avatars.githubusercontent.com/u/25750748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vcharvet", "html_url": "https://github.com/vcharvet", "followers_url": "https://api.github.com/users/vcharvet/followers", "following_url": "https://api.github.com/users/vcharvet/following{/other_user}", "gists_url": "https://api.github.com/users/vcharvet/gists{/gist_id}", "starred_url": "https://api.github.com/users/vcharvet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vcharvet/subscriptions", "organizations_url": "https://api.github.com/users/vcharvet/orgs", "repos_url": "https://api.github.com/users/vcharvet/repos", "events_url": "https://api.github.com/users/vcharvet/events{/privacy}", "received_events_url": "https://api.github.com/users/vcharvet/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-10-22T16:12:59Z", "updated_at": "2022-04-26T11:02:08Z", "closed_at": "2022-04-26T11:02:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI'm trying to reproduce the Fully Bayesian GP with NUTS sampling for multioutput GP. The training works fine but I can't find a way to make predictions once I load the MCMC samples in the model\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\ntrain_x = torch.linspace(0, 1, 4)[:, None]\r\ntrain_y = torch.cat([\r\n    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n    torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2\r\n],1)\r\nbatch_shape = torch.Size([2])\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=batch_shape)\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(batch_shape=batch_shape),\r\n            batch_shape=batch_shape)\r\n        \r\n    \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\nsmoke_test = ('CI' in os.environ)\r\nnum_samples = 2 if smoke_test else 50\r\nwarmup_steps = 2 if smoke_test else 100\r\n\r\n\r\nfrom gpytorch.priors import LogNormalPrior, NormalPrior, UniformPrior\r\n# Use a positive constraint instead of usual GreaterThan(1e-4) so that LogNormal has support over full range.\r\n# likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.Positive())\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood(\r\n    noise_constraint=gpytorch.constraints.Positive(),\r\n    batch_shape=batch_shape)\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n\r\nmodel.mean_module.register_prior(\"mean_prior\", UniformPrior(-1, 1), \"constant\")\r\nmodel.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\r\nmodel.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\r\nlikelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\r\n\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ndef pyro_model(x, y):\r\n    with gpytorch.settings.fast_computations(False, False, False):\r\n        model.pyro_sample_from_prior()\r\n        output = model.likelihood(model(x))\r\n        pyro.sample(\"obs\", output, obs=y)\r\n    return y\r\n\r\nnuts_kernel = NUTS(pyro_model)\r\nmcmc_run = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=smoke_test)\r\nmcmc_run.run(train_x, train_y.T)\r\n\r\nmodel.pyro_load_from_samples(mcmc_run.get_samples())\r\n\r\nmodel.eval()\r\ntest_x = torch.linspace(0, 1, 101).unsqueeze(-1)\r\n# test_y = torch.sin(test_x * (2 * math.pi))\r\nexpanded_test_x = test_x.unsqueeze(0).repeat(num_samples, 1, 1)\r\noutput = model(expanded_test_x)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-59-3dc71941a8ee> in <module>\r\n      4 # test_y = torch.sin(test_x * (2 * math.pi))\r\n      5 expanded_test_x = test_x.unsqueeze(0).repeat(1, 1, num_samples)\r\n----> 6 output = model(expanded_test_x)\r\n\r\n~/workspace/pythonProjects/.venvs_python37/venv-pilco/lib/python3.7/site-packages/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)\r\n    278             # Get the terms that only depend on training data\r\n    279             if self.prediction_strategy is None:\r\n--> 280                 train_output = super().__call__(*train_inputs, **kwargs)\r\n    281 \r\n    282                 # Create the prediction strategy for\r\n\r\n~/workspace/pythonProjects/.venvs_python37/venv-pilco/lib/python3.7/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n<ipython-input-30-e5ee2e65501e> in forward(self, x)\r\n     13 \r\n     14     def forward(self, x):\r\n---> 15         mean_x = self.mean_module(x)\r\n     16         covar_x = self.covar_module(x)\r\n     17         return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n~/workspace/pythonProjects/.venvs_python37/venv-pilco/lib/python3.7/site-packages/gpytorch/means/mean.py in __call__(self, x)\r\n     20             x = x.unsqueeze(1)\r\n     21 \r\n---> 22         res = super(Mean, self).__call__(x)\r\n     23 \r\n     24         return res\r\n\r\n~/workspace/pythonProjects/.venvs_python37/venv-pilco/lib/python3.7/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/workspace/pythonProjects/.venvs_python37/venv-pilco/lib/python3.7/site-packages/gpytorch/means/constant_mean.py in forward(self, input)\r\n     19             return self.constant.expand(input.shape[:-1])\r\n     20         else:\r\n---> 21             return self.constant.expand(_mul_broadcast_shape(input.shape[:-1], self.constant.shape))\r\n\r\n~/workspace/pythonProjects/.venvs_python37/venv-pilco/lib/python3.7/site-packages/gpytorch/utils/broadcasting.py in _mul_broadcast_shape(error_msg, *shapes)\r\n     18             if any(size != non_singleton_sizes[0] for size in non_singleton_sizes):\r\n     19                 if error_msg is None:\r\n---> 20                     raise RuntimeError(\"Shapes are not broadcastable for mul operation\")\r\n     21                 else:\r\n     22                     raise RuntimeError(error_msg)\r\n\r\nRuntimeError: Shapes are not broadcastable for mul operation\r\n```\r\n\r\n## Expected Behavior\r\nI'd expect the same behaviour as the single output case but I don't see what I am missing.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- PyTorch version 1.9.0\r\n- GPyTorch 1.3.1\r\n- Pyro 1.7.0\r\n- <!-- Computer OS -->\r\n- Ubuntu 20.04\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1792/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1792/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1780", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1780/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1780/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1780/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1780", "id": 1016158826, "node_id": "I_kwDOBZhSr848kVpq", "number": 1780, "title": "[Bug]In the tutorials of SVDKL, an error occurred when I run 'from densenet import DenseNet'", "user": {"login": "wyxwyx46941930", "id": 28503738, "node_id": "MDQ6VXNlcjI4NTAzNzM4", "avatar_url": "https://avatars.githubusercontent.com/u/28503738?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wyxwyx46941930", "html_url": "https://github.com/wyxwyx46941930", "followers_url": "https://api.github.com/users/wyxwyx46941930/followers", "following_url": "https://api.github.com/users/wyxwyx46941930/following{/other_user}", "gists_url": "https://api.github.com/users/wyxwyx46941930/gists{/gist_id}", "starred_url": "https://api.github.com/users/wyxwyx46941930/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wyxwyx46941930/subscriptions", "organizations_url": "https://api.github.com/users/wyxwyx46941930/orgs", "repos_url": "https://api.github.com/users/wyxwyx46941930/repos", "events_url": "https://api.github.com/users/wyxwyx46941930/events{/privacy}", "received_events_url": "https://api.github.com/users/wyxwyx46941930/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-10-05T10:33:43Z", "updated_at": "2021-10-05T12:01:40Z", "closed_at": "2021-10-05T11:43:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "In the tutorials of SVDKL, an error A occurred when I run \"from densenet import DenseNet\". The information of error A is \"No module names densenet\". When I tried to use \"pip install densenet\" to deal with this question, another error B occurred. The information of error B is \"Could not find a version that satisfies the requirement tensorflow==2.0.0-alpha0 (from densenet) (from versions: 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.5.0rc0, 2.5.0rc1, 2.5.0rc2, 2.5.0rc3, 2.5.0, 2.5.1, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0)ERROR: No matching distribution found for tensorflow==2.0.0-alpha0 (from densenet)\r\n\". But I have installed tensorflow==2.4.0 and the densenet in this tutorial should be in pytorch format.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1780/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1780/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1753", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1753/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1753/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1753/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1753", "id": 996552945, "node_id": "I_kwDOBZhSr847ZjDx", "number": 1753, "title": "[Bug] fails to handle over 800 scalar field data (2D data)", "user": {"login": "YangFjur", "id": 29362815, "node_id": "MDQ6VXNlcjI5MzYyODE1", "avatar_url": "https://avatars.githubusercontent.com/u/29362815?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YangFjur", "html_url": "https://github.com/YangFjur", "followers_url": "https://api.github.com/users/YangFjur/followers", "following_url": "https://api.github.com/users/YangFjur/following{/other_user}", "gists_url": "https://api.github.com/users/YangFjur/gists{/gist_id}", "starred_url": "https://api.github.com/users/YangFjur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YangFjur/subscriptions", "organizations_url": "https://api.github.com/users/YangFjur/orgs", "repos_url": "https://api.github.com/users/YangFjur/repos", "events_url": "https://api.github.com/users/YangFjur/events{/privacy}", "received_events_url": "https://api.github.com/users/YangFjur/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-09-15T00:52:09Z", "updated_at": "2021-10-07T09:29:05Z", "closed_at": "2021-10-07T09:29:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport loadData as ld\r\nimport numpy as np\r\nimport torch\r\nimport gpytorch\r\nimport matplotlib.pyplot as plt\r\n\r\n#  load trainning raw data      \r\n    hdrfile = 'data/ontario_clip4.hdr'\r\n    fltfile = 'data/ontario_clip4.flt'\r\n    nx,ny,xmin,ymin,dx,xmax,ymax,rawData = ld.loadDSMData(hdrfile,fltfile)\r\n    training_iter = 1600\r\n\r\n# rawData is ndarray \r\n\r\n    x = np.linspace(xmin,xmax,int(nx))\r\n    y = np.linspace(ymin,ymax,int(ny))\r\n    \r\n    xv,yv = np.meshgrid(x,y)\r\n    xv_ = xv.reshape(-1,1)\r\n    yv_ = yv.reshape(-1,1)  \r\n\r\n    X = np.concatenate((xv_,yv_),axis=1)\r\n    Y = rawData.reshape(-1,1)\r\n    \r\n    # trainning data, which is selected from rawData\r\n    num_sample = 900\r\n    inds = np.random.randint(low=0,high=Y.size,size=num_sample)\r\n    train_x = torch.from_numpy(X[inds,:])\r\n    train_y = torch.from_numpy(Y[inds].squeeze())\r\n\r\n# model setting\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n    model = ExactGPModel(train_x, train_y, likelihood)\r\n\r\n    # train model\r\n    model.train()\r\n    likelihood.train()\r\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n    \r\n    for i in range(training_iter):\r\n        # Zero gradients from previous iteration\r\n        optimizer.zero_grad()\r\n        # Output from model\r\n        output = model(train_x)\r\n        # Calc loss and backprop gradients\r\n        loss = -mll(output, train_y)\r\n        loss.backward()\r\n        print('Iter%d/%d-Loss:%.3flengthscale:%.3fnoise:%.3f'%(i + 1, training_iter, loss.item(),model.covar_module.base_kernel.lengthscale.item(),model.likelihood.noise.item()))\r\n        optimizer.step()\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n// Exception has occurred: RuntimeError       (note: full exception trace is shown but execution is paused at: _run_module_as_main)\r\nFound dtype Float but expected Double\r\n  File \"/home/l1yang/anaconda3/envs/multiagent/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\", line 57, in _matmul\r\n    return torch.addcmul(self._lazy_tensor._matmul(rhs), self._diag_tensor._diag.unsqueeze(-1), rhs)\r\n  File \"/home/l1yang/anaconda3/envs/multiagent/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py\", line 174, in linear_cg\r\n    residual = rhs - matmul_closure(initial_guess)\r\n  File \"/home/l1yang/anaconda3/envs/multiagent/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\", line 658, in _solve\r\n    return utils.linear_cg(\r\n  File \"/home/l1yang/anaconda3/envs/multiagent/lib/python3.8/site-packages/gpytorch/functions/_inv_quad_log_det.py\", line 157, in forward\r\n    solves, t_mat = lazy_tsr._solve(rhs, preconditioner, num_tridiag=num_random_probes)\r\n  File \"/home/l1yang/anaconda3/envs/multiagent/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\", line 1282, in inv_quad_logdet\r\n    inv_quad_term, logdet_term = func(\r\n  File \"/home/l1yang/anaconda3/envs/multiagent/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\", line 169, in log_prob\r\n    inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n  File \"/home/l1yang/anaconda3/envs/multiagent/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\", line 62, in forward\r\n    res = output.log_prob(target)\r\n  File \"/home/l1yang/anaconda3/envs/multiagent/lib/python3.8/site-packages/gpytorch/module.py\", line 30, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/l1yang/gitreposity/gpy_demo/demo_gpy_regression.py\", line 61, in demo2D\r\n    loss = -mll(output, train_y)\r\n  File \"/home/l1yang/gitreposity/gpy_demo/demo_gpy_regression.py\", line 106, in <module>\r\n    demo2D()\r\n  File \"/home/l1yang/anaconda3/envs/multiagent/lib/python3.8/runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/l1yang/anaconda3/envs/multiagent/lib/python3.8/runpy.py\", line 97, in _run_module_code\r\n    _run_code(code, mod_globals, init_globals,\r\n  File \"/home/l1yang/anaconda3/envs/multiagent/lib/python3.8/runpy.py\", line 265, in run_path\r\n    return _run_module_code(code, init_globals, run_name,\r\n  File \"/home/l1yang/anaconda3/envs/multiagent/lib/python3.8/runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n```\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> gpytorch 1.5.1\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> torch 1.9.0\r\n- <!-- Computer OS --> ubuntu20.04 LTS, gpu gtx165, gcc 9.3.0\r\n\r\n## Additional context\r\nAll is okey when number of trainning data is less than 800 exactly, but fails when >800.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1753/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1753/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1736", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1736/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1736/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1736/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1736", "id": 977562355, "node_id": "MDU6SXNzdWU5Nzc1NjIzNTU=", "number": 1736, "title": "[Bug] `python setup.py test` fails", "user": {"login": "samuela", "id": 226872, "node_id": "MDQ6VXNlcjIyNjg3Mg==", "avatar_url": "https://avatars.githubusercontent.com/u/226872?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samuela", "html_url": "https://github.com/samuela", "followers_url": "https://api.github.com/users/samuela/followers", "following_url": "https://api.github.com/users/samuela/following{/other_user}", "gists_url": "https://api.github.com/users/samuela/gists{/gist_id}", "starred_url": "https://api.github.com/users/samuela/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samuela/subscriptions", "organizations_url": "https://api.github.com/users/samuela/orgs", "repos_url": "https://api.github.com/users/samuela/repos", "events_url": "https://api.github.com/users/samuela/events{/privacy}", "received_events_url": "https://api.github.com/users/samuela/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-08-23T23:29:42Z", "updated_at": "2021-08-31T13:27:08Z", "closed_at": "2021-08-31T13:27:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nThe setuptools tests are broken. I discovered this while packaging for Nix, but presumably the same failure could be seen via `python setup.py test`.\r\n\r\n## To reproduce\r\nI'm building via Nix, but everything should be the same without Nix as well. Here's my full derivation:\r\n```nix\r\n{ buildPythonPackage, fetchPypi, lib\r\n, pytorch, scikit-learn\r\n}:\r\n\r\nbuildPythonPackage rec {\r\n  pname = \"gpytorch\";\r\n  version = \"1.5.0\";\r\n\r\n  src = fetchPypi {\r\n    inherit pname version;\r\n    sha256 = \"sha256:0xijni7pavyv5hx42qcnglp3l0mbdz719jv4pm7a0cfk6fhr6hag\";\r\n  };\r\n\r\n  # pip dependencies\r\n  propagatedBuildInputs = [ pytorch scikit-learn ];\r\n\r\n  pythonImportsCheck = [ \"gpytorch\" ];\r\n\r\n  meta = with lib; {\r\n    description = \"An implementation of Gaussian Processes in Pytorch\";\r\n    homepage    = \"https://gpytorch.ai/\";\r\n    license     = licenses.mit;\r\n    maintainers = with maintainers; [ samuela ];\r\n  };\r\n}\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nsetuptoolsCheckPhase\r\nExecuting setuptoolsCheckPhase\r\nrunning test\r\nWARNING: Testing via this command is deprecated and will be removed in a future version. Users looking for a generic test entry point independent of test runner are encouraged to use tox.\r\nrunning egg_info\r\nwriting gpytorch.egg-info/PKG-INFO\r\nwriting dependency_links to gpytorch.egg-info/dependency_links.txt\r\nwriting requirements to gpytorch.egg-info/requires.txt\r\nwriting top-level names to gpytorch.egg-info/top_level.txt\r\nreading manifest file 'gpytorch.egg-info/SOURCES.txt'\r\nwriting manifest file 'gpytorch.egg-info/SOURCES.txt'\r\nrunning build_ext\r\nTraceback (most recent call last):\r\n  File \"/build/gpytorch-1.5.0/nix_run_setup\", line 8, in <module>\r\n    exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\\\\r\\\\n', '\\\\n'), __file__, 'exec'))\r\n  File \"setup.py\", line 41, in <module>\r\n    setup(\r\n  File \"/nix/store/cr08vgmnr3qvdxmrifshnv0xd336w0ah-python3.9-setuptools-57.2.0/lib/python3.9/site-packages/setuptools/__init__.py\", line 153, in setup\r\n    return distutils.core.setup(**attrs)\r\n  File \"/nix/store/nki9ywqzbvz68vr75kn2r7g1q84f5agy-python3-3.9.6/lib/python3.9/distutils/core.py\", line 148, in setup\r\n    dist.run_commands()\r\n  File \"/nix/store/nki9ywqzbvz68vr75kn2r7g1q84f5agy-python3-3.9.6/lib/python3.9/distutils/dist.py\", line 966, in run_commands\r\n    self.run_command(cmd)\r\n  File \"/nix/store/nki9ywqzbvz68vr75kn2r7g1q84f5agy-python3-3.9.6/lib/python3.9/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/nix/store/cr08vgmnr3qvdxmrifshnv0xd336w0ah-python3.9-setuptools-57.2.0/lib/python3.9/site-packages/setuptools/command/test.py\", line 232, in run\r\n    self.run_tests()\r\n  File \"/nix/store/cr08vgmnr3qvdxmrifshnv0xd336w0ah-python3.9-setuptools-57.2.0/lib/python3.9/site-packages/setuptools/command/test.py\", line 250, in run_tests\r\n    test = unittest.main(\r\n  File \"/nix/store/nki9ywqzbvz68vr75kn2r7g1q84f5agy-python3-3.9.6/lib/python3.9/unittest/main.py\", line 100, in __init__\r\n    self.parseArgs(argv)\r\n  File \"/nix/store/nki9ywqzbvz68vr75kn2r7g1q84f5agy-python3-3.9.6/lib/python3.9/unittest/main.py\", line 124, in parseArgs\r\n    self._do_discovery(argv[2:])\r\n  File \"/nix/store/nki9ywqzbvz68vr75kn2r7g1q84f5agy-python3-3.9.6/lib/python3.9/unittest/main.py\", line 244, in _do_discovery\r\n    self.createTests(from_discovery=True, Loader=Loader)\r\n  File \"/nix/store/nki9ywqzbvz68vr75kn2r7g1q84f5agy-python3-3.9.6/lib/python3.9/unittest/main.py\", line 154, in createTests\r\n    self.test = loader.discover(self.start, self.pattern, self.top)\r\n  File \"/nix/store/nki9ywqzbvz68vr75kn2r7g1q84f5agy-python3-3.9.6/lib/python3.9/unittest/loader.py\", line 349, in discover\r\n    tests = list(self._find_tests(start_dir, pattern))\r\n  File \"/nix/store/nki9ywqzbvz68vr75kn2r7g1q84f5agy-python3-3.9.6/lib/python3.9/unittest/loader.py\", line 405, in _find_tests\r\n    tests, should_recurse = self._find_test_path(\r\n  File \"/nix/store/nki9ywqzbvz68vr75kn2r7g1q84f5agy-python3-3.9.6/lib/python3.9/unittest/loader.py\", line 483, in _find_test_path\r\n    tests = self.loadTestsFromModule(package, pattern=pattern)\r\n  File \"/nix/store/cr08vgmnr3qvdxmrifshnv0xd336w0ah-python3.9-setuptools-57.2.0/lib/python3.9/site-packages/setuptools/command/test.py\", line 50, in loadTestsFromModule\r\n    tests.append(self.loadTestsFromName(submodule))\r\n  File \"/nix/store/nki9ywqzbvz68vr75kn2r7g1q84f5agy-python3-3.9.6/lib/python3.9/unittest/loader.py\", line 191, in loadTestsFromName\r\n    return self.loadTestsFromModule(obj)\r\n  File \"/nix/store/cr08vgmnr3qvdxmrifshnv0xd336w0ah-python3.9-setuptools-57.2.0/lib/python3.9/site-packages/setuptools/command/test.py\", line 50, in loadTestsFromModule\r\n    tests.append(self.loadTestsFromName(submodule))\r\n  File \"/nix/store/nki9ywqzbvz68vr75kn2r7g1q84f5agy-python3-3.9.6/lib/python3.9/unittest/loader.py\", line 205, in loadTestsFromName\r\n    test = obj()\r\nTypeError: contour_integral_quad() missing 2 required positional arguments: 'lazy_tensor' and 'rhs'\r\nbuilder for '/nix/store/fvynsjqnl9x7ak0b6c5g74k3n1c1k78m-python3.9-gpytorch-1.5.0.drv' failed with exit code 1\r\nerror: build of '/nix/store/fvynsjqnl9x7ak0b6c5g74k3n1c1k78m-python3.9-gpytorch-1.5.0.drv' failed\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThe test suite to pass.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch 1.5.0\r\n- pytorch 1.6.0\r\n- NixOS 20.09.3301.42809feaa9f\r\n\r\n## Additional context\r\nn/a", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1736/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1736/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1730", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1730/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1730/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1730/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1730", "id": 973701467, "node_id": "MDU6SXNzdWU5NzM3MDE0Njc=", "number": 1730, "title": "[Bug] Double on a LazyTensor assigns entire representation as double", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-08-18T14:01:49Z", "updated_at": "2021-08-23T20:47:07Z", "closed_at": "2021-08-23T20:47:07Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThis will apply to #1726 as well.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nfrom gpytorch.kernels import MaternKernel\r\n\r\nx = torch.randn(20,1)\r\nkernel = MaternKernel()\r\nkernel.lengthscale.dtype # torch.float32\r\n\r\ndkernel = kernel(x).double()\r\ndkernel.dtype #torch.float64 \r\n\r\nkernel.lengthscale.dtype # torch.float64 \r\n```\r\n\r\nNo real error, but this is unexpected error and can cause issues downstream.\r\n\r\n## Expected Behavior\r\n\r\nthe kernel's lengthscale should have stayed in float, not double.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\ngpytorch master\r\n\r\n## Additional context\r\nI'll try to put up a PR bc it's closely related to #1726.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1730/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1730/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1723", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1723/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1723/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1723/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1723", "id": 968428316, "node_id": "MDU6SXNzdWU5Njg0MjgzMTY=", "number": 1723, "title": "Don't know how to simply set the prior mean in GP", "user": {"login": "SyngnathZ", "id": 54241614, "node_id": "MDQ6VXNlcjU0MjQxNjE0", "avatar_url": "https://avatars.githubusercontent.com/u/54241614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SyngnathZ", "html_url": "https://github.com/SyngnathZ", "followers_url": "https://api.github.com/users/SyngnathZ/followers", "following_url": "https://api.github.com/users/SyngnathZ/following{/other_user}", "gists_url": "https://api.github.com/users/SyngnathZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/SyngnathZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SyngnathZ/subscriptions", "organizations_url": "https://api.github.com/users/SyngnathZ/orgs", "repos_url": "https://api.github.com/users/SyngnathZ/repos", "events_url": "https://api.github.com/users/SyngnathZ/events{/privacy}", "received_events_url": "https://api.github.com/users/SyngnathZ/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-08-12T09:20:22Z", "updated_at": "2021-08-18T13:43:35Z", "closed_at": "2021-08-18T13:43:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "## My code\r\n\r\n```python\r\nclass ExactGPModel(models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.mean_module.register_prior(\"mean_prior\", gpytorch.priors.NormalPrior(1.0, 1), \"constant\")\r\n        self.mean_module.train(False)\r\n        RBF = gpytorch.kernels.RBFKernel()\r\n        RBF.initialize(lengthscale=xyz_range * 0.04)\r\n        self.covar_module = RBF\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return distr.MultivariateNormal(mean_x, covar_x)\r\n\r\n     ......\r\n\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n    model = ExactGPModel(train_X, train_y, likelihood)\r\n\r\n    # Get into evaluation (predictive posterior) mode\r\n    model.eval()\r\n    likelihood.eval()\r\n\r\n    test_X_torch = torch.Tensor(test_X)\r\n    f_preds = model(test_X_torch)\r\n    mu = f_preds.mean\r\n\r\n    mu_num = mu.detach().numpy()\r\n```\r\n\r\nAnd the **model.mean_module.mean_prior.mean = tensor(1.)**\r\nBut I cannot get a reasonable output cause the prior mean is not taking effect.\r\n\r\n```\r\nmu_num: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0., 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0., 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0., 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. .......]\r\n```\r\nMy training set train_X is a **3D coordinate** (x,y,z) , train_Y is 0 (which means it is on the object at that 3D coordinate), and when y=1 it means it is not on the object, so I need the a priori mean to be all 1 (Because all the points are not on the object at the beginning, and I will gradually put the 3D coordinates on the object to train this Gaussian process).\r\n\r\nSo when I put in some training set with y=0, mu_num should be **between 0 and 1**, and there should be a lot of 1, but it can't be all 0, which can only mean that the a priori mean value is not set successfully.\r\n\r\n## Additional context\r\nThe procedure I want to implement is the same as the function shown below (setting the m), by setting the a priori mean value to achieve the function I described above.\r\n```python\r\n    def predict(self, X):\r\n        if not self.is_fit:\r\n            print(\"GPR Model not fit yet.\")\r\n            return\r\n\r\n        X = np.asarray(X)\r\n        Kff = self.kernel(self.train_X, self.train_X)  # (N, N)\r\n        Kyy = self.kernel(X, X)  # (k, k)\r\n        Kfy = self.kernel(self.train_X, X)  # (N, k)\r\n        Kff_inv = np.linalg.inv(Kff + 1e-8 * np.eye(len(self.train_X)))  # (N, N)\r\n\r\n        m = 1 # set the prior mean\r\n        mu = m + Kfy.T.dot(Kff_inv).dot(self.train_y - m)\r\n        cov = Kyy - Kfy.T.dot(Kff_inv).dot(Kfy)\r\n        return mu, cov\r\n```\r\nSo how should I modify my code to implement the above process? Thanks!", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1723/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1723/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1720", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1720/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1720/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1720/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1720", "id": 965483515, "node_id": "MDU6SXNzdWU5NjU0ODM1MTU=", "number": 1720, "title": "[Bug] ScaleKernel error with pyro sampling", "user": {"login": "npbaskerville", "id": 37937341, "node_id": "MDQ6VXNlcjM3OTM3MzQx", "avatar_url": "https://avatars.githubusercontent.com/u/37937341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/npbaskerville", "html_url": "https://github.com/npbaskerville", "followers_url": "https://api.github.com/users/npbaskerville/followers", "following_url": "https://api.github.com/users/npbaskerville/following{/other_user}", "gists_url": "https://api.github.com/users/npbaskerville/gists{/gist_id}", "starred_url": "https://api.github.com/users/npbaskerville/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/npbaskerville/subscriptions", "organizations_url": "https://api.github.com/users/npbaskerville/orgs", "repos_url": "https://api.github.com/users/npbaskerville/repos", "events_url": "https://api.github.com/users/npbaskerville/events{/privacy}", "received_events_url": "https://api.github.com/users/npbaskerville/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-08-10T22:32:15Z", "updated_at": "2021-08-31T15:38:16Z", "closed_at": "2021-08-31T15:38:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen using a `ScaleKernel` composed with `LinearKernel` and using pyro for Bayesian inference over the `ScaleKernel` constant, there is an error inside `RootLazyTensor` method `_mul_constant` due to a check on the sign of the constant. \r\n\r\n## To reproduce\r\n\r\n```python\r\nimport math\r\n\r\nimport pyro\r\nfrom pyro.infer.mcmc import NUTS, MCMC\r\nimport torch\r\n\r\nimport gpytorch\r\nfrom gpytorch.priors import UniformPrior\r\n\r\n# Training data is 11 points in [0,1] inclusive regularly spaced\r\ntrain_x = torch.linspace(0, 1, 6)\r\n# True function is sin(2*pi*x) with Gaussian noise\r\ntrain_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2\r\n\r\n# Set this to get the error, or turn it off to show that the error is specific to constant x linear.\r\nlinear = True\r\n\r\n\r\n# We will use the simplest form of GP model, exact inference\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        inner_kernel = gpytorch.kernels.LinearKernel() if linear else gpytorch.kernels.RBFKernel()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(inner_kernel)\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\nnum_samples = 2\r\nwarmup_steps = 2\r\n\r\n# Use a positive constraint instead of usual GreaterThan(1e-4) so that LogNormal has support over full range.\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.Positive())\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n\r\nmodel.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\r\n\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\n\r\ndef pyro_model(x, y):\r\n    sampled_model = model.pyro_sample_from_prior()\r\n    output = sampled_model.likelihood(sampled_model(x))\r\n    pyro.sample(\"obs\", output, obs=y)\r\n\r\n\r\nnuts_kernel = pyro.infer.mcmc.NUTS(pyro_model)\r\nmcmc_run = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=True)\r\nmcmc_run.run(train_x, train_y)\r\n\r\n\r\nmodel.pyro_load_from_samples(mcmc_run.get_samples())\r\n\r\n\r\nmodel.eval()\r\ntest_x = torch.linspace(0, 1, 101).unsqueeze(-1)\r\ntest_y = torch.sin(test_x * (2 * math.pi))\r\nexpanded_test_x = test_x.unsqueeze(0).repeat(num_samples, 1, 1)\r\n\r\n# error on this line\r\noutput = model(expanded_test_x)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/nicholasbaskerville/Library/Application Support/JetBrains/PyCharmCE2021.1/scratches/scratch_1.py\", line 63, in <module>\r\n    output = model(expanded_test_x)\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/models/exact_gp.py\", line 319, in __call__\r\n    predictive_mean, predictive_covar = self.prediction_strategy.exact_prediction(full_mean, full_covar)\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 262, in exact_prediction\r\n    self.exact_predictive_mean(test_mean, test_train_covar),\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 280, in exact_predictive_mean\r\n    res = (test_train_covar @ self.mean_cache.unsqueeze(-1)).squeeze(-1)\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/utils/memoize.py\", line 59, in g\r\n    return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 229, in mean_cache\r\n    mean_cache = train_train_covar.evaluate_kernel().inv_matmul(train_labels_offset).squeeze(-1)\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/lazy/added_diag_lazy_tensor.py\", line 187, in evaluate_kernel\r\n    added_diag_lazy_tsr = self.representation_tree()(*self.representation())\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 1513, in representation_tree\r\n    return LazyTensorRepresentationTree(self)\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/lazy/lazy_tensor_representation_tree.py\", line 13, in __init__\r\n    representation_size = len(arg.representation())\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 317, in representation\r\n    return self.evaluate_kernel().representation()\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/utils/memoize.py\", line 59, in g\r\n    return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 284, in evaluate_kernel\r\n    res = self.kernel(x1, x2, diag=False, last_dim_is_batch=self.last_dim_is_batch, **self.params)\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/kernels/kernel.py\", line 398, in __call__\r\n    res = lazify(super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/module.py\", line 30, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/kernels/scale_kernel.py\", line 101, in forward\r\n    return orig_output.mul(outputscales)\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 1377, in mul\r\n    return self._mul_constant(other.view(*other.shape[:-2]))\r\n  File \"/Users/nicholasbaskerville/Documents/gpytorch/gpytorch/lazy/root_lazy_tensor.py\", line 59, in _mul_constant\r\n    if constant > 0:\r\nRuntimeError: Boolean value of Tensor with more than one value is ambiguous```\r\n\r\n## Expected Behavior\r\n\r\nForward pass through the model after loading pyro samples should be succesful rather than throwing an error, as it is when using a scaled RBF, for example.\r\n\r\n\r\n## System information\r\n\r\nGPyTorch Version: 1.5.0\r\nPyTorch Version: 1.9.0\r\nComputer OS: Mac OS Big Sur 11.4", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1720/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1720/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1713", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1713/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1713/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1713/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1713", "id": 955158535, "node_id": "MDU6SXNzdWU5NTUxNTg1MzU=", "number": 1713, "title": "[Bug] stable_pinverse fails when not full column rank", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-07-28T19:12:19Z", "updated_at": "2021-07-28T19:29:27Z", "closed_at": "2021-07-28T19:29:27Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n`stable_pinverse` fails if some columns are exactly zero. \r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nfrom gpytorch.utils import stable_qr, stable_pinverse\r\n\r\nA = torch.randn(30, 5)\r\nA = torch.cat((A, torch.zeros(30, 25)), dim=-1)\r\n\r\nstable_pinverse(A) \r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n~/Documents/GitHub/wjm_gpytorch/gpytorch/utils/pinverse.py in stable_pinverse(A)\r\n     13         # skinny (or square) matrix\r\n     14         Q, R = stable_qr(A)\r\n---> 15         return torch.triangular_solve(Q.transpose(-1, -2), R).solution\r\n     16     else:\r\n     17         # fat matrix\r\n\r\nRuntimeError: triangular_solve_cpu: U(6,6) is zero, singular U.\r\n```\r\n\r\n## Expected Behavior\r\n\r\nWhat's happening is that the jittering in stable_qr doesn't work if the diagonals are exactly zero (torch.sign returns zero)\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch master\r\n- pytorch 1.8.1\r\n\r\n## Additional context\r\n\r\nWill put up a fix for stable_qr\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1713/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1713/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1711", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1711/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1711/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1711/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1711", "id": 954165107, "node_id": "MDU6SXNzdWU5NTQxNjUxMDc=", "number": 1711, "title": "[Bug] Cat_rows evaluation fails to capture correct device", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-07-27T18:38:25Z", "updated_at": "2021-07-28T01:23:09Z", "closed_at": "2021-07-28T01:23:09Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nEvaluating `LazyTensor.cat_rows` on the gpu returns a cpu tensor.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nfrom gpytorch.kernels import MaternKernel\r\nimport torch\r\n\r\nx = torch.randn(10, 3).cuda()\r\ny = torch.randn(5, 3).cuda()\r\n\r\nkernel = MaternKernel().cuda()\r\n\r\nkxx = kernel(x)\r\nkxy = kernel(y, x)\r\nkyy = kernel(y)\r\n\r\njoint_covariance = kxx.cat_rows(kxy, kyy)\r\njoint_covariance.matmul(torch.randn(15, 3).cuda()).device # on the gpu properly\r\njoint_covariance.evaluate().device # returns cpu\r\n```\r\n\r\n** Stack trace/error message **\r\nSee above. It's a missing device_id argument in the CatLazyTensor calls.\r\n\r\n## Expected Behavior\r\n\r\nreturns on the gpu. \r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch master\r\n\r\n## Additional context\r\nI'll put up a PR shortly. I think that this is causing the test failures in https://github.com/pytorch/botorch/pull/883\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1711/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1711/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1693", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1693/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1693/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1693/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1693", "id": 941108705, "node_id": "MDU6SXNzdWU5NDExMDg3MDU=", "number": 1693, "title": "[Bug]", "user": {"login": "mkishinev", "id": 34379276, "node_id": "MDQ6VXNlcjM0Mzc5Mjc2", "avatar_url": "https://avatars.githubusercontent.com/u/34379276?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mkishinev", "html_url": "https://github.com/mkishinev", "followers_url": "https://api.github.com/users/mkishinev/followers", "following_url": "https://api.github.com/users/mkishinev/following{/other_user}", "gists_url": "https://api.github.com/users/mkishinev/gists{/gist_id}", "starred_url": "https://api.github.com/users/mkishinev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mkishinev/subscriptions", "organizations_url": "https://api.github.com/users/mkishinev/orgs", "repos_url": "https://api.github.com/users/mkishinev/repos", "events_url": "https://api.github.com/users/mkishinev/events{/privacy}", "received_events_url": "https://api.github.com/users/mkishinev/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-07-09T22:55:16Z", "updated_at": "2021-07-13T21:39:39Z", "closed_at": "2021-07-13T16:06:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nThe Spectral Mixture kernel as used in the tutorial https://docs.gpytorch.ai/en/latest/examples/01_Exact_GPs/Spectral_Mixture_GP_Regression.html \r\nhas non-deterministic behavior (i.e. run-to-run variations).\r\n\r\nIf the notebook runs twice from scratch (i.e. restart the kernel and run all) we see \r\n* first run:\r\n  Iter 1/100 - Loss: 1.272\r\n  ...\r\n  Iter 100/100 - Loss: -2.424\r\n\r\n* second run:\r\n  Iter 1/100 - Loss: 1.274\r\n  ...\r\n  Iter 100/100 - Loss: -1.203\r\n\r\nSimilar on other examples with this kernel. The Matern kernel does not have run-to-run variations.\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nDeterministic behavior (as an option) e.g. by propagating a fixed random seed as an input parameter to initialize functions that are responsible for the non-determinism.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> gpytorch version:  1.4.2\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> torch version:  1.9.0+cpu\r\n- <!-- Computer OS --> Windows 10\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1693/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1693/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1689", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1689/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1689/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1689/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1689", "id": 939868753, "node_id": "MDU6SXNzdWU5Mzk4Njg3NTM=", "number": 1689, "title": "[Bug] Possible inconsistency in exact multitask modeling results between GPyTorch versions 1.4.1 and 1.5.0", "user": {"login": "lucheroni", "id": 60316215, "node_id": "MDQ6VXNlcjYwMzE2MjE1", "avatar_url": "https://avatars.githubusercontent.com/u/60316215?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucheroni", "html_url": "https://github.com/lucheroni", "followers_url": "https://api.github.com/users/lucheroni/followers", "following_url": "https://api.github.com/users/lucheroni/following{/other_user}", "gists_url": "https://api.github.com/users/lucheroni/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucheroni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucheroni/subscriptions", "organizations_url": "https://api.github.com/users/lucheroni/orgs", "repos_url": "https://api.github.com/users/lucheroni/repos", "events_url": "https://api.github.com/users/lucheroni/events{/privacy}", "received_events_url": "https://api.github.com/users/lucheroni/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2021-07-08T13:36:33Z", "updated_at": "2021-07-13T15:09:01Z", "closed_at": "2021-07-13T15:09:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nAfter I upgraded from GPyTorch version 1.4.1 to version 1.5.0, I noticed that I\r\nget two very different results when I run the same program under the two versions.\r\nThis program makes use of the exact multitask setup. From it, I can get differences in loss values up to an order 100.\r\nNotice that I think that the problem is related only to the exact multitask classes. I made some quick tests with the single task case too, and I got no problem in that case.\r\n\r\nIt is not easy to prepare a code snippet to reproduce the problem, but I'll try. This is because each time the model is instantiated there are some parameters that are initialized randomly.  \r\nWhereas v. 1.4.1 doesn't allow to initialize parameters in the exact multitask case (an error which was eliminated in v. 1.5.0), v. 1.5.0 does. \r\n\r\nConsider that before upgrading I took a safety copy of my conda environment. Hence I have available both my original env with v. 1.4.1 and a clone env of it with v. 1.5.0 as the only difference (I checked during the update that 'conda install -c conda-forge gpytorch' didn't change anything else except gpytorch itself).\r\n\r\nThe code hereafter should be run as follows. I'm having in mind that the test is made under Spyder. \r\nPrepare the two environments, identical except for gpytorch versions.\r\n\r\nFirst, choose the appropriate v. 1.4.1 python interpreter from Tools, start a console,\r\nand run the code in it. Note down the values of cf and rw - these will be inserted 'by hand' when running the other version. Note down the loss value.\r\nSecond, switch to the v. 1.5.1 interpreter (both by loading a suitable kernel and starting another console). Run the code. Note down the loss value.\r\n\r\nI tried a few times, and I got always different values, of the same order of magnitude.\r\n\r\nThe example proposed is very small, just two tasks, one latent gp, and one basic one-parameter kernel type. Cf and rw are the only parameters that get random initialization. \r\nIn my own program the tasks are 24, the latents are 24, the kernels are complicated and computation time is large. This is probably the reason why I get those huge differences. I also noticed that the larger is the numer of time points, the larger is the error. This is why I chose an example with six time points at least.\r\n\r\n\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n# test for the difference in behavior \r\n# for the Exact MULTI-TASK case\r\n# between gpytorch ver. 1.4.1 and 1.5.0\r\n\r\nimport torch\r\nimport gpytorch\r\n\r\nclass MultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\r\n        \r\n        self.mean_module = gpytorch.means.MultitaskMean(\r\n            gpytorch.means.ConstantMean(), num_tasks=num_tasks\r\n        )\r\n        \r\n        ker = gpytorch.kernels.RBFKernel()\r\n                                                                         \r\n        self.covar_module = gpytorch.kernels.LCMKernel(\r\n            [ker for _ in range(num_latents)],            \r\n            num_tasks=num_tasks, rank=rank            )\r\n                                                               \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        \r\n        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\r\n\r\n\r\nrank = 1\r\nnum_tasks = 2\r\nnum_latents = 1\r\n\r\n# 2 time points\r\ntrain_x = torch.linspace(0, 1, 6)\r\n\r\n# 2 tasks \r\ntrain_y = torch.stack([\r\n            torch.tensor([1,2,1,2,1,2]), torch.tensor([2,2,2,2,2,2])\r\n                      ])\r\n\r\ntorch.set_printoptions(threshold=10_000)\r\n\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=num_tasks)\r\nmodel = MultitaskGPModel(train_x, train_y, likelihood)\r\n\r\n# every parameter is set to zero \r\n# except covar_factor and raw_var \r\n#for name, param in model.named_parameters():\r\n#    if param.requires_grad:\r\n#        print(name,param)\r\n#for name, param in likelihood.named_parameters():\r\n#    if param.requires_grad:\r\n#        print(name,param)\r\n\r\n\r\nversion = gpytorch.__version__\r\n\r\nif version == '1.4.1': \r\n    cf_141 = model.covar_module.covar_module_list[0].task_covar_module.covar_factor.detach() \r\n    rv_141 = model.covar_module.covar_module_list[0].task_covar_module.raw_var.detach()                   \r\n    #\r\n    print('cf = ', cf_141.flatten()) #  tensor([-0.0007,  0.0964])\r\n    print('rv = ', rv_141.flatten()) #  tensor([2.5536, 2.3405])\r\n    print('note down these values')\r\n\r\n\r\nif version == '1.5.0':\r\n    hypers = {\r\n        'covar_module.covar_module_list.0.task_covar_module.covar_factor': torch.tensor([-1.3655,  2.8571]),\r\n        'covar_module.covar_module_list.0.task_covar_module.raw_var': torch.tensor([ 0.0093, -1.8867])\r\n             }\r\n    # works only with 1.5.0\r\n    model.initialize(**hypers)\r\n    #\r\n    print('parameters reinitialized')\r\n\r\n# check\r\n#for name, param in model.named_parameters():\r\n#    if param.requires_grad:\r\n#        print(name,param)  \r\n\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\n# in case, check all values\r\nif False:\r\n# all parameters:\r\n# all zero\r\n    mll.likelihood.raw_task_noises\r\n    mll.likelihood.raw_noise\r\n# all zero\r\n    mll.model.likelihood.raw_task_noises\r\n    mll.model.likelihood.raw_noise\r\n# all zero\r\n    mll.model.mean_module.base_means[0].constant\r\n    mll.model.mean_module.base_means[1].constant\r\n# these are not zero\r\n    mll.model.covar_module.covar_module_list[0].task_covar_module.covar_factor\r\n    mll.model.covar_module.covar_module_list[0].task_covar_module.raw_var\r\n# this is zero\r\n    mll.model.covar_module.covar_module_list[0].data_covar_module.raw_lengthscale\r\n\r\n\r\noutput = model(train_x)\r\nloss = -mll(output, train_y) \r\n#\r\nprint(gpytorch.__version__) # 1.4.1 , 1.5.0\r\nprint(loss.item())  # 3.029841184616089 # 1.742202639579773         \r\n        \r\nif version == '1.4.1': \r\n    print('note down this value')\r\n\r\n# run 1.4.1 first, get cf_141 and rv_141,\r\n# note down the loss\r\n# then insert them into code, \r\n# then run 1.5.0\r\n# and note down the loss.\r\n# Compare.\r\n\r\n\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n// Paste the bad output here!\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nNo difference between the two versions - identical output.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> GPyTorch versions 1.4.1 and 1.5.0\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> Pytorch 1.8.1\r\n- <!-- Computer OS --> OS Win10 Pro\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1689/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1689/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1687", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1687/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1687/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1687/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1687", "id": 938032574, "node_id": "MDU6SXNzdWU5MzgwMzI1NzQ=", "number": 1687, "title": "[Bug]: Possible error in exact multitask learning setup w.r.t. LCMKernel and model.initialize", "user": {"login": "lucheroni", "id": 60316215, "node_id": "MDQ6VXNlcjYwMzE2MjE1", "avatar_url": "https://avatars.githubusercontent.com/u/60316215?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucheroni", "html_url": "https://github.com/lucheroni", "followers_url": "https://api.github.com/users/lucheroni/followers", "following_url": "https://api.github.com/users/lucheroni/following{/other_user}", "gists_url": "https://api.github.com/users/lucheroni/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucheroni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucheroni/subscriptions", "organizations_url": "https://api.github.com/users/lucheroni/orgs", "repos_url": "https://api.github.com/users/lucheroni/repos", "events_url": "https://api.github.com/users/lucheroni/events{/privacy}", "received_events_url": "https://api.github.com/users/lucheroni/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-07-06T15:45:27Z", "updated_at": "2021-07-07T16:28:58Z", "closed_at": "2021-07-07T16:28:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nIn the Multitask Exact GP setting, when using an LCMKernel and\r\ntrying to initialize one of the covar_module parameters of this kernel by hand\r\nwith model.initialize(**hypers),\r\nI obtain an AttributeError of type\r\n'LCMKernel has no module covar_module_list[0]' (or whatever other index).\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n\r\nimport gpytorch\r\nimport numpy as np\r\nimport torch\r\n\r\nrank_test = 1\r\nnum_tasks_test = 2\r\nnum_latents_test = 2\r\n\r\nclass MultitaskGPModel_test(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(MultitaskGPModel_test, self).__init__(train_x, train_y, likelihood)\r\n        \r\n        self.mean_module = gpytorch.means.MultitaskMean(\r\n            gpytorch.means.ConstantMean(), num_tasks=num_tasks_test\r\n        )\r\n               \r\n        ker =  gpytorch.kernels.RQKernel()       \r\n        self.covar_module = gpytorch.kernels.LCMKernel(\r\n            [ker for _ in range(num_latents_test)],            \r\n            num_tasks=num_tasks_test, rank=rank_test\r\n                                                      )  \r\n        \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        \r\n        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\r\n\r\nw_l = 5\r\nXc_test_npa = np.arange(0,w_l,1,dtype=np.float32).reshape(-1, 1)\r\nXc_test = torch.from_numpy(Xc_t_npa).type(torch.Tensor)\r\nYc_test = torch.rand(2,w_l)\r\n\r\nlikelihood_test = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=num_tasks_test)\r\nmodel_test = MultitaskGPModel_test(Xc_test, Yc_test, likelihood_test)\r\n\r\n# parameter raw_var with index 0 exists\r\nprint(model_test.covar_module.covar_module_list[0].task_covar_module.raw_var) \r\n\r\nhypers = {\r\n    'covar_module.covar_module_list[0].task_covar_module.raw_var': torch.zeros(2)\r\n}\r\n\r\nmodel_test.initialize(**hypers)\r\n# generates AttributeError: \r\n# Invalid parameter name \r\n# covar_module_list[0].task_covar_module.raw_var. \r\n# LCMKernel has no module covar_module_list[0]\r\n\r\n\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n// AttributeError: Invalid parameter name covar_module_list[0].task_covar_module.raw_var. LCMKernel has no module covar_module_list[0]\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- no error -->\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> GPyTorch 1.4.1\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> PyTorch 1.8.1\r\n- <!-- Computer OS --> OS WIN10 Pro\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1687/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1687/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1685", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1685/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1685/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1685/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1685", "id": 937201685, "node_id": "MDExOlB1bGxSZXF1ZXN0NjgzNzk2NDY2", "number": 1685, "title": "Kernel batch size recurses through module lists.", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-07-05T15:36:22Z", "updated_at": "2021-11-22T14:11:35Z", "closed_at": "2021-07-22T14:48:17Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1685", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1685", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1685.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1685.patch", "merged_at": "2021-07-22T14:48:17Z"}, "body": "To determine the batch size of an AdditiveKernel or a ProductKernel, we need to recurse through ModuleLists as well as stand-alone sub kernels. This PR addresses that.\r\n\r\n[Fixes #1672]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1685/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1685/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1678", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1678/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1678/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1678/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1678", "id": 932567060, "node_id": "MDU6SXNzdWU5MzI1NjcwNjA=", "number": 1678, "title": "[Bug] Deprecation warning for Batch Independent Multitask Model under pytorch 1.10", "user": {"login": "andrewsali", "id": 15079591, "node_id": "MDQ6VXNlcjE1MDc5NTkx", "avatar_url": "https://avatars.githubusercontent.com/u/15079591?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewsali", "html_url": "https://github.com/andrewsali", "followers_url": "https://api.github.com/users/andrewsali/followers", "following_url": "https://api.github.com/users/andrewsali/following{/other_user}", "gists_url": "https://api.github.com/users/andrewsali/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewsali/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewsali/subscriptions", "organizations_url": "https://api.github.com/users/andrewsali/orgs", "repos_url": "https://api.github.com/users/andrewsali/repos", "events_url": "https://api.github.com/users/andrewsali/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewsali/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-06-29T12:06:01Z", "updated_at": "2021-07-05T10:20:58Z", "closed_at": "2021-07-05T10:20:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen a certain dimension size is exceeded, gpytorch appears to be calling deprecated torch methods (as of latest pytorch source version 1.10). With lower dimension size as in the example https://docs.gpytorch.ai/en/stable/examples/03_Multitask_Exact_GPs/Batch_Independent_Multioutput_GP.html, this problem does not appear.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\n\r\ntrain_x = torch.linspace(0, 1, 100)\r\n\r\ntrain_y = torch.stack([\r\n    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2 for i in range(9) # no warning below 9\r\n], -1)\r\n\r\nclass BatchIndependentMultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super().__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([train_y.shape[1]]))\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([train_y.shape[1]])),\r\n            batch_shape=torch.Size([train_y.shape[1]])\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultitaskMultivariateNormal.from_batch_mvn(\r\n            gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n        )\r\n\r\n\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=train_y.shape[1])\r\nmodel = BatchIndependentMultitaskGPModel(train_x, train_y, likelihood)\r\n\r\n# this is for running the notebook in our testing framework\r\nimport os\r\nsmoke_test = ('CI' in os.environ)\r\ntraining_iterations = 2 if smoke_test else 50\r\n\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iterations):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n    optimizer.step()\r\n\r\n# Set into eval mode\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\n# Make predictions\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    test_x = torch.linspace(0, 1, 51)\r\n    predictions = likelihood(model(test_x))\r\n    mean = predictions.mean\r\n    lower, upper = predictions.confidence_region()\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n/opt/conda/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py:266: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)\r\n  _jit_linear_cg_updates_no_precond(\r\n/opt/conda/lib/python3.8/site-packages/gpytorch/utils/lanczos.py:173: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\r\nThe default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\r\nL, _ = torch.symeig(A, upper=upper)\r\nshould be replaced with\r\nL = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\r\nand\r\nL, V = torch.symeig(A, eigenvectors=True)\r\nshould be replaced with\r\nL, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2482.)\r\n  retr = torch.symeig(t_mat.cpu(), eigenvectors=True)\r\n```\r\n## Expected Behavior\r\n\r\nNo deprecation warning even for higher dimensions.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGpytorch - 1.4.2\r\nPyTorch - 1.10.0a0+git5ff407d\r\nLinux\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1678/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1678/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1673", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1673/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1673/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1673/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1673", "id": 929537457, "node_id": "MDU6SXNzdWU5Mjk1Mzc0NTc=", "number": 1673, "title": "[Bug] InvQuadLogDet with SumKroneckerLazyTensor doesn't work", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-06-24T19:11:40Z", "updated_at": "2021-07-05T15:45:38Z", "closed_at": "2021-07-05T15:45:38Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nsolves + logdets fail when using `inv_quad_logdet` on a SumKroneckerLazyTensor. I'll put up a PR fixing it soon hopefully.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nfrom gpytorch.kernels import MaternKernel\r\nfrom gpytorch.lazy import SumKroneckerLazyTensor, KroneckerProductLazyTensor, DiagLazyTensor\r\n\r\nkernels = [MaternKernel()] * 3\r\nx = [torch.randn(20, 1)] * 3\r\nkplt1 = KroneckerProductLazyTensor(*[k(xx) for xx, k in zip(x, kernels)])\r\n\r\nkplt2 = KroneckerProductLazyTensor(*[DiagLazyTensor(torch.rand(20))]*3)\r\n\r\nsum_kplt = kplt1 + kplt2\r\n\r\nrhs = torch.randn(sum_kplt.shape[-1], 1)\r\n\r\nsum_kplt.inv_matmul(rhs) # works\r\n\r\nsum_kplt.inv_quad_log_det(inv_quad_rhs=rhs, logdet = True) # error\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n/mnt/xarfuse/uid-228567/f0320543-seed-nspid4026531836_cgpid17430139-ns-4026531840/gpytorch/lazy/lazy_tensor.py in inv_quad_logdet(self, inv_quad_rhs, logdet, reduce_inv_quad)\r\n   1277         func = InvQuadLogDet.apply\r\n   1278 \r\n-> 1279         inv_quad_term, logdet_term = func(\r\n   1280             self.representation_tree(),\r\n   1281             self.dtype,\r\n\r\n/mnt/xarfuse/uid-228567/f0320543-seed-nspid4026531836_cgpid17430139-ns-4026531840/gpytorch/functions/_inv_quad_log_det.py in forward(ctx, representation_tree, dtype, device, matrix_shape, batch_shape, inv_quad, logdet, probe_vectors, probe_vector_norms, *args)\r\n    155         t_mat = None\r\n    156         if ctx.logdet and settings.skip_logdet_forward.off():\r\n--> 157             solves, t_mat = lazy_tsr._solve(rhs, preconditioner, num_tridiag=num_random_probes)\r\n    158 \r\n    159         else:\r\n\r\nValueError: too many values to unpack (expected 2)\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThis should work, was attempting to write a specific type of high rank, tensorized Gaussian likelihood. \r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\ngpytorch 1.4.2\r\npytorch master\r\n\r\ncc @Balandat \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1673/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1673/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1672", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1672/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1672/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1672/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1672", "id": 928905883, "node_id": "MDU6SXNzdWU5Mjg5MDU4ODM=", "number": 1672, "title": "[Bug]", "user": {"login": "lucheroni", "id": 60316215, "node_id": "MDQ6VXNlcjYwMzE2MjE1", "avatar_url": "https://avatars.githubusercontent.com/u/60316215?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucheroni", "html_url": "https://github.com/lucheroni", "followers_url": "https://api.github.com/users/lucheroni/followers", "following_url": "https://api.github.com/users/lucheroni/following{/other_user}", "gists_url": "https://api.github.com/users/lucheroni/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucheroni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucheroni/subscriptions", "organizations_url": "https://api.github.com/users/lucheroni/orgs", "repos_url": "https://api.github.com/users/lucheroni/repos", "events_url": "https://api.github.com/users/lucheroni/events{/privacy}", "received_events_url": "https://api.github.com/users/lucheroni/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2021-06-24T06:50:21Z", "updated_at": "2021-07-22T14:48:17Z", "closed_at": "2021-07-22T14:48:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug: Possible error with multitask learning with additive kernel structure\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nWhen I define in the class MultitaskGPModel the multitask kernel\r\n\r\n            self.covar_module = (gpytorch.kernels.ScaleKernel(\r\n                     gpytorch.kernels.PeriodicKernel(batch_shape=torch.Size([num_latents])) * \r\n                     gpytorch.kernels.RQKernel(batch_shape=torch.Size([num_latents])),\r\n                                               batch_shape=torch.Size([num_latents])\r\n                                                             )  + \r\n                                gpytorch.kernels.ScaleKernel(\r\n                     gpytorch.kernels.MaternKernel(nu=0.5, batch_shape=torch.Size([num_latents])), \r\n                                               batch_shape=torch.Size([num_latents])\r\n                                                             )\r\n                                )\r\n\r\nwhich uses the additive kernel as its outermost layer, and I apply the class on data as\r\n\r\n  w_l = 50\r\n  num_latents = 24\r\n  Xc_t_npa = np.arange(0,w_l,1,dtype=np.float32).reshape(-1, 1)\r\n  Xc_t = torch.from_numpy(Xc_t_npa).type(torch.Tensor)\r\n  model_mul(Xc_t)\r\n\r\nI get \r\n'RuntimeError: The expected shape of the kernel was torch.Size([100, 100]), but got torch.Size([24, 100, 100]). This is likely a bug in GPyTorch'.\r\nThis behavior seems not to change when changing the number of tasks or the number of latent gps.\r\n\r\nIf I use the same kernel in a non-batch setting, it works smoothly.\r\n\r\nI wrote the batched problem with another kernel which is mathematically the same but which doesn't use the outer additive kernel, and it works smoothly. Unfortunatly the role of the subkernel parameters in the new form is not the same as that of the malfunctioning kernel, and I have to re-run a lot of past non-batch fits in the new form to make them comparable with the new setting.\r\n\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n# Your code goes here\r\n# Please make sure it does not require any external dependencies (other than PyTorch!)\r\n# (We much prefer small snippets rather than links to existing libraries!)\r\n```\r\n    Zc_intra_np = np.arange(0, 24, 1).reshape(-1, 1)\r\n    Zc_intra = torch.tensor(Zc_intra_np, dtype=torch.float)\r\n \r\n    w_l = 50\r\n    num_latents = 24\r\n    num_tasks = 12\r\n    Xc_t_npa = np.arange(0,w_l,1,dtype=np.float32).reshape(-1, 1)\r\n    Xc_t = torch.from_numpy(Xc_t_npa).type(torch.Tensor)\r\n\r\n    model_mul = MultitaskGPModel()\r\n    likelihood_mul = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=num_tasks)\r\n    model_mul(Xc_t)\r\n\r\n\r\n    class MultitaskGPModel(gpytorch.models.ApproximateGP):\r\n        \r\n        def __init__(self):\r\n            \r\n\r\n            inducing_points = Zc_intra\r\n        \r\n            variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\r\n                inducing_points.size(-2), batch_shape=torch.Size([num_latents])\r\n            )\r\n\r\n            variational_strategy = gpytorch.variational.LMCVariationalStrategy(\r\n                gpytorch.variational.VariationalStrategy(\r\n                    self, inducing_points, variational_distribution, learn_inducing_locations=True\r\n                ),\r\n                num_tasks=num_tasks,\r\n                num_latents=num_latents,\r\n                # could be 0\r\n                latent_dim=-1\r\n            )\r\n\r\n            super().__init__(variational_strategy)\r\n\r\n            self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([num_latents]))\r\n        \r\n            self.covar_module = gpytorch.kernels.ScaleKernel(\r\n                     gpytorch.kernels.PeriodicKernel(batch_shape=torch.Size([num_latents])) * \r\n                     gpytorch.kernels.RQKernel(batch_shape=torch.Size([num_latents]))  + \r\n                     gpytorch.kernels.ScaleKernel(\r\n                         gpytorch.kernels.MaternKernel(nu=0.5, batch_shape=torch.Size([num_latents])), \r\n                                                 batch_shape=torch.Size([num_latents])),                 \r\n                             batch_shape=torch.Size([num_latents])  \r\n                                                             )\r\n\r\n\r\n        def forward(self, x):\r\n            mean_x = self.mean_module(x)\r\n            covar_x = self.covar_module(x)\r\n            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\n\r\n\r\n\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-398-5fc832e3a3f0>\", line 1, in <module>\r\n    model_mul(Xc_t)\r\n\r\n  File \"C:\\Users\\lucheron\\Anaconda3\\envs\\pyro16_py37\\lib\\site-packages\\gpytorch\\models\\approximate_gp.py\", line 81, in __call__\r\n    return self.variational_strategy(inputs, prior=prior, **kwargs)\r\n\r\n  File \"C:\\Users\\lucheron\\Anaconda3\\envs\\pyro16_py37\\lib\\site-packages\\gpytorch\\variational\\lmc_variational_strategy.py\", line 124, in __call__\r\n    function_dist = self.base_variational_strategy(x, prior=prior, **kwargs)\r\n\r\n  File \"C:\\Users\\lucheron\\Anaconda3\\envs\\pyro16_py37\\lib\\site-packages\\gpytorch\\variational\\variational_strategy.py\", line 168, in __call__\r\n    return super().__call__(x, prior=prior, **kwargs)\r\n\r\n  File \"C:\\Users\\lucheron\\Anaconda3\\envs\\pyro16_py37\\lib\\site-packages\\gpytorch\\variational\\_variational_strategy.py\", line 129, in __call__\r\n    **kwargs,\r\n\r\n  File \"C:\\Users\\lucheron\\Anaconda3\\envs\\pyro16_py37\\lib\\site-packages\\gpytorch\\module.py\", line 28, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n\r\n  File \"C:\\Users\\lucheron\\Anaconda3\\envs\\pyro16_py37\\lib\\site-packages\\gpytorch\\variational\\variational_strategy.py\", line 96, in forward\r\n    induc_induc_covar = full_covar[..., :num_induc, :num_induc].add_jitter()\r\n\r\n  File \"C:\\Users\\lucheron\\Anaconda3\\envs\\pyro16_py37\\lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py\", line 237, in add_jitter\r\n    return self.evaluate_kernel().add_jitter(jitter_val)\r\n\r\n  File \"C:\\Users\\lucheron\\Anaconda3\\envs\\pyro16_py37\\lib\\site-packages\\gpytorch\\utils\\memoize.py\", line 59, in g\r\n    return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n\r\n  File \"C:\\Users\\lucheron\\Anaconda3\\envs\\pyro16_py37\\lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py\", line 291, in evaluate_kernel\r\n    f\"The expected shape of the kernel was {self.shape}, but got {res.shape}. \"\r\n\r\nRuntimeError: The expected shape of the kernel was torch.Size([100, 100]), but got torch.Size([24, 100, 100]). This is likely a bug in GPyTorch.\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. --> Run with no errors\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 1.4.1\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> 1.8.1\r\n- <!-- Computer OS --> Win10 pro 19042.1052\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1672/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1672/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1667", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1667/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1667/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1667/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1667", "id": 926952415, "node_id": "MDU6SXNzdWU5MjY5NTI0MTU=", "number": 1667, "title": "Trying to overfit a minibatch with `SoftmaxLikelihood`", "user": {"login": "lopezpaz", "id": 2237879, "node_id": "MDQ6VXNlcjIyMzc4Nzk=", "avatar_url": "https://avatars.githubusercontent.com/u/2237879?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lopezpaz", "html_url": "https://github.com/lopezpaz", "followers_url": "https://api.github.com/users/lopezpaz/followers", "following_url": "https://api.github.com/users/lopezpaz/following{/other_user}", "gists_url": "https://api.github.com/users/lopezpaz/gists{/gist_id}", "starred_url": "https://api.github.com/users/lopezpaz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lopezpaz/subscriptions", "organizations_url": "https://api.github.com/users/lopezpaz/orgs", "repos_url": "https://api.github.com/users/lopezpaz/repos", "events_url": "https://api.github.com/users/lopezpaz/events{/privacy}", "received_events_url": "https://api.github.com/users/lopezpaz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-06-22T08:07:54Z", "updated_at": "2021-06-22T17:04:01Z", "closed_at": "2021-06-22T15:45:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nI am trying to overfit a mini-batch of synthetic data for multi-class classification, with no luck. In fact, the los value barely moves, no matter how long I optimize. I attach the minimal failing example below. The version of `torch` is `1.8` and the one of `gpytorch` is `1.4.2`. What's wrong with my code? Thank you!\r\n\r\n```python\t\r\nimport torch\r\nimport gpytorch\r\n\r\nclass GP(gpytorch.models.ApproximateGP):\r\n    def __init__(self, x, num_tasks):\r\n        variational_distribution = \\\r\n            gpytorch.variational.CholeskyVariationalDistribution(len(x))\r\n\r\n        variational_strategy = \\\r\n            gpytorch.variational.IndependentMultitaskVariationalStrategy(\r\n                gpytorch.variational.VariationalStrategy(\r\n                    self, x, variational_distribution),\r\n                num_tasks=num_tasks)\r\n\r\n        super(GP, self).__init__(variational_strategy)\r\n\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        return gpytorch.distributions.MultivariateNormal(\r\n            self.mean_module(x), self.covar_module(x))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    num_tasks = 50\r\n    x = torch.randn(32, 100)\r\n    y = torch.randn(32).random_(num_tasks).long()\r\n\r\n    model = GP(x, num_tasks)\r\n\r\n    likelihood = gpytorch.likelihoods.SoftmaxLikelihood(\r\n        num_classes=num_tasks, mixing_weights=False)\r\n\r\n    loss = gpytorch.mlls.VariationalELBO(\r\n        likelihood,\r\n        model,\r\n        num_data=len(x))\r\n\r\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\r\n\r\n    for epoch in range(500):\r\n        loss_value = -loss(model(x), y)\r\n\r\n        optimizer.zero_grad()\r\n        loss_value.backward()\r\n        optimizer.step()\r\n\r\n        accuracy = model(x).mean.argmax(1).eq(y).float().mean().item()\r\n        print(loss_value.item(), accuracy)\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1667/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1667/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1659", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1659/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1659/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1659/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1659", "id": 923612140, "node_id": "MDU6SXNzdWU5MjM2MTIxNDA=", "number": 1659, "title": "[Bug] ard_num_dims with IndependentMultitaskVariationalStrategy", "user": {"login": "valentinecesbio", "id": 77112599, "node_id": "MDQ6VXNlcjc3MTEyNTk5", "avatar_url": "https://avatars.githubusercontent.com/u/77112599?v=4", "gravatar_id": "", "url": "https://api.github.com/users/valentinecesbio", "html_url": "https://github.com/valentinecesbio", "followers_url": "https://api.github.com/users/valentinecesbio/followers", "following_url": "https://api.github.com/users/valentinecesbio/following{/other_user}", "gists_url": "https://api.github.com/users/valentinecesbio/gists{/gist_id}", "starred_url": "https://api.github.com/users/valentinecesbio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/valentinecesbio/subscriptions", "organizations_url": "https://api.github.com/users/valentinecesbio/orgs", "repos_url": "https://api.github.com/users/valentinecesbio/repos", "events_url": "https://api.github.com/users/valentinecesbio/events{/privacy}", "received_events_url": "https://api.github.com/users/valentinecesbio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-06-17T08:08:13Z", "updated_at": "2021-07-01T06:42:52Z", "closed_at": "2021-06-22T16:30:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nHello, \r\n\r\nI am working on a multi-class (3 classes) classification using the dataset from sklearn `make_blobs` with 500 samples per class, and 20 features.\r\nI would like to use the `ard_num_dims` option in order to have a separate lengthscale for each input dimension. I already use the option `batch_shape` because I want to learn a different set of variational parameters and hyperparameters for each output dimension.\r\nAs I want independent output dimensions, I do not want to use `LMCVariationalStrategy` but instead `IndependentMultitaskVariationalStrategy`. \r\n\r\nI got a correct classification with  `LMCVariationalStrategy` but it is not working with `IndependentMultitaskVariationalStrategy`.\r\n\r\nThanks for your help\r\n\r\n## To reproduce\r\n**Example with `LMCVariationalStrategy`**:\r\n\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nimport numpy as np\r\nimport tqdm.notebook\r\nfrom matplotlib import pyplot as plt\r\nfrom sklearn.datasets import make_blobs\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.metrics import confusion_matrix as CM, accuracy_score as AS\r\n\r\nprint(\"numpy version: \" + np.__version__)\r\nprint(\"gpytorch version: \" + gpytorch.__version__)\r\nprint(\"torch version: \" + torch.__version__)\r\n\r\nnb_samples = 500\r\nnb_features = 20\r\nnb_classes = 3\r\nrandom_state = 1\r\ntrain_size = 0.75\r\nnumber_inducing_points = 50\r\n\r\nX_, y_ = make_blobs(n_samples=nb_samples, n_features=nb_features, centers=nb_classes, random_state=random_state)\r\n\r\nX_train, X_val, y_train, y_val = train_test_split(X_, y_, train_size=train_size, random_state=random_state)\r\n\r\nX_train = torch.tensor(X_train, dtype=torch.float)\r\ny_train = torch.tensor(y_train , dtype=torch.float)\r\nX_val = torch.tensor(X_val, dtype=torch.float)\r\ny_val = torch.tensor(y_val, dtype=torch.float)\r\n\r\n# Extract some random inducing points\r\ntorch.manual_seed(random_state)\r\n# Returns a random permutation of integers from 0 to n - 1.\r\nperm = torch.randperm(X_train.size(0))\r\nidx = perm[:number_inducing_points]\r\n# Same inducing points for each GP (size : nb_points_induits * nb_features)\r\ninducing_points = X_train[idx, :]\r\n# Different inducing points for each GP (size : nb_labels\r\n# * nb_points_induits * nb_features)\r\ninducing_points = np.repeat(inducing_points[np.newaxis, :, :], nb_classes, axis=0)\r\n\r\nclass GP_MultiClass_LMC(gpytorch.models.ApproximateGP):\r\n\r\n    def __init__(self, inducing_points, nb_classes):\r\n\r\n        # Define a Variational distribution\r\n        variational_distribution = gpytorch.variational\\\r\n            .CholeskyVariationalDistribution(inducing_points.size(-2),\r\n                                             batch_shape=torch.Size([nb_classes]))\r\n\r\n        # MultitaskVariationalStrategy is deprecated, use\r\n        # IndependentMultitaskVariationalStrategy instead.\r\n        variational_strategy = gpytorch.variational.LMCVariationalStrategy(\r\n            gpytorch.variational.VariationalStrategy(\r\n                self, inducing_points, variational_distribution, learn_inducing_locations=True\r\n            ),\r\n            num_tasks=nb_classes,\r\n            num_latents=nb_classes,\r\n            latent_dim=-1,\r\n        )\r\n\r\n        super(GP_MultiClass_LMC, self).__init__(variational_strategy)\r\n        self.mean_module = gpytorch.means.ConstantMean(\r\n            batch_shape=torch.Size([nb_classes]))\r\n\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(ard_nums_dim=nb_features,\r\n                batch_shape=torch.Size([nb_classes])),\r\n            batch_shape=torch.Size([nb_classes]), ard_num_dims=None)\r\n\r\n         # Define a MultivariateNormal Distribution\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        latent_pred = gpytorch.distributions.MultivariateNormal(mean_x,\r\n                                                                covar_x)\r\n        return latent_pred\r\n\r\n# Define GP model\r\nmodelMulti = GP_MultiClass_LMC(inducing_points, nb_classes)\r\n\r\n# Define a likelihood\r\nlikelihoodSoftmax = gpytorch.likelihoods.SoftmaxLikelihood(num_features=nb_classes, num_classes=nb_classes, mixing_weights=True)\r\n\r\nnum_epochs=100\r\nlearning_rate=0.1\r\n\r\n# Find optimal model hyperparameters\r\nmodelMulti.train()\r\nlikelihoodSoftmax.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': modelMulti.parameters()},\r\n    {'params': likelihoodSoftmax.parameters()},\r\n], lr=learning_rate)\r\n\r\nmll = gpytorch.mlls.VariationalELBO(likelihoodSoftmax, modelMulti, y_train.numel())\r\n\r\n\r\nepochs_iter = tqdm.notebook.tqdm(range(num_epochs), desc=\"Epoch\")\r\n\r\n\r\nfor i in epochs_iter:\r\n    # Within each iteration, we will go over each minibatch of data\r\n    optimizer.zero_grad()\r\n    output = modelMulti(X_train)\r\n    loss = -mll(output, y_train)\r\n    epochs_iter.set_postfix(loss=loss.item())\r\n    loss.backward()\r\n    optimizer.step()\r\n\r\n# Get into evaluation (predictive posterior) mode\r\nmodelMulti.eval()\r\nlikelihoodSoftmax.eval()\r\n\r\n# Test points are regularly spaced along [0,1]\r\n# Make predictions by feeding model through likelihood\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n        observed_pred = likelihoodSoftmax(modelMulti(X_val))\r\n        y_pred = observed_pred.probs.mean(0).argmax(-1)\r\n\r\nconf_mat = CM(y_val, y_pred)\r\nprint(f\"Confusion matrix:\\n {conf_mat}\")\r\n\r\naccuracy = AS(y_val, y_pred)\r\nprint(f\"Global accuracy: {accuracy}\")\r\n\r\nprint(modelMulti.covar_module.base_kernel.lengthscale.shape)\r\nprint(modelMulti.covar_module.base_kernel.raw_lengthscale)\r\nprint(modelMulti.covar_module.base_kernel.raw_lengthscale_constraint)\r\n```\r\n\r\n**Output**\r\n```\r\nConfusion matrix:\r\n [[48  0  0]\r\n [ 0 35  0]\r\n [ 0  0 42]]\r\nGlobal accuracy: 1.0\r\ntorch.Size([3, 1, 1])\r\nParameter containing:\r\ntensor([[[-0.8027]],\r\n\r\n        [[ 7.4186]],\r\n\r\n        [[ 5.0510]]], requires_grad=True)\r\nPositive()\r\n```\r\n\r\n**Example with `IndependentMultitaskVariationalStrategy`**:\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nimport numpy as np\r\nimport tqdm.notebook\r\nfrom matplotlib import pyplot as plt\r\nfrom sklearn.datasets import make_blobs\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.metrics import confusion_matrix as CM, accuracy_score as AS\r\n\r\nprint(\"numpy version: \" + np.__version__)\r\nprint(\"gpytorch version: \" + gpytorch.__version__)\r\nprint(\"torch version: \" + torch.__version__)\r\n\r\nnb_samples = 500\r\nnb_features = 20\r\nnb_classes = 3\r\nrandom_state = 1\r\ntrain_size = 0.75\r\nnumber_inducing_points = 50\r\n\r\nX_, y_ = make_blobs(n_samples=nb_samples, n_features=nb_features, centers=nb_classes, random_state=random_state)\r\n\r\nX_train, X_val, y_train, y_val = train_test_split(X_, y_, train_size=train_size, random_state=random_state)\r\n\r\nX_train = torch.tensor(X_train, dtype=torch.float)\r\ny_train = torch.tensor(y_train , dtype=torch.float)\r\nX_val = torch.tensor(X_val, dtype=torch.float)\r\ny_val = torch.tensor(y_val, dtype=torch.float)\r\n\r\n# Extract some random inducing points\r\ntorch.manual_seed(random_state)\r\n# Returns a random permutation of integers from 0 to n - 1.\r\nperm = torch.randperm(X_train.size(0))\r\nidx = perm[:number_inducing_points]\r\n# Same inducing points for each GP (size : nb_points_induits * nb_features)\r\ninducing_points = X_train[idx, :]\r\n# Different inducing points for each GP (size : nb_labels\r\n# * nb_points_induits * nb_features)\r\ninducing_points = np.repeat(inducing_points[np.newaxis, :, :], nb_classes, axis=0)\r\n\r\nclass GP_MultiClass_Independent(gpytorch.models.ApproximateGP):\r\n\r\n    def __init__(self, inducing_points, nb_classes):\r\n\r\n        # Define a Variational distribution\r\n        variational_distribution = gpytorch.variational\\\r\n            .CholeskyVariationalDistribution(inducing_points.size(-2),\r\n                                             batch_shape=torch.Size([nb_classes]))\r\n\r\n        # MultitaskVariationalStrategy is deprecated, use\r\n        # IndependentMultitaskVariationalStrategy instead.\r\n        variational_strategy = gpytorch.variational.IndependentMultitaskVariationalStrategy(\r\n            gpytorch.variational.VariationalStrategy(\r\n                self, inducing_points, variational_distribution,\r\n                learn_inducing_locations=True\r\n            ),\r\n            num_tasks=nb_classes,\r\n            )\r\n\r\n        super(GP_MultiClass_Independent, self).__init__(variational_strategy)\r\n        self.mean_module = gpytorch.means.ConstantMean(\r\n            batch_shape=torch.Size([nb_classes]))\r\n\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(ard_nums_dim=nb_features,\r\n                batch_shape=torch.Size([nb_classes])),\r\n            batch_shape=torch.Size([nb_classes]), ard_num_dims=None)\r\n\r\n         # Define a MultivariateNormal Distribution\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        latent_pred = gpytorch.distributions.MultivariateNormal(mean_x,\r\n                                                                covar_x)\r\n        return latent_pred\r\n\r\n# Define GP model\r\nmodelMulti = GP_MultiClass_Independent(inducing_points, nb_classes)\r\n\r\n# Define a likelihood\r\nlikelihoodSoftmax = gpytorch.likelihoods.SoftmaxLikelihood(num_features=nb_classes, num_classes=nb_classes, mixing_weights=True)\r\n\r\nnum_epochs=100\r\nlearning_rate=0.1\r\n\r\n# Find optimal model hyperparameters\r\nmodelMulti.train()\r\nlikelihoodSoftmax.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': modelMulti.parameters()},\r\n    {'params': likelihoodSoftmax.parameters()},\r\n], lr=learning_rate)\r\n\r\nmll = gpytorch.mlls.VariationalELBO(likelihoodSoftmax, modelMulti, y_train.numel())\r\n\r\n\r\nepochs_iter = tqdm.notebook.tqdm(range(num_epochs), desc=\"Epoch\")\r\n\r\n\r\nfor i in epochs_iter:\r\n    # Within each iteration, we will go over each minibatch of data\r\n    optimizer.zero_grad()\r\n    output = modelMulti(X_train)\r\n    loss = -mll(output, y_train)\r\n    epochs_iter.set_postfix(loss=loss.item())\r\n    loss.backward()\r\n    optimizer.step()\r\n\r\n# Get into evaluation (predictive posterior) mode\r\nmodelMulti.eval()\r\nlikelihoodSoftmax.eval()\r\n\r\n# Test points are regularly spaced along [0,1]\r\n# Make predictions by feeding model through likelihood\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n        observed_pred = likelihoodSoftmax(modelMulti(X_val))\r\n        y_pred = observed_pred.probs.mean(0).argmax(-1)\r\n```\r\n**Output**\r\n```\r\nConfusion matrix:\r\n [[ 0 48  0]\r\n [ 0 35  0]\r\n [ 0 42  0]]\r\nGlobal accuracy: 0.28\r\ntorch.Size([3, 1, 1])\r\nParameter containing:\r\ntensor([[[-1.2953]],\r\n\r\n        [[-0.6173]],\r\n\r\n        [[ 0.0733]]], requires_grad=True)\r\nPositive()\r\n```\r\n## Expected Behavior\r\n\r\n**First question:** \r\n\r\nWhy my lengthscale is not a `c x 1 x d` tensor but a `c x 1 x 1` tensor with `batch_shape=nb_classes=c` and `ard_num_dims=d`  ?\r\n\r\n**Second question:**\r\n\r\nWhy the optimization is well working with `LMCVariationalStrategy` but it is not working with `IndependentMultitaskVariationalStrategy` when I add the option `ard_num_dims` ?\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\ngpytorch version: 1.2.0\r\ntorch version: 1.3.1\r\nUbuntu 20.04.1 LTS\r\n\r\n## Additional context\r\nMaybe this is related to #1209\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1659/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1659/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1657", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1657/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1657/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1657/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1657", "id": 921696569, "node_id": "MDU6SXNzdWU5MjE2OTY1Njk=", "number": 1657, "title": "[Bug] The Added Loss term for InducingKernel seems flipped in sign?", "user": {"login": "maharjun", "id": 4582526, "node_id": "MDQ6VXNlcjQ1ODI1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/4582526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maharjun", "html_url": "https://github.com/maharjun", "followers_url": "https://api.github.com/users/maharjun/followers", "following_url": "https://api.github.com/users/maharjun/following{/other_user}", "gists_url": "https://api.github.com/users/maharjun/gists{/gist_id}", "starred_url": "https://api.github.com/users/maharjun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maharjun/subscriptions", "organizations_url": "https://api.github.com/users/maharjun/orgs", "repos_url": "https://api.github.com/users/maharjun/repos", "events_url": "https://api.github.com/users/maharjun/events{/privacy}", "received_events_url": "https://api.github.com/users/maharjun/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2021-06-15T18:48:16Z", "updated_at": "2021-10-24T01:26:51Z", "closed_at": "2021-06-23T18:59:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n```\r\n    def loss(self, *params):\r\n        prior_covar = self.prior_dist.lazy_covariance_matrix\r\n        variational_covar = self.variational_dist.lazy_covariance_matrix\r\n        diag = prior_covar.diag() - variational_covar.diag()\r\n        shape = prior_covar.shape[:-1]\r\n        noise_diag = self.likelihood._shaped_noise_covar(shape, *params).diag()\r\n        return 0.5 * (diag / noise_diag).sum()\r\n```\r\nThis is the current code for InducingPointKernelAddedLossTerm.loss\r\n\r\nFrom what I see, this \"loss term\" is added into the mll that is returned by the `ExactMarginalLogLikelihood` class. This in itself is misleading as the loss is usually the negative of the mll.\r\n\r\nMoreover, the variational negative loss used to evaluate inducing points is given below\r\n\r\n![image](https://user-images.githubusercontent.com/4582526/122106510-4c545980-ce1a-11eb-9bbc-681bea511bec.png)\r\n\r\nAs can be seen, the above is the expression for the pseudo-mll that is maximized when optimizing the inducing points. in this, the component of `InducingPointKernelAddedLossTerm` is negative to the value that is being added into the loss.\r\n\r\nThis is quite likely a significant bug. Please fix (just invert the sign of `diag` above)\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1657/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1657/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1648", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1648/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1648/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1648/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1648", "id": 916860049, "node_id": "MDU6SXNzdWU5MTY4NjAwNDk=", "number": 1648, "title": "[Bug] Inconsistent behavior between running with CPU and GPU tensors", "user": {"login": "archielee", "id": 10553758, "node_id": "MDQ6VXNlcjEwNTUzNzU4", "avatar_url": "https://avatars.githubusercontent.com/u/10553758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/archielee", "html_url": "https://github.com/archielee", "followers_url": "https://api.github.com/users/archielee/followers", "following_url": "https://api.github.com/users/archielee/following{/other_user}", "gists_url": "https://api.github.com/users/archielee/gists{/gist_id}", "starred_url": "https://api.github.com/users/archielee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/archielee/subscriptions", "organizations_url": "https://api.github.com/users/archielee/orgs", "repos_url": "https://api.github.com/users/archielee/repos", "events_url": "https://api.github.com/users/archielee/events{/privacy}", "received_events_url": "https://api.github.com/users/archielee/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2021-06-10T03:49:48Z", "updated_at": "2021-06-29T02:02:53Z", "closed_at": "2021-06-29T02:02:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI've been trying to learn how to use GPyTorch by playing around with the `IndependentModelList` example code on a toy example. I've noticed some odd behavior and crashes when attempting to use CUDA acceleration. In the program below, I have 2 options to play with: `n_train` and `cuda`.\r\n\r\nWhen I leave CUDA off and `n_train = 500`, the program runs fine and I get a nice fit. The loss constantly goes down as well.\r\n\r\nWhen I turn on CUDA with `n_train = 500`, the program crashes with the error `RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\r\n\r\nWhen I turn on CUDA with `n_train = 250`, the model trains but the fit is noticable worse and the loss increases after several training iterations (with no changes to the optimizer at all).\r\n\r\nI'm not sure what's going on, I can use CPU-only but this behavior with GPU acceleration is unexpected. Monitoring my GPU memory usage with `nvidia-smi`, I only see about 10% VRAM usage and 5% GPU utilization.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport gpytorch\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport torch\r\n\r\ncuda = True\r\nn_train = 500\r\nn_test = 100\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super().__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(ard_num_dims=train_x.shape[-1],\r\n                                       lengthscale_constraint=gpytorch.constraints.GreaterThan(1e-4))\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\ndef f(x):\r\n    return np.stack([\r\n        2 * x[:, 0] - 3 * x[:, 1],\r\n        2 * np.sin(x[:, 0]) - 3 * np.cos(x[:, 1])\r\n    ], axis=-1)\r\n\r\n# Set up training data\r\ntrain_x = np.append(np.random.uniform(low=2.0, high=4.0, size=[n_train // 2]),\r\n                    np.random.uniform(low=5.0, high=7.0, size=[n_train // 2]))\r\ntrain_x = np.stack([train_x, 2 * np.ones(train_x.shape)], axis=-1)\r\ntrain_y = f(train_x) + np.stack([2.5e-1 * train_x[:, 0] * np.random.randn(len(train_x[:, 0])),\r\n                                 2.5e-1 * train_x[:, 0] * np.random.randn(len(train_x[:, 0]))], axis=-1)\r\ntrain_x = torch.from_numpy(train_x).float()\r\ntrain_y = torch.from_numpy(train_y).float()\r\n\r\n# Set up testing data\r\ntest_x = np.stack([np.linspace(0, 10, n_test), 2 * np.ones(n_test)], axis=-1)\r\ntest_y = f(test_x)\r\ntest_x = torch.from_numpy(test_x).float()\r\ntest_y = torch.from_numpy(test_y).float()\r\n\r\nif cuda:\r\n    train_x = train_x.to(\"cuda\")\r\n    train_y = train_y.to(\"cuda\")\r\n    test_x = test_x.to(\"cuda\")\r\n\r\nmodels, likelihoods = [], []\r\nfor dim in range(train_y.shape[-1]):\r\n    # Create model for each output dimension\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n    model = ExactGPModel(train_x, train_y[:, dim], likelihood)\r\n    models.append(model)\r\n    likelihoods.append(likelihood)\r\nmodel = gpytorch.models.IndependentModelList(*models)\r\nlikelihood = gpytorch.likelihoods.LikelihoodList(*likelihoods)\r\n\r\nif cuda:\r\n    model.cuda()\r\n    likelihood.cuda()\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\nopt = torch.optim.Adam(model.parameters(), lr=0.1)\r\nmll = gpytorch.mlls.SumMarginalLogLikelihood(likelihood, model)\r\n\r\ntraining_iterations = 50\r\nfor i in range(training_iterations):\r\n    opt.zero_grad()\r\n    output = model(*model.train_inputs)\r\n    # Calc loss and backprop gradients\r\n    loss = -mll(output, model.train_targets)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n    opt.step()\r\n\r\nmodel.eval()\r\n\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    predictions = likelihood(*model(test_x, test_x))\r\n\r\n    pred_y, pred_ub, pred_lb = [], [], []\r\n    for submodel, prediction in zip(model.models, predictions):\r\n        mean = prediction.mean\r\n        lower, upper = prediction.confidence_region()\r\n\r\n        if cuda:\r\n            mean = mean.cpu()\r\n            lower = lower.cpu()\r\n            upper = upper.cpu()\r\n\r\n        pred_y.append(mean.numpy())\r\n        pred_ub.append(upper.numpy())\r\n        pred_lb.append(lower.numpy())\r\n    pred_y = np.array(pred_y).T\r\n    pred_ub = np.array(pred_ub).T\r\n    pred_lb = np.array(pred_lb).T\r\n\r\ntrain_x = train_x.cpu().numpy()\r\ntrain_y = train_y.cpu().numpy()\r\ntest_x = test_x.cpu().numpy()\r\ntest_y = test_y.cpu().numpy()\r\n\r\nfig, axs = plt.subplots(1, 2)\r\naxs[0].scatter(train_x[:, 0], train_y[:, 0], marker=\"*\", s=4, c=\"r\")\r\naxs[0].plot(test_x[:, 0], test_y[:, 0], c=\"k\", label=\"ground truth\")\r\naxs[0].plot(test_x[:, 0], pred_y[:, 0], color=\"tab:blue\", label=\"pred. mean\")\r\naxs[0].fill_between(test_x[:, 0], pred_lb[:, 0], pred_ub[:, 0], alpha=0.4, color=\"tab:blue\", label=\"pred. 2$\\sigma$ bound\")\r\naxs[0].legend()\r\naxs[1].scatter(train_x[:, 0], train_y[:, 1], marker=\"*\", s=4, c=\"r\")\r\naxs[1].plot(test_x[:, 0], test_y[:, 1], c=\"k\", label=\"ground truth\")\r\naxs[1].plot(test_x[:, 0], pred_y[:, 1], color=\"tab:blue\", label=\"pred. mean\")\r\naxs[1].fill_between(test_x[:, 0], pred_lb[:, 1], pred_ub[:, 1], alpha=0.4, color=\"tab:blue\", label=\"pred. 2$\\sigma$ bound\")\r\naxs[1].legend()\r\nplt.show()\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"scripts/test_gp.py\", line 78, in <module>\r\n    loss.backward()\r\n  File \"/home/archie/trail/hybrid-mbrl/venv/lib/python3.8/site-packages/torch/tensor.py\", line 245, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\r\n  File \"/home/archie/trail/hybrid-mbrl/venv/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 145, in backward\r\n    Variable._execution_engine.run_backward(\r\nRuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)\r\n```\r\n\r\n## Expected Behavior\r\n\r\nModel training behavior should not change between CPU and GPU. Model fit on same amount of data should be similar between CPU and GPU.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version 1.4.2\r\n- PyTorch Version 1.8.1+cu111\r\n- Ubuntu 20.04\r\n- Nvidia driver version 465.27\r\n- GPU: Nvidia Titan Xp\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1648/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1648/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1647", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1647/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1647/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1647/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1647", "id": 916780442, "node_id": "MDExOlB1bGxSZXF1ZXN0NjY2NDA3MTUx", "number": 1647, "title": "Fix erroneous loss for ExactGP multitask models", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1607679275, "node_id": "MDU6TGFiZWwxNjA3Njc5Mjc1", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/multitask", "name": "multitask", "color": "ffffff", "default": false, "description": "For questions about multitask models"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-06-10T00:42:36Z", "updated_at": "2021-06-10T14:48:49Z", "closed_at": "2021-06-10T14:48:45Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1647", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1647", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1647.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1647.patch", "merged_at": "2021-06-10T14:48:45Z"}, "body": "The code in ExactMLL divides by `targets.size(-1)`.\r\nFor multitask models, this is the number of outputs.\r\nInstead, this code divides by `function_dist.event_shape.numel()`,\r\nwhich will result in losses that are similar in size to univariate\r\nExactGP models.\r\n\r\n[Fixes #1155]\r\n[Fixes #1033]\r\n[Fixes #1159]\r\n[Addresses #1129]\r\n[Addresses #1633]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1647/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1647/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1634", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1634/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1634/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1634/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1634", "id": 910036012, "node_id": "MDU6SXNzdWU5MTAwMzYwMTI=", "number": 1634, "title": "[Bug] module.initialize does not work with module lists (additive kernels)", "user": {"login": "jpchen", "id": 1869641, "node_id": "MDQ6VXNlcjE4Njk2NDE=", "avatar_url": "https://avatars.githubusercontent.com/u/1869641?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpchen", "html_url": "https://github.com/jpchen", "followers_url": "https://api.github.com/users/jpchen/followers", "following_url": "https://api.github.com/users/jpchen/following{/other_user}", "gists_url": "https://api.github.com/users/jpchen/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpchen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpchen/subscriptions", "organizations_url": "https://api.github.com/users/jpchen/orgs", "repos_url": "https://api.github.com/users/jpchen/repos", "events_url": "https://api.github.com/users/jpchen/events{/privacy}", "received_events_url": "https://api.github.com/users/jpchen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-06-03T02:34:33Z", "updated_at": "2021-06-07T04:39:37Z", "closed_at": "2021-06-07T04:39:36Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "[`module.initialize`](https://docs.gpytorch.ai/en/stable/module.html?#gpytorch.Module.initialize) does not seem to handle module lists properly eg when an additive kernel is used. This seems to be because of the [recursive `initialize` call](https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/module.py#L90) and `ModuleLists` do not have an `initialize` method as `gpytorch.Modules` do. One dirty solution might be to include the index into the namespace and index in the event of a module list.\r\n\r\ncc: @caozhen-bupt\r\n\r\nExample:\r\n<details>\r\n\r\n```python\r\nIn [32]: \r\n    ...: class ExactGPModel(gpytorch.models.ExactGP):\r\n    ...:     def __init__(self, train_x, train_y, likelihood):\r\n    ...:         super(ExactGPModel, self).__init__(train_x, train_y, gpytorch.likelihoods.GaussianLikelihood())\r\n    ...:         self.covar_module = gpytorch.kernels.RBFKernel()\r\n    ...:         self.additive = gpytorch.kernels.RBFKernel() + gpytorch.kernels.RBFKernel()\r\n    ...:\r\n    ...:     def forward(self, x):\r\n    ...:         pass\r\n    ...:\r\n    ...: # initialize likelihood and model\r\n    ...: likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n    ...: model = ExactGPModel(train_x, train_y, likelihood)\r\n\r\nIn [33]: model.initialize(**{'covar_module.lengthscale': torch.tensor(1.)})  # this is ok\r\n\r\nIn [34]: model.additive\r\nOut[34]:\r\nAdditiveKernel(\r\n  (kernels): ModuleList(\r\n    (0): RBFKernel(\r\n      (raw_lengthscale_constraint): Positive()\r\n    )\r\n    (1): RBFKernel(\r\n      (raw_lengthscale_constraint): Positive()\r\n    )\r\n  )\r\n)\r\n\r\nIn [35]: model.initialize(**{'additive.kernels.0.lengthscale': torch.tensor(1.)})\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-30-38d6b8203c68> in <module>\r\n----> 1 model.initialize(**{'additive.kernels.0.lengthscale': torch.tensor(1.)})\r\n\r\n~/miniconda3/envs/bm/lib/python3.7/site-packages/gpytorch/module.py in initialize(self, **kwargs)\r\n     88             if \".\" in name:\r\n     89                 module, name = self._get_module_and_name(name)\r\n---> 90                 module.initialize(**{name: val})\r\n     91             elif not hasattr(self, name):\r\n     92                 raise AttributeError(\"Unknown parameter {p} for {c}\".format(p=name, c=self.__class__.__name__))\r\n\r\n~/miniconda3/envs/bm/lib/python3.7/site-packages/gpytorch/module.py in initialize(self, **kwargs)\r\n     88             if \".\" in name:\r\n     89                 module, name = self._get_module_and_name(name)\r\n---> 90                 module.initialize(**{name: val})\r\n     91             elif not hasattr(self, name):\r\n     92                 raise AttributeError(\"Unknown parameter {p} for {c}\".format(p=name, c=self.__class__.__name__))\r\n\r\n~/miniconda3/envs/bm/lib/python3.7/site-packages/torch/nn/modules/module.py in __getattr__(self, name)\r\n   1129                 return modules[name]\r\n   1130         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\r\n-> 1131             type(self).__name__, name))\r\n   1132\r\n   1133     def __setattr__(self, name: str, value: Union[Tensor, 'Module']) -> None:\r\n\r\nAttributeError: 'ModuleList' object has no attribute 'initialize'\r\n```\r\n\r\n</details>", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1634/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1634/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1615", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1615/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1615/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1615/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1615", "id": 886929297, "node_id": "MDU6SXNzdWU4ODY5MjkyOTc=", "number": 1615, "title": "[Bug] Wrong formulation of the PeriodicKernel", "user": {"login": "glemaitre", "id": 7454015, "node_id": "MDQ6VXNlcjc0NTQwMTU=", "avatar_url": "https://avatars.githubusercontent.com/u/7454015?v=4", "gravatar_id": "", "url": "https://api.github.com/users/glemaitre", "html_url": "https://github.com/glemaitre", "followers_url": "https://api.github.com/users/glemaitre/followers", "following_url": "https://api.github.com/users/glemaitre/following{/other_user}", "gists_url": "https://api.github.com/users/glemaitre/gists{/gist_id}", "starred_url": "https://api.github.com/users/glemaitre/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/glemaitre/subscriptions", "organizations_url": "https://api.github.com/users/glemaitre/orgs", "repos_url": "https://api.github.com/users/glemaitre/repos", "events_url": "https://api.github.com/users/glemaitre/events{/privacy}", "received_events_url": "https://api.github.com/users/glemaitre/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-05-11T11:15:18Z", "updated_at": "2021-05-31T12:11:50Z", "closed_at": "2021-05-31T12:11:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThe current formulation of the periodic kernel is the following:\r\n\r\n<img src=\"https://render.githubusercontent.com/render/math?math=k(\\mathbf{x^1, x^2}) = \\exp ( \\frac{-2 \\sin^2(\\frac{\\pi}{p} \\sum_i | x^{1}_{i} - x^{2}_{i} |)}{l^2} )\">\r\n\r\nHowever, the original formula proposed [Mackay, 1998](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.1927&rep=rep1&type=pdf) (Eq. 47) is the following:\r\n\r\n<img src=\"https://render.githubusercontent.com/render/math?math=k(\\mathbf{x^1, x^2}) = \\exp ( \\frac{-0.5  \\sum_i \\sin^2(\\frac{\\pi}{p} | x^{1}_{i} - x^{2}_{i} |)}{l^2} )\">\r\n\r\nThe constant is not -2 or -0.5 is not really important (it will have an impact on the derivative only). However, the original formulation is taking the the sum of the sine squared of the difference. Currently, the formulation is the sine squared of the sum of the difference. Note that the confusion could come from the fact that in the literature, the kernel is used for 1D signal and thus there is no sum, thus both formulations are equivalent.\r\n\r\nIn addition, looking at the implementation, it seems that the distance computed between the samples is norm-2 distance and not the norm-1 distance.\r\n\r\nThe current formulation make it that the kernel is not PSD. In addition, there is still another bug with a missing square over the length scale as reported in https://github.com/cornellius-gp/gpytorch/issues/1020.\r\n\r\nNote: I found this issue because I am currently working on a similar issues in scikit-learn:\r\nhttps://github.com/scikit-learn/scikit-learn/issues/19343\r\nhttps://github.com/scikit-learn/scikit-learn/pull/20070\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport numpy as np\r\nimport torch\r\nfrom gpytorch.kernels import PeriodicKernel\r\n\r\nr = np.linspace(0, 1, num=4)\r\ntrain_x, train_y = np.meshgrid(r, r)\r\nX = np.stack((train_x.flatten(), train_y.flatten()), axis=-1)\r\n\r\nperiodicity, length_scale=1.5, 0.5\r\nkernel_pytorch = PeriodicKernel(\r\n    period=periodicity, length_scale=length_scale\r\n)\r\nK_pytorch = kernel_pytorch(torch.from_numpy(X))\r\n\r\nnp.linalg.eigh(K_pytorch.numpy())[0]\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\narray([-1.27815495, -1.21435487, -1.21435487, -0.93566031, -0.75456704,\r\n       -0.24301193, -0.24301193,  0.47435512,  0.72370254,  1.58773803,\r\n        1.58773803,  2.42356711,  2.67356606,  2.67356606,  3.10565507,\r\n        6.63322787])\r\n```\r\n\r\nThere is some negative eigenvalues.\r\n\r\n## Expected Behavior\r\n\r\nWe are investigating the issue in scikit-learn and already implemented a naive approach: https://github.com/scikit-learn/scikit-learn/pull/20070 for tracking the bug. With the code of the PR, there is no negative eigenvalues:\r\n\r\n```python\r\nfrom sklearn.gaussian_process.kernels import ExpSineSquared\r\n\r\nkernel_sklearn = ExpSineSquared(\r\n    periodicity=periodicity, length_scale=length_scale,\r\n)\r\nK_sklearn = kernel_sklearn(X)\r\nnp.linalg.eigh(K_sklearn)[0]\r\n```\r\n\r\n```\r\narray([0.88422032, 0.92031869, 0.92031869, 0.95789078, 0.95961332,\r\n       0.95961332, 0.99716727, 0.99716727, 0.99878962, 0.99878962,\r\n       1.03787671, 1.03787671, 1.0414347 , 1.08219069, 1.08219069,\r\n       1.12454163])\r\n```\r\n\r\nOn the process, we also worked with the implementation of tensorflow-probability that follow the equation of the paper, and we have consistent results:\r\n\r\n```python\r\nfrom tensorflow_probability import math\r\n\r\nkernel_tfp = math.psd_kernels.ExpSinSquared(\r\n   period=periodicity, length_scale=length_scale\r\n)\r\nK_tfp = kernel_tfp.matrix(X, X)\r\nnp.linalg.eigh(K_tfp.numpy())[0]\r\n``` \r\n\r\n```\r\narray([0.8842203 , 0.92031866, 0.92031866, 0.95789075, 0.9596133 ,\r\n       0.9596133 , 0.9971673 , 0.9971673 , 0.9987896 , 0.9987896 ,\r\n       1.0378767 , 1.0378767 , 1.0414346 , 1.0821906 , 1.0821906 ,\r\n       1.1245416 ], dtype=float32)\r\n```\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch version: `1.4.1`\r\n- PyTorch version: `1.8.1+cpu`\r\n- Linux 5.8.0-50-generic #56-Ubuntu SMP Mon Apr 12 17:18:36 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1615/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1615/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1602", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1602/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1602/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1602/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1602", "id": 873126184, "node_id": "MDU6SXNzdWU4NzMxMjYxODQ=", "number": 1602, "title": "[Bug] Singular matrix error when crossing cholesky->lanczos threshold", "user": {"login": "mwlon", "id": 6504033, "node_id": "MDQ6VXNlcjY1MDQwMzM=", "avatar_url": "https://avatars.githubusercontent.com/u/6504033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mwlon", "html_url": "https://github.com/mwlon", "followers_url": "https://api.github.com/users/mwlon/followers", "following_url": "https://api.github.com/users/mwlon/following{/other_user}", "gists_url": "https://api.github.com/users/mwlon/gists{/gist_id}", "starred_url": "https://api.github.com/users/mwlon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mwlon/subscriptions", "organizations_url": "https://api.github.com/users/mwlon/orgs", "repos_url": "https://api.github.com/users/mwlon/repos", "events_url": "https://api.github.com/users/mwlon/events{/privacy}", "received_events_url": "https://api.github.com/users/mwlon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-04-30T19:13:42Z", "updated_at": "2021-05-31T12:10:08Z", "closed_at": "2021-05-31T12:10:08Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nTrying to `get_fantasy_model` with>800 observations where the covariance matrix between`x` values is very singular gives the error below.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```\r\nimport torch\r\nfrom gpytorch.kernels import LinearKernel, MaternKernel, AdditiveKernel, ScaleKernel\r\nfrom gpytorch.models import ExactGP\r\nfrom gpytorch.mlls import ExactMarginalLogLikelihood\r\nfrom gpytorch.likelihoods.gaussian_likelihood import GaussianLikelihood\r\nfrom gpytorch.distributions import MultivariateNormal\r\nfrom gpytorch.means import ConstantMean\r\n\r\n\r\nclass ExactGpModel(ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood, covar_module):\r\n        super(ExactGpModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = ConstantMean()\r\n        self.covar_module = covar_module\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return MultivariateNormal(mean_x, covar_x)\r\n\r\nn_dims = 1\r\nbase_n = 801\r\nlikelihood = GaussianLikelihood()\r\nx = torch.ones((base_n, n_dims))\r\ny = torch.randn(base_n)\r\nmodel = ExactGpModel(x, y, likelihood=likelihood, covar_module=MaternKernel())\r\nmll = ExactMarginalLogLikelihood(likelihood, model)\r\nmll.train()\r\nmll.eval()\r\nmvn = model(torch.randn((77, n_dims)))\r\n\r\nnew_x = torch.randn((77, n_dims))\r\nnew_y = torch.randn(77)\r\nmodel.get_fantasy_model(new_x, new_y)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---> 34 model.get_fantasy_model(new_x, new_y)\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/models/exact_gp.py in get_fantasy_model(self, inputs, targets, **kwargs)\r\n    228 \r\n    229         new_model.likelihood = old_likelihood.get_fantasy_likelihood(**fantasy_kwargs)\r\n--> 230         new_model.prediction_strategy = old_pred_strat.get_fantasy_strategy(\r\n    231             inputs, targets, full_inputs, full_targets, full_output, **fantasy_kwargs\r\n    232         )\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py in get_fantasy_strategy(self, inputs, targets, full_inputs, full_targets, full_output, **kwargs)\r\n    184 \r\n    185         # now update the root and root inverse\r\n--> 186         new_lt = self.lik_train_train_covar.cat_rows(fant_train_covar, fant_fant_covar)\r\n    187         new_root = new_lt.root_decomposition().root.evaluate()\r\n    188         new_covar_cache = new_lt.root_inv_decomposition().root.evaluate()\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in cat_rows(self, cross_mat, new_mat, generate_roots, **root_decomp_kwargs)\r\n    826         else:\r\n    827             # otherwise we use the pseudo-inverse of Z as new inv root\r\n--> 828             new_inv_root = stable_pinverse(new_root).transpose(-2, -1)\r\n    829 \r\n    830         add_to_cache(new_lazy_tensor, \"root_decomposition\", RootLazyTensor(lazify(new_root)))\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/utils/pinverse.py in stable_pinverse(A)\r\n     13         # skinny (or square) matrix\r\n     14         Q, R = stable_qr(A)\r\n---> 15         return torch.triangular_solve(Q.transpose(-1, -2), R).solution\r\n     16     else:\r\n     17         # fat matrix\r\n\r\nRuntimeError: triangular_solve_cpu: U(1,1) is zero, singular U.\r\n\r\n```\r\n\r\n## Expected Behavior\r\n\r\nIt should use lanczos without error past this threshold\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch version: 1.4.1\r\n- torch version: 1.7.1\r\n- OS: ubuntu\r\n\r\n## Additional context\r\nI tried it with various `x` matrices. It works down to about rank ~250 with 1D data and 801 data points.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1602/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1602/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1599", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1599/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1599/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1599/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1599", "id": 871397285, "node_id": "MDU6SXNzdWU4NzEzOTcyODU=", "number": 1599, "title": "[Bug]", "user": {"login": "ZacharyVarley", "id": 33402037, "node_id": "MDQ6VXNlcjMzNDAyMDM3", "avatar_url": "https://avatars.githubusercontent.com/u/33402037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZacharyVarley", "html_url": "https://github.com/ZacharyVarley", "followers_url": "https://api.github.com/users/ZacharyVarley/followers", "following_url": "https://api.github.com/users/ZacharyVarley/following{/other_user}", "gists_url": "https://api.github.com/users/ZacharyVarley/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZacharyVarley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZacharyVarley/subscriptions", "organizations_url": "https://api.github.com/users/ZacharyVarley/orgs", "repos_url": "https://api.github.com/users/ZacharyVarley/repos", "events_url": "https://api.github.com/users/ZacharyVarley/events{/privacy}", "received_events_url": "https://api.github.com/users/ZacharyVarley/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-04-29T19:30:25Z", "updated_at": "2021-05-04T21:06:05Z", "closed_at": "2021-05-04T21:06:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nDeprecated method ScaleToBounds in tutorial: [Exact DKL Regression w/ KISS-GP\r\n](https://docs.gpytorch.ai/en/stable/examples/06_PyTorch_NN_Integration_DKL/KISSGP_Deep_Kernel_Regression_CUDA.html#Overview)\r\n## To reproduce\r\n\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nself.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nmodule 'gpytorch.utils.grid' has no attribute 'ScaleToBounds'\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nI expected to be able to scale the NN learned features to (-1,1) as described in the write-up. As a quick get-around I tried:\r\n\r\n```\r\nself.scale_to_bounds = lambda x: gpytorch.utils.grid.scale_to_bounds(x, -1., 1.)\r\n```\r\nThis attempt led me to the following _redacted_ error traceback from 'gpytorch\\utils\\ftt.py' :\r\n\r\n```\r\n\r\n  File \"my_GP_NN.py\", line 110, in <module>\r\n    train()\r\n\r\n  File \"my_GP_NN.py\", line 105, in train\r\n    loss = -mll(output, train_y)\r\n\r\n  File \"gpytorch/module.py\", line 28, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n\r\n  File \"gpytorch/mlls/exact_marginal_log_likelihood.py\", line 51, in forward\r\n    res = output.log_prob(target)\r\n\r\n  File \"gpytorch/distributions/multivariate_normal.py\", line 135, in log_prob\r\n    inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n\r\n  File \"gpytorch/lazy/lazy_tensor.py\", line 1002, in inv_quad_logdet\r\n    cholesky = CholLazyTensor(self.cholesky())\r\n\r\n  File \"gpytorch/lazy/lazy_tensor.py\", line 739, in cholesky\r\n    res = self._cholesky()\r\n\r\n  File \"gpytorch/utils/memoize.py\", line 34, in g\r\n    add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n\r\n  File \"gpytorch/lazy/lazy_tensor.py\", line 407, in _cholesky\r\n    evaluated_mat = evaluated_kern_mat.evaluate()\r\n\r\n  File \"gpytorch/utils/memoize.py\", line 34, in g\r\n    add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n\r\n  File \"gpytorch/lazy/sum_lazy_tensor.py\", line 62, in evaluate\r\n    return sum(lazy_tensor.evaluate() for lazy_tensor in self.lazy_tensors)\r\n\r\n  File \"gpytorch/lazy/sum_lazy_tensor.py\", line 62, in <genexpr>\r\n    return sum(lazy_tensor.evaluate() for lazy_tensor in self.lazy_tensors)\r\n\r\n  File \"gpytorch/utils/memoize.py\", line 34, in g\r\n    add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n\r\n  File \"gpytorch/lazy/lazy_tensor.py\", line 877, in evaluate\r\n    res = self.matmul(eye)\r\n\r\n  File \"gpytorch/lazy/interpolated_lazy_tensor.py\", line 405, in matmul\r\n    base_res = self.base_lazy_tensor.matmul(right_interp_res)\r\n\r\n  File \"gpytorch/lazy/lazy_tensor.py\", line 1097, in matmul\r\n    return func.apply(self.representation_tree(), other, *self.representation())\r\n\r\n  File \"gpytorch/functions/_matmul.py\", line 21, in forward\r\n    res = lazy_tsr._matmul(rhs)\r\n\r\n  File \"gpytorch/lazy/kronecker_product_lazy_tensor.py\", line 87, in _matmul\r\n    res = _matmul(self.lazy_tensors, self.shape, rhs.contiguous())\r\n\r\n  File \"gpytorch/lazy/kronecker_product_lazy_tensor.py\", line 26, in _matmul\r\n    factor = lazy_tensor._matmul(res)\r\n\r\n  File \"gpytorch/lazy/toeplitz_lazy_tensor.py\", line 30, in _matmul\r\n    return sym_toeplitz_matmul(self.column, rhs)\r\n\r\n  File \"gpytorch/utils/toeplitz.py\", line 163, in sym_toeplitz_matmul\r\n    return toeplitz_matmul(toeplitz_column, toeplitz_column, tensor)\r\n\r\n  File \"gpytorch/utils/toeplitz.py\", line 138, in toeplitz_matmul\r\n    fft_M = fft.fft1(temp_tensor.transpose(1, 2).contiguous())\r\n\r\n  File \"gpytorch/utils/fft.py\", line 8, in fft1\r\n    return complex_input.fft(1)\r\n\r\nAttributeError: 'Tensor' object has no attribute 'fft'\r\n```\r\n\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> GPyTorch Version 1.1.1\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> PyTorch Version 1.8.1\r\n- <!-- Computer OS --> Ubuntu 20.04\r\n\r\n## Additional context\r\nI manually specified the \"smoketest\" data with the following line:\r\n```\r\nX, y = torch.randn(20, 3), torch.randn(20)\r\n```\r\nCuda is available on my machine. ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1599/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1599/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1592", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1592/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1592/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1592/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1592", "id": 867821265, "node_id": "MDExOlB1bGxSZXF1ZXN0NjIzNDI5MTYw", "number": 1592, "title": "Fix SGPR errors when testing on training data.", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-04-26T15:19:44Z", "updated_at": "2021-05-04T00:44:26Z", "closed_at": "2021-05-04T00:44:22Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1592", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1592", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1592.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1592.patch", "merged_at": "2021-05-04T00:44:22Z"}, "body": "[Closes #1581]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1592/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1592/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1583", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1583/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1583/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1583/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1583", "id": 864276966, "node_id": "MDU6SXNzdWU4NjQyNzY5NjY=", "number": 1583, "title": "[Bug] LazyTensor root_inv_decomposition can fail under certain conditions", "user": {"login": "mwlon", "id": 6504033, "node_id": "MDQ6VXNlcjY1MDQwMzM=", "avatar_url": "https://avatars.githubusercontent.com/u/6504033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mwlon", "html_url": "https://github.com/mwlon", "followers_url": "https://api.github.com/users/mwlon/followers", "following_url": "https://api.github.com/users/mwlon/following{/other_user}", "gists_url": "https://api.github.com/users/mwlon/gists{/gist_id}", "starred_url": "https://api.github.com/users/mwlon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mwlon/subscriptions", "organizations_url": "https://api.github.com/users/mwlon/orgs", "repos_url": "https://api.github.com/users/mwlon/repos", "events_url": "https://api.github.com/users/mwlon/events{/privacy}", "received_events_url": "https://api.github.com/users/mwlon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-04-21T20:52:48Z", "updated_at": "2021-08-02T17:54:30Z", "closed_at": "2021-08-02T17:54:30Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nFor instance, if `method='cholesky'` and there is a cache miss, `root_inv_decomposition` will throw a nonsensical error saying `local variable 'inv_root' referenced before assignment`.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\nThe issue is flaky, hard to reproduce, but the code path causing it is pretty obvious. See below.\r\n\r\n** Stack trace/error message **\r\n```\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, function_dist, target, *params)\r\n     60         # Get the log prob of the marginal distribution\r\n     61         output = self.likelihood(function_dist, *params)\r\n---> 62         res = output.log_prob(target)\r\n     63         res = self._add_other_terms(res, params)\r\n     64 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    145     def log_prob(self, value):\r\n    146         if settings.fast_computations.log_prob.off():\r\n--> 147             return super().log_prob(value)\r\n    148 \r\n    149         if self._validate_args:\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/torch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    206             self._validate_sample(value)\r\n    207         diff = value - self.loc\r\n--> 208         M = _batch_mahalanobis(self._unbroadcasted_scale_tril, diff)\r\n    209         half_log_det = self._unbroadcasted_scale_tril.diagonal(dim1=-2, dim2=-1).log().sum(-1)\r\n    210         return -0.5 * (self._event_shape[0] * math.log(2 * math.pi) + M) - half_log_det\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py in _unbroadcasted_scale_tril(self)\r\n     55         if self.islazy and self.__unbroadcasted_scale_tril is None:\r\n     56             # cache root decoposition\r\n---> 57             ust = delazify(self.lazy_covariance_matrix.cholesky())\r\n     58             self.__unbroadcasted_scale_tril = ust\r\n     59         return self.__unbroadcasted_scale_tril\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in cholesky(self, upper)\r\n    966             (LazyTensor) Cholesky factor (triangular, upper/lower depending on \"upper\" arg)\r\n    967         \"\"\"\r\n--> 968         chol = self._cholesky(upper=False)\r\n    969         if upper:\r\n    970             chol = chol._transpose_nonbatch()\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in _cholesky(self, upper)\r\n    415         from .keops_lazy_tensor import KeOpsLazyTensor\r\n    416 \r\n--> 417         evaluated_kern_mat = self.evaluate_kernel()\r\n    418 \r\n    419         if any(isinstance(sub_mat, KeOpsLazyTensor) for sub_mat in evaluated_kern_mat._args):\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py in evaluate_kernel(self)\r\n    181         In particular, covar1 would *always* be a standard AddedDiagLazyTensor, but covar2 might be a subtype.\r\n    182         \"\"\"\r\n--> 183         added_diag_lazy_tsr = self.representation_tree()(*self.representation())\r\n    184         return added_diag_lazy_tsr._lazy_tensor + added_diag_lazy_tsr._diag_tensor\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in representation_tree(self)\r\n   1521         including all subobjects. This is used internally.\r\n   1522         \"\"\"\r\n-> 1523         return LazyTensorRepresentationTree(self)\r\n   1524 \r\n   1525     @property\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor_representation_tree.py in __init__(self, lazy_tsr)\r\n     11         for arg in lazy_tsr._args:\r\n     12             if hasattr(arg, \"representation\") and callable(arg.representation):  # Is it a lazy tensor?\r\n---> 13                 representation_size = len(arg.representation())\r\n     14                 self.children.append((slice(counter, counter + representation_size, None), arg.representation_tree()))\r\n     15                 counter += representation_size\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in representation(self)\r\n    315         # representation\r\n    316         else:\r\n--> 317             return self.evaluate_kernel().representation()\r\n    318 \r\n    319     def representation_tree(self):\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)\r\n    282             temp_active_dims = self.kernel.active_dims\r\n    283             self.kernel.active_dims = None\r\n--> 284             res = self.kernel(x1, x2, diag=False, last_dim_is_batch=self.last_dim_is_batch, **self.params)\r\n    285             self.kernel.active_dims = temp_active_dims\r\n    286 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, last_dim_is_batch, **params)\r\n    396                 res = LazyEvaluatedKernelTensor(x1_, x2_, kernel=self, last_dim_is_batch=last_dim_is_batch, **params)\r\n    397             else:\r\n--> 398                 res = lazify(super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\r\n    399             return res\r\n    400 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/kernels/kernel.py in forward(self, x1, x2, diag, **params)\r\n    465             next_term = kern(x1, x2, diag=diag, **params)\r\n    466             if not diag:\r\n--> 467                 res = res + lazify(next_term)\r\n    468             else:\r\n    469                 res = res + next_term\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/non_lazy_tensor.py in __add__(self, other)\r\n     79             return NonLazyTensor(self.tensor + other)\r\n     80         else:\r\n---> 81             return super(NonLazyTensor, self).__add__(other)\r\n     82 \r\n     83     def mul(self, other):\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in __add__(self, other)\r\n   2043             return AddedDiagLazyTensor(self, other)\r\n   2044         elif isinstance(other, RootLazyTensor):\r\n-> 2045             return self.add_low_rank(other.root)\r\n   2046         elif isinstance(other, Tensor):\r\n   2047             other = lazify(other)\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in add_low_rank(self, low_rank_mat, root_decomp_method, root_inv_decomp_method, generate_roots, **root_decomp_kwargs)\r\n    894 \r\n    895         # and MM^T = A^{-1}\r\n--> 896         current_inv_root = self.root_inv_decomposition(method=root_inv_decomp_method).root.transpose(-1, -2)\r\n    897 \r\n    898         # compute p = M B and take its SVD\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in root_inv_decomposition(self, initial_vectors, test_vectors, method)\r\n   1765             inv_root = torch.pinverse(root).transpose(-1, -2)\r\n   1766 \r\n-> 1767         return RootLazyTensor(inv_root)\r\n   1768 \r\n   1769     def size(self, val=None):\r\n\r\nUnboundLocalError: local variable 'inv_root' referenced before assignment\r\n```\r\n\r\n## Expected Behavior\r\n\r\nNo `referenced before assignment` errors, ever. >:(\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch version: 1.4.1\r\n- torch version: 1.7.1\r\n- OS: ubuntu\r\n\r\n## Additional context\r\nThe violating code is obvious enough: https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/lazy/lazy_tensor.py#L1725-L1767\r\n```\r\n...\r\n        if method == \"pinverse\":\r\n            # this is numerically unstable and should rarely be used\r\n            root = self.root_decomposition().root.evaluate()\r\n            inv_root = torch.pinverse(root).transpose(-1, -2)\r\n\r\n        return RootLazyTensor(inv_root)\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1583/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1583/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1581", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1581/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1581/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1581/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1581", "id": 862744643, "node_id": "MDU6SXNzdWU4NjI3NDQ2NDM=", "number": 1581, "title": "[Bug] - New release broke SGPR? ", "user": {"login": "mxef", "id": 45259486, "node_id": "MDQ6VXNlcjQ1MjU5NDg2", "avatar_url": "https://avatars.githubusercontent.com/u/45259486?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mxef", "html_url": "https://github.com/mxef", "followers_url": "https://api.github.com/users/mxef/followers", "following_url": "https://api.github.com/users/mxef/following{/other_user}", "gists_url": "https://api.github.com/users/mxef/gists{/gist_id}", "starred_url": "https://api.github.com/users/mxef/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mxef/subscriptions", "organizations_url": "https://api.github.com/users/mxef/orgs", "repos_url": "https://api.github.com/users/mxef/repos", "events_url": "https://api.github.com/users/mxef/events{/privacy}", "received_events_url": "https://api.github.com/users/mxef/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-04-20T12:03:20Z", "updated_at": "2021-05-04T00:44:22Z", "closed_at": "2021-05-04T00:44:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nHi and thanks a lot for your work. Since the new release when i am trying to predict with the SGPR model, i get an error message that says that it is likely a bug in GPyTorch.\r\n\r\nThanks in advance.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport numpy as np\r\nfrom tslearn.datasets import UCR_UEA_datasets\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom gpytorch.means import ConstantMean\r\nfrom gpytorch.kernels import ScaleKernel, RBFKernel, MaternKernel, InducingPointKernel\r\nfrom gpytorch.distributions import MultivariateNormal\r\n\r\n# Make plots inline\r\n%matplotlib inline\r\n\r\ninducing_p = 0\r\n\r\nfrom gpytorch.means import ConstantMean\r\nfrom gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\r\nfrom gpytorch.distributions import MultivariateNormal\r\n\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n        global inducing_p\r\n        self.mean_module = ConstantMean()\r\n        self.base_covar_module = RBFKernel()\r\n        self.covar_module = InducingPointKernel(self.base_covar_module, inducing_points=torch.linspace(torch.min(train_x), torch.max(train_x), inducing_p), likelihood=likelihood)\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return MultivariateNormal(mean_x, covar_x)\r\n\r\n#global inducing_p\r\nX_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset('Beef')\r\n\r\ndata = np.r_[X_train, X_test]\r\ntrain_y = X_train[0,:,0]  \r\n\r\nfor indx in range(1, 20):\r\n    train_y = np.vstack([train_y, data[indx,:,0]])\r\n\r\ntrain_x = torch.from_numpy(np.arange(1,train_y.shape[1]+1)).float()\r\ntrain_y = torch.from_numpy(train_y).float()\r\ntrain_x = (train_x - train_x.mean(0)) / train_x.std(0)\r\n\r\n#Normalization [-1,1]\r\nfor i in range(20):\r\n    train_y[i] = train_y[i] - torch.min(train_y[i])\r\n    train_y[i] = 2 * (train_y[i] / torch.max(train_y[i])) - 1  \r\n\r\ninducing_p = 2*(int(math.log2(train_y.shape[1]))+1)\r\n# initialize likelihood and model\r\nlikelihood = []\r\nmodel = []\r\nfor i in range(20):\r\n    likelihood.append(gpytorch.likelihoods.GaussianLikelihood())\r\n    model.append(GPRegressionModel(train_x, train_y[i], likelihood[i]))\r\n\r\ntraining_iter = 50\r\nfor i in range(20):\r\n    # Find optimal model hyperparameters\r\n    model[i].train()\r\n    likelihood[i].train()\r\n\r\n    # Use the adam optimizer\r\n    optimizer = torch.optim.Adam(model[i].parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\r\n    # \"Loss\" for GPs - the marginal log likelihood\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood[i], model[i])\r\n\r\n    for it in range(training_iter):\r\n        # Zero gradients from previous iteration\r\n        optimizer.zero_grad()\r\n        # Output from model\r\n        output = model[i](train_x)\r\n        # Calc loss and backprop gradients\r\n        loss = -mll(output, train_y[i])\r\n        loss.backward()        \r\n        optimizer.step()\r\n\r\n\r\n# Get into evaluation (predictive posterior) mode\r\nfor i in range(20):\r\n    model[i].eval()\r\n    likelihood[i].eval()\r\n\r\n# Test points are regularly spaced along [0,1]\r\n# Make predictions by feeding model through likelihood\r\nobserved_pred = []\r\ncross_covar = []\r\npreds = []\r\nwith gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\r\n    for i in range(20):\r\n        preds.append(model[i](train_x))               \r\n```\r\n## Error message\r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-20-e9aa2e04e88d> in <module>\r\n     90 with gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\r\n     91     for i in range(20):\r\n---> 92         preds.append(model[i](train_x))\r\n\r\n~/miniconda3/lib/python3.8/site-packages/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)\r\n    317             # Make the prediction\r\n    318             with settings._use_eval_tolerance():\r\n--> 319                 predictive_mean, predictive_covar = self.prediction_strategy.exact_prediction(full_mean, full_covar)\r\n    320 \r\n    321             # Reshape predictive mean to match the appropriate event shape\r\n\r\n~/miniconda3/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py in exact_prediction(self, joint_mean, joint_covar)\r\n    805         return (\r\n    806             self.exact_predictive_mean(test_mean, test_train_covar),\r\n--> 807             self.exact_predictive_covar(test_test_covar, test_train_covar),\r\n    808         )\r\n    809 \r\n\r\n~/miniconda3/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py in exact_predictive_covar(self, test_test_covar, test_train_covar)\r\n    815         if not isinstance(test_train_covar, MatmulLazyTensor):\r\n    816             # We should not hit this point of the code - this is to catch potential bugs in GPyTorch\r\n--> 817             raise ValueError(\r\n    818                 f\"Expected SGPR output to be a MatmulLazyTensor. Got {test_train_covar.__class__.__name__} instead. \"\r\n    819                 \"This is likely a bug in GPyTorch.\"\r\n\r\nValueError: Expected SGPR output to be a MatmulLazyTensor. Got LowRankRootAddedDiagLazyTensor instead. This is likely a bug in GPyTorch.\r\n```\r\n\r\n## System information\r\n\r\n- GPyTorch: Version 1.4.1\r\n- PyTorch Version: 1.8.1+cu102\r\n- Computer OS: Ubuntu 18.04.5 LTS", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1581/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1581/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1579", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1579/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1579/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1579/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1579", "id": 861701876, "node_id": "MDU6SXNzdWU4NjE3MDE4NzY=", "number": 1579, "title": "[Bug] Inf value calculated by mll ", "user": {"login": "Luckick", "id": 12540789, "node_id": "MDQ6VXNlcjEyNTQwNzg5", "avatar_url": "https://avatars.githubusercontent.com/u/12540789?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Luckick", "html_url": "https://github.com/Luckick", "followers_url": "https://api.github.com/users/Luckick/followers", "following_url": "https://api.github.com/users/Luckick/following{/other_user}", "gists_url": "https://api.github.com/users/Luckick/gists{/gist_id}", "starred_url": "https://api.github.com/users/Luckick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Luckick/subscriptions", "organizations_url": "https://api.github.com/users/Luckick/orgs", "repos_url": "https://api.github.com/users/Luckick/repos", "events_url": "https://api.github.com/users/Luckick/events{/privacy}", "received_events_url": "https://api.github.com/users/Luckick/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-04-19T18:52:02Z", "updated_at": "2021-04-27T03:38:10Z", "closed_at": "2021-04-27T03:38:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport gpytorch\r\nfrom gpytorch.models import ApproximateGP\r\nfrom gpytorch.likelihoods import BetaLikelihood\r\nfrom gpytorch.variational import VariationalStrategy\r\nfrom gpytorch.variational import NaturalVariationalDistribution\r\nfrom gpytorch.priors import SmoothedBoxPrior\r\nfrom gpytorch.distributions import base_distributions\r\nimport torch\r\nfrom gpytorch.models import ExactGP\r\nfrom gpytorch.kernels import MaternKernel, ScaleKernel\r\nfrom gpytorch.means import ConstantMean\r\nfrom  gpytorch.distributions import MultivariateNormal\r\n\r\nclass base_model(ApproximateGP):\r\n  def __init__(self, train_x):\r\n    distribution = CholeskyVariationalDistribution(train_x.shape[0])\r\n    variational_strategy = VariationalStrategy(self, train_x, distribution, learn_inducing_locations=True)\r\n    super(base_model, self).__init__(variational_strategy)\r\n    self.mean_module = gpytorch.means.ConstantMean(prior=SmoothedBoxPrior(0.5, 1))\r\n    num_dims = len(train_x) if len(train_x) == 0 else len(train_x[0])\r\n    kernel = MaternKernel(nu=2.5, ard_num_dims=num_dims)\r\n    self.covar_module = ScaleKernel(kernel)\r\n\r\n  def forward(self, x):\r\n    mean_x = self.mean_module(x)\r\n    covar_x = self.covar_module(x)\r\n    latent_pred = gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n    return latent_pred\r\n\r\nclass BetaGP_Model:\r\n  def __init__(self, X, y, training_iters=100, learning_rate=0.1,  gpu=False, nu=2.5,n_restarts=0):\r\n    self.X = X\r\n    self.y = y\r\n    self.training_iters = training_iters\r\n    self.learning_rate = learning_rate\r\n    self.gpu = gpu\r\n    self.n_restarts = n_restarts\r\n    self.likelihood = BetaLikelihood()\r\n    self.model = base_model(self.X)\r\n    if torch.cuda.is_available() and gpu == True:\r\n      self.model = self.model.cuda()\r\n\r\n  def fit(self):\r\n    self.model.train()\r\n    self.likelihood.train()\r\n    optimizer = torch.optim.Adam([{'params': self.model.parameters()}, ], lr=self.learning_rate)\r\n    mll = gpytorch.mlls.VariationalELBO(self.likelihood, self.model, num_data=y.size(0))\r\n    for restart in range(0 + 1):\r\n      for i in range(self.training_iters):\r\n        optimizer.zero_grad()\r\n        output = self.model(self.X)\r\n        loss = -mll(output, self.y)\r\n        loss.backward()\r\n        optimizer.step()\r\n\r\nmodel = BetaGP_Model(X, y, training_iters=100, learning_rate=0.1, gpu=False, nu=2.5, n_restarts=0)\r\nmodel.fit()\r\n```\r\n\r\n** Stack trace/error message **\r\nThe loss will be inf after 1st iteration, then after backpropagation, the covariance will be nan values. \r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/qil15006/.conda/envs/edbo/lib/python3.7/site-packages/gpytorch/utils/cholesky.py\", line 32, in psd_safe_cholesky\r\n    L = torch.cholesky(A, upper=upper, out=out)\r\nRuntimeError: cholesky_cpu: U(1,1) is zero, singular U.\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/qil15006/tmp/pycharm_project_623/experiments/simplified.py\", line 77, in <module>\r\n    model.fit()\r\n  File \"/home/qil15006/tmp/pycharm_project_623/experiments/simplified.py\", line 65, in fit\r\n    output = self.model(self.X)\r\n  File \"/home/qil15006/.conda/envs/edbo/lib/python3.7/site-packages/gpytorch/models/approximate_gp.py\", line 81, in __call__\r\n    return self.variational_strategy(inputs, prior=prior, **kwargs)\r\n  File \"/home/qil15006/.conda/envs/edbo/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py\", line 168, in __call__\r\n    return super().__call__(x, prior=prior, **kwargs)\r\n  File \"/home/qil15006/.conda/envs/edbo/lib/python3.7/site-packages/gpytorch/variational/_variational_strategy.py\", line 129, in __call__\r\n    **kwargs,\r\n  File \"/home/qil15006/.conda/envs/edbo/lib/python3.7/site-packages/gpytorch/module.py\", line 28, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/qil15006/.conda/envs/edbo/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py\", line 103, in forward\r\n    L = self._cholesky_factor(induc_induc_covar)\r\n  File \"/home/qil15006/.conda/envs/edbo/lib/python3.7/site-packages/gpytorch/utils/memoize.py\", line 76, in g\r\n    return _add_to_cache_ignore_args(self, cache_name, method(self, *args, **kwargs))\r\n  File \"/home/qil15006/.conda/envs/edbo/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py\", line 72, in _cholesky_factor\r\n    L = psd_safe_cholesky(delazify(induc_induc_covar).double())\r\n  File \"/home/qil15006/.conda/envs/edbo/lib/python3.7/site-packages/gpytorch/utils/cholesky.py\", line 38, in psd_safe_cholesky\r\n    f\"cholesky_cpu: {isnan.sum().item()} of {A.numel()} elements of the {A.shape} tensor are NaN.\"\r\ngpytorch.utils.errors.NanError: cholesky_cpu: 10000 of 10000 elements of the torch.Size([100, 100]) tensor are NaN.\r\n```\r\n\r\n## Expected Behavior\r\nNon Inf value\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGPyTorch Version (`1.4.0`)\r\nPyTorch Version (`1.8.1+cu102`) \r\nComputer OS  Ubuntu 16.04.7 \r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1579/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1579/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1578", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1578/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1578/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1578/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1578", "id": 860302726, "node_id": "MDU6SXNzdWU4NjAzMDI3MjY=", "number": 1578, "title": "[Bug] Fully Bayesian Inference with Pyro Does Not Work", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2021-04-17T02:25:12Z", "updated_at": "2021-06-23T13:39:01Z", "closed_at": "2021-06-23T13:39:01Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nRight now, the way our Bayesian inference with pyro works is that we loop over all `Parameter`s with priors, call `pyro.sample` and load the sample into the parameter value. Here's an extremely simplified model that is equivalent to what we do that does NOT work:\r\n```python\r\ndef pyro_model2(x, y):\r\n    raw_lengthscale = pyro.sample('raw_lengthscale', Normal(0, 1))\r\n    raw_outputscale = pyro.sample('raw_outputscale', Normal(0, 1))\r\n\r\n    # This is not an okay way to load the results of pyro.sample statements into a Module\r\n    covar_module.initialize(**{'raw_outputscale': raw_outputscale, 'base_kernel.raw_lengthscale': raw_lengthscale})\r\n    \r\n    covar_x = covar_module(x).evaluate()\r\n    pyro.sample(\"obs\", pyro.distributions.MultivariateNormal(torch.zeros(y.size(-1)), covar_x + torch.eye(y.size(-1))), obs=y)\r\n```\r\nSee the attached python notebook that demonstrates that this leads to completely wrong gradients for the potential energy, so HMC is entirely broken.\r\n\r\nThe best way I've found to fix this is to use the (possibly deprecated?) `pyro.random_module` primitive. Here's a pyro model using a full GPyTorch GP that gets correct potential derivatives:\r\n```python\r\ndef pyro_model5(x, y):\r\n    priors= {\r\n        'covar_module.base_kernel.raw_lengthscale': Normal(0, 1).expand([1, 1]),\r\n        'covar_module.raw_outputscale': Normal(0, 1),\r\n        'likelihood.noise_covar.raw_noise': Normal(0, 1).expand([1]),\r\n        'mean_module.constant': Normal(0, 1),\r\n   }\r\n    fn = pyro.random_module(\"model\", model, prior=priors)\r\n    sampled_model = fn()\r\n    \r\n    output = sampled_model.likelihood(sampled_model(x))\r\n    pyro.sample(\"obs\", output, obs=y)\r\n```\r\nNow, we could definitely just replace our existing GPyTorch interface to basically do the above instead for any parameter that has a prior registered. The only problem is that I don't know if this will let us place priors over functions of `Parameters` (i.e., if we want to place a prior over the `lengthscale` rather than the `raw_lengthscale`).\r\n\r\nThoughts? I feel like the above is *almost* there, but it'd be great to still support placing priors over derived values of the parameters.\r\n\r\ncc/ @rmgarnett\r\n\r\nalso cc/ @fritzo @eb8680 @martinjankowiak in case any of the pyro devs hopefully have a thought about how to do this properly that I'm just missing?\r\n\r\n[Sampling Bug.ipynb.txt](https://github.com/cornellius-gp/gpytorch/files/6328496/Sampling.Bug.ipynb.txt)", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1578/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 1}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1578/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1577", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1577/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1577/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1577/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1577", "id": 859145065, "node_id": "MDU6SXNzdWU4NTkxNDUwNjU=", "number": 1577, "title": "[Bug] Lazy tensor addition with RootLazyTensor broken", "user": {"login": "mwlon", "id": 6504033, "node_id": "MDQ6VXNlcjY1MDQwMzM=", "avatar_url": "https://avatars.githubusercontent.com/u/6504033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mwlon", "html_url": "https://github.com/mwlon", "followers_url": "https://api.github.com/users/mwlon/followers", "following_url": "https://api.github.com/users/mwlon/following{/other_user}", "gists_url": "https://api.github.com/users/mwlon/gists{/gist_id}", "starred_url": "https://api.github.com/users/mwlon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mwlon/subscriptions", "organizations_url": "https://api.github.com/users/mwlon/orgs", "repos_url": "https://api.github.com/users/mwlon/repos", "events_url": "https://api.github.com/users/mwlon/events{/privacy}", "received_events_url": "https://api.github.com/users/mwlon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-04-15T18:29:04Z", "updated_at": "2021-04-16T20:28:48Z", "closed_at": "2021-04-16T20:28:47Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nIn various cases, gpytorch adds a RootLazyTensor to another lazy tensor. These cause the below issue. This appears to have been a long-standing bug, now opened up by unrelated fixes accessing this code path.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nfrom gpytorch.kernels import LinearKernel, MaternKernel, AdditiveKernel, ScaleKernel\r\nfrom gpytorch.models import ExactGP\r\nfrom gpytorch.mlls import ExactMarginalLogLikelihood\r\nfrom gpytorch.likelihoods.gaussian_likelihood import GaussianLikelihood\r\nimport torch\r\nimport gpytorch\r\nfrom gpytorch import settings as gpt_settings\r\nfrom gpytorch.priors import GammaPrior\r\n\r\nk0 = MaternKernel(active_dims=[0, 1, 2])\r\nk1 = LinearKernel(active_dims=[0])  # produces root lazy tensor, must come 2nd\r\nkernel = AdditiveKernel(k0, k1)\r\n\r\n\r\nclass ExactGpModel(ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood, covar_module):\r\n        super(ExactGpModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = covar_module\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nn_dims = 3\r\nn = 2\r\nlikelihood = GaussianLikelihood(noise_prior=GAUSSIAN_NOISE_PRIOR)\r\nx = torch.randn((n, n_dims))\r\ny = torch.randn(n)\r\nmodel = ExactGpModel(x, y, likelihood=likelihood, covar_module=kernel)\r\nmll = ExactMarginalLogLikelihood(likelihood, model)\r\nmll.train()\r\nmll.eval()\r\nmvn = model(torch.randn(77, n_dims))\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, function_dist, target, *params)\r\n     60         # Get the log prob of the marginal distribution\r\n     61         output = self.likelihood(function_dist, *params)\r\n---> 62         res = output.log_prob(target)\r\n     63         res = self._add_other_terms(res, params)\r\n     64 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    145     def log_prob(self, value):\r\n    146         if settings.fast_computations.log_prob.off():\r\n--> 147             return super().log_prob(value)\r\n    148 \r\n    149         if self._validate_args:\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/torch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    206             self._validate_sample(value)\r\n    207         diff = value - self.loc\r\n--> 208         M = _batch_mahalanobis(self._unbroadcasted_scale_tril, diff)\r\n    209         half_log_det = self._unbroadcasted_scale_tril.diagonal(dim1=-2, dim2=-1).log().sum(-1)\r\n    210         return -0.5 * (self._event_shape[0] * math.log(2 * math.pi) + M) - half_log_det\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py in _unbroadcasted_scale_tril(self)\r\n     55         if self.islazy and self.__unbroadcasted_scale_tril is None:\r\n     56             # cache root decoposition\r\n---> 57             ust = delazify(self.lazy_covariance_matrix.cholesky())\r\n     58             self.__unbroadcasted_scale_tril = ust\r\n     59         return self.__unbroadcasted_scale_tril\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in cholesky(self, upper)\r\n    965             (LazyTensor) Cholesky factor (triangular, upper/lower depending on \"upper\" arg)\r\n    966         \"\"\"\r\n--> 967         chol = self._cholesky(upper=False)\r\n    968         if upper:\r\n    969             chol = chol._transpose_nonbatch()\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in _cholesky(self, upper)\r\n    415         from .keops_lazy_tensor import KeOpsLazyTensor\r\n    416 \r\n--> 417         evaluated_kern_mat = self.evaluate_kernel()\r\n    418 \r\n    419         if any(isinstance(sub_mat, KeOpsLazyTensor) for sub_mat in evaluated_kern_mat._args):\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py in evaluate_kernel(self)\r\n    181         In particular, covar1 would *always* be a standard AddedDiagLazyTensor, but covar2 might be a subtype.\r\n    182         \"\"\"\r\n--> 183         added_diag_lazy_tsr = self.representation_tree()(*self.representation())\r\n    184         return added_diag_lazy_tsr._lazy_tensor + added_diag_lazy_tsr._diag_tensor\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in representation_tree(self)\r\n   1520         including all subobjects. This is used internally.\r\n   1521         \"\"\"\r\n-> 1522         return LazyTensorRepresentationTree(self)\r\n   1523 \r\n   1524     @property\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor_representation_tree.py in __init__(self, lazy_tsr)\r\n     11         for arg in lazy_tsr._args:\r\n     12             if hasattr(arg, \"representation\") and callable(arg.representation):  # Is it a lazy tensor?\r\n---> 13                 representation_size = len(arg.representation())\r\n     14                 self.children.append((slice(counter, counter + representation_size, None), arg.representation_tree()))\r\n     15                 counter += representation_size\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in representation(self)\r\n    315         # representation\r\n    316         else:\r\n--> 317             return self.evaluate_kernel().representation()\r\n    318 \r\n    319     def representation_tree(self):\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)\r\n    282             temp_active_dims = self.kernel.active_dims\r\n    283             self.kernel.active_dims = None\r\n--> 284             res = self.kernel(x1, x2, diag=False, last_dim_is_batch=self.last_dim_is_batch, **self.params)\r\n    285             self.kernel.active_dims = temp_active_dims\r\n    286 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, last_dim_is_batch, **params)\r\n    396                 res = LazyEvaluatedKernelTensor(x1_, x2_, kernel=self, last_dim_is_batch=last_dim_is_batch, **params)\r\n    397             else:\r\n--> 398                 res = lazify(super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\r\n    399             return res\r\n    400 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/kernels/kernel.py in forward(self, x1, x2, diag, **params)\r\n    465             next_term = kern(x1, x2, diag=diag, **params)\r\n    466             if not diag:\r\n--> 467                 res = res + lazify(next_term)\r\n    468             else:\r\n    469                 res = res + next_term\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/non_lazy_tensor.py in __add__(self, other)\r\n     79             return NonLazyTensor(self.tensor + other)\r\n     80         else:\r\n---> 81             return super(NonLazyTensor, self).__add__(other)\r\n     82 \r\n     83     def mul(self, other):\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in __add__(self, other)\r\n   2042             return AddedDiagLazyTensor(self, other)\r\n   2043         elif isinstance(other, RootLazyTensor):\r\n-> 2044             return self.add_low_rank(self, other.root)\r\n   2045         elif isinstance(other, Tensor):\r\n   2046             other = lazify(other)\r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in add_low_rank(self, low_rank_mat, root_decomp_method, root_inv_decomp_method, generate_roots, **root_decomp_kwargs)\r\n    890 \r\n    891         # first get LL^T = A\r\n--> 892         current_root = self.root_decomposition(method=root_decomp_method, **root_decomp_kwargs).root\r\n    893         return_triangular = isinstance(current_root, TriangularLazyTensor)\r\n    894 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n/code/venvs/venv/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py in root_decomposition(self, method)\r\n   1662             return RootLazyTensor(self._root_decomposition())\r\n   1663 \r\n-> 1664         raise RuntimeError(f\"Unknown method '{method}'\")\r\n   1665 \r\n   1666     @cached(name=\"root_inv_decomposition\")\r\n\r\nRuntimeError: Unknown method '<gpytorch.lazy.non_lazy_tensor.NonLazyTensor object at 0x7f346c2217f0>'\r\n```\r\n\r\n## Expected Behavior\r\n\r\ncorrect addition without 1. type errors (it expects string but got tensor) or 2. treating lazy tensors as regular tensors\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch version: 1.4.1\r\n- torch version: 1.7.1\r\n- OS: ubuntu\r\n\r\n## Additional context\r\n\r\nI already made a PR that fixes this: https://github.com/cornellius-gp/gpytorch/pull/1576\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1577/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1577/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1562", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1562/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1562/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1562/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1562", "id": 856017514, "node_id": "MDExOlB1bGxSZXF1ZXN0NjEzNjY0MTk1", "number": 1562, "title": "No CG warning when max_iter < 10", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-04-12T14:09:09Z", "updated_at": "2021-11-22T14:11:37Z", "closed_at": "2021-04-12T22:22:51Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1562", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1562", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1562.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1562.patch", "merged_at": "2021-04-12T22:22:51Z"}, "body": "[Fixes #1557]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1562/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1562/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1557", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1557/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1557/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1557/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1557", "id": 853717663, "node_id": "MDU6SXNzdWU4NTM3MTc2NjM=", "number": 1557, "title": "[Bug] CG convergence warning incorrectly triggered when max_iter <= 10", "user": {"login": "anthonycaterini", "id": 8323248, "node_id": "MDQ6VXNlcjgzMjMyNDg=", "avatar_url": "https://avatars.githubusercontent.com/u/8323248?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anthonycaterini", "html_url": "https://github.com/anthonycaterini", "followers_url": "https://api.github.com/users/anthonycaterini/followers", "following_url": "https://api.github.com/users/anthonycaterini/following{/other_user}", "gists_url": "https://api.github.com/users/anthonycaterini/gists{/gist_id}", "starred_url": "https://api.github.com/users/anthonycaterini/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anthonycaterini/subscriptions", "organizations_url": "https://api.github.com/users/anthonycaterini/orgs", "repos_url": "https://api.github.com/users/anthonycaterini/repos", "events_url": "https://api.github.com/users/anthonycaterini/events{/privacy}", "received_events_url": "https://api.github.com/users/anthonycaterini/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-04-08T18:04:32Z", "updated_at": "2021-04-12T22:22:51Z", "closed_at": "2021-04-12T22:22:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThe linear conjugate gradient method can incorrectly flag a numerical error higher than the tolerance when `max_iter <= 10`.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nfrom gpytorch.utils import linear_cg\r\nimport torch\r\n\r\nmat = torch.rand((2,2))\r\nmatmul_closure = lambda x: torch.matmul(mat, x)\r\nrhs = torch.rand((2,1))\r\n\r\nsolve = linear_cg(matmul_closure, rhs, max_iter=2, max_tridiag_iter=2)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nNumericalWarning: CG terminated in 2 iterations with average residual norm 0.48401400446891785 which is larger than the tolerance of 1 specified by gpytorch.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a gpytorch.settings.max_cg_iterations(value) context.\r\n```\r\n\r\n## Expected Behavior\r\n\r\nWe would expect this warning to not be triggered, as the average residual norm is smaller than the tolerance of 1.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version 1.4.0\r\n- PyTorch Version 1.7.1\r\n- Computer OS: Ubuntu 18.04\r\n\r\n## Additional context\r\nThe problem here is that `tolerance_reached=True` is never triggered on Line 286 of `linear_cg.py` since `k < 10` whenever `max_iter <= 10`. This then incorrectly triggers the warning on Line 317.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1557/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1557/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1543", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1543/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1543/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1543/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1543", "id": 841143355, "node_id": "MDU6SXNzdWU4NDExNDMzNTU=", "number": 1543, "title": "[Bug] Keops kernels have no gradients when inputs are not contiguous", "user": {"login": "KeAWang", "id": 11478740, "node_id": "MDQ6VXNlcjExNDc4NzQw", "avatar_url": "https://avatars.githubusercontent.com/u/11478740?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KeAWang", "html_url": "https://github.com/KeAWang", "followers_url": "https://api.github.com/users/KeAWang/followers", "following_url": "https://api.github.com/users/KeAWang/following{/other_user}", "gists_url": "https://api.github.com/users/KeAWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/KeAWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KeAWang/subscriptions", "organizations_url": "https://api.github.com/users/KeAWang/orgs", "repos_url": "https://api.github.com/users/KeAWang/repos", "events_url": "https://api.github.com/users/KeAWang/events{/privacy}", "received_events_url": "https://api.github.com/users/KeAWang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-03-25T17:16:46Z", "updated_at": "2021-06-09T17:31:45Z", "closed_at": "2021-06-09T17:31:45Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\n\r\nmake_contiguous = False  # change to `True` to get correct gradients\r\n\r\ndevice = \"cuda\"\r\nx = torch.randn(3, 1000, device=device)\r\nx = x.transpose(0, 1).view(1000, 3)  # make non-contiguous\r\nif make_contiguous:\r\n    x = x.contiguous()\r\nprint(f\"x is contiguous: {x.is_contiguous()}\")\r\ny = x.sum(-1) \r\n\r\nkernel = gpytorch.kernels.keops.RBFKernel().to(device)\r\nkernel.train()\r\nresult = (kernel(x) @ y).sum()\r\nresult.backward()\r\nprint(f\"raw_lengthscale.grad: {kernel.raw_lengthscale.grad}\")\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nx is contiguous: False\r\nraw_lengthscale.grad: None\r\n```\r\n\r\n## Expected Behavior\r\nShould print a non-zero gradient:\r\n```\r\nraw_lengthscale.grad: tensor([[-8274.9004]], device='cuda:0')\r\n```\r\nwhich you can reproduce by setting `make_contiguous = True`\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch version: '1.3.0', but also reproduces on `master`\r\n- PyTorch version: '1.8.0'\r\n\r\n## Some extra context\r\nThis is an issue because if `train_x` is ever not contiguous, we get a silent failure in the gradients (they all become None). A hotfix would just be to call `.contiguous` everywhere within the keops kernels, though I think this is an issue on the keops side.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1543/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1543/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1528", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1528/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1528/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1528/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1528", "id": 832099809, "node_id": "MDExOlB1bGxSZXF1ZXN0NTkzMzE1ODU2", "number": 1528, "title": "Speed up SGPR covariances", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2021-03-15T18:54:30Z", "updated_at": "2021-04-12T13:20:38Z", "closed_at": "2021-04-12T13:20:34Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1528", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1528", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1528.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1528.patch", "merged_at": "2021-04-12T13:20:34Z"}, "body": "Addresses problem in #1515 . @monabf - can you check out the `faster_sgpr_covar` branch and make sure that this fix works for you? If so, then we'll cut a bug fix release that should hopefully fix these SGPR issues once and for all :)", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1528/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1528/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1525", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1525/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1525/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1525/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1525", "id": 827507245, "node_id": "MDU6SXNzdWU4Mjc1MDcyNDU=", "number": 1525, "title": "[Bug] Deterministic Initializations (Perhaps this is Feature Request or Documentation, depends on intended behavior)", "user": {"login": "syncrostone", "id": 7110955, "node_id": "MDQ6VXNlcjcxMTA5NTU=", "avatar_url": "https://avatars.githubusercontent.com/u/7110955?v=4", "gravatar_id": "", "url": "https://api.github.com/users/syncrostone", "html_url": "https://github.com/syncrostone", "followers_url": "https://api.github.com/users/syncrostone/followers", "following_url": "https://api.github.com/users/syncrostone/following{/other_user}", "gists_url": "https://api.github.com/users/syncrostone/gists{/gist_id}", "starred_url": "https://api.github.com/users/syncrostone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/syncrostone/subscriptions", "organizations_url": "https://api.github.com/users/syncrostone/orgs", "repos_url": "https://api.github.com/users/syncrostone/repos", "events_url": "https://api.github.com/users/syncrostone/events{/privacy}", "received_events_url": "https://api.github.com/users/syncrostone/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-03-10T10:33:53Z", "updated_at": "2021-03-10T16:21:04Z", "closed_at": "2021-03-10T16:21:04Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThe initialization of kernel parameters seems to be deterministic even when initializing multiple versions of the kernel individually.\r\n\r\nIf this is expected behavior, it would be nice to document this somewhere. In that case, this should be converted to a feature request -- ideally, I would like to be able to set it so that kernel parameters initialize randomly, and it would be nice to be able to specify what distribution these parameters are drawn from.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\na = gpytorch.kernels.RBFKernel()\r\nb = gpytorch.kernels.RBFKernel()\r\nprint(a.lengthscale)\r\nprint(b.lengthscale)\r\n```\r\n\r\n** Output **\r\n```\r\n tensor([[0.6931]], grad_fn=<SoftplusBackward>)\r\n tensor([[0.6931]], grad_fn=<SoftplusBackward>)\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI expected the lengthscales for the two different initializations of RBFKernel to be different.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 1.4.0\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> '1.7.1+cu101'\r\n- <!-- Computer OS --> Ubuntu 16.04.6 LTS\r\n\r\n## Additional context\r\nI am using a version of multitask kernels (implementing GPFA in GPytorch, will post a pull request with details and implementation questions later), and symmetry in lengthscales is annoying for training at least at the start. I can initialize randomly after the fact, but ideally I would think that should be default behavior (you can always make it deterministic by setting the seed).\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1525/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1525/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1518", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1518/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1518/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1518/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1518", "id": 819035646, "node_id": "MDExOlB1bGxSZXF1ZXN0NTgyMjAyMzA4", "number": 1518, "title": "Ensure LazyEvaluatedKernelTensor requires grad.", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-03-01T16:29:06Z", "updated_at": "2021-03-18T14:07:02Z", "closed_at": "2021-03-18T14:06:54Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1518", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1518", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1518.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1518.patch", "merged_at": "2021-03-18T14:06:54Z"}, "body": "Currently, LazyEvaluatedKernelTensor only checks the kernel inputs during a  call. This is not desired behavior, because the kernel object itself likely has parameters that require gradients.\r\nBy passing the kernel parameters into the LazyTensor super constructor, we ensure that these are included as part of the  call.\r\n\r\n[Fixes #1511]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1518/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1518/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1517", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1517/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1517/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1517/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1517", "id": 819004412, "node_id": "MDExOlB1bGxSZXF1ZXN0NTgyMTc2MTM1", "number": 1517, "title": "Fix SGPR variance bug", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-03-01T15:55:23Z", "updated_at": "2021-11-22T14:11:40Z", "closed_at": "2021-03-09T06:45:34Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1517", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1517", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1517.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1517.patch", "merged_at": "2021-03-09T06:45:34Z"}, "body": "[Fixes #1515]\r\n\r\nThis addresses a bug introduced by #1493 ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1517/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1517/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1516", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1516/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1516/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1516/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1516", "id": 818957630, "node_id": "MDU6SXNzdWU4MTg5NTc2MzA=", "number": 1516, "title": "[Bug] New release initialize MultitaskGaussianLikelihood", "user": {"login": "monabf", "id": 26089777, "node_id": "MDQ6VXNlcjI2MDg5Nzc3", "avatar_url": "https://avatars.githubusercontent.com/u/26089777?v=4", "gravatar_id": "", "url": "https://api.github.com/users/monabf", "html_url": "https://github.com/monabf", "followers_url": "https://api.github.com/users/monabf/followers", "following_url": "https://api.github.com/users/monabf/following{/other_user}", "gists_url": "https://api.github.com/users/monabf/gists{/gist_id}", "starred_url": "https://api.github.com/users/monabf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/monabf/subscriptions", "organizations_url": "https://api.github.com/users/monabf/orgs", "repos_url": "https://api.github.com/users/monabf/repos", "events_url": "https://api.github.com/users/monabf/events{/privacy}", "received_events_url": "https://api.github.com/users/monabf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2021-03-01T15:07:59Z", "updated_at": "2021-03-10T16:09:00Z", "closed_at": "2021-03-10T16:09:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n\r\nHi and thanks for the great work.\r\n\r\nBefore the new release I used to initialize the value of a MultitaskGaussianLikelihood with\r\n```python\r\nlikelihood.noise_covar.noise = torch.tensor([0.04])\r\nlikelihood.noise = torch.tensor([1e-4])\r\n```\r\nbut now this throws an error saying `likelihood.noise_covar.noise` does not exist and `likelihood.noise` is the wrong size for `num_tasks` > 1. Any idea how I am supposed to set the value of the MultitaskGaussianLikelihood now? See #1303 for the post that advised me to initialize this way in the first place.\r\n\r\nThanks!\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport torch\r\nimport gpytorch\r\nimport logging\r\nimport math\r\nimport numpy as np\r\nfrom matplotlib import pyplot as plt\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood, kernel):\r\n        train_x = torch.squeeze(train_x)\r\n        train_y = torch.squeeze(train_y)\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = kernel\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n    def optimize(self, likelihood, train_x, train_y, training_iter=50,\r\n                 optimizer='Adam'):\r\n        train_x = torch.squeeze(train_x)\r\n        train_y = torch.squeeze(train_y)\r\n        self.train()\r\n        likelihood.train()\r\n        if optimizer == 'Adam':\r\n            optimizer = torch.optim.Adam(self.parameters(), lr=0.1)\r\n        else:\r\n            logging.error('Undefined optimizer')\r\n        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, self)\r\n        for i in range(training_iter):\r\n            # Zero gradients from previous iteration\r\n            optimizer.zero_grad()\r\n            # Output from model\r\n            output = self(train_x)\r\n            # Calculate loss and backpropagate gradients\r\n            loss = -mll(output, train_y)\r\n            loss.backward()\r\n            optimizer.step()\r\n\r\n    def predict(self, x, likelihood, full_cov=False):\r\n        self.eval()\r\n        likelihood.eval()\r\n        with torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n            observed_pred = likelihood(self(x))\r\n            if not full_cov:\r\n                mean = observed_pred.mean\r\n                var = observed_pred.variance\r\n            else:\r\n                mean = observed_pred.mean\r\n                var = observed_pred.covariance_matrix\r\n        return mean, var\r\n\r\nclass BatchIndependentMultitaskGPModel(ExactGPModel):\r\n    def __init__(self, train_x, train_y, likelihood, kernel, output_size=1):\r\n        super().__init__(train_x, train_y, likelihood, kernel)\r\n        self.mean_module = gpytorch.means.ConstantMean(\r\n            batch_shape=torch.Size([output_size]))\r\n        self.covar_module = kernel\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        multitask_result = \\\r\n            gpytorch.distributions.MultitaskMultivariateNormal.from_batch_mvn(\r\n                gpytorch.distributions.MultivariateNormal(mean_x, covar_x))\r\n        return multitask_result\r\n\r\nif __name__ == '__main__':\r\n    # Multi input, independent multi output\r\n    train_x = torch.stack((\r\n        torch.linspace(0, 1, 100), torch.linspace(0, 1, 100)), dim=1)\r\n    train_y = torch.stack((\r\n        torch.sin(train_x[:, 0] * (2 * math.pi)) + torch.randn(\r\n            train_x[:, 0].size()) * math.sqrt(0.04),\r\n        3 * torch.square(\r\n            torch.cos(train_x[:, 1] * (2 * math.pi))) + torch.randn(\r\n            train_x[:, 1].size()) * math.sqrt(0.0001),\r\n        3 * torch.square(\r\n            torch.cos(train_x[:, 1] * (2 * math.pi))) + torch.randn(\r\n            train_x[:, 1].size()) * math.sqrt(0.0001)), dim=1)\r\n    train_y = torch.squeeze(train_y)\r\n    likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(\r\n        num_tasks=train_y.shape[1],\r\n        noise_prior=gpytorch.priors.MultivariateNormalPrior(\r\n            torch.tensor([0.04, 0.04, 0.04]),\r\n            torch.diag(torch.tensor([1., 1, 1]))))\r\n    likelihood.noise_covar.noise = torch.tensor([0.04])\r\n    likelihood.noise = torch.tensor([1e-4])\r\n    lengthscale_prior = gpytorch.priors.MultivariateNormalPrior(\r\n        torch.tensor([0.2, 0.2]),\r\n        torch.diag(torch.tensor([6.0, 6.0])))\r\n    outputscale_prior = gpytorch.priors.NormalPrior(1.0, 0.15)\r\n    hypers = {'base_kernel.lengthscale': lengthscale_prior.mean,\r\n              'outputscale': outputscale_prior.mean}\r\n    kernel = gpytorch.kernels.ScaleKernel(\r\n        gpytorch.kernels.RBFKernel(\r\n            batch_shape=torch.Size([train_y.shape[1]]),\r\n            ard_num_dims=train_x.shape[1]),\r\n        batch_shape=torch.Size([train_y.shape[1]]))\r\n    kernel.initialize(**hypers)  # init kernel hyperparams\r\n    model = BatchIndependentMultitaskGPModel(train_x, train_y, likelihood,\r\n                                             kernel,\r\n                                             output_size=train_y.shape[1])\r\n    print('multioutput')\r\n    print(model.state_dict())\r\n    # Evaluate GP by making predictions on test set\r\n    test_x = torch.stack((\r\n        torch.linspace(0, 1, 51), torch.linspace(0, 1, 51)), dim=1)\r\n    mean, var = model.predict(test_x, likelihood)\r\n    lower = mean - 2 * torch.sqrt(var)\r\n    upper = mean + 2 * torch.sqrt(var)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch_advanced/venv/lib/python3.9/site-packages/gpytorch/module.py\", line 412, in __getattr__\r\n    return super().__getattribute__(name)\r\nAttributeError: 'MultitaskGaussianLikelihood' object has no attribute 'noise_covar'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch_advanced/src/script4.py\", line 89, in <module>\r\n    likelihood.noise_covar.noise = torch.tensor([0.04])\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch_advanced/venv/lib/python3.9/site-packages/gpytorch/module.py\", line 414, in __getattr__\r\n    raise e\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch_advanced/venv/lib/python3.9/site-packages/gpytorch/module.py\", line 409, in __getattr__\r\n    return super().__getattr__(name)\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch_advanced/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 778, in __getattr__\r\n    raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\r\ntorch.nn.modules.module.ModuleAttributeError: 'MultitaskGaussianLikelihood' object has no attribute 'noise_covar'\r\n```\r\n\r\n## System information\r\n\r\n- GPyTorch version 1.4.0\r\n- PyTorch version 1.7.1\r\n- Mac OS Big Sur\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1516/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1516/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1515", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1515/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1515/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1515/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1515", "id": 818939235, "node_id": "MDU6SXNzdWU4MTg5MzkyMzU=", "number": 1515, "title": "[Bug] New release broke SGPR predictive variance?", "user": {"login": "monabf", "id": 26089777, "node_id": "MDQ6VXNlcjI2MDg5Nzc3", "avatar_url": "https://avatars.githubusercontent.com/u/26089777?v=4", "gravatar_id": "", "url": "https://api.github.com/users/monabf", "html_url": "https://github.com/monabf", "followers_url": "https://api.github.com/users/monabf/followers", "following_url": "https://api.github.com/users/monabf/following{/other_user}", "gists_url": "https://api.github.com/users/monabf/gists{/gist_id}", "starred_url": "https://api.github.com/users/monabf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/monabf/subscriptions", "organizations_url": "https://api.github.com/users/monabf/orgs", "repos_url": "https://api.github.com/users/monabf/repos", "events_url": "https://api.github.com/users/monabf/events{/privacy}", "received_events_url": "https://api.github.com/users/monabf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2021-03-01T14:48:47Z", "updated_at": "2022-10-22T22:21:48Z", "closed_at": "2022-10-22T22:21:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nHi guys and thanks a lot for your work.\r\n\r\nThe predictive variance in my SGPR use cases is broken, approximately since the new release. This happens in both single output and batch mode, it doesn't throw an error but the values for the predictive variance are abnormally large and often negative. Probably a bug that slipped unnoticed through the release, maybe in the InducingPointKernel.\r\n\r\nThanks for your help!\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport time\r\nimport urllib.request\r\nimport gpytorch\r\nimport torch\r\nfrom gpytorch.distributions import MultivariateNormal\r\nfrom gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\r\nfrom gpytorch.means import ConstantMean\r\nfrom scipy.io import loadmat\r\n\r\nif __name__ == '__main__':\r\n    # Run GPyTorch SGPR + independent multioutputs example: approximate\r\n    # https://docs.gpytorch.ai/en/v1.2.1/examples/02_Scalable_Exact_GPs/SGPR_Regression_CUDA.html\r\n    # https://github.com/cornellius-gp/gpytorch/issues/1043\r\n    print('Downloading \\'elevators\\' UCI dataset...')\r\n    urllib.request.urlretrieve(\r\n        'https://drive.google.com/uc?export=download&id=1jhWL3YUHvXIaftia4qeAyDwVxo6j1alk',\r\n        '../elevators.mat')\r\n    output_size = 1\r\n    input_size = 18\r\n    nb_inducing_points = 500\r\n    data = torch.Tensor(loadmat('../elevators.mat')['data'])\r\n    X = data[:, :-1]\r\n    X = X - X.min(0)[0]\r\n    X = 2 * (X / X.max(0)[0]) - 1\r\n    X = X[:, :input_size]\r\n    y = data[:, -1]\r\n    # MAKE MULTIOUTPUT DATA\r\n    y = y.reshape(-1, 1)\r\n    y = y.repeat(1, output_size)\r\n    input_size = X.shape[1]\r\n    train_x = X[:10000, :].contiguous()\r\n    train_y = y[:10000].contiguous()\r\n    test_x = X[10000:20000, :].contiguous()\r\n    test_y = y[10000:20000].contiguous()\r\n    if torch.cuda.is_available():\r\n        train_x, train_y, test_x, test_y = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda()\r\n    # CONVERT TO BATCH GP\r\n    train_x = train_x.repeat(output_size, 1, 1)\r\n    train_y = train_y.transpose(-2, -1)\r\n    test_x = test_x.repeat(output_size, 1, 1)\r\n    test_y = test_y.transpose(-2, -1)\r\n\r\n\r\n    class GPRegressionModel(gpytorch.models.ExactGP):\r\n        def __init__(self, train_x, train_y, likelihood):\r\n            super(GPRegressionModel, self).__init__(train_x, train_y,\r\n                                                    likelihood)\r\n            self.mean_module = ConstantMean(\r\n                batch_shape=torch.Size([output_size]))\r\n            self.base_covar_module = ScaleKernel(RBFKernel(\r\n                batch_shape=torch.Size([output_size])),\r\n                batch_shape=torch.Size([output_size]))\r\n            inducing_points = train_x[:, :nb_inducing_points, :]\r\n            self.covar_module = InducingPointKernel(\r\n                self.base_covar_module,\r\n                inducing_points=inducing_points,\r\n                likelihood=likelihood)\r\n\r\n        def forward(self, x):\r\n            mean_x = self.mean_module(x)\r\n            covar_x = self.covar_module(x)\r\n            return MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood(\r\n        batch_shape=torch.Size([output_size]))\r\n    model = GPRegressionModel(train_x, train_y, likelihood)\r\n    if torch.cuda.is_available():\r\n        model = model.cuda()\r\n        likelihood = likelihood.cuda()\r\n    # Train\r\n    training_iterations = 10\r\n    model.train()\r\n    likelihood.train()\r\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n    for i in range(training_iterations):\r\n        start = time.time()\r\n        # Zero backprop gradients\r\n        optimizer.zero_grad()\r\n        # Get output from model\r\n        output = model(train_x)\r\n        # Calc loss and backprop derivatives\r\n        loss = -mll(output, train_y).sum()\r\n        loss.backward()\r\n        end = time.time()\r\n        print('Iter %d/%d - Loss: %.3f' % (\r\n            i + 1, training_iterations, loss.item()), 'in', str(end - start))\r\n        optimizer.step()\r\n        torch.cuda.empty_cache()\r\n    model.eval()\r\n    likelihood.eval()\r\n    with gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\r\n        with gpytorch.settings.max_root_decomposition_size(\r\n                30), gpytorch.settings.fast_pred_var():\r\n            preds = model(test_x)\r\n    print(torch.mean(preds.covariance_matrix))\r\n    print(torch.mean(preds.variance))\r\n```\r\n\r\n## Expected Behavior\r\n\r\nWith version 1.3.1 of GPyTorch, outputs `tensor(3.6882e-05, grad_fn=<MeanBackward0>)`, `tensor(0.0162, grad_fn=<MeanBackward0>)`.\r\nWith version 1.4.0, outputs `tensor(-2916.0591)` then hangs. \r\n\r\n## System information\r\n\r\n- GPyTorch version 1.4.0\r\n- PyTorch version 1.7.1\r\n- Mac OS Big Sur\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1515/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1515/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1511", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1511/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1511/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1511/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1511", "id": 817516078, "node_id": "MDU6SXNzdWU4MTc1MTYwNzg=", "number": 1511, "title": "[Bug] LazyEvaluatedKernelTensor does not require gradient if inputs do not require gradient", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-02-26T17:00:26Z", "updated_at": "2021-03-18T14:06:54Z", "closed_at": "2021-03-18T14:06:54Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nNot entirely sure if this is intended behavior, but it does produce some downstream problems. \r\nIf the input to `kernel(x)` doesn't require a gradient `LazyEvaluatedKernelTensor` does not portray as requiring a gradient, even though it does. Crucially `kernel(x).evaluate_kernel()` does. \r\n\r\nAs a result, it causes some weirdness downstream in objects that can manipulate lazy kernel tensors themselves:\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nfrom gpytorch.kernels import MaternKernel\r\nfrom gpytorch.lazy import KroneckerProductLazyTensor\r\n\r\ntorch.random.manual_seed(3)\r\n\r\nkernels = [MaternKernel()] * 3\r\nx = [torch.randn(5)] * 3\r\n\r\nkernels[0](x[0]).requires_grad # False\r\n\r\n# breaking behavior\r\nkplt = KroneckerProductLazyTensor(*[k(a) for k, a in zip(kernels, x)])\r\n\r\nrhs = torch.randn(kplt.shape[-1])\r\nprint(kplt.matmul(rhs).requires_grad) # True, as expected\r\n\r\nkdiag = kplt.diag()\r\nprint(kdiag.requires_grad) # False ??\r\n\r\n# the fix is that this works fine\r\nkplt = KroneckerProductLazyTensor(*[k(a).evaluate_kernel() for k, a in zip(kernels, x)])\r\nkdiag = kplt.diag()\r\nprint(kdiag.requires_grad) # True\r\n```\r\n\r\n\r\n## Expected Behavior\r\n\r\nLazyKernelEvaluatedTensor should probably require a gradient to prevent this sort of behavior from happening.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\ngpytorch master\r\n\r\n## Additional context\r\n\r\nI'm trying to implement structured variational MTGP models with non-gaussian likelihoods and am struggling to get reasonable gradients, noticed while debugging.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1511/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 1}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1511/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1509", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1509/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1509/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1509/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1509", "id": 817413761, "node_id": "MDU6SXNzdWU4MTc0MTM3NjE=", "number": 1509, "title": "[Bug] num_gauss_hermite quadrature value setter isn't working", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-02-26T14:44:13Z", "updated_at": "2021-03-01T14:48:08Z", "closed_at": "2021-03-01T14:48:07Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nTrying to set `num_gauss_hermite_quadrature(int)` isn't affecting the number of locations in the quadrature.\r\n\r\nI think it's with how the default is set in the initialization because using `num_likelhood_samples(int)` works fine so it's not just the setter method.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nfrom gpytorch.utils.quadrature import GaussHermiteQuadrature1D\r\nfrom gpytorch.settings import num_gauss_hermite_locs\r\n\r\nwith num_gauss_hermite_locs(25):\r\n    quadrature = GaussHermiteQuadrature1D()\r\n    print(num_gauss_hermite_locs._global_value) # 25\r\n    print(num_gauss_hermite_locs.value()) # 25\r\n    print(quadrature.num_locs) # 20\r\n```\r\n\r\n** Stack trace/error message **\r\nsee above\r\n\r\n## Expected Behavior\r\n\r\n`quadrature.num_locs` should be 20\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch master\r\n- torch 1.7.0\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1509/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1509/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1500", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1500/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1500/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1500/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1500", "id": 812829053, "node_id": "MDU6SXNzdWU4MTI4MjkwNTM=", "number": 1500, "title": "[Bug] Variational GPs w/ Multiple Outputs example produces error", "user": {"login": "flcello", "id": 57724549, "node_id": "MDQ6VXNlcjU3NzI0NTQ5", "avatar_url": "https://avatars.githubusercontent.com/u/57724549?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flcello", "html_url": "https://github.com/flcello", "followers_url": "https://api.github.com/users/flcello/followers", "following_url": "https://api.github.com/users/flcello/following{/other_user}", "gists_url": "https://api.github.com/users/flcello/gists{/gist_id}", "starred_url": "https://api.github.com/users/flcello/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flcello/subscriptions", "organizations_url": "https://api.github.com/users/flcello/orgs", "repos_url": "https://api.github.com/users/flcello/repos", "events_url": "https://api.github.com/users/flcello/events{/privacy}", "received_events_url": "https://api.github.com/users/flcello/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-02-21T11:08:27Z", "updated_at": "2021-02-22T15:33:06Z", "closed_at": "2021-02-22T15:33:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen I try to reproduce the [Variational GPs w/ Multiple Outputs](https://docs.gpytorch.ai/en/v1.1.1/examples/04_Variational_and_Approximate_GPs/SVGP_Multitask_GP_Regression.html) example from the docs I run into an error.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nimport tqdm\r\nfrom matplotlib import pyplot as plt\r\n\r\n%matplotlib inline\r\n%load_ext autoreload\r\n%autoreload 2\r\n\r\ntrain_x = torch.linspace(0, 1, 100)\r\n\r\ntrain_y = torch.stack([\r\n    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n    torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n], -1)\r\n\r\nclass MultitaskGPModel(gpytorch.models.ApproximateGP):\r\n    def __init__(self, inducing_points):\r\n        # We have to mark the CholeskyVariationalDistribution as batch\r\n        # so that we learn a variational distribution for each task\r\n        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\r\n            inducing_points.size(-2), batch_shape=torch.Size([2])\r\n        )\r\n\r\n        # We have to wrap the VariationalStrategy in a MultitaskVariationalStrategy\r\n        # so that the output will be a MultitaskMultivariateNormal rather than a batch output\r\n        variational_strategy = gpytorch.variational.MultitaskVariationalStrategy(\r\n            gpytorch.variational.VariationalStrategy(\r\n                self, inducing_points, variational_distribution, learn_inducing_locations=True\r\n            ), num_tasks=2\r\n        )\r\n\r\n        super().__init__(variational_strategy)\r\n\r\n        # The mean and covariance modules should be marked as batch\r\n        # so we learn a different set of hyperparameters\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([2]))\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([2])),\r\n            batch_shape=torch.Size([2])\r\n        )\r\n\r\n    def forward(self, x):\r\n        # The forward function should be written as if we were dealing with each output\r\n        # dimension in batch\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\n# The shape of the inducing points should be (2 x m x 1) - so that we learn different inducing\r\n# points for each output\r\ninducing_points = torch.rand(2, 16, 1)\r\nmodel = MultitaskGPModel(inducing_points)\r\n\r\n# We're going to use a multitask likeihood with this model\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-3-462fa336eb04> in <module>\r\n     36 # points for each output\r\n     37 inducing_points = torch.rand(2, 16, 1)\r\n---> 38 model = MultitaskGPModel(inducing_points)\r\n     39 \r\n     40 # We're going to use a multitask likeihood with this model\r\n\r\n<ipython-input-3-462fa336eb04> in __init__(self, inducing_points)\r\n      9         # We have to wrap the VariationalStrategy in a MultitaskVariationalStrategy\r\n     10         # so that the output will be a MultitaskMultivariateNormal rather than a batch output\r\n---> 11         variational_strategy = gpytorch.variational.MultitaskVariationalStrategy(\r\n     12             gpytorch.variational.VariationalStrategy(\r\n     13                 self, inducing_points, variational_distribution, learn_inducing_locations=True\r\n\r\nTypeError: Can't instantiate abstract class MultitaskVariationalStrategy with abstract methods prior_distribution\r\n```\r\n\r\n## Expected Behavior\r\n\r\nModel instantiation without any error.\r\n\r\n## System information\r\n\r\n- GPyTorch Version: 1.3.1\r\n- PyTorch Version: 1.7.1\r\n- Computer OS: Ubuntu 20.04.1 LTS\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1500/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1500/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1495", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1495/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1495/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1495/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1495", "id": 811558931, "node_id": "MDExOlB1bGxSZXF1ZXN0NTc2MDcwMjA2", "number": 1495, "title": "Avoid Lanczos decomposition with non-deterministic logdet probes", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-02-18T23:40:30Z", "updated_at": "2021-03-20T03:31:57Z", "closed_at": "2021-02-19T00:15:57Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1495", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1495", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1495.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1495.patch", "merged_at": "2021-02-19T00:15:56Z"}, "body": "[Fixes #1491] ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1495/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1495/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1491", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1491/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1491/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1491/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1491", "id": 811311855, "node_id": "MDU6SXNzdWU4MTEzMTE4NTU=", "number": 1491, "title": "[Bug] `gpytorch.settings.deterministic_probes` computes an extra Lanczos factorization", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}, {"id": 1672980023, "node_id": "MDU6TGFiZWwxNjcyOTgwMDIz", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/memory/efficiency", "name": "memory/efficiency", "color": "ffffff", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-02-18T17:31:13Z", "updated_at": "2021-02-19T00:15:56Z", "closed_at": "2021-02-19T00:15:56Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nIn preconditioned CG mode, we make the following lining calls for each training iteration:\r\n\r\n```\r\nLinAlg (Verbose) - DEBUG - Running Pivoted Cholesky on a torch.Size([5000, 5000]) RHS for 15 iterations.\r\n\r\n# these two calls shouldn't exist\r\nLinAlg (Verbose) - DEBUG - Running Lanczos on a torch.Size([5000, 5000]) matrix with a torch.Size([5000, 1]) RHS for 100 iterations.\r\nLinAlg (Verbose) - DEBUG - Running symeig on a matrix of size torch.Size([9, 9]).\r\n\r\nLinAlg (Verbose) - DEBUG - Running CG on a torch.Size([5000, 11]) RHS for 1000 iterations (tol=1). Output: torch.Size([5000, 11]).\r\nLinAlg (Verbose) - DEBUG - Running symeig on a matrix of size torch.Size([10, 4, 4]).\r\n\r\nLinAlg (Verbose) - INFO - Iter 1/50 - Loss: 0.808   lengthscale: 0.693   noise: 0.693\r\n```\r\n\r\nThis Lanczos/symeig calls come from this line in [inv_quad_logdet](https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/functions/_inv_quad_log_det.py#L98)\r\n\r\n```python\r\n            else:  # When preconditioning, probe vectors must be drawn from N(0, P)\r\n                if precond_lt.size()[-2:] == torch.Size([1, 1]):\r\n                    covar_root = precond_lt.evaluate().sqrt()\r\n                else:\r\n                    covar_root = precond_lt.root_decomposition().root\r\n```\r\n\r\nBefore the `gpytorch.settings.deterministic_probes` option was added (#929), the code looked like this:\r\n\r\n```python\r\n            else:  # When preconditioning, probe vectors must be drawn from N(0, P)\r\n                probe_vectors = precond_lt.zero_mean_mvn_samples(num_random_probes)\r\n                # ...\r\n```\r\n\r\nThis is much more efficient, as it does not perform a root decomposition.\r\n\r\n@jacobrgardner there is an obvious easy fix: we don't call `root_decomposition` unless we're using deterministic probes. However, I think this makes the `deterministic_probes` setting really undesirable - the slight variance reductions gains we get from it come at the cost of an extra linalg routine.\r\n\r\nThoughts?", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1491/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1491/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1481", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1481/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1481/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1481/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1481", "id": 808499865, "node_id": "MDU6SXNzdWU4MDg0OTk4NjU=", "number": 1481, "title": "[Bug] Unexpected behavior -- initial value for constraint sets raw value, not transformed value", "user": {"login": "syncrostone", "id": 7110955, "node_id": "MDQ6VXNlcjcxMTA5NTU=", "avatar_url": "https://avatars.githubusercontent.com/u/7110955?v=4", "gravatar_id": "", "url": "https://api.github.com/users/syncrostone", "html_url": "https://github.com/syncrostone", "followers_url": "https://api.github.com/users/syncrostone/followers", "following_url": "https://api.github.com/users/syncrostone/following{/other_user}", "gists_url": "https://api.github.com/users/syncrostone/gists{/gist_id}", "starred_url": "https://api.github.com/users/syncrostone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/syncrostone/subscriptions", "organizations_url": "https://api.github.com/users/syncrostone/orgs", "repos_url": "https://api.github.com/users/syncrostone/repos", "events_url": "https://api.github.com/users/syncrostone/events{/privacy}", "received_events_url": "https://api.github.com/users/syncrostone/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-02-15T12:32:31Z", "updated_at": "2021-02-17T20:39:56Z", "closed_at": "2021-02-17T20:39:56Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nSetting the initial value of a parameter constraint sets the raw parameter to that value, not the transformed parameter. I expect the transformed parameter to be set as that is what I and I expect other users would want to set as the initial value. \r\n\r\nIf setting the raw parameter is the expected / desired behavior, then that should be clarified in the docs.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nimport gpytorch\r\ninitial_value = torch.tensor(1.)\r\nkernel = gpytorch.kernels.RBFKernel(lengthscale_constraint=gpytorch.constraints.Positive(initial_value=initial_value))\r\nprint(\"kernel lengthscale: %f \\nkernel raw_lengthscale: %f\"% (kernel.lengthscale, kernel.raw_lengthscale))\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nkernel lengthscale: 1.313262 \r\nkernel raw_lengthscale: 1.000000\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI expect the following output\r\n```\r\nkernel lengthscale: 1.00000\r\nkernel raw_lengthscale: 0.541325\r\n```\r\n\r\nbecause I expect the above code snippet to be equivalent to \r\n```python\r\nimport torch\r\nimport gpytorch\r\ninitial_value = torch.tensor(1.)\r\nkernel = gpytorch.kernels.RBFKernel()\r\nkernel.lengthscale= initial_value\r\nprint(\"kernel lengthscale: %f \\nkernel raw_lengthscale: %f\"% (kernel.lengthscale, kernel.raw_lengthscale))\r\n```\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version 1.3.1\r\n- PyTorch Version 1.7.1+cu101\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1481/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1481/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1479", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1479/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1479/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1479/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1479", "id": 807133576, "node_id": "MDU6SXNzdWU4MDcxMzM1NzY=", "number": 1479, "title": "[Bug] cholesky decomposition on multitask sparse GP", "user": {"login": "vcharvet", "id": 25750748, "node_id": "MDQ6VXNlcjI1NzUwNzQ4", "avatar_url": "https://avatars.githubusercontent.com/u/25750748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vcharvet", "html_url": "https://github.com/vcharvet", "followers_url": "https://api.github.com/users/vcharvet/followers", "following_url": "https://api.github.com/users/vcharvet/following{/other_user}", "gists_url": "https://api.github.com/users/vcharvet/gists{/gist_id}", "starred_url": "https://api.github.com/users/vcharvet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vcharvet/subscriptions", "organizations_url": "https://api.github.com/users/vcharvet/orgs", "repos_url": "https://api.github.com/users/vcharvet/repos", "events_url": "https://api.github.com/users/vcharvet/events{/privacy}", "received_events_url": "https://api.github.com/users/vcharvet/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-02-12T10:48:21Z", "updated_at": "2021-02-13T11:22:35Z", "closed_at": "2021-02-13T11:22:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\nHello,\r\nI'm using a sparse multitask GP to learn a dynamical model in a reinforcement learning problem. I'm then using the model to compute Moment Matching predictions at uncertain inputs.\r\nIt works well up to a certain amount of points.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nimport gpytorch\r\nimport numpy as np\r\n\r\nfrom gpytorch.likelihoods import GaussianLikelihood, MultitaskGaussianLikelihood\r\nfrom gpytorch.constraints import GreaterThan, Interval\r\nfrom gpytorch.variational import CholeskyVariationalDistribution\r\nfrom gpytorch.variational import VariationalStrategy, IndependentMultitaskVariationalStrategy, CholeskyVariationalDistribution\r\nfrom gpytorch.kernels import RBFKernel, ScaleKernel\r\nfrom gpytorch.distributions import MultitaskMultivariateNormal, MultivariateNormal\r\nfrom gpytorch.means import ConstantMean\r\nfrom gpytorch.mlls import VariationalELBO\r\nfrom gpytorch.lazy import DiagLazyTensor\r\n\r\ntorch.set_default_dtype(torch.float64)\r\n\r\n\r\nnp.random.seed(0)\r\n\r\nk = 2\r\nd = 3\r\nn = 850\r\n\r\n\r\nX0 =  np.random.rand(n, d)\r\nA = np.random.rand(d, k)\r\nY0 = np.sin(X0).dot(A) + 1e-3*(np.random.rand(n, k) - 0.5)  #  Just something\r\nM = 50\r\n\r\nclass SparseMultivariate(gpytorch.models.ApproximateGP):\r\n    def __init__(self, inducing_points):\r\n        batch_shape = torch.Size([k])\r\n        var_distrib = CholeskyVariationalDistribution(\r\n            inducing_points.size(0), batch_shape)\r\n        var_strategy = IndependentMultitaskVariationalStrategy(\r\n            VariationalStrategy(self,\r\n                                inducing_points,\r\n                                var_distrib,\r\n                                learn_inducing_locations=True),\r\n            num_tasks=k)\r\n        super(SparseMultivariate, self).__init__(var_strategy)\r\n        self.mean_module = ConstantMean(batch_shape=batch_shape)\r\n        self.covar_module = ScaleKernel(\r\n            RBFKernel(ard_num_dim=d,\r\n                      batch_shape=batch_shape),\r\n            batch_shape=batch_shape)\r\n\r\n    @property\r\n    def Z(self):\r\n        Z = self.variational_strategy.base_variational_strategy.inducing_points#.T\r\n        return Z.squeeze()\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        mvn =  MultivariateNormal(mean_x, covar_x)\r\n        return mvn\r\n\r\ninducing_points = torch.rand(M, d, dtype=torch.float64)\r\nmodel = SparseMultivariate(inducing_points)\r\n\r\nlikelihood = MultitaskGaussianLikelihood(num_tasks=k)\r\n\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},\r\n    {'params': likelihood.parameters()}], lr=0.1)\r\n\r\nmll = VariationalELBO(likelihood, model, num_data=n)\r\n\r\n\r\nX, Y = torch.tensor(X0), torch.tensor(Y0)\r\nfor i in range(100):\r\n    optimizer.zero_grad()\r\n    output = model(X)\r\n    loss = -mll(output, Y)\r\n    loss.backward()\r\n    optimizer.step()\r\n\r\n# code to compute moments\r\n# eye = torch.eye(M).repeat(d, 1, 1)\r\neye_full = torch.eye(n).repeat(k, 1, 1)\r\n\r\nKmm = model.covar_module(model.Z)\r\nKmn = model.covar_module(model.Z, X)\r\nKnn = model.covar_module(X)\r\n\r\nnoise = likelihood.noise_covar.noise\r\nQ = Kmm.inv_matmul(Kmn.evaluate(), left_tensor=Kmn.transpose(-1, -2).evaluate())\r\nG = DiagLazyTensor((Knn - Q).diag()) + noise[:, None, None] * eye_full\r\nB = Kmm + G.inv_matmul(Kmn.transpose(-1, -2).evaluate(),\r\n                       left_tensor=Kmn.evaluate())\r\n\r\n# beta = B.inv_matmul(Kmn.evaluate()) @ G.inv_matmul(y_train.T[:, :, None])\r\nbeta = G.inv_matmul(Y.T[:, :, None],\r\n                    left_tensor=B.inv_matmul(Kmn.evaluate()))\r\n\r\n```\r\nIt works for `n=800` but not for `n=900`\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/valou/workspace/pythonProjects/.venvs-python37/venv-gym-fb/lib/python3.7/site-packages/gpytorch/utils/cholesky.py\", line 27, in psd_safe_cholesky\r\n    L = torch.cholesky(A, upper=upper, out=out)\r\nRuntimeError: cholesky_cpu: For batch 0: U(13,13) is zero, singular U.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"gpytorch_issue.py\", line 95, in <module>\r\n    left_tensor=B.inv_matmul(Kmn.evaluate()))\r\n  File \"/home/valou/workspace/pythonProjects/.venvs-python37/venv-gym-fb/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\", line 963, in inv_matmul\r\n    return func.apply(self.representation_tree(), False, right_tensor, *self.representation())\r\n  File \"/home/valou/workspace/pythonProjects/.venvs-python37/venv-gym-fb/lib/python3.7/site-packages/gpytorch/functions/_inv_matmul.py\", line 51, in forward\r\n    solves = _solve(lazy_tsr, right_tensor)\r\n  File \"/home/valou/workspace/pythonProjects/.venvs-python37/venv-gym-fb/lib/python3.7/site-packages/gpytorch/functions/_inv_matmul.py\", line 15, in _solve\r\n    return lazy_tsr.cholesky()._cholesky_solve(rhs)\r\n  File \"/home/valou/workspace/pythonProjects/.venvs-python37/venv-gym-fb/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\", line 750, in cholesky\r\n    chol = self._cholesky(upper=False)\r\n  File \"/home/valou/workspace/pythonProjects/.venvs-python37/venv-gym-fb/lib/python3.7/site-packages/gpytorch/utils/memoize.py\", line 59, in g\r\n    return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n  File \"/home/valou/workspace/pythonProjects/.venvs-python37/venv-gym-fb/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\", line 419, in _cholesky\r\n    cholesky = psd_safe_cholesky(evaluated_mat, jitter=settings.cholesky_jitter.value(), upper=upper).contiguous()\r\n  File \"/home/valou/workspace/pythonProjects/.venvs-python37/venv-gym-fb/lib/python3.7/site-packages/gpytorch/utils/cholesky.py\", line 51, in psd_safe_cholesky\r\n    f\"Matrix not positive definite after repeatedly adding jitter up to {jitter_new:.1e}. \"\r\ngpytorch.utils.errors.NotPSDError: Matrix not positive definite after repeatedly adding jitter up to 1.0e-06. Original error on first attempt: cholesky_cpu: For batch 0: U(13,13) is zero, singular U.\r\n\r\n```\r\n\r\n## Expected Behavior\r\n\r\nFor low values of n, but if n is too high, matrix `B` becomes singular\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGPytorch version: 1.3.1\r\nPytorch version:  1.7.0\r\n\r\nOS: `$lsb_release - a`  \r\nDistributor ID: Debian\r\nDescription:    Debian GNU/Linux 9.13 (stretch)\r\nRelease:        9.13\r\nCodename:       stretch\r\n\r\n\r\n## Additional context\r\nIn the RL context, we should be able to compute the predictions as $n \\rightarrow \\infty$\r\n\r\nReference for MM prediction: Peter Deisenroth, M. (2010). Efficient Reinforcement Learning using Gaussian Processes, chapter 2.4\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1479/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1479/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1478", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1478/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1478/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1478/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1478", "id": 807006585, "node_id": "MDU6SXNzdWU4MDcwMDY1ODU=", "number": 1478, "title": "How are additive kernels represented", "user": {"login": "dhruvbalwada", "id": 18236610, "node_id": "MDQ6VXNlcjE4MjM2NjEw", "avatar_url": "https://avatars.githubusercontent.com/u/18236610?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dhruvbalwada", "html_url": "https://github.com/dhruvbalwada", "followers_url": "https://api.github.com/users/dhruvbalwada/followers", "following_url": "https://api.github.com/users/dhruvbalwada/following{/other_user}", "gists_url": "https://api.github.com/users/dhruvbalwada/gists{/gist_id}", "starred_url": "https://api.github.com/users/dhruvbalwada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dhruvbalwada/subscriptions", "organizations_url": "https://api.github.com/users/dhruvbalwada/orgs", "repos_url": "https://api.github.com/users/dhruvbalwada/repos", "events_url": "https://api.github.com/users/dhruvbalwada/events{/privacy}", "received_events_url": "https://api.github.com/users/dhruvbalwada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-02-12T07:10:12Z", "updated_at": "2021-03-08T16:19:31Z", "closed_at": "2021-02-18T16:36:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to learn how to add and multiply different kernels together, and am doing this a bit arbitrarily at this point. \r\nThe thing I find confusing is, how is the internal representations of combined kernels being made? \r\n\r\nIn the screenshot below you can see that things like `kernels.0.kernels.0` are being set. I would have have thought that if I added three kernels then I might get 'kernels.0`, 'kernels.1`, 'kernels.2` etc.  \r\n\r\nAm I doing something wrong? or is there some documentation on how the parameters get represented? I am asking because I want to initialize the different parameters, and it is quite confusing to figure out which kernel is getting inherited inside what.\r\n\r\n![Screen Shot 2021-02-11 at 11 05 19 PM](https://user-images.githubusercontent.com/18236610/107739424-b23ea200-6cbd-11eb-996a-77c1e523fe9f.png)\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1478/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1478/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1462", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1462/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1462/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1462/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1462", "id": 803566560, "node_id": "MDU6SXNzdWU4MDM1NjY1NjA=", "number": 1462, "title": "[Bug] Customized kernel produces error when obtaining diagonal for predictive variance", "user": {"login": "conan19842002", "id": 3224630, "node_id": "MDQ6VXNlcjMyMjQ2MzA=", "avatar_url": "https://avatars.githubusercontent.com/u/3224630?v=4", "gravatar_id": "", "url": "https://api.github.com/users/conan19842002", "html_url": "https://github.com/conan19842002", "followers_url": "https://api.github.com/users/conan19842002/followers", "following_url": "https://api.github.com/users/conan19842002/following{/other_user}", "gists_url": "https://api.github.com/users/conan19842002/gists{/gist_id}", "starred_url": "https://api.github.com/users/conan19842002/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/conan19842002/subscriptions", "organizations_url": "https://api.github.com/users/conan19842002/orgs", "repos_url": "https://api.github.com/users/conan19842002/repos", "events_url": "https://api.github.com/users/conan19842002/events{/privacy}", "received_events_url": "https://api.github.com/users/conan19842002/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-02-08T13:29:18Z", "updated_at": "2021-02-16T14:45:43Z", "closed_at": "2021-02-16T14:45:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nIn my case, when producing predictive variance, I get an error RuntimeError: The kernel LazyEvaluatedKernelTensor is not equipped to handle and diag. Expected size torch.Size([200]). Got size torch.Size([1, 200]), I've tried to reduce the data size but the issue remained.\r\n\r\n## To reproduce\r\n## Code snippet to reproduce \r\n```python\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nfrom IPython.display import display, HTML\r\nimport gpytorch\r\nimport torch\r\nfrom gpytorch.kernels import Kernel\r\nfrom numpy import ndarray\r\nimport os\r\nimport math\r\nfrom math import floor\r\n\r\n\r\nclass GenSquaredExponetialKernel(Kernel):\r\n    r\"\"\"\r\n      Computes a covariance matrix based on the generalized squared exponential kernel\r\n        between inputs :math:`\\mathbf{x_1}` and :math:`\\mathbf{x_2}`:\r\n        .. math::\r\n          \\begin{equation*}\r\n              k_{(\\mathbf{x_1}, \\mathbf{x_2}) = \\sigma(x_1) sigma(x_2) \\sqrt \\left(\\fract{2 l(x_1) l(x_2)}{l(x_1)^2 + l(x_2)^2} \\right)\r\n                \\exp \\left( - \\fract{(x_1-x_2)^2}{l(x_1)^2 + l(x_2)^2} \\right)  \r\n          \\end{equation*}\r\n      where\r\n      \r\n      * :math:`\\sigma` is the signal variance\r\n        :math:`x_1` and :math:`x_2` scaled by the :attr:`lengthscale` parameter :math:`l`.\r\n    \"\"\"\r\n    has_lengthscale = False\r\n\r\n    def __init__(self, s1, s2, l1 , l2, log_transformed = False, **kwargs):\r\n        \r\n        if isinstance(s1, ndarray):\r\n            self.s1 = torch.tensor(s1, dtype=torch.float)\r\n        elif torch.is_tensor(s1):\r\n            self.s1 = s1\r\n        else:\r\n            raise TypeError(f\"variance is expected to be an array or tensor. \"\r\n                            f\"Got {type(s1)} instead.\")\r\n        if isinstance(s2, ndarray):\r\n            self.s2 = torch.tensor(s2, dtype=torch.float)\r\n        elif torch.is_tensor(s2):\r\n            self.s2 = s2\r\n        else:\r\n            raise TypeError(f\"variance is expected to be an array or tensor. \"\r\n                            f\"Got {type(s2)} instead.\")\r\n            \r\n        if isinstance(l1, ndarray):\r\n            self.l1 = torch.tensor(l1, dtype=torch.float)\r\n        elif torch.is_tensor(l):\r\n            self.l1 = l1\r\n        else:\r\n            raise TypeError(f\"lengthscale is expected to be an array or tensor. \"\r\n                            f\"Got {type(l1)} instead.\")\r\n\r\n        if isinstance(l2, ndarray):\r\n            self.l2 = torch.tensor(l2, dtype=torch.float)\r\n        elif torch.is_tensor(l):\r\n            self.l2 = l2\r\n        else:\r\n            raise TypeError(f\"lengthscale is expected to be an array or tensor. \"\r\n                            f\"Got {type(l2)} instead.\")\r\n\r\n\r\n        if log_transformed:\r\n          self.l1 = torch.exp(self.l1).double()\r\n          self.l2 = torch.exp(self.l2).double()\r\n          self.s1 = torch.exp(self.s1).double()\r\n          self.s2 = torch.exp(self.s2).double()\r\n        super(GenSquaredExponetialKernel, self).__init__(**kwargs)\r\n    \r\n    def forward(self, x1, x2, diag=False, **params):\r\n        \r\n        n_features = x1.size()[1]\r\n\r\n        first_comp = 1\r\n        second_comp = 0\r\n        for i in range(n_features):\r\n          s = torch.pow(self.l1[i].view(-1,1), 2) + torch.pow(self.l2[i].view(1,-1), 2)\r\n          first_comp *= torch.sqrt(torch.div(2*self.l1[i].view(-1,1)*self.l2[i].view(1,-1), s))\r\n          dist = self.covar_dist(x1[:,i:i+1], x2[:,i:i+1], square_dist=True, diag=diag, **params)\r\n  \r\n          f = dist.div(s)\r\n          second_comp += f   \r\n        \r\n        first_comp *= torch.matmul(self.s1, self.s2.t())\r\n        second_comp = torch.exp(-second_comp)\r\n        k = first_comp * second_comp\r\n        return k\r\n    \r\nclass MyGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, s1, s2, l1, l2, train_x, train_y, likelihood):\r\n        super(MyGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.set_train_data(train_x, train_y)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(GenSquaredExponetialKernel(s1, s2, l1, l2))\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n####### Prepare fake data ########\r\nX = torch.randn(1000,4)[:,:-1]\r\ny = X[:,-1]\r\ntrain_n = int(floor(0.8 * len(X)))\r\ntrain_x = X[:train_n, :]\r\ntrain_y = y[:train_n]\r\n\r\ntest_x = X[train_n:, :]\r\ntest_y = y[train_n:]\r\n\r\ns1 = np.array([0.1]*3)\r\ns2 = np.array([0.2]*3)\r\nl1 = np.array([3.0]*3)\r\nl2 = np.array([4.0]*3)\r\n\r\nmodel = MyGPModel(s1, s2, l1, l2, train_x=train_x, train_y=train_y, likelihood=likelihood)\r\n\r\nif torch.cuda.is_available():\r\n    train_x = train_x.cuda()\r\n    train_y = train_y.cuda()\r\n    model = model.cude()\r\n    likelihood = likelihood.cuda()\r\n\r\n################################# Training step #############################\r\nimport os\r\nsmoke_test = ('CI' in os.environ)\r\ntraining_iter = 2 if smoke_test else 10\r\n# Find optimal model hyperparameters\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n# Use Adam optimizer\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\r\n\r\n# Loss func for GP, the log marginal likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n#train_x, train_y = train_x.type(torch.DoubleTensor), train_y.type(torch.DoubleTensor)\r\nfor i in range(training_iter):\r\n  # Zero gradient from previous iteration\r\n  optimizer.zero_grad()\r\n  output = model(train_x)\r\n\r\n  # Calculate backprop gradients\r\n  loss = -mll(output, train_y)\r\n  loss.backward()\r\n\r\n  print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iter, loss.item()))\r\n  optimizer.step()\r\n\r\n########################## Make predictions ###############################\r\n# Get into evaluation (predictive posterior) mode\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\n# Make predictions by feeding model through likelihood\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    observed_pred = likelihood(model(test_x))\r\n    mean = observed_pred.mean\r\n    lower, upper = observed_pred.confidence_region()\r\n\r\ntest_results_gpytorch = np.median((test_y - mean) / test_y, axis=0)\r\ntest_results_gpytorch\r\n\r\n```\r\n## Stack trace/error message \r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-38-d91bfe47d828> in <module>()\r\n     12     observed_pred = likelihood(model(test_x))\r\n     13     mean = observed_pred.mean\r\n---> 14     lower, upper = observed_pred.confidence_region()\r\n     15 \r\n     16 test_results_gpytorch = np.median((test_y - mean) / test_y, axis=0)\r\n\r\n8 frames\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in diag(self)\r\n    253                 raise RuntimeError(\r\n    254                     \"The kernel {} is not equipped to handle and diag. Expected size {}. \"\r\n--> 255                     \"Got size {}\".format(self.__class__.__name__, expected_shape, res.shape)\r\n    256                 )\r\n    257 \r\n\r\nRuntimeError: The kernel LazyEvaluatedKernelTensor is not equipped to handle and diag. Expected size torch.Size([200]). Got size torch.Size([1, 200])\r\n```\r\n\r\n## Expected Behavior\r\nI expected the variance to be computed correctly.\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGPyTorch Version (run print(gpytorch.__version__))\r\n1.3.1\r\nPyTorch Version (run print(torch.__version__))\r\n1.7.0+cu101\r\nComputer OS\r\nWindow 10\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1462/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1462/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1459", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1459/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1459/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1459/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1459", "id": 802062089, "node_id": "MDU6SXNzdWU4MDIwNjIwODk=", "number": 1459, "title": "[Bug] Time series prediction with batch independent SGPR", "user": {"login": "monabf", "id": 26089777, "node_id": "MDQ6VXNlcjI2MDg5Nzc3", "avatar_url": "https://avatars.githubusercontent.com/u/26089777?v=4", "gravatar_id": "", "url": "https://api.github.com/users/monabf", "html_url": "https://github.com/monabf", "followers_url": "https://api.github.com/users/monabf/followers", "following_url": "https://api.github.com/users/monabf/following{/other_user}", "gists_url": "https://api.github.com/users/monabf/gists{/gist_id}", "starred_url": "https://api.github.com/users/monabf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/monabf/subscriptions", "organizations_url": "https://api.github.com/users/monabf/orgs", "repos_url": "https://api.github.com/users/monabf/repos", "events_url": "https://api.github.com/users/monabf/events{/privacy}", "received_events_url": "https://api.github.com/users/monabf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2021-02-05T10:49:30Z", "updated_at": "2021-02-26T13:39:36Z", "closed_at": "2021-02-20T23:49:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nHi,\r\n\r\nI still have trouble doing large-scale multioutput regression for time series as discussed in #1349 and #1376. I agree that PR #1356 improved the time performance, which now seems satisfactory both on CPU (reasonably similar to GPy) and on GPU (much faster).\r\n\r\nHowever, in my case I am using time series data (input 20k x 7, output 20k x 5), and I want to predict trajectories of my system (rollouts). I am not looking at uncertainty propagation along the rollout for now, I just want to predict the mean trajectory without considering uncertainty in the inputs.\r\n\r\nMy problem is that I need to predict each point of the rollout one after the other. **But the prediction of one single point takes too long, about as long as the prediction of a few thousand points!** \r\n\r\nFor example, in the following test code, the prediction time for the test set (3k x 18) of around 0.5s is acceptable and comparable to that of GPy, but the prediction time for a single test point is also around 0.5s and that makes predicting a long rollout super slow.\r\n\r\nIs there a fix for this? Or a better way of predicting rollouts? Or should I be using something else than SGPR for multioutput time series prediction with about 150k samples? I tried [Multitask SVGP](https://docs.gpytorch.ai/en/latest/examples/04_Variational_and_Approximate_GPs/SVGP_Multitask_GP_Regression.html), it was a bit better for my issue (0.5s for 3k predictions, 0.05s for a single point), but learning was much slower and the test code led to running out of memory when I tried it on the GPU...\r\n\r\nThanks a lot for your help!\r\n\r\n## To reproduce: example code\r\n```python\r\nimport time\r\nimport urllib.request\r\nfrom math import floor\r\n\r\nimport GPy\r\nimport gpytorch\r\nimport torch\r\nfrom gpytorch.distributions import MultivariateNormal\r\nfrom gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\r\nfrom gpytorch.means import ConstantMean\r\nfrom scipy.io import loadmat\r\n\r\nif __name__ == '__main__':\r\n    # Run GPyTorch SGPR + independent multioutputs example: approximate\r\n    # https://docs.gpytorch.ai/en/v1.2.1/examples/02_Scalable_Exact_GPs/SGPR_Regression_CUDA.html\r\n    # https://github.com/cornellius-gp/gpytorch/issues/1043\r\n    print('Downloading \\'elevators\\' UCI dataset...')\r\n    urllib.request.urlretrieve(\r\n        'https://drive.google.com/uc?export=download&id=1jhWL3YUHvXIaftia4qeAyDwVxo6j1alk',\r\n        '../elevators.mat')\r\n    output_size = 5\r\n    nb_inducing_points = 500\r\n    data = torch.Tensor(loadmat('../elevators.mat')['data'])\r\n    X = data[:, :-1]\r\n    X = X - X.min(0)[0]\r\n    X = 2 * (X / X.max(0)[0]) - 1\r\n    y = data[:, -1]\r\n    # MAKE MULTIOUTPUT DATA\r\n    y = y.reshape(-1, 1)\r\n    y = y.repeat(1, output_size)\r\n    print(X.shape, y.shape)\r\n    input_size = X.shape[1]\r\n    train_n = int(floor(0.8 * len(X)))\r\n    train_x = X[:train_n, :].contiguous()\r\n    train_y = y[:train_n].contiguous()\r\n    test_x = X[train_n:, :].contiguous()\r\n    test_y = y[train_n:].contiguous()\r\n    if torch.cuda.is_available():\r\n        train_x, train_y, test_x, test_y = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda()\r\n    # CONVERT TO BATCH GP\r\n    train_x = train_x.repeat(output_size, 1, 1)\r\n    train_y = train_y.transpose(-2, -1)\r\n    test_x = test_x.repeat(output_size, 1, 1)\r\n    test_y = test_y.transpose(-2, -1)\r\n    print(train_x.shape, train_y.shape, test_x.shape)\r\n\r\n\r\n    class GPRegressionModel(gpytorch.models.ExactGP):\r\n        def __init__(self, train_x, train_y, likelihood):\r\n            super(GPRegressionModel, self).__init__(train_x, train_y,\r\n                                                    likelihood)\r\n            self.mean_module = ConstantMean(\r\n                batch_shape=torch.Size([output_size]))\r\n            self.base_covar_module = ScaleKernel(RBFKernel(\r\n                batch_shape=torch.Size([output_size])),\r\n                batch_shape=torch.Size([output_size]))\r\n            inducing_points = train_x[:, :nb_inducing_points, :]\r\n            print(inducing_points.shape)\r\n            self.covar_module = InducingPointKernel(\r\n                self.base_covar_module,\r\n                inducing_points=inducing_points,\r\n                likelihood=likelihood)\r\n\r\n        def forward(self, x):\r\n            mean_x = self.mean_module(x)\r\n            covar_x = self.covar_module(x)\r\n            return MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood(\r\n        batch_shape=torch.Size([output_size]))\r\n    model = GPRegressionModel(train_x, train_y, likelihood)\r\n    if torch.cuda.is_available():\r\n        model = model.cuda()\r\n        likelihood = likelihood.cuda()\r\n    # Train\r\n    training_iterations = 10\r\n    model.train()\r\n    likelihood.train()\r\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n    start_whole = time.time()\r\n    for i in range(training_iterations):\r\n        start = time.time()\r\n        # Zero backprop gradients\r\n        optimizer.zero_grad()\r\n        # Get output from model\r\n        output = model(train_x)\r\n        # Calc loss and backprop derivatives\r\n        loss = -mll(output, train_y).sum()\r\n        loss.backward()\r\n        end = time.time()\r\n        print('Iter %d/%d - Loss: %.3f' % (\r\n            i + 1, training_iterations, loss.item()), 'in', str(end - start))\r\n        optimizer.step()\r\n        torch.cuda.empty_cache()\r\n    end_whole = time.time()\r\n    print('GPyTorch training time', str(end_whole - start_whole))\r\n    model.eval()\r\n    likelihood.eval()\r\n    start = time.time()\r\n    with gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\r\n        with gpytorch.settings.max_root_decomposition_size(\r\n                30), gpytorch.settings.fast_pred_var():\r\n            preds = model(test_x)\r\n    end = time.time()\r\n    print('predict', str(test_x.shape), 'in', str(end - start))\r\n    start = time.time()\r\n    with gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\r\n        with gpytorch.settings.max_root_decomposition_size(\r\n                30), gpytorch.settings.fast_pred_var():\r\n            preds = model(test_x)\r\n    end = time.time()\r\n    print('predict 2nd time', str(test_x.shape), 'in', str(end - start))\r\n    print('Test MAE: {}'.format(torch.mean(torch.abs(preds.mean - test_y))))\r\n    start = time.time()\r\n    with gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\r\n        with gpytorch.settings.max_root_decomposition_size(\r\n                30), gpytorch.settings.fast_pred_var():\r\n            preds = model(test_x[:, 0, :])\r\n    end = time.time()\r\n    print('predict single point', str(test_x[:, 0, :].shape), 'in', str(end -\r\n                                                                        start),\r\n          '\\n')\r\n\r\n    # Compare GPy\r\n    # Cannot really use GPU: https://github.com/SheffieldML/GPy/issues/441\r\n    # CONVERT BACK FROM BATCH GP\r\n    train_x = X[:train_n, :].contiguous()\r\n    train_y = y[:train_n].contiguous()\r\n    test_x = X[train_n:, :].contiguous()\r\n    test_y = y[train_n:].contiguous()\r\n    gpykernel = GPy.kern.RBF(input_dim=train_x.numpy().shape[1], ARD=True)\r\n    gpymodel = GPy.core.SparseGP(train_x.numpy(),\r\n                                 train_y.numpy(),\r\n                                 train_x.numpy()[:nb_inducing_points, :],\r\n                                 kernel=gpykernel,\r\n                                 likelihood=GPy.likelihoods.Gaussian(),\r\n                                 inference_method=GPy.inference.latent_function_inference.VarDTC())\r\n    start = time.time()\r\n    gpymodel.optimize(messages=True, max_iters=training_iterations)\r\n    end = time.time()\r\n    print('GPy training time', str(end - start))\r\n    start = time.time()\r\n    gpymean, gpyvar = gpymodel.predict(test_x.numpy())\r\n    end = time.time()\r\n    print('predict', test_x.shape, 'in', str(end - start))\r\n    start = time.time()\r\n    gpymean, gpyvar = gpymodel.predict(test_x.numpy())\r\n    end = time.time()\r\n    print('predict 2nd time', test_x.shape, 'in', str(end - start))\r\n    print('Test MAE: {}'.format(torch.mean(torch.abs(torch.tensor(gpymean) -\r\n                                                     test_y))))\r\n    start = time.time()\r\n    gpymean, gpyvar = gpymodel.predict(test_x[0].reshape(1, -1).numpy())\r\n    end = time.time()\r\n    print('predict single point', test_x[0].reshape(1, -1).shape, 'in',\r\n          str(end - start), '\\n')\r\n```\r\n\r\n** Stack trace/error message **\r\nOn CPU:\r\n```\r\nGPyTorch training time 37.12532615661621\r\npredict torch.Size([5, 3320, 18]) in 5.143052101135254\r\npredict 2nd time torch.Size([5, 3320, 18]) in 0.6981589794158936\r\npredict single point torch.Size([5, 18]) in 0.5465080738067627 \r\n\r\nGPy training time 52.490806102752686\r\npredict torch.Size([3320, 18]) in 0.05931401252746582\r\npredict 2nd time torch.Size([3320, 18]) in 0.04732799530029297\r\npredict single point torch.Size([1, 18]) in 0.0005881786346435547 \r\n```\r\n\r\nOn GPU:\r\n```\r\nGPyTorch training time 1.204216480255127\r\npredict torch.Size([5, 3320, 18]) in 0.3035309314727783\r\npredict 2nd time torch.Size([5, 3320, 18]) in 0.0034995079040527344\r\npredict single point torch.Size([5, 18]) in 0.002752065658569336 \r\n\r\nGPy training time 86.75350904464722\r\npredict torch.Size([3320, 18]) in 0.1132357120513916\r\npredict 2nd time torch.Size([3320, 18]) in 0.11741828918457031\r\npredict single point torch.Size([1, 18]) in 0.0013453960418701172 \r\n```\r\n\r\n## Expected Behavior\r\n\r\nI was expecting the prediction time for a single point to be at least one order of magnitude lower than that of 3k points, so that I can predict rollouts in a reasonable time.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n-  GPyTorch version 1.3.1 \r\n- PyTorch version 1.7.0\r\n- Mac OS Catalina\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1459/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1459/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1446", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1446/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1446/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1446/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1446", "id": 792074985, "node_id": "MDExOlB1bGxSZXF1ZXN0NTYwMDIxNzEz", "number": 1446, "title": "Bug fixes to LowRank lazy tensors", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-01-22T15:02:41Z", "updated_at": "2021-01-22T16:34:30Z", "closed_at": "2021-01-22T16:34:27Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1446", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1446", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1446.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1446.patch", "merged_at": "2021-01-22T16:34:27Z"}, "body": "There were no unit tests for LowRankRootLazyTensor (or its added diag variant), and there were a number of issues. Most notably, `inv_quad_logdet` was not returning the right `inv_quad` term, which caused errors when using this LazyTensor on a batched GP model.\r\n\r\nThis PR fixes these issues, and also uses `LowRankRootLazyTensor` for RFF kernels.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1446/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1446/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1438", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1438/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1438/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1438/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1438", "id": 789794604, "node_id": "MDU6SXNzdWU3ODk3OTQ2MDQ=", "number": 1438, "title": "[Bug] Variational GPs w/ Multiple Outputs", "user": {"login": "valentinecesbio", "id": 77112599, "node_id": "MDQ6VXNlcjc3MTEyNTk5", "avatar_url": "https://avatars.githubusercontent.com/u/77112599?v=4", "gravatar_id": "", "url": "https://api.github.com/users/valentinecesbio", "html_url": "https://github.com/valentinecesbio", "followers_url": "https://api.github.com/users/valentinecesbio/followers", "following_url": "https://api.github.com/users/valentinecesbio/following{/other_user}", "gists_url": "https://api.github.com/users/valentinecesbio/gists{/gist_id}", "starred_url": "https://api.github.com/users/valentinecesbio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/valentinecesbio/subscriptions", "organizations_url": "https://api.github.com/users/valentinecesbio/orgs", "repos_url": "https://api.github.com/users/valentinecesbio/repos", "events_url": "https://api.github.com/users/valentinecesbio/events{/privacy}", "received_events_url": "https://api.github.com/users/valentinecesbio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-01-20T09:18:50Z", "updated_at": "2021-01-20T15:05:13Z", "closed_at": "2021-01-20T14:38:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nFollowing the tutorial from : https://docs.gpytorch.ai/en/v1.3.1/examples/04_Variational_and_Approximate_GPs/SVGP_Multitask_GP_Regression.html\r\n\r\nWorks fine with LMCVariationalStrategy and the class MultitaskGPModel.\r\n\r\nAs I want independent output dimensions, I replace LMCVariationalStrategy with IndependentMultitaskVariationalStrategy (as in the documentation). I got an error in the training step.\r\n\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nimport tqdm\r\nfrom matplotlib import pyplot as plt\r\nimport tqdm.notebook\r\n\r\ntrain_x = torch.linspace(0, 1, 100)\r\n\r\ntrain_y = torch.stack([\r\n    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n    torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n    torch.sin(train_x * (2 * math.pi)) + 2 * torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n    -torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n], -1)\r\n\r\nprint(train_x.shape, train_y.shape)\r\n\r\nnum_tasks = 4\r\n\r\nclass IndependentMultitaskGPModel(gpytorch.models.ApproximateGP):\r\n    def __init__(self):\r\n        # Let's use a different set of inducing points for each task\r\n        # Pour chaque output, on a 16 points induits entre 0 et 1 (diff\u00e9rent des autres)\r\n        inducing_points = torch.rand(num_tasks, 16, 1)\r\n\r\n        # We have to mark the CholeskyVariationalDistribution as batch\r\n        # so that we learn a variational distribution for each task\r\n        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\r\n            inducing_points.size(-2), batch_shape=torch.Size([num_tasks])\r\n        )\r\n\r\n        variational_strategy = gpytorch.variational.IndependentMultitaskVariationalStrategy(\r\n            gpytorch.variational.VariationalStrategy(\r\n                self, inducing_points, variational_distribution, learn_inducing_locations=True\r\n            ),\r\n            num_tasks=4,\r\n        )\r\n\r\n        super().__init__(variational_strategy)\r\n\r\n        # The mean and covariance modules should be marked as batch\r\n        # so we learn a different set of hyperparameters\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([num_tasks]))\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([num_tasks])),\r\n            batch_shape=torch.Size([num_tasks])\r\n        )\r\n\r\nmodel = IndependentMultitaskGPModel()\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=num_tasks)\r\n\r\nnum_epochs = 500\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},\r\n    {'params': likelihood.parameters()},\r\n], lr=0.1)\r\n\r\n# Our loss object. We're using the VariationalELBO, which essentially just computes the ELBO\r\nmll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\r\n\r\n# We use more CG iterations here because the preconditioner introduced in the NeurIPS paper seems to be less\r\n# effective for VI.\r\nepochs_iter = tqdm.notebook.tqdm(range(num_epochs), desc=\"Epoch\")\r\nfor i in epochs_iter:\r\n    # Within each iteration, we will go over each minibatch of data\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)\r\n    epochs_iter.set_postfix(loss=loss.item())\r\n    loss.backward()\r\n    optimizer.step()\r\n\r\n\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-15-80da080181cd> in <module>\r\n     18     # Within each iteration, we will go over each minibatch of data\r\n     19     optimizer.zero_grad()\r\n---> 20     output = model(train_x)\r\n     21     loss = -mll(output, train_y)\r\n     22     epochs_iter.set_postfix(loss=loss.item())\r\n\r\n~/miniconda3/envs/gpytorch-develop/lib/python3.9/site-packages/gpytorch/models/approximate_gp.py in __call__(self, inputs, prior, **kwargs)\r\n     79         if inputs.dim() == 1:\r\n     80             inputs = inputs.unsqueeze(-1)\r\n---> 81         return self.variational_strategy(inputs, prior=prior, **kwargs)\r\n\r\n~/miniconda3/envs/gpytorch-develop/lib/python3.9/site-packages/gpytorch/variational/independent_multitask_variational_strategy.py in __call__(self, x, prior, **kwargs)\r\n     45 \r\n     46     def __call__(self, x, prior=False, **kwargs):\r\n---> 47         function_dist = self.base_variational_strategy(x, prior=prior, **kwargs)\r\n     48         if (\r\n     49             self.task_dim > 0\r\n\r\n~/miniconda3/envs/gpytorch-develop/lib/python3.9/site-packages/gpytorch/variational/variational_strategy.py in __call__(self, x, prior, **kwargs)\r\n    167                 self.updated_strategy.fill_(True)\r\n    168 \r\n--> 169         return super().__call__(x, prior=prior, **kwargs)\r\n\r\n~/miniconda3/envs/gpytorch-develop/lib/python3.9/site-packages/gpytorch/variational/_variational_strategy.py in __call__(self, x, prior, **kwargs)\r\n    122         # Get q(f)\r\n    123         if isinstance(variational_dist_u, MultivariateNormal):\r\n--> 124             return super().__call__(\r\n    125                 x,\r\n    126                 inducing_points,\r\n\r\n~/miniconda3/envs/gpytorch-develop/lib/python3.9/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/miniconda3/envs/gpytorch-develop/lib/python3.9/site-packages/gpytorch/variational/variational_strategy.py in forward(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\r\n     89         # Compute full prior distribution\r\n     90         full_inputs = torch.cat([inducing_points, x], dim=-2)\r\n---> 91         full_output = self.model.forward(full_inputs, **kwargs)\r\n     92         full_covar = full_output.lazy_covariance_matrix\r\n     93 \r\n\r\n~/miniconda3/envs/gpytorch-develop/lib/python3.9/site-packages/gpytorch/models/approximate_gp.py in forward(self, x)\r\n     48 \r\n     49     def forward(self, x):\r\n---> 50         raise NotImplementedError\r\n     51 \r\n     52     def pyro_guide(self, input, beta=1.0, name_prefix=\"\"):\r\n\r\nNotImplementedError: \r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch version: 1.3.1\r\n- torch version: 1.7.1.post2\r\n- Ubuntu 20.04.1 LTS\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1438/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1438/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1419", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1419/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1419/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1419/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1419", "id": 779120088, "node_id": "MDU6SXNzdWU3NzkxMjAwODg=", "number": 1419, "title": "[Question] How to allow a list of tensor as input in ExactGP?", "user": {"login": "ZhiliangWu", "id": 18686697, "node_id": "MDQ6VXNlcjE4Njg2Njk3", "avatar_url": "https://avatars.githubusercontent.com/u/18686697?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZhiliangWu", "html_url": "https://github.com/ZhiliangWu", "followers_url": "https://api.github.com/users/ZhiliangWu/followers", "following_url": "https://api.github.com/users/ZhiliangWu/following{/other_user}", "gists_url": "https://api.github.com/users/ZhiliangWu/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZhiliangWu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZhiliangWu/subscriptions", "organizations_url": "https://api.github.com/users/ZhiliangWu/orgs", "repos_url": "https://api.github.com/users/ZhiliangWu/repos", "events_url": "https://api.github.com/users/ZhiliangWu/events{/privacy}", "received_events_url": "https://api.github.com/users/ZhiliangWu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-01-05T14:43:33Z", "updated_at": "2021-01-06T12:26:15Z", "closed_at": "2021-01-06T12:26:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "# Question\r\n\r\nThe use case is to combine `ExactGP` with DKL as in this [great tutorial](https://docs.gpytorch.ai/en/v1.2.1/examples/06_PyTorch_NN_Integration_DKL/KISSGP_Deep_Kernel_Regression_CUDA.html). Since a neural network can consume multiple inputs (a list of tensors), the constraint of defining `train_x` as a pure feature matrix of shape `n x d` seems a bit strict. \r\n\r\nFrom the [constructor of `ExactGP`](https://github.com/cornellius-gp/gpytorch/blob/4dec144de87ae4b6900f4afffcd6f276455b6786/gpytorch/models/exact_gp.py#L55) it seems that it accepts a list of tensor as `train_x`:\r\n\r\n```python\r\n    def __init__(self, train_inputs, train_targets, likelihood):\r\n        if train_inputs is not None and torch.is_tensor(train_inputs):\r\n            train_inputs = (train_inputs,)\r\n        if train_inputs is not None and not all(torch.is_tensor(train_input) for train_input in train_inputs):\r\n            raise RuntimeError(\"Train inputs must be a tensor, or a list/tuple of tensors\")\r\n```\r\n\r\nHowever, when I make up a toy example for a quick test as following, the code breaks:\r\n\r\n```bash\r\n  File \"xxxxxxxx/lib/python3.7/site-packages/gpytorch/models/exact_gp.py\", line 245, in <listcomp>\r\n    inputs = [i.unsqueeze(-1) if i.ndimension() == 1 else i for i in args]\r\nAttributeError: 'list' object has no attribute 'ndimension'\r\n```\r\n\r\nIs there any suggestion on how to achieve this? Thanks for any help in advance. \r\n\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\n\r\n# change the input to a list of tensor\r\ntrain_x = [torch.linspace(0, 1, 100), torch.linspace(0, 1, 100)]\r\ntrain_y = torch.sin(train_x[0] * (2 * math.pi)) + torch.randn(train_x[0].size()) * math.sqrt(0.04)\r\n\r\n# train_x = torch.linspace(0, 1, 100)\r\n# train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)\r\n\r\n\r\n# We will use the simplest form of GP model, exact inference\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        x = x[0] + x[1]\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n# initialize likelihood and model\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n\r\ntraining_iter = 50\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iter):\r\n    # Zero gradients from previous iteration\r\n    optimizer.zero_grad()\r\n    # Output from model\r\n    output = model(train_x)\r\n    # Calc loss and backprop gradients\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\r\n        i + 1, training_iter, loss.item(),\r\n        model.covar_module.base_kernel.lengthscale.item(),\r\n        model.likelihood.noise.item()\r\n    ))\r\n    optimizer.step()\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1419/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1419/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1418", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1418/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1418/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1418/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1418", "id": 778715565, "node_id": "MDU6SXNzdWU3Nzg3MTU1NjU=", "number": 1418, "title": "[Bug] Performance varies according to the batch size", "user": {"login": "beopst", "id": 10264378, "node_id": "MDQ6VXNlcjEwMjY0Mzc4", "avatar_url": "https://avatars.githubusercontent.com/u/10264378?v=4", "gravatar_id": "", "url": "https://api.github.com/users/beopst", "html_url": "https://github.com/beopst", "followers_url": "https://api.github.com/users/beopst/followers", "following_url": "https://api.github.com/users/beopst/following{/other_user}", "gists_url": "https://api.github.com/users/beopst/gists{/gist_id}", "starred_url": "https://api.github.com/users/beopst/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/beopst/subscriptions", "organizations_url": "https://api.github.com/users/beopst/orgs", "repos_url": "https://api.github.com/users/beopst/repos", "events_url": "https://api.github.com/users/beopst/events{/privacy}", "received_events_url": "https://api.github.com/users/beopst/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-01-05T08:12:37Z", "updated_at": "2021-04-12T17:18:33Z", "closed_at": "2021-04-12T17:18:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nThe accuracy of the classifier trained with the codes (https://github.com/cornellius-gp/gpytorch/tree/master/examples/06_PyTorch_NN_Integration_DKL) varies according to the batch size. It should be consistent regardless of the batch size. Am I missing something?\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nfrom torch.optim import SGD, Adam\r\nfrom torch.optim.lr_scheduler import MultiStepLR\r\nimport torch.nn.functional as F\r\nfrom torch import nn\r\nimport torch\r\nimport os\r\nimport torchvision.datasets as dset\r\nimport torchvision.transforms as transforms\r\nimport gpytorch\r\nimport math\r\nimport tqdm\r\n\r\n\r\nnormalize = transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\r\naug_trans = [transforms.RandomCrop(32, padding=4), transforms.RandomHorizontalFlip()]\r\ncommon_trans = [transforms.ToTensor(), normalize]\r\ntrain_compose = transforms.Compose(aug_trans + common_trans)\r\ntest_compose = transforms.Compose(common_trans)\r\n\r\n\r\ndataset = \"cifar10\"\r\n\r\n\r\nif ('CI' in os.environ):  # this is for running the notebook in our testing framework\r\n    train_set = torch.utils.data.TensorDataset(torch.randn(8, 3, 32, 32), torch.rand(8).round().long())\r\n    test_set = torch.utils.data.TensorDataset(torch.randn(4, 3, 32, 32), torch.rand(4).round().long())\r\n    train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True)\r\n    test_loader = torch.utils.data.DataLoader(test_set, batch_size=2, shuffle=False)\r\n    num_classes = 2\r\nelif dataset == 'cifar10':\r\n    train_set = dset.CIFAR10('data', train=True, transform=train_compose, download=True)\r\n    test_set = dset.CIFAR10('data', train=False, transform=test_compose)\r\n    train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True)\r\n    test_loader = torch.utils.data.DataLoader(test_set, batch_size=16, shuffle=False)\r\n    num_classes = 10\r\nelif dataset == 'cifar100':\r\n    train_set = dset.CIFAR100('data', train=True, transform=train_compose, download=True)\r\n    test_set = dset.CIFAR100('data', train=False, transform=test_compose)\r\n    train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True)\r\n    test_loader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)\r\n    num_classes = 100\r\nelse:\r\n    raise RuntimeError('dataset must be one of \"cifar100\" or \"cifar10\"')\r\n\r\nfrom densenet import DenseNet\r\n\r\nclass DenseNetFeatureExtractor(DenseNet):\r\n    def forward(self, x):\r\n        features = self.features(x)\r\n        out = F.relu(features, inplace=True)\r\n        out = F.avg_pool2d(out, kernel_size=self.avgpool_size).view(features.size(0), -1)\r\n        return out\r\n\r\nfeature_extractor = DenseNetFeatureExtractor(block_config=(6, 6, 6), num_classes=num_classes)\r\nnum_features = feature_extractor.classifier.in_features\r\n\r\nclass GaussianProcessLayer(gpytorch.models.ApproximateGP):\r\n    def __init__(self, num_dim, grid_bounds=(-10., 10.), grid_size=64):\r\n        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\r\n            num_inducing_points=grid_size, batch_shape=torch.Size([num_dim])\r\n        )\r\n\r\n        # Our base variational strategy is a GridInterpolationVariationalStrategy,\r\n        # which places variational inducing points on a Grid\r\n        # We wrap it with a IndependentMultitaskVariationalStrategy so that our output is a vector-valued GP\r\n        variational_strategy = gpytorch.variational.IndependentMultitaskVariationalStrategy(\r\n            gpytorch.variational.GridInterpolationVariationalStrategy(\r\n                self, grid_size=grid_size, grid_bounds=[grid_bounds],\r\n                variational_distribution=variational_distribution,\r\n            ), num_tasks=num_dim,\r\n        )\r\n        super().__init__(variational_strategy)\r\n\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(\r\n                lengthscale_prior=gpytorch.priors.SmoothedBoxPrior(\r\n                    math.exp(-1), math.exp(1), sigma=0.1, transform=torch.exp\r\n                )\r\n            )\r\n        )\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.grid_bounds = grid_bounds\r\n\r\n    def forward(self, x):\r\n        mean = self.mean_module(x)\r\n        covar = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean, covar)\r\n\r\n\r\nclass DKLModel(gpytorch.Module):\r\n    def __init__(self, feature_extractor, num_dim, grid_bounds=(-10., 10.)):\r\n        super(DKLModel, self).__init__()\r\n        self.feature_extractor = feature_extractor\r\n        self.gp_layer = GaussianProcessLayer(num_dim=num_dim, grid_bounds=grid_bounds)\r\n        self.grid_bounds = grid_bounds\r\n        self.num_dim = num_dim\r\n\r\n    def forward(self, x):\r\n        features = self.feature_extractor(x)\r\n        features = gpytorch.utils.grid.scale_to_bounds(features, self.grid_bounds[0], self.grid_bounds[1])\r\n        # This next line makes it so that we learn a GP for each feature\r\n        features = features.transpose(-1, -2).unsqueeze(-1)\r\n        res = self.gp_layer(features)\r\n        return res\r\n\r\nmodel = DKLModel(feature_extractor, num_dim=num_features)\r\nlikelihood = gpytorch.likelihoods.SoftmaxLikelihood(num_features=model.num_dim, num_classes=num_classes)\r\n\r\n\r\n# If you run this example without CUDA, I hope you like waiting!\r\nif torch.cuda.is_available():\r\n    model = model.cuda()\r\n    likelihood = likelihood.cuda()\r\n\r\n# load trained model\r\nstate_dict = torch.load('dkl_cifar_checkpoint.dat')\r\nmodel_state_dict = state_dict['model']\r\nlikelihood_state_dict = state_dict['likelihood']\r\n\r\nmodel.load_state_dict(model_state_dict)\r\nlikelihood.load_state_dict(likelihood_state_dict)\r\n\r\ndef test():\r\n    model.eval()\r\n    likelihood.eval()\r\n\r\n    correct = 0\r\n    with torch.no_grad(), gpytorch.settings.num_likelihood_samples(16):\r\n        for data, target in test_loader:\r\n            if torch.cuda.is_available():\r\n                data, target = data.cuda(), target.cuda()\r\n            output = likelihood(model(data))  # This gives us 16 samples from the predictive distribution\r\n            pred = output.probs.mean(0).argmax(-1)  # Taking the mean over all of the sample we've drawn\r\n            correct += pred.eq(target.view_as(pred)).cpu().sum()\r\n    print('Test set: Accuracy: {}/{} ({}%)'.format(\r\n        correct, len(test_loader.dataset), 100. * correct / float(len(test_loader.dataset))\r\n    ))\r\n\r\nwith gpytorch.settings.use_toeplitz(False):\r\n    test()\r\n\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nWhen the batch size is set to 256, the accuracy on the test set is 90.9% as expected. However, if the batch size is set to 16, the accuracy drops to 74.8%.\r\n\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version: 1.3.0\r\n- PyTorch Version: 1.8.0.dev20201117\r\n- Ubuntu 18.04\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1418/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1418/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1416", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1416/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1416/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1416/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1416", "id": 778160614, "node_id": "MDExOlB1bGxSZXF1ZXN0NTQ4Mjk4ODcz", "number": 1416, "title": "Make NGD is compatible with batch-mode variational GPs", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-01-04T15:08:12Z", "updated_at": "2021-01-19T22:26:03Z", "closed_at": "2021-01-14T19:32:17Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1416", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1416", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1416.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1416.patch", "merged_at": "2021-01-14T19:32:17Z"}, "body": "[Fixes #1300]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1416/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1416/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1415", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1415/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1415/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1415/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1415", "id": 777771912, "node_id": "MDU6SXNzdWU3Nzc3NzE5MTI=", "number": 1415, "title": "[Bug] Possible Memory Leak in UnwhitenedVariationalStrategy", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-01-04T02:20:52Z", "updated_at": "2021-02-18T12:58:52Z", "closed_at": "2021-02-18T12:58:52Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThis is a gpytorch-only issue reproducing https://github.com/pytorch/botorch/issues/641 . When using an `UnwhitenedVariationalStrategy`, it looks like something is building up in the (GPU) memory usage over multiple posterior calls that is causing out of memory issues.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nfrom gpytorch.kernels import MaternKernel, ScaleKernel\r\nfrom gpytorch.means import ZeroMean\r\n\r\nfrom gpytorch.models import ApproximateGP\r\nfrom gpytorch.variational import CholeskyVariationalDistribution\r\nfrom gpytorch.variational import UnwhitenedVariationalStrategy, VariationalStrategy\r\n\r\n### define variational model\r\nclass VariationalGPModel(ApproximateGP):\r\n    def __init__(self, inducing_points, likelihood, *args, **kwargs):\r\n        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\r\n        # this works\r\n#         variational_strategy = VariationalStrategy(\r\n#             self, inducing_points, variational_distribution, learn_inducing_locations=False\r\n#         )       \r\n        # this OOMs\r\n        variational_strategy = UnwhitenedVariationalStrategy(\r\n            self, inducing_points, variational_distribution, learn_inducing_locations=False\r\n        )\r\n        super(VariationalGPModel, self).__init__(variational_strategy)\r\n        self.mean_module = ZeroMean()\r\n        self.covar_module = ScaleKernel(\r\n            MaternKernel(\r\n                ard_num_dims=2,\r\n                nu=0.5,\r\n            ),\r\n        )\r\n        self.likelihood = likelihood\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n#### run simulated BO loop\r\n  if torch.cuda.is_available():\r\n      device = torch.device(\"cuda:3\")\r\n  else:\r\n      device = torch.device(\"cpu\")\r\n  \r\n  current_x = torch.randn(10, 2, device=device)\r\n  current_y = torch.randn(10, device=device)\r\n  \r\n  test_x = torch.randn(1000, 2, device=device)\r\n\r\n  induc_points = torch.rand(900, 2)\r\n  \r\n  model = VariationalGPModel(\r\n      inducing_points = induc_points,\r\n      likelihood=None,\r\n  ).to(device)\r\n\r\n  for step in range(500):\r\n      if step > 0 and step % 25 == 0:\r\n          print(\"Beginning step \", step)\r\n\r\n      start = time.time()\r\n      model.train()\r\n      model.zero_grad()\r\n          \r\n      model.eval()\r\n      pred = model(test_x)\r\n      vals, inds = pred.variance.sort()\r\n      acq_value = vals[-5:].mean().detach()\r\n      candidates = test_x[inds[-5:]]\r\n      del candidates, vals, inds, pred\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n~/gpytorch/gpytorch/models/approximate_gp.py in __call__(self, inputs, prior, **kwargs)\r\n     79         if inputs.dim() == 1:\r\n     80             inputs = inputs.unsqueeze(-1)\r\n---> 81         return self.variational_strategy(inputs, prior=prior, **kwargs)\r\n\r\n~/gpytorch/gpytorch/variational/_variational_strategy.py in __call__(self, x, prior, **kwargs)\r\n    127                 inducing_values=variational_dist_u.mean,\r\n    128                 variational_inducing_covar=variational_dist_u.lazy_covariance_matrix,\r\n--> 129                 **kwargs,\r\n    130             )\r\n    131         elif isinstance(variational_dist_u, Delta):\r\n\r\n~/gpytorch/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/gpytorch/gpytorch/variational/unwhitened_variational_strategy.py in forward(self, x, inducing_points, inducing_values, variational_inducing_covar)\r\n    131                     eager_rhs.detach(),\r\n    132                     logdet_terms=(not cholesky),\r\n--> 133                     include_tmats=(not settings.skip_logdet_forward.on() and not cholesky),\r\n    134                 )\r\n    135                 eager_rhss = [\r\n\r\n~/gpytorch/gpytorch/lazy/cached_cg_lazy_tensor.py in precompute_terms(cls, base_lazy_tensor, eager_rhs, logdet_terms, include_tmats)\r\n     67                         torch.cat([probe_vectors, eager_rhs], -1),\r\n     68                         preconditioner=base_lazy_tensor._preconditioner()[0],\r\n---> 69                         num_tridiag=probe_vectors.size(-1),\r\n     70                     )\r\n     71                 else:\r\n\r\n~/gpytorch/gpytorch/lazy/lazy_tensor.py in _solve(self, rhs, preconditioner, num_tridiag)\r\n    653             max_iter=settings.max_cg_iterations.value(),\r\n    654             max_tridiag_iter=settings.max_lanczos_quadrature_iterations.value(),\r\n--> 655             preconditioner=preconditioner,\r\n    656         )\r\n    657 \r\n\r\n~/gpytorch/gpytorch/utils/linear_cg.py in linear_cg(matmul_closure, rhs, n_tridiag, tolerance, eps, stop_updating_after, max_iter, max_tridiag_iter, initial_guess, preconditioner)\r\n    133         max_tridiag_iter = settings.max_lanczos_quadrature_iterations.value()\r\n    134     if initial_guess is None:\r\n--> 135         initial_guess = torch.zeros_like(rhs)\r\n    136     if tolerance is None:\r\n    137         if settings._use_eval_tolerance.on():\r\n\r\nRuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 3; 23.65 GiB total capacity; 21.73 GiB already allocated; 2.00 MiB free; 22.65 GiB reserved in total by PyTorch)\r\n```\r\n\r\n## Expected Behavior\r\n\r\nIt should not OOM like that.\r\n\r\n## System information\r\nUbuntu 18.04. titan rtx gpu\r\n\r\n**Please complete the following information:**\r\ngpytorch 1.3.0, commit 4dec144de\r\npytorch 1.7.0\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1415/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1415/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1407", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1407/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1407/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1407/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1407", "id": 775407545, "node_id": "MDExOlB1bGxSZXF1ZXN0NTQ2MDk5Mjg4", "number": 1407, "title": "Fix whitened SVGP for non-zero prior means.", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-12-28T13:43:57Z", "updated_at": "2021-11-22T14:11:45Z", "closed_at": "2021-01-14T19:32:44Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1407", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1407", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1407.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1407.patch", "merged_at": "2021-01-14T19:32:44Z"}, "body": "The whitened inducing points `\\tilde u` are given by the following deterministic transformation of the unwhitened inducing points `u`:\r\n\r\n`\\tilde u = K^{-1/2} ( u - \\mu )`\r\n\r\nwhere `K` and `\\mu` are the prior covariance/mean of `u`.\r\n\r\nThe (predictive) posterior mean of an SVGP model evaluated at `x` is given by:\r\n\r\n` k_x^T K^{-1} (m - \\mu) + \\mean_x `\r\n\r\nwhere `k_x` is the cross-covariance between `x` and the inducing points, `\\mean_x` is the GP prior mean evaluated at `x`, and `m` is the *unwhitened* inducing variational mean. By the deterministic transformation above, the whitened variational mean is equal to `\\tilde m = K^{-1/2} (m - \\mu)`. Therefore, we have that the (predictive) posterior mean is:\r\n\r\n` k_x^T K^{-1/2} \\tilde m + \\mean_x `\r\n\r\nIn variational_strategy.py, `interp_term` is equal to `K^{-1/2} k_x`, and `inducing_values` is equal to `\\tilde m`. Therefore, line 121 should be changed to:\r\n\r\n```python\r\npredictive_mean = (interp_term.transpose(-1, -2) @ inducing_values.unsqueeze(-1)).squeeze(-1) + test_mean\r\n```\r\n\r\n[Fixes #1402]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1407/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1407/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1402", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1402/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1402/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1402/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1402", "id": 772507295, "node_id": "MDU6SXNzdWU3NzI1MDcyOTU=", "number": 1402, "title": "Code in variational_strategy.py", "user": {"login": "jbgao", "id": 4993409, "node_id": "MDQ6VXNlcjQ5OTM0MDk=", "avatar_url": "https://avatars.githubusercontent.com/u/4993409?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbgao", "html_url": "https://github.com/jbgao", "followers_url": "https://api.github.com/users/jbgao/followers", "following_url": "https://api.github.com/users/jbgao/following{/other_user}", "gists_url": "https://api.github.com/users/jbgao/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbgao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbgao/subscriptions", "organizations_url": "https://api.github.com/users/jbgao/orgs", "repos_url": "https://api.github.com/users/jbgao/repos", "events_url": "https://api.github.com/users/jbgao/events{/privacy}", "received_events_url": "https://api.github.com/users/jbgao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-12-21T22:37:26Z", "updated_at": "2021-01-14T19:32:44Z", "closed_at": "2021-01-14T19:32:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nDear Gpytorch Developers\r\n\r\nHere is a possible issue with variational_strategy.py\r\n\r\nI am wondering whether it is a special consideration or something missing.  According to the formula in Line 121, it seems an L is missing in front of self.prior_distribution.mean in Line 115.   I understand variable inducing_values has already included L.inv() according to whitening of the inducing posterior, but this is not the case for the prior.   It is fortunate that self.prior_distribution.mean is always 0, so no errors.\r\n\r\nThank you for the great package\r\n\r\nJ.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n# Your code goes here\r\n# Please make sure it does not require any external dependencies (other than PyTorch!)\r\n# (We much prefer small snippets rather than links to existing libraries!)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n// Paste the bad output here!\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` -->\r\n- <!-- PyTorch Version (run `print(torch.__version__)` -->\r\n- <!-- Computer OS -->\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1402/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1402/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1392", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1392/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1392/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1392/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1392", "id": 768913313, "node_id": "MDExOlB1bGxSZXF1ZXN0NTQxMTkwOTE5", "number": 1392, "title": "Fix SM kernel functionality with SKI", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-12-16T14:08:55Z", "updated_at": "2021-01-19T20:33:52Z", "closed_at": "2021-01-19T20:29:31Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1392", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1392", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1392.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1392.patch", "merged_at": "2021-01-19T20:29:31Z"}, "body": "[Closes #1384]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1392/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1392/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1389", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1389/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1389/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1389/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1389", "id": 763006582, "node_id": "MDU6SXNzdWU3NjMwMDY1ODI=", "number": 1389, "title": "[Bug] inplace operation in RBFKernelGrad when diag=True", "user": {"login": "bletham", "id": 6339760, "node_id": "MDQ6VXNlcjYzMzk3NjA=", "avatar_url": "https://avatars.githubusercontent.com/u/6339760?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bletham", "html_url": "https://github.com/bletham", "followers_url": "https://api.github.com/users/bletham/followers", "following_url": "https://api.github.com/users/bletham/following{/other_user}", "gists_url": "https://api.github.com/users/bletham/gists{/gist_id}", "starred_url": "https://api.github.com/users/bletham/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bletham/subscriptions", "organizations_url": "https://api.github.com/users/bletham/orgs", "repos_url": "https://api.github.com/users/bletham/repos", "events_url": "https://api.github.com/users/bletham/events{/privacy}", "received_events_url": "https://api.github.com/users/bletham/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-12-11T22:42:37Z", "updated_at": "2020-12-12T00:40:30Z", "closed_at": "2020-12-12T00:39:43Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nRBFKernelGrad uses an inplace operation when diag=True that breaks backward.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport torch\r\nfrom gpytorch.kernels import RBFKernelGrad\r\n\r\n# This works\r\nk = RBFKernelGrad()\r\ntrain_x=torch.tensor([1., 2., 3.])\r\nz = k(train_x, train_x)\r\nz[0, 0].backward()\r\nprint(k.raw_lengthscale.grad)\r\n\r\n# This fails\r\nz = k(train_x, train_x, diag=True)\r\nz[0].backward()\r\nprint(k.raw_lengthscale.grad)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-17-ecb6525006fe> in <module>\r\n      1 z = k(train_x, train_x, diag=True)\r\n----> 2 z[0].backward()\r\n      3 print(k.raw_lengthscale.grad)\r\n\r\n/mnt/xarfuse/uid-66331/be3771ae-seed-nspid4026531836-ns-4026531840/torch/tensor.py in backward(self, gradient, retain_graph, create_graph, inputs)\r\n    231                 create_graph=create_graph,\r\n    232                 inputs=inputs)\r\n--> 233         torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\r\n    234 \r\n    235     def register_hook(self, hook):\r\n\r\n/mnt/xarfuse/uid-66331/be3771ae-seed-nspid4026531836-ns-4026531840/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\r\n    144     Variable._execution_engine.run_backward(\r\n    145         tensors, grad_tensors_, retain_graph, create_graph, inputs,\r\n--> 146         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\r\n    147 \r\n    148 \r\n\r\nRuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 1]], which is output 0 of SoftplusBackward, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).\r\n```\r\n\r\n## Expected Behavior\r\n\r\nSame as what happens without `diag=True`.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version 1.3.0\r\n- PyTorch Version 1.7.1\r\n- Linux", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1389/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1389/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1384", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1384/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1384/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1384/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1384", "id": 759610219, "node_id": "MDU6SXNzdWU3NTk2MTAyMTk=", "number": 1384, "title": "[Bug] SM + GridInterpolationKernel Interoperability", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-12-08T16:54:41Z", "updated_at": "2021-01-19T20:29:31Z", "closed_at": "2021-01-19T20:29:31Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nLooks like the updates to spectral mixture kernels have broken its interoperability with GridInterpolation Kernels.\r\n\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nfrom gpytorch.kernels import SpectralMixtureKernel, GridInterpolationKernel\r\n\r\ncovar_module = SpectralMixtureKernel(num_mixtures=3)\r\ngrid_interp = GridInterpolationKernel(covar_module, grid_size=12, grid_bounds = [[0, 1]])\r\n\r\ngrid_interp._inducing_forward(last_dim_is_batch=False)\r\n# should be KroneckerProductLT\r\ngrid_interp._inducing_forward(last_dim_is_batch=True)\r\n# should be ToeplitzLT\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n~/Documents/GitHub/wjm_gpytorch/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n~/Documents/GitHub/wjm_gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)\r\n    279             if res.shape != self.shape:\r\n    280                 raise RuntimeError(\r\n--> 281                     f\"The expected shape of the kernel was {self.shape}, but got {res.shape}. \"\r\n    282                     \"This is likely a bug in GPyTorch.\"\r\n    283                 )\r\n\r\nRuntimeError: The expected shape of the kernel was torch.Size([1, 1, 12]), but got torch.Size([3, 1, 12]). This is likely a bug in GPyTorch.\r\n```\r\n\r\n## Expected Behavior\r\n\r\nShouldn't have bugged out.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\ngpytorch master\r\npytorch 1.7.0\r\nMac OS\r\n\r\n## Additional context\r\nRolling back to aab81213 gives the expected output, but I haven't had a chance to debug more fully yet. \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1384/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1384/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1376", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1376/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1376/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1376/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1376", "id": 757143564, "node_id": "MDU6SXNzdWU3NTcxNDM1NjQ=", "number": 1376, "title": "[Bug]", "user": {"login": "monabf", "id": 26089777, "node_id": "MDQ6VXNlcjI2MDg5Nzc3", "avatar_url": "https://avatars.githubusercontent.com/u/26089777?v=4", "gravatar_id": "", "url": "https://api.github.com/users/monabf", "html_url": "https://github.com/monabf", "followers_url": "https://api.github.com/users/monabf/followers", "following_url": "https://api.github.com/users/monabf/following{/other_user}", "gists_url": "https://api.github.com/users/monabf/gists{/gist_id}", "starred_url": "https://api.github.com/users/monabf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/monabf/subscriptions", "organizations_url": "https://api.github.com/users/monabf/orgs", "repos_url": "https://api.github.com/users/monabf/repos", "events_url": "https://api.github.com/users/monabf/events{/privacy}", "received_events_url": "https://api.github.com/users/monabf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-12-04T14:28:04Z", "updated_at": "2021-02-16T21:15:49Z", "closed_at": "2021-02-16T21:15:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nSorry to bother you again, but my problem #1349 is still not solved and I cannot reopen the issue.\r\n\r\nI installed the newest version of GPyTorch, which contains PR #1356:\r\n`pip install --upgrade git+https://github.com/cornellius-gp/gpytorch.git`\r\n\r\nNow running my previous example code, I get an error in the forward function. This error comes from function `chol_cap_mat` in class `LowRankRootAddedDiagLazyTensor`. I fixed the bug by using \r\n```python\r\nbatch_shape = torch.Size([V.batch_shape[0], 1])        \r\nC = ConstantDiagLazyTensor(\r\n            torch.ones(batch_shape, device=V.device, dtype=V.dtype),\r\n            V.shape[-2])\r\n```\r\ninstead of \r\n```python\r\nC = ConstantDiagLazyTensor(torch.ones(V.batch_shape,\r\n        device=V.device, dtype=V.dtype), V.shape[-2])\r\n```\r\nbut this is hacky. Even with this fix, the code runs but not much faster than before.\r\n\r\nIn PR #1356, @jacobrgardner said that this fixed my problem and that my example code now had prediction times aligned with GPy. This is not the case at all for me: I get an error, and even if I don't the code is still roughly as slow. Am I not using this PR correctly? Or was there a mistake in it maybe?\r\n\r\nThanks a lot for your help...\r\n\r\n\r\n## To reproduce: previous example code\r\n\r\n```python\r\nimport time\r\nimport urllib.request\r\nfrom math import floor\r\n\r\nimport GPy\r\nimport gpytorch\r\nimport torch\r\nfrom gpytorch.distributions import MultivariateNormal\r\nfrom gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\r\nfrom gpytorch.means import ConstantMean\r\nfrom scipy.io import loadmat\r\n\r\nif __name__ == '__main__':\r\n    # Run GPyTorch SGPR + independent multioutputs example\r\n    # https://docs.gpytorch.ai/en/v1.2.1/examples/02_Scalable_Exact_GPs/SGPR_Regression_CUDA.html\r\n    # https://github.com/cornellius-gp/gpytorch/issues/1043\r\n    print('Downloading \\'elevators\\' UCI dataset...')\r\n    urllib.request.urlretrieve(\r\n        'https://drive.google.com/uc?export=download&id=1jhWL3YUHvXIaftia4qeAyDwVxo6j1alk',\r\n        '../elevators.mat')\r\n    output_size = 2\r\n    data = torch.Tensor(loadmat('../elevators.mat')['data'])\r\n    X = data[:, :-1]\r\n    X = X - X.min(0)[0]\r\n    X = 2 * (X / X.max(0)[0]) - 1\r\n    y = data[:, -1]\r\n    # MAKE MULTIOUTPUT DATA\r\n    y = y.reshape(-1, 1)\r\n    y = y.repeat(1, output_size)\r\n    print(X.shape, y.shape)\r\n    train_n = int(floor(0.8 * len(X)))\r\n    train_x = X[:train_n, :].contiguous()\r\n    train_y = y[:train_n].contiguous()\r\n    test_x = X[train_n:, :].contiguous()\r\n    test_y = y[train_n:].contiguous()\r\n    if torch.cuda.is_available():\r\n        train_x, train_y, test_x, test_y = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda()\r\n    # CONVERT TO BATCH GP\r\n    train_x = train_x.repeat(output_size, 1, 1)\r\n    train_y = train_y.transpose(-2, -1)\r\n    test_x = test_x.repeat(output_size, 1, 1)\r\n    test_y = test_y.transpose(-2, -1)\r\n    print(train_x.shape, train_y.shape, test_x.shape)\r\n\r\n\r\n    class GPRegressionModel(gpytorch.models.ExactGP):\r\n        def __init__(self, train_x, train_y, likelihood):\r\n            super(GPRegressionModel, self).__init__(train_x, train_y,\r\n                                                    likelihood)\r\n            self.mean_module = ConstantMean(\r\n                batch_shape=torch.Size([output_size]))\r\n            self.base_covar_module = ScaleKernel(RBFKernel(\r\n                batch_shape=torch.Size([output_size])),\r\n                batch_shape=torch.Size([output_size]))\r\n            self.covar_module = InducingPointKernel(\r\n                self.base_covar_module,\r\n                inducing_points=train_x[:, :500, :],\r\n                likelihood=likelihood)\r\n\r\n        def forward(self, x):\r\n            mean_x = self.mean_module(x)\r\n            covar_x = self.covar_module(x)\r\n            return MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood(\r\n        batch_shape=torch.Size([output_size]))\r\n    model = GPRegressionModel(train_x, train_y, likelihood)\r\n    if torch.cuda.is_available():\r\n        model = model.cuda()\r\n        likelihood = likelihood.cuda()\r\n    # Train\r\n    training_iterations = 50\r\n    model.train()\r\n    likelihood.train()\r\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n    start_whole = time.time()\r\n    for i in range(training_iterations):\r\n        start = time.time()\r\n        # Zero backprop gradients\r\n        optimizer.zero_grad()\r\n        # Get output from model\r\n        output = model(train_x)\r\n        # Calc loss and backprop derivatives\r\n        loss = -mll(output, train_y).sum()\r\n        loss.backward()\r\n        end = time.time()\r\n        print('Iter %d/%d - Loss: %.3f' % (\r\n            i + 1, training_iterations, loss.item()), 'in', str(end - start))\r\n        optimizer.step()\r\n        torch.cuda.empty_cache()\r\n    end_whole = time.time()\r\n    print('GPyTorch training time', str(end_whole - start_whole))\r\n    model.eval()\r\n    likelihood.eval()\r\n    start = time.time()\r\n    with gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\r\n        with gpytorch.settings.max_root_decomposition_size(\r\n                30), gpytorch.settings.fast_pred_var():\r\n            preds = model(test_x)\r\n    end = time.time()\r\n    print('predict', str(test_x.shape[1]), 'in', str(end - start))\r\n    print('Test MAE: {}'.format(torch.mean(torch.abs(preds.mean - test_y))))\r\n\r\n    # Compare GPy\r\n    train_x = X[:train_n, :].contiguous()\r\n    train_y = y[:train_n].contiguous()\r\n    test_x = X[train_n:, :].contiguous()\r\n    test_y = y[train_n:].contiguous()\r\n    gpykernel = GPy.kern.RBF(input_dim=train_x.numpy().shape[1], ARD=True)\r\n    gpymodel = GPy.core.SparseGP(train_x.numpy(),\r\n                                 train_y.numpy(),\r\n                                 train_x.numpy()[:500, :],\r\n                                 kernel=gpykernel,\r\n                                 likelihood=GPy.likelihoods.Gaussian(),\r\n                                 inference_method=GPy.inference.latent_function_inference.VarDTC())\r\n    start = time.time()\r\n    gpymodel.optimize(messages=True, max_iters=50)\r\n    end = time.time()\r\n    print('GPy training time', str(end - start))\r\n    start = time.time()\r\n    gpymean, gpyvar = gpymodel.predict(test_x.numpy())\r\n    end = time.time()\r\n    print('predict', str(len(test_x)), 'in', str(end - start))\r\n    print('Test MAE: {}'.format(torch.mean(torch.abs(torch.tensor(gpymean) -\r\n                                                     test_y))))\r\n```\r\n\r\n** Error message without the hacky fix **\r\n```\r\nTraceback (most recent call last):\r\n  File \"issue.py\", line 87, in <module>\r\n    loss = -mll(output, train_y).sum()\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch/venv/lib/python3.8/site-packages/gpytorch/module.py\", line 28, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch/venv/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\", line 62, in forward\r\n    res = output.log_prob(target)\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch/venv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\", line 141, in log_prob\r\n    inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch/venv/lib/python3.8/site-packages/gpytorch/lazy/low_rank_root_added_diag_lazy_tensor.py\", line 98, in inv_quad_logdet\r\n    self_inv_rhs = self._solve(inv_quad_rhs)\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch/venv/lib/python3.8/site-packages/gpytorch/lazy/low_rank_root_added_diag_lazy_tensor.py\", line 42, in _solve\r\n    chol_cap_mat = self.chol_cap_mat\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch/venv/lib/python3.8/site-packages/gpytorch/utils/memoize.py\", line 59, in g\r\n    return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch/venv/lib/python3.8/site-packages/gpytorch/lazy/low_rank_root_added_diag_lazy_tensor.py\", line 31, in chol_cap_mat\r\n    C = ConstantDiagLazyTensor(torch.ones(V.batch_shape, device=V.device, dtype=V.dtype), V.shape[-2])\r\n  File \"/Users/mona/PhD_code/observer_add_GPyTorch/venv/lib/python3.8/site-packages/gpytorch/lazy/diag_lazy_tensor.py\", line 221, in __init__\r\n    self._diag = diag_values.expand(*diag_values.shape[:-1], diag_shape)\r\nRuntimeError: The expanded size of the tensor (500) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [500].  Tensor sizes: [2]\r\n```\r\n\r\n** Computation time on my laptop's CPU with the hacky fix **\r\n```\r\nGPyTorch training time 113.91816210746765\r\npredict 3320 in 3.4245238304138184\r\nTest MAE: 0.07138565927743912\r\n\r\nGPy training time 331.20656394958496\r\npredict 3320 in 0.10564208030700684\r\nTest MAE: 0.06792577020335427\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI expected no error and roughly equal prediction times.\r\n\r\n## System information\r\n\r\n- GPyTorch version 1.2.0\r\n- PyTorch version 1.6.0\r\n- Mac OS Catalina\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1376/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1376/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1369", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1369/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1369/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1369/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1369", "id": 751430372, "node_id": "MDU6SXNzdWU3NTE0MzAzNzI=", "number": 1369, "title": "[Bug] DKL tutorial gives bug about size tuple", "user": {"login": "jeffwillette", "id": 9424192, "node_id": "MDQ6VXNlcjk0MjQxOTI=", "avatar_url": "https://avatars.githubusercontent.com/u/9424192?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeffwillette", "html_url": "https://github.com/jeffwillette", "followers_url": "https://api.github.com/users/jeffwillette/followers", "following_url": "https://api.github.com/users/jeffwillette/following{/other_user}", "gists_url": "https://api.github.com/users/jeffwillette/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeffwillette/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeffwillette/subscriptions", "organizations_url": "https://api.github.com/users/jeffwillette/orgs", "repos_url": "https://api.github.com/users/jeffwillette/repos", "events_url": "https://api.github.com/users/jeffwillette/events{/privacy}", "received_events_url": "https://api.github.com/users/jeffwillette/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-11-26T09:27:12Z", "updated_at": "2020-11-26T14:54:38Z", "closed_at": "2020-11-26T14:54:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nFollow DKL here and give a MVN and a tensor to `ExactMarginalLogLikelihood`\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nyhat = self.model(x)\r\nprint(yhat, y.size())\r\nloss = -self.mll(yhat, y)\r\nprint(loss.item())\r\nloss.backward()\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nMultivariateNormal(loc: torch.Size([364])) torch.Size([364])\r\nTraceback (most recent call last):\r\n  File \"train_regression.py\", line 21, in <module>\r\n    train[args.variant](args)\r\n  File \"/home/jeff/ml/gaussian-processes/trainers.py\", line 55, in exact_dkl_gp_regression\r\n    trainer.fit(x, y, args)\r\n  File \"/home/jeff/ml/gaussian-processes/trainers.py\", line 27, in fit\r\n    loss = -self.mll(yhat, y)\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/module.py\", line 28, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\", line 62, in forward\r\n    res = output.log_prob(target)\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\", line 140, in log_prob\r\n    inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\", line 1022, in inv_quad_logdet\r\n    cholesky = CholLazyTensor(TriangularLazyTensor(self.cholesky()))\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\", line 750, in cholesky\r\n    chol = self._cholesky(upper=False)\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/utils/memoize.py\", line 59, in g\r\n    return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\", line 407, in _cholesky\r\n    evaluated_kern_mat = self.evaluate_kernel()\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\", line 914, in evaluate_kernel\r\n    return self.representation_tree()(*self.representation())\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\", line 1296, in representation_tree\r\n    return LazyTensorRepresentationTree(self)\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor_representation_tree.py\", line 13, in __init__\r\n    representation_size = len(arg.representation())\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 307, in representation\r\n    return self.evaluate_kernel().representation()\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/utils/memoize.py\", line 59, in g\r\n    return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 274, in evaluate_kernel\r\n    res = self.kernel(x1, x2, diag=False, last_dim_is_batch=self.last_dim_is_batch, **self.params)\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/kernels/kernel.py\", line 396, in __call__\r\n    res = lazify(super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/module.py\", line 28, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/kernels/grid_interpolation_kernel.py\", line 181, in forward\r\n    left_interp_indices, left_interp_values = self._compute_grid(x1, last_dim_is_batch)\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/kernels/grid_interpolation_kernel.py\", line 137, in _compute_grid\r\n    interp_indices, interp_values = Interpolation().interpolate(self.grid, inputs)\r\n  File \"/home/jeff/.venv/env/lib/python3.8/site-packages/gpytorch/utils/interpolation.py\", line 93, in interpolate\r\n    interp_values = torch.ones(\r\nTypeError: ones(): argument 'size' must be tuple of ints, but found element of type int at pos 2\r\n```\r\n\r\n## Expected Behavior\r\n\r\nIt should handle the size correctly\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch: `1.2.1`\r\n- torch `1.7.0+cu110`\r\n- ubuntu: `20.04`\r\n\r\n## Additional context\r\n\r\nFollowing DKL tutorial here https://docs.gpytorch.ai/en/v1.2.1/examples/06_PyTorch_NN_Integration_DKL/KISSGP_Deep_Kernel_Regression_CUDA.html\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1369/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1369/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1367", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1367/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1367/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1367/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1367", "id": 751419917, "node_id": "MDU6SXNzdWU3NTE0MTk5MTc=", "number": 1367, "title": "[Bug] Resize error thrown when using Batch Independent Multi Output", "user": {"login": "acxz", "id": 17132214, "node_id": "MDQ6VXNlcjE3MTMyMjE0", "avatar_url": "https://avatars.githubusercontent.com/u/17132214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/acxz", "html_url": "https://github.com/acxz", "followers_url": "https://api.github.com/users/acxz/followers", "following_url": "https://api.github.com/users/acxz/following{/other_user}", "gists_url": "https://api.github.com/users/acxz/gists{/gist_id}", "starred_url": "https://api.github.com/users/acxz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/acxz/subscriptions", "organizations_url": "https://api.github.com/users/acxz/orgs", "repos_url": "https://api.github.com/users/acxz/repos", "events_url": "https://api.github.com/users/acxz/events{/privacy}", "received_events_url": "https://api.github.com/users/acxz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-11-26T09:12:36Z", "updated_at": "2020-11-27T16:02:44Z", "closed_at": "2020-11-27T16:02:44Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nEssentially I tried to take a crack at implementing the `from_batch_mvn` style for Batch Independent Multi Output GP based on the tutorial: https://docs.gpytorch.ai/en/v1.2.1/examples/03_Multitask_Exact_GPs/Batch_Independent_Multioutput_GP.html\r\n\r\nTraining works just fine, but when I try to predict in `eval()` mode, I get a resize error inside of gpytorch code.\r\nIt is interesting to note that when my output_dim is 1, I do not face any issues.\r\n\r\nMy code below is not really reproducible. I'm using [pytorch-lightning](https://www.pytorchlightning.ai/) to take care of the training loops and optimization calls. Its pretty neat and was happy I got it working with GPyTorch, maybe I'll submit a PR with an example usage of gpytorch and pytorch lightning together. In any case I'll add a minimal working example soon.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n\"\"\"Gaussian Process Model.\"\"\"\r\n\r\nimport argparse\r\n\r\nimport gpytorch\r\n\r\nimport pytorch_lightning as lt\r\n\r\nimport torch\r\n\r\n\r\nclass BIMOEGP(gpytorch.models.ExactGP):\r\n    \"\"\"batch independent multioutput exact gp model.\"\"\"\r\n\r\n    def __init__(self, train_input_data, train_output_data, likelihood):\r\n        \"\"\"Initialize gp model with mean and covar.\"\"\"\r\n        super().__init__(train_input_data, train_output_data, likelihood)\r\n\r\n        output_dim = train_output_data.shape[1]\r\n        output_dim_torch = torch.Size([output_dim])\r\n\r\n        self.mean_module = \\\r\n            gpytorch.means.ConstantMean(batch_shape=output_dim_torch)\r\n\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(batch_shape=output_dim_torch),\r\n            batch_shape=output_dim_torch)\r\n\r\n    # pylint: disable=arguments-differ\r\n    def forward(self, input_):\r\n        \"\"\"Compute prediction.\"\"\"\r\n        mean = self.mean_module(input_)\r\n        covar = self.covar_module(input_)\r\n\r\n        return \\\r\n            gpytorch.distributions.MultitaskMultivariateNormal.from_batch_mvn(\r\n                gpytorch.distributions.MultivariateNormal(mean, covar))\r\n\r\n\r\n# pylint: disable=too-many-ancestors\r\nclass BIMOEGPModel(lt.core.lightning.LightningModule):\r\n    \"\"\"batch independent multioutput exact gp model.\"\"\"\r\n\r\n    def __init__(self, hparams, train_input_data, train_output_data):\r\n        \"\"\"Initialize gp model with mean and covar.\"\"\"\r\n        super().__init__()\r\n\r\n        self.hparams = hparams\r\n\r\n        output_dim = train_output_data.shape[1]\r\n        self.likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(\r\n            num_tasks=output_dim)\r\n\r\n        self.bimoegp = BIMOEGP(train_input_data, train_output_data,\r\n                               self.likelihood)\r\n\r\n        self.mll = gpytorch.mlls.ExactMarginalLogLikelihood(\r\n            self.likelihood, self.bimoegp)\r\n\r\n    # pylint: disable=arguments-differ\r\n    def forward(self, input_):\r\n        \"\"\"Compute prediction.\"\"\"\r\n        return self.bimoegp(input_)\r\n\r\n    # pylint: disable=unused-argument\r\n    def training_step(self, batch, batch_idx):\r\n        \"\"\"Compute training loss.\"\"\"\r\n        input_, target = batch\r\n        output = self(input_)\r\n\r\n        loss = -self.mll(output, target)\r\n\r\n        return {'loss': loss}\r\n\r\n    def configure_optimizers(self):\r\n        \"\"\"Create optimizer.\"\"\"\r\n        optimizer = torch.optim.Adam(\r\n            self.parameters(),\r\n            lr=self.hparams.learning_rate)\r\n\r\n        return optimizer\r\n\r\n    # pylint: disable=unused-argument\r\n    def validation_step(self, batch, batch_idx):\r\n        \"\"\"Compute validation loss.\"\"\"\r\n        input_, target = batch\r\n        output = self(input_)\r\n\r\n        loss = -self.mll(output, target)\r\n\r\n        return {'val_loss': loss}\r\n\r\n    # pylint: disable=no-self-use\r\n    def validation_epoch_end(self, outputs):\r\n        \"\"\"Record validation loss.\"\"\"\r\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\r\n        self.log('avg_val_loss', avg_loss)\r\n\r\n    # pylint: disable=unused-argument\r\n    def test_step(self, batch, batch_idx):\r\n        \"\"\"Compute testing loss.\"\"\"\r\n        input_, target = batch\r\n        output = self(input_)\r\n\r\n        loss = -self.mll(output, target)\r\n\r\n        return {'test_loss': loss}\r\n\r\n    def test_epoch_end(self, outputs):\r\n        \"\"\"Record average test loss.\"\"\"\r\n        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\r\n        self.log('avg_test_loss', avg_loss)\r\n\r\n    @ staticmethod\r\n    def add_model_specific_args(parent_parser):\r\n        \"\"\"Parse model specific hyperparameters.\"\"\"\r\n        parser = argparse.ArgumentParser(\r\n            parents=[parent_parser], add_help=False)\r\n        parser.add_argument('--learning_rate', type=float, default=1e-3)\r\n\r\n        return parser\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n  File \"/usr/lib/python3.8/site-packages/pl_utils/models/gp.py\", line 73, in forward\r\n    return self.bimoegp(input_)\r\n  File \"/usr/lib/python3.8/site-packages/gpytorch/models/exact_gp.py\", line 283, in __call__\r\n    self.prediction_strategy = prediction_strategy(\r\n  File \"/usr/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\", line 33, in prediction_strategy\r\n    return cls(train_inputs, train_prior_dist, train_labels, likelihood)\r\n  File \"/usr/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\", line 40, in __init__\r\n    train_labels = train_labels.view(*train_labels.shape[: -len(train_shape)], train_shape.numel())\r\nRuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nThere should be no error related to resizing.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version: 1.2.1\r\n- PyTorch Version: 1.7.0\r\n- Arch Linux\r\n\r\n## Additional context\r\nDownstream issue: https://github.com/acxz/pl-utils/issues/7\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1367/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1367/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1360", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1360/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1360/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1360/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1360", "id": 749103586, "node_id": "MDU6SXNzdWU3NDkxMDM1ODY=", "number": 1360, "title": "[Bug] priors are lost after deepcopy (and ExactGP.get_fantasy_model) ", "user": {"login": "sdaulton", "id": 8037929, "node_id": "MDQ6VXNlcjgwMzc5Mjk=", "avatar_url": "https://avatars.githubusercontent.com/u/8037929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sdaulton", "html_url": "https://github.com/sdaulton", "followers_url": "https://api.github.com/users/sdaulton/followers", "following_url": "https://api.github.com/users/sdaulton/following{/other_user}", "gists_url": "https://api.github.com/users/sdaulton/gists{/gist_id}", "starred_url": "https://api.github.com/users/sdaulton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sdaulton/subscriptions", "organizations_url": "https://api.github.com/users/sdaulton/orgs", "repos_url": "https://api.github.com/users/sdaulton/repos", "events_url": "https://api.github.com/users/sdaulton/events{/privacy}", "received_events_url": "https://api.github.com/users/sdaulton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-11-23T20:31:01Z", "updated_at": "2020-12-17T22:54:23Z", "closed_at": "2020-12-17T22:54:23Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nGPyTorch modules register priors using a (name, prior, closure, setting_closure) tuple. The closure and setting_closure are callables that reference the instance (self) as a global variable. When a module is deepcopied. Those closure methods are copied over, but still reference the original instance (not the new copy). Therefore the closure returns the parameters attached to the old module, not the new copy. This makes the loss term from the priors constant in the MLL evaluation.\r\n\r\n## To reproduce\r\n[test_deepcopy.ipynb.txt](https://github.com/cornellius-gp/gpytorch/files/5585605/test_deepcopy.ipynb.txt)\r\n\r\n## Expected Behavior\r\n\r\nIdeally, the prior distributions would work as expected on fantasy models.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1360/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1360/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1354", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1354/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1354/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1354/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1354", "id": 746084323, "node_id": "MDU6SXNzdWU3NDYwODQzMjM=", "number": 1354, "title": "[Bug] ConstantMulLazyTensor recomputes its own root", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-11-18T22:40:51Z", "updated_at": "2021-02-18T03:36:16Z", "closed_at": "2021-02-18T03:36:16Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n`ConstantMulLazyTensor` recomputes its own root decomposition even when the component lazy tensor already has its own root. This is quite slow because it means more root decompositions are called than are strictly necessary.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nfrom gpytorch.lazy import lazify, RootLazyTensor\r\n\r\na = torch.randn(50, 10)\r\nlazy_square_a = RootLazyTensor(lazify(a))\r\n(4. * lazy_square_a).root_decomposition().root.evaluate() # this is not 2 * a.\r\n```\r\n\r\n## Expected Behavior\r\n\r\nAt least for positive constants, this should return 2 * a.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\ngpytorch master\r\npytorch 1.7.0\r\nmac os\r\n\r\n## Additional context\r\nI'll make a PR in a minute.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1354/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1349", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1349/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1349/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1349/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1349", "id": 742990508, "node_id": "MDU6SXNzdWU3NDI5OTA1MDg=", "number": 1349, "title": "[Question] Sparse GPs for Batch Independent MultiOutputs slow prediction?", "user": {"login": "monabf", "id": 26089777, "node_id": "MDQ6VXNlcjI2MDg5Nzc3", "avatar_url": "https://avatars.githubusercontent.com/u/26089777?v=4", "gravatar_id": "", "url": "https://api.github.com/users/monabf", "html_url": "https://github.com/monabf", "followers_url": "https://api.github.com/users/monabf/followers", "following_url": "https://api.github.com/users/monabf/following{/other_user}", "gists_url": "https://api.github.com/users/monabf/gists{/gist_id}", "starred_url": "https://api.github.com/users/monabf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/monabf/subscriptions", "organizations_url": "https://api.github.com/users/monabf/orgs", "repos_url": "https://api.github.com/users/monabf/repos", "events_url": "https://api.github.com/users/monabf/events{/privacy}", "received_events_url": "https://api.github.com/users/monabf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-11-14T11:57:15Z", "updated_at": "2020-11-30T09:44:30Z", "closed_at": "2020-11-28T20:14:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "# Question\r\n\r\nThanks for this great package!\r\n\r\nNot really a bug, rather a question. I need to train a GP with 20,000x7 training inputs, 20,000x5 training outputs, and 40,000x7 test inputs. My first call was to look into the implementation of sparse GPs, because that's what I usually use with GPy. I implemented a sparse + batch independent multioutput GP model class as in issue #1043 and tested it with the UCI elevators dataset from the [SGPR tutorial](https://docs.gpytorch.ai/en/v1.1.1/examples/02_Scalable_Exact_GPs/SGPR_Regression_CUDA.html). \r\n\r\nHowever, I noticed that while training runs as expected, prediction is unreasonably slow. Attached is a small example comparing training and prediction time with GPyTorch and GPy. The difference gets much larger as the number of output dimensions, training samples or inducing points grows. \r\n\r\nSo here are my questions:\r\n1) How come prediction takes so long with the sparse + multioutput GP model from #1043? Is there a bug somewhere, or is this actually expected?\r\n2) Is it just a bad call to try using SGPR with multioutputs? I don't care which method I am using, I just need to be able to train large, multioutput GPs efficiently. This will mostly be done on GPU, but I would still like it to run reasonably on CPU so I can do some tests locally. With sparse GPs from GPy my use case ran in around 2h, which I would consider reasonable on CPU for tests, but with my current GPyTorch implementation prediction alone takes about 20h... I am open to suggestions!\r\n\r\nThanks a lot for your help.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport time\r\nimport urllib.request\r\nfrom math import floor\r\n\r\nimport GPy\r\nimport gpytorch\r\nimport torch\r\nfrom gpytorch.distributions import MultivariateNormal\r\nfrom gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\r\nfrom gpytorch.means import ConstantMean\r\nfrom scipy.io import loadmat\r\n\r\nif __name__ == '__main__':\r\n    # Run GPyTorch SGPR + independent multioutputs example\r\n    # https://docs.gpytorch.ai/en/v1.2.1/examples/02_Scalable_Exact_GPs/SGPR_Regression_CUDA.html\r\n    # https://github.com/cornellius-gp/gpytorch/issues/1043\r\n    print('Downloading \\'elevators\\' UCI dataset...')\r\n    urllib.request.urlretrieve(\r\n        'https://drive.google.com/uc?export=download&id=1jhWL3YUHvXIaftia4qeAyDwVxo6j1alk',\r\n        '../elevators.mat')\r\n    output_size = 2\r\n    data = torch.Tensor(loadmat('../elevators.mat')['data'])\r\n    X = data[:, :-1]\r\n    X = X - X.min(0)[0]\r\n    X = 2 * (X / X.max(0)[0]) - 1\r\n    y = data[:, -1]\r\n    # MAKE MULTIOUTPUT DATA\r\n    y = y.reshape(-1, 1)\r\n    y = y.repeat(1, output_size)\r\n    print(X.shape, y.shape)\r\n    train_n = int(floor(0.8 * len(X)))\r\n    train_x = X[:train_n, :].contiguous()\r\n    train_y = y[:train_n].contiguous()\r\n    test_x = X[train_n:, :].contiguous()\r\n    test_y = y[train_n:].contiguous()\r\n    if torch.cuda.is_available():\r\n        train_x, train_y, test_x, test_y = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda()\r\n    # CONVERT TO BATCH GP\r\n    train_x = train_x.repeat(output_size, 1, 1)\r\n    train_y = train_y.transpose(-2, -1)\r\n    test_x = test_x.repeat(output_size, 1, 1)\r\n    test_y = test_y.transpose(-2, -1)\r\n    print(train_x.shape, train_y.shape, test_x.shape)\r\n\r\n\r\n    class GPRegressionModel(gpytorch.models.ExactGP):\r\n        def __init__(self, train_x, train_y, likelihood):\r\n            super(GPRegressionModel, self).__init__(train_x, train_y,\r\n                                                    likelihood)\r\n            self.mean_module = ConstantMean(\r\n                batch_shape=torch.Size([output_size]))\r\n            self.base_covar_module = ScaleKernel(RBFKernel(\r\n                batch_shape=torch.Size([output_size])),\r\n                batch_shape=torch.Size([output_size]))\r\n            self.covar_module = InducingPointKernel(\r\n                self.base_covar_module,\r\n                inducing_points=train_x[:, :500, :],\r\n                likelihood=likelihood)\r\n\r\n        def forward(self, x):\r\n            mean_x = self.mean_module(x)\r\n            covar_x = self.covar_module(x)\r\n            return MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood(\r\n        batch_shape=torch.Size([output_size]))\r\n    model = GPRegressionModel(train_x, train_y, likelihood)\r\n    if torch.cuda.is_available():\r\n        model = model.cuda()\r\n        likelihood = likelihood.cuda()\r\n    # Train\r\n    training_iterations = 50\r\n    model.train()\r\n    likelihood.train()\r\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n    start_whole = time.time()\r\n    for i in range(training_iterations):\r\n        start = time.time()\r\n        # Zero backprop gradients\r\n        optimizer.zero_grad()\r\n        # Get output from model\r\n        output = model(train_x)\r\n        # Calc loss and backprop derivatives\r\n        loss = -mll(output, train_y).sum()\r\n        loss.backward()\r\n        end = time.time()\r\n        print('Iter %d/%d - Loss: %.3f' % (\r\n            i + 1, training_iterations, loss.item()), 'in', str(end - start))\r\n        optimizer.step()\r\n        torch.cuda.empty_cache()\r\n    end_whole = time.time()\r\n    print('GPyTorch training time', str(end_whole - start_whole))\r\n    model.eval()\r\n    likelihood.eval()\r\n    start = time.time()\r\n    with gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\r\n        with gpytorch.settings.max_root_decomposition_size(\r\n                30), gpytorch.settings.fast_pred_var():\r\n            preds = model(test_x)\r\n    end = time.time()\r\n    print('predict', str(test_x.shape[1]), 'in', str(end - start))\r\n    print('Test MAE: {}'.format(torch.mean(torch.abs(preds.mean - test_y))))\r\n\r\n    # Compare GPy\r\n    train_x = X[:train_n, :].contiguous()\r\n    train_y = y[:train_n].contiguous()\r\n    test_x = X[train_n:, :].contiguous()\r\n    test_y = y[train_n:].contiguous()\r\n    gpykernel = GPy.kern.RBF(input_dim=train_x.numpy().shape[1], ARD=True)\r\n    gpymodel = GPy.core.SparseGP(train_x.numpy(),\r\n                                 train_y.numpy(),\r\n                                 train_x.numpy()[:500, :],\r\n                                 kernel=gpykernel,\r\n                                 likelihood=GPy.likelihoods.Gaussian(),\r\n                                 inference_method=GPy.inference.latent_function_inference.VarDTC())\r\n    start = time.time()\r\n    gpymodel.optimize(messages=True, max_iters=50)\r\n    end = time.time()\r\n    print('GPy training time', str(end - start))\r\n    start = time.time()\r\n    gpymean, gpyvar = gpymodel.predict(test_x.numpy())\r\n    end = time.time()\r\n    print('predict', str(len(test_x)), 'in', str(end - start))\r\n    print('Test MAE: {}'.format(torch.mean(torch.abs(torch.tensor(gpymean) -\r\n                                                     test_y))))\r\n```\r\n\r\n** On my laptop's CPU **\r\n```\r\nGPyTorch training time 182.81384825706482\r\npredict 3320 in 6.573011159896851\r\nTest MAE: 0.07266882807016373\r\n\r\nGPy training time 220.74766993522644\r\npredict 3320 in 0.06382608413696289\r\nTest MAE: 0.06792577020335429\r\n```\r\n\r\n** On GPU with Google Colab **\r\n```\r\nGPyTorch training time 12.468220949172974\r\npredict 3320 in 0.2444145679473877\r\nTest MAE: 0.07270058244466782\r\n\r\nGPy training time 340.8614845275879\r\npredict 3320 in 0.11290717124938965\r\nTest MAE: 0.06792590803210088\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI would expect training and prediction time for both GPyTorch and GPy to be of the same order of magnitude on CPU, GPyTorch an order of magnitude faster on GPU. For training this is approximately the case, but not for prediction...\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch version 1.2.0\r\n- PyTorch version 1.6.0\r\n- Mac OS Catalina\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1349/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 1}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1349/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1333", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1333/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1333/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1333/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1333", "id": 738047585, "node_id": "MDU6SXNzdWU3MzgwNDc1ODU=", "number": 1333, "title": "Non-Square Hadamard Multiplication Fails [Bug]", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-11-06T21:17:11Z", "updated_at": "2020-11-09T16:05:32Z", "closed_at": "2020-11-09T16:05:32Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nLooks like hadamard matrix multiplication is calling a root decomposition which is not well-defined for non-square lazy tensors. The fix is to check to see if the two matrices are non-square here.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\na = gpytorch.lazify(torch.randn(30, 10))\r\nb = gpytorch.lazify(torch.randn(10, 10))\r\n\r\nab = a.matmul(b)\r\n# is not a matmul lazy tensor\r\n\r\n(ab * ab) # fails\r\n\r\n(ab.evaluate() * ab.evaluate()) # does not fail\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/lazy_tensor.py in _mul_matrix(self, other)\r\n    508             left_lazy_tensor = self if self._root_decomposition_size() < other._root_decomposition_size() else other\r\n    509             right_lazy_tensor = other if left_lazy_tensor is self else self\r\n--> 510             return MulLazyTensor(left_lazy_tensor.root_decomposition(), right_lazy_tensor.root_decomposition())\r\n\r\nRuntimeError: root_decomposition only operates on (batches of) square (symmetric) LazyTensors. Got a MatmulLazyTensor of size torch.Size([30, 10]).\r\n```\r\n\r\n## Expected Behavior\r\n\r\nShould return a Hadamard? or matmul lazy tensor rather than failing.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch 1.2.0\r\n- torch 1.7.0\r\n- mac os\r\n\r\n## Additional context\r\nI'd like to circumvent passing ab into a RootLazyTensor to get the diagonal out and so would like to directly do the Hadamard product here and reduce. (e.g. ```RootLazyTensor(ab).diag()```).\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1333/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1333/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1328", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1328/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1328/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1328/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1328", "id": 735031302, "node_id": "MDU6SXNzdWU3MzUwMzEzMDI=", "number": 1328, "title": "[Bug] SpectralMixtureKernel training inputs w/ constant value along a dimension", "user": {"login": "SomeshDaga", "id": 5409975, "node_id": "MDQ6VXNlcjU0MDk5NzU=", "avatar_url": "https://avatars.githubusercontent.com/u/5409975?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SomeshDaga", "html_url": "https://github.com/SomeshDaga", "followers_url": "https://api.github.com/users/SomeshDaga/followers", "following_url": "https://api.github.com/users/SomeshDaga/following{/other_user}", "gists_url": "https://api.github.com/users/SomeshDaga/gists{/gist_id}", "starred_url": "https://api.github.com/users/SomeshDaga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SomeshDaga/subscriptions", "organizations_url": "https://api.github.com/users/SomeshDaga/orgs", "repos_url": "https://api.github.com/users/SomeshDaga/repos", "events_url": "https://api.github.com/users/SomeshDaga/events{/privacy}", "received_events_url": "https://api.github.com/users/SomeshDaga/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-11-03T05:34:31Z", "updated_at": "2020-11-03T19:59:48Z", "closed_at": "2020-11-03T19:59:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThe `initialize_from_data` method for the SpectralMixtureKernel does not admit a `train_x` with constant values along any dimension.  \r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\n# Initialize 100 samples training data\r\n# Inputs have dimension 5\r\n# Outputs have dimension 2\r\ntrain_x = torch.randn(100, 5)\r\n# Set values for inputs along dimension 1 to be  equal\r\ntrain_x[:, 1] = torch.ones(100)\r\ntrain_y = torch.randn(100, 2)\r\n\r\nkernel = gp.kernels.SpectralMixtureKernel(num_mixtures=4, ard_num_dims=5)\r\nkernel.initialize_from_data(train_x, train_y)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/somesh/imitation/src/imitation/sandbox/imitate.py\", line 138, in <module>\r\n    correlate_actions=False\r\n  File \"/home/somesh/imitation/src/imitation/sandbox/algorithms/bc/gp.py\", line 231, in __init__\r\n    feature_extractor_kwargs=feature_extractor_kwargs\r\n  File \"/home/somesh/imitation/src/imitation/sandbox/algorithms/bc/gp.py\", line 164, in __init__\r\n    self.covar_module.initialize_from_data(self.train_x, self.train_y)\r\n  File \"/home/somesh/imitation/lib/python3.7/site-packages/gpytorch/kernels/spectral_mixture_kernel.py\", line 211, in initialize_from_data\r\n    min_dist[:, ind] = min_dist_sort[((min_dist_sort[:, ind]).nonzero(as_tuple=False))[0], ind]\r\nIndexError: index 0 is out of bounds for dimension 0 with size 0\r\n```\r\n\r\n## Expected Behavior\r\n\r\nNo errors should be observed.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch 1.2.1\r\n- PyTorch 1.7.0\r\n- Ubuntu 18.04\r\n\r\n## Additional context\r\nThe `initialize_from_data` function clearly expects non-zero differences in values along every dimension. For datasets with a large amount of features, we may expect there to be some 'useless' features. One way to approach this might be to preprocess the data and remove such features, but it would be ideal if this scenario could be dealt with gracefully by the kernel class.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1328/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1328/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1320", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1320/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1320/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1320/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1320", "id": 728793296, "node_id": "MDU6SXNzdWU3Mjg3OTMyOTY=", "number": 1320, "title": "Time for bugfix release?", "user": {"login": "y0ast", "id": 485778, "node_id": "MDQ6VXNlcjQ4NTc3OA==", "avatar_url": "https://avatars.githubusercontent.com/u/485778?v=4", "gravatar_id": "", "url": "https://api.github.com/users/y0ast", "html_url": "https://github.com/y0ast", "followers_url": "https://api.github.com/users/y0ast/followers", "following_url": "https://api.github.com/users/y0ast/following{/other_user}", "gists_url": "https://api.github.com/users/y0ast/gists{/gist_id}", "starred_url": "https://api.github.com/users/y0ast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/y0ast/subscriptions", "organizations_url": "https://api.github.com/users/y0ast/orgs", "repos_url": "https://api.github.com/users/y0ast/repos", "events_url": "https://api.github.com/users/y0ast/events{/privacy}", "received_events_url": "https://api.github.com/users/y0ast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-10-24T13:48:04Z", "updated_at": "2020-10-27T16:29:01Z", "closed_at": "2020-10-27T16:29:01Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I just hit a combination of:\r\nhttps://github.com/cornellius-gp/gpytorch/commit/5bff5be87be033f2d3a95423557b5af3dbf1746b\r\nhttps://github.com/cornellius-gp/gpytorch/commit/903ae8bac6f35b250a0a3f58302935510d336f57\r\n\r\nand it was very painful to debug.\r\n\r\nWould it be possible to make a 1.2.1 bugfix release?\r\n\r\nI am running the nightly now, so it's fixed for me, but I don't wish anyone else the same bug chase experience. :)\r\n\r\nThanks for your work! I thoroughly enjoy GPyTorch.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1320/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1320/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1318", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1318/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1318/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1318/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1318", "id": 725900950, "node_id": "MDU6SXNzdWU3MjU5MDA5NTA=", "number": 1318, "title": "[Bug] Prior losses are incorrectly added to the mll in batch-mode", "user": {"login": "dme65", "id": 12738905, "node_id": "MDQ6VXNlcjEyNzM4OTA1", "avatar_url": "https://avatars.githubusercontent.com/u/12738905?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dme65", "html_url": "https://github.com/dme65", "followers_url": "https://api.github.com/users/dme65/followers", "following_url": "https://api.github.com/users/dme65/following{/other_user}", "gists_url": "https://api.github.com/users/dme65/gists{/gist_id}", "starred_url": "https://api.github.com/users/dme65/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dme65/subscriptions", "organizations_url": "https://api.github.com/users/dme65/orgs", "repos_url": "https://api.github.com/users/dme65/repos", "events_url": "https://api.github.com/users/dme65/events{/privacy}", "received_events_url": "https://api.github.com/users/dme65/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-10-20T19:59:44Z", "updated_at": "2022-10-18T10:39:41Z", "closed_at": "2022-10-18T10:39:41Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nPrior losses are currently being added up incorrectly in `ExactMarginalLogLikelihood`. The line: \r\n```\r\nres.add_(prior.log_prob(closure()).sum())\r\n```` \r\nwill sum up all of the losses and then add them to the mll. If you are using a batch model this sum gets added to all of the batch dimensions which will count the losses multiple times when eventually calling `loss.sum().backward()`. It looks like the priors may not support batch mode which leads to a large variety of different shapes, but the `.sum()` call masks this issue since it just sums everything up anyway.\r\n\r\n## To reproduce\r\n\r\n**Code snippet (taken from `test_train_on_batch_test_on_batch`):**\r\n\r\n```\r\nimport math\r\n\r\nimport torch\r\n\r\nimport gpytorch\r\nfrom gpytorch.distributions import MultivariateNormal\r\nfrom gpytorch.kernels import RBFKernel, ScaleKernel\r\nfrom gpytorch.likelihoods import GaussianLikelihood\r\nfrom gpytorch.means import ConstantMean\r\n\r\ntrain_x1 = torch.linspace(0, 2, 11).unsqueeze(-1)\r\ntrain_y1 = torch.sin(train_x1 * (2 * math.pi)).squeeze()\r\ntrain_x2 = torch.linspace(0, 1, 11).unsqueeze(-1)\r\ntrain_y2 = torch.sin(train_x2 * (2 * math.pi)).squeeze()\r\ntrain_x12 = torch.cat((train_x1.unsqueeze(0), train_x2.unsqueeze(0)), dim=0).contiguous()\r\ntrain_y12 = torch.cat((train_y1.unsqueeze(0), train_y2.unsqueeze(0)), dim=0).contiguous()\r\n\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_inputs, train_targets, likelihood, batch_shape=torch.Size()):\r\n        super(ExactGPModel, self).__init__(train_inputs, train_targets, likelihood)\r\n        self.mean_module = ConstantMean(batch_shape=batch_shape, prior=gpytorch.priors.SmoothedBoxPrior(-1, 1))\r\n        self.covar_module = ScaleKernel(\r\n            RBFKernel(\r\n                batch_shape=batch_shape,\r\n                lengthscale_prior=gpytorch.priors.NormalPrior(\r\n                    loc=torch.zeros(*batch_shape, 1, 1), scale=torch.ones(*batch_shape, 1, 1)\r\n                ),\r\n            ),\r\n            batch_shape=batch_shape,\r\n            outputscale_prior=gpytorch.priors.SmoothedBoxPrior(-2, 2),\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return MultivariateNormal(mean_x, covar_x)\r\n    \r\n\r\n# We're manually going to set the hyperparameters to something they shouldn't be\r\nlikelihood = GaussianLikelihood(\r\n    noise_prior=gpytorch.priors.NormalPrior(loc=torch.zeros(2), scale=torch.ones(2)),\r\n    batch_shape=torch.Size([2]),\r\n)\r\ngp_model = ExactGPModel(train_x12, train_y12, likelihood, batch_shape=torch.Size([2]))\r\n\r\nfor name, prior, closure, _ in gp_model.named_priors():\r\n    print(name, prior.log_prob(closure()).shape)\r\n```\r\n\r\n**Output:**\r\n```\r\nlikelihood.noise_covar.noise_prior torch.Size([2, 2])\r\nmean_module.mean_prior torch.Size([2])\r\ncovar_module.outputscale_prior torch.Size([])\r\ncovar_module.base_kernel.lengthscale_prior torch.Size([2, 1, 1])\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThe prior losses should have the same size and be added up via `res.add_(prior.log_prob(closure()))` without the inner sum call.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGPyTorch Version: 1.2.0\r\nPyTorch Version: 1.6.0\r\nMac\r\n\r\n## Additional context\r\nThis was originally discovered in PR #1314.\r\n\r\ncc: @Balandat ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1318/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1318/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1312", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1312/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1312/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1312/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1312", "id": 722443776, "node_id": "MDExOlB1bGxSZXF1ZXN0NTA0MTkzNTI0", "number": 1312, "title": "Fix shape issue for MMVN with broadcasted means", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}, {"id": 1607679275, "node_id": "MDU6TGFiZWwxNjA3Njc5Mjc1", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/multitask", "name": "multitask", "color": "ffffff", "default": false, "description": "For questions about multitask models"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-10-15T15:32:13Z", "updated_at": "2020-10-26T17:04:22Z", "closed_at": "2020-10-26T12:34:39Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1312", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1312", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1312.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1312.patch", "merged_at": "2020-10-26T12:34:39Z"}, "body": "If I have a MMVN with `mean.shape = [1 x d]` and `cover.shape = `[nd x nd]`, I would expect the singleton dimension in the mean to broadcast. Similarly for `mean.shape = [n x 1]` and `cover.shape = `[nd x nd]`.\r\n\r\nThis PR fixes a small bug and allows for this broadcasting.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1312/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1312/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1308", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1308/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1308/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1308/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1308", "id": 720104981, "node_id": "MDU6SXNzdWU3MjAxMDQ5ODE=", "number": 1308, "title": "[Bug] Reloading saved parameters into a variational model hurts performance", "user": {"login": "ZhiliangWu", "id": 18686697, "node_id": "MDQ6VXNlcjE4Njg2Njk3", "avatar_url": "https://avatars.githubusercontent.com/u/18686697?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZhiliangWu", "html_url": "https://github.com/ZhiliangWu", "followers_url": "https://api.github.com/users/ZhiliangWu/followers", "following_url": "https://api.github.com/users/ZhiliangWu/following{/other_user}", "gists_url": "https://api.github.com/users/ZhiliangWu/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZhiliangWu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZhiliangWu/subscriptions", "organizations_url": "https://api.github.com/users/ZhiliangWu/orgs", "repos_url": "https://api.github.com/users/ZhiliangWu/repos", "events_url": "https://api.github.com/users/ZhiliangWu/events{/privacy}", "received_events_url": "https://api.github.com/users/ZhiliangWu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2020-10-13T10:38:30Z", "updated_at": "2022-06-27T02:05:34Z", "closed_at": "2020-10-15T17:21:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThe performance of the saved SVGP model differs a lot if the model is not newly instantiated. \r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport os\r\n\r\nfrom math import floor\r\n\r\nimport tqdm\r\nimport gpytorch\r\nfrom gpytorch.models import ApproximateGP\r\nfrom gpytorch.variational import CholeskyVariationalDistribution\r\nfrom gpytorch.variational import VariationalStrategy\r\nfrom scipy.io import loadmat\r\nfrom sklearn.metrics import mean_squared_error\r\nimport torch\r\nfrom torch.utils.data import TensorDataset, DataLoader\r\nimport urllib.request\r\n\r\n\r\nif not os.path.isfile('../elevators.mat'):\r\n    print('Downloading \\'elevators\\' UCI dataset...')\r\n    urllib.request.urlretrieve('https://drive.google.com/uc?export=download&id=1jhWL3YUHvXIaftia4qeAyDwVxo6j1alk', '../elevators.mat')\r\n\r\ndata = torch.Tensor(loadmat('../elevators.mat')['data'])\r\nX = data[:, :-1]\r\nX = X - X.min(0)[0]\r\nX = 2 * (X / X.max(0)[0]) - 1\r\ny = data[:, -1]\r\n\r\n\r\ntrain_n = int(floor(0.8 * len(X)))\r\ntrain_x = X[:train_n, :].contiguous()\r\ntrain_y = y[:train_n].contiguous()\r\n\r\ntest_x = X[train_n:, :].contiguous()\r\ntest_y = y[train_n:].contiguous()\r\n\r\n\r\ntrain_dataset = TensorDataset(train_x, train_y)\r\ntrain_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\r\n\r\ntest_dataset = TensorDataset(test_x, test_y)\r\ntest_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\r\n\r\n\r\nclass GPModel(ApproximateGP):\r\n    def __init__(self, inducing_points):\r\n        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\r\n        variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\r\n        super(GPModel, self).__init__(variational_strategy)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\ninducing_points = train_x[:500, :]\r\nmodel = GPModel(inducing_points=inducing_points)\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n\r\nnum_epochs = 4\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# We use SGD here, rather than Adam. Emperically, we find that SGD is better for variational regression\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},\r\n    {'params': likelihood.parameters()},\r\n], lr=0.01)\r\n\r\n# Our loss object. We're using the VariationalELBO\r\nmll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\r\n\r\n\r\nepochs_iter = tqdm.tqdm(range(num_epochs), desc=\"Epoch\")\r\nfor i in epochs_iter:\r\n    # Within each iteration, we will go over each minibatch of data\r\n    minibatch_iter = tqdm.tqdm(train_loader, desc=\"Minibatch\", leave=False)\r\n    for x_batch, y_batch in minibatch_iter:\r\n        optimizer.zero_grad()\r\n        output = model(x_batch)\r\n        loss = -mll(output, y_batch)\r\n        minibatch_iter.set_postfix(loss=loss.item())\r\n        loss.backward()\r\n        optimizer.step()\r\n\r\n\r\nmodel.eval()\r\nlikelihood.eval()\r\ny_pred_list = []\r\ny_true_list = []\r\nwith torch.no_grad():\r\n    for x_batch, y_batch in test_loader:\r\n        preds = model(x_batch)\r\n        y_pred_list.append(preds.mean)\r\n        y_true_list.append(y_batch)\r\n\r\ny_pred = torch.cat(y_pred_list, dim=0).numpy()\r\ny_true = torch.cat(y_true_list, dim=0).numpy()\r\n\r\ntest_mse = mean_squared_error(y_true, y_pred)\r\nprint(test_mse)\r\n\r\n\r\n# torch.save(model.state_dict(), 'my_gp_with_nn_model.pth')    # uncomment once to save the model on the disk\r\nstate_dict = torch.load('my_gp_with_nn_model.pth')\r\n\r\n# inducing_points = train_x[:500, :]\r\n# model = GPModel(inducing_points=inducing_points)\r\n# likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n\r\nmodel.load_state_dict(state_dict)\r\n\r\nmodel.eval()\r\nlikelihood.eval()\r\ny_pred_list = []\r\ny_true_list = []\r\nwith torch.no_grad():\r\n    for x_batch, y_batch in test_loader:\r\n        preds = model(x_batch)\r\n        y_pred_list.append(preds.mean)\r\n        y_true_list.append(y_batch)\r\n\r\ny_pred = torch.cat(y_pred_list, dim=0).numpy()\r\ny_true = torch.cat(y_true_list, dim=0).numpy()\r\n\r\ntest_mse = mean_squared_error(y_true, y_pred)\r\nprint(test_mse)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n0.010551954\r\n0.23515734   # or 0.5873753 or 0.40703666, unpredictable\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThe performance of a saved model is expected to be consistent after loading from the saved file. However, whether instantiate it from class seems to affect the performance a lot. \r\n\r\nIn the snippet, the interesting part is \r\n\r\n```python\r\ninducing_points = train_x[:500, :]\r\nmodel = GPModel(inducing_points=inducing_points)\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n```\r\nIf I uncomment it, i.e., I instantiate a new model and load the weights to it, the performance is always consistent. The test MSE of the trained model and saved model is almost very close to each other. \r\nHowever, if I don't instantiate a new model, but rather load the weights to an existing trained model, the performance is unpredictable. \r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version: 1.2.0\r\n- PyTorch Version: 1.6.0 \r\n- Debian 10\r\n\r\n## Additional context\r\nI came across the bug when I saved the model to disk based on some validation score and reload it after the whole training and test it on a test set in the same script. The reloading was done to an existing trained model, rather than a newly instantiated model. When I start a new script, instantiate a new model, load the saved weights to double-check the test performance, the number turns out to be different. \r\n\r\nI also tested the same thing on ExactGP, which doesn't have such a problem. I am not sure whether such behavior is expected by the library itself. Pure PyTorch modules don't seem to have such behavior. ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1308/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1308/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1305", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1305/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1305/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1305/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1305", "id": 719321296, "node_id": "MDU6SXNzdWU3MTkzMjEyOTY=", "number": 1305, "title": "[Bug] Cast constraints to floating point", "user": {"login": "npbaskerville", "id": 37937341, "node_id": "MDQ6VXNlcjM3OTM3MzQx", "avatar_url": "https://avatars.githubusercontent.com/u/37937341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/npbaskerville", "html_url": "https://github.com/npbaskerville", "followers_url": "https://api.github.com/users/npbaskerville/followers", "following_url": "https://api.github.com/users/npbaskerville/following{/other_user}", "gists_url": "https://api.github.com/users/npbaskerville/gists{/gist_id}", "starred_url": "https://api.github.com/users/npbaskerville/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/npbaskerville/subscriptions", "organizations_url": "https://api.github.com/users/npbaskerville/orgs", "repos_url": "https://api.github.com/users/npbaskerville/repos", "events_url": "https://api.github.com/users/npbaskerville/events{/privacy}", "received_events_url": "https://api.github.com/users/npbaskerville/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-10-12T11:57:35Z", "updated_at": "2020-10-26T13:46:00Z", "closed_at": "2020-10-26T13:46:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nUsing integers to construct constraints throws an overflow exception.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport torch\r\nfrom gpytorch.constraints import Interval\r\nfrom gpytorch.distributions import MultivariateNormal\r\nfrom gpytorch.kernels import RBFKernel\r\nfrom gpytorch.likelihoods import GaussianLikelihood\r\nfrom gpytorch.means import ConstantMean\r\nfrom gpytorch.mlls import ExactMarginalLogLikelihood\r\nfrom gpytorch.models import ExactGP\r\n\r\nX = torch.randn(100, 2)\r\ny = torch.randn(100)\r\n\r\n\r\nclass GP(ExactGP):\r\n    def __init__(self, X, y, likelihood, ls_constraint):\r\n        super().__init__(X, y, likelihood)\r\n        self.likelihood = likelihood\r\n        self.mean_module = ConstantMean()\r\n        self.covar_module = RBFKernel(lengthscale_constraint=ls_constraint)\r\n\r\n    def forward(self, x):\r\n        mean = self.mean_module(x)\r\n        covar = self.covar_module(x)\r\n        return MultivariateNormal(mean, covar)\r\n\r\n\r\nlikelihood = GaussianLikelihood()\r\n\r\nls_constraint = Interval(1, 2)\r\n\r\nmodel = GP(X, y, likelihood, ls_constraint)\r\noptim = torch.optim.Adam(model.parameters())\r\nmll = ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nloss = mll(model(X), y)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-1-068518c8dae8> in <module>\r\n     33 mll = ExactMarginalLogLikelihood(likelihood, model)\r\n     34\r\n---> 35 loss = mll(model(X), y)\r\n\r\n~/github/gpytorch/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26\r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/github/gpytorch/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, function_dist, target, *params)\r\n     49         # Get the log prob of the marginal distribution\r\n     50         output = self.likelihood(function_dist, *params)\r\n---> 51         res = output.log_prob(target)\r\n     52\r\n     53         # Add additional terms (SGPR / learned inducing points, heteroskedastic likelihood models)\r\n\r\n~/github/gpytorch/gpytorch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    133\r\n    134         # Get log determininat and first part of quadratic form\r\n--> 135         inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n    136\r\n    137         res = -0.5 * sum([inv_quad, logdet, diff.size(-1) * math.log(2 * math.pi)])\r\n\r\n~/github/gpytorch/gpytorch/lazy/lazy_tensor.py in inv_quad_logdet(self, inv_quad_rhs, logdet, reduce_inv_quad)\r\n   1000             from .chol_lazy_tensor import CholLazyTensor\r\n   1001\r\n-> 1002             cholesky = CholLazyTensor(self.cholesky())\r\n   1003             return cholesky.inv_quad_logdet(inv_quad_rhs=inv_quad_rhs, logdet=logdet, reduce_inv_quad=reduce_inv_quad)\r\n   1004\r\n\r\n~/github/gpytorch/gpytorch/lazy/lazy_tensor.py in cholesky(self, upper)\r\n    737             (LazyTensor) Cholesky factor (lower triangular)\r\n    738         \"\"\"\r\n--> 739         res = self._cholesky()\r\n    740         if upper:\r\n    741             res = res.transpose(-1, -2)\r\n\r\n~/github/gpytorch/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36\r\n\r\n~/github/gpytorch/gpytorch/lazy/lazy_tensor.py in _cholesky(self)\r\n    400         from .keops_lazy_tensor import KeOpsLazyTensor\r\n    401\r\n--> 402         evaluated_kern_mat = self.evaluate_kernel()\r\n    403\r\n    404         if any(isinstance(sub_mat, KeOpsLazyTensor) for sub_mat in evaluated_kern_mat._args):\r\n\r\n~/github/gpytorch/gpytorch/lazy/lazy_tensor.py in evaluate_kernel(self)\r\n    883         all lazily evaluated kernels actually evaluated.\r\n    884         \"\"\"\r\n--> 885         return self.representation_tree()(*self.representation())\r\n    886\r\n    887     def inv_matmul(self, right_tensor, left_tensor=None):\r\n\r\n~/github/gpytorch/gpytorch/lazy/lazy_tensor.py in representation_tree(self)\r\n   1273         including all subobjects. This is used internally.\r\n   1274         \"\"\"\r\n-> 1275         return LazyTensorRepresentationTree(self)\r\n   1276\r\n   1277     @property\r\n\r\n~/github/gpytorch/gpytorch/lazy/lazy_tensor_representation_tree.py in __init__(self, lazy_tsr)\r\n     11         for arg in lazy_tsr._args:\r\n     12             if hasattr(arg, \"representation\") and callable(arg.representation):  # Is it a lazy tensor?\r\n---> 13                 representation_size = len(arg.representation())\r\n     14                 self.children.append((slice(counter, counter + representation_size, None), arg.representation_tree()))\r\n     15                 counter += representation_size\r\n\r\n~/github/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in representation(self)\r\n    311         # representation\r\n    312         else:\r\n--> 313             return self.evaluate_kernel().representation()\r\n    314\r\n    315     def representation_tree(self):\r\n\r\n~/github/gpytorch/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36\r\n\r\n~/github/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)\r\n    278             temp_active_dims = self.kernel.active_dims\r\n    279             self.kernel.active_dims = None\r\n--> 280             res = self.kernel(x1, x2, diag=False, last_dim_is_batch=self.last_dim_is_batch, **self.params)\r\n    281             self.kernel.active_dims = temp_active_dims\r\n    282\r\n\r\n~/github/gpytorch/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, last_dim_is_batch, **params)\r\n    394                 res = LazyEvaluatedKernelTensor(x1_, x2_, kernel=self, last_dim_is_batch=last_dim_is_batch, **params)\r\n    395             else:\r\n--> 396                 res = lazify(super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\r\n    397             return res\r\n    398\r\n\r\n~/github/gpytorch/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26\r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/github/gpytorch/gpytorch/kernels/rbf_kernel.py in forward(self, x1, x2, diag, **params)\r\n     87             x1,\r\n     88             x2,\r\n---> 89             self.lengthscale,\r\n     90             lambda x1, x2: self.covar_dist(\r\n     91                 x1, x2, square_dist=True, diag=False, dist_postprocess_func=postprocess_rbf, postprocess=False, **params\r\n\r\n~/github/gpytorch/gpytorch/kernels/kernel.py in lengthscale(self)\r\n    237     def lengthscale(self):\r\n    238         if self.has_lengthscale:\r\n--> 239             return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\r\n    240         else:\r\n    241             return None\r\n\r\n~/github/gpytorch/gpytorch/constraints/constraints.py in transform(self, tensor)\r\n     92             min_bound = torch.min(self.lower_bound)\r\n     93\r\n---> 94             if max_bound == math.inf or min_bound == -math.inf:\r\n     95                 raise RuntimeError(\r\n     96                     \"Cannot make an Interval directly with non-finite bounds. Use a derived class like \"\r\n\r\n~/anaconda3/lib/python3.7/site-packages/torch/tensor.py in wrapped(*args, **kwargs)\r\n     26     def wrapped(*args, **kwargs):\r\n     27         try:\r\n---> 28             return f(*args, **kwargs)\r\n     29         except TypeError:\r\n     30             return NotImplemented\r\n\r\nRuntimeError: value cannot be converted to type int64_t without overflow: inf\r\n```\r\n\r\n## Expected Behavior\r\n\r\nWhile the bounds in constraints are strictly speaking not ints, it feels unnecessarily picky to error because the user used ```Interval(1, 2)``` rather than ```Interval(1., 2.)```. I've wasted time looking for genuine numerical problems with the inference, when this was in fact the only problem. Could we just silently cast bounds to floats when constraints are initialised?\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version 1.1.1\r\n- PyTorch Version 1.6.0\r\n- OSX Catalina", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1305/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1305/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1300", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1300/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1300/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1300/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1300", "id": 715782846, "node_id": "MDU6SXNzdWU3MTU3ODI4NDY=", "number": 1300, "title": "[Bug] size mismatch when using natural gradient in multi-output GP", "user": {"login": "ZhiliangWu", "id": 18686697, "node_id": "MDQ6VXNlcjE4Njg2Njk3", "avatar_url": "https://avatars.githubusercontent.com/u/18686697?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZhiliangWu", "html_url": "https://github.com/ZhiliangWu", "followers_url": "https://api.github.com/users/ZhiliangWu/followers", "following_url": "https://api.github.com/users/ZhiliangWu/following{/other_user}", "gists_url": "https://api.github.com/users/ZhiliangWu/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZhiliangWu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZhiliangWu/subscriptions", "organizations_url": "https://api.github.com/users/ZhiliangWu/orgs", "repos_url": "https://api.github.com/users/ZhiliangWu/repos", "events_url": "https://api.github.com/users/ZhiliangWu/events{/privacy}", "received_events_url": "https://api.github.com/users/ZhiliangWu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1607679275, "node_id": "MDU6TGFiZWwxNjA3Njc5Mjc1", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/multitask", "name": "multitask", "color": "ffffff", "default": false, "description": "For questions about multitask models"}, {"id": 1607680352, "node_id": "MDU6TGFiZWwxNjA3NjgwMzUy", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/variational", "name": "variational", "color": "ffffff", "default": false, "description": "For questions about variational inference"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-10-06T15:20:53Z", "updated_at": "2021-01-14T19:32:17Z", "closed_at": "2021-01-14T19:32:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nsize mismatch when using natural gradient in multi-output GP\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nimport tqdm\r\nfrom matplotlib import pyplot as plt\r\n\r\ntrain_x = torch.linspace(0, 1, 100)\r\n\r\ntrain_y = torch.stack([\r\n    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n    torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n    torch.sin(train_x * (2 * math.pi)) + 2 * torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n    -torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n], -1)\r\n\r\nprint(train_x.shape, train_y.shape)\r\n\r\nnum_latents = 3\r\nnum_tasks = 4\r\n\r\n\r\nclass IndependentMultitaskGPModel(gpytorch.models.ApproximateGP):\r\n    def __init__(self):\r\n        # Let's use a different set of inducing points for each task\r\n        inducing_points = torch.rand(num_tasks, 16, 1)\r\n\r\n        # We have to mark the CholeskyVariationalDistribution as batch\r\n        # so that we learn a variational distribution for each task\r\n        # variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\r\n        #     inducing_points.size(-2), batch_shape=torch.Size([num_tasks])\r\n        # )\r\n        variational_distribution = gpytorch.variational.NaturalVariationalDistribution(\r\n            inducing_points.size(-2), batch_shape=torch.Size([num_tasks])\r\n        )\r\n\r\n        variational_strategy = gpytorch.variational.IndependentMultitaskVariationalStrategy(\r\n            gpytorch.variational.VariationalStrategy(\r\n                self, inducing_points, variational_distribution, learn_inducing_locations=True\r\n            ),\r\n            num_tasks=4,\r\n        )\r\n\r\n        super().__init__(variational_strategy)\r\n\r\n        # The mean and covariance modules should be marked as batch\r\n        # so we learn a different set of hyperparameters\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([num_tasks]))\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([num_tasks])),\r\n            batch_shape=torch.Size([num_tasks])\r\n        )\r\n\r\n    def forward(self, x):\r\n        # The forward function should be written as if we were dealing with each output\r\n        # dimension in batch\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\n# model = MultitaskGPModel()\r\n\r\nmodel = IndependentMultitaskGPModel()\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=num_tasks)\r\n\r\n# this is for running the notebook in our testing framework\r\nimport os\r\nsmoke_test = ('CI' in os.environ)\r\nnum_epochs = 1 if smoke_test else 500\r\n\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\nngd_optimizer = gpytorch.optim.NGD(model.variational_parameters(),\r\n                                   num_data=train_y.size(0),\r\n                                   lr=0.1)\r\n# We use SGD here, rather than Adam. Emperically, we find that SGD is better for variational regression\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.hyperparameters()},\r\n    {'params': likelihood.parameters()},\r\n], lr=0.1)\r\n\r\n# Our loss object. We're using the VariationalELBO, which essentially just computes the ELBO\r\nmll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\r\n\r\n# We use more CG iterations here because the preconditioner introduced in the NeurIPS paper seems to be less\r\n# effective for VI.\r\nepochs_iter = tqdm.tqdm(range(num_epochs), desc=\"Epoch\")\r\nfor i in epochs_iter:\r\n    # Within each iteration, we will go over each minibatch of data\r\n    ngd_optimizer.zero_grad()\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)\r\n    epochs_iter.set_postfix(loss=loss.item())\r\n    loss.backward()\r\n    ngd_optimizer.step()\r\n    optimizer.step()\r\n\r\n# Set into eval mode\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\n# Initialize plots\r\nfig, axs = plt.subplots(1, num_tasks, figsize=(4 * num_tasks, 3))\r\n\r\n# Make predictions\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    test_x = torch.linspace(0, 1, 51)\r\n    predictions = likelihood(model(test_x))\r\n    mean = predictions.mean\r\n    lower, upper = predictions.confidence_region()\r\n\r\nfor task, ax in enumerate(axs):\r\n    # Plot training data as black stars\r\n    ax.plot(train_x.detach().numpy(), train_y[:, task].detach().numpy(), 'k*')\r\n    # Predictive mean as blue line\r\n    ax.plot(test_x.numpy(), mean[:, task].numpy(), 'b')\r\n    # Shade in confidence\r\n    ax.fill_between(test_x.numpy(), lower[:, task].numpy(), upper[:, task].numpy(), alpha=0.5)\r\n    ax.set_ylim([-3, 3])\r\n    ax.legend(['Observed Data', 'Mean', 'Confidence'])\r\n    ax.set_title(f'Task {task + 1}')\r\n\r\nfig.tight_layout()\r\nplt.show()\r\n```\r\n\r\n** Stack trace/error message **\r\n```bash\r\nTraceback (most recent call last):\r\ntorch.Size([100]) torch.Size([100, 4])\r\nEpoch:   0%|                                            | 0/500 [00:00<?, ?it/s]\r\nTraceback (most recent call last):\r\n  File \"multi-svgp.py\", line 99, in <module>\r\n    output = model(train_x)\r\n  File \"/home/user/miniconda2/envs/torch_play/lib/python3.7/site-packages/gpytorch/models/approximate_gp.py\", line 81, in __call__\r\n    return self.variational_strategy(inputs, prior=prior)\r\n  File \"/home/user/miniconda2/envs/torch_play/lib/python3.7/site-packages/gpytorch/variational/independent_multitask_variational_strategy.py\", line 47, in __call__\r\n    function_dist = self.base_variational_strategy(x, prior=prior)\r\n  File \"/home/user/miniconda2/envs/torch_play/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py\", line 166, in __call__\r\n    return super().__call__(x, prior=prior)\r\n  File \"/home/user/miniconda2/envs/torch_play/lib/python3.7/site-packages/gpytorch/variational/_variational_strategy.py\", line 114, in __call__\r\n    self._variational_distribution.initialize_variational_distribution(prior_dist)\r\n  File \"/home/user/miniconda2/envs/torch_play/lib/python3.7/site-packages/gpytorch/variational/natural_variational_distribution.py\", line 69, in initialize_variational_distribution\r\n    self.natural_vec.data.copy_((prior_prec @ prior_mean).add_(noise))\r\nRuntimeError: size mismatch, m1: [64 x 16], m2: [4 x 16] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41\r\n```\r\n\r\n## Expected Behavior\r\n\r\nGetting similar results as in the [non-natural gradient notebook](https://docs.gpytorch.ai/en/v1.2.0/examples/04_Variational_and_Approximate_GPs/SVGP_Multitask_GP_Regression.html#Train-the-model)\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n-  GPyTorch Version 1.2.0 \r\n- PyTorch Version 1.6.0\r\n-  Debian 10\r\n\r\n## Additional context\r\nI followed the [NGD tutorial](https://docs.gpytorch.ai/en/v1.2.0/examples/04_Variational_and_Approximate_GPs/Natural_Gradient_Descent.html) and replace the necessary code in the multi-output SVGP cases. Seems the problems come to the shape of `prior_prec` and `prior_mean`. \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1300/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1300/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1299", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1299/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1299/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1299/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1299", "id": 714836795, "node_id": "MDExOlB1bGxSZXF1ZXN0NDk3ODUxMTI5", "number": 1299, "title": "Fix bug in fixed-noise preconditioner", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-10-05T13:22:25Z", "updated_at": "2020-10-05T21:28:25Z", "closed_at": "2020-10-05T21:28:22Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1299", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1299", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1299.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1299.patch", "merged_at": "2020-10-05T21:28:21Z"}, "body": "(Also removes an unnecessary test in test/example/test_white_noise_gp.py; hopefully speeds up test suite)\r\n\r\n[Fixes #1298]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1299/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1299/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1298", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1298/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1298/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1298/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1298", "id": 713065758, "node_id": "MDU6SXNzdWU3MTMwNjU3NTg=", "number": 1298, "title": "[Bug]", "user": {"login": "samuelstanton", "id": 22999782, "node_id": "MDQ6VXNlcjIyOTk5Nzgy", "avatar_url": "https://avatars.githubusercontent.com/u/22999782?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samuelstanton", "html_url": "https://github.com/samuelstanton", "followers_url": "https://api.github.com/users/samuelstanton/followers", "following_url": "https://api.github.com/users/samuelstanton/following{/other_user}", "gists_url": "https://api.github.com/users/samuelstanton/gists{/gist_id}", "starred_url": "https://api.github.com/users/samuelstanton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samuelstanton/subscriptions", "organizations_url": "https://api.github.com/users/samuelstanton/orgs", "repos_url": "https://api.github.com/users/samuelstanton/repos", "events_url": "https://api.github.com/users/samuelstanton/events{/privacy}", "received_events_url": "https://api.github.com/users/samuelstanton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-10-01T17:58:48Z", "updated_at": "2020-10-05T21:28:22Z", "closed_at": "2020-10-05T21:28:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nBatched fixed noise GPs fail when the preconditioning threshold is reached. The concatenation in this line fails with a shape error.\r\n\r\nhttps://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/lazy/added_diag_lazy_tensor.py#L126\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\nclass BatchFixedNoiseGP(gpytorch.models.GP):\r\n    def __init__(self, init_x, init_y, noise, batch_shape):\r\n        super().__init__()\r\n        self.mean_module = gpytorch.means.ZeroMean()\r\n        self.covar_module = gpytorch.kernels.RBFKernel(batch_shape=batch_shape)\r\n        self.likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise)\r\n        \r\n    def forward(self, inputs):\r\n        mean = self.mean_module(inputs)\r\n        covar = self.covar_module(inputs)\r\n        return gpytorch.distributions.MultivariateNormal(mean, covar)\r\n\r\nbatch_shape = [2]\r\ntrain_x = torch.randn(*batch_shape, 101, 3)\r\ntrain_y = torch.randn(*batch_shape, 101)\r\ntrain_noise = torch.rand(*batch_shape, 101)\r\n\r\ngp = BatchFixedNoiseGP(train_x, train_y, train_noise, batch_shape)\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(gp.likelihood, gp)\r\n\r\nwith gpytorch.settings.max_cholesky_size(100), gpytorch.settings.min_preconditioning_size(100):\r\n    train_dist = gp(train_x)\r\n    loss = -mll(train_dist, train_y).sum()\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-4-9e151e2de37a> in <module>\r\n     24 with gpytorch.settings.max_cholesky_size(100), gpytorch.settings.min_preconditioning_size(100):\r\n     25     train_dist = gp(train_x)\r\n---> 26     loss = -mll(train_dist, train_y).sum()\r\n\r\n~/Code/gpytorch/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/Code/gpytorch/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, function_dist, target, *params)\r\n     49         # Get the log prob of the marginal distribution\r\n     50         output = self.likelihood(function_dist, *params)\r\n---> 51         res = output.log_prob(target)\r\n     52 \r\n     53         # Add additional terms (SGPR / learned inducing points, heteroskedastic likelihood models)\r\n\r\n~/Code/gpytorch/gpytorch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    138 \r\n    139         # Get log determininat and first part of quadratic form\r\n--> 140         inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n    141 \r\n    142         res = -0.5 * sum([inv_quad, logdet, diff.size(-1) * math.log(2 * math.pi)])\r\n\r\n~/Code/gpytorch/gpytorch/lazy/lazy_tensor.py in inv_quad_logdet(self, inv_quad_rhs, logdet, reduce_inv_quad)\r\n   1069             probe_vectors,\r\n   1070             probe_vector_norms,\r\n-> 1071             *args,\r\n   1072         )\r\n   1073 \r\n\r\n~/Code/gpytorch/gpytorch/functions/_inv_quad_log_det.py in forward(ctx, representation_tree, dtype, device, matrix_shape, batch_shape, inv_quad, logdet, probe_vectors, probe_vector_norms, *args)\r\n     65         lazy_tsr = ctx.representation_tree(*matrix_args)\r\n     66         with torch.no_grad():\r\n---> 67             preconditioner, precond_lt, logdet_correction = lazy_tsr._preconditioner()\r\n     68 \r\n     69         ctx.preconditioner = preconditioner\r\n\r\n~/Code/gpytorch/gpytorch/lazy/added_diag_lazy_tensor.py in _preconditioner(self)\r\n     84                 )\r\n     85                 return None, None, None\r\n---> 86             self._init_cache()\r\n     87 \r\n     88         # NOTE: We cannot memoize this precondition closure as it causes a memory leak\r\n\r\n~/Code/gpytorch/gpytorch/lazy/added_diag_lazy_tensor.py in _init_cache(self)\r\n    107             self._init_cache_for_constant_diag(eye, batch_shape, n, k)\r\n    108         else:\r\n--> 109             self._init_cache_for_non_constant_diag(eye, batch_shape, n)\r\n    110 \r\n    111         self._precond_lt = PsdSumLazyTensor(RootLazyTensor(self._piv_chol_self), self._diag_tensor)\r\n\r\n~/Code/gpytorch/gpytorch/lazy/added_diag_lazy_tensor.py in _init_cache_for_non_constant_diag(self, eye, batch_shape, n)\r\n    125         # With non-constant diagonals, we cant factor out the noise as easily\r\n    126         # eye = eye.expand(*batch_shape, -1, -1)\r\n--> 127         self._q_cache, self._r_cache = torch.qr(torch.cat((self._piv_chol_self / self._noise.sqrt(), eye)))\r\n    128         self._q_cache = self._q_cache[..., :n, :] / self._noise.sqrt()\r\n    129 \r\n\r\nRuntimeError: Tensors must have same number of dimensions: got 3 and 2\r\n```\r\n\r\n## Expected Behavior\r\n\r\nEverything works fine until the preconditioning threshold is reached. Obviously one would hope that it would continue to work.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGPyTorch Version: 1.2.0\r\nPyTorch Version:  '1.6.0.dev20200522'\r\nOS: Ubuntu 16.04 LTS\r\n\r\n## Additional context\r\nThis appears to fix the problem\r\n```\r\n    def _init_cache_for_non_constant_diag(self, eye, batch_shape, n):\r\n        # With non-constant diagonals, we cant factor out the noise as easily\r\n        eye = eye.expand(*batch_shape, -1, -1)\r\n        self._q_cache, self._r_cache = torch.qr(torch.cat((self._piv_chol_self / self._noise.sqrt(), eye), dim=-2))\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1298/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 1, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1298/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1294", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1294/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1294/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1294/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1294", "id": 706713877, "node_id": "MDU6SXNzdWU3MDY3MTM4Nzc=", "number": 1294, "title": "[Bug] Matrix multiplication of rectangular ZeroLazyTensor", "user": {"login": "PFMassiani", "id": 26139531, "node_id": "MDQ6VXNlcjI2MTM5NTMx", "avatar_url": "https://avatars.githubusercontent.com/u/26139531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PFMassiani", "html_url": "https://github.com/PFMassiani", "followers_url": "https://api.github.com/users/PFMassiani/followers", "following_url": "https://api.github.com/users/PFMassiani/following{/other_user}", "gists_url": "https://api.github.com/users/PFMassiani/gists{/gist_id}", "starred_url": "https://api.github.com/users/PFMassiani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PFMassiani/subscriptions", "organizations_url": "https://api.github.com/users/PFMassiani/orgs", "repos_url": "https://api.github.com/users/PFMassiani/repos", "events_url": "https://api.github.com/users/PFMassiani/events{/privacy}", "received_events_url": "https://api.github.com/users/PFMassiani/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-09-22T21:46:55Z", "updated_at": "2021-06-10T00:37:40Z", "closed_at": "2021-06-10T00:37:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThe matrix multiplication of `ZeroLazyTensor` does not allow rectangular tensors, while it is allowed at construction. More specifically, the methods `ZeroLazyTensor.matmul`, `ZeroLazyTensor._matmul` and `ZeroLazyTensor._t_matmul` are the problematic ones.\r\nThere are two problems (batch sizes are omitted):\r\n- when multiplying a `ZeroLazyTensor` of shape `(m, n)` to a LazyTensor or PyTorch tensor of shape `(n, ?)`, the output is _systematically_ of shape `(n, ?)`, whereas it should be of shape `(m, ?)`\r\n- when doing the transpose multiplication (method `_t_matmul`) of a `ZeroLazyTensor` of shape `(m, n)` to a PyTorch tensor of shape `(m, ?)`, the operation _fails_ unless `m == n`: the `ZeroLazyTensor` is not transposed.\r\nThis issue also prevents the concatenation of `ZeroLazyTensor` as described in https://github.com/cornellius-gp/gpytorch/issues/1292.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport traceback\r\nimport torch\r\nfrom gpytorch.lazy import ZeroLazyTensor\r\n\r\ndef check_equality(product, actual):\r\n        if product.shape != actual.shape:\r\n                print(f'Size mismatch: {product.shape} != {actual.shape}')\r\n        elif torch.max((product - actual).abs()) > 1e-4:\r\n                print(f'Value mismatch: {product}\\n!=\\n{actual}')\r\n        else:\r\n                print('Tensors are equal.')\r\n\r\nprint('------- TEST 1')\r\nzero = ZeroLazyTensor(5, 4, 3)\r\nlazy_square = ZeroLazyTensor(5, 3, 3)\r\nactual = torch.zeros(5, 4, 3)\r\nproduct = zero.matmul(lazy_square)\r\ncheck_equality(product.evaluate(), actual)\r\n\r\nprint('------- TEST 2')\r\ntensor_square = torch.eye(3).repeat(5, 1, 1)\r\nproduct = zero._matmul(tensor_square)\r\ncheck_equality(product, actual)\r\n\r\nprint('------- TEST 3')\r\ntensor_square = torch.eye(4).repeat(5, 1, 1)\r\nactual = torch.zeros(5, 3, 4)\r\ntry:\r\n        product = zero._t_matmul(tensor_square)\r\n        check_equality(product, actual)\r\nexcept RuntimeError:\r\n        print(f'Fatal RuntimeError! The ZeroLazyTensor is not transposed before multiplication!')\r\n        traceback.print_exc()\r\n```\r\n\r\nOutput:\r\n```\r\n------- TEST 1\r\nSize mismatch: torch.Size([5, 3, 3]) != torch.Size([5, 4, 3])\r\n------- TEST 2\r\nSize mismatch: torch.Size([5, 3, 3]) != torch.Size([5, 4, 3])\r\n------- TEST 3\r\nFatal RuntimeError! The ZeroLazyTensor is not transposed before multiplication!\r\nTraceback (most recent call last):\r\n  File \"bug_matmul.py\", line 29, in <module>\r\n    product = zero._t_matmul(tensor_square)\r\n  File \"<module>/gpytorch/gpytorch/lazy/zero_lazy_tensor.py\", line 76, in _t_matmul\r\n    raise RuntimeError(\"Size mismatch, self: {}, rhs: {}\".format(self.size(), rhs.size()))\r\nRuntimeError: Size mismatch, self: torch.Size([5, 4, 3]), rhs: torch.Size([5, 4, 4])\r\n```\r\n\r\n## Expected Behavior\r\n\r\nMultiplication of rectangular `ZeroLazyTensor` behaves as usual matrix multiplication, and does not fail when transposing and multiplying.\r\n\r\n## System information\r\n\r\n- GPyTorch version: 1.2.0\r\n- PyTorch version: 1.5.0 (__Note__: a standard installation of version 1.6.0 does not work on my computer (illegal processor instruction), but version 1.5.0 has worked fine for months)\r\n- Ubuntu 16.04\r\n\r\n\r\n## Additional context\r\nSee https://github.com/cornellius-gp/gpytorch/issues/1292.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1294/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1294/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1288", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1288/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1288/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1288/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1288", "id": 702520141, "node_id": "MDU6SXNzdWU3MDI1MjAxNDE=", "number": 1288, "title": "[Bug]Unexpected Error while implementing simpleGP", "user": {"login": "shgaurav1", "id": 10630482, "node_id": "MDQ6VXNlcjEwNjMwNDgy", "avatar_url": "https://avatars.githubusercontent.com/u/10630482?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shgaurav1", "html_url": "https://github.com/shgaurav1", "followers_url": "https://api.github.com/users/shgaurav1/followers", "following_url": "https://api.github.com/users/shgaurav1/following{/other_user}", "gists_url": "https://api.github.com/users/shgaurav1/gists{/gist_id}", "starred_url": "https://api.github.com/users/shgaurav1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shgaurav1/subscriptions", "organizations_url": "https://api.github.com/users/shgaurav1/orgs", "repos_url": "https://api.github.com/users/shgaurav1/repos", "events_url": "https://api.github.com/users/shgaurav1/events{/privacy}", "received_events_url": "https://api.github.com/users/shgaurav1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-09-16T07:16:26Z", "updated_at": "2020-10-14T20:25:19Z", "closed_at": "2020-09-16T17:48:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\ndf = pd.read_csv('train.csv')\r\ndata = torch.Tensor(np.array(df))\r\ntrain_x = data[:, :-1]\r\ntrain_y = data[:, -1]\r\n\r\n# We will use the simplest form of GP model, exact inference\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n    \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n# initialize likelihood and model\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n\r\ntraining_iter = 50# if smoke_test else 50\r\n\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iter):\r\n    # Zero gradients from previous iteration\r\n    optimizer.zero_grad()\r\n    # Output from model\r\n    output = model(train_x)\r\n    # Calc loss and backprop gradients\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\r\n        i + 1, training_iter, loss.item(),\r\n        model.covar_module.base_kernel.lengthscale.item(),\r\n        model.likelihood.noise.item()\r\n    ))\r\n    optimizer.step()```\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"issue.py\", line 46, in <module>\r\n    output = model(train_x)\r\n  File \"/vulcanscratch/gauravsh/myenv/lib/python3.6/site-packages/gpytorch/models/exact_gp.py\", line 265, in __call__\r\n    raise RuntimeError(\"You must train on the training inputs!\")\r\nRuntimeError: You must train on the training inputs!```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nI was expecting for the training to take place seemlessly. However, the error raised here is very unexpected! please find the training file attached here -> [https://drive.google.com/file/d/1LvY9ltLOgGeb71NvwNBXTSC8slXVoMi3/view?usp=sharing](url)\r\nI believe the error might be coming because of the peculiarity of data. If so can you please let me know what's the issue.\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 1.2.0\r\n- <!-- PyTorch Version (run `print(torch.__version__)` -->1.6.0\r\n- <!-- Computer OS -->\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1288/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1288/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1281", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1281/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1281/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1281/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1281", "id": 695996559, "node_id": "MDU6SXNzdWU2OTU5OTY1NTk=", "number": 1281, "title": "[Bug] BlockDiagLT symeig fails when no eigenvectors are desired", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-09-08T16:02:26Z", "updated_at": "2020-09-09T05:48:47Z", "closed_at": "2020-09-09T05:48:47Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nCalling `symeig` on a blockdiagLT fails if you don't want the eigenvectors because the `ZeroLT` shaping in the eigenvectors isn't set up correctly.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nblt = torch.randn(4, 2, 8, 8)\r\nlt = BlockDiagLazyTensor(blt)\r\nlt.symeig()\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-4-16a8470314fa> in <module>\r\n----> 1 lt.symeig()\r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     57         kwargs_pkl = pickle.dumps(kwargs)\r\n     58         if not _is_in_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl):\r\n---> 59             return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)\r\n     60         return _get_from_cache(self, cache_name, *args, kwargs_pkl=kwargs_pkl)\r\n     61 \r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/lazy_tensor.py in symeig(self, eigenvectors)\r\n   1593         except CachingError:\r\n   1594             pass\r\n-> 1595         return self._symeig(eigenvectors=eigenvectors)\r\n   1596 \r\n   1597     def to(self, device_id):\r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/block_diag_lazy_tensor.py in _symeig(self, eigenvectors)\r\n    130         # Doesn't make much sense to sort here, o/w we lose the structure\r\n    131         evals = evals.reshape(*evals.shape[:-2], evals.shape[-2:].numel())\r\n--> 132         evecs = self.__class__(evecs)  # can assume that block_dim is -3 here\r\n    133         return evals, evecs\r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/block_lazy_tensor.py in __init__(self, base_lazy_tensor, block_dim)\r\n     33             raise RuntimeError(\r\n     34                 \"base_lazy_tensor must be a batch matrix (i.e. at least 3 dimensions - got \"\r\n---> 35                 \"{}\".format(base_lazy_tensor.dim())\r\n     36             )\r\n     37 \r\n\r\nRuntimeError: base_lazy_tensor must be a batch matrix (i.e. at least 3 dimensions - got 1\r\n```\r\n\r\n## Expected Behavior\r\n\r\nNo error.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\ngpytorch master\r\n\r\n## Additional context\r\nThere's some other funkiness with symeig stuff but that's not necessarily this issue. I'll try to put up a PR fixing this later today, but it's low priority since there's probably no easy way to create this error.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1281/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1281/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1266", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1266/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1266/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1266/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1266", "id": 685960183, "node_id": "MDU6SXNzdWU2ODU5NjAxODM=", "number": 1266, "title": "[Bug] Typo in doc - Matern Kernel", "user": {"login": "dhruvbalwada", "id": 18236610, "node_id": "MDQ6VXNlcjE4MjM2NjEw", "avatar_url": "https://avatars.githubusercontent.com/u/18236610?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dhruvbalwada", "html_url": "https://github.com/dhruvbalwada", "followers_url": "https://api.github.com/users/dhruvbalwada/followers", "following_url": "https://api.github.com/users/dhruvbalwada/following{/other_user}", "gists_url": "https://api.github.com/users/dhruvbalwada/gists{/gist_id}", "starred_url": "https://api.github.com/users/dhruvbalwada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dhruvbalwada/subscriptions", "organizations_url": "https://api.github.com/users/dhruvbalwada/orgs", "repos_url": "https://api.github.com/users/dhruvbalwada/repos", "events_url": "https://api.github.com/users/dhruvbalwada/events{/privacy}", "received_events_url": "https://api.github.com/users/dhruvbalwada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-26T02:41:57Z", "updated_at": "2020-09-13T20:16:17Z", "closed_at": "2020-09-13T20:16:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nShould the documentation here https://docs.gpytorch.ai/en/v1.1.1/kernels.html#maternkernel have $ \\Theta^{-2}$ in the definition of `d` like the other kernels (example RBF)? \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1266/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1266/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1263", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1263/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1263/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1263/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1263", "id": 684569426, "node_id": "MDU6SXNzdWU2ODQ1Njk0MjY=", "number": 1263, "title": "[Bug] GPytorch conda mirror at capacity", "user": {"login": "y0ast", "id": 485778, "node_id": "MDQ6VXNlcjQ4NTc3OA==", "avatar_url": "https://avatars.githubusercontent.com/u/485778?v=4", "gravatar_id": "", "url": "https://api.github.com/users/y0ast", "html_url": "https://github.com/y0ast", "followers_url": "https://api.github.com/users/y0ast/followers", "following_url": "https://api.github.com/users/y0ast/following{/other_user}", "gists_url": "https://api.github.com/users/y0ast/gists{/gist_id}", "starred_url": "https://api.github.com/users/y0ast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/y0ast/subscriptions", "organizations_url": "https://api.github.com/users/y0ast/orgs", "repos_url": "https://api.github.com/users/y0ast/repos", "events_url": "https://api.github.com/users/y0ast/events{/privacy}", "received_events_url": "https://api.github.com/users/y0ast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-24T10:52:53Z", "updated_at": "2020-08-24T17:11:54Z", "closed_at": "2020-08-24T17:02:05Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nInstalling gpytorch via conda gives an at capacity error. This happens for all installs right now for me.\r\n\r\n## To reproduce\r\n\r\nInstall gpytorch using conda, observe the following message:\r\n\r\n```\r\n  CondaHTTPError: HTTP 503 SERVICE UNAVAILABLE: BACK-END SERVER IS AT CAPACITY for url <https://conda.anaconda.org/gpytorch/linux-64/repodata.json>\r\n  Elapsed: 00:00.517339\r\n  CF-RAY: 5c7c7936886206e5-LHR\r\n\r\n  A remote server error occurred when trying to retrieve this URL.\r\n\r\n  A 500-type error (e.g. 500, 501, 502, 503, etc.) indicates the server failed to\r\n  fulfill a valid request.  The problem may be spurious, and will resolve itself if you\r\n  try your request again.  If the problem persists, consider notifying the maintainer\r\n  of the remote server.\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nInstall normally.\r\n\r\n## System information\r\n\r\nGPytorch 1.1.1, Ubuntu 16.04, Conda 4.8 \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1263/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1263/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1254", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1254/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1254/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1254/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1254", "id": 681277768, "node_id": "MDU6SXNzdWU2ODEyNzc3Njg=", "number": 1254, "title": "[Bug]", "user": {"login": "dialuser", "id": 34311441, "node_id": "MDQ6VXNlcjM0MzExNDQx", "avatar_url": "https://avatars.githubusercontent.com/u/34311441?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dialuser", "html_url": "https://github.com/dialuser", "followers_url": "https://api.github.com/users/dialuser/followers", "following_url": "https://api.github.com/users/dialuser/following{/other_user}", "gists_url": "https://api.github.com/users/dialuser/gists{/gist_id}", "starred_url": "https://api.github.com/users/dialuser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dialuser/subscriptions", "organizations_url": "https://api.github.com/users/dialuser/orgs", "repos_url": "https://api.github.com/users/dialuser/repos", "events_url": "https://api.github.com/users/dialuser/events{/privacy}", "received_events_url": "https://api.github.com/users/dialuser/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-18T19:26:42Z", "updated_at": "2020-08-18T20:23:09Z", "closed_at": "2020-08-18T20:23:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nTensor object has no attribute 'ndim'\r\n## To reproduce\r\nRun the multioutput example, from https://docs.gpytorch.ai/en/latest/examples/03_Multitask_Exact_GPs/Multitask_GP_Regression.html\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n# Your code goes here\r\n# Please make sure it does not require any external dependencies (other than PyTorch!)\r\n# (We much prefer small snippets rather than links to existing libraries!)\r\n```\r\n\r\n** Stack trace/error message **\r\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\", line 107, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 93, in backward\r\n    allow_unreachable=True)  # allow_unreachable flag\r\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/function.py\", line 77, in apply\r\n    return self._forward_cls.backward(self, *args)\r\n  File \"/opt/anaconda3/lib/python3.7/site-packages/gpytorch/functions/_matmul.py\", line 46, in backward\r\n    arg_grads = ctx.representation_tree(*matrix_args)._quad_form_derivative(grad_output_matrix, rhs)\r\n  File \"/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/block_lazy_tensor.py\", line 114, in _quad_form_derivative\r\n    if left_vecs.ndim == 1:\r\nAttributeError: 'Tensor' object has no attribute 'ndim'\r\n\r\n// Paste the bad output here!\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` -->\r\n- <!-- PyTorch Version (run `print(torch.__version__)` -->\r\n- <!-- Computer OS -->\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1254/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1254/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1248", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1248/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1248/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1248/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1248", "id": 677103684, "node_id": "MDU6SXNzdWU2NzcxMDM2ODQ=", "number": 1248, "title": "SVDKL on CIFAR-10/100 Example [Bug]", "user": {"login": "akern40", "id": 24760729, "node_id": "MDQ6VXNlcjI0NzYwNzI5", "avatar_url": "https://avatars.githubusercontent.com/u/24760729?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akern40", "html_url": "https://github.com/akern40", "followers_url": "https://api.github.com/users/akern40/followers", "following_url": "https://api.github.com/users/akern40/following{/other_user}", "gists_url": "https://api.github.com/users/akern40/gists{/gist_id}", "starred_url": "https://api.github.com/users/akern40/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akern40/subscriptions", "organizations_url": "https://api.github.com/users/akern40/orgs", "repos_url": "https://api.github.com/users/akern40/repos", "events_url": "https://api.github.com/users/akern40/events{/privacy}", "received_events_url": "https://api.github.com/users/akern40/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-11T18:35:42Z", "updated_at": "2020-08-20T13:49:03Z", "closed_at": "2020-08-20T13:11:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI'm trying to use the [SVDKL example](https://docs.gpytorch.ai/en/v1.1.1/examples/06_PyTorch_NN_Integration_DKL/Deep_Kernel_Learning_DenseNet_CIFAR_Tutorial.html) on gpytorch v1.1.1, however I'm running into a number of issues.\r\n\r\n1. I'm not sure what `from densenet import DenseNet` is from - I don't know of a PyTorch-compatible package called `densenet`. The code seems to align with the `DenseNet` from `torchvision.models`, although making that change brings its own issues.\r\n2. When training, during the forward pass, I get `RuntimeError: Shapes are not broadcastable for mul operation`. This is the most puzzling part, and I'm really not sure what's happening - it seems that, while calculating the predictive mean in the grid interpolation variational strategy, the shapes can't be broadcasted together.\r\n\r\n## To reproduce\r\n\r\nRun the [SVDKL example](https://docs.gpytorch.ai/en/v1.1.1/examples/06_PyTorch_NN_Integration_DKL/Deep_Kernel_Learning_DenseNet_CIFAR_Tutorial.html)\r\n\r\n## Stack trace/error message\r\n```python\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-9-f33484a0f2d7> in <module>\r\n      1 for epoch in range(1, n_epochs + 1):\r\n      2     with gpytorch.settings.use_toeplitz(False):\r\n----> 3         train(epoch)\r\n      4         test()\r\n      5     scheduler.step()\r\n\r\n<ipython-input-8-bc9a57700a55> in train(epoch)\r\n     21                 data, target = data.cuda(), target.cuda()\r\n     22             optimizer.zero_grad()\r\n---> 23             output = model(data)\r\n     24             loss = -mll(output, target)\r\n     25             loss.backward()\r\n\r\n~/.conda/envs/gpytorch/lib/python3.6/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n<ipython-input-7-48adb3fc1e18> in forward(self, x)\r\n     12         # This next line makes it so that we learn a GP for each feature\r\n     13         features = features.transpose(-1, -2).unsqueeze(-1)\r\n---> 14         res = self.gp_layer(features)\r\n     15         return res\r\n     16 \r\n\r\n~/.conda/envs/gpytorch/lib/python3.6/site-packages/gpytorch/models/approximate_gp.py in __call__(self, inputs, prior, **kwargs)\r\n     79         if inputs.dim() == 1:\r\n     80             inputs = inputs.unsqueeze(-1)\r\n---> 81         return self.variational_strategy(inputs, prior=prior)\r\n\r\n~/.conda/envs/gpytorch/lib/python3.6/site-packages/gpytorch/variational/multitask_variational_strategy.py in __call__(self, x, prior)\r\n     41 \r\n     42     def __call__(self, x, prior=False):\r\n---> 43         function_dist = self.base_variational_strategy(x, prior=prior)\r\n     44         if (\r\n     45             self.task_dim > 0\r\n\r\n~/.conda/envs/gpytorch/lib/python3.6/site-packages/gpytorch/variational/_variational_strategy.py in __call__(self, x, prior)\r\n    125                 inducing_points,\r\n    126                 inducing_values=variational_dist_u.mean,\r\n--> 127                 variational_inducing_covar=variational_dist_u.lazy_covariance_matrix,\r\n    128             )\r\n    129         elif isinstance(variational_dist_u, Delta):\r\n\r\n~/.conda/envs/gpytorch/lib/python3.6/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/.conda/envs/gpytorch/lib/python3.6/site-packages/gpytorch/variational/grid_interpolation_variational_strategy.py in forward(self, x, inducing_points, inducing_values, variational_inducing_covar)\r\n     91         # Compute test mean\r\n     92         # Left multiply samples by interpolation matrix\r\n---> 93         predictive_mean = left_interp(interp_indices, interp_values, inducing_values.unsqueeze(-1))\r\n     94         predictive_mean = predictive_mean.squeeze(-1)\r\n     95 \r\n\r\n~/.conda/envs/gpytorch/lib/python3.6/site-packages/gpytorch/utils/interpolation.py in left_interp(interp_indices, interp_values, rhs)\r\n    181         num_data, num_columns = rhs.shape[-2:]\r\n    182         interp_shape = torch.Size((*interp_indices.shape[:-1], num_data))\r\n--> 183         output_shape = _matmul_broadcast_shape(interp_shape, rhs.shape)\r\n    184         batch_shape = output_shape[:-2]\r\n    185 \r\n\r\n~/.conda/envs/gpytorch/lib/python3.6/site-packages/gpytorch/utils/broadcasting.py in _matmul_broadcast_shape(shape_a, shape_b, error_msg)\r\n     55         bc_shape = batch_shape_a\r\n     56     else:\r\n---> 57         bc_shape = _mul_broadcast_shape(batch_shape_a, batch_shape_b)\r\n     58     return bc_shape + tail_shape\r\n     59 \r\n\r\n~/.conda/envs/gpytorch/lib/python3.6/site-packages/gpytorch/utils/broadcasting.py in _mul_broadcast_shape(error_msg, *shapes)\r\n     18             if any(size != non_singleton_sizes[0] for size in non_singleton_sizes):\r\n     19                 if error_msg is None:\r\n---> 20                     raise RuntimeError(\"Shapes are not broadcastable for mul operation\")\r\n     21                 else:\r\n     22                     raise RuntimeError(error_msg)\r\n\r\nRuntimeError: Shapes are not broadcastable for mul operation\r\n```\r\n\r\n## Expected Behavior\r\n\r\nAs in the example online, I expect the model to run the forward and backward passes without issue.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version 1.1.1\r\n- PyTorch Version 1.5.0\r\n- Linux\r\n\r\n## Additional context\r\nI found Issues #1153 and #1084, but can't make heads or tails of how those issues apply to this example. Any help would be greatly appreciated!", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1248/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1248/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1246", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1246/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1246/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1246/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1246", "id": 676324001, "node_id": "MDU6SXNzdWU2NzYzMjQwMDE=", "number": 1246, "title": "[Bug] Possible bug in variational strategy", "user": {"login": "ptonner", "id": 1526006, "node_id": "MDQ6VXNlcjE1MjYwMDY=", "avatar_url": "https://avatars.githubusercontent.com/u/1526006?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ptonner", "html_url": "https://github.com/ptonner", "followers_url": "https://api.github.com/users/ptonner/followers", "following_url": "https://api.github.com/users/ptonner/following{/other_user}", "gists_url": "https://api.github.com/users/ptonner/gists{/gist_id}", "starred_url": "https://api.github.com/users/ptonner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ptonner/subscriptions", "organizations_url": "https://api.github.com/users/ptonner/orgs", "repos_url": "https://api.github.com/users/ptonner/repos", "events_url": "https://api.github.com/users/ptonner/events{/privacy}", "received_events_url": "https://api.github.com/users/ptonner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-08-10T18:16:37Z", "updated_at": "2020-09-23T22:32:22Z", "closed_at": "2020-08-10T18:23:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\nI'm reviewing the Variational Strategy code and there may be a                                                                                   \r\nbug in how the predictive mean is calculated. Alternatively                                                                                      \r\n(and more likely) I am not understanding the logic.                                                                                              \r\n                                                                                                                                                 \r\nConern starts [here](https://github.com/cornellius-gp/gpytorch/blob/7d43e26851a5390bcd821ccead16dfd22e64f714/gpytorch/variational/variational_strategy.py#L99):\r\n\r\n        L = self._cholesky_factor(induc_induc_covar)\r\n        if L.shape != induc_induc_covar.shape:\r\n            # Aggressive caching can cause nasty shape incompatibilies when evaluating with different batch shapes\r\n            # TODO: Use a hook fo this\r\n            pop_from_cache(self, \"cholesky_factor\")\r\n            L = self._cholesky_factor(induc_induc_covar)\r\n        interp_term = L.inv_matmul(induc_data_covar.double()).to(full_inputs.dtype)\r\n\r\n        # Compute the mean of q(f)\r\n        # k_XZ K_ZZ^{-1/2} (m - K_ZZ^{-1/2} \\mu_Z) + \\mu_X\r\n        predictive_mean = (\r\n            torch.matmul(\r\n                interp_term.transpose(-1, -2), (inducing_values - self.prior_distribution.mean).unsqueeze(-1)\r\n            ).squeeze(-1)\r\n            + test_mean\r\n        )                                                                                               \r\n                                                                                                                                                 \r\nTrying to maintain notation with the documentation provided,                                                                                     \r\nI believe we want to calculate: K_{XZ}K_{ZZ}^{-1}(u - \\mu_u) =                                                                                             \r\nK_{XZ}L_{ZZ}^{-T}L_{ZZ}^{-1}(u - \\mu_u)                                                                                                          \r\n                                                                                                                                                 \r\nFrom my understanding, the `interp_term` is giving us                                                                                            \r\nK_{XZ}L_{ZZ}^{-T} and I think we're missing a second                                                                                             \r\nL_{ZZ}^{-1} term.                                                                                                                                \r\n                                                                                                                                                 \r\nApologies if I'm just missing something or got my equations                                                                                      \r\nwrong!                                                                                                                                           ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1246/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1246/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1244", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1244/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1244/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1244/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1244", "id": 675588208, "node_id": "MDU6SXNzdWU2NzU1ODgyMDg=", "number": 1244, "title": "[Bug] AttributeError on import", "user": {"login": "fonnesbeck", "id": 81476, "node_id": "MDQ6VXNlcjgxNDc2", "avatar_url": "https://avatars.githubusercontent.com/u/81476?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fonnesbeck", "html_url": "https://github.com/fonnesbeck", "followers_url": "https://api.github.com/users/fonnesbeck/followers", "following_url": "https://api.github.com/users/fonnesbeck/following{/other_user}", "gists_url": "https://api.github.com/users/fonnesbeck/gists{/gist_id}", "starred_url": "https://api.github.com/users/fonnesbeck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fonnesbeck/subscriptions", "organizations_url": "https://api.github.com/users/fonnesbeck/orgs", "repos_url": "https://api.github.com/users/fonnesbeck/repos", "events_url": "https://api.github.com/users/fonnesbeck/events{/privacy}", "received_events_url": "https://api.github.com/users/fonnesbeck/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-08-08T21:04:09Z", "updated_at": "2020-08-19T16:22:03Z", "closed_at": "2020-08-19T16:22:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've installed the latest release of GPyTorch on AWS, via pip. However, when I try to import `gpytorch`, I get an AttributeError having to do with the poutine submodule:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-1-8b7747befa0d> in <module>\r\n----> 1 import gpytorch\r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/__init__.py in <module>\r\n      1 #!/usr/bin/env python3\r\n----> 2 from . import (\r\n      3     beta_features,\r\n      4     distributions,\r\n      5     kernels,\r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/distributions/__init__.py in <module>\r\n      9 try:\r\n     10     # If pyro is installed, use that set of base distributions\r\n---> 11     import pyro.distributions as base_distributions\r\n     12 except ImportError:\r\n     13     # Otherwise, use PyTorch\r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pyro/__init__.py in <module>\r\n      2 # SPDX-License-Identifier: Apache-2.0\r\n      3 \r\n----> 4 import pyro.poutine as poutine\r\n      5 from pyro.logger import log\r\n      6 from pyro.poutine import condition, do, markov\r\n\r\nAttributeError: module 'pyro' has no attribute 'poutine'\r\n```\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version: 1.1.1\r\n- PyTorch Version: 1.6.0\r\n- Computer OS: AWS (Linux)\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1244/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1244/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1238", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1238/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1238/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1238/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1238", "id": 672897551, "node_id": "MDExOlB1bGxSZXF1ZXN0NDYyODU0MTM2", "number": 1238, "title": "Some small fixes to the low-level Pyro interface", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-04T15:51:05Z", "updated_at": "2020-08-04T19:12:24Z", "closed_at": "2020-08-04T19:12:20Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1238", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1238", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1238.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1238.patch", "merged_at": "2020-08-04T19:12:20Z"}, "body": "- [x] Use `name_prefix` instead of (leftover) `self.name_prefix`\r\n- [x] Remove batch dimensions from sample calls to inducing distribution\r\n- [x] Don't divide the prior priobability by num_data (Pyro doesn't divide any of the losses)\r\n- [x] Fix Cox process example to draw inducing samples outside of batched plate context\r\n\r\ncc/ @jacobrgardner @martinjankowiak ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1238/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1238/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1230", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1230/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1230/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1230/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1230", "id": 668308657, "node_id": "MDU6SXNzdWU2NjgzMDg2NTc=", "number": 1230, "title": "[Bug] Is it WhiteNoiseKernel deprecated?", "user": {"login": "josuelandinez", "id": 10901060, "node_id": "MDQ6VXNlcjEwOTAxMDYw", "avatar_url": "https://avatars.githubusercontent.com/u/10901060?v=4", "gravatar_id": "", "url": "https://api.github.com/users/josuelandinez", "html_url": "https://github.com/josuelandinez", "followers_url": "https://api.github.com/users/josuelandinez/followers", "following_url": "https://api.github.com/users/josuelandinez/following{/other_user}", "gists_url": "https://api.github.com/users/josuelandinez/gists{/gist_id}", "starred_url": "https://api.github.com/users/josuelandinez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/josuelandinez/subscriptions", "organizations_url": "https://api.github.com/users/josuelandinez/orgs", "repos_url": "https://api.github.com/users/josuelandinez/repos", "events_url": "https://api.github.com/users/josuelandinez/events{/privacy}", "received_events_url": "https://api.github.com/users/josuelandinez/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-30T02:28:11Z", "updated_at": "2020-07-30T02:45:20Z", "closed_at": "2020-07-30T02:45:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, \r\n\r\nI tried to use the WhiteKernelNoise:\r\n\r\na=gpytorch.kernels.WhiteNoiseKernel()\r\n\r\nand get: \r\n--------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-10-93041d9c7d0a> in <module>\r\n----> 1 a=gpytorch.kernels.WhiteNoiseKernel()\r\n\r\nAttributeError: module 'gpytorch.kernels' has no attribute 'WhiteNoiseKernel'\r\n\r\nI looked to several threads, seems it was implemented but seems is not anymore that is correct?, is there any hint or solution to implement it?. The reason to use this kernel my data have noise and also  it keeps stable the Cholesky decomposition while optimizing for several combinations of kernels like RBF, Mattern, Linear, etc using LBFGS. I already tested in the same data and kernels in sklearn and seems to work. However, I started to use gpytorch because I can get faster optimization. I already tested softmax transofrmations with another L-BSGF optimizer suggested in another gpytorch thread, however still the problem happens. I appreciated any insisght you can provide. \r\n\r\nbest regards, \r\n\r\nEdgar \r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1230/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1230/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1209", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1209/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1209/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1209/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1209", "id": 654980077, "node_id": "MDU6SXNzdWU2NTQ5ODAwNzc=", "number": 1209, "title": "[Bug] Inducing point kernel does not work with grad kernel", "user": {"login": "YuuuXie", "id": 24205323, "node_id": "MDQ6VXNlcjI0MjA1MzIz", "avatar_url": "https://avatars.githubusercontent.com/u/24205323?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YuuuXie", "html_url": "https://github.com/YuuuXie", "followers_url": "https://api.github.com/users/YuuuXie/followers", "following_url": "https://api.github.com/users/YuuuXie/following{/other_user}", "gists_url": "https://api.github.com/users/YuuuXie/gists{/gist_id}", "starred_url": "https://api.github.com/users/YuuuXie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YuuuXie/subscriptions", "organizations_url": "https://api.github.com/users/YuuuXie/orgs", "repos_url": "https://api.github.com/users/YuuuXie/repos", "events_url": "https://api.github.com/users/YuuuXie/events{/privacy}", "received_events_url": "https://api.github.com/users/YuuuXie/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-10T19:05:50Z", "updated_at": "2022-02-28T12:09:53Z", "closed_at": "2020-07-23T12:54:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nWhen I tried to combine the [Sparse GP](https://docs.gpytorch.ai/en/v1.1.1/examples/02_Scalable_Exact_GPs/SGPR_Regression_CUDA.html) or [Variational GP with multiple outputs](https://docs.gpytorch.ai/en/v1.1.1/examples/04_Variational_and_Approximate_GPs/SVGP_Multitask_GP_Regression.html) with the [2D derivative example](https://docs.gpytorch.ai/en/latest/examples/08_Advanced_Usage/Simple_GP_Regression_Derivative_Information_2d.html), I got dimension mismatch issues. It seems to me that the SGPR does not really work for multitask, and though the SVGP works for multitask, it only accepts covariance matrix which has the same size as the input. \r\n\r\nFor example, for the gradient kernel, the covariance matrix has shape n(d+1) x n(d+1), while in the inducing kernel, e.g. `gpytorch/variational/variational_strategy.py` forward function (line 87-135), it seems that only the shape n x n is allowed?\r\n\r\n## To reproduce\r\n\r\nI tried this in the [2D derivative example](https://docs.gpytorch.ai/en/latest/examples/08_Advanced_Usage/Simple_GP_Regression_Derivative_Information_2d.html)\r\n\r\n```python\r\n 41 class MultitaskGPModel(gpytorch.models.ApproximateGP):\r\n 42     def __init__(self):\r\n 43         # Let's use a different set of inducing points for each task\r\n 44         inducing_points = torch.rand(num_tasks, 16, 2)\r\n 45 \r\n 46         # We have to mark the CholeskyVariationalDistribution as batch\r\n 47         # so that we learn a variational distribution for each task\r\n 48         variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\r\n 49             inducing_points.size(-2), batch_shape=torch.Size([num_tasks])\r\n 50         )\r\n 51 \r\n 52         variational_strategy = gpytorch.variational.IndependentMultitaskVariationalStrategy(\r\n 53             gpytorch.variational.VariationalStrategy(\r\n 54                 self, inducing_points, variational_distribution, learn_inducing_locations=True\r\n 55             ),\r\n 56             num_tasks=num_tasks,\r\n 57         )\r\n 58 \r\n 59         super().__init__(variational_strategy)\r\n 60 \r\n 61         # The mean and covariance modules should be marked as batch\r\n 62         # so we learn a different set of hyperparameters\r\n 63         self.mean_module = gpytorch.means.ConstantMeanGrad(batch_shape=torch.Size([num_tasks]))\r\n 64         self.covar_module = gpytorch.kernels.ScaleKernel(\r\n 65             gpytorch.kernels.RBFKernelGrad(ard_num_dims=2, batch_shape=torch.Size([num_tasks])),\r\n 66 #             gpytorch.kernels.RBFKernel(batch_shape=torch.Size([num_tasks])),\r\n 67             batch_shape=torch.Size([num_tasks])\r\n 68         )\r\n 69 \r\n 70 \r\n 71     def forward(self, x):\r\n 72         mean_x = self.mean_module(x)\r\n 73         covar_x = self.covar_module(x)\r\n 74         print('forward x', x.shape, mean_x.shape, covar_x.shape)\r\n 75         return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\r\n 76 \r\n 77 likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=num_tasks)  # Value + x-derivative + y-derivative\r\n 78 model = MultitaskGPModel()\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"2d_derv.py\", line 114, in <module>\r\n    output = model(train_x)\r\n  File \"/Users/xiey/anaconda3/lib/python3.7/site-packages/gpytorch/models/approximate_gp.py\", line 81, in __call__\r\n    return self.variational_strategy(inputs, prior=prior)\r\n  File \"/Users/xiey/anaconda3/lib/python3.7/site-packages/gpytorch/variational/independent_multitask_variational_strategy.py\", line 47, in __call__\r\n    function_dist = self.base_variational_strategy(x, prior=prior)\r\n  File \"/Users/xiey/anaconda3/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py\", line 181, in __call__\r\n    return super().__call__(x, prior=prior)\r\n  File \"/Users/xiey/anaconda3/lib/python3.7/site-packages/gpytorch/variational/_variational_strategy.py\", line 134, in __call__\r\n    variational_inducing_covar=variational_dist_u.lazy_covariance_matrix,\r\n  File \"/Users/xiey/anaconda3/lib/python3.7/site-packages/gpytorch/module.py\", line 28, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/Users/xiey/anaconda3/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py\", line 116, in forward\r\n    + test_mean\r\nRuntimeError: The size of tensor a (332) must match the size of tensor b (0) at non-singleton dimension 2\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch: 1.1.1\r\n- PyTorch: 1.5.0\r\n- macOS Catalina, 10.15.5\r\n\r\n## Additional context\r\nMaybe this is related to #1063 and #1121 \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1209/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1209/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1204", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1204/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1204/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1204/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1204", "id": 653687880, "node_id": "MDU6SXNzdWU2NTM2ODc4ODA=", "number": 1204, "title": "[Question]error only with Periodic Kernel", "user": {"login": "yucho147", "id": 53713732, "node_id": "MDQ6VXNlcjUzNzEzNzMy", "avatar_url": "https://avatars.githubusercontent.com/u/53713732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yucho147", "html_url": "https://github.com/yucho147", "followers_url": "https://api.github.com/users/yucho147/followers", "following_url": "https://api.github.com/users/yucho147/following{/other_user}", "gists_url": "https://api.github.com/users/yucho147/gists{/gist_id}", "starred_url": "https://api.github.com/users/yucho147/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yucho147/subscriptions", "organizations_url": "https://api.github.com/users/yucho147/orgs", "repos_url": "https://api.github.com/users/yucho147/repos", "events_url": "https://api.github.com/users/yucho147/events{/privacy}", "received_events_url": "https://api.github.com/users/yucho147/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-09T01:06:49Z", "updated_at": "2020-07-10T00:10:43Z", "closed_at": "2020-07-10T00:10:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,  \r\nI am having trouble with the implementation of periodic kernel.  \r\nI'd appreciate your advice.\r\n\r\n## To reproduce\r\n\r\nI create models with only different kernel as follows\r\n```python\r\nfrom gpytorch.distributions import MultivariateNormal\r\nfrom gpytorch.kernels import PeriodicKernel, RBFKernel, ScaleKernel\r\nfrom gpytorch.likelihoods import GaussianLikelihood\r\nfrom gpytorch.means import ConstantMean\r\nfrom gpytorch.mlls import VariationalELBO\r\nfrom gpytorch.models import ApproximateGP\r\nfrom gpytorch.variational import (CholeskyVariationalDistribution,\r\n                                  VariationalStrategy)\r\nfrom torch.utils.data import TensorDataset, DataLoader\r\nimport matplotlib.pyplot as plt\r\nimport torch\r\n\r\n\r\nclass PeriodicModel(ApproximateGP):\r\n    def __init__(self, inducing_points):\r\n        variational_distribution = CholeskyVariationalDistribution(\r\n            inducing_points.size(0)\r\n        )\r\n        variational_strategy = VariationalStrategy(\r\n            self,\r\n            inducing_points,\r\n            variational_distribution,\r\n            learn_inducing_locations=True\r\n        )\r\n        super(PeriodicModel, self).__init__(variational_strategy)\r\n        self.mean_module = ConstantMean()\r\n        self.covar_module = ScaleKernel(\r\n            PeriodicKernel()\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return MultivariateNormal(mean_x, covar_x)\r\n\r\nclass PeriodicRBFModel(ApproximateGP):\r\n    def __init__(self, inducing_points):\r\n        variational_distribution = CholeskyVariationalDistribution(\r\n            inducing_points.size(0)\r\n        )\r\n        variational_strategy = VariationalStrategy(\r\n            self,\r\n            inducing_points,\r\n            variational_distribution,\r\n            learn_inducing_locations=True\r\n        )\r\n        super(PeriodicRBFModel, self).__init__(variational_strategy)\r\n        self.mean_module = ConstantMean()\r\n        self.covar_module = ScaleKernel(\r\n            PeriodicKernel() * RBFKernel()\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return MultivariateNormal(mean_x, covar_x)\r\n\r\nclass RBFModel(ApproximateGP):\r\n    def __init__(self, inducing_points):\r\n        variational_distribution = CholeskyVariationalDistribution(\r\n            inducing_points.size(0)\r\n        )\r\n        variational_strategy = VariationalStrategy(\r\n            self,\r\n            inducing_points,\r\n            variational_distribution,\r\n            learn_inducing_locations=True\r\n        )\r\n        super(RBFModel, self).__init__(variational_strategy)\r\n        self.mean_module = ConstantMean()\r\n        self.covar_module = ScaleKernel(\r\n            RBFKernel()\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return MultivariateNormal(mean_x, covar_x)\r\n```\r\n\r\nI create sample data as follow\r\n```python\r\n# create sample data #######\r\nnum = 1000\r\nepochs = 20\r\nlr = 1e-1\r\nx = torch.arange(num, dtype=torch.float32).reshape(-1, 1).contiguous()\r\ny = torch.sin(torch.arange(num) * 0.05) + torch.randn(num) / 3\r\n\r\ntrain_dataset = TensorDataset(x, y)\r\ntrain_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\r\n\r\nindices = torch.randperm(len(x))[:100]\r\ninducing_points = x[indices]\r\n############################\r\n```\r\n\r\nAnd  I get an error only with using periodic kernel.  \r\nWhy do I get it?\r\n```python\r\n# PeriodicModel ############\r\nmodel = PeriodicModel(inducing_points)\r\nlikelihood = GaussianLikelihood()\r\nmll = VariationalELBO(likelihood, model, y.size(0))\r\noptimizer = torch.optim.Adam(\r\n    [{'params': model.parameters()},\r\n     {'params': likelihood.parameters()}],\r\n    lr=lr)\r\n\r\nfor epoch in range(epochs):\r\n    print(f'epoch : {epoch}')\r\n    model.train()\r\n    likelihood.train()\r\n    for x_batch, y_batch in train_loader:\r\n        optimizer.zero_grad()\r\n        output = model(x_batch)\r\n        loss = - mll(output, y_batch)\r\n        loss.backward()\r\n        optimizer.step()\r\n    print(loss.item())\r\nwith torch.no_grad():y_hat = likelihood(model(x)).mean\r\nplt.plot(x.numpy(), y.numpy())\r\nplt.plot(x.numpy(), y_hat.numpy())\r\nplt.show()\r\n############################\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-2-95272eb92f7b> in <module>\r\n     14     for x_batch, y_batch in train_loader:\r\n     15         optimizer.zero_grad()\r\n---> 16         output = model(x_batch)\r\n     17         loss = - mll(output, y_batch)\r\n     18         loss.backward()\r\n\r\n~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/gpytorch/models/approximate_gp.py in __call__(self, inputs, prior, **kwargs)\r\n     79         if inputs.dim() == 1:\r\n     80             inputs = inputs.unsqueeze(-1)\r\n---> 81         return self.variational_strategy(inputs, prior=prior)\r\n\r\n~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py in __call__(self, x, prior)\r\n    173                 self.updated_strategy.fill_(True)\r\n    174 \r\n--> 175         return super().__call__(x, prior=prior)\r\n\r\n~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/gpytorch/variational/_variational_strategy.py in __call__(self, x, prior)\r\n    125                 inducing_points,\r\n    126                 inducing_values=variational_dist_u.mean,\r\n--> 127                 variational_inducing_covar=variational_dist_u.lazy_covariance_matrix,\r\n    128             )\r\n    129         elif isinstance(variational_dist_u, Delta):\r\n\r\n~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py in forward(self, x, inducing_points, inducing_values, variational_inducing_covar)\r\n     95         # K_ZZ^{-1/2} K_ZX\r\n     96         # K_ZZ^{-1/2} \\mu_Z\r\n---> 97         L = self._cholesky_factor(induc_induc_covar)\r\n     98         if L.shape != induc_induc_covar.shape:\r\n     99             # Aggressive caching can cause nasty shape incompatibilies when evaluating with different batch shapes\r\n\r\n~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36 \r\n\r\n~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py in _cholesky_factor(self, induc_induc_covar)\r\n     68     @cached(name=\"cholesky_factor\")\r\n     69     def _cholesky_factor(self, induc_induc_covar):\r\n---> 70         L = psd_safe_cholesky(delazify(induc_induc_covar).double())\r\n     71         return L\r\n     72 \r\n\r\n~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/gpytorch/utils/cholesky.py in psd_safe_cholesky(A, upper, out, jitter)\r\n     46             except RuntimeError:\r\n     47                 continue\r\n---> 48         raise e\r\n\r\n~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/gpytorch/utils/cholesky.py in psd_safe_cholesky(A, upper, out, jitter)\r\n     23     \"\"\"\r\n     24     try:\r\n---> 25         L = torch.cholesky(A, upper=upper, out=out)\r\n     26         return L\r\n     27     except RuntimeError as e:\r\n\r\nRuntimeError: cholesky_cpu: U(19,19) is zero, singular U.\r\n```\r\n\r\n## Expected Behavior\r\n\r\n- I need to know why the error is occurring.\r\n- Please give me an example of a model using periodic kernel(+scale kernel).\r\n\r\n## System information\r\n\r\n- GPyTorch Version : 1.1.1\r\n- PyTorch Version : 1.5.0\r\n- Computer OS : macOS Catalina 10.15.5\r\n\r\n## Supplement\r\nI don't get an error with other implementations\r\n```python\r\n# PeriodicRBFModel #########\r\nmodel = PeriodicRBFModel(inducing_points)\r\nlikelihood = GaussianLikelihood()\r\nmll = VariationalELBO(likelihood, model, y.size(0))\r\noptimizer = torch.optim.Adam(\r\n    [{'params': model.parameters()},\r\n     {'params': likelihood.parameters()}],\r\n    lr=lr)\r\n\r\nfor epoch in range(epochs):\r\n    print(f'epoch : {epoch}')\r\n    model.train()\r\n    likelihood.train()\r\n    for x_batch, y_batch in train_loader:\r\n        optimizer.zero_grad()\r\n        output = model(x_batch)\r\n        loss = - mll(output, y_batch)\r\n        loss.backward()\r\n        optimizer.step()\r\n    print(loss.item())\r\nwith torch.no_grad():y_hat = likelihood(model(x)).mean\r\nplt.plot(x.numpy(), y.numpy())\r\nplt.plot(x.numpy(), y_hat.numpy())\r\nplt.show()\r\n############################\r\n\r\n# RBFModel #################\r\nmodel = RBFModel(inducing_points)\r\nlikelihood = GaussianLikelihood()\r\nmll = VariationalELBO(likelihood, model, y.size(0))\r\noptimizer = torch.optim.Adam(\r\n    [{'params': model.parameters()},\r\n     {'params': likelihood.parameters()}],\r\n    lr=lr)\r\n\r\nfor epoch in range(epochs):\r\n    print(f'epoch : {epoch}')\r\n    model.train()\r\n    likelihood.train()\r\n    for x_batch, y_batch in train_loader:\r\n        optimizer.zero_grad()\r\n        output = model(x_batch)\r\n        loss = - mll(output, y_batch)\r\n        loss.backward()\r\n        optimizer.step()\r\n    print(loss.item())\r\nwith torch.no_grad():y_hat = likelihood(model(x)).mean\r\nplt.plot(x.numpy(), y.numpy())\r\nplt.plot(x.numpy(), y_hat.numpy())\r\nplt.show()\r\n############################\r\n```\r\n\r\nThe figure below shows the result of executing on PeriodicRBFkernel.\r\n![Figure_1](https://user-images.githubusercontent.com/53713732/86934684-f2153800-c176-11ea-8d21-af4d08ac84a5.png)", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1204/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1204/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1200", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1200/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1200/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1200/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1200", "id": 652391329, "node_id": "MDU6SXNzdWU2NTIzOTEzMjk=", "number": 1200, "title": "[Question]", "user": {"login": "amisaw", "id": 55594380, "node_id": "MDQ6VXNlcjU1NTk0Mzgw", "avatar_url": "https://avatars.githubusercontent.com/u/55594380?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amisaw", "html_url": "https://github.com/amisaw", "followers_url": "https://api.github.com/users/amisaw/followers", "following_url": "https://api.github.com/users/amisaw/following{/other_user}", "gists_url": "https://api.github.com/users/amisaw/gists{/gist_id}", "starred_url": "https://api.github.com/users/amisaw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amisaw/subscriptions", "organizations_url": "https://api.github.com/users/amisaw/orgs", "repos_url": "https://api.github.com/users/amisaw/repos", "events_url": "https://api.github.com/users/amisaw/events{/privacy}", "received_events_url": "https://api.github.com/users/amisaw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2020-07-07T14:54:38Z", "updated_at": "2020-07-07T23:58:51Z", "closed_at": "2020-07-07T23:58:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello - I am new to GPytorch and I trying to implement DKL Regression using a modified version of the example code here https://docs.gpytorch.ai/en/v1.1.1/examples/06_PyTorch_NN_Integration_DKL/KISSGP_Deep_Kernel_Regression_CUDA.html. \r\n\r\nHowever, after I've trained the model on dummy training data and switch to eval() mode and try to predict using test data, I'm finding that the forward method still uses the training data (rather than the test data I'm giving it). Any suggestions as to why this is happening?\r\n\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)           \r\n        self.mean_module = gpytorch.means.ZeroMean()\r\n        length_scale_initial = 20\r\n        signal_var_initial = 10\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n\r\n        # initialize lengthscale and outputscale hyperparams\r\n        self.covar_module.base_kernel.lengthscale = length_scale_initial\r\n        self.covar_module.outputscale = signal_var_initial\r\n      \r\n        # NN feature extractor\r\n        self.embedd_extractor = embedd_extractor \r\n\r\n    def forward(self, x):\r\n        projected_x = self.embedd_extractor.forward_image(x, relu_on_emb=True)        \r\n        mean_x = self.mean_module(projected_x)\r\n        covar_x = self.covar_module(projected_x)        \r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n    \r\ndef train(num_epochs):   \r\n    for epoch in range(num_epochs):    \r\n        optimizer.zero_grad()       \r\n        output = model(train_x)       \r\n        loss = -mll(output, train_y)        \r\n        loss.backward()\r\n        optimizer.step() \r\n\r\nif __name__ == \"__main__\":\r\n    # load NN embedding model from checkpoint - note - code for this is not posted here\r\n    emb_trainer = create_voxel_trainer_with_checkpoint(checkpoint_path, cuda = 1)    \r\n    embedd_extractor = emb_trainer.model\r\n\r\n    train_x = np.zeros((10, 3, 50, 50, 50)) # dummy data for now\r\n    train_x = torch.from_numpy(train_x)\r\n    train_x = train_x.float()\r\n    train_y = torch.from_numpy(np.repeat(2,10)) # dummy data for now\r\n\r\n    # define likelihood function and model\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n    model = GPRegressionModel(train_x, train_y, likelihood) \r\n  \r\n    # train the model    \r\n    model.train()\r\n    likelihood.train()\r\n\r\n    # Use the adam optimizer\r\n    optimizer = torch.optim.Adam([\r\n        {'params': model.embedd_extractor.parameters()},\r\n        {'params': model.covar_module.parameters()},\r\n        {'params': model.mean_module.parameters()},\r\n        {'params': model.likelihood.parameters()},\r\n    ], lr=0.01)\r\n\r\n    # \"Loss\" for GPs - the marginal log likelihood\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\n    # train model\r\n    train(num_epochs = 2)\r\n\r\n    # evaluate model\r\n    test_x =  torch.from_numpy(np.ones((1, 3, 50, 50, 50)))\r\n    test_x = test_x.float()  \r\n\r\n    #evaluate_model(test_x)\r\n    model.eval()\r\n    likelihood.eval()\r\n    print('evaluating model')\r\n    with torch.no_grad(), gpytorch.settings.use_toeplitz(False):  \r\n        preds = model(test_x)\r\n\r\nExpected behavior:\r\nDuring evaluation of the model, when preds = model(test_x) is called, I would expect it to use the trained model to predict with test_x data. But when I step into the forward method of the GPRegressionModel class after this line, it is using the train_x data not the test_x data as expected. I assume there's a bug in my code, but I'm not sure where it's occurring. \r\n\r\nAny help would be much appreciated!\r\n\r\nSystem information:\r\nGPytorch version: 1.1.1\r\nPyTorch version: 1.5.0\r\nUbuntu 16.04\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1200/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1200/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1177", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1177/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1177/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1177/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1177", "id": 637327696, "node_id": "MDU6SXNzdWU2MzczMjc2OTY=", "number": 1177, "title": "Batched Multi-Output GP preconditioner doesn't compute noise model properly[Bug]", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-11T21:23:50Z", "updated_at": "2020-06-11T21:58:00Z", "closed_at": "2020-06-11T21:58:00Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThe noise checking to see if the diagonal is constant in the `init_cache` method for the preconditioner is incorrect for batched GPs. Specifically, [here](https://github.com/cornellius-gp/gpytorch/blob/1e19a641d301218936008f828bfb6e8da081ad3d/gpytorch/lazy/added_diag_lazy_tensor.py#L96) indexes the noise improperly when the noise could be batched.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood, batch_shape=torch.Size([])):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=batch_shape)\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(batch_shape=batch_shape),\r\n                                                        batch_shape=batch_shape)\r\n    \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n## base case that works\r\ntrain_x = torch.randn(301, 1)\r\ntrain_y = torch.sin(3.1 * train_x) + 0.1 * torch.randn_like(train_x)\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = ExactGPModel(train_x, train_y, likelihood) \r\n\r\nwith gpytorch.settings.max_cholesky_size(100), gpytorch.settings.min_preconditioning_size(100):\r\n\r\n    print(likelihood(model(train_x)).log_prob(train_y).sum())\r\n\r\n### This doesn't work\r\n### I'm playing with the settings here to force it to crash but it's a shaping error.\r\ntrain_x = torch.randn(301, 1)\r\ntrain_y = torch.cat((torch.sin(3.1 * train_x) + 0.1 * torch.randn_like(train_x),\r\n                     torch.sin(train_x) + 0.1 * torch.randn_like(train_x)),dim=1)\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood(batch_shape=torch.Size([2]))\r\nmodel = ExactGPModel(train_x, train_y, likelihood, batch_shape=torch.Size([2])) \r\n\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\r\n\r\nfor i in range(3):\r\n    optimizer.zero_grad()\r\n\r\n    with gpytorch.settings.max_cholesky_size(100), gpytorch.settings.min_preconditioning_size(100):\r\n\r\n        loss = -likelihood(model(train_x)).log_prob(train_y.t()).sum()\r\n        loss.backward()\r\n        optimizer.step()\r\n```\r\n\r\n** Stack trace/error message **\r\nThe noise checking is actually incorrect so you see this error message --- note that we got pushed into the `_init_cache_for_non_constant_diag` method for a homoscedastic noise model.\r\n```\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/added_diag_lazy_tensor.py in _init_cache(self)\r\n    100             self._init_cache_for_constant_diag(eye, batch_shape, n, k)\r\n    101         else:\r\n--> 102             self._init_cache_for_non_constant_diag(eye, batch_shape, n)\r\n    103 \r\n    104         self._precond_lt = PsdSumLazyTensor(RootLazyTensor(self._piv_chol_self), self._diag_tensor)\r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/added_diag_lazy_tensor.py in _init_cache_for_non_constant_diag(self, eye, batch_shape, n)\r\n    117     def _init_cache_for_non_constant_diag(self, eye, batch_shape, n):\r\n    118         # With non-constant diagonals, we cant factor out the noise as easily\r\n--> 119         self._q_cache, self._r_cache = torch.qr(torch.cat((self._piv_chol_self / self._noise.sqrt(), eye)))\r\n    120         self._q_cache = self._q_cache[..., :n, :] / self._noise.sqrt()\r\n    121 \r\n\r\nRuntimeError: Tensors must have same number of dimensions: got 3 and 2\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThe noise shaping should be done properly so that `_init_cache_for_constant_diag` gets called instead. It runs properly.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\ngpytorch 1.1.1\r\npytorch 1.5.0\r\n\r\n## Additional context\r\nI'll toss up a PR in a minute. It's not that hard to fix.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1177/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1177/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1176", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1176/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1176/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1176/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1176", "id": 636542350, "node_id": "MDU6SXNzdWU2MzY1NDIzNTA=", "number": 1176, "title": "[Question] ExactGP Regression returns the same value for high dimensional input", "user": {"login": "Godric877", "id": 28264771, "node_id": "MDQ6VXNlcjI4MjY0Nzcx", "avatar_url": "https://avatars.githubusercontent.com/u/28264771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Godric877", "html_url": "https://github.com/Godric877", "followers_url": "https://api.github.com/users/Godric877/followers", "following_url": "https://api.github.com/users/Godric877/following{/other_user}", "gists_url": "https://api.github.com/users/Godric877/gists{/gist_id}", "starred_url": "https://api.github.com/users/Godric877/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Godric877/subscriptions", "organizations_url": "https://api.github.com/users/Godric877/orgs", "repos_url": "https://api.github.com/users/Godric877/repos", "events_url": "https://api.github.com/users/Godric877/events{/privacy}", "received_events_url": "https://api.github.com/users/Godric877/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-06-10T20:53:28Z", "updated_at": "2022-12-13T06:03:36Z", "closed_at": "2020-06-11T00:22:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Question\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nI modified the example at https://gpytorch.readthedocs.io/en/latest/examples/01_Exact_GPs/Simple_GP_Regression.html#Introduction to train and test on higher-dimensional data. While generating predictions, the model always returns the same output for each test element.\r\n## To reproduce\r\nTo reproduce, I am providing the modified example\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\n# # Training data is 100 points in [0,1] inclusive regularly spaced\r\n# train_x = torch.linspace(0, 1, 100)\r\n# # True function is sin(2*pi*x) with Gaussian noise\r\n# train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)\r\ntrain_x = torch.randn(50,35)\r\ntrain_y = torch.randn(50)\r\n\r\n# We will use the simplest form of GP model, exact inference\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n# initialize likelihood and model\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n\r\n# this is for running the notebook in our testing framework\r\nimport os\r\nsmoke_test = ('CI' in os.environ)\r\ntraining_iter = 2 if smoke_test else 50\r\n\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n], lr=0.1)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iter):\r\n    # Zero gradients from previous iteration\r\n    optimizer.zero_grad()\r\n    # Output from model\r\n    output = model(train_x)\r\n    # Calc loss and backprop gradients\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\r\n        i + 1, training_iter, loss.item(),\r\n        model.covar_module.base_kernel.lengthscale.item(),\r\n        model.likelihood.noise.item()\r\n    ))\r\n    optimizer.step()\r\n    \r\n# Get into evaluation (predictive posterior) mode\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\n# Test points are regularly spaced along [0,1]\r\n# Make predictions by feeding model through likelihood\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    test_x = torch.randn(10,35)\r\n    observed_pred = likelihood(model(test_x))\r\n\r\nprint(observed_pred.mean)\r\n# Your code goes here\r\n# Please make sure it does not require any external dependencies (other than PyTorch!)\r\n# (We much prefer small snippets rather than links to existing libraries!)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nIter 1/50 - Loss: 1.610   lengthscale: 0.693   noise: 0.693\r\nIter 2/50 - Loss: 1.600   lengthscale: 0.693   noise: 0.744\r\nIter 3/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.754\r\nIter 4/50 - Loss: 1.599   lengthscale: 0.693   noise: 0.739\r\nIter 5/50 - Loss: 1.601   lengthscale: 0.693   noise: 0.717\r\nIter 6/50 - Loss: 1.602   lengthscale: 0.693   noise: 0.701\r\nIter 7/50 - Loss: 1.600   lengthscale: 0.693   noise: 0.696\r\nIter 8/50 - Loss: 1.599   lengthscale: 0.693   noise: 0.700\r\nIter 9/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.709\r\nIter 10/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.719\r\nIter 11/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.727\r\nIter 12/50 - Loss: 1.599   lengthscale: 0.693   noise: 0.730\r\nIter 13/50 - Loss: 1.599   lengthscale: 0.693   noise: 0.728\r\nIter 14/50 - Loss: 1.599   lengthscale: 0.693   noise: 0.723\r\nIter 15/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.716\r\nIter 16/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.710\r\nIter 17/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.706\r\nIter 18/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.705\r\nIter 19/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.708\r\nIter 20/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.712\r\nIter 21/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.717\r\nIter 22/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.722\r\nIter 23/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.723\r\nIter 24/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.722\r\nIter 25/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.718\r\nIter 26/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.713\r\nIter 27/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.709\r\nIter 28/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.708\r\nIter 29/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.709\r\nIter 30/50 - Loss: 1.598   lengthscale: 0.693   noise: 0.712\r\nIter 31/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.716\r\nIter 32/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.719\r\nIter 33/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.720\r\nIter 34/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.719\r\nIter 35/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.716\r\nIter 36/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.713\r\nIter 37/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.711\r\nIter 38/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.710\r\nIter 39/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.712\r\nIter 40/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.714\r\nIter 41/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.716\r\nIter 42/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.718\r\nIter 43/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.717\r\nIter 44/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.716\r\nIter 45/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.714\r\nIter 46/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.713\r\nIter 47/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.712\r\nIter 48/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.712\r\nIter 49/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.714\r\nIter 50/50 - Loss: 1.597   lengthscale: 0.693   noise: 0.715\r\ntensor([-0.1962, -0.1962, -0.1962, -0.1962, -0.1962, -0.1962, -0.1962, -0.1962,\r\n        -0.1962, -0.1962])\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nI expected the model to atleast generate different outputs for different inputs.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version  1.1.1\r\n- PyTorch Version 1.5.0\r\n- Computer OS Ubuntu\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\nAny advice about training on multidimensional inputs would be highly valuable to me. Thank you so much for your help. \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1176/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1176/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1174", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1174/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1174/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1174/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1174", "id": 635484372, "node_id": "MDExOlB1bGxSZXF1ZXN0NDMxODM5OTkw", "number": 1174, "title": "Fix errors with LazyTensor#__add__", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-09T14:34:10Z", "updated_at": "2020-06-14T00:44:11Z", "closed_at": "2020-06-14T00:44:08Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1174", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1174", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1174.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1174.patch", "merged_at": "2020-06-14T00:44:07Z"}, "body": "There were a few bugs in various `LT#_expand_batch` methods, which would cause failures when adding two LTs. This PR addresses those errors and adds a unit test.\r\n\r\n[Closes #1133]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1174/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1174/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1168", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1168/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1168/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1168/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1168", "id": 631325057, "node_id": "MDU6SXNzdWU2MzEzMjUwNTc=", "number": 1168, "title": "[Bug]Expected the input to have 2 dimensionality (based on the ard_num_dims argument). Got 1.", "user": {"login": "karlzhang-hhg", "id": 22112581, "node_id": "MDQ6VXNlcjIyMTEyNTgx", "avatar_url": "https://avatars.githubusercontent.com/u/22112581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karlzhang-hhg", "html_url": "https://github.com/karlzhang-hhg", "followers_url": "https://api.github.com/users/karlzhang-hhg/followers", "following_url": "https://api.github.com/users/karlzhang-hhg/following{/other_user}", "gists_url": "https://api.github.com/users/karlzhang-hhg/gists{/gist_id}", "starred_url": "https://api.github.com/users/karlzhang-hhg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karlzhang-hhg/subscriptions", "organizations_url": "https://api.github.com/users/karlzhang-hhg/orgs", "repos_url": "https://api.github.com/users/karlzhang-hhg/repos", "events_url": "https://api.github.com/users/karlzhang-hhg/events{/privacy}", "received_events_url": "https://api.github.com/users/karlzhang-hhg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-05T05:34:23Z", "updated_at": "2020-06-12T20:13:10Z", "closed_at": "2020-06-12T20:13:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI try to rerun my code to generate a GP prior distribution in 2-dimensional space. This code was run successfully on 0.3.5, but fail on 1.1.1\r\n\r\n## To reproduce\r\n\r\nI defined following functions.\r\n\r\n```\r\n# %%\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nimport PIL\r\nimport numpy as np\r\nimport pandas as pd\r\nimport os\r\nimport sys\r\nimport time\r\nimport matplotlib.pyplot as plt\r\nfrom itertools import product\r\nfrom matplotlib.ticker import LinearLocator, FormatStrFormatter\r\nfrom matplotlib import cm\r\nfrom mpl_toolkits.mplot3d import Axes3D\r\n\r\n\r\n# %% [markdown]\r\nclass GridGPPriorGenerator(gpytorch.models.ExactGP):\r\n    \"\"\"\r\n    Generate prior distribution for GP.\r\n    \"\"\"\r\n\r\n    def __init__(self, grid, train_x, train_y, lengthscale, likelihood, opscale=1):\r\n        \"\"\" Generate a GP prior realization just by giving only one pair of training observation and it is far away from all testing data input.\r\n            Args:\r\n                grid: The input value grids to get the GP prior.\r\n                train_x: One example of training x.\r\n                train_y: One example of training y.\r\n                lengthscale: An array of lengthscale along each axis.\r\n                likelihood: The likelihood function to mapping latent function to observation y (e.g., Gaussian for regression).\r\n                outputscale: The scale for the kernel (https://gpytorch.readthedocs.io/en/latest/kernels.html#gpytorch.kernels.RBFKernel).\r\n\r\n        \"\"\"\r\n        super(GridGPPriorGenerator, self).__init__(train_x, train_y, likelihood)\r\n        self.dims = train_x.size(-1)\r\n        self.opscale = opscale\r\n        self.mean_module = gpytorch.means.ConstantMean() # Default is 0 constant mean.\r\n        kernel = gpytorch.kernels.RBFKernel(ard_num_dims=train_x.size(-1))\r\n        print(\"The default length scale is {}.\".format(kernel.lengthscale)) # Default value: \r\n        kernel.lengthscale = lengthscale.to(torch.float) # Assign the lengthscale values.        \r\n        self.covar_module = gpytorch.kernels.GridKernel(kernel, grid=grid)\r\n        \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)*self.opscale\r\n        print(mean_x.shape, covar_x.shape)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\ndef Gen_GP_Latent_Func(dim: int, train_x: torch.tensor, train_y: torch.tensor,\r\n                       grid_size: int, lengthscale: torch.tensor, opscale: float=1, noise: float=0):\r\n    \"\"\"\r\n        dim: The dimension of input space.\r\n        train_x: One example of training x.\r\n        train_y: One example of training y.\r\n        grid_size: The number of grid points along each axis.\r\n        lengthscale: The diagonal parameters of theta for specifying length-scale along each axis: https://gpytorch.readthedocs.io/en/latest/kernels.html#gpytorch.kernels.RBFKernel.\r\n        noise: The variance of noise: https://github.com/cornellius-gp/gpytorch/blob/92e07cf4dae26083fe0aed926e1dfd483443924e/gpytorch/likelihoods/gaussian_likelihood.py#L106.\r\n        opscale: The outputscale for the kernel.\r\n\r\n    \"\"\"\r\n    grid = torch.zeros(grid_size, dim, dtype=torch.float)\r\n    for ci in range(dim):\r\n        grid[:, ci] = torch.arange(grid_size)\r\n    test_x = gpytorch.utils.grid.create_data_from_grid(grid)\r\n    \r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n    model = GridGPPriorGenerator(grid, train_x, train_y, lengthscale, likelihood, opscale=opscale)\r\n\r\n    model.train()\r\n    likelihood.train()\r\n\r\n    print(model.covar_module.base_kernel.lengthscale)\r\n\r\n    model.eval()\r\n    likelihood.eval()\r\n\r\n    with torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n        observed_pred = likelihood(model(test_x), noise=noise*torch.ones(test_x.size(0)))\r\n\r\n    return observed_pred\r\n\r\ndef Grayscale_Latent_Func(rfield_tensor):\r\n    rfield = rfield_tensor.detach().numpy()\r\n    min_v, max_v = np.min(rfield), np.max(rfield)\r\n    rfield = (rfield-min_v)/(max_v-min_v)*255\r\n    return rfield.astype(dtype=np.uint8)\r\n\r\ndef Gen_Save_GP_Micro_Struct(dim: int, train_x: torch.tensor, train_y: torch.tensor, \r\n                             grid_size: int, lengthscale: torch.tensor, opscale: float, noise: float,\r\n                             lat_func: object, save_path: str, postfix: str = \"\", lat_func_kwargs: dict = {}):\r\n    gp_proc = Gen_GP_Latent_Func(dim, train_x, train_y, grid_size, lengthscale, opscale, noise)\r\n\r\n    start_time = time.time()\r\n    rfield_tensor = gp_proc.rsample(sample_shape=torch.Size((grid_size, grid_size)))\r\n    print(rfield_tensor.size())\r\n    rfield_tensor = rfield_tensor.view(grid_size, grid_size)\r\n    print(\"The prediction for the 40000 grid points takes time: {}s.\\n\".format(\r\n        time.time()-start_time,))\r\n    print(\"The random realization is:\\n {}.\\n\".format(rfield_tensor,))\r\n\r\n    # Postfix for plots.\r\n    if postfix != \"\":\r\n        postfix += '_'\r\n    postfix += '_'.join([str(int(lengthscale[0])), str(int(lengthscale[1]))])\r\n    save_subfolder_path = os.path.join(save_path, 'gp_obse_'+postfix)\r\n    if not os.path.exists(save_subfolder_path):\r\n        os.mkdir(save_subfolder_path)\r\n\r\n    # Latent function to micro-structure pixel observations.\r\n    img_arr = lat_func(rfield_tensor, **lat_func_kwargs)\r\n\r\n    img = PIL.Image.fromarray(img_arr)\r\n\r\n    img.save(os.path.join(save_subfolder_path, \"one_gp_obse_micro_struct_{}.png\".format(postfix,)))\r\n\r\n    return img\r\n```\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n# Your code goes here\r\n# Please make sure it does not require any external dependencies (other than PyTorch!)\r\n# (We much prefer small snippets rather than links to existing libraries!)\r\n\r\ndim = 2\r\ntrain_x = torch.tensor([[10000, 10000],[10000, 20000]], dtype=torch.float) # The only one data point is far away from the testing point so that the testing point is just a GP prior.\r\ntrain_y = torch.tensor([0,0], dtype=torch.float)\r\ngrid_size = 200\r\nlengthscale = torch.tensor([[5, 5]]) # Have to\r\nopscale = 4.0\r\nnoise = 0.05 * opscale\r\nlat_func = Grayscale_Latent_Func\r\nsave_path = \"/projects/p30309/CD/20200606-Gen_GP_Rand_Struct/\"\r\npostfix = 'ref'\r\n\r\nref_img = Gen_Save_GP_Micro_Struct(dim, train_x, train_y, grid_size, lengthscale, opscale, noise, lat_func, save_path, postfix)\r\n\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nThe default length scale is tensor([[0.6931, 0.6931]], grad_fn=<SoftplusBackward>).\r\ntensor([[5., 5.]], grad_fn=<SoftplusBackward>)\r\ntorch.Size([2]) torch.Size([2, 2])\r\ntorch.Size([40002]) torch.Size([40002, 40002])\r\n40000\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n/projects/p30309/CD/CD_github/gen_matsci_img_dataset.py in \r\n     10 postfix = 'ref'\r\n     11 \r\n---> 12 ref_img = Gen_Save_GP_Micro_Struct(dim, train_x, train_y, grid_size, lengthscale, opscale, noise, lat_func, save_path, postfix)\r\n     13 \r\n\r\n/projects/p30309/CD/CD_github/control_chart/matsci_data_generation.py in Gen_Save_GP_Micro_Struct(dim, train_x, train_y, grid_size, lengthscale, opscale, noise, lat_func, save_path, postfix, lat_func_kwargs)\r\n    155 \r\n    156     start_time = time.time()\r\n--> 157     rfield_tensor = gp_proc.rsample(sample_shape=torch.Size((grid_size, grid_size)))\r\n    158     print(rfield_tensor.size())\r\n    159     rfield_tensor = rfield_tensor.view(grid_size, grid_size)\r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/distributions/multivariate_normal.py in rsample(self, sample_shape, base_samples)\r\n    146             # Get samples\r\n    147             print(num_samples)\r\n--> 148             print(covar.zero_mean_mvn_samples(num_samples))\r\n    149             print(self.loc.unsqueeze(0))\r\n    150             res = covar.zero_mean_mvn_samples(num_samples) + self.loc.unsqueeze(0)\r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in zero_mean_mvn_samples(self, num_samples)\r\n   1589             covar_root = self.evaluate().sqrt()\r\n   1590         else:\r\n-> 1591             covar_root = self.root_decomposition().root\r\n   1592 \r\n   1593         base_samples = torch.randn(\r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36 \r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in root_decomposition(self)\r\n   1331                 )\r\n   1332 \r\n-> 1333         res = self._root_decomposition()\r\n   1334         return RootLazyTensor(res)\r\n   1335 \r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in _root_decomposition(self)\r\n    584         func = RootDecomposition()\r\n    585         res, _ = func.apply(\r\n--> 586             self.representation_tree(),\r\n    587             self._root_decomposition_size(),\r\n    588             self.dtype,\r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in representation_tree(self)\r\n   1273         including all subobjects. This is used internally.\r\n   1274         \"\"\"\r\n-> 1275         return LazyTensorRepresentationTree(self)\r\n   1276 \r\n   1277     @property\r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor_representation_tree.py in __init__(self, lazy_tsr)\r\n     11         for arg in lazy_tsr._args:\r\n     12             if hasattr(arg, \"representation\") and callable(arg.representation):  # Is it a lazy tensor?\r\n---> 13                 representation_size = len(arg.representation())\r\n     14                 self.children.append((slice(counter, counter + representation_size, None), arg.representation_tree()))\r\n     15                 counter += representation_size\r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in representation(self)\r\n   1261                 representation.append(arg)\r\n   1262             elif hasattr(arg, \"representation\") and callable(arg.representation):  # Is it a LazyTensor?\r\n-> 1263                 representation += list(arg.representation())\r\n   1264             else:\r\n   1265                 raise RuntimeError(\"Representation of a LazyTensor should consist only of Tensors\")\r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in representation(self)\r\n   1261                 representation.append(arg)\r\n   1262             elif hasattr(arg, \"representation\") and callable(arg.representation):  # Is it a LazyTensor?\r\n-> 1263                 representation += list(arg.representation())\r\n   1264             else:\r\n   1265                 raise RuntimeError(\"Representation of a LazyTensor should consist only of Tensors\")\r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in representation(self)\r\n    311         # representation\r\n    312         else:\r\n--> 313             return self.evaluate_kernel().representation()\r\n    314 \r\n    315     def representation_tree(self):\r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36 \r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)\r\n    278             temp_active_dims = self.kernel.active_dims\r\n    279             self.kernel.active_dims = None\r\n--> 280             res = self.kernel(x1, x2, diag=False, last_dim_is_batch=self.last_dim_is_batch, **self.params)\r\n    281             self.kernel.active_dims = temp_active_dims\r\n    282 \r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, last_dim_is_batch, **params)\r\n    394                 res = LazyEvaluatedKernelTensor(x1_, x2_, kernel=self, last_dim_is_batch=last_dim_is_batch, **params)\r\n    395             else:\r\n--> 396                 res = lazify(super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\r\n    397             return res\r\n    398 \r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/kernels/grid_kernel.py in forward(self, x1, x2, diag, last_dim_is_batch, **params)\r\n    120                 covars = [\r\n    121                     self.base_kernel(first, proj, last_dim_is_batch=False, **params)\r\n--> 122                     for first, proj in zip(first_grid_point, grid)\r\n    123                 ]  # Each entry i contains a 1 x grid_size[i] covariance matrix\r\n    124                 covars = [delazify(c) for c in covars]\r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/kernels/grid_kernel.py in (.0)\r\n    120                 covars = [\r\n    121                     self.base_kernel(first, proj, last_dim_is_batch=False, **params)\r\n--> 122                     for first, proj in zip(first_grid_point, grid)\r\n    123                 ]  # Each entry i contains a 1 x grid_size[i] covariance matrix\r\n    124                 covars = [delazify(c) for c in covars]\r\n\r\n~/.local/lib/python3.7/site-packages/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, last_dim_is_batch, **params)\r\n    378                 raise RuntimeError(\r\n    379                     \"Expected the input to have {} dimensionality \"\r\n--> 380                     \"(based on the ard_num_dims argument). Got {}.\".format(self.ard_num_dims, x1_.size(-1))\r\n    381                 )\r\n    382 \r\n\r\nRuntimeError: Expected the input to have 2 dimensionality (based on the ard_num_dims argument). Got 1.\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nIt should generate a random realization of Gaussian Process field. Because here, I only have 2 training data points and it is far away from testing data, so that the random field should behave like a prior distribution.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 1.1.1\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> 1.5.0\r\n- <!-- Computer OS --> MacOS\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1168/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1168/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1166", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1166/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1166/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1166/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1166", "id": 629907497, "node_id": "MDU6SXNzdWU2Mjk5MDc0OTc=", "number": 1166, "title": "Dimension out of range error", "user": {"login": "iprada", "id": 25404123, "node_id": "MDQ6VXNlcjI1NDA0MTIz", "avatar_url": "https://avatars.githubusercontent.com/u/25404123?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iprada", "html_url": "https://github.com/iprada", "followers_url": "https://api.github.com/users/iprada/followers", "following_url": "https://api.github.com/users/iprada/following{/other_user}", "gists_url": "https://api.github.com/users/iprada/gists{/gist_id}", "starred_url": "https://api.github.com/users/iprada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iprada/subscriptions", "organizations_url": "https://api.github.com/users/iprada/orgs", "repos_url": "https://api.github.com/users/iprada/repos", "events_url": "https://api.github.com/users/iprada/events{/privacy}", "received_events_url": "https://api.github.com/users/iprada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-03T11:12:23Z", "updated_at": "2020-06-13T22:25:25Z", "closed_at": "2020-06-13T22:25:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n\r\n\r\nI am using using the Spectral mixture kernel, and initalizing it from the empircal spectrum of the data. However, I get an IndexError.\r\n## To reproduce\r\n\r\n**Minimal example:**\r\n```python\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        # Super interact to with teh gpytorch.models.ExactGP\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.SpectralMixtureKernel(num_mixtures=4)\r\n        #self.covar_module.initialize_from_data(train_x, train_y)\r\n        self.covar_module.initialize_from_data_empspect(train_x, train_y)\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\ntrain_x = np.arange(1,100)\r\ntrain_y = np.random.rand(100)\r\n\r\n\r\nfor i in range(0,50):       \r\n    \r\n\r\n    # Convert to tensor\r\n    train_x = torch.from_numpy(train_x)\r\n    train_y = torch.from_numpy(train_y)\r\n    train_x = train_x.type(torch.FloatTensor)\r\n    train_y = train_y.type(torch.FloatTensor)\r\n\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n    model = ExactGPModel(train_x, train_y, likelihood)\r\n\r\n```\r\n\r\n** Error message**\r\n```\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-18-3796fe5ce2f5> in <module>\r\n     19 \r\n     20     likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n---> 21     model = ExactGPModel(train_x, train_y, likelihood)\r\n\r\n<ipython-input-5-6b823c7240a5> in __init__(self, train_x, train_y, likelihood)\r\n      7         self.covar_module = gpytorch.kernels.SpectralMixtureKernel(num_mixtures=4)\r\n      8         #self.covar_module.initialize_from_data(train_x, train_y)\r\n----> 9         self.covar_module.initialize_from_data_empspect(train_x, train_y)\r\n     10 \r\n     11     def forward(self, x):\r\n\r\n~/miniconda3/envs/GP/lib/python3.7/site-packages/gpytorch/kernels/spectral_mixture_kernel.py in initialize_from_data_empspect(self, train_x, train_y)\r\n    159         from scipy.integrate import cumtrapz\r\n    160 \r\n--> 161         N = train_x.size(-2)\r\n    162         emp_spect = np.abs(fft(train_y.cpu().detach().numpy())) ** 2 / N\r\n    163         M = math.floor(N / 2)\r\n\r\nIndexError: Dimension out of range (expected to be in range of [-1, 0], but got -2)\r\n```\r\n\r\n\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version (1.1.1)\r\n- PyTorch Version 1.5.0)\r\n- Windows bash on windows 10\r\n\r\n## Additional context\r\nLet me know if you need more info.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1166/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1166/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1164", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1164/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1164/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1164/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1164", "id": 628777551, "node_id": "MDU6SXNzdWU2Mjg3Nzc1NTE=", "number": 1164, "title": "[Bug] Cannot serialize/deserialize SmoothedBoxPrior when some args are broadcast", "user": {"login": "mshvartsman", "id": 70196, "node_id": "MDQ6VXNlcjcwMTk2", "avatar_url": "https://avatars.githubusercontent.com/u/70196?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mshvartsman", "html_url": "https://github.com/mshvartsman", "followers_url": "https://api.github.com/users/mshvartsman/followers", "following_url": "https://api.github.com/users/mshvartsman/following{/other_user}", "gists_url": "https://api.github.com/users/mshvartsman/gists{/gist_id}", "starred_url": "https://api.github.com/users/mshvartsman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mshvartsman/subscriptions", "organizations_url": "https://api.github.com/users/mshvartsman/orgs", "repos_url": "https://api.github.com/users/mshvartsman/repos", "events_url": "https://api.github.com/users/mshvartsman/events{/privacy}", "received_events_url": "https://api.github.com/users/mshvartsman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-01T22:50:15Z", "updated_at": "2020-06-25T23:58:40Z", "closed_at": "2020-06-25T23:58:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nIt seems like `SmoothedBoxPrior` for >1d doesn't work with serialization/deserialization when only some args are broadcast. \r\n\r\n## To reproduce\r\n\r\n```python\r\nimport torch\r\nimport gpytorch\r\npr = gpytorch.priors.SmoothedBoxPrior(torch.zeros(2), torch.ones(2))\r\npr.load_state_dict(pr.state_dict())\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-5-6b4b2e881beb> in <module>\r\n      2 import gpytorch\r\n      3 pr = gpytorch.priors.SmoothedBoxPrior(torch.zeros(2), torch.ones(2))\r\n----> 4 pr.load_state_dict(pr.state_dict())\r\n\r\n<...PATH..>/torch/nn/modules/module.py in load_state_dict(self, state_dict, strict)\r\n    877         if len(error_msgs) > 0:\r\n    878             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\r\n--> 879                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\r\n    880         return _IncompatibleKeys(missing_keys, unexpected_keys)\r\n    881 \r\n\r\nRuntimeError: Error(s) in loading state_dict for SmoothedBoxPrior:\r\n\tWhile copying the parameter named \"sigma\", whose dimensions in the model are torch.Size([2]) and whose dimensions in the checkpoint are torch.Size([2]), an exception occured : ('unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.',).\r\n\r\n```\r\n\r\nNote that `SmoothedBoxPrior(a=torch.zeros(2), b=torch.ones(2), sigma=torch.ones(2)*0.01)` succeeds, as does `gpytorch.priors.GammaPrior(torch.ones(2),1)`.\r\n\r\n## Expected Behavior\r\n\r\nSuccessful load. \r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch version: 1.1.1\r\n- pytorch version: 1.5.0\r\n- OS: tested on Centos and Mac OSX. \r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1164/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1164/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1162", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1162/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1162/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1162/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1162", "id": 627978120, "node_id": "MDU6SXNzdWU2Mjc5NzgxMjA=", "number": 1162, "title": "ExactMarginalLogLikelihood with multi dimensional input", "user": {"login": "samsja", "id": 55492238, "node_id": "MDQ6VXNlcjU1NDkyMjM4", "avatar_url": "https://avatars.githubusercontent.com/u/55492238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samsja", "html_url": "https://github.com/samsja", "followers_url": "https://api.github.com/users/samsja/followers", "following_url": "https://api.github.com/users/samsja/following{/other_user}", "gists_url": "https://api.github.com/users/samsja/gists{/gist_id}", "starred_url": "https://api.github.com/users/samsja/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samsja/subscriptions", "organizations_url": "https://api.github.com/users/samsja/orgs", "repos_url": "https://api.github.com/users/samsja/repos", "events_url": "https://api.github.com/users/samsja/events{/privacy}", "received_events_url": "https://api.github.com/users/samsja/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-31T14:48:47Z", "updated_at": "2020-06-01T03:56:34Z", "closed_at": "2020-06-01T03:56:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi everibody,\r\n\r\nI want to make a regression over parametrized vectorial function and I have got a x_train.shape : (100) torch tensor and a y_train.shape: (100,2)  at each point in x_train I associated a vector of dimension 2.\r\n\r\nI am using the following models \r\n\r\n```python\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = ExactGPModel(M_train, y_train, likelihood)\r\n```\r\nwith the mll: \r\n\r\n```python\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n```\r\n\r\nhowerver when i call \r\n\r\n```python\r\noutput = model(M_train)\r\nloss = -mll(output, y_train)\r\n```\r\n\r\nI have got the folowing error :\r\n```python\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-143-c02e1b54aff7> in <module>\r\n      5     output = model(M_train)\r\n      6     # Calc loss and backprop gradients\r\n----> 7     loss = -mll(output, y_train)\r\n      8     loss.backward()\r\n      9 \r\n\r\n~/.local/lib/python3.8/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     26 \r\n     27     def __call__(self, *inputs, **kwargs):\r\n---> 28         outputs = self.forward(*inputs, **kwargs)\r\n     29         if isinstance(outputs, list):\r\n     30             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/.local/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, function_dist, target, *params)\r\n     49         # Get the log prob of the marginal distribution\r\n     50         output = self.likelihood(function_dist, *params)\r\n---> 51         res = output.log_prob(target)\r\n     52 \r\n     53         # Add additional terms (SGPR / learned inducing points, heteroskedastic likelihood models)\r\n\r\n~/.local/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    118 \r\n    119         mean, covar = self.loc, self.lazy_covariance_matrix\r\n--> 120         diff = value - mean\r\n    121 \r\n    122         # Repeat the covar to match the batch shape of diff\r\n\r\nRuntimeError:  The size of tensor a (2) must match the size of tensor b (100) at non-singleton dimension 1\r\n```\r\n\r\nI suspected that there are erros when dealing with multidimensional y vector.\r\n\r\nIs that a bug or is there a better way to apply these exactGP to multivariable functions ?\r\n\r\nThanks in advance ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1162/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1162/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1157", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1157/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1157/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1157/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1157", "id": 622863994, "node_id": "MDU6SXNzdWU2MjI4NjM5OTQ=", "number": 1157, "title": "[Bug] Fantasizing is very slow on GPU due to torch.qr", "user": {"login": "danielrjiang", "id": 18407088, "node_id": "MDQ6VXNlcjE4NDA3MDg4", "avatar_url": "https://avatars.githubusercontent.com/u/18407088?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danielrjiang", "html_url": "https://github.com/danielrjiang", "followers_url": "https://api.github.com/users/danielrjiang/followers", "following_url": "https://api.github.com/users/danielrjiang/following{/other_user}", "gists_url": "https://api.github.com/users/danielrjiang/gists{/gist_id}", "starred_url": "https://api.github.com/users/danielrjiang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danielrjiang/subscriptions", "organizations_url": "https://api.github.com/users/danielrjiang/orgs", "repos_url": "https://api.github.com/users/danielrjiang/repos", "events_url": "https://api.github.com/users/danielrjiang/events{/privacy}", "received_events_url": "https://api.github.com/users/danielrjiang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-22T00:11:23Z", "updated_at": "2020-07-24T01:02:46Z", "closed_at": "2020-07-24T01:02:46Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\ntorch.qr is causing things to be very slow on the GPU, when using fantasies. This is likely caused by https://github.com/pytorch/pytorch/issues/22573.\r\n\r\n\r\n\r\n## To reproduce\r\n\r\nSee the following notebook example.\r\n[KG_GPU_investigate.ipynb.txt](https://github.com/cornellius-gp/gpytorch/files/4665346/KG_GPU_investigate.ipynb.txt)\r\n\r\n** Stack trace/error message **\r\nSee the following profile results.\r\n<img width=\"1211\" alt=\"CPU\" src=\"https://user-images.githubusercontent.com/18407088/82617537-388de380-9b85-11ea-91c7-c5d86fe103b7.png\">\r\n<img width=\"1107\" alt=\"GPU\" src=\"https://user-images.githubusercontent.com/18407088/82617539-3b88d400-9b85-11ea-9ecc-c5171d8380b7.png\">\r\n[kg_cpu.cprofile.txt](https://github.com/cornellius-gp/gpytorch/files/4665343/kg_cpu.cprofile.txt)\r\n[kg_gpu.cprofile.txt](https://github.com/cornellius-gp/gpytorch/files/4665344/kg_gpu.cprofile.txt)\r\n\r\n\r\n## Expected Behavior\r\n\r\nRunning on CUDA should show speedups compared to CPU.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- latest master\r\n- 1.6.0a0\r\n- Mac OS X Catalina 10.15.4\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1157/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1157/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1155", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1155/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1155/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1155/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1155", "id": 622117151, "node_id": "MDU6SXNzdWU2MjIxMTcxNTE=", "number": 1155, "title": "[Bug] Large MLLs on multitask models, even with z-scored data", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2020-05-20T22:14:18Z", "updated_at": "2021-06-10T14:48:45Z", "closed_at": "2021-06-10T14:48:45Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "It seems like we've had several issues (e.g. #1129) where multitask models are returning very large MLL values (e.g. in the 1000s) even though the data is z-scored.\r\n\r\ncc/ @Balandat @jacobrgardner ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1155/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1155/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1153", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1153/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1153/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1153/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1153", "id": 620599470, "node_id": "MDU6SXNzdWU2MjA1OTk0NzA=", "number": 1153, "title": "[Bug] #1084 not solved with version 1.1.1", "user": {"login": "foail", "id": 65576488, "node_id": "MDQ6VXNlcjY1NTc2NDg4", "avatar_url": "https://avatars.githubusercontent.com/u/65576488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/foail", "html_url": "https://github.com/foail", "followers_url": "https://api.github.com/users/foail/followers", "following_url": "https://api.github.com/users/foail/following{/other_user}", "gists_url": "https://api.github.com/users/foail/gists{/gist_id}", "starred_url": "https://api.github.com/users/foail/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/foail/subscriptions", "organizations_url": "https://api.github.com/users/foail/orgs", "repos_url": "https://api.github.com/users/foail/repos", "events_url": "https://api.github.com/users/foail/events{/privacy}", "received_events_url": "https://api.github.com/users/foail/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2020-05-19T01:06:08Z", "updated_at": "2020-06-09T18:28:25Z", "closed_at": "2020-06-08T19:11:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThe same problem as stated in issue #1084 occurs with the version 1.1.1. I am also trying to combine conv2d with deep kernel learning for a regression task. So I used a very similar approach as stated in issue #1084. Although issue #1084 is closed, I ran the same code in issue #1084 and reproduced the same error \"RuntimeError: Shapes are not broadcastable for mul operatio\". \r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Mon Mar 23 19:17:40 2020\r\n\r\n@author: denisilie94\r\n\"\"\"\r\n\r\n#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Mon Mar 23 15:38:22 2020\r\n\r\n@author: denisilie94\r\n\"\"\"\r\n\r\nimport os\r\nimport tqdm\r\nimport torch\r\nimport gpytorch\r\nimport numpy as np\r\nfrom matplotlib import pyplot as plt\r\n\r\n\r\n# Define a plotting function\r\ndef ax_plot(f, ax, y_labels, title):\r\n    im = ax.imshow(y_labels)\r\n    ax.set_title(title)\r\n    f.colorbar(im)\r\n    \r\n\r\n# Load Olivetti faces database\r\ndata = np.load('olivetti.npz')\r\n\r\ntrain_x = torch.Tensor(data['train_x'])\r\ntrain_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1], train_x.shape[2]))\r\ntrain_y = torch.Tensor(data['train_y'])\r\n\r\n\r\ntest_x = torch.Tensor(data['test_x'])\r\ntest_x = test_x.reshape((test_x.shape[0], 1, test_x.shape[1], test_x.shape[2]))\r\ntest_y = torch.Tensor(data['test_y'])\r\n\r\n\r\n# Create dataset\r\ndataset    = torch.utils.data.TensorDataset(train_x, train_y)\r\ndataloader = torch.utils.data.DataLoader(dataset) \r\n\r\nif torch.cuda.is_available():\r\n    train_x, train_y = train_x.cuda(), train_y.cuda()\r\n    \r\n    \r\n# Defining the DKL Feature Extractor\r\ndata_dim = train_x.size(-1)\r\n\r\nclass LargeFeatureExtractor(torch.nn.Sequential):           \r\n    def __init__(self):                                      \r\n        super(LargeFeatureExtractor, self).__init__()        \r\n        self.add_module('conv1', torch.nn.Conv2d(kernel_size=(5,5), stride=1, in_channels=1, out_channels=20))\r\n        self.add_module('pool1', torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2))                  \r\n        self.add_module('conv2', torch.nn.Conv2d(kernel_size=(5,5), stride=1, in_channels=20, out_channels=50))     \r\n        self.add_module('pool2', torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2))\r\n        self.add_module('flatt', torch.nn.Flatten())              \r\n        self.add_module('full3', torch.nn.Linear(800, 1000))\r\n        self.add_module('relu3', torch.nn.ReLU())\r\n        self.add_module('full4', torch.nn.Linear(1000, 500))                  \r\n        self.add_module('relu4', torch.nn.ReLU())\r\n        self.add_module('full5', torch.nn.Linear(500, 50))       \r\n        self.add_module('full6', torch.nn.Linear(50, 2))\r\n        \r\nfeature_extractor = LargeFeatureExtractor()\r\n\r\n\r\n# Defining the DKL-GP Model\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n        def __init__(self, train_x, train_y, likelihood):\r\n            super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n            self.mean_module = gpytorch.means.ConstantMean()\r\n            self.covar_module = gpytorch.kernels.GridInterpolationKernel(\r\n                gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=1)),\r\n                num_dims=2, grid_size=100\r\n            )\r\n            self.feature_extractor = feature_extractor\r\n\r\n        def forward(self, x):\r\n            # We're first putting our data through a deep net (feature extractor)\r\n            # We're also scaling the features so that they're nice values\r\n            projected_x = self.feature_extractor(x)\r\n            projected_x = projected_x - projected_x.min(0)[0]\r\n            projected_x = 2 * (projected_x / projected_x.max(0)[0]) - 1\r\n        \r\n            mean_x = self.mean_module(projected_x)\r\n            covar_x = self.covar_module(projected_x)\r\n            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n        \r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = GPRegressionModel(train_x, train_y, likelihood)\r\n\r\nif torch.cuda.is_available():\r\n    model = model.cuda()\r\n    likelihood = likelihood.cuda()\r\n    \r\n# Training the model\r\ntraining_iterations = 1\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.feature_extractor.parameters()},\r\n    {'params': model.covar_module.parameters()},\r\n    {'params': model.mean_module.parameters()},\r\n    {'params': model.likelihood.parameters()},\r\n], lr=0.01)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ndef train():\r\n    iterator = tqdm.tqdm_notebook(range(training_iterations))\r\n    for i in iterator:\r\n        # Zero backprop gradients\r\n        optimizer.zero_grad()\r\n        # Get output from model\r\n        output = model(train_x)\r\n        # Calc loss and backprop derivatives\r\n        loss = -mll(output, train_y)\r\n        loss.backward()\r\n        iterator.set_postfix(loss=loss.item())\r\n        optimizer.step()\r\n        \r\n        # extract covariance matrix\r\n#        cov_mat = output.covariance_matrix.detach().numpy()\r\n        \r\n        # Plot our predictive means\r\n#        fig, observed_ax = plt.subplots(1, 1)\r\n#        ax_plot(fig, observed_ax, cov_mat, 'Covariance kernel matrix')\r\n#        fig.savefig('{}/{}_{}.png'.format(outputDir, i, outputDir))\r\n#        plt.close(fig)\r\n\r\n# define output folder\r\nif type(model.covar_module.base_kernel.base_kernel) is gpytorch.kernels.rbf_kernel.RBFKernel:\r\n    outputDir = 'RBFKernel'\r\nelse:\r\n    outputDir = 'SpectralMixtureKernel'\r\n    \r\n# create output directory if needed    \r\nif not os.path.exists(outputDir):\r\n    os.mkdir(outputDir)\r\n        \r\n# train model\r\ntrain()\r\n\r\n\r\n# Making predictions\r\nmodel.eval()\r\nlikelihood.eval()\r\nwith torch.no_grad(), gpytorch.settings.use_toeplitz(False), gpytorch.settings.fast_pred_var():\r\n    preds = model(test_x)\r\n\r\nprint('Test MAE: {}'.format(torch.mean(torch.abs(preds.mean - test_y))))\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-22-f38243cc9371> in <module>()\r\n      4 likelihood.eval()\r\n      5 with torch.no_grad(), gpytorch.settings.use_toeplitz(False), gpytorch.settings.fast_pred_var():\r\n----> 6     preds = model(test_x)\r\n      7 \r\n      8 print('Test MAE: {}'.format(torch.mean(torch.abs(preds.mean - test_y))))\r\n\r\n1 frames\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)\r\n    306                     train_input = train_input.expand(*batch_shape, *train_input.shape[-2:])\r\n    307                 if batch_shape != input.shape[:-2]:\r\n--> 308                     batch_shape = _mul_broadcast_shape(batch_shape, input.shape[:-2])\r\n    309                     train_input = train_input.expand(*batch_shape, *train_input.shape[-2:])\r\n    310                     input = input.expand(*batch_shape, *input.shape[-2:])\r\n\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/utils/broadcasting.py in _mul_broadcast_shape(error_msg, *shapes)\r\n     18             if any(size != non_singleton_sizes[0] for size in non_singleton_sizes):\r\n     19                 if error_msg is None:\r\n---> 20                     raise RuntimeError(\"Shapes are not broadcastable for mul operation\")\r\n     21                 else:\r\n     22                     raise RuntimeError(error_msg)\r\n\r\nRuntimeError: Shapes are not broadcastable for mul operation\r\n```\r\n\r\n\r\n\r\n## System information\r\n\r\nGPyTorch Version 1.1.1\r\nPyTorch Version 1.4.0\r\nGoogle Colab \r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1153/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1153/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1133", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1133/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1133/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1133/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1133", "id": 611962348, "node_id": "MDU6SXNzdWU2MTE5NjIzNDg=", "number": 1133, "title": "[Bug] ConstantMulLazyTensor can only add batched tensors", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-04T15:26:19Z", "updated_at": "2020-06-14T00:44:07Z", "closed_at": "2020-06-14T00:44:07Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nConstantMulLazyTensor attempts to expand `_constant` according to batch dimensions which fails when there is no batch dimension.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport gpytorch\r\nimport torch\r\n\r\ntlt = gpytorch.lazy.ToeplitzLazyTensor(torch.randn(100).abs())\r\ncmtlt = torch.ones(1) * tlt\r\ncmtlt + torch.randn(100, 100)\r\n\r\n#more specifically\r\ncmtlt._constant.expand(*torch.Size([])) # fails\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-16-0d626e17adaf> in <module>\r\n----> 1 cmtlt + torch.randn(100, 100)\r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/lazy_tensor.py in __add__(self, other)\r\n   1625             other = lazify(other)\r\n   1626             shape = _mul_broadcast_shape(self.shape, other.shape)\r\n-> 1627             return SumLazyTensor(self.expand(shape), other.expand(shape))\r\n   1628         else:\r\n   1629             return SumLazyTensor(self, other)\r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/lazy_tensor.py in expand(self, *sizes)\r\n    857             raise RuntimeError(\"Invalid arguments {} to expand.\".format(sizes))\r\n    858 \r\n--> 859         res = self._expand_batch(batch_shape=shape[:-2])\r\n    860         return res\r\n    861 \r\n\r\n~/Documents/GitHub/gpytorch/gpytorch/lazy/constant_mul_lazy_tensor.py in _expand_batch(self, batch_shape)\r\n     70     def _expand_batch(self, batch_shape):\r\n---> 71         return self.__class__(self.base_lazy_tensor._expand_batch(batch_shape), self._constant.expand(*batch_shape))\r\n     72 \r\n     73     def _get_indices(self, row_index, col_index, *batch_indices):\r\n\r\nTypeError: expand() missing 1 required positional arguments: \"size\"\r\n```\r\n\r\n## Expected Behavior\r\n\r\nIt should return a SumLazyTensor of shape 100 x 100.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\ngpytorch 1.0.1 (code hasn't changed in 1.1.0)\r\npytorch 1.4.0\r\nMacOS\r\n\r\n## Additional context\r\nThe fix is to force the tensor that is being added to have a batch dimension.\r\n```python\r\ncmtlt + torch.randn(1, 100, 100)\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1133/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1133/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1110", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1110/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1110/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1110/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1110", "id": 595901728, "node_id": "MDExOlB1bGxSZXF1ZXN0NDAwMjk1NDQ3", "number": 1110, "title": "Fix issues with `from_batch_mvn`", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-04-07T14:15:30Z", "updated_at": "2020-04-07T17:30:05Z", "closed_at": "2020-04-07T17:08:47Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1110", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1110", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1110.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1110.patch", "merged_at": "2020-04-07T17:08:47Z"}, "body": " - Add custom _getitem method for BlockLazyTensors\r\n - Add a test case\r\n\r\n[Fixes #1024]\r\n[Fixes #1065]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1110/reactions", "total_count": 5, "+1": 1, "-1": 0, "laugh": 1, "hooray": 1, "confused": 0, "heart": 1, "rocket": 1, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1110/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1090", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1090/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1090/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1090/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1090", "id": 590492990, "node_id": "MDU6SXNzdWU1OTA0OTI5OTA=", "number": 1090, "title": "[Bug] dimension error raised in VariationalStrategy", "user": {"login": "sjiang2018", "id": 41413582, "node_id": "MDQ6VXNlcjQxNDEzNTgy", "avatar_url": "https://avatars.githubusercontent.com/u/41413582?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sjiang2018", "html_url": "https://github.com/sjiang2018", "followers_url": "https://api.github.com/users/sjiang2018/followers", "following_url": "https://api.github.com/users/sjiang2018/following{/other_user}", "gists_url": "https://api.github.com/users/sjiang2018/gists{/gist_id}", "starred_url": "https://api.github.com/users/sjiang2018/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sjiang2018/subscriptions", "organizations_url": "https://api.github.com/users/sjiang2018/orgs", "repos_url": "https://api.github.com/users/sjiang2018/repos", "events_url": "https://api.github.com/users/sjiang2018/events{/privacy}", "received_events_url": "https://api.github.com/users/sjiang2018/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-03-30T18:17:41Z", "updated_at": "2020-03-31T21:30:45Z", "closed_at": "2020-03-31T21:30:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nIn my case,  the inducing points have the dimension as torch.Size([10, 50, 4])\r\nwhere 10 is the number of inducing points, 4 is the input channels and 50 is the number input sequences.\r\nso the model would be output(1x3) =  model(intput(50x4))\r\n\r\nhowever, in variational_strategy.py\r\nline 86: full_inputs = torch.cat([inducing_points, x], dim=-2)\r\nline 91: num_induc = inducing_points.size(-2)\r\nIn my case, the dimension -2 is not the number of inducing point.\r\n\r\nThank you and looking forward to your reply. \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1090/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1090/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1089", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1089/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1089/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1089/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1089", "id": 589823904, "node_id": "MDExOlB1bGxSZXF1ZXN0Mzk1Mjc1MjE5", "number": 1089, "title": "Fix batch evaluation of index kernel", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-29T16:00:05Z", "updated_at": "2020-03-30T14:46:41Z", "closed_at": "2020-03-30T14:46:16Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1089", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1089", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1089.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1089.patch", "merged_at": "2020-03-30T14:46:16Z"}, "body": "The recent change ##1087 fixed one thing but broke batch evaluation of non-batched models. This fixes it by broadcasting the different batch shapes involved.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1089/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1089/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1088", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1088/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1088/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1088/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1088", "id": 589500788, "node_id": "MDU6SXNzdWU1ODk1MDA3ODg=", "number": 1088, "title": "[Bug] run time error when converting variational models to TorchScript", "user": {"login": "sjiang2018", "id": 41413582, "node_id": "MDQ6VXNlcjQxNDEzNTgy", "avatar_url": "https://avatars.githubusercontent.com/u/41413582?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sjiang2018", "html_url": "https://github.com/sjiang2018", "followers_url": "https://api.github.com/users/sjiang2018/followers", "following_url": "https://api.github.com/users/sjiang2018/following{/other_user}", "gists_url": "https://api.github.com/users/sjiang2018/gists{/gist_id}", "starred_url": "https://api.github.com/users/sjiang2018/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sjiang2018/subscriptions", "organizations_url": "https://api.github.com/users/sjiang2018/orgs", "repos_url": "https://api.github.com/users/sjiang2018/repos", "events_url": "https://api.github.com/users/sjiang2018/events{/privacy}", "received_events_url": "https://api.github.com/users/sjiang2018/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-03-28T03:37:55Z", "updated_at": "2020-03-29T05:17:04Z", "closed_at": "2020-03-29T05:17:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\ntraced_model saving issue\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n# Your code goes here\r\nclass MeanVarModelWrapper(nn.Module):\r\n    def __init__(self, gp):\r\n        super().__init__()\r\n        self.gp = gp\r\n\r\n    def forward(self, x):\r\n        output_dist = self.gp(x)\r\n        return output_dist.mean, output_dist.variance\r\n\r\n\r\ndef save_gp(model, test_x):\r\n    wrapped_model = MeanVarModelWrapper(model)\r\n    with torch.no_grad():\r\n        fake_input = test_x\r\n        pred = wrapped_model(fake_input)  # Compute caches\r\n        traced_model = torch.jit.trace(wrapped_model, fake_input, check_trace=False)\r\n        logging.info(\"saving model\")\r\n    traced_model.save('/tmp/traced_gp_example.pt')\r\n\r\n# Please make sure it does not require any external dependencies (other than PyTorch!)\r\n# (We much prefer small snippets rather than links to existing libraries!)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n  File \"./gp_regression/gpytorch_train_example.py\", line 127, in <module>\r\n    save_gp(gp_model, test_x)\r\n  File \"./gp_regression/gpytorch_train_example.py\", line 107, in save_gp\r\n    traced_model.save('/tmp/traced_gp_example.pt')\r\n  File \"/home/sjiang/.local/lib/python3.6/site-packages/torch/jit/__init__.py\", line 1626, in save\r\n    return self._c.save(*args, **kwargs)\r\nRuntimeError: \r\nCould not export Python function call 'MaternCovariance'. Remove calls to Python functions before export. Did you forget add @script or @script_method annotation? If this is a nn.ModuleList, add it to __constants__:\r\n\r\n// Paste the bad output here!\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` -->\r\n- <!-- PyTorch Version (run `print(torch.__version__)` -->\r\n- <!-- Computer OS -->\r\n\r\n## Additional context\r\nI am following the instruction listed here\r\nhttps://github.com/cornellius-gp/gpytorch/blob/ff1881b5fe92147f5e34e4141c0d5255e2650fdc/examples/08_Advanced_Usage/TorchScript_Variational_Models.ipynb\r\nexcept:\r\nself.covar_module = MaternKernel()\r\n\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1088/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1088/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1085", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1085/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1085/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1085/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1085", "id": 588192506, "node_id": "MDU6SXNzdWU1ODgxOTI1MDY=", "number": 1085, "title": "[Bug] SVGP mulitclass classification", "user": {"login": "lmao14", "id": 17412680, "node_id": "MDQ6VXNlcjE3NDEyNjgw", "avatar_url": "https://avatars.githubusercontent.com/u/17412680?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lmao14", "html_url": "https://github.com/lmao14", "followers_url": "https://api.github.com/users/lmao14/followers", "following_url": "https://api.github.com/users/lmao14/following{/other_user}", "gists_url": "https://api.github.com/users/lmao14/gists{/gist_id}", "starred_url": "https://api.github.com/users/lmao14/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lmao14/subscriptions", "organizations_url": "https://api.github.com/users/lmao14/orgs", "repos_url": "https://api.github.com/users/lmao14/repos", "events_url": "https://api.github.com/users/lmao14/events{/privacy}", "received_events_url": "https://api.github.com/users/lmao14/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-26T06:42:33Z", "updated_at": "2020-04-07T12:15:59Z", "closed_at": "2020-04-07T12:15:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\nHi!\r\nI am trying to implement a multiclass SVGP model and encounter an error. It seems due to a bug on slicing a Lazy Tensor.\r\n\r\n```python\r\nprint(gpytorch.__version__)\r\nprint(torch.__version__)\r\n\r\ncov = model.forward(X).lazy_covariance_matrix\r\nprint(cov.shape)\r\nprint(cov[..., :10, 20:].shape)\r\nprint(cov[..., :10, 20:].evaluate().shape)\r\nprint(cov.evaluate()[..., :10, 20:].shape)\r\n```\r\n\r\n```\r\n1.0.1\r\n1.3.1\r\ntorch.Size([3, 100, 100])\r\ntorch.Size([3, 10, 10])\r\ntorch.Size([3, 10, 10])\r\ntorch.Size([3, 10, 80])\r\n```\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nimport gpytorch\r\nimport numpy as np\r\n\r\n# Generate data\r\nN = 100\r\nnum_classes = 3\r\nX = np.random.rand(N, num_classes)\r\nY = np.argmax(X, 1).reshape(-1,).astype(int)\r\nX = torch.tensor(X).double()\r\nY = torch.tensor(Y).double()\r\ninducing_points = X[20:]\r\n\r\n# Define GP model\r\nclass GPClassificationModel(ApproximateGP):\r\n    def __init__(self, inducing_points, num_classes):\r\n        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0), batch_shape=torch.Size([num_classes]))\r\n        variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\r\n        variational_strategy = gpytorch.variational.MultitaskVariationalStrategy(\r\n            variational_strategy, num_tasks=num_classes,\r\n        )\r\n        super(GPClassificationModel, self).__init__(variational_strategy)\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([num_classes]))\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([num_classes])), batch_shape=torch.Size([num_classes])\r\n        )\r\n\r\n    def forward(self,x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nmodel = GPClassificationModel(inducing_points=inducing_points,num_classes=num_classes).double()\r\nlikelihood = gpytorch.likelihoods.SoftmaxLikelihood(num_classes=num_classes,mixing_weights=False).double()\r\n\r\n# Train\r\nmodel.train()\r\nlikelihood.train()\r\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\r\nmll = VariationalELBO(likelihood, model, Y.numel(), combine_terms=True)\r\nfor i in range(100):\r\n    optimizer.zero_grad()\r\n    output = model(X)\r\n    loss = -mll(output, Y)\r\n    loss.backward()\r\n    optimizer.step()\r\n    scheduler.step()\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-166-342ebe4bcdab> in <module>\r\n     41 for i in range(100):\r\n     42     optimizer.zero_grad()\r\n---> 43     output = model(X)\r\n     44     loss = -mll(output, Y)\r\n     45     loss.backward()\r\n\r\n~/anaconda3/envs/gpytorchgit/lib/python3.7/site-packages/gpytorch/models/approximate_gp.py in __call__(self, inputs, prior, **kwargs)\r\n     79         if inputs.dim() == 1:\r\n     80             inputs = inputs.unsqueeze(-1)\r\n---> 81         return self.variational_strategy(inputs, prior=prior)\r\n\r\n~/anaconda3/envs/gpytorchgit/lib/python3.7/site-packages/gpytorch/variational/multitask_variational_strategy.py in __call__(self, x, prior)\r\n     41 \r\n     42     def __call__(self, x, prior=False):\r\n---> 43         function_dist = self.base_variational_strategy(x, prior=prior)\r\n     44         if (\r\n     45             self.task_dim > 0\r\n\r\n~/anaconda3/envs/gpytorchgit/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py in __call__(self, x, prior)\r\n    163                 self.updated_strategy.fill_(True)\r\n    164 \r\n--> 165         return super().__call__(x, prior=prior)\r\n\r\n~/anaconda3/envs/gpytorchgit/lib/python3.7/site-packages/gpytorch/variational/_variational_strategy.py in __call__(self, x, prior)\r\n    125                 inducing_points,\r\n    126                 inducing_values=variational_dist_u.mean,\r\n--> 127                 variational_inducing_covar=variational_dist_u.lazy_covariance_matrix,\r\n    128             )\r\n    129         elif isinstance(variational_dist_u, Delta):\r\n\r\n~/anaconda3/envs/gpytorchgit/lib/python3.7/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     22 \r\n     23     def __call__(self, *inputs, **kwargs):\r\n---> 24         outputs = self.forward(*inputs, **kwargs)\r\n     25         if isinstance(outputs, list):\r\n     26             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/anaconda3/envs/gpytorchgit/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py in forward(self, x, inducing_points, inducing_values, variational_inducing_covar)\r\n    106                 interp_term.transpose(-1, -2), (inducing_values - self.prior_distribution.mean).unsqueeze(-1)\r\n    107             ).squeeze(-1)\r\n--> 108             + test_mean\r\n    109         )\r\n    110 \r\n\r\nRuntimeError: The size of tensor a (80) must match the size of tensor b (100) at non-singleton dimension 1\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1085/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1085/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1084", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1084/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1084/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1084/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1084", "id": 587659569, "node_id": "MDU6SXNzdWU1ODc2NTk1Njk=", "number": 1084, "title": "[Bug] Deep Kernel Learning -  face orientation extraction", "user": {"login": "denisilie94", "id": 5717520, "node_id": "MDQ6VXNlcjU3MTc1MjA=", "avatar_url": "https://avatars.githubusercontent.com/u/5717520?v=4", "gravatar_id": "", "url": "https://api.github.com/users/denisilie94", "html_url": "https://github.com/denisilie94", "followers_url": "https://api.github.com/users/denisilie94/followers", "following_url": "https://api.github.com/users/denisilie94/following{/other_user}", "gists_url": "https://api.github.com/users/denisilie94/gists{/gist_id}", "starred_url": "https://api.github.com/users/denisilie94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/denisilie94/subscriptions", "organizations_url": "https://api.github.com/users/denisilie94/orgs", "repos_url": "https://api.github.com/users/denisilie94/repos", "events_url": "https://api.github.com/users/denisilie94/events{/privacy}", "received_events_url": "https://api.github.com/users/denisilie94/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-25T12:25:40Z", "updated_at": "2020-04-06T23:43:45Z", "closed_at": "2020-04-06T23:43:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nHi,\r\n\r\nI am trying to implement the olivetti face orientation classification problem from https://arxiv.org/abs/1511.02222 with gpytorch. Unfortunetly I could not manage to solve the following error.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport os\r\nimport tqdm\r\nimport torch\r\nimport gpytorch\r\nimport numpy as np\r\nfrom matplotlib import pyplot as plt\r\n\r\n\r\n# Define a plotting function\r\ndef ax_plot(f, ax, y_labels, title):\r\n    im = ax.imshow(y_labels)\r\n    ax.set_title(title)\r\n    f.colorbar(im)\r\n    \r\n\r\n# Load Olivetti faces database\r\ndata = np.load('olivetti.npz')\r\n\r\ntrain_x = torch.Tensor(data['train_x'])\r\ntrain_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1], train_x.shape[2]))\r\ntrain_y = torch.Tensor(data['train_y'])\r\n\r\n\r\ntest_x = torch.Tensor(data['test_x'])\r\ntest_x = test_x.reshape((test_x.shape[0], 1, test_x.shape[1], test_x.shape[2]))\r\ntest_y = torch.Tensor(data['test_y'])\r\n\r\n\r\n# Create dataset\r\ndataset    = torch.utils.data.TensorDataset(train_x, train_y)\r\ndataloader = torch.utils.data.DataLoader(dataset) \r\n\r\nif torch.cuda.is_available():\r\n    train_x, train_y = train_x.cuda(), train_y.cuda()\r\n    \r\n    \r\n# Defining the DKL Feature Extractor\r\ndata_dim = train_x.size(-1)\r\n\r\nclass LargeFeatureExtractor(torch.nn.Sequential):           \r\n    def __init__(self):                                      \r\n        super(LargeFeatureExtractor, self).__init__()        \r\n        self.add_module('conv1', torch.nn.Conv2d(kernel_size=(5,5), stride=1, in_channels=1, out_channels=20))\r\n        self.add_module('pool1', torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2))                  \r\n        self.add_module('conv2', torch.nn.Conv2d(kernel_size=(5,5), stride=1, in_channels=20, out_channels=50))     \r\n        self.add_module('pool2', torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2))\r\n        self.add_module('flatt', torch.nn.Flatten())              \r\n        self.add_module('full3', torch.nn.Linear(800, 1000))\r\n        self.add_module('relu3', torch.nn.ReLU())\r\n        self.add_module('full4', torch.nn.Linear(1000, 500))                  \r\n        self.add_module('relu4', torch.nn.ReLU())\r\n        self.add_module('full5', torch.nn.Linear(500, 50))       \r\n        self.add_module('full6', torch.nn.Linear(50, 2))\r\n        \r\nfeature_extractor = LargeFeatureExtractor()\r\n\r\n\r\n# Defining the DKL-GP Model\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n        def __init__(self, train_x, train_y, likelihood):\r\n            super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n            self.mean_module = gpytorch.means.ConstantMean()\r\n            self.covar_module = gpytorch.kernels.GridInterpolationKernel(\r\n                gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=1)),\r\n                num_dims=2, grid_size=100\r\n            )\r\n            self.feature_extractor = feature_extractor\r\n\r\n        def forward(self, x):\r\n            # We're first putting our data through a deep net (feature extractor)\r\n            # We're also scaling the features so that they're nice values\r\n            projected_x = self.feature_extractor(x)\r\n            projected_x = projected_x - projected_x.min(0)[0]\r\n            projected_x = 2 * (projected_x / projected_x.max(0)[0]) - 1\r\n        \r\n            mean_x = self.mean_module(projected_x)\r\n            covar_x = self.covar_module(projected_x)\r\n            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n        \r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = GPRegressionModel(train_x, train_y, likelihood)\r\n\r\nif torch.cuda.is_available():\r\n    model = model.cuda()\r\n    likelihood = likelihood.cuda()\r\n    \r\n# Training the model\r\ntraining_iterations = 1\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.feature_extractor.parameters()},\r\n    {'params': model.covar_module.parameters()},\r\n    {'params': model.mean_module.parameters()},\r\n    {'params': model.likelihood.parameters()},\r\n], lr=0.01)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ndef train():\r\n    iterator = tqdm.tqdm_notebook(range(training_iterations))\r\n    for i in iterator:\r\n        # Zero backprop gradients\r\n        optimizer.zero_grad()\r\n        # Get output from model\r\n        output = model(train_x)\r\n        # Calc loss and backprop derivatives\r\n        loss = -mll(output, train_y)\r\n        loss.backward()\r\n        iterator.set_postfix(loss=loss.item())\r\n        optimizer.step()\r\n        \r\n# train model\r\ntrain()\r\n\r\n\r\n# Making predictions\r\nmodel.eval()\r\nlikelihood.eval()\r\nwith torch.no_grad(), gpytorch.settings.use_toeplitz(False), gpytorch.settings.fast_pred_var():\r\n    preds = model(test_x)\r\n\r\nprint('Test MAE: {}'.format(torch.mean(torch.abs(preds.mean - test_y))))\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-1-88b9df752e72>\", line 1, in <module>\r\n    runfile('/home/user/Desktop/dl-dev python/gp_examples/test.py', wdir='/home/user/Desktop/dl-dev python/gp_examples')\r\n\r\n  File \"/home/user/anaconda3/envs/dkl/lib/python3.6/site-packages/spyder_kernels/customize/spydercustomize.py\", line 827, in runfile\r\n    execfile(filename, namespace)\r\n\r\n  File \"/home/user/anaconda3/envs/dkl/lib/python3.6/site-packages/spyder_kernels/customize/spydercustomize.py\", line 110, in execfile\r\n    exec(compile(f.read(), filename, 'exec'), namespace)\r\n\r\n  File \"/home/user/Desktop/dl-dev python/gp_examples/test.py\", line 136, in <module>\r\n    preds = model(test_x)\r\n\r\n  File \"/home/user/anaconda3/envs/dkl/lib/python3.6/site-packages/gpytorch/models/exact_gp.py\", line 294, in __call__\r\n    likelihood=self.likelihood,\r\n\r\n  File \"/home/user/anaconda3/envs/dkl/lib/python3.6/site-packages/gpytorch/models/exact_prediction_strategies.py\", line 36, in prediction_strategy\r\n    return cls(train_inputs, train_prior_dist, train_labels, likelihood)\r\n\r\n  File \"/home/user/anaconda3/envs/dkl/lib/python3.6/site-packages/gpytorch/kernels/grid_interpolation_kernel.py\", line 205, in prediction_strategy\r\n    return InterpolatedPredictionStrategy(train_inputs, train_prior_dist, train_labels, likelihood)\r\n\r\n  File \"/home/user/anaconda3/envs/dkl/lib/python3.6/site-packages/gpytorch/models/exact_prediction_strategies.py\", line 380, in __init__\r\n    super().__init__(train_inputs, train_prior_dist, train_labels, likelihood)\r\n\r\n  File \"/home/user/anaconda3/envs/dkl/lib/python3.6/site-packages/gpytorch/models/exact_prediction_strategies.py\", line 50, in __init__\r\n    mvn = self.likelihood(train_prior_dist, train_inputs)\r\n\r\n  File \"/home/user/anaconda3/envs/dkl/lib/python3.6/site-packages/gpytorch/likelihoods/likelihood.py\", line 313, in __call__\r\n    return self.marginal(input, *args, **kwargs)\r\n\r\n  File \"/home/user/anaconda3/envs/dkl/lib/python3.6/site-packages/gpytorch/likelihoods/gaussian_likelihood.py\", line 76, in marginal\r\n    full_covar = covar + noise_covar\r\n\r\n  File \"/home/user/anaconda3/envs/dkl/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\", line 1626, in __add__\r\n    return AddedDiagLazyTensor(self, other)\r\n\r\n  File \"/home/user/anaconda3/envs/dkl/lib/python3.6/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\", line 27, in __init__\r\n    broadcasting._mul_broadcast_shape(lazy_tensors[0].shape, lazy_tensors[1].shape)\r\n\r\n  File \"/home/user/anaconda3/envs/dkl/lib/python3.6/site-packages/gpytorch/utils/broadcasting.py\", line 20, in _mul_broadcast_shape\r\n    raise RuntimeError(\"Shapes are not broadcastable for mul operation\")\r\n\r\nRuntimeError: Shapes are not broadcastable for mul operatio\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI seems that the train mode is working well, but the eval mode fails.\r\n\r\n## System information\r\n- GPyTorch Version 1.0.1\r\n- PyTorch Version 1.4.0\r\n- Computer OS Ubuntu 18.04.4 LTS\r\n\r\n## Additional context\r\nI may be missing something in the feature extractor...\r\n[dkl.zip](https://github.com/cornellius-gp/gpytorch/files/4380811/dkl.zip)", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1084/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1084/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1070", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1070/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1070/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1070/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1070", "id": 576365368, "node_id": "MDU6SXNzdWU1NzYzNjUzNjg=", "number": 1070, "title": "[Bug] Bug on Additive kernels", "user": {"login": "cauchy7203", "id": 9944333, "node_id": "MDQ6VXNlcjk5NDQzMzM=", "avatar_url": "https://avatars.githubusercontent.com/u/9944333?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cauchy7203", "html_url": "https://github.com/cauchy7203", "followers_url": "https://api.github.com/users/cauchy7203/followers", "following_url": "https://api.github.com/users/cauchy7203/following{/other_user}", "gists_url": "https://api.github.com/users/cauchy7203/gists{/gist_id}", "starred_url": "https://api.github.com/users/cauchy7203/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cauchy7203/subscriptions", "organizations_url": "https://api.github.com/users/cauchy7203/orgs", "repos_url": "https://api.github.com/users/cauchy7203/repos", "events_url": "https://api.github.com/users/cauchy7203/events{/privacy}", "received_events_url": "https://api.github.com/users/cauchy7203/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-05T16:09:23Z", "updated_at": "2022-09-22T11:49:55Z", "closed_at": "2022-09-22T11:49:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "I carefully checked the using of additive kernel, finding it is really a bug.\r\n\r\nSource code:\r\n``` python\r\n\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\nfrom gpytorch.kernels import *\r\n\r\ncovar_module =  LinearKernel(active_dims=torch.tensor([0])) + RBFKernel(active_dims=torch.tensor([1]))\r\nx1 = torch.randn(3, 2) # randomly generate a 3 x 2 matrix\r\n\r\nadditive_kernel_matrix = covar_module(x1)\r\ntensor_covar_matrix = lazy_covar_matrix.evaluate() \r\n\r\nprint(tensor_covar_matrix)\r\n```\r\n\r\n**See the results after 5 runs:**\r\n\r\ntensor([[0.0000, 0.0000, 0.0000],\r\n        [0.0000, 0.6931, 1.3863],\r\n        [0.0000, 1.3863, 2.7726]], grad_fn=<MmBackward>)\r\n\r\n\r\ntensor([[0.0000, 0.0000, 0.0000],\r\n        [0.0000, 0.6931, 1.3863],\r\n        [0.0000, 1.3863, 2.7726]], grad_fn=<MmBackward>)\r\n\r\ntensor([[0.0000, 0.0000, 0.0000],\r\n        [0.0000, 0.6931, 1.3863],\r\n        [0.0000, 1.3863, 2.7726]], grad_fn=<MmBackward>)\r\n\r\ntensor([[0.0000, 0.0000, 0.0000],\r\n        [0.0000, 0.6931, 1.3863],\r\n        [0.0000, 1.3863, 2.7726]], grad_fn=<MmBackward>)\r\n\r\ntensor([[0.0000, 0.0000, 0.0000],\r\n        [0.0000, 0.6931, 1.3863],\r\n        [0.0000, 1.3863, 2.7726]], grad_fn=<MmBackward>)\r\n\r\nNotice that the matrix  `x1` used here is randomly generated, but the results are always the same. \r\n\r\nThere must be something wrong in this module. \r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1070/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1070/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1065", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1065/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1065/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1065/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1065", "id": 573625597, "node_id": "MDU6SXNzdWU1NzM2MjU1OTc=", "number": 1065, "title": "[Bug] Lazy Tensor Internal Indexing Error for Large Variance Evaluation (MultitaskMultivariateNormal)", "user": {"login": "LemonPi", "id": 5508542, "node_id": "MDQ6VXNlcjU1MDg1NDI=", "avatar_url": "https://avatars.githubusercontent.com/u/5508542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LemonPi", "html_url": "https://github.com/LemonPi", "followers_url": "https://api.github.com/users/LemonPi/followers", "following_url": "https://api.github.com/users/LemonPi/following{/other_user}", "gists_url": "https://api.github.com/users/LemonPi/gists{/gist_id}", "starred_url": "https://api.github.com/users/LemonPi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LemonPi/subscriptions", "organizations_url": "https://api.github.com/users/LemonPi/orgs", "repos_url": "https://api.github.com/users/LemonPi/repos", "events_url": "https://api.github.com/users/LemonPi/events{/privacy}", "received_events_url": "https://api.github.com/users/LemonPi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1607679275, "node_id": "MDU6TGFiZWwxNjA3Njc5Mjc1", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/multitask", "name": "multitask", "color": "ffffff", "default": false, "description": "For questions about multitask models"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-03-01T22:15:35Z", "updated_at": "2020-04-07T17:08:47Z", "closed_at": "2020-04-07T17:08:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\nWhen calculating the `variance` of a `MultitaskMultivariateNormal`, evaluating `self.lazy_covariance_matrix.diag()` returns an indexing error when the number of query points is too large. When the number of data points is small (<150), inside the `MultitaskMultivariateNormal` we have\r\n```\r\nself.lazy_covariance_matrix.lazy_tensors\r\nOut[2]: \r\n(<gpytorch.lazy.non_lazy_tensor.NonLazyTensor at 0x125d53350>,\r\n <gpytorch.lazy.added_diag_lazy_tensor.AddedDiagLazyTensor at 0x12cd99050>)\r\n```\r\nBut when we increase the number of query points we get\r\n```\r\nself.lazy_covariance_matrix.lazy_tensors\r\nOut[4]: \r\n(<gpytorch.lazy.interpolated_lazy_tensor.InterpolatedLazyTensor at 0x131338410>,\r\n <gpytorch.lazy.matmul_lazy_tensor.MatmulLazyTensor at 0x131338550>,\r\n <gpytorch.lazy.block_diag_lazy_tensor.BlockDiagLazyTensor at 0x131338290>,\r\n <gpytorch.lazy.diag_lazy_tensor.DiagLazyTensor at 0x131338610>)\r\n```\r\nHaving different implementation strategy depending on size is fine, but the strategy for large batches errors out when evaluating variance.\r\n## To reproduce\r\nPretty much the Batch Independent Multioutput GP [tutorial](https://gpytorch.readthedocs.io/en/latest/examples/03_Multitask_Exact_GPs/Batch_Independent_Multioutput_GP.html) but increase the `ntest` to 200 (no problems if you use 51 as in the tutorial)\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\ntrain_x = torch.linspace(0, 1, 100)\r\nntest = 200\r\n\r\ntrain_y = torch.stack([\r\n    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.shape[0]) * 0.2,\r\n    torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.shape[0]) * 0.8,\r\n], -1)\r\nny = train_y.shape[1]\r\n\r\n\r\nclass BatchIndependentMultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super().__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([ny]))\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([ny])),\r\n            batch_shape=torch.Size([ny])\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultitaskMultivariateNormal.from_batch_mvn(\r\n            gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n        )\r\n\r\n\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=ny)\r\nmodel = BatchIndependentMultitaskGPModel(train_x, train_y, likelihood)\r\n\r\ntraining_iterations = 50\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n], lr=0.1)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iterations):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n    optimizer.step()\r\n# Set into eval mode\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\n# Initialize plots\r\nf, axes = plt.subplots(1, ny, figsize=(8, 3))\r\n\r\n# Make predictions\r\nwith torch.no_grad():\r\n    test_x = torch.linspace(0, 1, ntest)\r\n    xx = torch.stack([test_x, torch.linspace(0, 2, test_x.shape[0])], -1)\r\n    predictions = likelihood(model(test_x))\r\n    mean = predictions.mean\r\n    lower, upper = predictions.confidence_region()\r\n\r\n# This contains predictions for both tasks, flattened out\r\n# The first half of the predictions is for the first task\r\n# The second half is for the second task\r\n\r\nfor i in range(train_y.shape[1]):\r\n    # Plot training data as black stars\r\n    axes[i].plot(train_x.detach().numpy(), train_y[:, i].detach().numpy(), 'k*')\r\n    # Predictive mean as blue line\r\n    axes[i].plot(test_x.numpy(), mean[:, i].numpy(), 'b')\r\n    # Shade in confidence\r\n    axes[i].fill_between(test_x.numpy(), lower[:, i].numpy(), upper[:, i].numpy(), alpha=0.5)\r\n    axes[i].set_ylim([-3, 3])\r\naxes[-1].legend(['Observed Data', 'Mean', 'Confidence'])\r\naxes[-1].set_title('Observed Values (Likelihood)')\r\nplt.show()\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 88, in _getitem\r\n    x1 = x1[(*batch_indices, row_index, dim_index)]\r\nIndexError: too many indices for tensor of dimension 2\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/johnsonzhong/Research/meta_contact/simulation/temp.py\", line 70, in <module>\r\n    lower, upper = predictions.confidence_region()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/distributions/multivariate_normal.py\", line 80, in confidence_region\r\n    std2 = self.stddev.mul_(2)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/distributions/distribution.py\", line 111, in stddev\r\n    return self.variance.sqrt()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/distributions/multitask_multivariate_normal.py\", line 219, in variance\r\n    var = super().variance\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/distributions/multivariate_normal.py\", line 189, in variance\r\n    diag = self.lazy_covariance_matrix.diag()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/lazy/sum_lazy_tensor.py\", line 96, in diag\r\n    return sum(lazy_tensor.diag().contiguous() for lazy_tensor in self.lazy_tensors)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/lazy/sum_lazy_tensor.py\", line 96, in <genexpr>\r\n    return sum(lazy_tensor.diag().contiguous() for lazy_tensor in self.lazy_tensors)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/lazy/interpolated_lazy_tensor.py\", line 387, in diag\r\n    return super(InterpolatedLazyTensor, self).diag()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\", line 839, in diag\r\n    return self[..., row_col_iter, row_col_iter]\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\", line 1716, in __getitem__\r\n    res = self._get_indices(row_index, col_index, *batch_indices)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/lazy/interpolated_lazy_tensor.py\", line 110, in _get_indices\r\n    *[batch_index.view(*batch_index.shape, 1, 1) for batch_index in batch_indices],\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/lazy/block_interleaved_lazy_tensor.py\", line 58, in _get_indices\r\n    res = self.base_lazy_tensor._get_indices(row_index, col_index, *batch_indices, row_index_block)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\", line 294, in _get_indices\r\n    base_lazy_tensor = self._getitem(_noop_index, _noop_index, *batch_indices)._expand_batch(final_shape)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 97, in _getitem\r\n    f\"Attempting to tensor index a non-batch matrix's batch dimensions. \"\r\nRuntimeError: Attempting to tensor index a non-batch matrix's batch dimensions. Got batch index {batch_indices} but my shape was {self.shape}\r\n```\r\n\r\n## Expected Behavior\r\nCalculating variance should work the same regardless of number of query points.\r\n\r\n## System information\r\n\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> gpytorch 1.01\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> pytorch 1.3.1\r\n- <!-- Computer OS --> MacOS 10.15.3 \r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1065/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1065/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1064", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1064/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1064/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1064/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1064", "id": 573043361, "node_id": "MDU6SXNzdWU1NzMwNDMzNjE=", "number": 1064, "title": "BatchRepeatLazyTensor cannot evaluate when matrix is not square [Bug]", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-28T22:35:16Z", "updated_at": "2020-03-04T00:15:05Z", "closed_at": "2020-03-04T00:15:05Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nBatchRepeatLazyTensor is trying to expand the `rhs` in the `_matmul` method to look like the expected output when the `rhs` is not the same size as the expected output. \r\nFrom my limited tests, using torch batching standards is probably fine and the [batching expansions](https://github.com/cornellius-gp/gpytorch/blob/ae42649da8199b97a4bc2869708b6a97fc99dc70/gpytorch/lazy/batch_repeat_lazy_tensor.py#L98) (line 98-102) are unecessary as LazyTensors ought to be able to handle batched matmuls. \r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nx = torch.randn(256, 128)\r\nx_lazy = gpytorch.lazify(x)\r\nbatch_repeated_x = gpytorch.lazy.BatchRepeatLazyTensor(x_lazy, torch.Size((10,)))\r\nbatch_repeated_x.evaluate()\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nRuntimeError: The expanded size of the tensor (256) must match the existing size (128) at non-singleton dimension 1.  Target sizes: [10, 256, 128].  Tensor sizes: [10, 128, 128]\r\n```\r\n\r\n## Expected Behavior\r\n\r\nIt should evaluate. In particular, a 10 x 256 x 128 matrix should be returned.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch.1.0.1\r\n- torch 1.3.1\r\n\r\n## Additional context\r\nI believe that a potential fix is to have the `_matmul` method be simply `self.base_lazy_tensor._matmul(rhs)`.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1064/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1064/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1062", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1062/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1062/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1062/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1062", "id": 572136365, "node_id": "MDU6SXNzdWU1NzIxMzYzNjU=", "number": 1062, "title": "[Bug] ImportError in Fully Bayesian GPs Example", "user": {"login": "hmedal", "id": 1995032, "node_id": "MDQ6VXNlcjE5OTUwMzI=", "avatar_url": "https://avatars.githubusercontent.com/u/1995032?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hmedal", "html_url": "https://github.com/hmedal", "followers_url": "https://api.github.com/users/hmedal/followers", "following_url": "https://api.github.com/users/hmedal/following{/other_user}", "gists_url": "https://api.github.com/users/hmedal/gists{/gist_id}", "starred_url": "https://api.github.com/users/hmedal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hmedal/subscriptions", "organizations_url": "https://api.github.com/users/hmedal/orgs", "repos_url": "https://api.github.com/users/hmedal/repos", "events_url": "https://api.github.com/users/hmedal/events{/privacy}", "received_events_url": "https://api.github.com/users/hmedal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-02-27T14:58:13Z", "updated_at": "2020-03-04T00:33:49Z", "closed_at": "2020-03-04T00:33:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "I ran block `[4]` of this tutorial:\r\n\r\n[https://gpytorch.readthedocs.io/en/latest/examples/01_Exact_GPs/GP_Regression_Fully_Bayesian.html](url)\r\n\r\nand I got this error\r\n\r\n`ImportError: cannot import name 'LogNormalPrior' from 'gpytorch.priors'`\r\n\r\nNote: I installed pyro using `pip install pyro-ppl`", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1062/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1062/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1059", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1059/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1059/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1059/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1059", "id": 570217704, "node_id": "MDExOlB1bGxSZXF1ZXN0Mzc5Mjg5NjE0", "number": 1059, "title": "Make grid kernel work better with ARD", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-24T23:48:11Z", "updated_at": "2020-06-12T20:12:09Z", "closed_at": "2020-06-12T20:12:06Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1059", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1059", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1059.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1059.patch", "merged_at": "2020-06-12T20:12:06Z"}, "body": "Closes #1054 \r\n\r\nGridKernel and GridInterpKernel sometimes worked with ard (depending on the scale kernel ordering). This change makes GridKernel much more stable (and parallel) - and makes it so that ARD works with or without a scale kernel.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1059/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1059/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1058", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1058/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1058/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1058/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1058", "id": 570189160, "node_id": "MDExOlB1bGxSZXF1ZXN0Mzc5MjY1Njk5", "number": 1058, "title": "Fix issue in pytorch#master with tril_indices", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-02-24T22:33:33Z", "updated_at": "2020-02-24T22:42:47Z", "closed_at": "2020-02-24T22:42:43Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1058", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1058", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1058.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1058.patch", "merged_at": "2020-02-24T22:42:43Z"}, "body": "This fixes a recent change in the latest version of pytorch (see test failures [here](https://travis-ci.org/cornellius-gp/gpytorch/jobs/654636958?utm_medium=notification&utm_source=github_status))", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1058/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1058/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1056", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1056/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1056/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1056/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1056", "id": 570108682, "node_id": "MDU6SXNzdWU1NzAxMDg2ODI=", "number": 1056, "title": "[Bug] Multitask Exact GP + RBF kernel possibly malfunctioning ", "user": {"login": "YukiyaSaito", "id": 22481682, "node_id": "MDQ6VXNlcjIyNDgxNjgy", "avatar_url": "https://avatars.githubusercontent.com/u/22481682?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YukiyaSaito", "html_url": "https://github.com/YukiyaSaito", "followers_url": "https://api.github.com/users/YukiyaSaito/followers", "following_url": "https://api.github.com/users/YukiyaSaito/following{/other_user}", "gists_url": "https://api.github.com/users/YukiyaSaito/gists{/gist_id}", "starred_url": "https://api.github.com/users/YukiyaSaito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YukiyaSaito/subscriptions", "organizations_url": "https://api.github.com/users/YukiyaSaito/orgs", "repos_url": "https://api.github.com/users/YukiyaSaito/repos", "events_url": "https://api.github.com/users/YukiyaSaito/events{/privacy}", "received_events_url": "https://api.github.com/users/YukiyaSaito/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-02-24T20:00:31Z", "updated_at": "2020-02-25T00:40:03Z", "closed_at": "2020-02-25T00:40:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "# Context\r\n\r\nI have been trying to create a GP emulator for a computer model which maps 354-dimensional input onto 30-dimensional output.\r\nFor this purpose, I tried using Multitask Exact GP with RBF kernel. \r\nHowever, when I use a validation data set to see the generalization capability of this model, the model returns basically the same output for any input, with the whole scale being slightly varied.\r\n\r\nThe figure below shows this behaviour. \r\nIf the GP emulator is perfect, all the points would lie on the y=x line.\r\n![RBF](https://user-images.githubusercontent.com/22481682/75186535-ed3a7500-56fc-11ea-82a5-e71457240d4f.png)\r\n\r\nWhereas if I use Matern kernel, prediction of the model is reasonably good (or bad):\r\n![Matern](https://user-images.githubusercontent.com/22481682/75185095-5cfb3080-56fa-11ea-9c22-77da049bd4d7.png)\r\n\r\nI cannot quite understand this behaviour with my limited experience, therefore I would appreciate any comment or insight regarding this issue.\r\n\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\nMy model is pretty much identical to the example shown in the Multitask Exact GP notebook.\r\nEverything is run on Google Colab with a GPU.\r\n\r\n### Install GPyTorch on Colab and Load packages\r\nInstalled version of GPyTorch is 1.0.1, and PyTorch version is 1.4.0 on Google Colab.\r\n```python\r\nimport math\r\nimport torch\r\n!pip install gpytorch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\n%matplotlib inline\r\n%load_ext autoreload\r\n%autoreload 2\r\n```\r\n\r\n### Load data\r\nMy training data is here: https://drive.google.co/open?id=1Tu3IUN6Xryi_wgtbBOhOY5sRCAf9h0-H\r\n```python\r\nimport numpy as np\r\nloaded = np.load('data_train.npz') #load data from data_train.npz\r\nlhd = loaded['s1n_var']\r\nabA_short_label = loaded['label']\r\nabA_short_data = loaded['data']\r\n\r\nnumsize = 10000 #train with 10000 points\r\n\r\ntrain_x = torch.empty(size=(numsize,354))\r\ntrain_y = torch.empty(size=(numsize, 30))\r\n\r\nfor i in range(354):\r\n    train_x[:,i] = torch.from_numpy(lhd[0:numsize,i])\r\nfor i in range(30):\r\n    train_y[:,i] = torch.from_numpy(abA_short_data[i,0:numsize]*10**3)\r\n    \r\nprint(train_x.shape)\r\nprint(train_y.shape)\r\n```\r\n\r\n### Model definition\r\n```python\r\nclass MultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.MultitaskMean(\r\n            gpytorch.means.ConstantMean(), num_tasks=30\r\n        )\r\n        self.covar_module = gpytorch.kernels.MultitaskKernel(\r\n            gpytorch.kernels.RBFKernel(), num_tasks=30, rank=1\r\n            #gpytorch.kernels.MaternKernel(nu=1.5), num_tasks=30, rank=1\r\n        )\r\n        #self.covar_module.initialize_from_data(train_x, train_y)\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\r\n\r\n\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=30)\r\nmodel = MultitaskGPModel(train_x, train_y, likelihood)\r\n\r\ntrain_x = train_x.cuda()\r\ntrain_y = train_y.cuda()\r\nmodel = model.cuda()\r\nlikelihood = likelihood.cuda()\r\n```\r\n\r\n### training\r\n```python\r\nimport os\r\nsmoke_test = ('CI' in os.environ)\r\ntraining_iterations = 2 if smoke_test else 500\r\n\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n], lr=0.01)\r\n\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iterations):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f  noise: %.3f' % (i + 1, training_iterations, loss.item(), model.likelihood.noise.item()))\r\n    optimizer.step()\r\n```\r\n### Load validation data\r\nMy validation data is here: https://drive.google.com/open?id=12sC7uCSxayZEEDK-TtIlF43o5DU-SB5p\r\n```python\r\nimport numpy as np\r\nloaded = np.load('./valid.npz') #load data from valid.npz\r\nlhd_valid = loaded['valid_s1n']\r\nvalid_label = loaded['valid_label']\r\nvalid_data = loaded['valid_data']\r\n\r\ntest_x = torch.empty(size=(2000,354))\r\ntest_y = torch.empty(size=(2000, 30))\r\n\r\nfor i in range(354):\r\n    test_x[:,i] = torch.from_numpy(lhd_valid[0:2000,i])\r\nfor i in range(30):\r\n    test_y[:,i] = torch.from_numpy(valid_data[i,0:2000]*10**3)\r\n\r\ntest_x = test_x.cuda()\r\ntest_y = test_y.cuda()\r\n\r\nprint(test_x.shape) #validation with 2000 points\r\nprint(test_y.shape)\r\n```\r\n\r\n### How my plots are generated\r\n```python\r\nfig, axs = plt.subplots(6,5,figsize=(30, 25))\r\nfor i in range(6):\r\n  for j in range(5):\r\n    axs[i,j].plot(pred_valid[:,5*i+j].cpu(), test_y[:,5*i+j].cpu(),'o',markersize=2)\r\n    axs[i,j].plot([0,20], [0,20], 'k-', alpha=0.75, zorder=0)\r\n    axs[i,j].set_title('$abundance$, $A = %d$'%valid_label[5*i+j,0])\r\n    axs[i,j].set_xlim(0,0.2)\r\n    axs[i,j].set_ylim(0,0.2)\r\nfor ax in axs.flat:\r\n    ax.set(xlabel='Prediction', ylabel='PRISM')\r\n\r\n# Hide x labels and tick labels for top plots and y ticks for right plots.\r\nfor ax in axs.flat:\r\n    ax.label_outer()\r\nplt.show()\r\n```\r\n\r\n## Expected Behavior\r\nExpected output would be something similar to the output with Matern kernel shown in the second figure above.\r\n\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version: 1.0.1\r\n- PyTorch Version: 1.4.0\r\n- GPU: NVIDIA Tesla T4 (on Google Colab)\r\n- CUDA Version: 10.1\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1056/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1056/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1054", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1054/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1054/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1054/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1054", "id": 569530914, "node_id": "MDU6SXNzdWU1Njk1MzA5MTQ=", "number": 1054, "title": "[Question] Way to use ard_num_dims ", "user": {"login": "yosungho", "id": 31395364, "node_id": "MDQ6VXNlcjMxMzk1MzY0", "avatar_url": "https://avatars.githubusercontent.com/u/31395364?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yosungho", "html_url": "https://github.com/yosungho", "followers_url": "https://api.github.com/users/yosungho/followers", "following_url": "https://api.github.com/users/yosungho/following{/other_user}", "gists_url": "https://api.github.com/users/yosungho/gists{/gist_id}", "starred_url": "https://api.github.com/users/yosungho/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yosungho/subscriptions", "organizations_url": "https://api.github.com/users/yosungho/orgs", "repos_url": "https://api.github.com/users/yosungho/repos", "events_url": "https://api.github.com/users/yosungho/events{/privacy}", "received_events_url": "https://api.github.com/users/yosungho/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-02-23T17:42:02Z", "updated_at": "2020-02-26T02:56:22Z", "closed_at": "2020-02-26T02:56:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "Thanks for sharing your great tool. I have a question for using ard_num_dims.\r\nI am modifying my code to use different length-scale at each grid axis.\r\nBut, I am getting the error and do not understand what part is going wrong.\r\n\r\nPlease help me find any clue.\r\n\r\n**Error Message:**\r\n**RuntimeError: Expected the input to have 2 dimensionality (based on the ard_num_dims argument). Got 1.**\r\nSince my test_x input is 2 dimension [478555, 2], I especially do not understand why it received only 1.\r\n\r\n**Train and Test Data Size**\r\ntrain_x:  torch.Size([20486, 2])\r\ntrain_y:  torch.Size([20486])\r\ntest_x:  torch.Size([478555, 2])\r\n\r\n**Code Modification**\r\nard_num_dims = 2\r\n'covar_module.base_kernel.lengthscale': torch.tensor([0.1, 0.1]) # originally it was torch.tensor(0.1)\r\n\r\n```ruby\r\nclass GridGPRegressionModel(gpytorch.models.ExactGP):\r\n        def __init__(self, train_x, train_y, likelihood):\r\n            super(GridGPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n            \r\n            # SKI requires a grid size hyperparameter. This util can help with that\r\n            grid_size = gpytorch.utils.grid.choose_grid_size(train_x)\r\n\r\n            self.mean_module = gpytorch.means.ConstantMean()\r\n            self.covar_module = gpytorch.kernels.GridInterpolationKernel(gpytorch.kernels.MaternKernel(nu=nu_factor, ard_num_dims = 2), grid_size=grid_size, num_dims=2)\r\n            \r\n        def forward(self, x):\r\n            mean_x = self.mean_module(x)\r\n            covar_x = self.covar_module(x)\r\n            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nlikelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=noises, learn_additional_noise=False)\r\nmodel = GridGPRegressionModel(train_x, train_y, likelihood)\r\n\r\nhypers = {\r\n        'covar_module.base_kernel.lengthscale': torch.tensor([0.1, 0.1]),\r\n        }\r\nmodel.initialize(**hypers)\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.settings.max_root_decomposition_size(30):\r\n        observed_pred = (model(test_x.float()))\r\n\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1054/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1054/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1049", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1049/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1049/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1049/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1049", "id": 566228856, "node_id": "MDU6SXNzdWU1NjYyMjg4NTY=", "number": 1049, "title": "[Bug] Spectral Mixture Kernel initialization bug", "user": {"login": "ennichita", "id": 59562544, "node_id": "MDQ6VXNlcjU5NTYyNTQ0", "avatar_url": "https://avatars.githubusercontent.com/u/59562544?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ennichita", "html_url": "https://github.com/ennichita", "followers_url": "https://api.github.com/users/ennichita/followers", "following_url": "https://api.github.com/users/ennichita/following{/other_user}", "gists_url": "https://api.github.com/users/ennichita/gists{/gist_id}", "starred_url": "https://api.github.com/users/ennichita/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ennichita/subscriptions", "organizations_url": "https://api.github.com/users/ennichita/orgs", "repos_url": "https://api.github.com/users/ennichita/repos", "events_url": "https://api.github.com/users/ennichita/events{/privacy}", "received_events_url": "https://api.github.com/users/ennichita/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-17T11:13:27Z", "updated_at": "2020-02-21T18:32:49Z", "closed_at": "2020-02-21T18:32:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nSpectral kernel initialize_from_data fails for particular types of data. In this case, if one of the dimensions of the training data is equal for all points, the initialization fails.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n\r\nfrom gpytorch.kernels import SpectralMixtureKernel\r\n\r\nX = torch.randint(0, 2, (100, 200))\r\nY = torch.randn(100)\r\n\r\nfor i in X:\r\n    i[0] = 0\r\n    \r\ncovar_module = SpectralMixtureKernel(num_mixtures=4, ard_num_dims=200)\r\ncovar_module.initialize_from_data(X, Y)\r\n\r\n```\r\n```\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-175-3388eb419418> in <module>\r\n      8 \r\n      9 covar_module = SpectralMixtureKernel(num_mixtures=4, ard_num_dims=200)\r\n---> 10 covar_module.initialize_from_data(X, Y)\r\n\r\n~/anaconda3/envs/gpmodel/lib/python3.7/site-packages/gpytorch/kernels/spectral_mixture_kernel.py in initialize_from_data(self, train_x, train_y, **kwargs)\r\n    162         min_dist = torch.zeros(1, self.ard_num_dims, dtype=train_x.dtype, device=train_x.device)\r\n    163         for ind in range(self.ard_num_dims):\r\n--> 164             min_dist[:, ind] = min_dist_sort[(torch.nonzero(min_dist_sort[:, ind]))[0], ind]\r\n    165 \r\n    166         # Inverse of lengthscales should be drawn from truncated Gaussian | N(0, max_dist^2) |\r\n\r\nIndexError: index 0 is out of bounds for dimension 0 with size 0\r\n\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThe kernel should be initialized for the data.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 1.0.1\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> 1.4.0\r\n- <!-- Computer OS --> OSX\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1049/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1049/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1046", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1046/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1046/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1046/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1046", "id": 564311038, "node_id": "MDU6SXNzdWU1NjQzMTEwMzg=", "number": 1046, "title": "[Docs] Need help in loading a Full Bayesian model that uses Pyro for MCMC", "user": {"login": "natarajanmolecule", "id": 59585102, "node_id": "MDQ6VXNlcjU5NTg1MTAy", "avatar_url": "https://avatars.githubusercontent.com/u/59585102?v=4", "gravatar_id": "", "url": "https://api.github.com/users/natarajanmolecule", "html_url": "https://github.com/natarajanmolecule", "followers_url": "https://api.github.com/users/natarajanmolecule/followers", "following_url": "https://api.github.com/users/natarajanmolecule/following{/other_user}", "gists_url": "https://api.github.com/users/natarajanmolecule/gists{/gist_id}", "starred_url": "https://api.github.com/users/natarajanmolecule/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/natarajanmolecule/subscriptions", "organizations_url": "https://api.github.com/users/natarajanmolecule/orgs", "repos_url": "https://api.github.com/users/natarajanmolecule/repos", "events_url": "https://api.github.com/users/natarajanmolecule/events{/privacy}", "received_events_url": "https://api.github.com/users/natarajanmolecule/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 956525576, "node_id": "MDU6TGFiZWw5NTY1MjU1NzY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/documentation", "name": "documentation", "color": "e2b188", "default": true, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 11, "created_at": "2020-02-12T22:17:41Z", "updated_at": "2020-03-23T15:48:20Z", "closed_at": "2020-03-23T15:48:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to build a fully Bayesian GP with MCMC sampled parameters using Pyro based on the documentation. When I try to save and then load the model (using the save/load model documentation) later, I get an error about size mismatch: \r\n\r\nRuntimeError: Error(s) in loading state_dict for ExactGPModel:\r\n\tsize mismatch for likelihood.noise_covar.raw_noise: copying a param with shape torch.Size([100, 1]) from checkpoint, the shape in current model is torch.Size([1]).\r\n\tsize mismatch for mean_module.constant: copying a param with shape torch.Size([100, 1]) from checkpoint, the shape in current model is torch.Size([1]).\r\n\tsize mismatch for covar_module.base_kernel.raw_lengthscale: copying a param with shape torch.Size([100, 1, 13]) from checkpoint, the shape in current model is torch.Size([1, 13]).\r\n\r\nIn this case, my dataset has 13 features, and I have run a NUTS sampler for 100 samples when i originally built the model. \r\nI think this is because when I instantiate ExactGPModel as indicated in the documentation, it is allocating only one sample for the different hyperparameters. Any thoughts on how to get around this error? It will also be great to include such an example in the saving and loading documentation.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1046/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1046/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1043", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1043/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1043/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1043/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1043", "id": 563757602, "node_id": "MDU6SXNzdWU1NjM3NTc2MDI=", "number": 1043, "title": "[Question] Implementing Sparse GPs for Batch Independent MultiOutputs", "user": {"login": "acxz", "id": 17132214, "node_id": "MDQ6VXNlcjE3MTMyMjE0", "avatar_url": "https://avatars.githubusercontent.com/u/17132214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/acxz", "html_url": "https://github.com/acxz", "followers_url": "https://api.github.com/users/acxz/followers", "following_url": "https://api.github.com/users/acxz/following{/other_user}", "gists_url": "https://api.github.com/users/acxz/gists{/gist_id}", "starred_url": "https://api.github.com/users/acxz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/acxz/subscriptions", "organizations_url": "https://api.github.com/users/acxz/orgs", "repos_url": "https://api.github.com/users/acxz/repos", "events_url": "https://api.github.com/users/acxz/events{/privacy}", "received_events_url": "https://api.github.com/users/acxz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-02-12T05:10:10Z", "updated_at": "2020-10-09T16:33:06Z", "closed_at": "2020-02-18T03:57:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# Question\r\n\r\nNot a bug, sorry for the incorrect label, maybe docs/examples would have been better.\r\n\r\nI am trying to implement a Sparse GP that takes in a multidimensional input and has an independent multidimensional output. For the regular Exact GP case, I understand adding `batch_shape=torch.Size([dim_output])` to the `means` and `kernels` methods (along with `num_tasks=dim_output` to the likelihood) does the trick. However for SparseGP with an `InducingPointKernel` when I add `batch_shape=torch.Size([dim_output])` I get the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"multioutput-sgp-example.py\", line 57, in <module>\r\n    model = BatchIndependentMultitaskSGPModel(train_x, train_y, likelihood)\r\n  File \"multioutput-sgp-example.py\", line 41, in __init__\r\n    self.covar_module = gpytorch.kernels.InducingPointKernel(\r\nTypeError: __init__() got an unexpected keyword argument 'batch_shape'\r\n```\r\nNot adding `batch_shape` to the `InducingPointKernel` I get the following:\r\n```\r\nTraceback (most recent call last):\r\n  File \"multioutput-sgp-example.py\", line 82, in <module>\r\n    loss = -mll(output, train_y)\r\n  File \"/usr/lib/python3.8/site-packages/gpytorch/module.py\", line 24, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/usr/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\", line 55, in forward\r\n    res = res.add(added_loss_term.loss(*params))\r\n  File \"/usr/lib/python3.8/site-packages/gpytorch/mlls/inducing_point_kernel_added_loss_term.py\", line 18, in loss\r\n    return 0.5 * (diag / noise_diag).sum()\r\nRuntimeError: The size of tensor a (100) must match the size of tensor b (36) at non-singleton dimension 1\r\n```\r\n100 is my sample size and 6 is my output dimension.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\n\r\ntrain_x = torch.randn(100, 9)\r\n\r\ntrain_y = torch.stack([\r\n    torch.sin(train_x[:,0] * (2 * math.pi)) + torch.randn(100) * 0.2,\r\n    torch.cos(train_x[:,1] * (2 * math.pi)) + torch.randn(100) * 0.2,\r\n    torch.sin(train_x[:,2] * (2 * math.pi)) + torch.randn(100) * 0.2,\r\n    torch.cos(train_x[:,3] * (2 * math.pi)) + torch.randn(100) * 0.2,\r\n    torch.sin(train_x[:,4] * (2 * math.pi)) + torch.randn(100) * 0.2,\r\n    torch.cos(train_x[:,5] * (2 * math.pi)) + torch.randn(100) * 0.2,\r\n], -1)\r\n\r\n#test_x = torch.linspace(0, 1, 51)\r\ntest_x = torch.randn(51, 6)\r\n\r\n# Load data onto GPU\r\nif torch.cuda.is_available():\r\n    train_x = train_x.cuda()\r\n    train_y = train_y.cuda()\r\n    test_x = test_x.cuda()\r\n\r\nclass BatchIndependentMultitaskSGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super().__init__(train_x, train_y, likelihood)\r\n\r\n        # INPUT: num_inducing_points\r\n        num_inducing_points = 30\r\n        \r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([6]))\r\n        self.base_covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([6])),\r\n            batch_shape=torch.Size([6])\r\n        )\r\n\r\n        self.covar_module = gpytorch.kernels.InducingPointKernel(\r\n            self.base_covar_module,\r\n            inducing_points=train_x[:num_inducing_points],\r\n            #batch_shape=torch.Size([6]),    \r\n            likelihood=likelihood\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultitaskMultivariateNormal.from_batch_mvn(\r\n            gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n        )\r\n\r\n\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=6)\r\nmodel = BatchIndependentMultitaskSGPModel(train_x, train_y, likelihood)\r\n\r\n# Load model onto GPU\r\nif torch.cuda.is_available():\r\n    model = model.cuda()\r\n    likelihood = likelihood.cuda()\r\n    \r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n], lr=0.1)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ntraining_iterations = 50\r\n\r\nfor i in range(training_iterations):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n    optimizer.step()\r\n  \r\n```\r\n\r\n** Stack trace/error message **\r\nSee above error messages\r\n\r\n## Expected Behavior\r\n\r\nIdeally I should be able to use Sparse GPs in a multi input/ multi output fashion. When adding an InducingPointKernel to existing regular multi input/ multi output Exact GP, (thereby turning it into a SGP model) the model should train and predict properly.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version: 1.0.1`\r\n- PyTorch Version: 1.4.0`\r\n- ArchLinux", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1043/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1043/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1039", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1039/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1039/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1039/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1039", "id": 559662539, "node_id": "MDU6SXNzdWU1NTk2NjI1Mzk=", "number": 1039, "title": "Can't get Batch Independent GP to fit a single point", "user": {"login": "rlrs", "id": 7533072, "node_id": "MDQ6VXNlcjc1MzMwNzI=", "avatar_url": "https://avatars.githubusercontent.com/u/7533072?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rlrs", "html_url": "https://github.com/rlrs", "followers_url": "https://api.github.com/users/rlrs/followers", "following_url": "https://api.github.com/users/rlrs/following{/other_user}", "gists_url": "https://api.github.com/users/rlrs/gists{/gist_id}", "starred_url": "https://api.github.com/users/rlrs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rlrs/subscriptions", "organizations_url": "https://api.github.com/users/rlrs/orgs", "repos_url": "https://api.github.com/users/rlrs/repos", "events_url": "https://api.github.com/users/rlrs/events{/privacy}", "received_events_url": "https://api.github.com/users/rlrs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 623304447, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDc=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/duplicate", "name": "duplicate", "color": "cccccc", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}, {"id": 1607679275, "node_id": "MDU6TGFiZWwxNjA3Njc5Mjc1", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/multitask", "name": "multitask", "color": "ffffff", "default": false, "description": "For questions about multitask models"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-02-04T11:39:01Z", "updated_at": "2020-04-07T15:58:08Z", "closed_at": "2020-04-07T15:58:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to obtain a simple multi-output GP in GPytorch, but I'm having some trouble. I followed the code in the docs for batch independent GPs, but when I test it on even a single training point it does not fit it correctly. Am I doing something wrong? Below is a small example:\r\n\r\n```\r\nimport torch\r\nimport gpytorch\r\n\r\nN = 1  # number of training points\r\nD = 1  # input dimensions\r\nK = 2  # target dimensions\r\n\r\nclass ExactGP(gpytorch.models.ExactGP):\r\n    def __init__(self, X_train, Y_train, likelihood):\r\n        super().__init__(X_train, Y_train, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([K]))\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(batch_shape=torch.Size([K])), batch_shape=torch.Size([K]))\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultitaskMultivariateNormal.from_batch_mvn(gpytorch.distributions.MultivariateNormal(mean_x, covar_x))\r\n\r\nX_train = torch.randn(N, D)\r\nY_train = torch.randn(N, K)\r\nprint(\"Y_train[0]:\", Y_train[0])\r\n\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=K)\r\nlikelihood.noise = 1e-4\r\nmodel = ExactGP(X_train, Y_train, likelihood)\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\nmu = X_train[0:1, :]\r\nposterior = model(mu)\r\nprint(\"Posterior:\", posterior.mean, posterior.covariance_matrix)\r\n```\r\n\r\nExample output:\r\n\r\n> Y_train[0]: tensor([-0.5498, -0.7388])\r\n>Posterior: tensor([[-0.2749, -0.3693]], grad_fn=<ViewBackward>) tensor([[0.3466, 0.0000],\r\n        [0.0000, 0.3466]], grad_fn=<AddmmBackward>)\r\n\r\nIn this case the mean is off by a factor of 2, but this seems to depend on N? I hope I'm making some obvious mistake.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1039/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1039/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1033", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1033/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1033/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1033/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1033", "id": 557224227, "node_id": "MDU6SXNzdWU1NTcyMjQyMjc=", "number": 1033, "title": "[Bug] Error handling on model predictions", "user": {"login": "khameedk", "id": 7607375, "node_id": "MDQ6VXNlcjc2MDczNzU=", "avatar_url": "https://avatars.githubusercontent.com/u/7607375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/khameedk", "html_url": "https://github.com/khameedk", "followers_url": "https://api.github.com/users/khameedk/followers", "following_url": "https://api.github.com/users/khameedk/following{/other_user}", "gists_url": "https://api.github.com/users/khameedk/gists{/gist_id}", "starred_url": "https://api.github.com/users/khameedk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/khameedk/subscriptions", "organizations_url": "https://api.github.com/users/khameedk/orgs", "repos_url": "https://api.github.com/users/khameedk/repos", "events_url": "https://api.github.com/users/khameedk/events{/privacy}", "received_events_url": "https://api.github.com/users/khameedk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-01-30T02:05:32Z", "updated_at": "2021-06-10T14:48:45Z", "closed_at": "2021-06-10T14:48:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen running the code to train a Gaussian process, I get the following error. I haven't encountered an error thrown this way so I'm unable to debug it post-mortem. I've attached two input CSV files for the program, one of which throws the error (trained_agent.csv) and the other which doesn't. Files are linked below.\r\n[data_files.zip](https://github.com/cornellius-gp/gpytorch/files/4131815/data_files.zip) \r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\nimport torch\r\nimport gpytorch\r\n\r\n\r\nclass MultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\r\n        num_tasks = train_y.shape[-1]\r\n        self.mean_module = gpytorch.means.MultitaskMean(\r\n            gpytorch.means.ConstantMean(), num_tasks=num_tasks\r\n        )\r\n        self.covar_module = gpytorch.kernels.MultitaskKernel(\r\n            gpytorch.kernels.RBFKernel(), num_tasks=num_tasks, rank=1\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultitaskMultivariateNormal(\r\n            mean_x, covar_x\r\n        )\r\n\r\n\r\ndef check_for_tensor_and_convert(x):\r\n    \"\"\"Checks if the input is a torch.Tensor. If not, convert it. Also, returns as a float to ensure conformity between tensors.\r\n    \r\n    Args:\r\n        x (iterable): input data.\r\n    \r\n    Returns:\r\n        torch.Tensor: converted data.\r\n    \"\"\"\r\n    if not isinstance(x, torch.Tensor):\r\n        x = np.array(x)\r\n        x = torch.from_numpy(x)\r\n    return x.float()\r\n\r\n\r\ndef convert_array_from_string(array_as_string):\r\n    \"\"\"Converts a string that appears as a certain kind of list to a numerical array. For example, \"[1 2 3]\" will be converted to the array [1, 2, 3].\r\n    \r\n    Args:\r\n        array_as_string (str): The array as a string.\r\n    \r\n    Returns:\r\n        numpy.ndarray: The converted array.\r\n    \"\"\"\r\n    l = array_as_string[1:-1].split(' ')\r\n    array = [float(x) for x in l if x != '']\r\n    return np.array(array)\r\n\r\n\r\ndef import_episode_data_from_file(file_name):\r\n    \"\"\"Imports a file that can be used in a regresssion problem.\r\n    \r\n    Args:\r\n        file_name (str): The file containing the data.\r\n    \r\n    Returns:\r\n        np.array, np.array: Matrices corresponding to the predictors and\r\n        responses to be used for regression.\r\n    \"\"\"\r\n    df = pd.read_csv(file_name)\r\n    # convert string columns\r\n    df['image'] = df['image'].apply(convert_array_from_string)\r\n    df['action'] = df['action'].apply(convert_array_from_string)\r\n    df['action'] = np.roll(df['action'], -1)\r\n\r\n    def concat(row):\r\n        return np.concatenate( [row['action'], row['image']] )\r\n    predictors = df.apply(concat, axis=1)\r\n    predictors = np.vstack(predictors)\r\n    predictors = predictors[:-1, :]\r\n    responses = np.vstack(df['image'][1:])\r\n    return predictors, responses\r\n\r\n\r\ndef train_gp(model, likelihood, train_x, train_y, n_iter=2):\r\n    \"\"\"Trains a Gaussian process with the given training data.\r\n\r\n    Credit to https://gpytorch.readthedocs.io/en/latest/examples/01_Exact_GPs/Simple_GP_Regression.html#Training-the-model\r\n    \r\n    Args:\r\n        model (gpytorch.models.ExactGP): the model to train.\r\n        likelihood (gpytorch.mlls): A likelihood that is compatible with model.\r\n        for more info.\r\n        train_x (torch.Tensor): The training covariates, as a matrix.\r\n        train_y (torch.Tensor): The training responses, may be a vector or matrix.\r\n        n_iter (int, optional): The number of iterations to train the Gaussian process.\r\n    \r\n    Returns:\r\n        gpytorch.models.ExactGP, gpytorch.mlls): The trained model and the\r\n        likelihood used.\r\n    \"\"\"\r\n    # Find optimal model hyperparameters\r\n    model.train()\r\n    likelihood.train()\r\n    # Use the adam optimizer\r\n    optimizer = torch.optim.Adam([\r\n        {'params': model.parameters()}, # Includes GaussianLikelihood parameters\r\n    ], lr=0.01)\r\n\r\n    # \"Loss\" for GPs - the marginal log likelihood\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\n    for i in range(n_iter):\r\n        optimizer.zero_grad()\r\n        output = model(train_x)\r\n        loss = -mll(output, train_y)\r\n        loss.backward()\r\n        print('Iter %d/%d - Loss: %.3f' % (i + 1, n_iter, loss.item()))\r\n        optimizer.step()\r\n\r\n    return model, likelihood\r\n\r\n\r\nif __name__ == '__main__':\r\n    X, y = import_episode_data_from_file('logs/test_runs/trained_agent.csv')\r\n    X = check_for_tensor_and_convert(X)\r\n    y = check_for_tensor_and_convert(y)\r\n\r\n    likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(\r\n        num_tasks=y.shape[-1]\r\n    )\r\n    model = MultitaskGPModel(X, y, likelihood)\r\n    \r\n    model, likelihood = train_gp(\r\n        model, likelihood, X, y, n_iter=2\r\n    )\r\n\r\n    test_x = check_for_tensor_and_convert(np.ones((10, 34)))\r\n    model.training = False\r\n    with torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n        predictions = likelihood(model(test_x))\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 138, in <module>\r\n    predictions = likelihood(model(test_x))\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gpytorch\\models\\exact_gp.py\", line 326, in __call__\r\n    predictive_mean, predictive_covar = self.prediction_strategy.exact_prediction(full_mean, full_covar)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py\", line 302, in exact_prediction\r\n    self.exact_predictive_mean(test_mean, test_train_covar),\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py\", line 320, in exact_predictive_mean\r\n    res = (test_train_covar @ self.mean_cache.unsqueeze(-1)).squeeze(-1)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gpytorch\\utils\\memoize.py\", line 34, in g\r\n    add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py\", line 269, in mean_cache\r\n    mean_cache = train_train_covar.inv_matmul(train_labels_offset).squeeze(-1)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gpytorch\\lazy\\lazy_tensor.py\", line 939, in inv_matmul\r\n    return func.apply(self.representation_tree(), False, right_tensor, *self.representation())\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gpytorch\\functions\\_inv_matmul.py\", line 47, in forward\r\n    solves = _solve(lazy_tsr, right_tensor)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gpytorch\\functions\\_inv_matmul.py\", line 15, in _solve\r\n    return lazy_tsr._solve(rhs, preconditioner)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gpytorch\\lazy\\lazy_tensor.py\", line 655, in _solve\r\n    preconditioner=preconditioner,\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gpytorch\\utils\\linear_cg.py\", line 271, in linear_cg\r\n    curr_conjugate_vec,\r\nRuntimeError: Expected object of type Variable but found type CPUFloatType for argument #0 'self'\r\nThe above operation failed in interpreter, with the following stack trace:\r\nat C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gpytorch\\utils\\linear_cg.py:55:4\r\n    eps,\r\n    beta,\r\n    residual,\r\n    precond_residual,\r\n    mul_storage,\r\n    is_zero,\r\n    curr_conjugate_vec,\r\n):\r\n    torch.mul(curr_conjugate_vec, mvms, out=mul_storage)\r\n    torch.sum(mul_storage, dim=-2, keepdim=True, out=alpha)\r\n    ~~~~~~~~~ <--- HERE\r\n\r\n    # Do a safe division here\r\n    torch.lt(alpha, eps, out=is_zero)\r\n    alpha.masked_fill_(is_zero, 1)\r\n    torch.div(residual_inner_prod, alpha, out=alpha)\r\n    alpha.masked_fill_(is_zero, 0)\r\n\r\n    # We'll cancel out any updates by setting alpha=0 for any vector that has already converged\r\n    alpha.masked_fill_(has_converged, 0)\r\n```\r\n\r\n## Expected \r\n\r\nWith the given input data files, the program should simply print the training loss for each iteration and complete without errors. For example,\r\n\r\n```\r\nIter 1/2 - Loss: 12250.880\r\nIter 2/2 - Loss: 12203.549\r\n```\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version 1.0.1\r\n- PyTorch Version 1.3.0\r\n- Windows 10\r\n\r\n## Additional context\r\nThis happens to work on macOS Mojave Version 10.14.6, running GPyTorch version 0.3.6 and PyTorch version 1.3.0, with both files.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1033/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1033/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1024", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1024/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1024/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1024/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1024", "id": 550961550, "node_id": "MDU6SXNzdWU1NTA5NjE1NTA=", "number": 1024, "title": "[Bug] Batch Independent Multioutput GP returns an error at 4 outputs", "user": {"login": "GP781", "id": 59972706, "node_id": "MDQ6VXNlcjU5OTcyNzA2", "avatar_url": "https://avatars.githubusercontent.com/u/59972706?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GP781", "html_url": "https://github.com/GP781", "followers_url": "https://api.github.com/users/GP781/followers", "following_url": "https://api.github.com/users/GP781/following{/other_user}", "gists_url": "https://api.github.com/users/GP781/gists{/gist_id}", "starred_url": "https://api.github.com/users/GP781/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GP781/subscriptions", "organizations_url": "https://api.github.com/users/GP781/orgs", "repos_url": "https://api.github.com/users/GP781/repos", "events_url": "https://api.github.com/users/GP781/events{/privacy}", "received_events_url": "https://api.github.com/users/GP781/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}, {"id": 1607679275, "node_id": "MDU6TGFiZWwxNjA3Njc5Mjc1", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/multitask", "name": "multitask", "color": "ffffff", "default": false, "description": "For questions about multitask models"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-01-16T17:49:59Z", "updated_at": "2020-04-07T17:08:47Z", "closed_at": "2020-04-07T17:08:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen extending the notebook example [Batch Independent Multioutput GP](https://gpytorch.readthedocs.io/en/latest/examples/03_Multitask_Exact_GPs/Batch_Independent_Multioutput_GP.html) by two additional outputs GPyTorch returns _IndexError: too many indices for tensor of dimension 2_ and _RuntimeError: Attempting to tensor index a non-batch matrix's batch dimensions. Got batch index {batch_indices} but my shape was {self.shape}_. It seems that the line `lower, upper = predictions.confidence_region()` is the reason for that.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\ntrain_x = torch.linspace(0, 1, 100)\r\n\r\ntrain_y = torch.stack([\r\n    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n    torch.sin(train_x * math.pi) + torch.randn(train_x.size()) * 0.2,\r\n    torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\r\n    torch.cos(train_x * math.pi) + torch.randn(train_x.size()) * 0.2,\r\n], -1)\r\n\r\nclass BatchIndependentMultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super().__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([4]))\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([4])),\r\n            batch_shape=torch.Size([4])\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultitaskMultivariateNormal.from_batch_mvn(\r\n            gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n        )\r\n\r\n\r\nlikelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=4)\r\nmodel = BatchIndependentMultitaskGPModel(train_x, train_y, likelihood)\r\n\r\n# this is for running the notebook in our testing framework\r\nimport os\r\nsmoke_test = ('CI' in os.environ)\r\ntraining_iterations = 2 if smoke_test else 50\r\n\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n], lr=0.1)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iterations):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n    optimizer.step()\r\n\r\n# Set into eval mode\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\n# Initialize plots\r\nf, ((y1_ax, y2_ax), (y3_ax, y4_ax)) = plt.subplots(2, 2, figsize=(8, 3))\r\n\r\n# Make predictions\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    test_x = torch.linspace(0, 1, 51)\r\n    predictions = likelihood(model(test_x))\r\n    mean = predictions.mean\r\n    lower, upper = predictions.confidence_region()\r\n\r\n# This contains predictions for both tasks, flattened out\r\n# The first half of the predictions is for the first task\r\n# The second half is for the second task\r\n\r\n# Plot training data as black stars\r\ny1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\r\n# Predictive mean as blue line\r\ny1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\r\n# Shade in confidence\r\ny1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\r\ny1_ax.set_ylim([-3, 3])\r\ny1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\r\ny1_ax.set_title('Observed Values (Likelihood)')\r\n\r\n# Plot training data as black stars\r\ny2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\r\n# Predictive mean as blue line\r\ny2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\r\n# Shade in confidence\r\ny2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\r\ny2_ax.set_ylim([-3, 3])\r\ny2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\r\ny2_ax.set_title('Observed Values (Likelihood)')\r\n\r\n# Plot training data as black stars\r\ny3_ax.plot(train_x.detach().numpy(), train_y[:, 2].detach().numpy(), 'k*')\r\n# Predictive mean as blue line\r\ny3_ax.plot(test_x.numpy(), mean[:, 2].numpy(), 'b')\r\n# Shade in confidence\r\ny3_ax.fill_between(test_x.numpy(), lower[:, 2].numpy(), upper[:, 2].numpy(), alpha=0.5)\r\ny3_ax.set_ylim([-3, 3])\r\ny3_ax.legend(['Observed Data', 'Mean', 'Confidence'])\r\ny3_ax.set_title('Observed Values (Likelihood)')\r\n\r\n# Plot training data as black stars\r\ny4_ax.plot(train_x.detach().numpy(), train_y[:, 3].detach().numpy(), 'k*')\r\n# Predictive mean as blue line\r\ny4_ax.plot(test_x.numpy(), mean[:, 3].numpy(), 'b')\r\n# Shade in confidence\r\ny4_ax.fill_between(test_x.numpy(), lower[:, 3].numpy(), upper[:, 3].numpy(), alpha=0.5)\r\ny4_ax.set_ylim([-3, 3])\r\ny4_ax.legend(['Observed Data', 'Mean', 'Confidence'])\r\ny4_ax.set_title('Observed Values (Likelihood)')\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nRuntimeError: Attempting to tensor index a non-batch matrix's batch dimensions. Got batch index {batch_indices} but my shape was {self.shape}\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI'm attempting to use the [Batch Independent Multioutput GP](https://gpytorch.readthedocs.io/en/latest/examples/03_Multitask_Exact_GPs/Batch_Independent_Multioutput_GP.html) example to get additional outputs.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch v1.0.0\r\n- PyTorch v1.3.0\r\n- Windows\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1024/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1024/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1013", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1013/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1013/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1013/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1013", "id": 547674267, "node_id": "MDU6SXNzdWU1NDc2NzQyNjc=", "number": 1013, "title": "[Bug] Can't reproduce GPyTorch Regression Tutorial", "user": {"login": "ThiagoLira", "id": 11686042, "node_id": "MDQ6VXNlcjExNjg2MDQy", "avatar_url": "https://avatars.githubusercontent.com/u/11686042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ThiagoLira", "html_url": "https://github.com/ThiagoLira", "followers_url": "https://api.github.com/users/ThiagoLira/followers", "following_url": "https://api.github.com/users/ThiagoLira/following{/other_user}", "gists_url": "https://api.github.com/users/ThiagoLira/gists{/gist_id}", "starred_url": "https://api.github.com/users/ThiagoLira/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ThiagoLira/subscriptions", "organizations_url": "https://api.github.com/users/ThiagoLira/orgs", "repos_url": "https://api.github.com/users/ThiagoLira/repos", "events_url": "https://api.github.com/users/ThiagoLira/events{/privacy}", "received_events_url": "https://api.github.com/users/ThiagoLira/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-01-09T19:27:58Z", "updated_at": "2020-01-09T20:53:38Z", "closed_at": "2020-01-09T20:53:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThe training loop on the example yields an error.\r\n\r\n## To reproduce\r\n\r\nJust copy the code from https://gpytorch.readthedocs.io/en/latest/examples/01_Exact_GPs/Simple_GP_Regression.html\r\n\r\n** Stack trace/error message **\r\n\r\n/usr/local/lib/python3.7/site-packages/gpytorch/utils/pivoted_cholesky.py in woodbury_factor(low_rank_mat, shift)\r\n    100     shifted_mat = shifted_mat + torch.eye(k, dtype=shifted_mat.dtype, device=shifted_mat.device)\r\n    101 \r\n--> 102     R = torch.potrs(low_rank_mat, torch.cholesky(shifted_mat, upper=True))\r\n    103     return R\r\n    104 \r\n\r\n**AttributeError: module 'torch' has no attribute 'potrs'**\r\n\r\n## Expected Behavior\r\n\r\nModel trains without further errors.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version 1.0.0 <!--  -->\r\n- PyTorch Version  1.3.1  <!--  -->\r\n- Computer OS  MacOS Catalina<!--  -->\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1013/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1013/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1012", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1012/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1012/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1012/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1012", "id": 546565905, "node_id": "MDExOlB1bGxSZXF1ZXN0MzYwMjIwNjM3", "number": 1012, "title": "Dont squeeze kernel vector outputs in PeriodicKernel", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-01-07T23:40:47Z", "updated_at": "2020-01-09T13:38:40Z", "closed_at": "2020-01-09T13:38:36Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/1012", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/1012", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/1012.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/1012.patch", "merged_at": "2020-01-09T13:38:36Z"}, "body": "On master, the following breaks:\r\n```python\r\nfrom gpytorch.kernels import PeriodicKernel\r\nkern = PeriodicKernel()\r\nx1 = torch.randn(1, 1)  # Code works if x1 is any n x d other than 1 x d\r\nx2 = torch.randn(5, 1)\r\nK = kern(x1, x2).evaluate()\r\n```\r\nClearly, this should not break :-). In our defense, GPyTorch returns exactly the error you'd hope:\r\n```python\r\nRuntimeError: The expected shape of the kernel was torch.Size([1, 5]), but got torch.Size([5]). This is likely a bug in GPyTorch.\r\n```\r\nbut clearly we should add some unit tests for edge cases like this. \r\n\r\nFixes #1011 ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1012/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 1, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1012/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1011", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1011/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1011/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1011/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1011", "id": 546277900, "node_id": "MDU6SXNzdWU1NDYyNzc5MDA=", "number": 1011, "title": "[Bug] IndexError when GridInterpolationKernel wraps a PeriodicKernel", "user": {"login": "vvvvalvalval", "id": 5859120, "node_id": "MDQ6VXNlcjU4NTkxMjA=", "avatar_url": "https://avatars.githubusercontent.com/u/5859120?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vvvvalvalval", "html_url": "https://github.com/vvvvalvalval", "followers_url": "https://api.github.com/users/vvvvalvalval/followers", "following_url": "https://api.github.com/users/vvvvalvalval/following{/other_user}", "gists_url": "https://api.github.com/users/vvvvalvalval/gists{/gist_id}", "starred_url": "https://api.github.com/users/vvvvalvalval/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vvvvalvalval/subscriptions", "organizations_url": "https://api.github.com/users/vvvvalvalval/orgs", "repos_url": "https://api.github.com/users/vvvvalvalval/repos", "events_url": "https://api.github.com/users/vvvvalvalval/events{/privacy}", "received_events_url": "https://api.github.com/users/vvvvalvalval/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-01-07T13:17:10Z", "updated_at": "2020-01-09T13:38:36Z", "closed_at": "2020-01-09T13:38:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI tried to adapt the [KISS-GP for 1D data tutorial](https://gpytorch.readthedocs.io/en/latest/examples/02_Scalable_Exact_GPs/KISSGP_Regression.html#KISS-GP-for-1D-Data) to use a `PeriodicKernel` instead of an `RBFKernel`.\r\n\r\nHowever, trying to evaluate the MLL fails with an `IndexError: Dimension out of range (expected to be in range of [-1, 0], but got -2)`, thrown from [grid_kernel.py: 133](https://github.com/cornellius-gp/gpytorch/blob/0317b121ebaaa921a7851a6af4f2219ff18eeaf0/gpytorch/kernels/grid_kernel.py#L133).\r\n\r\nIt seems to me this can only be a bug, as an RBF kernel and a Periodic kernel are really not very different semantically?\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n\r\n```python\r\n#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Tue Jan  7 13:52:48 2020\r\n\r\n@author: val\r\n\"\"\"\r\n\r\n\r\nimport math\r\nimport torch\r\nimport gpytorch\r\n\r\n#%matplotlib inline\r\n\r\ntrain_x = torch.linspace(0, 1, 1000)\r\ntrain_y = torch.sin(train_x * (4 * math.pi) + torch.randn(train_x.size()) * 0.2)\r\n\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n\r\n        # SKI requires a grid size hyperparameter. This util can help with that. Here we are using a grid that has the same number of points as the training data (a ratio of 1.0). Performance can be sensitive to this parameter, so you may want to adjust it for your own problem on a validation set.\r\n        grid_size = gpytorch.utils.grid.choose_grid_size(train_x,1.0)\r\n\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.GridInterpolationKernel(    \r\n                ## NOTE the only difference from the 1D KISS-GP tutorial is that the RBFKernel got replaced with a PeriodicKernel()\r\n                gpytorch.kernels.PeriodicKernel(), #gpytorch.kernels.RBFKernel(),\r\n                grid_size=grid_size, num_dims=1\r\n            )\r\n        )\r\n        #self.covar_module = gpytorch.kernels.PeriodicKernel() \r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = GPRegressionModel(train_x, train_y, likelihood)\r\n\r\ntraining_iterations = 1\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n], lr=0.1)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nfor i in range(training_iterations):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y) ## NOTE fails here.\r\n    loss.backward()\r\n    optimizer.step()\r\n```\r\n\r\n** Stack trace/error message **\r\n\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-13-effc04c4ab77>\", line 61, in <module>\r\n    loss = -mll(output, train_y) ## NOTE fails here.\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/module.py\", line 24, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\", line 51, in forward\r\n    res = output.log_prob(target)\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/distributions/multivariate_normal.py\", line 135, in log_prob\r\n    inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\", line 1038, in inv_quad_logdet\r\n    args = self.representation()\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\", line 1268, in representation\r\n    representation += list(arg.representation())\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 311, in representation\r\n    return self.evaluate_kernel().representation()\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/utils/memoize.py\", line 34, in g\r\n    add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 278, in evaluate_kernel\r\n    res = self.kernel(x1, x2, diag=False, last_dim_is_batch=self.last_dim_is_batch, **self.params)\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/kernels/kernel.py\", line 395, in __call__\r\n    res = super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params)\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/module.py\", line 24, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/kernels/scale_kernel.py\", line 90, in forward\r\n    orig_output = self.base_kernel.forward(x1, x2, diag=diag, last_dim_is_batch=last_dim_is_batch, **params)\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/kernels/grid_interpolation_kernel.py\", line 177, in forward\r\n    base_lazy_tsr = lazify(self._inducing_forward(last_dim_is_batch=last_dim_is_batch, **params))\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/kernels/grid_interpolation_kernel.py\", line 143, in _inducing_forward\r\n    return super().forward(self.grid, self.grid, last_dim_is_batch=last_dim_is_batch, **params)\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/kernels/grid_kernel.py\", line 133, in forward\r\n    covars = [ToeplitzLazyTensor(c.squeeze(-2)) for c in covars]\r\n\r\n  File \"/Users/val/opt/anaconda3/lib/python3.7/site-packages/gpytorch/kernels/grid_kernel.py\", line 133, in <listcomp>\r\n    covars = [ToeplitzLazyTensor(c.squeeze(-2)) for c in covars]\r\n\r\nIndexError: Dimension out of range (expected to be in range of [-1, 0], but got -2)\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI expected the training loop to terminate successfully, without throwing errors.\r\n\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version: 1.0.0\r\n- PyTorch Version: 1.3.1\r\n- Computer OS macOS High Sierra 10.13.3\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1011/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1011/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1007", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1007/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1007/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1007/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1007", "id": 544202165, "node_id": "MDU6SXNzdWU1NDQyMDIxNjU=", "number": 1007, "title": "conda wants to instal 0.3.6 instead of 1.0.0 on windows", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-31T14:32:52Z", "updated_at": "2020-01-17T01:19:46Z", "closed_at": "2020-01-17T01:19:46Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "The following installs gpytorch 1.0.0 just fine on OSX:\r\n```\r\nconda install -c pytorch pytorch cpuonly\r\nconda install -c gpytorch gpytorcy\r\n```\r\nHowever, when on Windows 10 (run in a VM), this results in conda wanting to install 0.3.6 instead.\r\n\r\nI don't understand why, since the conda package is architecture-independent, and both the OSX and the Win10 installation have pytorch 1.3.1 installed before installing gpytorch.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1007/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1007/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1005", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1005/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1005/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1005/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1005", "id": 543194097, "node_id": "MDU6SXNzdWU1NDMxOTQwOTc=", "number": 1005, "title": "[Bug] different learning rates cause an error", "user": {"login": "cherepanovic", "id": 10064548, "node_id": "MDQ6VXNlcjEwMDY0NTQ4", "avatar_url": "https://avatars.githubusercontent.com/u/10064548?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cherepanovic", "html_url": "https://github.com/cherepanovic", "followers_url": "https://api.github.com/users/cherepanovic/followers", "following_url": "https://api.github.com/users/cherepanovic/following{/other_user}", "gists_url": "https://api.github.com/users/cherepanovic/gists{/gist_id}", "starred_url": "https://api.github.com/users/cherepanovic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cherepanovic/subscriptions", "organizations_url": "https://api.github.com/users/cherepanovic/orgs", "repos_url": "https://api.github.com/users/cherepanovic/repos", "events_url": "https://api.github.com/users/cherepanovic/events{/privacy}", "received_events_url": "https://api.github.com/users/cherepanovic/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-12-28T14:46:02Z", "updated_at": "2019-12-29T00:57:36Z", "closed_at": "2019-12-29T00:57:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "I tried to adapt scheduler and got these exceptions which has to do with cholesky.py \r\n\r\n```\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"o_different.py\", line 67, in forward\r\n    res = self.gp_layer(features)\r\n  File \"/anaconda3/envs/my_env_p36/lib/python3.6/site-packages/gpytorch/models/abstract_variational_gp.py\", line 22, in __call__\r\n    return self.variational_strategy(inputs)\r\n  File \"/anaconda3/envs/my_env_p36/lib/python3.6/site-packages/gpytorch/variational/variational_strategy.py\", line 223, in __call__\r\n    self.initialize_variational_dist()\r\n  File \"/anaconda3/envs/my_env_p36/lib/python3.6/site-packages/gpytorch/variational/variational_strategy.py\", line 93, in initialize_variational_dist\r\n    scale_tril=psd_safe_cholesky(prior_dist.covariance_matrix),\r\n  File \"/anaconda3/envs/my_env_p36/lib/python3.6/site-packages/gpytorch/utils/cholesky.py\", line 46, in psd_safe_cholesky\r\n    raise e\r\n  File \"/anaconda3/envs/my_env_p36/lib/python3.6/site-packages/gpytorch/utils/cholesky.py\", line 21, in psd_safe_cholesky\r\n    L = torch.cholesky(A, upper=upper, out=out)\r\nRuntimeError: CUDA error: invalid device function\r\n\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1005/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1005/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1004", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1004/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1004/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1004/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/1004", "id": 543144189, "node_id": "MDU6SXNzdWU1NDMxNDQxODk=", "number": 1004, "title": "raise NotImplementedError", "user": {"login": "YuanduLai", "id": 26640064, "node_id": "MDQ6VXNlcjI2NjQwMDY0", "avatar_url": "https://avatars.githubusercontent.com/u/26640064?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YuanduLai", "html_url": "https://github.com/YuanduLai", "followers_url": "https://api.github.com/users/YuanduLai/followers", "following_url": "https://api.github.com/users/YuanduLai/following{/other_user}", "gists_url": "https://api.github.com/users/YuanduLai/gists{/gist_id}", "starred_url": "https://api.github.com/users/YuanduLai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YuanduLai/subscriptions", "organizations_url": "https://api.github.com/users/YuanduLai/orgs", "repos_url": "https://api.github.com/users/YuanduLai/repos", "events_url": "https://api.github.com/users/YuanduLai/events{/privacy}", "received_events_url": "https://api.github.com/users/YuanduLai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-12-28T12:29:52Z", "updated_at": "2019-12-28T13:04:50Z", "closed_at": "2019-12-28T13:04:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "hello, when i run ''gpytorch/examples/05_Deep_Gaussian_Processes/Deep_Gaussian_Processes.ipynb''.\r\ni get this error.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 190, in <module>\r\n    predictive_means, predictive_variances, test_lls = model.predict(test_loader)\r\n  File \"train.py\", line 146, in predict\r\n    preds = model.likelihood(model(x_batch))\r\n  File \"/home/lyd/anaconda3/envs/py3tor1/lib/python3.6/site-packages/gpytorch/likelihoods/likelihood.py\", line 123, in __call__\r\n    return self.marginal(input, *params, **kwargs)\r\n  File \"/home/lyd/anaconda3/envs/py3tor1/lib/python3.6/site-packages/gpytorch/likelihoods/likelihood.py\", line 105, in marginal\r\n    return self.forward(function_samples)\r\n  File \"/home/lyd/anaconda3/envs/py3tor1/lib/python3.6/site-packages/gpytorch/likelihoods/likelihood.py\", line 62, in forward\r\n    raise NotImplementedError\r\nNotImplementedError\r\n\r\nI do not change anything, if any thing wrong with the code? could you help me please?", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1004/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/1004/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/995", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/995/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/995/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/995/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/995", "id": 537069401, "node_id": "MDU6SXNzdWU1MzcwNjk0MDE=", "number": 995, "title": "[Bug] DKL example fails with broadcast error", "user": {"login": "bakirillov", "id": 30053869, "node_id": "MDQ6VXNlcjMwMDUzODY5", "avatar_url": "https://avatars.githubusercontent.com/u/30053869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bakirillov", "html_url": "https://github.com/bakirillov", "followers_url": "https://api.github.com/users/bakirillov/followers", "following_url": "https://api.github.com/users/bakirillov/following{/other_user}", "gists_url": "https://api.github.com/users/bakirillov/gists{/gist_id}", "starred_url": "https://api.github.com/users/bakirillov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bakirillov/subscriptions", "organizations_url": "https://api.github.com/users/bakirillov/orgs", "repos_url": "https://api.github.com/users/bakirillov/repos", "events_url": "https://api.github.com/users/bakirillov/events{/privacy}", "received_events_url": "https://api.github.com/users/bakirillov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-12T16:03:38Z", "updated_at": "2019-12-16T23:14:12Z", "closed_at": "2019-12-16T23:14:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nWhen I run Deep_Kernel_Learning_DenseNet_CIFAR_Tutorial, it fails with the following error:\r\nRuntimeError: output with shape [64] doesn't match the broadcast shape [132, 64].\r\n\r\n## To reproduce\r\nRun Deep_Kernel_Learning_DenseNet_CIFAR_Tutorial.ipynb from the examples folder - last cell will crash.\r\n\r\n** Stack trace/error message **\r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-9-6f7e8ea00fe7> in <module>\r\n      2     scheduler.step()\r\n      3     with gpytorch.settings.use_toeplitz(False):\r\n----> 4         train(epoch)\r\n      5         test()\r\n      6     state_dict = model.state_dict()\r\n\r\n<ipython-input-8-2fe6607c5f10> in train(epoch)\r\n     19         data, target = data.cuda(), target.cuda()\r\n     20         optimizer.zero_grad()\r\n---> 21         output = model(data)\r\n     22         print(output.shape, target.shape)\r\n     23         loss = -mll(output, target)\r\n\r\n~/anaconda3/envs/lapki/lib/python3.7/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     22 \r\n     23     def __call__(self, *inputs, **kwargs):\r\n---> 24         outputs = self.forward(*inputs, **kwargs)\r\n     25         if isinstance(outputs, list):\r\n     26             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n<ipython-input-7-834e655c1eac> in forward(self, x)\r\n     10         features = self.feature_extractor(x)\r\n     11         features = gpytorch.utils.grid.scale_to_bounds(features, self.grid_bounds[0], self.grid_bounds[1])\r\n---> 12         res = self.gp_layer(features)\r\n     13         return res\r\n     14 \r\n\r\n~/anaconda3/envs/lapki/lib/python3.7/site-packages/gpytorch/models/approximate_gp.py in __call__(self, inputs, prior, **kwargs)\r\n     54         if inputs.dim() == 1:\r\n     55             inputs = inputs.unsqueeze(-1)\r\n---> 56         return self.variational_strategy(inputs, prior=prior)\r\n\r\n~/anaconda3/envs/lapki/lib/python3.7/site-packages/gpytorch/variational/_variational_strategy.py in __call__(self, x, prior)\r\n    106         if not self.variational_params_initialized.item():\r\n    107             prior_dist = self.prior_distribution\r\n--> 108             self._variational_distribution.initialize_variational_distribution(prior_dist)\r\n    109             self.variational_params_initialized.fill_(1)\r\n    110 \r\n\r\n~/anaconda3/envs/lapki/lib/python3.7/site-packages/gpytorch/variational/cholesky_variational_distribution.py in initialize_variational_distribution(self, prior_dist)\r\n     48 \r\n     49     def initialize_variational_distribution(self, prior_dist):\r\n---> 50         self.variational_mean.data.copy_(prior_dist.mean)\r\n     51         self.variational_mean.data.add_(self.mean_init_std, torch.randn_like(prior_dist.mean))\r\n     52         self.chol_variational_covar.data.copy_(prior_dist.lazy_covariance_matrix.cholesky().evaluate())\r\n\r\nRuntimeError: output with shape [64] doesn't match the broadcast shape [132, 64]\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\nI have expected this to train.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n-  GPytorch:  0.3.6    \r\n-  Pytorch: 1.3.1   \r\n-  OS: Ubuntu 19.10, 5.3.0-24;   \r\n-  Python: 3.7.5\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/995/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/995/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/989", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/989/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/989/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/989/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/989", "id": 533617077, "node_id": "MDU6SXNzdWU1MzM2MTcwNzc=", "number": 989, "title": "[Bug] Extremely slow and memory-inefficient .diag calls", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-05T21:46:06Z", "updated_at": "2020-01-13T06:15:17Z", "closed_at": "2020-01-13T06:15:16Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nIn some cases, calling `diag()` on a lazy tensor is much slower than calling `evaluate().diag()`, and uses a large amount of memory. In fact, this can easily result in OOMs even for very moderate sizes. \r\n\r\n## To reproduce\r\n\r\nSee this notebook: \r\n[diag_issue.ipynb.txt](https://github.com/cornellius-gp/gpytorch/files/3929252/diag_issue.ipynb.txt)\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGPyTorch master, torch 1.3.1\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/989/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/989/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/981", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/981/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/981/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/981/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/981", "id": 530864195, "node_id": "MDU6SXNzdWU1MzA4NjQxOTU=", "number": 981, "title": "[Bug]  in version 0.3.6 , the kissGP example cannot be put on CUDA", "user": {"login": "ArnoVel", "id": 48685588, "node_id": "MDQ6VXNlcjQ4Njg1NTg4", "avatar_url": "https://avatars.githubusercontent.com/u/48685588?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ArnoVel", "html_url": "https://github.com/ArnoVel", "followers_url": "https://api.github.com/users/ArnoVel/followers", "following_url": "https://api.github.com/users/ArnoVel/following{/other_user}", "gists_url": "https://api.github.com/users/ArnoVel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ArnoVel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ArnoVel/subscriptions", "organizations_url": "https://api.github.com/users/ArnoVel/orgs", "repos_url": "https://api.github.com/users/ArnoVel/repos", "events_url": "https://api.github.com/users/ArnoVel/events{/privacy}", "received_events_url": "https://api.github.com/users/ArnoVel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2019-12-02T03:22:12Z", "updated_at": "2019-12-08T23:01:35Z", "closed_at": "2019-12-08T23:01:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nHi,\r\nI directly installed gpytorch alpha version (compatible with my pytorch version, see below), and started with [this tutorial for kissGP](https://github.com/cornellius-gp/gpytorch/blob/master/examples/04_Scalable_GP_Regression_1D/KISSGP_Regression_1D.ipynb)\r\n\r\nHowever upon running the code on GPU (w/ only 1 gpu, i'm on a laptop) one encounters this\r\n\r\n## To reproduce\r\n\r\n**Code snippet to reproduce**\r\n```python\r\nll = gpt.likelihoods.GaussianLikelihood().to('cuda:0')\r\nm = GPRegressionModel(x_tr, y_tr, ll)\r\nm = m.to('cuda:0')\r\n\r\n# Find optimal model hyperparameters\r\nm.train()\r\nll.train()\r\n\r\n# Use the adam optimizer\r\nopt = th.optim.Adam(\r\n                        [{'params': m.parameters()},],\r\n                        lr=0.1)\r\n# Includes GaussianLikelihood parameters\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpt.mlls.ExactMarginalLogLikelihood(ll, m)\r\n\r\ntraining_iterations = 30\r\nfor i in range(training_iterations):\r\n    opt.zero_grad()\r\n    output = m(x_tr)\r\n    print(x_tr.device, output, y_tr.device)\r\n    loss = -mll(output, y_tr)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n    opt.step()\r\n\r\n```\r\n\r\n**Stack trace/error message**\r\n```\r\n~/SJTU/research_code/TCEP/GP_scoring/gpytorch_local/gpytorch/kernels/rbf_kernel.py in forward(self, x1, x2, diag, **params)\r\n     80             x2,\r\n     81             self.lengthscale,\r\n---> 82             lambda x1, x2: self.covar_dist(\r\n     83                 x1, x2, square_dist=True, diag=False, dist_postprocess_func=postprocess_rbf, postprocess=False, **params\r\n     84             ),\r\n\r\n~/SJTU/research_code/TCEP/GP_scoring/gpytorch_local/gpytorch/functions/rbf_covariance.py in forward(ctx, x1, x2, lengthscale, sq_dist_func)\r\n     10             raise ValueError(\"RBFCovariance cannot handle multiple lengthscales\")\r\n     11         needs_grad = any(ctx.needs_input_grad)\r\n---> 12         x1_ = x1.div(lengthscale)\r\n     13         x2_ = x2.div(lengthscale)\r\n     14         unitless_sq_dist = sq_dist_func(x1_, x2_)\r\n\r\nRuntimeError: expected device cpu and dtype Float but got device cuda:0 and dtype Float\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI expected all the model parameters to be on GPU, however the basic model you give is\r\n```python\r\nclass GPRegressionModel(gpt.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n        \r\n        # SKI requires a grid size hyperparameter.\r\n        #This util can help with that. Here we are using a grid\r\n        #that has the same number of points as the training data\r\n        #(a ratio of 1.0).\r\n        #Performance can be sensitive to this parameter,\r\n        #so you may want to adjust it for your own problem\r\n        #on a validation set.\r\n        grid_size = gpt.utils.grid.choose_grid_size(train_x,1.0)\r\n        \r\n        self.mean_module = gpt.means.ConstantMean()\r\n        self.covar_module = gpt.kernels.GridInterpolationKernel(\r\n            gpt.kernels.ScaleKernel(gpt.kernels.RBFKernel()),\r\n            grid_size=grid_size, num_dims=1,\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpt.distributions.MultivariateNormal(mean_x, covar_x)\r\n```\r\nwhich returns a ``` gpt.distributions.MultivariateNormal``` which cannot be put on GPU. This is solved when I clone the code and modify as follows\r\n```python\r\nclass RBFCovariance(torch.autograd.Function):\r\n    @staticmethod\r\n    def forward(ctx, x1, x2, lengthscale, sq_dist_func):\r\n        if any(ctx.needs_input_grad[:2]):\r\n            raise RuntimeError(\"RBFCovariance cannot compute gradients with \" \"respect to x1 and x2\")\r\n        if lengthscale.size(-1) > 1:\r\n            raise ValueError(\"RBFCovariance cannot handle multiple lengthscales\")\r\n        needs_grad = any(ctx.needs_input_grad)\r\n        x1_ = x1.to('cuda:0').div(lengthscale)\r\n        x2_ = x2.to('cuda:0').div(lengthscale)\r\n        unitless_sq_dist = sq_dist_func(x1_, x2_)\r\n        # clone because inplace operations will mess with what's saved for backward\r\n        unitless_sq_dist_ = unitless_sq_dist.clone() if needs_grad else unitless_sq_dist\r\n        covar_mat = unitless_sq_dist_.div_(-2.0).exp_()\r\n        if needs_grad:\r\n            d_output_d_input = unitless_sq_dist.mul_(covar_mat).div_(lengthscale)\r\n            ctx.save_for_backward(d_output_d_input)\r\n        return covar_mat\r\n```\r\n\r\n**BUT** then the ```interpolate``` method is not put on GPU either\r\n\r\n```\r\n~/SJTU/research_code/TCEP/GP_scoring/gpytorch_local/gpytorch/utils/interpolation.py in interpolate(self, x_grid, x_target, interp_points, eps)\r\n    112 \r\n    113             # get the interp. coeff. based on distances to interpolating points\r\n--> 114             scaled_dist = lower_pt_rel_dists.unsqueeze(-1) + interp_points_flip.unsqueeze(-2)\r\n    115             dim_interp_values = self._cubic_interpolation_kernel(scaled_dist)\r\n    116 \r\n\r\nRuntimeError: expected device cuda:0 and dtype Float but got device cpu and dtype Float\r\n```\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 0.3.6\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> 1.2.0\r\n- <!-- Computer OS --> Ubuntu 18.04\r\n\r\n## Additional context\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/981/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/981/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/979", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/979/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/979/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/979/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/979", "id": 530634745, "node_id": "MDU6SXNzdWU1MzA2MzQ3NDU=", "number": 979, "title": "AttributeError: 'VariationalStrategy' object has no attribute 'size' [Bug]", "user": {"login": "PingjunChen", "id": 32883033, "node_id": "MDQ6VXNlcjMyODgzMDMz", "avatar_url": "https://avatars.githubusercontent.com/u/32883033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PingjunChen", "html_url": "https://github.com/PingjunChen", "followers_url": "https://api.github.com/users/PingjunChen/followers", "following_url": "https://api.github.com/users/PingjunChen/following{/other_user}", "gists_url": "https://api.github.com/users/PingjunChen/gists{/gist_id}", "starred_url": "https://api.github.com/users/PingjunChen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PingjunChen/subscriptions", "organizations_url": "https://api.github.com/users/PingjunChen/orgs", "repos_url": "https://api.github.com/users/PingjunChen/repos", "events_url": "https://api.github.com/users/PingjunChen/events{/privacy}", "received_events_url": "https://api.github.com/users/PingjunChen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-30T21:54:18Z", "updated_at": "2019-12-01T01:39:03Z", "closed_at": "2019-12-01T01:39:03Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b AttributeError: 'VariationalStrategy' object has no attribute 'size'\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nI tried to follow the tutorial `Simple_GP_Classification.ipynb` in `gpytorch/examples/02_Simple_GP_Classification/` and copied the code to my script to run. I came across the problem of using `VariationalStrategy`.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom gpytorch.models import VariationalGP\r\nfrom gpytorch.variational import CholeskyVariationalDistribution\r\nfrom gpytorch.variational import VariationalStrategy\r\n\r\n\r\ntrain_x = torch.linspace(0, 1, 10)\r\ntrain_y = torch.sign(torch.cos(train_x * (4 * math.pi))).add(1).div(2)\r\n\r\nclass GPClassificationModel(VariationalGP):\r\n    def __init__(self, train_x):\r\n        variational_distribution = CholeskyVariationalDistribution(train_x.size(0))\r\n        variational_strategy = VariationalStrategy(self, train_x, variational_distribution)\r\n        super(GPClassificationModel, self).__init__(variational_strategy)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        latent_pred = gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n        return latent_pred\r\n\r\n# Initialize model and likelihood\r\nmodel = GPClassificationModel(train_x)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/pingjun/anaconda3/lib/python3.6/site-packages/gpytorch/module.py\", line 291, in __getattr__\r\n    return super().__getattribute__(name)\r\nAttributeError: 'VariationalStrategy' object has no attribute 'size'\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"cls_sin.py\", line 36, in <module>\r\n    model = GPClassificationModel(train_x)\r\n  File \"cls_sin.py\", line 24, in __init__\r\n    super(GPClassificationModel, self).__init__(variational_strategy)\r\n  File \"/home/pingjun/anaconda3/lib/python3.6/site-packages/gpytorch/models/variational_gp.py\", line 15, in __init__\r\n    variational_distribution = CholeskyVariationalDistribution(train_input.size(0))\r\n  File \"/home/pingjun/anaconda3/lib/python3.6/site-packages/gpytorch/module.py\", line 293, in __getattr__\r\n    raise e\r\n  File \"/home/pingjun/anaconda3/lib/python3.6/site-packages/gpytorch/module.py\", line 288, in __getattr__\r\n    return super().__getattr__(name)\r\n  File \"/home/pingjun/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 585, in __getattr__\r\n    type(self).__name__, name))\r\nAttributeError: 'VariationalStrategy' object has no attribute 'size'\r\n```\r\n\r\n## System information\r\n- GPyTorch Version: 0.3.6\r\n- PyTorch Version: 1.3.1\r\n- Computer OS: ubuntu 16.04 LTS\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/979/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/979/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/978", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/978/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/978/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/978/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/978", "id": 530534105, "node_id": "MDU6SXNzdWU1MzA1MzQxMDU=", "number": 978, "title": "ImportError: cannot import name 'ApproximateGP' [Bug]", "user": {"login": "PingjunChen", "id": 32883033, "node_id": "MDQ6VXNlcjMyODgzMDMz", "avatar_url": "https://avatars.githubusercontent.com/u/32883033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PingjunChen", "html_url": "https://github.com/PingjunChen", "followers_url": "https://api.github.com/users/PingjunChen/followers", "following_url": "https://api.github.com/users/PingjunChen/following{/other_user}", "gists_url": "https://api.github.com/users/PingjunChen/gists{/gist_id}", "starred_url": "https://api.github.com/users/PingjunChen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PingjunChen/subscriptions", "organizations_url": "https://api.github.com/users/PingjunChen/orgs", "repos_url": "https://api.github.com/users/PingjunChen/repos", "events_url": "https://api.github.com/users/PingjunChen/events{/privacy}", "received_events_url": "https://api.github.com/users/PingjunChen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-30T05:13:03Z", "updated_at": "2019-11-30T21:37:00Z", "closed_at": "2019-11-30T21:37:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b 'ApproximateGP' ImportError\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nfrom gpytorch.models import ApproximateGP\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-bb3a720fdf62> in <module>\r\n----> 1 from gpytorch.models import ApproximateGP\r\n\r\nImportError: cannot import name 'ApproximateGP'\r\n```\r\n\r\n## Expected Behavior\r\nImport without error. I tried this import on multiple machines, including two ubuntu machines and one Mac, all have this import error. \r\n\r\n## System information\r\n- GPyTorch Version: 0.3.6\r\n- PyTorch Version: 1.3.1\r\n- Computer OS: ubuntu 16.04 LTS\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/978/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/978/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/976", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/976/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/976/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/976/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/976", "id": 530385032, "node_id": "MDU6SXNzdWU1MzAzODUwMzI=", "number": 976, "title": "[Bug] NUTS not working when GammaPrior in model", "user": {"login": "DavidWalz", "id": 2913236, "node_id": "MDQ6VXNlcjI5MTMyMzY=", "avatar_url": "https://avatars.githubusercontent.com/u/2913236?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DavidWalz", "html_url": "https://github.com/DavidWalz", "followers_url": "https://api.github.com/users/DavidWalz/followers", "following_url": "https://api.github.com/users/DavidWalz/following{/other_user}", "gists_url": "https://api.github.com/users/DavidWalz/gists{/gist_id}", "starred_url": "https://api.github.com/users/DavidWalz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DavidWalz/subscriptions", "organizations_url": "https://api.github.com/users/DavidWalz/orgs", "repos_url": "https://api.github.com/users/DavidWalz/repos", "events_url": "https://api.github.com/users/DavidWalz/events{/privacy}", "received_events_url": "https://api.github.com/users/DavidWalz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-11-29T14:54:30Z", "updated_at": "2019-11-30T18:45:38Z", "closed_at": "2019-11-30T18:45:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI'm trying to use the [NUTS example](https://gpytorch.readthedocs.io/en/latest/examples/01_Simple_GP_Regression/Simple_GP_Regression_Fully_Bayesian.html#Sampling-Hyperparamters-with-GPyTorch-+-NUTS) together with the model from [this example](https://gpytorch.readthedocs.io/en/latest/examples/00_Basic_Usage/Hyperparameters.html#Putting-it-Together) and get \r\n```\r\nAttributeError: 'GammaPrior' object has no attribute 'concentration'\r\n```\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nclass ExactGPWithPriors(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPWithPriors, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n\r\n        lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\r\n        outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\r\n            \r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(\r\n                lengthscale_prior=lengthscale_prior,\r\n            ),\r\n            outputscale_prior=outputscale_prior\r\n        )\r\n\r\n        # Initialize lengthscale and outputscale to mean of priors\r\n        self.covar_module.base_kernel.lengthscale = lengthscale_prior.mean\r\n        self.covar_module.outputscale = outputscale_prior.mean\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood(\r\n    noise_constraint=gpytorch.constraints.GreaterThan(1e-2),\r\n)\r\n\r\nmodel = ExactGPWithPriors(train_x, train_y, likelihood)\r\n\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ndef pyro_model(x, y):\r\n    model.pyro_sample_from_prior()\r\n    output = model(x)\r\n    loss = mll.pyro_factor(output, y)\r\n    return y\r\n\r\nnuts_kernel = pyro.infer.mcmc.NUTS(pyro_model, adapt_step_size=True)\r\nmcmc_run = pyro.infer.mcmc.MCMC(nuts_kernel, num_samples=100, warmup_steps=200)\r\nmcmc_run.run(train_x, train_y)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nWarmup:   0%|          | 0/300 [00:00, ?it/s]\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-22-1dcdc695642b> in <module>\r\n      9 nuts_kernel = pyro.infer.mcmc.NUTS(pyro_model, adapt_step_size=True)\r\n     10 mcmc_run = pyro.infer.mcmc.MCMC(nuts_kernel, num_samples=100, warmup_steps=200)\r\n---> 11 mcmc_run.run(train_x, train_y)\r\n\r\n~/.local/lib/python3.8/site-packages/pyro/poutine/messenger.py in _context_wrap(context, fn, *args, **kwargs)\r\n      6 def _context_wrap(context, fn, *args, **kwargs):\r\n      7     with context:\r\n----> 8         return fn(*args, **kwargs)\r\n      9 \r\n     10 \r\n\r\n~/.local/lib/python3.8/site-packages/pyro/infer/mcmc/api.py in run(self, *args, **kwargs)\r\n    352         z_flat_acc = [[] for _ in range(self.num_chains)]\r\n    353         with pyro.validation_enabled(not self.disable_validation):\r\n--> 354             for x, chain_id in self.sampler.run(*args, **kwargs):\r\n    355                 if num_samples[chain_id] == 0:\r\n    356                     num_samples[chain_id] += 1\r\n\r\n~/.local/lib/python3.8/site-packages/pyro/infer/mcmc/api.py in run(self, *args, **kwargs)\r\n    161             logger = initialize_logger(logger, \"\", progress_bar)\r\n    162             hook_w_logging = _add_logging_hook(logger, progress_bar, self.hook)\r\n--> 163             for sample in _gen_samples(self.kernel, self.warmup_steps, self.num_samples, hook_w_logging,\r\n    164                                        i if self.num_chains > 1 else None,\r\n    165                                        *args, **kwargs):\r\n\r\n~/.local/lib/python3.8/site-packages/pyro/infer/mcmc/api.py in _gen_samples(kernel, warmup_steps, num_samples, hook, chain_id, *args, **kwargs)\r\n    105 \r\n    106 def _gen_samples(kernel, warmup_steps, num_samples, hook, chain_id, *args, **kwargs):\r\n--> 107     kernel.setup(warmup_steps, *args, **kwargs)\r\n    108     params = kernel.initial_params\r\n    109     # yield structure (key, value.shape) of params\r\n\r\n~/.local/lib/python3.8/site-packages/pyro/infer/mcmc/hmc.py in setup(self, warmup_steps, *args, **kwargs)\r\n    258         self._warmup_steps = warmup_steps\r\n    259         if self.model is not None:\r\n--> 260             self._initialize_model_properties(args, kwargs)\r\n    261         potential_energy = self.potential_fn(self.initial_params)\r\n    262         self._cache(self.initial_params, potential_energy, None)\r\n\r\n~/.local/lib/python3.8/site-packages/pyro/infer/mcmc/hmc.py in _initialize_model_properties(self, model_args, model_kwargs)\r\n    223 \r\n    224     def _initialize_model_properties(self, model_args, model_kwargs):\r\n--> 225         init_params, potential_fn, transforms, trace = initialize_model(\r\n    226             self.model,\r\n    227             model_args,\r\n\r\n~/.local/lib/python3.8/site-packages/pyro/infer/mcmc/util.py in initialize_model(model, model_args, model_kwargs, transforms, max_plate_nesting, jit_compile, jit_options, skip_jit_warnings, num_chains)\r\n    363         automatic_transform_enabled = False\r\n    364     if max_plate_nesting is None:\r\n--> 365         max_plate_nesting = _guess_max_plate_nesting(model, model_args, model_kwargs)\r\n    366     # Wrap model in `poutine.enum` to enumerate over discrete latent sites.\r\n    367     # No-op if model does not have any discrete latents.\r\n\r\n~/.local/lib/python3.8/site-packages/pyro/infer/mcmc/util.py in _guess_max_plate_nesting(model, args, kwargs)\r\n    231     \"\"\"\r\n    232     with poutine.block():\r\n--> 233         model_trace = poutine.trace(model).get_trace(*args, **kwargs)\r\n    234     sites = [site for site in model_trace.nodes.values()\r\n    235              if site[\"type\"] == \"sample\"]\r\n\r\n~/.local/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py in get_trace(self, *args, **kwargs)\r\n    161         Calls this poutine and returns its trace instead of the function's return value.\r\n    162         \"\"\"\r\n--> 163         self(*args, **kwargs)\r\n    164         return self.msngr.get_trace()\r\n\r\n~/.local/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py in __call__(self, *args, **kwargs)\r\n    141                                       args=args, kwargs=kwargs)\r\n    142             try:\r\n--> 143                 ret = self.fn(*args, **kwargs)\r\n    144             except (ValueError, RuntimeError):\r\n    145                 exc_type, exc_value, traceback = sys.exc_info()\r\n\r\n<ipython-input-22-1dcdc695642b> in pyro_model(x, y)\r\n      2 \r\n      3 def pyro_model(x, y):\r\n----> 4     model.pyro_sample_from_prior()\r\n      5     output = model(x)\r\n      6     loss = mll.pyro_factor(output, y)\r\n\r\n~/.local/lib/python3.8/site-packages/gpytorch/module.py in pyro_sample_from_prior(self)\r\n    287         parameters of the model that have GPyTorch priors registered to them.\r\n    288         \"\"\"\r\n--> 289         return _pyro_sample_from_prior(module=self, memo=None, prefix=\"\")\r\n    290 \r\n    291     def local_load_samples(self, samples_dict, memo, prefix):\r\n\r\n~/.local/lib/python3.8/site-packages/gpytorch/module.py in _pyro_sample_from_prior(module, memo, prefix)\r\n    396     for mname, module_ in module.named_children():\r\n    397         submodule_prefix = prefix + (\".\" if prefix else \"\") + mname\r\n--> 398         _pyro_sample_from_prior(module=module_, memo=memo, prefix=submodule_prefix)\r\n    399 \r\n    400 \r\n\r\n~/.local/lib/python3.8/site-packages/gpytorch/module.py in _pyro_sample_from_prior(module, memo, prefix)\r\n    391                 memo.add(prior)\r\n    392                 prior = prior.expand(closure().shape)\r\n--> 393                 value = pyro.sample(prefix + (\".\" if prefix else \"\") + prior_name, prior)\r\n    394                 setting_closure(value)\r\n    395 \r\n\r\n~/.local/lib/python3.8/site-packages/pyro/primitives.py in sample(name, fn, *args, **kwargs)\r\n    108             msg[\"is_observed\"] = True\r\n    109         # apply the stack and return its return value\r\n--> 110         apply_stack(msg)\r\n    111         return msg[\"value\"]\r\n    112 \r\n\r\n~/.local/lib/python3.8/site-packages/pyro/poutine/runtime.py in apply_stack(initial_msg)\r\n    193             break\r\n    194 \r\n--> 195     default_process_message(msg)\r\n    196 \r\n    197     for frame in stack[-pointer:]:\r\n\r\n~/.local/lib/python3.8/site-packages/pyro/poutine/runtime.py in default_process_message(msg)\r\n    154         return msg\r\n    155 \r\n--> 156     msg[\"value\"] = msg[\"fn\"](*msg[\"args\"], **msg[\"kwargs\"])\r\n    157 \r\n    158     # after fn has been called, update msg to prevent it from being called again.\r\n\r\n~/.local/lib/python3.8/site-packages/pyro/distributions/torch_distribution.py in __call__(self, sample_shape)\r\n     38         :rtype: torch.Tensor\r\n     39         \"\"\"\r\n---> 40         return self.rsample(sample_shape) if self.has_rsample else self.sample(sample_shape)\r\n     41 \r\n     42     @property\r\n\r\n/usr/lib/python3.8/site-packages/torch/distributions/gamma.py in rsample(self, sample_shape)\r\n     59     def rsample(self, sample_shape=torch.Size()):\r\n     60         shape = self._extended_shape(sample_shape)\r\n---> 61         value = _standard_gamma(self.concentration.expand(shape)) / self.rate.expand(shape)\r\n     62         value.detach().clamp_(min=torch.finfo(value.dtype).tiny)  # do not record in autograd graph\r\n     63         return value\r\n\r\n/usr/lib/python3.8/site-packages/torch/nn/modules/module.py in __getattr__(self, name)\r\n    582             if name in modules:\r\n    583                 return modules[name]\r\n--> 584         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\r\n    585             type(self).__name__, name))\r\n    586 \r\n\r\nAttributeError: 'GammaPrior' object has no attribute 'concentration'\r\n```\r\n\r\n## System information\r\ngpytorch 0.3.6 (pip install git, https://github.com/cornellius-gp/gpytorch/commit/4a1ba02d2367e4e9dd03eb1ccbfa4707da02dd08)\r\ntorch 1.3.1\r\npyro 1.0.0", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/976/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/976/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/973", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/973/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/973/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/973/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/973", "id": 528312954, "node_id": "MDExOlB1bGxSZXF1ZXN0MzQ1Mzk3ODYw", "number": 973, "title": "Fix grid kernel batch issues.", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-25T20:15:32Z", "updated_at": "2019-11-29T16:40:57Z", "closed_at": "2019-11-29T16:40:54Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/973", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/973", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/973.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/973.patch", "merged_at": "2019-11-29T16:40:54Z"}, "body": "This addresses using different batch shapes within GridInterpolationKernel. Now it's possible to use any sort of broadcastable batch sizes with  1) input data, 2) inducing points, and 3) kernel hypers.\r\n\r\n[Fixes #963]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/973/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/973/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/971", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/971/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/971/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/971/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/971", "id": 528229615, "node_id": "MDExOlB1bGxSZXF1ZXN0MzQ1MzMyMjc2", "number": 971, "title": "Prevent NaNs in grid interpolation.", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-25T17:25:20Z", "updated_at": "2019-11-29T16:56:06Z", "closed_at": "2019-11-29T16:56:01Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/971", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/971", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/971.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/971.patch", "merged_at": "2019-11-29T16:56:01Z"}, "body": "When GP inputs become very close (usually as a result of DKL - where the deep net maps all points on top of each other), sometimes we'll get NaNs which cause the grid interpolation indices to be very non-sensical (e.g. very negative values).\r\n\r\nThis isn't maybe the ulimate error that we want, but it should at least prevent us from introducing extra NaNs from div-by-0 errors.\r\n\r\n[Closes #955]", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/971/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/971/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/961", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/961/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/961/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/961/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/961", "id": 526896918, "node_id": "MDU6SXNzdWU1MjY4OTY5MTg=", "number": 961, "title": "[Bug] Pyro Examples are out of date", "user": {"login": "wjmaddox", "id": 13008542, "node_id": "MDQ6VXNlcjEzMDA4NTQy", "avatar_url": "https://avatars.githubusercontent.com/u/13008542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjmaddox", "html_url": "https://github.com/wjmaddox", "followers_url": "https://api.github.com/users/wjmaddox/followers", "following_url": "https://api.github.com/users/wjmaddox/following{/other_user}", "gists_url": "https://api.github.com/users/wjmaddox/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjmaddox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjmaddox/subscriptions", "organizations_url": "https://api.github.com/users/wjmaddox/orgs", "repos_url": "https://api.github.com/users/wjmaddox/repos", "events_url": "https://api.github.com/users/wjmaddox/events{/privacy}", "received_events_url": "https://api.github.com/users/wjmaddox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-21T23:22:33Z", "updated_at": "2019-12-16T23:14:12Z", "closed_at": "2019-12-16T23:14:12Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI'm attempting to run the Pyro examples in [examples/09_Pyro_Integration](https://github.com/cornellius-gp/gpytorch/tree/master/examples/09_Pyro_Integration), but am getting backwards related issues.\r\n\r\n## To reproduce\r\n\r\nRun the [Pyro GP Regression](https://github.com/cornellius-gp/gpytorch/blob/master/examples/09_Pyro_Integration/Pyro_Variational_GP_Regression.ipynb) tutorial into cell [5] and gives the following error. However, I've seen it through all three tutorials. \r\n\r\n** Code snippet to reproduce **\r\n\r\nError seems to require clearing a gradient step in the iteration perspective, but I'm not particularly familiar enough with Pyro to come up with a fix off the top of my head.\r\n\r\n** Stack trace/error message **\r\n```\r\n<ipython-input-5-b72bfb4618e0> in train(num_iter)\r\n      9     for i in range(num_iter):\r\n     10         model.zero_grad()\r\n---> 11         loss = svi.step(train_x, train_y)\r\n     12         if not (i + 1) % 50:\r\n     13             print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pyro/infer/svi.py in step(self, *args, **kwargs)\r\n    117         # get loss and compute gradients\r\n    118         with poutine.trace(param_only=True) as param_capture:\r\n--> 119             loss = self.loss_and_grads(self.model, self.guide, *args, **kwargs)\r\n    120 \r\n    121         params = set(site[\"value\"].unconstrained()\r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pyro/infer/trace_elbo.py in loss_and_grads(self, model, guide, *args, **kwargs)\r\n    132             if trainable_params and getattr(surrogate_loss_particle, 'requires_grad', False):\r\n    133                 surrogate_loss_particle = surrogate_loss_particle / self.num_particles\r\n--> 134                 surrogate_loss_particle.backward(retain_graph=self.retain_graph)\r\n    135         warn_if_nan(loss, \"loss\")\r\n    136         return loss\r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)\r\n    164                 products. Defaults to ``False``.\r\n    165         \"\"\"\r\n--> 166         torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n    167 \r\n    168     def register_hook(self, hook):\r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\r\n     97     Variable._execution_engine.run_backward(\r\n     98         tensors, grad_tensors, retain_graph, create_graph,\r\n---> 99         allow_unreachable=True)  # allow_unreachable flag\r\n    100 \r\n    101 \r\n\r\nRuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThe tutorial should work :). Sorry if this is just reporting a bug. But, it should be part of the examples refactor.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- Pyro 1.0.0 \r\n- gpytorch 0.3.6 (built from master) \r\n- pytorch 1.3.1 \r\n- Ubuntu 18.04\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/961/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/961/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/955", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/955/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/955/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/955/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/955", "id": 524719078, "node_id": "MDU6SXNzdWU1MjQ3MTkwNzg=", "number": 955, "title": "[Bug] Invalid index in gather during call to mll in training loop", "user": {"login": "jeffwillette", "id": 9424192, "node_id": "MDQ6VXNlcjk0MjQxOTI=", "avatar_url": "https://avatars.githubusercontent.com/u/9424192?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeffwillette", "html_url": "https://github.com/jeffwillette", "followers_url": "https://api.github.com/users/jeffwillette/followers", "following_url": "https://api.github.com/users/jeffwillette/following{/other_user}", "gists_url": "https://api.github.com/users/jeffwillette/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeffwillette/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeffwillette/subscriptions", "organizations_url": "https://api.github.com/users/jeffwillette/orgs", "repos_url": "https://api.github.com/users/jeffwillette/repos", "events_url": "https://api.github.com/users/jeffwillette/events{/privacy}", "received_events_url": "https://api.github.com/users/jeffwillette/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-11-19T01:36:38Z", "updated_at": "2019-12-26T02:10:17Z", "closed_at": "2019-11-29T16:56:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI followed the docs related to DKL exactly and got the following error during the training loop when calculating the loss with the marginal likelihood function\r\n\r\n** Stack trace/error message **\r\n```\r\nTraceback (most recent call last):\r\n  File \"gp.py\", line 24, in <module>\r\n    exact.train()\r\n  File \"/st2/jeff/real_estate/models/gaussian_processes/exact.py\", line 102, in train\r\n    loss = -mll(output, train_y).sum()\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/module.py\", line 22, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\", line 27, in forward\r\n    res = output.log_prob(target)\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/distributions/multivariate_normal.py\", line 128, in log_prob\r\n    inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/lazy/batch_repeat_lazy_tensor.py\", line 242, in inv_quad_logdet\r\n    inv_quad_rhs, logdet, reduce_inv_quad=False\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\", line 1052, in inv_quad_logdet\r\n    *args,\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/functions/_inv_quad_log_det.py\", line 63, in forward\r\n    preconditioner, precond_lt, logdet_correction = lazy_tsr._preconditioner()\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\", line 59, in _preconditioner\r\n    self._piv_chol_self = pivoted_cholesky.pivoted_cholesky(self._lazy_tensor, max_iter)\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/utils/pivoted_cholesky.py\", line 19, in pivoted_cholesky\r\n    matrix_diag = matrix._approx_diag()\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/lazy/interpolated_lazy_tensor.py\", line 90, in _approx_diag\r\n    left_res = left_interp(self.left_interp_indices, self.left_interp_values, base_diag_root.unsqueeze(-1))\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/utils/interpolation.py\", line 187, in left_interp\r\n    res = rhs_expanded.gather(-3, interp_indices_expanded).mul(interp_values_expanded)\r\nRuntimeError: Invalid index in gather at /tmp/pip-req-build-58y_cjjl/aten/src/TH/generic/THTensorEvenMoreMath.cpp:472\r\nloss: 57158.71 med: 0.30, minmax: 0.30 0.30 noise: 0.56: : 0it [00:08, ?it/s]\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI am left unsure of what is causing the error and how to go about fixing it because it is initially successful in iterating and calculating the loss and then it crashes. The sizing of tensors must be correct, but there is must be some numerical instability and I am unsure about where to look for it.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\ngpytorch version: `0.3.6`\r\ntorch version: `1.2.0\r\nUbuntu 18.04\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/955/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/955/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/952", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/952/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/952/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/952/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/952", "id": 524025241, "node_id": "MDU6SXNzdWU1MjQwMjUyNDE=", "number": 952, "title": "[Bug] probe_vectors should NOT be unit norm functions/_inv_quad_log_det.py?", "user": {"login": "joacorapela", "id": 27322752, "node_id": "MDQ6VXNlcjI3MzIyNzUy", "avatar_url": "https://avatars.githubusercontent.com/u/27322752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joacorapela", "html_url": "https://github.com/joacorapela", "followers_url": "https://api.github.com/users/joacorapela/followers", "following_url": "https://api.github.com/users/joacorapela/following{/other_user}", "gists_url": "https://api.github.com/users/joacorapela/gists{/gist_id}", "starred_url": "https://api.github.com/users/joacorapela/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joacorapela/subscriptions", "organizations_url": "https://api.github.com/users/joacorapela/orgs", "repos_url": "https://api.github.com/users/joacorapela/repos", "events_url": "https://api.github.com/users/joacorapela/events{/privacy}", "received_events_url": "https://api.github.com/users/joacorapela/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-17T18:37:40Z", "updated_at": "2019-11-17T21:12:34Z", "closed_at": "2019-11-17T21:12:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nIn functions/_inv_quad_log_det.py I see that probe_vectors are set to unit\r\nnorm:\r\n\r\n>             probe_vectors = probe_vectors.div(probe_vector_norms)\r\n\r\nand, as I show below, I think this is a mistake.\r\n\r\nAs in page 4 of Gardner et al, 2018, suppose I want to estimate the trace of\r\nthe identity matrix I_m in R^m and that A is an invertible matrix in R^{nxn}.\r\nThen:\r\n\r\nTr(I_m) = Tr(AxA^{-1}) ~ 1/t \\sum_{i=1}^t z_i^T A A^{-1} z_i =\r\n                       = 1/t \\sum_{i=1}^t z_i^T z_i = (because z_i unit norm)\r\n                       = 1/t \\sum_{i=1}^t 1 = 1\r\n\r\nBut Tr(I_m) equals m.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/952/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/952/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/951", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/951/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/951/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/951/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/951", "id": 523953653, "node_id": "MDU6SXNzdWU1MjM5NTM2NTM=", "number": 951, "title": "[Bug] RuntimeError: Expected object of type Variable... when trying to predict on datasets trained on more than 32767 datapoints", "user": {"login": "jgibson2", "id": 5562125, "node_id": "MDQ6VXNlcjU1NjIxMjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5562125?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jgibson2", "html_url": "https://github.com/jgibson2", "followers_url": "https://api.github.com/users/jgibson2/followers", "following_url": "https://api.github.com/users/jgibson2/following{/other_user}", "gists_url": "https://api.github.com/users/jgibson2/gists{/gist_id}", "starred_url": "https://api.github.com/users/jgibson2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jgibson2/subscriptions", "organizations_url": "https://api.github.com/users/jgibson2/orgs", "repos_url": "https://api.github.com/users/jgibson2/repos", "events_url": "https://api.github.com/users/jgibson2/events{/privacy}", "received_events_url": "https://api.github.com/users/jgibson2/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-11-17T08:22:06Z", "updated_at": "2021-09-24T18:37:05Z", "closed_at": "2021-09-24T18:37:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen training on 1D Tensors of size > 32767 (larger than the signed integer maximum), a RuntimeError is thrown about expecting a Variable instead of a FloatTensor. Wrapping tensors in torch.autograd.Variable does not solve the issue. \r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n\"\"\"\r\nType error thrown\r\n\r\nRef: https://github.com/cornellius-gp/gpytorch/blob/master/examples/04_Scalable_GP_Regression_1D/KISSGP_Regression_1D.ipynb\r\n\"\"\"\r\nimport math\r\nimport torch\r\nimport gpytorch\r\n\r\n\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n\r\n        # SKI requires a grid size hyperparameter.\r\n        # This util can help with that. Here we are using a grid that\r\n        # has the same number of points as the training data (a ratio of 1.0).\r\n        # Performance can be sensitive to this parameter,\r\n        # so you may want to adjust it for your own problem on a validation set.\r\n        grid_size = gpytorch.utils.grid.choose_grid_size(train_x, 1.0)\r\n\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.GridInterpolationKernel(\r\n            gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()),\r\n            grid_size=grid_size, num_dims=1,\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nif __name__ == '__main__':\r\n\r\n    training_iterations = 5\r\n\r\n    # one greater than signed integer limit...\r\n    train_x = torch.linspace(0, 100, 32768)\r\n    train_y = train_x * (4 * math.pi) + torch.randn(train_x.size()) * 0.2\r\n\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n    model = GPRegressionModel(train_x, train_y, likelihood)\r\n\r\n    # Find optimal model hyperparameters\r\n    model.train()\r\n    likelihood.train()\r\n\r\n    # Use the adam optimizer\r\n    optimizer = torch.optim.Adam([\r\n        {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n    ], lr=0.5)\r\n\r\n    # \"Loss\" for GPs - the marginal log likelihood\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\n    for i in range(training_iterations):\r\n        optimizer.zero_grad()\r\n        output = model(train_x)\r\n        loss = -mll(output, train_y)\r\n        loss.backward()\r\n        print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n        optimizer.step()\r\n\r\n\r\n    # Switch to evaluation mode\r\n    model.eval()\r\n    likelihood.eval()\r\n\r\n    # The gpytorch.settings.fast_pred_var flag activates LOVE (for fast variances)\r\n    # See https://arxiv.org/abs/1803.06058\r\n    with torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.settings.max_root_decomposition_size(10):\r\n        test_x = torch.round(torch.linspace(min(train_x), max(train_x), 1000))\r\n        prediction = likelihood(model(test_x))\r\n        mean = prediction.mean\r\n\r\n        # Get lower and upper predictive bounds\r\n        lower, upper = prediction.confidence_region()\r\n\r\n    print(mean)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nIter 1/5 - Loss: 681.360\r\nIter 2/5 - Loss: 347.955\r\nIter 3/5 - Loss: 202.934\r\nIter 4/5 - Loss: 132.062\r\nIter 5/5 - Loss: 94.708\r\nTraceback (most recent call last):\r\n  File \"/home/john/workspace/bcaller/training_failure_example.py\", line 74, in <module>\r\n    prediction = likelihood(model(test_x))\r\n  File \"/home/john/workspace/bcaller/venv/lib/python3.6/site-packages/gpytorch/models/exact_gp.py\", line 291, in __call__\r\n    predictive_mean, predictive_covar = self.prediction_strategy.exact_prediction(full_mean, full_covar)\r\n  File \"/home/john/workspace/bcaller/venv/lib/python3.6/site-packages/gpytorch/models/exact_prediction_strategies.py\", line 494, in exact_prediction\r\n    self.exact_predictive_mean(test_mean, test_train_covar),\r\n  File \"/home/john/workspace/bcaller/venv/lib/python3.6/site-packages/gpytorch/models/exact_prediction_strategies.py\", line 499, in exact_predictive_mean\r\n    precomputed_cache = self.mean_cache\r\n  File \"/home/john/workspace/bcaller/venv/lib/python3.6/site-packages/gpytorch/utils/memoize.py\", line 34, in g\r\n    add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n  File \"/home/john/workspace/bcaller/venv/lib/python3.6/site-packages/gpytorch/models/exact_prediction_strategies.py\", line 405, in mean_cache\r\n    train_train_covar_inv_labels = train_train_covar_with_noise.inv_matmul(mean_diff)\r\n  File \"/home/john/workspace/bcaller/venv/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\", line 928, in inv_matmul\r\n    *self.representation(),\r\n  File \"/home/john/workspace/bcaller/venv/lib/python3.6/site-packages/gpytorch/functions/_inv_matmul.py\", line 46, in forward\r\n    solves = _solve(lazy_tsr, right_tensor)\r\n  File \"/home/john/workspace/bcaller/venv/lib/python3.6/site-packages/gpytorch/functions/_inv_matmul.py\", line 14, in _solve\r\n    return lazy_tsr._solve(rhs, preconditioner)\r\n  File \"/home/john/workspace/bcaller/venv/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\", line 641, in _solve\r\n    preconditioner=preconditioner,\r\n  File \"/home/john/workspace/bcaller/venv/lib/python3.6/site-packages/gpytorch/utils/linear_cg.py\", line 208, in linear_cg\r\n    torch.sum(mul_storage, -2, keepdim=True, out=alpha)\r\nRuntimeError: Expected object of type Variable but found type torch.FloatTensor for argument #0 'self'\r\n```\r\n\r\n## Expected Behavior\r\nTraining and prediction to work without error.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch version: 0.3.6\r\n- Torch version: 1.3.1\r\n- Ubuntu 14.04 LTS 64-bit\r\n\r\n## Additional context\r\n\r\nNo documentation about large datasets mentioned this error.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/951/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/951/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/945", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/945/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/945/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/945/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/945", "id": 523054356, "node_id": "MDU6SXNzdWU1MjMwNTQzNTY=", "number": 945, "title": "[Bug] Example for Deep Kernel Learning is out of date.", "user": {"login": "mmirtcho", "id": 10713045, "node_id": "MDQ6VXNlcjEwNzEzMDQ1", "avatar_url": "https://avatars.githubusercontent.com/u/10713045?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mmirtcho", "html_url": "https://github.com/mmirtcho", "followers_url": "https://api.github.com/users/mmirtcho/followers", "following_url": "https://api.github.com/users/mmirtcho/following{/other_user}", "gists_url": "https://api.github.com/users/mmirtcho/gists{/gist_id}", "starred_url": "https://api.github.com/users/mmirtcho/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mmirtcho/subscriptions", "organizations_url": "https://api.github.com/users/mmirtcho/orgs", "repos_url": "https://api.github.com/users/mmirtcho/repos", "events_url": "https://api.github.com/users/mmirtcho/events{/privacy}", "received_events_url": "https://api.github.com/users/mmirtcho/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 956525576, "node_id": "MDU6TGFiZWw5NTY1MjU1NzY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/documentation", "name": "documentation", "color": "e2b188", "default": true, "description": ""}, {"id": 1607679890, "node_id": "MDU6TGFiZWwxNjA3Njc5ODkw", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/DKL", "name": "DKL", "color": "ffffff", "default": false, "description": "For questions about DKL"}, {"id": 1607680352, "node_id": "MDU6TGFiZWwxNjA3NjgwMzUy", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/variational", "name": "variational", "color": "ffffff", "default": false, "description": "For questions about variational inference"}], "state": "closed", "locked": false, "assignee": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2019-11-14T19:20:29Z", "updated_at": "2019-12-16T23:14:12Z", "closed_at": "2019-12-16T23:14:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen running the CIFAR 10 example, it gives a shape mismatch error.\r\n\r\n## To reproduce\r\n\r\nRun this line by line in iPython (use dataset = 'cifar10' as in the example):\r\n\r\nhttps://github.com/cornellius-gp/gpytorch/blob/master/examples/08_Deep_Kernel_Learning/Deep_Kernel_Learning_DenseNet_CIFAR_Tutorial.ipynb\r\n\r\n```\r\n\r\n** Stack trace/error message **\r\n\r\n     49     def initialize_variational_distribution(self, prior_dist):\r\n---> 50         self.variational_mean.data.copy_(prior_dist.mean)\r\n     51         self.variational_mean.data.add_(self.mean_init_std, torch.randn_like(prior_dist.mean))\r\n     52         self.chol_variational_covar.data.copy_(prior_dist.lazy_covariance_matrix.cholesky().evaluate())\r\n\r\nRuntimeError: output with shape [64] doesn't match the broadcast shape [132, 64]\r\n ```\r\nfrom\r\n```\r\ngpytorch/variational/cholesky_variational_distribution.py in initialize_variational_distribution(self, prior_dist)\r\n``` \r\n\r\n## Expected Behavior\r\n\r\nIt should train a DKL, but errors when training.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 0.3.6\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> 1.3.1\r\n- <!-- Computer OS --> Ubuntu 16.04.6\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/945/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/945/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/943", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/943/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/943/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/943/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/943", "id": 522616133, "node_id": "MDU6SXNzdWU1MjI2MTYxMzM=", "number": 943, "title": "[Bug] cholesky singular U", "user": {"login": "jeffwillette", "id": 9424192, "node_id": "MDQ6VXNlcjk0MjQxOTI=", "avatar_url": "https://avatars.githubusercontent.com/u/9424192?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeffwillette", "html_url": "https://github.com/jeffwillette", "followers_url": "https://api.github.com/users/jeffwillette/followers", "following_url": "https://api.github.com/users/jeffwillette/following{/other_user}", "gists_url": "https://api.github.com/users/jeffwillette/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeffwillette/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeffwillette/subscriptions", "organizations_url": "https://api.github.com/users/jeffwillette/orgs", "repos_url": "https://api.github.com/users/jeffwillette/repos", "events_url": "https://api.github.com/users/jeffwillette/events{/privacy}", "received_events_url": "https://api.github.com/users/jeffwillette/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1607680352, "node_id": "MDU6TGFiZWwxNjA3NjgwMzUy", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/variational", "name": "variational", "color": "ffffff", "default": false, "description": "For questions about variational inference"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2019-11-14T04:24:31Z", "updated_at": "2019-11-16T08:55:38Z", "closed_at": "2019-11-16T08:55:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\n\r\nI followed the directions here for a variational GP (https://gpytorch.readthedocs.io/en/latest/examples/05_Scalable_GP_Regression_Multidimensional/SVGP_Regression_CUDA.html#Overview) with the HEAD build of gpytorch and it trains for a while and then crashes with...\r\n\r\n** Stack trace/error message **\r\n```\r\n  File \"main.py\", line 93, in <module>\r\n    pred = model(x)\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589       | 999/1088 [00:42<00:02, 31.22it/s]\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch-0.3.6-py3.7.egg/gpytorch/models/approximate_gp.py\", line 56, in __call__\r\n    return self.variational_strategy(inputs, prior=prior)\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch-0.3.6-py3.7.egg/gpytorch/variational/whitened_variational_strategy.py\", line 240, in __call__\r\n    return Module.__call__(self, x)\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch-0.3.6-py3.7.egg/gpytorch/module.py\", line 24, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch-0.3.6-py3.7.egg/gpytorch/variational/whitened_variational_strategy.py\", line 141, in forward\r\n    induc_induc_covar = CholLazyTensor(induc_induc_covar.cholesky())                                                                \r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch-0.3.6-py3.7.egg/gpytorch/lazy/lazy_tensor.py\", line 738, in cholesky\r\n    res = self._cholesky()\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch-0.3.6-py3.7.egg/gpytorch/utils/memoize.py\", line 34, in g\r\n    add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch-0.3.6-py3.7.egg/gpytorch/lazy/lazy_tensor.py\", line 413, in _cholesky\r\n    cholesky = psd_safe_cholesky(evaluated_mat).contiguous()\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch-0.3.6-py3.7.egg/gpytorch/utils/cholesky.py\", line 39, in psd_safe_cholesky\r\n    raise e\r\n  File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch-0.3.6-py3.7.egg/gpytorch/utils/cholesky.py\", line 22, in psd_safe_cholesky\r\n    L = torch.cholesky(A, upper=upper, out=out)\r\nRuntimeError: cholesky_cpu: U(1,1) is zero, singular U.\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI'm not sure why it is running into a singular matrix there, as I would expect that case to be covered. \r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n0.3.6 - cd1c8f8\r\n1.2.0\r\nUbuntu \r\n\r\n## Additional context\r\n\r\nAdditionally, I get a cuda OOM error every time I try to call `.to(device)` using gpytorch, even with minimal data, which is strange. \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/943/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/943/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/939", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/939/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/939/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/939/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/939", "id": 522302177, "node_id": "MDU6SXNzdWU1MjIzMDIxNzc=", "number": 939, "title": "Replicating results presented in Doubly Stochastic Variational Inference for Deep Gaussian Processes", "user": {"login": "JanSochman", "id": 5571610, "node_id": "MDQ6VXNlcjU1NzE2MTA=", "avatar_url": "https://avatars.githubusercontent.com/u/5571610?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JanSochman", "html_url": "https://github.com/JanSochman", "followers_url": "https://api.github.com/users/JanSochman/followers", "following_url": "https://api.github.com/users/JanSochman/following{/other_user}", "gists_url": "https://api.github.com/users/JanSochman/gists{/gist_id}", "starred_url": "https://api.github.com/users/JanSochman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JanSochman/subscriptions", "organizations_url": "https://api.github.com/users/JanSochman/orgs", "repos_url": "https://api.github.com/users/JanSochman/repos", "events_url": "https://api.github.com/users/JanSochman/events{/privacy}", "received_events_url": "https://api.github.com/users/JanSochman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2019-11-13T15:39:18Z", "updated_at": "2020-01-03T14:05:20Z", "closed_at": "2020-01-03T14:04:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, has anybody succeeded in replicating the results of the paper Doubly Stochastic Variational Inference for Deep Gaussian Processes by Salimbeni and Deisenroth in GPyTorch? There is an example DeepGP notebook referring to the paper, but when I tried to run it on the datasets used by the paper I often observe divergence in the test log-likelihood (this is the example for training on kin8nm dataset).\r\n![Training on kin8nm dataset](https://user-images.githubusercontent.com/5571610/68777622-3a08ad00-0632-11ea-846f-06978c5806a4.png)\r\n\r\nThe divergence does not occur every time, but I am not sure what is its cause and I see no way to control it...\r\n\r\nI am attaching my modified notebook with reading of the datasets, a model without residual connections, batch size and layer dimensions as in the paper. Any idea what is happening here?\r\n\r\n[salimbeni_replication_issue.zip](https://github.com/cornellius-gp/gpytorch/files/3842004/salimbeni_replication_issue.zip)\r\n\r\nThanks,\r\nJan", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/939/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/939/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/905", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/905/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/905/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/905/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/905", "id": 508033206, "node_id": "MDU6SXNzdWU1MDgwMzMyMDY=", "number": 905, "title": "[Bug] add_jitter fails with AttributeError: other must be a LazyTensor at eval time", "user": {"login": "activatedgeek", "id": 3909933, "node_id": "MDQ6VXNlcjM5MDk5MzM=", "avatar_url": "https://avatars.githubusercontent.com/u/3909933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/activatedgeek", "html_url": "https://github.com/activatedgeek", "followers_url": "https://api.github.com/users/activatedgeek/followers", "following_url": "https://api.github.com/users/activatedgeek/following{/other_user}", "gists_url": "https://api.github.com/users/activatedgeek/gists{/gist_id}", "starred_url": "https://api.github.com/users/activatedgeek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/activatedgeek/subscriptions", "organizations_url": "https://api.github.com/users/activatedgeek/orgs", "repos_url": "https://api.github.com/users/activatedgeek/repos", "events_url": "https://api.github.com/users/activatedgeek/events{/privacy}", "received_events_url": "https://api.github.com/users/activatedgeek/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1607680352, "node_id": "MDU6TGFiZWwxNjA3NjgwMzUy", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/variational", "name": "variational", "color": "ffffff", "default": false, "description": "For questions about variational inference"}], "state": "closed", "locked": false, "assignee": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-10-16T18:49:08Z", "updated_at": "2019-11-11T16:21:52Z", "closed_at": "2019-11-11T16:21:52Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nUsing `add_jitter` with the covariance module fails at eval time.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n\r\n1. Start from the example https://github.com/cornellius-gp/gpytorch/blob/master/examples/05_Scalable_GP_Regression_Multidimensional/SVGP_Regression_CUDA.ipynb\r\n\r\n2. Optionally, replace `WhitenedVariationalStrategy` with `VariationalStrategy` in `GPModel.__init__`\r\n\r\n3. Replace `self.covar_module(x)` with `self.covar_module(x).add_jitter(1e-6)` in `GPModel.forward`\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-6-c955f39ee560> in <module>\r\n      4 with torch.no_grad():\r\n      5     for x_batch, y_batch in test_loader:\r\n----> 6         preds = model(x_batch)\r\n      7         means = torch.cat([means, preds.mean.cpu()])\r\n      8 means = means[1:]\r\n\r\n~/miniconda3/envs/mbrl/lib/python3.7/site-packages/gpytorch/models/abstract_variational_gp.py in __call__(self, inputs, **kwargs)\r\n     20             inputs = inputs.unsqueeze(-1)\r\n     21 \r\n---> 22         return self.variational_strategy(inputs)\r\n\r\n~/miniconda3/envs/mbrl/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py in __call__(self, x)\r\n    228                 self._memoize_cache = dict()\r\n    229 \r\n--> 230         return super(VariationalStrategy, self).__call__(x)\r\n\r\n~/miniconda3/envs/mbrl/lib/python3.7/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     20 \r\n     21     def __call__(self, *inputs, **kwargs):\r\n---> 22         outputs = self.forward(*inputs, **kwargs)\r\n     23         if isinstance(outputs, list):\r\n     24             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/miniconda3/envs/mbrl/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py in forward(self, x)\r\n    214                     induc_induc_covar.inv_matmul(induc_data_covar)\r\n    215                 )\r\n--> 216                 data_covariance = data_data_covar + neg_induc_data_data_covar\r\n    217             predictive_covar = PsdSumLazyTensor(predictive_covar, data_covariance)\r\n    218 \r\n\r\n~/miniconda3/envs/mbrl/lib/python3.7/site-packages/gpytorch/lazy/sum_lazy_tensor.py in __add__(self, other)\r\n     75             return SumLazyTensor(*(list(self.lazy_tensors) + [other]))\r\n     76         else:\r\n---> 77             raise AttributeError(\"other must be a LazyTensor\")\r\n     78 \r\n     79     def diag(self):\r\n\r\nAttributeError: other must be a LazyTensor\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThe model to return outputs like always.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version: `0.3.6`\r\n- PyTorch Version: `1.2.0`\r\n- OS Version: `Ubuntu 18.04.3 LTS`\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/905/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/905/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/904", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/904/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/904/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/904/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/904", "id": 508024678, "node_id": "MDU6SXNzdWU1MDgwMjQ2Nzg=", "number": 904, "title": "[Bug] CatLazyTensor fails matrix multiplication on Rectangular InterpolatedLazyTensors", "user": {"login": "wecacuee", "id": 161433, "node_id": "MDQ6VXNlcjE2MTQzMw==", "avatar_url": "https://avatars.githubusercontent.com/u/161433?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wecacuee", "html_url": "https://github.com/wecacuee", "followers_url": "https://api.github.com/users/wecacuee/followers", "following_url": "https://api.github.com/users/wecacuee/following{/other_user}", "gists_url": "https://api.github.com/users/wecacuee/gists{/gist_id}", "starred_url": "https://api.github.com/users/wecacuee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wecacuee/subscriptions", "organizations_url": "https://api.github.com/users/wecacuee/orgs", "repos_url": "https://api.github.com/users/wecacuee/repos", "events_url": "https://api.github.com/users/wecacuee/events{/privacy}", "received_events_url": "https://api.github.com/users/wecacuee/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-16T18:33:06Z", "updated_at": "2019-10-16T19:25:22Z", "closed_at": "2019-10-16T19:25:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nCatLazyTensor fails matrix multiplication on Rectangular InterpolatedLazyTensors. I think the bug is withing InterpolatedLazyTensors.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport torch\r\nfrom gpytorch.lazy import InterpolatedLazyTensor, NonLazyTensor, CatLazyTensor\r\n\r\ncatlzt = CatLazyTensor(\r\n        InterpolatedLazyTensor(NonLazyTensor(torch.rand(4, 2)),\r\n                               left_interp_indices=torch.arange(4).reshape(4,1),\r\n                               left_interp_values=torch.ones((4,1)),\r\n                               right_interp_indices=torch.arange(2).reshape(2,1),\r\n                               right_interp_values=torch.ones((2,1))),\r\n        InterpolatedLazyTensor(NonLazyTensor(torch.rand(2, 2)),\r\n                               left_interp_indices=torch.arange(2).reshape(2,1),\r\n                               left_interp_values=torch.ones((2,1)),\r\n                               right_interp_indices=torch.arange(2).reshape(2,1),\r\n                               right_interp_values=torch.ones((2,1))))\r\nres = catlzt @ torch.eye(2)\r\nassert res.shape == (6, 2)\r\n```\r\n\r\n** Stack trace/error message **\r\n``` \r\n File \"<ipython-input-5-d4b789a61558>\", line 15, in <module>\r\n    res = catlzt @ torch.eye(2)\r\n  File \"/home/vdhiman/wrk/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 1731, in __matmul__\r\n    return self.matmul(other)\r\n  File \"/home/vdhiman/wrk/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 1098, in matmul\r\n    return func.apply(self.representation_tree(), other, *self.representation())\r\n  File \"/home/vdhiman/wrk/gpytorch/gpytorch/functions/_matmul.py\", line 20, in forward\r\n    res = lazy_tsr._matmul(rhs)\r\n  File \"/home/vdhiman/wrk/gpytorch/gpytorch/lazy/cat_lazy_tensor.py\", line 244, in _matmul\r\n    for t, rhs in zip(self.lazy_tensors, rhs_)]\r\n  File \"/home/vdhiman/wrk/gpytorch/gpytorch/lazy/cat_lazy_tensor.py\", line 244, in <listcomp>\r\n    for t, rhs in zip(self.lazy_tensors, rhs_)]\r\n  File \"/home/vdhiman/wrk/gpytorch/gpytorch/lazy/interpolated_lazy_tensor.py\", line 159, in _matmul\r\n    left_interp_t = self._sparse_left_interp_t(self.left_interp_indices, self.left_interp_values)\r\n  File \"/home/vdhiman/wrk/gpytorch/gpytorch/lazy/interpolated_lazy_tensor.py\", line 311, in _sparse_left_interp_t\r\n    left_interp_indices_tensor, left_interp_values_tensor, self.base_lazy_tensor.size()[-1]\r\n  File \"/home/vdhiman/wrk/gpytorch/gpytorch/utils/sparse.py\", line 61, in make_sparse_from_indices_and_values\r\n    res = cls(index_tensor, value_tensor, interp_size)\r\nRuntimeError: size is inconsistent with indices: for dim 0, size is 2 but found index 3\r\n\r\n```\r\n\r\n## Expected Behavior\r\n\r\nExpect the matrix multiplication to succeed\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version origin/master (v0.3.5)\r\n- PyTorch Version 1.2\r\n- Ubuntu 16.04\r\n\r\n## Additional information\r\nProbably related to #900 ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/904/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/904/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/900", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/900/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/900/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/900/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/900", "id": 507001818, "node_id": "MDU6SXNzdWU1MDcwMDE4MTg=", "number": 900, "title": "[Bug] `InterpolatedLazyTensor` cannot handle rectangular `base_lazy_tensors`", "user": {"login": "wecacuee", "id": 161433, "node_id": "MDQ6VXNlcjE2MTQzMw==", "avatar_url": "https://avatars.githubusercontent.com/u/161433?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wecacuee", "html_url": "https://github.com/wecacuee", "followers_url": "https://api.github.com/users/wecacuee/followers", "following_url": "https://api.github.com/users/wecacuee/following{/other_user}", "gists_url": "https://api.github.com/users/wecacuee/gists{/gist_id}", "starred_url": "https://api.github.com/users/wecacuee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wecacuee/subscriptions", "organizations_url": "https://api.github.com/users/wecacuee/orgs", "repos_url": "https://api.github.com/users/wecacuee/repos", "events_url": "https://api.github.com/users/wecacuee/events{/privacy}", "received_events_url": "https://api.github.com/users/wecacuee/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-10-15T04:44:25Z", "updated_at": "2019-10-16T19:25:07Z", "closed_at": "2019-10-16T19:25:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n`InterpolatedLazyTensor` results in error when base_lazy_tensor is not square\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n    itplzt = InterpolatedLazyTensor(NonLazyTensor(torch.rand(2, 3)))\r\n    res = itplzt @ torch.eye(3)\r\n    assert res.shape == (2, 3)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n(py37) vdhiman@dwarf:~/wrk/BayesCBF_ws/BayesCBF$ python tests/test_interpolated_lazy_tensor.py \r\nTraceback (most recent call last):\r\n  File \"tests/test_interpolated_lazy_tensor.py\", line 30, in <module>\r\n    test_interpolated_lazy_tensor()\r\n  File \"tests/test_interpolated_lazy_tensor.py\", line 7, in test_interpolated_lazy_tensor\r\n    res = itplzt @ torch.eye(3)\r\n  File \"/home/vdhiman/wrk/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 1731, in __matmul__\r\n    return self.matmul(other)\r\n  File \"/home/vdhiman/wrk/gpytorch/gpytorch/lazy/interpolated_lazy_tensor.py\", line 393, in matmul\r\n    right_interp_res = left_t_interp(self.right_interp_indices, self.right_interp_values, tensor, base_size)\r\n  File \"/home/vdhiman/wrk/gpytorch/gpytorch/utils/interpolation.py\", line 202, in left_t_interp\r\n    values = rhs.unsqueeze(-2) * interp_values.unsqueeze(-1)\r\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0\r\n```\r\n\r\n## Expected Behavior\r\n\r\nExpect res to be a Tensor of size (2,3)\r\n\r\n## System information\r\n\r\n- GPyTorch Version 0.3.5 \r\n- PyTorch Version 1.2.0\r\n- Ubuntu 16.04.6 LTS\r\n\r\n## Additional information\r\nThe test cases in `test_interpolated_lazy_tensor.py` carefully construct PSD, square symmetric `base_lazy_tensor`s but the constructor or the documentation does not say so. I am specifically getting errors when `InterpolatedLazyTensor` is being constructed at `lazy_tensor.py:307`. In that case, the `baze_lazy_tensor` is not square.\r\nAdding the following test case to `test_interpolated_lazy_tensor.py` fails almost all test cases\r\n```python\r\nclass TestInterpolatedLazyTensorRectangular(LazyTensorTestCase, unittest.TestCase):\r\n    def create_lazy_tensor(self):\r\n        itplzt = InterpolatedLazyTensor(NonLazyTensor(torch.rand(2, 3)))\r\n        return itplzt\r\n\r\n    def evaluate_lazy_tensor(self, lazy_tensor):\r\n        return lazy_tensor.base_lazy_tensor.tensor\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/900/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/900/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/895", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/895/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/895/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/895/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/895", "id": 503523869, "node_id": "MDU6SXNzdWU1MDM1MjM4Njk=", "number": 895, "title": "[Bug] Interpolation gives wrong interp_values next to the left boundary", "user": {"login": "NinelK", "id": 1615928, "node_id": "MDQ6VXNlcjE2MTU5Mjg=", "avatar_url": "https://avatars.githubusercontent.com/u/1615928?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NinelK", "html_url": "https://github.com/NinelK", "followers_url": "https://api.github.com/users/NinelK/followers", "following_url": "https://api.github.com/users/NinelK/following{/other_user}", "gists_url": "https://api.github.com/users/NinelK/gists{/gist_id}", "starred_url": "https://api.github.com/users/NinelK/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NinelK/subscriptions", "organizations_url": "https://api.github.com/users/NinelK/orgs", "repos_url": "https://api.github.com/users/NinelK/repos", "events_url": "https://api.github.com/users/NinelK/events{/privacy}", "received_events_url": "https://api.github.com/users/NinelK/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2019-10-07T15:23:39Z", "updated_at": "2019-10-08T21:43:29Z", "closed_at": "2019-10-08T21:43:29Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nInterpolation utility returns asymetric interp_values for symmetric grid & inputs.\r\nThe problem arises next to the left boundary, where all points between gridpoint-0 and gridpoint-2 are interpolated with the same value (this should not happen)!\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport numpy\r\nimport torch\r\n\r\ngrid_size = 8\r\ngrid_bounds=[(0, 1)]\r\ngrid = torch.zeros(grid_size, len(grid_bounds))\r\nfor i in range(len(grid_bounds)):\r\n    grid_diff = float(grid_bounds[i][1] - grid_bounds[i][0]) / (grid_size - 2)\r\n    grid[:, i] = torch.linspace(grid_bounds[i][0] - grid_diff, grid_bounds[i][1] + grid_diff, grid_size)\r\n\r\nfrom gpytorch.utils.interpolation import Interpolation\r\n\r\ninputs = torch.tensor([0.0,0.1,0.2,0.3,0.5,0.7,0.8,0.9,1.0]).unsqueeze(1)\r\ninterp_indices, interp_values = Interpolation().interpolate(grid, inputs)\r\n\r\ninterp_values\r\n\r\n```\r\n\r\nFor symmetric input (see above), this code returns the following (asymetric!) interp_values, where 2nd and 3rd rows are incorrect:\r\n```\r\ntensor([[ 0.0000,  1.0000,  0.0000,  0.0000],\r\n        [ 0.0000,  1.0000,  0.0000,  0.0000],\r\n        [ 0.0000,  0.0000,  1.0000,  0.0000],\r\n        [-0.0681,  0.6304,  0.4933, -0.0557],\r\n        [-0.0625,  0.5625,  0.5625, -0.0625],\r\n        [-0.0557,  0.4933,  0.6304, -0.0681],\r\n        [-0.0321,  0.9866,  0.0481, -0.0026],\r\n        [-0.0480,  0.4240,  0.6960, -0.0720],\r\n        [ 0.0000,  0.0000,  1.0000,  0.0000]])\r\n```\r\n\r\nand correct interp_indices:\r\n```\r\ntensor([[0, 1, 2, 3],\r\n        [0, 1, 2, 3],\r\n        [0, 1, 2, 3],\r\n        [1, 2, 3, 4],\r\n        [2, 3, 4, 5],\r\n        [3, 4, 5, 6],\r\n        [4, 5, 6, 7],\r\n        [4, 5, 6, 7],\r\n        [4, 5, 6, 7]])\r\n```\r\n\r\n## Expected Behavior\r\n\r\nShould return symmetric interp_values for symmetric grid & inputs:\r\n```\r\ntensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\r\n        [-7.2000e-02,  6.9600e-01,  4.2400e-01, -4.8000e-02],\r\n        [-2.6014e-03,  4.8117e-02,  9.8657e-01, -3.2086e-02],\r\n        [-6.8063e-02,  6.3044e-01,  4.9331e-01, -5.5688e-02],\r\n        [-3.0470e-04,  1.3726e-02,  9.9846e-01, -1.1883e-02],\r\n        [-6.2500e-02,  5.6250e-01,  5.6250e-01, -6.2500e-02],\r\n        [-1.1883e-02,  9.9846e-01,  1.3727e-02, -3.0470e-04],\r\n        [-3.2086e-02,  9.8657e-01,  4.8117e-02, -2.6019e-03],\r\n        [-4.8000e-02,  4.2400e-01,  6.9600e-01, -7.2000e-02],\r\n        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00]])\r\n```\r\n\r\n## Additional context\r\n\r\nThe solution will follow shortly (#896).\r\nIt basically replaces 1->0 in one line.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/895/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/895/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/884", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/884/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/884/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/884/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/884", "id": 499438310, "node_id": "MDU6SXNzdWU0OTk0MzgzMTA=", "number": 884, "title": "[Bug] MaternKernel works incorrectly", "user": {"login": "yeahrmek", "id": 4017554, "node_id": "MDQ6VXNlcjQwMTc1NTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/4017554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yeahrmek", "html_url": "https://github.com/yeahrmek", "followers_url": "https://api.github.com/users/yeahrmek/followers", "following_url": "https://api.github.com/users/yeahrmek/following{/other_user}", "gists_url": "https://api.github.com/users/yeahrmek/gists{/gist_id}", "starred_url": "https://api.github.com/users/yeahrmek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yeahrmek/subscriptions", "organizations_url": "https://api.github.com/users/yeahrmek/orgs", "repos_url": "https://api.github.com/users/yeahrmek/repos", "events_url": "https://api.github.com/users/yeahrmek/events{/privacy}", "received_events_url": "https://api.github.com/users/yeahrmek/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-09-27T13:13:19Z", "updated_at": "2019-09-27T16:43:16Z", "closed_at": "2019-09-27T16:42:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen I try to calculate gradient of some function, that depends on GP, w.r.t. **one** input point I obtain different results in different runs though the input is the same.\r\n\r\nLooks like the problem with the `MaternKernel`, because when I switch to `RBFKernel` everything works correctly. Also, when I calculate the gradient w.r.t. to several input points (not one) it works correctly as well with `MaternKernel`\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super().__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.MaternKernel()\r\n        )\r\n    \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n\r\nX = torch.randn(10, 2)\r\ny = X.sum(dim=1)**2\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = ExactGPModel(X, y, likelihood)\r\n\r\nx_test = torch.randn(1, 2)\r\nx_test.requires_grad_(True)\r\n\r\nmodel.eval()\r\n\r\n# Calculate gradient w.r.t. to the same input point 10 times\r\nfor _ in range(10):\r\n    loss = model(x_test).mean.sum()\r\n    loss.backward()\r\n\r\n    print(x_test.grad)\r\n    x_test = x_test.detach()\r\n    x_test.requires_grad_(True)\r\n```\r\n\r\nThe output looks like this\r\n```\r\ntensor([[-9.0657e+31,  6.2069e+31]])\r\ntensor([[-0.1179,  0.0331]])\r\ntensor([[-0.1179,  0.0331]])\r\ntensor([[-0.1179,  0.0331]])\r\ntensor([[-0.1179,  0.0331]])\r\ntensor([[-0.1179,  0.0331]])\r\ntensor([[-0.1179,  0.0331]])\r\ntensor([[-0.1179,  0.0331]])\r\ntensor([[-0.0790, -0.0018]])\r\ntensor([[ 0.1508, -0.3041]])\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThe same output at each iteration\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch==0.3.5\r\n- PyTorch==1.2.0\r\n- OS: Ubuntu 19.04\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/884/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/884/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/875", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/875/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/875/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/875/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/875", "id": 494577232, "node_id": "MDU6SXNzdWU0OTQ1NzcyMzI=", "number": 875, "title": "reproducing the svgp results in exact 1 million gp paper", "user": {"login": "thjashin", "id": 5267554, "node_id": "MDQ6VXNlcjUyNjc1NTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/5267554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thjashin", "html_url": "https://github.com/thjashin", "followers_url": "https://api.github.com/users/thjashin/followers", "following_url": "https://api.github.com/users/thjashin/following{/other_user}", "gists_url": "https://api.github.com/users/thjashin/gists{/gist_id}", "starred_url": "https://api.github.com/users/thjashin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thjashin/subscriptions", "organizations_url": "https://api.github.com/users/thjashin/orgs", "repos_url": "https://api.github.com/users/thjashin/repos", "events_url": "https://api.github.com/users/thjashin/events{/privacy}", "received_events_url": "https://api.github.com/users/thjashin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-09-17T11:55:26Z", "updated_at": "2019-09-21T10:36:20Z", "closed_at": "2019-09-21T10:36:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\r\n\r\nI tried to reproduced the svgp results in the [exact 1 million gp paper](https://arxiv.org/pdf/1903.08114.pdf) during which I found several things:\r\n\r\n* It seems that the dataset does not split into 2/3 training and 1/3 test as described because the number of training data in table 1 is not 2/3 of the whole dataset, e.g., for kin40k, 25,600 is not 2/3 of 40000. So what's the true proportion used?\r\n\r\n* I cannot reproduce the results for elevators dataset if I randomly shuffle the dataset. And I found that [the code for elevators in this repo](https://github.com/cornellius-gp/gpytorch/blob/master/examples/13_Deep_Gaussian_Processes/Deep_Gaussian_Processes.ipynb) has a mistake in shuffling data: \r\n```\r\ndata = torch.Tensor(loadmat('elevators.mat')['data'])\r\nX = data[:, :-1]\r\ny = data[:, -1]\r\n\r\nN = data.shape[0]\r\nnp.random.seed(0)\r\ndata = data[np.random.permutation(np.arange(N)),:]\r\n```\r\nit splits into feature and labels before doing the shuffle which means that the data used is not shuffled. When not shuffled, the number seems to match the one reported in the paper.\r\n\r\n* It seems that the test rmse in the paper are computed without considering the normalization of the testing data. For which the true rmse should multiply the std used for normalization. Can you clarify if you directly compute the rmse based on the normalized data?\r\n\r\nSince the exact gp on 1 million data points paper refers to this library for the source code. I'm raising this issue here. Hope you can help clarify.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/875/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/875/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/873", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/873/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/873/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/873/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/873", "id": 494158372, "node_id": "MDU6SXNzdWU0OTQxNTgzNzI=", "number": 873, "title": "[Bug] LinearMean bias fix", "user": {"login": "stanbiryukov", "id": 36061055, "node_id": "MDQ6VXNlcjM2MDYxMDU1", "avatar_url": "https://avatars.githubusercontent.com/u/36061055?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stanbiryukov", "html_url": "https://github.com/stanbiryukov", "followers_url": "https://api.github.com/users/stanbiryukov/followers", "following_url": "https://api.github.com/users/stanbiryukov/following{/other_user}", "gists_url": "https://api.github.com/users/stanbiryukov/gists{/gist_id}", "starred_url": "https://api.github.com/users/stanbiryukov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stanbiryukov/subscriptions", "organizations_url": "https://api.github.com/users/stanbiryukov/orgs", "repos_url": "https://api.github.com/users/stanbiryukov/repos", "events_url": "https://api.github.com/users/stanbiryukov/events{/privacy}", "received_events_url": "https://api.github.com/users/stanbiryukov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-09-16T16:38:19Z", "updated_at": "2019-09-16T21:54:58Z", "closed_at": "2019-09-16T21:54:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nThe linear mean kernel fails when bias is not set to True.\r\n\r\n## To reproduce\r\nExample google colab notebook with error and solution:\r\nhttps://colab.research.google.com/drive/19mF1xPoH7r7DvywodQ34do9IjAA_lfDd\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nfrom gpytorch.means import Mean\r\n\r\n## Fix by registering bias as None first\r\nclass LBMean(Mean):\r\n    def __init__(self, input_size, batch_shape=torch.Size(), bias=True):\r\n        super().__init__()\r\n        self.register_parameter(name='weights',\r\n                                parameter=torch.nn.Parameter(torch.randn(*batch_shape, input_size, 1)))\r\n        self.register_parameter('bias', None)\r\n        if bias:\r\n            self.register_parameter(name='bias', parameter=torch.nn.Parameter(torch.randn(*batch_shape, 1)))\r\n        \r\n    def forward(self, x):\r\n        res = x.matmul(self.weights).squeeze(-1)\r\n        if self.bias is not None:\r\n            res = res + self.bias\r\n        return res\r\n\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = LinearMean(input_size=train_x.shape[-1], bias=None) # doesn't work with no bias\r\n        # self.mean_module = LBMean(input_size=train_x.shape[-1], bias=None) # this works\r\n        self.base_covar_module = ScaleKernel(RBFKernel())\r\n        self.covar_module = InducingPointKernel(self.base_covar_module, inducing_points=train_x[:500, :], likelihood=likelihood)\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return MultivariateNormal(mean_x, covar_x)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n\r\nAttributeError: 'LinearMean' object has no attribute 'bias'\r\n\r\n```\r\n\r\n## Expected Behavior\r\nSuccessful training\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` -->\r\n0.3.5\r\n- <!-- PyTorch Version (run `print(torch.__version__)` -->\r\n1.1.0\r\n- <!-- Computer OS -->\r\nposix.uname_result(sysname='Linux', nodename='c02afd15d7f2', release='4.14.137+', version='#1 SMP Thu Aug 8 02:47:02 PDT 2019', machine='x86_64')\r\n\r\n## Additional context\r\nWe just need to register the bias parameter as None first for it to work in the forward pass syntax.  See LBMean definition above.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/873/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/873/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/870", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/870/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/870/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/870/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/870", "id": 493084127, "node_id": "MDExOlB1bGxSZXF1ZXN0MzE3MTMzODgz", "number": 870, "title": "Fix MLL computation for heteroskedastic noise models", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 623304448, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDg=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-09-13T00:16:46Z", "updated_at": "2019-10-04T03:53:29Z", "closed_at": "2019-10-04T03:53:25Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/870", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/870", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/870.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/870.patch", "merged_at": "2019-10-04T03:53:25Z"}, "body": "Previously, when using a heteroskedastic noise model with a separate model providing the noise, joint training would not work properly because\r\n1. the noise model would be evaluated in prior mode (wheras we need the noise model's posterior predictions for the noise in the actual model)\r\n2. the MLL did not account for the MLL of the noise model.\r\n\r\nFor 1. the fix is to simply ensure that the noise model is in eval mode when called inside `HeteroskedasticNoise`'s `forward` method. Note that this also requires ensuring to not detach the test caches of the main model during evaluation, since o/w some of the noise model's parameters are chopped off from the compute graph.\r\n\r\nFor 2. this PR introduces the `NoiseModelAddedLossTerm`.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/870/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/870/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/866", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/866/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/866/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/866/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/866", "id": 492796829, "node_id": "MDU6SXNzdWU0OTI3OTY4Mjk=", "number": 866, "title": "[Bug] SumBatchLazyTensor size is inconsistent with indices", "user": {"login": "panaali", "id": 705865, "node_id": "MDQ6VXNlcjcwNTg2NQ==", "avatar_url": "https://avatars.githubusercontent.com/u/705865?v=4", "gravatar_id": "", "url": "https://api.github.com/users/panaali", "html_url": "https://github.com/panaali", "followers_url": "https://api.github.com/users/panaali/followers", "following_url": "https://api.github.com/users/panaali/following{/other_user}", "gists_url": "https://api.github.com/users/panaali/gists{/gist_id}", "starred_url": "https://api.github.com/users/panaali/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/panaali/subscriptions", "organizations_url": "https://api.github.com/users/panaali/orgs", "repos_url": "https://api.github.com/users/panaali/repos", "events_url": "https://api.github.com/users/panaali/events{/privacy}", "received_events_url": "https://api.github.com/users/panaali/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-09-12T13:11:25Z", "updated_at": "2019-09-13T19:29:24Z", "closed_at": "2019-09-13T19:29:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI want to do a KroneckerProductLazyTensor on a batch of lazyTensor `x` times, then SumBatchLazyTensor and then get a specific row and finally evaluate. The code works if I first do an evaluation on the `sum_a` then retrieve the row (which is inefficient) but gives `size is inconsistent with indices` error if I retrieve the row first and then wants to evaluate.\r\n\r\nInterestingly, If I use the same number for the dimension -1 and -2, there would be no error then.\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport gpytorch\r\nx = 3\r\na = torch.rand((x, 5, 2, 3))\r\nlazy_a = gpytorch.lazy.NonLazyTensor(a)\r\nassert lazy_a.shape == torch.Size([3, 5, 2, 3])\r\nprod_a = gpytorch.lazy.KroneckerProductLazyTensor(*lazy_a)\r\nassert prod_a.shape == torch.Size([5, 8, 27])\r\nsum_a = gpytorch.lazy.SumBatchLazyTensor(prod_a)\r\nassert sum_a.shape == torch.Size([8, 27])\r\nassert sum_a.evaluate()[0].shape == torch.Size([27])\r\nassert sum_a[0].evaluate().shape == torch.Size([27]) # gives error in here\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-251-7cce10ce99d3> in <module>()\r\n      8 assert sum_a.shape == torch.Size([8, 27])\r\n      9 assert sum_a.evaluate()[0].shape == torch.Size([27])\r\n---> 10 assert sum_a[0].evaluate().shape == torch.Size([27])\r\n     11 \r\n\r\n9 frames\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/lazy/lazy_tensor.py in __getitem__(self, index)\r\n   1703         # with the appropriate shape\r\n   1704         if (squeeze_row or squeeze_col or row_col_are_absorbed):\r\n-> 1705             res = delazify(res)\r\n   1706         if squeeze_row:\r\n   1707             res = res.squeeze(-2)\r\n\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/lazy/lazy_tensor.py in delazify(obj)\r\n   1753         return obj\r\n   1754     elif isinstance(obj, LazyTensor):\r\n-> 1755         return obj.evaluate()\r\n   1756     else:\r\n   1757         raise TypeError(\"object of class {} cannot be made into a Tensor\".format(obj.__class__.__name__))\r\n\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36 \r\n\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/lazy/lazy_tensor.py in evaluate(self)\r\n    858             eye = torch.eye(num_rows, dtype=self.dtype, device=self.device)\r\n    859             eye = eye.expand(*self.batch_shape, num_rows, num_rows)\r\n--> 860             res = self.transpose(-1, -2).matmul(eye).transpose(-1, -2).contiguous()\r\n    861         else:\r\n    862             eye = torch.eye(num_cols, dtype=self.dtype, device=self.device)\r\n\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/lazy/lazy_tensor.py in matmul(self, other)\r\n   1093 \r\n   1094         func = Matmul()\r\n-> 1095         return func.apply(self.representation_tree(), other, *self.representation())\r\n   1096 \r\n   1097     @property\r\n\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/functions/_matmul.py in forward(ctx, representation_tree, rhs, *matrix_args)\r\n     18 \r\n     19         lazy_tsr = ctx.representation_tree(*matrix_args)\r\n---> 20         res = lazy_tsr._matmul(rhs)\r\n     21 \r\n     22         to_save = [orig_rhs] + list(matrix_args)\r\n\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/lazy/block_lazy_tensor.py in _matmul(self, rhs)\r\n     64 \r\n     65         rhs = self._add_batch_dim(rhs)\r\n---> 66         res = self.base_lazy_tensor._matmul(rhs)\r\n     67         res = self._remove_batch_dim(res)\r\n     68 \r\n\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/lazy/interpolated_lazy_tensor.py in _matmul(self, rhs)\r\n    157     def _matmul(self, rhs):\r\n    158         # Get sparse tensor representations of left/right interp matrices\r\n--> 159         left_interp_t = self._sparse_left_interp_t(self.left_interp_indices, self.left_interp_values)\r\n    160         right_interp_t = self._sparse_right_interp_t(self.right_interp_indices, self.right_interp_values)\r\n    161 \r\n\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/lazy/interpolated_lazy_tensor.py in _sparse_left_interp_t(self, left_interp_indices_tensor, left_interp_values_tensor)\r\n    309 \r\n    310         left_interp_t = sparse.make_sparse_from_indices_and_values(\r\n--> 311             left_interp_indices_tensor, left_interp_values_tensor, self.base_lazy_tensor.size()[-1]\r\n    312         )\r\n    313         self._left_interp_indices_memo = left_interp_indices_tensor\r\n\r\n/usr/local/lib/python3.6/dist-packages/gpytorch/utils/sparse.py in make_sparse_from_indices_and_values(interp_indices, interp_values, num_rows)\r\n     59     else:\r\n     60         cls = getattr(torch.sparse, type_name)\r\n---> 61     res = cls(index_tensor, value_tensor, interp_size)\r\n     62 \r\n     63     # Wrap things as a variable, if necessary\r\n\r\nRuntimeError: size is inconsistent with indices: for dim 1, size is 8 but found index 26\r\n```\r\n\r\n## Expected Behavior\r\n\r\nExpected to pass the tests.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version 0.3.5\r\n- PyTorch Version 1.2.0\r\n- Ubuntu 18.04.3 LTS\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/866/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/866/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/837", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/837/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/837/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/837/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/837", "id": 480242982, "node_id": "MDU6SXNzdWU0ODAyNDI5ODI=", "number": 837, "title": "[Bug] Issue with double and spectral mixture kernel", "user": {"login": "wtstephe", "id": 1521541, "node_id": "MDQ6VXNlcjE1MjE1NDE=", "avatar_url": "https://avatars.githubusercontent.com/u/1521541?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wtstephe", "html_url": "https://github.com/wtstephe", "followers_url": "https://api.github.com/users/wtstephe/followers", "following_url": "https://api.github.com/users/wtstephe/following{/other_user}", "gists_url": "https://api.github.com/users/wtstephe/gists{/gist_id}", "starred_url": "https://api.github.com/users/wtstephe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wtstephe/subscriptions", "organizations_url": "https://api.github.com/users/wtstephe/orgs", "repos_url": "https://api.github.com/users/wtstephe/repos", "events_url": "https://api.github.com/users/wtstephe/events{/privacy}", "received_events_url": "https://api.github.com/users/wtstephe/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-13T16:09:25Z", "updated_at": "2019-08-13T16:44:22Z", "closed_at": "2019-08-13T16:44:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen initializing a spectral mixture kernel using initialize_from_data() with data of type torch.DoubleTensor, the initialization crashes. I think the problem is the line in spectral_mixture_kernel.py, which always creates a tensor of type torch.FloatTensor:\r\n\r\n```python\r\nmin_dist = torch.zeros(1, self.ard_num_dims)\r\n```\r\nThe following fixed this for me:\r\n```python\r\nmin_dist = torch.zeros(1, self.ard_num_dims).type(train_x.type())\r\n```\r\n\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\nX = torch.sin(torch.linspace(0,1)).double()\r\nY = torch.sin(torch.linspace(0,1)).double() + 4.5\r\n\r\ncovar_module = gpytorch.kernels.SpectralMixtureKernel(num_mixtures=10)\r\ncovar_module.double()\r\ncovar_module.initialize_from_data(X, Y)\r\n\r\n```\r\nError message:\r\n```\r\nTraceback (most recent call last):\r\n  File \"breakSpectralMixtureKernel.py\", line 9, in <module>\r\n    covar_module.initialize_from_data(X, Y)\r\n  File \"/home/will/anaconda3/lib/python3.6/site-packages/gpytorch-0.3.3-py3.6.egg/gpytorch/kernels/spectral_mixture_kernel.py\", line 163, in initialize_from_data\r\nRuntimeError: output with backend CPU and dtype Float doesn't match the desired backend CPU and dtype Double\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/837/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/837/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/823", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/823/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/823/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/823/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/823", "id": 475899862, "node_id": "MDExOlB1bGxSZXF1ZXN0MzAzNTYzNTQ4", "number": 823, "title": "Fix issues due to upstream change of tensor comparison behavior", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 859608502, "node_id": "MDU6TGFiZWw4NTk2MDg1MDI=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/compatibility", "name": "compatibility", "color": "ebef7a", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-08-01T21:35:46Z", "updated_at": "2019-08-01T22:04:31Z", "closed_at": "2019-08-01T22:04:28Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/823", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/823", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/823.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/823.patch", "merged_at": "2019-08-01T22:04:28Z"}, "body": "Addresses #822", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/823/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/823/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/822", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/822/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/822/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/822/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/822", "id": 475878426, "node_id": "MDU6SXNzdWU0NzU4Nzg0MjY=", "number": 822, "title": "[Bug] Upstream changes to tensor comparisons breaks things", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 859608502, "node_id": "MDU6TGFiZWw4NTk2MDg1MDI=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/compatibility", "name": "compatibility", "color": "ebef7a", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2019-08-01T20:39:09Z", "updated_at": "2019-08-02T18:25:19Z", "closed_at": "2019-08-02T18:25:19Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nAfter https://github.com/pytorch/pytorch/pull/21113 a bunch of tests are failing b/c of the change in tensor comparison behavior (return type from uint8 to bool). Creating this issue to track the fix. ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/822/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/822/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/816", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/816/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/816/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/816/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/816", "id": 474739958, "node_id": "MDU6SXNzdWU0NzQ3Mzk5NTg=", "number": 816, "title": "[Bug] Request to re-open: SpectralMixtureKernel initialize_from_data CUDA bug", "user": {"login": "adam-rysanek", "id": 14067405, "node_id": "MDQ6VXNlcjE0MDY3NDA1", "avatar_url": "https://avatars.githubusercontent.com/u/14067405?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adam-rysanek", "html_url": "https://github.com/adam-rysanek", "followers_url": "https://api.github.com/users/adam-rysanek/followers", "following_url": "https://api.github.com/users/adam-rysanek/following{/other_user}", "gists_url": "https://api.github.com/users/adam-rysanek/gists{/gist_id}", "starred_url": "https://api.github.com/users/adam-rysanek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adam-rysanek/subscriptions", "organizations_url": "https://api.github.com/users/adam-rysanek/orgs", "repos_url": "https://api.github.com/users/adam-rysanek/repos", "events_url": "https://api.github.com/users/adam-rysanek/events{/privacy}", "received_events_url": "https://api.github.com/users/adam-rysanek/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-30T18:27:53Z", "updated_at": "2019-07-30T18:37:32Z", "closed_at": "2019-07-30T18:35:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've written a comment on #737 . I am able to replicate that issue, and the advice suggested doesn't seem to work for me. I'm creating this new issue just to draw attention it to the response.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/816/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/816/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/811", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/811/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/811/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/811/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/811", "id": 474253131, "node_id": "MDU6SXNzdWU0NzQyNTMxMzE=", "number": 811, "title": "[Bug] RuntimeError when predicting from a model with updated parameter values", "user": {"login": "fonnesbeck", "id": 81476, "node_id": "MDQ6VXNlcjgxNDc2", "avatar_url": "https://avatars.githubusercontent.com/u/81476?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fonnesbeck", "html_url": "https://github.com/fonnesbeck", "followers_url": "https://api.github.com/users/fonnesbeck/followers", "following_url": "https://api.github.com/users/fonnesbeck/following{/other_user}", "gists_url": "https://api.github.com/users/fonnesbeck/gists{/gist_id}", "starred_url": "https://api.github.com/users/fonnesbeck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fonnesbeck/subscriptions", "organizations_url": "https://api.github.com/users/fonnesbeck/orgs", "repos_url": "https://api.github.com/users/fonnesbeck/repos", "events_url": "https://api.github.com/users/fonnesbeck/events{/privacy}", "received_events_url": "https://api.github.com/users/fonnesbeck/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-29T20:57:28Z", "updated_at": "2019-11-12T20:16:26Z", "closed_at": "2019-11-12T20:16:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to use 10-fold crossvalidation to select hyperparameters for my model, but hit a RuntimeError when calling the likelihood. \r\n\r\nThe error arises in this call:\r\n\r\n```python\r\nobserved_pred = likelihood(model(torch.Tensor(Z).contiguous().cuda()))\r\n```\r\n\r\nwhere Z is a grid of values, and the `model` and `likelihood` are for a single GP model. The hyperparameters of this model have been updated by averaging the parameters of the folds of a cross-validated model, run in batch mode. I have ensured that the parameters are of the same type and shape:\r\n\r\n### Original parameters\r\n\r\n```\r\nlikelihood.noise_covar.raw_noise tensor([-4.9271], device='cuda:0')\r\ncovar_module.raw_outputscale tensor(-5.0590, device='cuda:0')\r\ncovar_module.base_kernel.kernels.0.raw_variance tensor([[-5.0590]], device='cuda:0')\r\ncovar_module.base_kernel.kernels.1.raw_lengthscale tensor([[-0.1901, -0.5527]], device='cuda:0')\r\n```\r\n\r\n### New parameters\r\n\r\n```\r\nlikelihood.noise_covar.raw_noise tensor([-4.9184], device='cuda:0')\r\ncovar_module.raw_outputscale tensor(-5.4085, device='cuda:0')\r\ncovar_module.base_kernel.kernels.0.raw_variance tensor([[-5.4085]], device='cuda:0')\r\ncovar_module.base_kernel.kernels.1.raw_lengthscale tensor([[-4.3704, -4.3507]], device='cuda:0')\r\n```\r\n\r\nBut the following occurs:\r\n\r\n```\r\n~/spatial_pitch_effectiveness/notebooks/plotting.py in plot_heatmaps(model, X, y, cov_val, week, vmin, vmax, size_scale, name, cmap, lengthscale)\r\n     92 \r\n     93     with torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n---> 94         observed_pred = likelihood(model(torch.Tensor(Z).contiguous().cuda()))\r\n     95         pred_labels = observed_pred.mean.view(nd, nd)\r\n     96         pred_var = observed_pred.variance.view(nd, nd)\r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)\r\n    263             # Make the prediction\r\n    264             with settings._use_eval_tolerance():\r\n--> 265                 predictive_mean, predictive_covar = self.prediction_strategy.exact_prediction(full_mean, full_covar)\r\n    266 \r\n    267             # Reshape predictive mean to match the appropriate event shape\r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/gpytorch/models/exact_prediction_strategies.py in exact_prediction(self, joint_mean, joint_covar)\r\n    263         return (\r\n    264             self.exact_predictive_mean(test_mean, test_train_covar),\r\n--> 265             self.exact_predictive_covar(test_test_covar, test_train_covar),\r\n    266         )\r\n    267 \r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/gpytorch/models/exact_prediction_strategies.py in exact_predictive_covar(self, test_test_covar, test_train_covar)\r\n    328                 return test_test_covar + MatmulLazyTensor(test_train_covar, covar_correction_rhs.mul(-1))\r\n    329 \r\n--> 330         precomputed_cache = self.covar_cache\r\n    331         covar_inv_quad_form_root = self._exact_predictive_covar_inv_quad_form_root(precomputed_cache,\r\n    332                                                                                    test_train_covar)\r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36 \r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/gpytorch/models/exact_prediction_strategies.py in covar_cache(self)\r\n    224     def covar_cache(self):\r\n    225         train_train_covar = self.lik_train_train_covar\r\n--> 226         train_train_covar_inv_root = delazify(train_train_covar.root_inv_decomposition().root)\r\n    227         return self._exact_predictive_covar_inv_quad_form_cache(train_train_covar_inv_root, self._last_test_train_covar)\r\n    228 \r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36 \r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in root_inv_decomposition(self, initial_vectors, test_vectors)\r\n   1375                 )\r\n   1376 \r\n-> 1377         inv_roots = self._root_inv_decomposition(initial_vectors)\r\n   1378 \r\n   1379         # Choose the best of the inv_roots, if there were more than one initial vectors\r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in _root_inv_decomposition(self, initial_vectors)\r\n    612             inverse=True,\r\n    613             initial_vectors=initial_vectors,\r\n--> 614         )(*self.representation())\r\n    615 \r\n    616         if initial_vectors is not None and initial_vectors.size(-1) > 1:\r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/gpytorch/functions/_root_decomposition.py in forward(self, *matrix_args)\r\n     51             matrix_shape=self.matrix_shape,\r\n     52             batch_shape=self.batch_shape,\r\n---> 53             init_vecs=self.initial_vectors,\r\n     54         )\r\n     55 \r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/gpytorch/utils/lanczos.py in lanczos_tridiag(matmul_closure, max_iter, dtype, device, matrix_shape, batch_shape, init_vecs, num_init_vecs, tol)\r\n     71 \r\n     72     # Initial alpha value: alpha_0\r\n---> 73     r_vec = matmul_closure(q_0_vec)\r\n     74     alpha_0 = q_0_vec.mul(r_vec).sum(dim_dimension)\r\n     75 \r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py in _matmul(self, rhs)\r\n     38 \r\n     39     def _matmul(self, rhs):\r\n---> 40         return torch.addcmul(self._lazy_tensor._matmul(rhs), self._diag_tensor._diag.unsqueeze(-1), rhs)\r\n     41 \r\n     42     def add_diag(self, added_diag):\r\n\r\nRuntimeError: Expected object of backend CUDA but got backend CPU for argument #3 'tensor1'\r\n```\r\n\r\nI'm confused by the backend error, because everything is CUDA here--all I have done is swap out values, with the reassigned values being CUDA. I can confirm that the call runs without error with the original parameter values.\r\n\r\nRunning GPyTorch 0.3.2 and Torch 1.1.0.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/811/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/811/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/803", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/803/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/803/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/803/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/803", "id": 470824594, "node_id": "MDU6SXNzdWU0NzA4MjQ1OTQ=", "number": 803, "title": "AttributeError: 'LazyEvaluatedKernelTensor' object has no attribute 'lazy_tensors'", "user": {"login": "Akella17", "id": 16236287, "node_id": "MDQ6VXNlcjE2MjM2Mjg3", "avatar_url": "https://avatars.githubusercontent.com/u/16236287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Akella17", "html_url": "https://github.com/Akella17", "followers_url": "https://api.github.com/users/Akella17/followers", "following_url": "https://api.github.com/users/Akella17/following{/other_user}", "gists_url": "https://api.github.com/users/Akella17/gists{/gist_id}", "starred_url": "https://api.github.com/users/Akella17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Akella17/subscriptions", "organizations_url": "https://api.github.com/users/Akella17/orgs", "repos_url": "https://api.github.com/users/Akella17/repos", "events_url": "https://api.github.com/users/Akella17/events{/privacy}", "received_events_url": "https://api.github.com/users/Akella17/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-21T21:04:30Z", "updated_at": "2022-06-23T06:17:02Z", "closed_at": "2019-07-23T14:04:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "The ```gpytorch.settings.fast_pred_var()``` setting fails when I am using an additive kernel, i.e. a composition of an RBF kernel and Linear kernel. This however does not occur when the additive kernel is over two RBF kernels.\r\n\r\nTo reproduce this issue,\r\n```Python\r\nimport torch\r\nimport gpytorch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\nimport math\r\n\r\nclass GP_layer(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GP_layer, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        \r\n        self.covar_module_1 = gpytorch.kernels.RBFKernel(ard_num_dims=2, active_dims=torch.tensor([0,1]))\r\n        self.covar_module_2 = gpytorch.kernels.LinearKernel(active_dims=torch.tensor([2,3]))\r\n        self.covar_module = self.covar_module_1 + self.covar_module_2\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\ntrain_x = torch.stack((torch.linspace(0, 10, 1500), torch.linspace(0.5, 10.5, 1500), torch.linspace(3, 14, 1500), torch.linspace(7.5, 19.5, 1500)),1).cuda()\r\ntrain_y = (train_x[:,3]**2 - train_x[:,2])/10 + torch.cos(train_x[:,0] * (2 * math.pi)) + torch.sin(train_x[:,1] * (2 * math.pi)) + 0.1 * torch.randn(1500).cuda()\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood().cuda()\r\nmodel = GP_layer(train_x, train_y, likelihood).cuda()\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nmodel.train()\r\nlikelihood.train()\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3)\r\n\r\nfor _ in range(10):\r\n    optimizer.zero_grad()\r\n    outputs = model(train_x)\r\n    loss = -mll(outputs, train_y).mean()\r\n    loss.backward()\r\n    optimizer.step()\r\n\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\ntest_x = torch.stack((torch.linspace(0, 10, 17), torch.linspace(0.5, 10.5, 17), torch.linspace(3, 14, 17), torch.linspace(7.5, 19.5, 17)),1).cuda()\r\ntest_y = (test_x[:,3]**2 - test_x[:,2])/10 + torch.cos(test_x[:,0] * (2 * math.pi)) + torch.sin(test_x[:,1] * (2 * math.pi)) + 0.1 * torch.randn(17).cuda()\r\n\r\nwith gpytorch.settings.fast_pred_var():\r\n    outputs_y = model(test_x).mean\r\nprint(outputs_y.size())\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 46, in <module>\r\n    outputs_y = model(test_x).mean\r\n  File \"/home1/deepak/anaconda/envs/rl_proj/lib/python3.6/site-packages/gpytorch/models/exact_gp.py\", line 265, in __call__\r\n    predictive_mean, predictive_covar = self.prediction_strategy.exact_prediction(full_mean, full_covar)\r\n  File \"/home1/deepak/anaconda/envs/rl_proj/lib/python3.6/site-packages/gpytorch/models/exact_prediction_strategies.py\", line 265, in exact_prediction\r\n    self.exact_predictive_covar(test_test_covar, test_train_covar),\r\n  File \"/home1/deepak/anaconda/envs/rl_proj/lib/python3.6/site-packages/gpytorch/models/exact_prediction_strategies.py\", line 332, in exact_predictive_covar\r\n    test_train_covar)\r\n  File \"/home1/deepak/anaconda/envs/rl_proj/lib/python3.6/site-packages/gpytorch/models/exact_prediction_strategies.py\", line 549, in _exact_predictive_covar_inv_quad_form_root\r\n    self._sub_strategies, precomputed_cache, test_train_covar.evaluate_kernel().lazy_tensors\r\n  File \"/home1/deepak/anaconda/envs/rl_proj/lib/python3.6/site-packages/gpytorch/models/exact_prediction_strategies.py\", line 515, in _sub_strategies\r\n    for lazy_tensor in self.train_prior_dist.lazy_covariance_matrix.lazy_tensors:\r\nAttributeError: 'LazyEvaluatedKernelTensor' object has no attribute 'lazy_tensors'\r\n\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/803/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/803/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/802", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/802/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/802/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/802/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/802", "id": 470820205, "node_id": "MDU6SXNzdWU0NzA4MjAyMDU=", "number": 802, "title": "[Bug] Unable to estimate independent scale parameters for each input ", "user": {"login": "fonnesbeck", "id": 81476, "node_id": "MDQ6VXNlcjgxNDc2", "avatar_url": "https://avatars.githubusercontent.com/u/81476?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fonnesbeck", "html_url": "https://github.com/fonnesbeck", "followers_url": "https://api.github.com/users/fonnesbeck/followers", "following_url": "https://api.github.com/users/fonnesbeck/following{/other_user}", "gists_url": "https://api.github.com/users/fonnesbeck/gists{/gist_id}", "starred_url": "https://api.github.com/users/fonnesbeck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fonnesbeck/subscriptions", "organizations_url": "https://api.github.com/users/fonnesbeck/orgs", "repos_url": "https://api.github.com/users/fonnesbeck/repos", "events_url": "https://api.github.com/users/fonnesbeck/events{/privacy}", "received_events_url": "https://api.github.com/users/fonnesbeck/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-07-21T20:15:30Z", "updated_at": "2019-07-22T13:58:47Z", "closed_at": "2019-07-21T20:51:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a spatio-temporal GP with three input dimensions (2 spatial coordinates plus time) and am trying to use ARD to have separate lengthscale parameters for each, as well as separate scale kernels for the spatial vs the temporal inputs. My covariance function looks like this:\r\n\r\n```python\r\nself.covar_module = (\r\n            gpytorch.kernels.ScaleKernel(\r\n                gpytorch.kernels.MaternKernel(nu=1/2, \r\n                                          active_dims=torch.tensor([0, 1]), \r\n                                          ard_num_dims=2,\r\n                                          batch_size=batch_size),\r\n                active_dims=torch.tensor([0, 1]), \r\n                ard_num_dims=2,\r\n                batch_size=batch_size)\r\n            * gpytorch.kernels.ScaleKernel(\r\n                gpytorch.kernels.RBFKernel(active_dims=torch.tensor([2]),\r\n                                          batch_size=batch_size),\r\n                active_dims=torch.tensor([2]),\r\n                batch_size=batch_size))\r\n```\r\n\r\nHowever, when I fit the model, looking at the estimated parameters afterwards shows that the same scale is being estimated for both components:\r\n\r\n```\r\nlikelihood.noise_covar.raw_noise tensor([-5.4645], device='cuda:0')\r\ncovar_module.kernels.0.raw_outputscale tensor(-3.7285, device='cuda:0')\r\ncovar_module.kernels.0.base_kernel.raw_lengthscale tensor([[2.4628, 3.4885]], device='cuda:0')\r\ncovar_module.kernels.1.raw_outputscale tensor(-3.7285, device='cuda:0')\r\ncovar_module.kernels.1.base_kernel.raw_lengthscale tensor([[3.7490]], device='cuda:0')\r\n```\r\nas having the same value to 4 decimal places seems unlikely otherwise. \r\n\r\nIs this user error on my part, or is this a bug? Is it possible to estimate different scales for each input feature?", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/802/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/802/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/795", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/795/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/795/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/795/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/795", "id": 470322614, "node_id": "MDU6SXNzdWU0NzAzMjI2MTQ=", "number": 795, "title": "[Bug] Deprecation of legacy functions breaks unit tests", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 859608502, "node_id": "MDU6TGFiZWw4NTk2MDg1MDI=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/compatibility", "name": "compatibility", "color": "ebef7a", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-07-19T13:24:12Z", "updated_at": "2019-07-19T21:34:20Z", "closed_at": "2019-07-19T21:34:20Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nSince https://github.com/pytorch/pytorch/pull/22762 a number of unit tests (e.g. TestSVGPRegression) fail.\r\n\r\nThe PR adds a warning for legacy autograd functions. Tests fail because they explicitly count emitted warnings. \r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\n\r\nRun unit tests on pytorch post the above PR.\r\n\r\n## Additional context\r\n\r\nLegacy functions will be hard-deprecated in pytorch 1.3, so instead of modifying the tests we should really update the remaining legacy functions (e.g. DSMM, LogNormalCDF, ...)", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/795/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/795/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/794", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/794/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/794/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/794/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/794", "id": 469521592, "node_id": "MDU6SXNzdWU0Njk1MjE1OTI=", "number": 794, "title": "[Bug] Error when I import gpytorch constraint", "user": {"login": "kellywzhang", "id": 14792301, "node_id": "MDQ6VXNlcjE0NzkyMzAx", "avatar_url": "https://avatars.githubusercontent.com/u/14792301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kellywzhang", "html_url": "https://github.com/kellywzhang", "followers_url": "https://api.github.com/users/kellywzhang/followers", "following_url": "https://api.github.com/users/kellywzhang/following{/other_user}", "gists_url": "https://api.github.com/users/kellywzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/kellywzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kellywzhang/subscriptions", "organizations_url": "https://api.github.com/users/kellywzhang/orgs", "repos_url": "https://api.github.com/users/kellywzhang/repos", "events_url": "https://api.github.com/users/kellywzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/kellywzhang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-18T01:06:58Z", "updated_at": "2019-07-18T12:49:50Z", "closed_at": "2019-07-18T12:49:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI just installed gpytorch using conda. I get an error when I try to import constraints. \r\n\r\n## To reproduce\r\n\r\nPython 3.7.2 (default, Dec 29 2018, 00:00:04)\r\n[Clang 4.0.1 (tags/RELEASE_401/final)] :: Anaconda, Inc. on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import gpytorch\r\n>>> from gpytorch import constraints\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/miniconda3/envs/py37/lib/python3.7/site-packages/gpytorch/constraints/__init__.py\", line 1, in <module>\r\n    from .constraints import GreaterThan, Interval, LessThan, Positive\r\n  File \"/miniconda3/envs/py37/lib/python3.7/site-packages/gpytorch/constraints/constraints.py\", line 6, in <module>\r\n    from ..utils.transforms import _get_inv_param_transform, inv_sigmoid, inv_softplus\r\nImportError: cannot import name 'inv_sigmoid' from 'gpytorch.utils.transforms' (/miniconda3/envs/py37/lib/python3.7/site-packages/gpytorch/utils/transforms.py)\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 0.2.1\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> 1.1.0\r\n- <!-- Computer OS --> Mac\r\n\r\n## Additional context\r\nIt looks like gpytorch.utils.transforms was recently updated based on the github repo: https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/utils/transforms.py\r\n\r\nLet me know if there is an error on my side.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/794/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/794/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/791", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/791/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/791/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/791/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/791", "id": 468867302, "node_id": "MDU6SXNzdWU0Njg4NjczMDI=", "number": 791, "title": "[Bug] SGPR Regularization different from Titias 2009?", "user": {"login": "KeAWang", "id": 11478740, "node_id": "MDQ6VXNlcjExNDc4NzQw", "avatar_url": "https://avatars.githubusercontent.com/u/11478740?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KeAWang", "html_url": "https://github.com/KeAWang", "followers_url": "https://api.github.com/users/KeAWang/followers", "following_url": "https://api.github.com/users/KeAWang/following{/other_user}", "gists_url": "https://api.github.com/users/KeAWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/KeAWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KeAWang/subscriptions", "organizations_url": "https://api.github.com/users/KeAWang/orgs", "repos_url": "https://api.github.com/users/KeAWang/repos", "events_url": "https://api.github.com/users/KeAWang/events{/privacy}", "received_events_url": "https://api.github.com/users/KeAWang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-16T21:14:58Z", "updated_at": "2019-07-16T23:02:45Z", "closed_at": "2019-07-16T23:02:45Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThe paper by [Titsias 2009](http://proceedings.mlr.press/v5/titsias09a.html) derives a trace regularization term for the loss function of variational SGPR which has a coefficient of Tr(T)/(2 * sigma^2). But the code here implements it as just Tr(T) / sigma https://github.com/cornellius-gp/gpytorch/blob/b4aee6f81a3428172d4914e7e0fef0e71cd1f519/gpytorch/mlls/inducing_point_kernel_added_loss_term.py#L15\r\n\r\nIs there a reason for this difference?", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/791/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/791/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/784", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/784/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/784/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/784/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/784", "id": 467695556, "node_id": "MDU6SXNzdWU0Njc2OTU1NTY=", "number": 784, "title": "[Bug] get_fantasy_model does not work for SGPR with InducingPointKernel", "user": {"login": "danielecc", "id": 12210788, "node_id": "MDQ6VXNlcjEyMjEwNzg4", "avatar_url": "https://avatars.githubusercontent.com/u/12210788?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danielecc", "html_url": "https://github.com/danielecc", "followers_url": "https://api.github.com/users/danielecc/followers", "following_url": "https://api.github.com/users/danielecc/following{/other_user}", "gists_url": "https://api.github.com/users/danielecc/gists{/gist_id}", "starred_url": "https://api.github.com/users/danielecc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danielecc/subscriptions", "organizations_url": "https://api.github.com/users/danielecc/orgs", "repos_url": "https://api.github.com/users/danielecc/repos", "events_url": "https://api.github.com/users/danielecc/events{/privacy}", "received_events_url": "https://api.github.com/users/danielecc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-07-13T09:13:26Z", "updated_at": "2019-07-13T18:18:16Z", "closed_at": "2019-07-13T09:53:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nNot sure if this should be considered a bug or a feature request, but gpytorch's implementation of SGPR using the InducingPointKernel kernel seems to not support get_fantasy_model.\r\n\r\n## To reproduce\r\nI am including the smallest mwe (or should I say mnwe) here. Note that I get the same behaviour by taking the [example tutorial for SGPR](https://gpytorch.readthedocs.io/en/latest/examples/05_Scalable_GP_Regression_Multidimensional/SGPR_Example_CUDA.html) and add a get_fantasy_model added at the end. I can post that too if required, but it is longer and might clutter the ticket.\r\n\r\n**Code snippet to reproduce**\r\n```python\r\nimport gpytorch\r\nimport torch\r\nfrom gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\r\nfrom gpytorch.distributions import MultivariateNormal\r\nfrom gpytorch.likelihoods import GaussianLikelihood\r\nfrom gpytorch.means import ConstantMean\r\n\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = ConstantMean()\r\n        self.base_covar_module = ScaleKernel(RBFKernel())\r\n        self.covar_module = InducingPointKernel(self.base_covar_module, inducing_points=train_x[:500, :], likelihood=likelihood)\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return MultivariateNormal(mean_x, covar_x)\r\n\r\ntrain_X = torch.randn((100,5)).to(\"cpu\")\r\ntrain_y = torch.randn((100)).to(\"cpu\")\r\n\r\nlikelihood = GaussianLikelihood()\r\n\r\nmodel = GPRegressionModel(train_X, train_y, likelihood)\r\nmodel.train()\r\nmodel.eval()\r\n\r\ntest_pred = model(torch.randn((1,5)).to(\"cpu\"))\r\n\r\nmodel = model.get_fantasy_model(torch.randn((1,5)).to(\"cpu\"), torch.randn((1)).to(\"cpu\"))\r\n```\r\n\r\n**Stack trace/error message**\r\n```\r\nTraceback (most recent call last):\r\n  File \"mwe_sgpr_fantasy.py\", line 31, in <module>\r\n    model = model.get_fantasy_model(torch.randn((1,5)).to(\"cpu\"), torch.randn((1)).to(\"cpu\"))\r\n  File \"/home/user/miniconda3/lib/python3.7/site-packages/gpytorch/models/exact_gp.py\", line 173, in get_fantasy_model\r\n    new_model = deepcopy(self)\r\n  File \"/home/user/miniconda3/lib/python3.7/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/home/user/miniconda3/lib/python3.7/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/home/user/miniconda3/lib/python3.7/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/home/user/miniconda3/lib/python3.7/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/home/user/miniconda3/lib/python3.7/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/home/user/miniconda3/lib/python3.7/copy.py\", line 306, in _reconstruct\r\n    value = deepcopy(value, memo)\r\n  File \"/home/user/miniconda3/lib/python3.7/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/home/user/miniconda3/lib/python3.7/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/home/user/miniconda3/lib/python3.7/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/home/user/miniconda3/lib/python3.7/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/home/user/miniconda3/lib/python3.7/copy.py\", line 161, in deepcopy\r\n    y = copier(memo)\r\n  File \"/home/user/miniconda3/lib/python3.7/site-packages/torch/tensor.py\", line 23, in __deepcopy__\r\n    raise RuntimeError(\"Only Tensors created explicitly by the user \"\r\nRuntimeError: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI would expect a fantasized model to be returned efficiently.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version 0.3.3\r\n\r\n\r\n- PyTorch Version 1.1.0\r\n- Ubuntu 18.04\r\n\r\n## Additional context\r\nIt seems that during the update, the `new_model = deepcopy(self)` tries to copy `self._inducing_inv_root` but detects that it is trainable by autograd and balks. I guess gpytorch made this design choice because of the goal of optimizing the inducing points as a hyperparameter, but as a tradeoff it does not allow for efficient updates.\r\n\r\nSo far I tried to replace the inducing points with a non-trainable version by setting `requires_grad` to `False`, but it seems to not help. I would guess that [any of these tensors multiplications](https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/kernels/inducing_point_kernel.py#L45-L47) in the implementation of `_inducing_inv_root` could end up reactivating autograd, and I am afraid that without more knowledge of gpytorch's internals patching them one-by-one might end up in a long whack-a-mole.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/784/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/784/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/782", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/782/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/782/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/782/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/782", "id": 467132544, "node_id": "MDExOlB1bGxSZXF1ZXN0Mjk2ODQ3MDcw", "number": 782, "title": "Add __getitem__ to kernels, which allows slicing batch dimensions", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 623304448, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDg=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-07-11T22:17:02Z", "updated_at": "2019-10-29T21:33:54Z", "closed_at": "2019-10-29T21:33:51Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/782", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/782", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/782.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/782.patch", "merged_at": "2019-10-29T21:33:50Z"}, "body": "Right now on master, there's a problem where if `lazy_evaluated_kt` is a `LazyEvaluatedKernelTensor`, then doing for example `lazy_evaluated_kt[0, :, :]` will correctly slice `x1` and `x2` from `b x n x d` to `n x d`, but if the kernel itself is batch mode, the size of the sliced tensor will still be `b x n x m` because the kernel call on the `n x d` data will do broadcasting.\r\n\r\nIn other words, `lazy_evaluated_kt[0, :, :]` currently means \"Take the 0th batch of data, run it through my batch of GPs, and give me a `b x n x n` set of covariance matrices.\" What we probably want it to mean is \"Take the 0th batch of data, run it through the 0th GP, and give me an `n x n`covariance matrix,\" since this is more consistent with how every other `LazyTensor` works for `__getitem__`.\r\n\r\nThe only way I could see to solve this issue was to add a `__getitem__` to kernels, so that `lazy_evaluated_kt[0, :, :]` now roughly corresponds to `kernel[0](x1[0, :, :], x2[0, :, :])`. \r\n\r\nI'm not wild about kernels having `__getitem__` methods, so I'm happy to take suggestions on alternate mechanisms for solving this problem.\r\n\r\nFixes #758 ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/782/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/782/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/780", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/780/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/780/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/780/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/780", "id": 466901949, "node_id": "MDU6SXNzdWU0NjY5MDE5NDk=", "number": 780, "title": "[Bug] RBF Kernel is sometimes not positive definite", "user": {"login": "wtstephe", "id": 1521541, "node_id": "MDQ6VXNlcjE1MjE1NDE=", "avatar_url": "https://avatars.githubusercontent.com/u/1521541?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wtstephe", "html_url": "https://github.com/wtstephe", "followers_url": "https://api.github.com/users/wtstephe/followers", "following_url": "https://api.github.com/users/wtstephe/following{/other_user}", "gists_url": "https://api.github.com/users/wtstephe/gists{/gist_id}", "starred_url": "https://api.github.com/users/wtstephe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wtstephe/subscriptions", "organizations_url": "https://api.github.com/users/wtstephe/orgs", "repos_url": "https://api.github.com/users/wtstephe/repos", "events_url": "https://api.github.com/users/wtstephe/events{/privacy}", "received_events_url": "https://api.github.com/users/wtstephe/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-07-11T13:44:01Z", "updated_at": "2019-07-11T18:42:00Z", "closed_at": "2019-07-11T18:42:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen I create a RBFKernel with 512 evenly spaced points between 500 and 501, and form the resulting kernel matrix, the matrix seems numerically positive definite (minimum eigenvalue is -1e-6). But, when I do the same with 513 points, the kernel matrix is very far from positive definite (minimum eigenvalue is -0.1). This behavior seems to crop up when using 513 points or more -- everything seems fine when using 512 or less; the results are also dependent on the range from which the datapoints are generated.\r\n\r\nIs this a bug, or am I grossly misusing some feature?\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport numpy as np\r\nimport torch\r\nimport gpytorch\r\n\r\nupper = 500\r\nlower = 501\r\ncovar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\ncovar_module.base_kernel.lengthscale = 1.0\r\ncovar_module.outputscale = 1.0\r\n\r\n\r\n# Evaluate a RBF kernel on 512 evenly spaced points between 100 and\r\n#  101. The resulting kernel matrix is numerically PSD (smallest eigenvalue\r\n#  is -1e-6)\r\nX = torch.linspace(lower, upper, 512)\r\ncovarX = covar_module(X, X).numpy()\r\nprint('Min eigenvalue with 512 points', np.linalg.eigvals(covarX).min())\r\n\r\n# Evaluate a RBF kernel on 513 evenly spaced points between 100 and\r\n#  101. The resulting kernel matrix is *not* numerically PSD (smallest eigenvalue\r\n#  is -0.1)\r\nX2 = torch.linspace(lower, upper, 513)\r\ncovarX2 = covar_module(X2, X2).numpy()\r\nprint('Min eigenvalue with 513 points', np.linalg.eigvals(covarX2).min())\r\n\r\n```\r\n\r\n** Stack trace/error message **\r\nThe output that I get from the above code is:\r\n```\r\nMin eigenvalue with 512 points -1.1961828e-06\r\nMin eigenvalue with 513 points -0.18964253\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI would expect the minimum eigenvalue with 513 points to not be so negative.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n-  GPyTorch Version: 0.3.3\r\n- PyTorch Version: 1.1.0 \r\n- Computer OS: Ubuntu 18.04\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/780/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/780/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/775", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/775/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/775/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/775/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/775", "id": 464864691, "node_id": "MDU6SXNzdWU0NjQ4NjQ2OTE=", "number": 775, "title": "More stable inverse softplus", "user": {"login": "anh-tong", "id": 20637355, "node_id": "MDQ6VXNlcjIwNjM3MzU1", "avatar_url": "https://avatars.githubusercontent.com/u/20637355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anh-tong", "html_url": "https://github.com/anh-tong", "followers_url": "https://api.github.com/users/anh-tong/followers", "following_url": "https://api.github.com/users/anh-tong/following{/other_user}", "gists_url": "https://api.github.com/users/anh-tong/gists{/gist_id}", "starred_url": "https://api.github.com/users/anh-tong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anh-tong/subscriptions", "organizations_url": "https://api.github.com/users/anh-tong/orgs", "repos_url": "https://api.github.com/users/anh-tong/repos", "events_url": "https://api.github.com/users/anh-tong/events{/privacy}", "received_events_url": "https://api.github.com/users/anh-tong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-07-06T15:31:28Z", "updated_at": "2019-07-06T18:34:10Z", "closed_at": "2019-07-06T18:34:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI found that the current inverse softplus is unstable for high-value inputs.\r\n```python\r\ndef inv_softplus(x):\r\n    return torch.log(torch.exp(x) - 1)\r\n```\r\nProbably, the more stable version would be\r\n```python\r\ndef inv_softplus(x):\r\n    return x + torch.log(1 - torch.exp(-x)) \r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/775/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/775/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/774", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/774/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/774/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/774/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/774", "id": 464764973, "node_id": "MDU6SXNzdWU0NjQ3NjQ5NzM=", "number": 774, "title": "[Bug] Batched GPs with CUDA fails with shape issue", "user": {"login": "fonnesbeck", "id": 81476, "node_id": "MDQ6VXNlcjgxNDc2", "avatar_url": "https://avatars.githubusercontent.com/u/81476?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fonnesbeck", "html_url": "https://github.com/fonnesbeck", "followers_url": "https://api.github.com/users/fonnesbeck/followers", "following_url": "https://api.github.com/users/fonnesbeck/following{/other_user}", "gists_url": "https://api.github.com/users/fonnesbeck/gists{/gist_id}", "starred_url": "https://api.github.com/users/fonnesbeck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fonnesbeck/subscriptions", "organizations_url": "https://api.github.com/users/fonnesbeck/orgs", "repos_url": "https://api.github.com/users/fonnesbeck/repos", "events_url": "https://api.github.com/users/fonnesbeck/events{/privacy}", "received_events_url": "https://api.github.com/users/fonnesbeck/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-07-05T20:25:21Z", "updated_at": "2022-12-20T19:10:48Z", "closed_at": "2019-07-05T22:58:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "When attempting to do batch processing for cross-validation, the `backward()` step fails with what appears to be a shape issue. \r\n\r\nI'm doing 10-fold cross-validation, with input and output shapes as follows:\r\n\r\n![image](https://user-images.githubusercontent.com/81476/60743797-ae229e00-9f38-11e9-8418-196cd14cc1cc.png)\r\n\r\nThus, 3 input features and a single output. I've applied `.contiguous().cuda()` to the data and `.cuda()` to the model and likelihood. However, when I get to the training step, it fails:\r\n\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-244-9676fb877471> in <module>\r\n     10         optimizer.step()\r\n     11     print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n---> 12 train()\r\n\r\n<ipython-input-244-9676fb877471> in train()\r\n      5         output = model_cv(Xs)\r\n      6         loss = -mll_cv(output, ys)\r\n----> 7         loss.backward()\r\n      8         if not i % 10:\r\n      9             print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)\r\n    105                 products. Defaults to ``False``.\r\n    106         \"\"\"\r\n--> 107         torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n    108 \r\n    109     def register_hook(self, hook):\r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\r\n     85         grad_tensors = list(grad_tensors)\r\n     86 \r\n---> 87     grad_tensors = _make_grads(tensors, grad_tensors)\r\n     88     if retain_graph is None:\r\n     89         retain_graph = create_graph\r\n\r\n/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py in _make_grads(outputs, grads)\r\n     26             if out.requires_grad:\r\n     27                 if out.numel() != 1:\r\n---> 28                     raise RuntimeError(\"grad can be implicitly created only for scalar outputs\")\r\n     29                 new_grads.append(torch.ones_like(out))\r\n     30             else:\r\n\r\nRuntimeError: grad can be implicitly created only for scalar outputs\r\n\r\n```\r\n\r\nRunning GPyTorch 0.3.2 and PyTorch 1.1.0 on GCS.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/774/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/774/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/768", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/768/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/768/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/768/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/768", "id": 462286708, "node_id": "MDU6SXNzdWU0NjIyODY3MDg=", "number": 768, "title": "[Bug] GridInterpolationKernel fails to converge on Branin with small N and grid_size", "user": {"login": "tmpethick", "id": 544312, "node_id": "MDQ6VXNlcjU0NDMxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/544312?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tmpethick", "html_url": "https://github.com/tmpethick", "followers_url": "https://api.github.com/users/tmpethick/followers", "following_url": "https://api.github.com/users/tmpethick/following{/other_user}", "gists_url": "https://api.github.com/users/tmpethick/gists{/gist_id}", "starred_url": "https://api.github.com/users/tmpethick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tmpethick/subscriptions", "organizations_url": "https://api.github.com/users/tmpethick/orgs", "repos_url": "https://api.github.com/users/tmpethick/repos", "events_url": "https://api.github.com/users/tmpethick/events{/privacy}", "received_events_url": "https://api.github.com/users/tmpethick/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-06-29T09:52:45Z", "updated_at": "2019-07-01T12:42:00Z", "closed_at": "2019-06-29T17:39:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nKISS-GP fails to converge on noiseless Branin for even small `N` and `grid_size` (`N=100` and `grid_size=10`). In the experiment I have made sure `max_cg_iterations`, `max_preconditioner_size` and `eval_cg_tolerance` was not the bottleneck and I have fixed hyperparameters (learned with a vanilla GP) to avoid learning step.\r\n\r\nWe get an RMSE of `~15,000` whereas the same code without `GridInterpolationKernel` achieves `0.5`.\r\n\r\nMind that this is not a low noise problem as it fails even with `likelihood.noise` set to `1e-2`. Do you have any idea what could cause this mis-behaviour for a seemingly trivial problem?\r\n\r\n<img width=\"320\" alt=\"Screenshot 2019-06-29 at 11 53 47\" src=\"https://user-images.githubusercontent.com/544312/60382539-96dd3f80-9a64-11e9-8512-271778037fca.png\">\r\n\r\n## To reproduce\r\n\r\n\r\n<details><summary>Helper methods</summary>\r\n<p>\r\n\r\n```python\r\nimport math\r\n\r\nimport numpy as np\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\nfrom gpytorch.likelihoods import GaussianLikelihood\r\n\r\n# ---------------------------- Helpers ---------------------------------\r\n\r\nclass Branin(object):\r\n    \"\"\"Scrupulously stolen from GPyOpt and modified.\"\"\"\r\n    def __init__(self,bounds=None,a=None,b=None,c=None,r=None,s=None,t=None,sd=None):\r\n        self.input_dim = 2\r\n        if bounds is  None: self.bounds = np.array([(-5,10),(1,15)])\r\n        else: self.bounds = bounds\r\n        if a==None: self.a = 1\r\n        else: self.a = a           \r\n        if b==None: self.b = 5.1/(4*np.pi**2)\r\n        else: self.b = b\r\n        if c==None: self.c = 5/np.pi\r\n        else: self.c = c\r\n        if r==None: self.r = 6\r\n        else: self.r = r\r\n        if s==None: self.s = 10 \r\n        else: self.s = s\r\n        if t==None: self.t = 1/(8*np.pi)\r\n        else: self.t = t    \r\n        if sd==None: self.sd = 0\r\n        else: self.sd=sd\r\n        self.min = [(-np.pi,12.275),(np.pi,2.275),(9.42478,2.475)] \r\n        self.fmin = 0.397887\r\n        self.name = 'Branin'\r\n    \r\n    def __call__(self,X):\r\n        n = X.shape[0]\r\n        if X.shape[1] != self.input_dim: \r\n            return 'Wrong input dimension'  \r\n        else:\r\n            x1 = X[:,0]\r\n            x2 = X[:,1]\r\n            fval = self.a * (x2 - self.b*x1**2 + self.c*x1 - self.r)**2 + self.s*(1-self.t)*np.cos(x1) + self.s \r\n            return fval.reshape(n,1)\r\n\r\n\r\ndef random_hypercube_samples(n_samples, bounds, rng=None):\r\n    \"\"\"Random sample from d-dimensional hypercube (d = bounds.shape[0]).\r\n\r\n    Returns: (n_samples, dim)\r\n    \"\"\"\r\n    if rng is None:\r\n        rng = np.random.RandomState()\r\n\r\n    dims = bounds.shape[0]\r\n    a = rng.uniform(0, 1, (dims, n_samples))\r\n    bounds_repeated = np.repeat(bounds[:, :, None], n_samples, axis=2)\r\n    samples = a * np.abs(bounds_repeated[:,1] - bounds_repeated[:,0]) + bounds_repeated[:,0]\r\n    samples = np.swapaxes(samples, 0, 1)\r\n\r\n    # This handles the case where the sample is slightly above or below the bounds\r\n    # due to floating point precision (leading to slightly more samples from the boundary...).\r\n    return constrain_points(samples, bounds)\r\n\r\n\r\ndef constrain_points(x, bounds):\r\n    dim = x.shape[0]\r\n    minx = np.repeat(bounds[:, 0][None, :], dim, axis=0)\r\n    maxx = np.repeat(bounds[:, 1][None, :], dim, axis=0)\r\n    return np.clip(x, a_min=minx, a_max=maxx)\r\n\r\n\r\ndef plot2D(predict, f, X_train, Y_train):\r\n    XY, X, Y = construct_2D_grid(f.bounds)\r\n\r\n    # remove grid\r\n    original_grid_size = XY.shape[0]\r\n    XY = XY.reshape((-1, 2))\r\n\r\n    mean, var = predict(XY)\r\n    ground_truth = f(XY)\r\n\r\n    # recreate grid\r\n    mean = mean.reshape((original_grid_size, original_grid_size))\r\n    var = var.reshape((original_grid_size, original_grid_size))\r\n    ground_truth = ground_truth.reshape((original_grid_size, original_grid_size))\r\n\r\n    fig = plt.figure()\r\n    ax = fig.add_subplot(221)\r\n    ax.set_title('Ground truth $f$')\r\n    cont = ax.contourf(X, Y, ground_truth, 50)\r\n    fig.colorbar(cont)\r\n    ax.plot(X_train[:, 0], X_train[:, 1], '.', markersize=2)\r\n\r\n    ax = fig.add_subplot(222)\r\n    ax.set_title('Mean estimate $m$')\r\n    cont = ax.contourf(X, Y, mean, 50)\r\n    fig.colorbar(cont)\r\n    # ax.plot(model.X[:, 0], model.X[:, 1], '.', markersize=10)\r\n\r\n    ax = fig.add_subplot(223)\r\n    ax.set_title('Model std')\r\n    cont = ax.contourf(X, Y, np.sqrt(var), 50, vmin=0)\r\n    fig.colorbar(cont)\r\n    # ax.plot(model.X[:, 0], model.X[:, 1], '.', markersize=10)\r\n\r\n    ax = fig.add_subplot(224)\r\n    ax.set_title('Estimate Error $|f-m|$')\r\n    cont = ax.contourf(X, Y, np.abs(mean - ground_truth), 50)\r\n    fig.colorbar(cont)\r\n\r\n    plt.tight_layout()\r\n\r\n    return fig\r\n\r\n\r\ndef construct_2D_grid(bounds, N=2500):\r\n    n = int(math.sqrt(N))\r\n    x_bounds = bounds[0]\r\n    y_bounds = bounds[1]\r\n    X = np.linspace(x_bounds[0], x_bounds[1], n)\r\n    Y = np.linspace(y_bounds[0], y_bounds[1], n)\r\n    X, Y = np.meshgrid(X, Y)\r\n    XY = np.stack((X,Y), axis=-1)\r\n\r\n    return XY, X, Y\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n```python\r\nrng = np.random.RandomState(99)\r\n\r\nf = Branin()\r\ntrain_x_np = random_hypercube_samples(100, f.bounds, rng=rng)\r\ntrain_y_np = f(train_x_np)[:, 0]\r\ntrain_x = torch.tensor(train_x_np).double()\r\ntrain_y = torch.tensor(train_y_np).double()\r\n\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n\r\n        self.mean_module = gpytorch.means.ZeroMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.GridInterpolationKernel(\r\n                gpytorch.kernels.RBFKernel(ard_num_dims=2),\r\n                num_dims=2,\r\n                grid_size=10,\r\n            )\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nfast = True\r\n\r\nlikelihood = GaussianLikelihood().double()\r\nmodel = GPRegressionModel(train_x, train_y, likelihood).double()\r\n\r\nmodel.initialize(**{\r\n    'covar_module.base_kernel.base_kernel.lengthscale': torch.tensor([5, 60]).double(),\r\n    'covar_module.outputscale': 40,\r\n    'likelihood.noise': 1e-4,\r\n})\r\n\r\ndef predict(X):\r\n    # Set model and likelihood into evaluation mode\r\n    model.eval()\r\n    likelihood.eval()\r\n\r\n    test_x = torch.tensor(X).double()\r\n    with torch.no_grad(), \\\r\n        gpytorch.settings.fast_computations(covar_root_decomposition=fast, log_prob=fast, solves=fast), \\\r\n        gpytorch.settings.fast_pred_var(fast),\\\r\n        gpytorch.settings.use_toeplitz(True), \\\r\n        gpytorch.settings.max_cg_iterations(3000),\\\r\n        gpytorch.settings.max_preconditioner_size(10),\\\r\n        gpytorch.settings.eval_cg_tolerance(1e-8):\r\n\r\n        observed_pred = likelihood(model(test_x))\r\n        pred_labels = observed_pred.mean\r\n        pred_var = observed_pred.variance\r\n        return pred_labels.detach().numpy()[:,None], pred_var.detach().numpy()\r\n\r\nplot2D(predict, f, train_x_np, train_y_np)\r\n\r\n# Calculate RMSE\r\nN = 2500\r\nX_test = random_hypercube_samples(N, f.bounds)\r\nY_test = f(X_test)\r\nY_hat = predict(X_test)[0]\r\nrmse = np.sqrt(np.sum(np.square(Y_test - Y_hat)) / N)\r\nprint(\"RMSE:\", rmse)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n// Paste the bad output here!\r\n```\r\n\r\n## Expected Behavior\r\n\r\n<details><summary>Without GridInterpolationKernel we achieve 0.5</summary>\r\n<p>\r\n\r\n```python\r\nimport math\r\n\r\nimport numpy as np\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\nfrom gpytorch.likelihoods import GaussianLikelihood\r\n\r\n\r\n# ---------------------------- Helpers ---------------------------------\r\n\r\nclass Branin(object):\r\n    \"\"\"Scrupulously stolen from GPyOpt and modified.\"\"\"\r\n    def __init__(self,bounds=None,a=None,b=None,c=None,r=None,s=None,t=None,sd=None):\r\n        self.input_dim = 2\r\n        if bounds is  None: self.bounds = np.array([(-5,10),(1,15)])\r\n        else: self.bounds = bounds\r\n        if a==None: self.a = 1\r\n        else: self.a = a           \r\n        if b==None: self.b = 5.1/(4*np.pi**2)\r\n        else: self.b = b\r\n        if c==None: self.c = 5/np.pi\r\n        else: self.c = c\r\n        if r==None: self.r = 6\r\n        else: self.r = r\r\n        if s==None: self.s = 10 \r\n        else: self.s = s\r\n        if t==None: self.t = 1/(8*np.pi)\r\n        else: self.t = t    \r\n        if sd==None: self.sd = 0\r\n        else: self.sd=sd\r\n        self.min = [(-np.pi,12.275),(np.pi,2.275),(9.42478,2.475)] \r\n        self.fmin = 0.397887\r\n        self.name = 'Branin'\r\n    \r\n    def __call__(self,X):\r\n        n = X.shape[0]\r\n        if X.shape[1] != self.input_dim: \r\n            return 'Wrong input dimension'  \r\n        else:\r\n            x1 = X[:,0]\r\n            x2 = X[:,1]\r\n            fval = self.a * (x2 - self.b*x1**2 + self.c*x1 - self.r)**2 + self.s*(1-self.t)*np.cos(x1) + self.s \r\n            return fval.reshape(n,1)\r\n\r\n\r\ndef random_hypercube_samples(n_samples, bounds, rng=None):\r\n    \"\"\"Random sample from d-dimensional hypercube (d = bounds.shape[0]).\r\n\r\n    Returns: (n_samples, dim)\r\n    \"\"\"\r\n    if rng is None:\r\n        rng = np.random.RandomState()\r\n\r\n    dims = bounds.shape[0]\r\n    a = rng.uniform(0, 1, (dims, n_samples))\r\n    bounds_repeated = np.repeat(bounds[:, :, None], n_samples, axis=2)\r\n    samples = a * np.abs(bounds_repeated[:,1] - bounds_repeated[:,0]) + bounds_repeated[:,0]\r\n    samples = np.swapaxes(samples, 0, 1)\r\n\r\n    # This handles the case where the sample is slightly above or below the bounds\r\n    # due to floating point precision (leading to slightly more samples from the boundary...).\r\n    return constrain_points(samples, bounds)\r\n\r\n\r\ndef constrain_points(x, bounds):\r\n    dim = x.shape[0]\r\n    minx = np.repeat(bounds[:, 0][None, :], dim, axis=0)\r\n    maxx = np.repeat(bounds[:, 1][None, :], dim, axis=0)\r\n    return np.clip(x, a_min=minx, a_max=maxx)\r\n\r\n\r\ndef plot2D(predict, f, X_train, Y_train):\r\n    XY, X, Y = construct_2D_grid(f.bounds)\r\n\r\n    # remove grid\r\n    original_grid_size = XY.shape[0]\r\n    XY = XY.reshape((-1, 2))\r\n\r\n    mean, var = predict(XY)\r\n    ground_truth = f(XY)\r\n\r\n    # recreate grid\r\n    mean = mean.reshape((original_grid_size, original_grid_size))\r\n    var = var.reshape((original_grid_size, original_grid_size))\r\n    ground_truth = ground_truth.reshape((original_grid_size, original_grid_size))\r\n\r\n    fig = plt.figure()\r\n    ax = fig.add_subplot(221)\r\n    ax.set_title('Ground truth $f$')\r\n    cont = ax.contourf(X, Y, ground_truth, 50)\r\n    fig.colorbar(cont)\r\n    ax.plot(X_train[:, 0], X_train[:, 1], '.', markersize=2)\r\n\r\n    ax = fig.add_subplot(222)\r\n    ax.set_title('Mean estimate $m$')\r\n    cont = ax.contourf(X, Y, mean, 50)\r\n    fig.colorbar(cont)\r\n    # ax.plot(model.X[:, 0], model.X[:, 1], '.', markersize=10)\r\n\r\n    ax = fig.add_subplot(223)\r\n    ax.set_title('Model std')\r\n    cont = ax.contourf(X, Y, np.sqrt(var), 50, vmin=0)\r\n    fig.colorbar(cont)\r\n    # ax.plot(model.X[:, 0], model.X[:, 1], '.', markersize=10)\r\n\r\n    ax = fig.add_subplot(224)\r\n    ax.set_title('Estimate Error $|f-m|$')\r\n    cont = ax.contourf(X, Y, np.abs(mean - ground_truth), 50)\r\n    fig.colorbar(cont)\r\n\r\n    plt.tight_layout()\r\n\r\n    return fig\r\n\r\n\r\ndef construct_2D_grid(bounds, N=2500):\r\n    n = int(math.sqrt(N))\r\n    x_bounds = bounds[0]\r\n    y_bounds = bounds[1]\r\n    X = np.linspace(x_bounds[0], x_bounds[1], n)\r\n    Y = np.linspace(y_bounds[0], y_bounds[1], n)\r\n    X, Y = np.meshgrid(X, Y)\r\n    XY = np.stack((X,Y), axis=-1)\r\n\r\n    return XY, X, Y\r\n\r\n\r\n# ------------------------------ Main script ----------------------------\r\n\r\nrng = np.random.RandomState(99)\r\n\r\nf = Branin()\r\ntrain_x_np = random_hypercube_samples(100, f.bounds, rng=rng)\r\ntrain_y_np = f(train_x_np)[:, 0]\r\ntrain_x = torch.tensor(train_x_np).double()\r\ntrain_y = torch.tensor(train_y_np).double()\r\n\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n\r\n        self.mean_module = gpytorch.means.ZeroMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(ard_num_dims=2),\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nfast = True\r\n\r\nlikelihood = GaussianLikelihood().double()\r\nmodel = GPRegressionModel(train_x, train_y, likelihood).double()\r\n\r\nmodel.initialize(**{\r\n    'covar_module.base_kernel.lengthscale': torch.tensor([5, 60]).double(),\r\n    'covar_module.outputscale': 40,\r\n    'likelihood.noise': 1e-4,\r\n})\r\n\r\ndef predict(X):\r\n    # Set model and likelihood into evaluation mode\r\n    model.eval()\r\n    likelihood.eval()\r\n\r\n    test_x = torch.tensor(X).double()\r\n    with torch.no_grad(), \\\r\n        gpytorch.settings.fast_computations(covar_root_decomposition=fast, log_prob=fast, solves=fast), \\\r\n        gpytorch.settings.fast_pred_var(fast),\\\r\n        gpytorch.settings.use_toeplitz(True), \\\r\n        gpytorch.settings.max_cg_iterations(5000),\\\r\n        gpytorch.settings.max_preconditioner_size(10),\\\r\n        gpytorch.settings.eval_cg_tolerance(1e-8):\r\n\r\n        observed_pred = likelihood(model(test_x))\r\n        pred_labels = observed_pred.mean\r\n        pred_var = observed_pred.variance\r\n        return pred_labels.detach().numpy()[:,None], pred_var.detach().numpy()\r\n\r\nplot2D(predict, f, train_x_np, train_y_np)\r\n\r\n# Calculate RMSE\r\nN = 2500\r\nX_test = random_hypercube_samples(N, f.bounds)\r\nY_test = f(X_test)\r\nY_hat = predict(X_test)[0]\r\nrmse = np.sqrt(np.sum(np.square(Y_test - Y_hat)) / N)\r\nprint(\"RMSE:\", rmse)\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGPyTorch Version: 0.3.3\r\nPyTorch Version: 1.1.0\r\nComputer OS: MacOS 10.14\r\n\r\n\r\n## Additional context\r\nAdd any other context about the problem here.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/768/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/768/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/766", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/766/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/766/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/766/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/766", "id": 462214634, "node_id": "MDU6SXNzdWU0NjIyMTQ2MzQ=", "number": 766, "title": "[Bug] Incorrect gradients for kernels using torch.cdist", "user": {"login": "sdaulton", "id": 8037929, "node_id": "MDQ6VXNlcjgwMzc5Mjk=", "avatar_url": "https://avatars.githubusercontent.com/u/8037929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sdaulton", "html_url": "https://github.com/sdaulton", "followers_url": "https://api.github.com/users/sdaulton/followers", "following_url": "https://api.github.com/users/sdaulton/following{/other_user}", "gists_url": "https://api.github.com/users/sdaulton/gists{/gist_id}", "starred_url": "https://api.github.com/users/sdaulton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sdaulton/subscriptions", "organizations_url": "https://api.github.com/users/sdaulton/orgs", "repos_url": "https://api.github.com/users/sdaulton/repos", "events_url": "https://api.github.com/users/sdaulton/events{/privacy}", "received_events_url": "https://api.github.com/users/sdaulton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-06-28T21:31:11Z", "updated_at": "2019-08-27T01:11:02Z", "closed_at": "2019-06-28T22:07:22Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\nAuto-differientiating torch.cdist on the GPU is broken (https://github.com/pytorch/pytorch/issues/22353). This means kernels using torch.cdist have incorrect gradients on the GPU\r\n\r\n## To reproduce\r\n[cdist_issue_gpytorch.ipynb.txt](https://github.com/cornellius-gp/gpytorch/files/3340948/cdist_issue_gpytorch.ipynb.txt)\r\n\r\n## Expected Behavior\r\n\r\nNumerical and analytic gradients match\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGPyTorch Version: master\r\nPyTorch Version (e.g., 1.0): master\r\nOS (e.g., Linux): CentOS Linux 7 (Core)\r\nCUDA/cuDNN version:CUDA Version 9.2.88\r\nTesla M40\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/766/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/766/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/762", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/762/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/762/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/762/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/762", "id": 461767348, "node_id": "MDU6SXNzdWU0NjE3NjczNDg=", "number": 762, "title": "[Bug] when 'test_x=train_x', it stops responding for a long time and then gives an error.", "user": {"login": "mejunliu", "id": 4575879, "node_id": "MDQ6VXNlcjQ1NzU4Nzk=", "avatar_url": "https://avatars.githubusercontent.com/u/4575879?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mejunliu", "html_url": "https://github.com/mejunliu", "followers_url": "https://api.github.com/users/mejunliu/followers", "following_url": "https://api.github.com/users/mejunliu/following{/other_user}", "gists_url": "https://api.github.com/users/mejunliu/gists{/gist_id}", "starred_url": "https://api.github.com/users/mejunliu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mejunliu/subscriptions", "organizations_url": "https://api.github.com/users/mejunliu/orgs", "repos_url": "https://api.github.com/users/mejunliu/repos", "events_url": "https://api.github.com/users/mejunliu/events{/privacy}", "received_events_url": "https://api.github.com/users/mejunliu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-06-27T21:57:39Z", "updated_at": "2019-06-27T22:09:09Z", "closed_at": "2019-06-27T22:09:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```\r\nimport gpytorch\r\nimport torch\r\nimport math\r\n\r\ngrid_bounds = [(0, 1), (0, 2)]\r\ngrid_size = 100\r\ngrid = torch.zeros(grid_size, len(grid_bounds))\r\nfor i in range(len(grid_bounds)):\r\n    grid_diff = float(grid_bounds[i][1] - grid_bounds[i][0]) / (grid_size - 2)\r\n    grid[:, i] = torch.linspace(grid_bounds[i][0] - grid_diff, grid_bounds[i][1] + grid_diff, grid_size)\r\n\r\ntrain_x = gpytorch.utils.grid.create_data_from_grid(grid)\r\ntrain_y = torch.sin((train_x[:, 0] + train_x[:, 1]) * (2 * math.pi)) + torch.randn_like(train_x[:, 0]).mul(0.01)\r\n\r\nclass GridGPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, grid, train_x, train_y, likelihood):\r\n        super(GridGPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n        num_dims = train_x.size(-1)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.GridKernel(gpytorch.kernels.RBFKernel(), grid=grid)\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = GridGPRegressionModel(grid, train_x, train_y, likelihood)\r\n\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n], lr=0.1)\r\n\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ntraining_iter = 5\r\nfor i in range(training_iter):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y.view(1,-1))\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\r\n        i + 1, training_iter, loss.item(),\r\n        model.covar_module.base_kernel.lengthscale.item(),\r\n        model.likelihood.noise.item()\r\n    ))\r\n    optimizer.step()\r\n\r\nmodel.eval()\r\nlikelihood.eval()\r\nn = 20\r\ntest_x = torch.zeros(int(pow(n, 2)), 2)\r\nfor i in range(n):\r\n    for j in range(n):\r\n        test_x[i * n + j][0] = float(i) / (n-1)\r\n        test_x[i * n + j][1] = float(j) / (n-1)\r\n\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    observed_pred = likelihood(model(train_x))\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nC:\\Users\\Anaconda3\\envs\\default\\lib\\site-packages\\gpytorch\\models\\exact_gp.py:247: UserWarning: The input matches the stored training data. Did you forget to call model.train()?\r\n  \"The input matches the stored training data. Did you forget to call model.train()?\", UserWarning\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-1-b4aadbcf139b>\", line 1, in <module>\r\n    runfile('C:/Users/Desktop/spyder/gp_regression.py', wdir='C:/Users/Jun/Desktop/spyder')\r\n\r\n  File \"C:\\Users\\Anaconda3\\envs\\default\\lib\\site-packages\\spyder_kernels\\customize\\spydercustomize.py\", line 827, in runfile\r\n    execfile(filename, namespace)\r\n\r\n  File \"C:\\Users\\Anaconda3\\envs\\default\\lib\\site-packages\\spyder_kernels\\customize\\spydercustomize.py\", line 110, in execfile\r\n    exec(compile(f.read(), filename, 'exec'), namespace)\r\n\r\n  File \"C:/Users/Desktop/spyder/gp_regression.py\", line 68, in <module>\r\n    pred_labels = observed_pred.mean.view(n, n)\r\n\r\nRuntimeError: shape '[20, 20]' is invalid for input of size 10000\r\n```\r\n\r\n## Expected Behavior\r\nIt should give a result instead of not responding and then showing an error.\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPytorch 0.3.2\r\n- pytorch 1.1.0\r\n- win10\r\n\r\n## Additional context\r\nThe weird thing is that this error doesn't appear when I use a 1d example from the tutorial page.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/762/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/762/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/760", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/760/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/760/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/760/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/760", "id": 461475632, "node_id": "MDU6SXNzdWU0NjE0NzU2MzI=", "number": 760, "title": "[Bug] Multiplication of two ScaleKernel(LinearKernel()) creates runtime error", "user": {"login": "MichaelDoron", "id": 3288047, "node_id": "MDQ6VXNlcjMyODgwNDc=", "avatar_url": "https://avatars.githubusercontent.com/u/3288047?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MichaelDoron", "html_url": "https://github.com/MichaelDoron", "followers_url": "https://api.github.com/users/MichaelDoron/followers", "following_url": "https://api.github.com/users/MichaelDoron/following{/other_user}", "gists_url": "https://api.github.com/users/MichaelDoron/gists{/gist_id}", "starred_url": "https://api.github.com/users/MichaelDoron/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MichaelDoron/subscriptions", "organizations_url": "https://api.github.com/users/MichaelDoron/orgs", "repos_url": "https://api.github.com/users/MichaelDoron/repos", "events_url": "https://api.github.com/users/MichaelDoron/events{/privacy}", "received_events_url": "https://api.github.com/users/MichaelDoron/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-27T11:30:53Z", "updated_at": "2019-06-27T19:04:10Z", "closed_at": "2019-06-27T19:04:10Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nTraining a model using a multiplication of two ScaleKernel(LinearKernel()) evokes `Lapack Error syev : 2 off-diagonal elements didn't converge to zero`\r\nUpdate: Notice that a multiplication of four LinearKernels creates the same error, even without ScaleKernel (commented out in the code snippet below).\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```import gpytorch\r\nimport math\r\nimport torch\r\nfrom time import time\r\nimport copy\r\n\r\ntorch.manual_seed(0)\r\n\r\ndata_samples = 400 \r\ntraining_iterations = 100\r\n\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.LinearKernel()) * gpytorch.kernels.ScaleKernel(gpytorch.kernels.LinearKernel())\r\n        # self.covar_module = gpytorch.kernels.LinearKernel() * gpytorch.kernels.LinearKernel() * gpytorch.kernels.LinearKernel() * gpytorch.kernels.LinearKernel()\r\n        \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_module = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_module)\r\n\r\ntrain_x = torch.linspace(0, 0.5, data_samples)\r\ntrain_y = torch.sin(train_x * 100.0)\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = GPRegressionModel(train_x, train_y, likelihood)\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\noptimizer = torch.optim.Adam([{'params': model.parameters()}], lr=0.1)\r\nmodel.train()\r\nlikelihood.train()\r\n\r\noptimizer.zero_grad()\r\noutput = model(train_x)\r\nloss = -mll(output, train_y)\r\nloss.backward()\r\noptimizer.step()    \r\nfor i in range(training_iterations):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\r\n    optimizer.step()\r\n\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\nwith torch.no_grad():\r\n    test_x = torch.linspace(0, train_x[-1] * 1, len(train_x) * 1)\r\n    prediction = likelihood(model(test_x))\r\n    mean = prediction.mean\r\n    lower, upper = prediction.confidence_region()\r\n\r\nprint('Reached the end of the script without Runtime errors')\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nRuntimeError: Lapack Error syev : 2 off-diagonal elements didn't converge to zero at /Users/distiller/project/conda/conda-bld/pytorch_1556653464916/work/aten/src/TH/generic/THTensorLapack.cpp:296\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThe model should train without returning a runtime error. \r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` -->0.3.3\r\n- <!-- PyTorch Version (run `print(torch.__version__)` -->1.1.0\r\n- <!-- Computer OS -->macOS\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/760/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/760/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/758", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/758/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/758/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/758/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/758", "id": 461096763, "node_id": "MDU6SXNzdWU0NjEwOTY3NjM=", "number": 758, "title": "[Bug] Batch-indexing lazy covariance matrix fails for batch-mode ExactGP", "user": {"login": "sdaulton", "id": 8037929, "node_id": "MDQ6VXNlcjgwMzc5Mjk=", "avatar_url": "https://avatars.githubusercontent.com/u/8037929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sdaulton", "html_url": "https://github.com/sdaulton", "followers_url": "https://api.github.com/users/sdaulton/followers", "following_url": "https://api.github.com/users/sdaulton/following{/other_user}", "gists_url": "https://api.github.com/users/sdaulton/gists{/gist_id}", "starred_url": "https://api.github.com/users/sdaulton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sdaulton/subscriptions", "organizations_url": "https://api.github.com/users/sdaulton/orgs", "repos_url": "https://api.github.com/users/sdaulton/repos", "events_url": "https://api.github.com/users/sdaulton/events{/privacy}", "received_events_url": "https://api.github.com/users/sdaulton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-26T17:35:13Z", "updated_at": "2019-10-29T21:33:51Z", "closed_at": "2019-10-29T21:33:51Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nEvaluating a batch-mode ExactGP with training inputs of shape `b x n x d` and targets of shape `b x n` on a set of test points with shape `m x d` yields a lazy_covariance_matrix with shape `b x m x m`. Indexing along the batch dimension fails.\r\n\r\n## To reproduce\r\n\r\n[batch_indexing_bug_lazy_covar.ipynb.txt](https://github.com/cornellius-gp/gpytorch/files/3331406/batch_indexing_bug_lazy_covar.ipynb.txt)\r\n\r\n## Expected Behavior\r\n\r\nSelecting a single index of the batch dimension:\r\n\r\n```\r\nmvn.lazy_covariance_matrix[0, :, :]\r\n```\r\nshould yield the lazy covariance matrix for the 0th batch (with shape `m x m`)\r\n\r\n## System information\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 0.3.2\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> 1.0.0a0\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/758/reactions", "total_count": 3, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 1}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/758/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/755", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/755/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/755/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/755/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/755", "id": 460543986, "node_id": "MDU6SXNzdWU0NjA1NDM5ODY=", "number": 755, "title": "[Bug] Shape errors with GridInterpolationKernel", "user": {"login": "g-benton", "id": 29232979, "node_id": "MDQ6VXNlcjI5MjMyOTc5", "avatar_url": "https://avatars.githubusercontent.com/u/29232979?v=4", "gravatar_id": "", "url": "https://api.github.com/users/g-benton", "html_url": "https://github.com/g-benton", "followers_url": "https://api.github.com/users/g-benton/followers", "following_url": "https://api.github.com/users/g-benton/following{/other_user}", "gists_url": "https://api.github.com/users/g-benton/gists{/gist_id}", "starred_url": "https://api.github.com/users/g-benton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/g-benton/subscriptions", "organizations_url": "https://api.github.com/users/g-benton/orgs", "repos_url": "https://api.github.com/users/g-benton/repos", "events_url": "https://api.github.com/users/g-benton/events{/privacy}", "received_events_url": "https://api.github.com/users/g-benton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-06-25T17:16:40Z", "updated_at": "2019-06-27T18:49:14Z", "closed_at": "2019-06-27T18:49:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nDealing with a bug when using `GridInterpolationKernel` in which when each of the input dimensions is even in size everything runs, but when the input sizes are odd an internal shape error is thrown. \r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n# define SKI model\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n\r\n        # SKI requires a grid size hyperparameter. This util can help with that\r\n        grid_size = [50, 50]\r\n        \r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        base = gpytorch.kernels.RBFKernel\r\n        \r\n        grid_kernels = [gpytorch.kernels.GridInterpolationKernel(\r\n                base(),num_dims = train_x.size(-1), active_dims = (d),\r\n            grid_size = grid_size[d]\r\n        ) for d in range(train_x.size(-1))]\r\n        \r\n        self.covar_module = gpytorch.kernels.ProductKernel(*grid_kernels)        \r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n        \r\n# generate data\r\nn = 30\r\ntrain_x = torch.zeros(pow(n, 2), 2)\r\nfor i in range(n):\r\n    for j in range(n):\r\n        train_x[i * n + j][0] = float(i) / (n-1)\r\n        train_x[i * n + j][1] = float(j) / (n-1)\r\n# True function is sin( 2*pi*(x0+x1))\r\ntrain_y = torch.sin((train_x[:, 0] + train_x[:, 1]) * (2 * math.pi)) + torch.randn_like(train_x[:, 0]).mul(0.01)\r\n\r\nin_dims = 1 if train_x.dim() == 1 else train_x.size(1)\r\n\r\n# define the model and make the log prob call\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = GPRegressionModel(train_x, train_y, likelihood)\r\n\r\nlikelihood.train()\r\nmodel.train()\r\n\r\nwith gpytorch.settings.num_trace_samples(100), torch.no_grad():\r\n    print(likelihood(model(train_x)).log_prob(train_y))\r\n    \r\n# generate data with odd n\r\nn = 35 \r\ntrain_x = torch.zeros(pow(n, 2), 2)\r\nfor i in range(n):\r\n    for j in range(n):\r\n        train_x[i * n + j][0] = float(i) / (n-1)\r\n        train_x[i * n + j][1] = float(j) / (n-1)\r\n# True function is sin( 2*pi*(x0+x1))\r\ntrain_y = torch.sin((train_x[:, 0] + train_x[:, 1]) * (2 * math.pi)) + torch.randn_like(train_x[:, 0]).mul(0.01)\r\n\r\nin_dims = 1 if train_x.dim() == 1 else train_x.size(1)\r\n\r\n# define the model and make the log prob call\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = GPRegressionModel(train_x, train_y, likelihood)\r\n\r\nlikelihood.train()\r\nmodel.train()\r\n\r\nwith gpytorch.settings.num_trace_samples(100), torch.no_grad():\r\n    print(likelihood(model(train_x)).log_prob(train_y))\r\n\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-9-2edc81b19af7> in <module>\r\n     14 \r\n     15 with gpytorch.settings.num_trace_samples(100), torch.no_grad():\r\n---> 16     print(likelihood(model(train_x)).log_prob(train_y))\r\n\r\n~/gpytorch/gpytorch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    126 \r\n    127         # Get log determininat and first part of quadratic form\r\n--> 128         inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n    129 \r\n    130         res = -0.5 * sum([inv_quad, logdet, diff.size(-1) * math.log(2 * math.pi)])\r\n\r\n~/gpytorch/gpytorch/lazy/lazy_tensor.py in inv_quad_logdet(self, inv_quad_rhs, logdet, reduce_inv_quad)\r\n   1021                 )\r\n   1022 \r\n-> 1023         args = self.representation()\r\n   1024         if inv_quad_rhs is not None:\r\n   1025             args = [inv_quad_rhs] + list(args)\r\n\r\n~/gpytorch/gpytorch/lazy/lazy_tensor.py in representation(self)\r\n   1251                 representation.append(arg)\r\n   1252             elif hasattr(arg, \"representation\") and callable(arg.representation):  # Is it a LazyTensor?\r\n-> 1253                 representation += list(arg.representation())\r\n   1254             else:\r\n   1255                 raise RuntimeError(\"Representation of a LazyTensor should consist only of Tensors\")\r\n\r\n~/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in representation(self)\r\n    306         # representation\r\n    307         else:\r\n--> 308             return self.evaluate_kernel().representation()\r\n    309 \r\n    310     def representation_tree(self):\r\n\r\n~/gpytorch/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36 \r\n\r\n~/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)\r\n    268             self.kernel.active_dims = None\r\n    269             res = self.kernel(\r\n--> 270                 x1, x2, diag=False, last_dim_is_batch=self.last_dim_is_batch, **self.params\r\n    271             )\r\n    272             self.kernel.active_dims = temp_active_dims\r\n\r\n~/gpytorch/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, last_dim_is_batch, **params)\r\n    374                 res = LazyEvaluatedKernelTensor(x1_, x2_, kernel=self, last_dim_is_batch=last_dim_is_batch, **params)\r\n    375             else:\r\n--> 376                 res = super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params)\r\n    377             return res\r\n    378 \r\n\r\n~/gpytorch/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     20 \r\n     21     def __call__(self, *inputs, **kwargs):\r\n---> 22         outputs = self.forward(*inputs, **kwargs)\r\n     23         if isinstance(outputs, list):\r\n     24             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/gpytorch/gpytorch/kernels/kernel.py in forward(self, x1, x2, diag, **params)\r\n    442             res = delazify(self.kernels[0](x1, x2, diag=diag, **params))\r\n    443         else:\r\n--> 444             res = self.kernels[0](x1, x2, diag=diag, **params)\r\n    445 \r\n    446             if not diag:\r\n\r\n~/gpytorch/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, last_dim_is_batch, **params)\r\n    374                 res = LazyEvaluatedKernelTensor(x1_, x2_, kernel=self, last_dim_is_batch=last_dim_is_batch, **params)\r\n    375             else:\r\n--> 376                 res = super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params)\r\n    377             return res\r\n    378 \r\n\r\n~/gpytorch/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     20 \r\n     21     def __call__(self, *inputs, **kwargs):\r\n---> 22         outputs = self.forward(*inputs, **kwargs)\r\n     23         if isinstance(outputs, list):\r\n     24             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/gpytorch/gpytorch/kernels/grid_interpolation_kernel.py in forward(self, x1, x2, diag, last_dim_is_batch, **params)\r\n    135         if self.grid_is_dynamic:  # This is true if a grid_bounds wasn't passed in\r\n    136             if torch.equal(x1, x2):\r\n--> 137                 x = x1.contiguous().view(-1, self.num_dims)\r\n    138             else:\r\n    139                 x = torch.cat([x1.contiguous().view(-1, self.num_dims), x2.contiguous().view(-1, self.num_dims)])\r\n\r\nRuntimeError: shape '[-1, 2]' is invalid for input of size 1225\r\n```\r\n\r\n## Expected Behavior\r\n\r\nSame as in the first case above when `n=30`\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gytorch 0.3.2, built from master 6/25\r\n- pytorch version 1.1.0\r\n- ubuntu 18.04\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/755/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/755/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/749", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/749/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/749/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/749/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/749", "id": 459574624, "node_id": "MDU6SXNzdWU0NTk1NzQ2MjQ=", "number": 749, "title": "[Bug] PeriodicKernel returns error with BernoulliLikelihood ", "user": {"login": "MichaelDoron", "id": 3288047, "node_id": "MDQ6VXNlcjMyODgwNDc=", "avatar_url": "https://avatars.githubusercontent.com/u/3288047?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MichaelDoron", "html_url": "https://github.com/MichaelDoron", "followers_url": "https://api.github.com/users/MichaelDoron/followers", "following_url": "https://api.github.com/users/MichaelDoron/following{/other_user}", "gists_url": "https://api.github.com/users/MichaelDoron/gists{/gist_id}", "starred_url": "https://api.github.com/users/MichaelDoron/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MichaelDoron/subscriptions", "organizations_url": "https://api.github.com/users/MichaelDoron/orgs", "repos_url": "https://api.github.com/users/MichaelDoron/repos", "events_url": "https://api.github.com/users/MichaelDoron/events{/privacy}", "received_events_url": "https://api.github.com/users/MichaelDoron/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2019-06-23T13:10:22Z", "updated_at": "2019-06-27T19:05:08Z", "closed_at": "2019-06-27T19:05:08Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen running the simple GPClassificationModel example (as in https://gpytorch.readthedocs.io/en/latest/examples/02_Simple_GP_Classification/Simple_GP_Classification.html), and changing the RBFKernel to a PeriodicKernel, the `likelihood(model(test_x))` line returns a RuntimeError:\r\n\r\n`RuntimeError: The kernel LazyEvaluatedKernelTensor is not equipped to handle and diag. Expected size torch.Size([101]). Got size torch.Size([1, 101])`\r\n\r\nThis error does not occur when changing the RBFKernel to a LinearKernel, or when changing the BernoulliLikelihood to GaussianLikelihood.\r\n\r\n## To reproduce\r\n\r\n```\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\ntrain_x = torch.linspace(0, 1, 10)\r\ntrain_y = torch.sign(torch.cos(train_x * (4 * math.pi))).add(1).div(2)\r\n\r\nfrom gpytorch.models import AbstractVariationalGP\r\nfrom gpytorch.variational import CholeskyVariationalDistribution\r\nfrom gpytorch.variational import VariationalStrategy\r\n\r\nclass GPClassificationModel(AbstractVariationalGP):\r\n    def __init__(self, train_x):\r\n        variational_distribution = CholeskyVariationalDistribution(train_x.size(0))\r\n        variational_strategy = VariationalStrategy(self, train_x, variational_distribution)\r\n        super(GPClassificationModel, self).__init__(variational_strategy)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.PeriodicKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        latent_pred = gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n        return latent_pred\r\n\r\n\r\nmodel = GPClassificationModel(train_x)\r\nlikelihood = gpytorch.likelihoods.BernoulliLikelihood()\r\n\r\nfrom gpytorch.mlls.variational_elbo import VariationalELBO\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\r\n\r\nmll = VariationalELBO(likelihood, model, train_y.numel())\r\n\r\ntraining_iter = 50\r\nfor i in range(training_iter):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    optimizer.step()\r\n\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\nwith torch.no_grad():\r\n    test_x = torch.linspace(0, 1, 101)\r\n    observed_pred = likelihood(model(test_x))\r\n\r\nprint('Reached the end of the script, successfully calculated likelihood')\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nRuntimeError: The kernel LazyEvaluatedKernelTensor is not equipped to handle and diag. Expected size torch.Size([101]). Got size torch.Size([1, 101])\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThe expected behavior is that the model will run with PeriodicKernel, and not only RBFKernel or LinearKernel.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` -->0.3.2\r\n- <!-- PyTorch Version (run `print(torch.__version__)` -->1.1.0\r\n- <!-- Computer OS -->macOS\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/749/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/749/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/744", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/744/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/744/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/744/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/744", "id": 459115508, "node_id": "MDU6SXNzdWU0NTkxMTU1MDg=", "number": 744, "title": "[Bug] Interval constraint miscalculates bounds", "user": {"login": "MichaelDoron", "id": 3288047, "node_id": "MDQ6VXNlcjMyODgwNDc=", "avatar_url": "https://avatars.githubusercontent.com/u/3288047?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MichaelDoron", "html_url": "https://github.com/MichaelDoron", "followers_url": "https://api.github.com/users/MichaelDoron/followers", "following_url": "https://api.github.com/users/MichaelDoron/following{/other_user}", "gists_url": "https://api.github.com/users/MichaelDoron/gists{/gist_id}", "starred_url": "https://api.github.com/users/MichaelDoron/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MichaelDoron/subscriptions", "organizations_url": "https://api.github.com/users/MichaelDoron/orgs", "repos_url": "https://api.github.com/users/MichaelDoron/repos", "events_url": "https://api.github.com/users/MichaelDoron/events{/privacy}", "received_events_url": "https://api.github.com/users/MichaelDoron/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-06-21T09:55:27Z", "updated_at": "2019-06-26T13:35:33Z", "closed_at": "2019-06-26T13:35:33Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nThe transform function in the Interval constraint class allows tensors to be above the upper bound.\r\n\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n\r\nimport torch\r\nimport gpytorch\r\n\r\nlower_bound = 0.2\r\nupper_bound = 0.3\r\ntensor = torch.Tensor([lower_bound + upper_bound + 0.1])\r\n\r\nconstrained_tensor = gpytorch.constraints.Interval(lower_bound = lower_bound, upper_bound=upper_bound).transform(tensor)\r\nassert constrained_tensor >= lower_bound, 'constrained tensor smaller than lower bound'\r\nassert constrained_tensor <= upper_bound, 'constrained tensor larger than upper bound'\r\n\r\n** Stack trace/error message **\r\n\r\nAssertionError: constrained tensor larger than upper bound\r\n\r\n## Expected Behavior\r\n\r\nWe would want the constrained tensor to be between lower bound and upper bound\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 0.3.2\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> 1.1.0\r\n- <!-- Computer OS --> macOS\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/744/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/744/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/740", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/740/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/740/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/740/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/740", "id": 458029715, "node_id": "MDU6SXNzdWU0NTgwMjk3MTU=", "number": 740, "title": "[Bug] Multitask learning with additive kernel structure", "user": {"login": "WRJacobs", "id": 23551270, "node_id": "MDQ6VXNlcjIzNTUxMjcw", "avatar_url": "https://avatars.githubusercontent.com/u/23551270?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WRJacobs", "html_url": "https://github.com/WRJacobs", "followers_url": "https://api.github.com/users/WRJacobs/followers", "following_url": "https://api.github.com/users/WRJacobs/following{/other_user}", "gists_url": "https://api.github.com/users/WRJacobs/gists{/gist_id}", "starred_url": "https://api.github.com/users/WRJacobs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WRJacobs/subscriptions", "organizations_url": "https://api.github.com/users/WRJacobs/orgs", "repos_url": "https://api.github.com/users/WRJacobs/repos", "events_url": "https://api.github.com/users/WRJacobs/events{/privacy}", "received_events_url": "https://api.github.com/users/WRJacobs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-06-19T13:56:18Z", "updated_at": "2019-06-25T12:33:08Z", "closed_at": "2019-06-25T12:33:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen I train a GP with an additive kernel structure the multitask learning (Hadamard) does not work correctly. It looks like it is only training on the first input (the one with an index of 0). The output (mean) is identical for any other index/task. \r\n\r\nIt is working for the product of kernels. \r\n\r\n## To reproduce\r\nTo reproduce you could replace the kernel in the example given in the documentation: Hadamard_Multitask_GP_Regression.ipynb\r\n\r\nOriginal: \r\n```python\r\nclass MultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.RBFKernel()\r\n        \r\n        # We learn an IndexKernel for 2 tasks\r\n        # (so we'll actually learn 2x2=4 tasks with correlations)\r\n        self.task_covar_module = gpytorch.kernels.IndexKernel(num_tasks=2, rank=1)\r\n```\r\nReplace with: \r\n```python\r\nclass MultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.RBFKernel() + gpytorch.kernels.PeriodicKernel()\r\n        \r\n        # We learn an IndexKernel for 2 tasks\r\n        # (so we'll actually learn 2x2=4 tasks with correlations)\r\n        self.task_covar_module = gpytorch.kernels.IndexKernel(num_tasks=2, rank=1)\r\n```\r\n\r\nI have included a plot of the output with the undesirable behaviour. \r\n\r\nMany thanks, \r\nWill. \r\n\r\n![image](https://user-images.githubusercontent.com/23551270/59771776-57636600-92a2-11e9-8d5b-35f24db8d16c.png)\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/740/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/740/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/737", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/737/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/737/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/737/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/737", "id": 456685992, "node_id": "MDU6SXNzdWU0NTY2ODU5OTI=", "number": 737, "title": "SpectralMixtureKernel initialize_from_data CUDA bug", "user": {"login": "tzoiker", "id": 6230141, "node_id": "MDQ6VXNlcjYyMzAxNDE=", "avatar_url": "https://avatars.githubusercontent.com/u/6230141?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tzoiker", "html_url": "https://github.com/tzoiker", "followers_url": "https://api.github.com/users/tzoiker/followers", "following_url": "https://api.github.com/users/tzoiker/following{/other_user}", "gists_url": "https://api.github.com/users/tzoiker/gists{/gist_id}", "starred_url": "https://api.github.com/users/tzoiker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tzoiker/subscriptions", "organizations_url": "https://api.github.com/users/tzoiker/orgs", "repos_url": "https://api.github.com/users/tzoiker/repos", "events_url": "https://api.github.com/users/tzoiker/events{/privacy}", "received_events_url": "https://api.github.com/users/tzoiker/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-06-16T21:52:53Z", "updated_at": "2019-11-12T20:23:38Z", "closed_at": "2019-11-12T20:23:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen running `initialize_from_data` with CUDA tensors, in [this](https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/kernels/spectral_mixture_kernel.py#L158) line zero tensor is initialized without input device consideration, so that code fails later.\r\n## To reproduce\r\n\r\n```python\r\nimport torch, gpytorch\r\ntrain_x = torch.tensor([1.0,2.0]).cuda()\r\ntrain_y = torch.ones(2).cuda()\r\nkernel = gpytorch.kernels.SpectralMixtureKernel(num_mixtures=4).cuda()\r\nkernel.initialize_from_data(train_x, train_y)\r\n```\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-1-419d92435b05> in <module>\r\n      3 train_y = torch.ones(2).cuda()\r\n      4 kernel = gpytorch.kernels.SpectralMixtureKernel(num_mixtures=4).cuda()\r\n----> 5 kernel.initialize_from_data(train_x, train_y)\r\n\r\n~/storage/miniconda2/envs/water/lib/python3.6/site-packages/gpytorch/kernels/spectral_mixture_kernel.py in initialize_from_data(self, train_x, train_y, **kwargs)\r\n    166         )\r\n    167         # Draw means from Unif(0, 0.5 / minimum distance between two points)\r\n--> 168         self.raw_mixture_means.data.uniform_().mul_(0.5).div_(min_dist)\r\n    169         self.raw_mixture_means.data = self.raw_mixture_means_constraint.inverse_transform(self.raw_mixture_means.data)\r\n    170         # Mixture weights should be roughly the stdv of the y values divided by the number of mixtures\r\n\r\nRuntimeError: expected backend CUDA and dtype Float but got backend CPU and dtype Float\r\n```\r\n\r\n## Expected Behavior\r\n\r\nI expected it to get device info from training data.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch 0.3.2\r\n- PyTorch 1.1.0\r\n- MacOS 10.14\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/737/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/737/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/731", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/731/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/731/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/731/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/731", "id": 454661789, "node_id": "MDU6SXNzdWU0NTQ2NjE3ODk=", "number": 731, "title": "[Bug] Problem installing gpytorch into Kaggle kernel", "user": {"login": "dandrocec", "id": 4005036, "node_id": "MDQ6VXNlcjQwMDUwMzY=", "avatar_url": "https://avatars.githubusercontent.com/u/4005036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dandrocec", "html_url": "https://github.com/dandrocec", "followers_url": "https://api.github.com/users/dandrocec/followers", "following_url": "https://api.github.com/users/dandrocec/following{/other_user}", "gists_url": "https://api.github.com/users/dandrocec/gists{/gist_id}", "starred_url": "https://api.github.com/users/dandrocec/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dandrocec/subscriptions", "organizations_url": "https://api.github.com/users/dandrocec/orgs", "repos_url": "https://api.github.com/users/dandrocec/repos", "events_url": "https://api.github.com/users/dandrocec/events{/privacy}", "received_events_url": "https://api.github.com/users/dandrocec/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-11T12:31:21Z", "updated_at": "2019-09-17T23:56:18Z", "closed_at": "2019-06-28T05:51:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "I tried to install gpytorch into Kaggle kernel:\r\n`pip install gpytorch`\r\nBut, I am getting the following error:\r\n```\r\nCollecting gpytorch\r\n  Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fd9c6743630>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)': /simple/gpytorch/\r\n  Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fd9c6743588>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)': /simple/gpytorch/\r\n  Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fd9c6743550>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)': /simple/gpytorch/\r\n  Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fd9c67435c0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)': /simple/gpytorch/\r\n```\r\nHow can this issue be resolved?", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/731/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/731/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/729", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/729/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/729/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/729/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/729", "id": 453100351, "node_id": "MDU6SXNzdWU0NTMxMDAzNTE=", "number": 729, "title": "[Bug] Tensor shape mismatch for low noise with cholesky", "user": {"login": "tmpethick", "id": 544312, "node_id": "MDQ6VXNlcjU0NDMxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/544312?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tmpethick", "html_url": "https://github.com/tmpethick", "followers_url": "https://api.github.com/users/tmpethick/followers", "following_url": "https://api.github.com/users/tmpethick/following{/other_user}", "gists_url": "https://api.github.com/users/tmpethick/gists{/gist_id}", "starred_url": "https://api.github.com/users/tmpethick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tmpethick/subscriptions", "organizations_url": "https://api.github.com/users/tmpethick/orgs", "repos_url": "https://api.github.com/users/tmpethick/repos", "events_url": "https://api.github.com/users/tmpethick/events{/privacy}", "received_events_url": "https://api.github.com/users/tmpethick/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-06T15:34:28Z", "updated_at": "2019-06-06T15:48:52Z", "closed_at": "2019-06-06T15:48:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI stumbled on a funny error when testing something else. If noise level is low `noise=0.0001` and double precision is not enabled (by using `.double()`) we know that CG approach will break. However, if we use cholesky approach instead we also break but weirdly enough with a Tensor shape mismatch (see stack trace).\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport numpy as np\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\ndef gpytorch_model(noise=0.5, lengthscale=2.5, variance=2, n_iter=200, use_double=True):\r\n    bounds = np.array([[0,1]])\r\n    train_x = torch.linspace(bounds[0,0], bounds[0,1], 1000)\r\n    if use_double:\r\n        train_x = train_x.double()\r\n\r\n    train_y = np.sin(60 * train_x ** 4)\r\n    lengthscale_prior = None\r\n    outputscale_prior = None\r\n\r\n    class ExactGPModel(gpytorch.models.ExactGP):\r\n        def __init__(self, train_x, train_y, likelihood):\r\n            super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n            self.mean_module = gpytorch.means.ZeroMean()\r\n            self.covar_module = gpytorch.kernels.ScaleKernel(\r\n                gpytorch.kernels.RBFKernel(\r\n                    lengthscale_prior=lengthscale_prior,\r\n                ),\r\n                outputscale_prior=outputscale_prior,\r\n            )\r\n\r\n        def forward(self, x):\r\n            mean_x = self.mean_module(x)\r\n            covar_x = self.covar_module(x)\r\n            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n    # initialize likelihood and model\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n    # likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=torch.ones(1) * 0.0001)\r\n    model = ExactGPModel(train_x, train_y, likelihood)\r\n    if use_double:\r\n        model = model.double()\r\n\r\n    model.initialize(**{\r\n        'likelihood.noise': noise,\r\n        'covar_module.base_kernel.lengthscale': lengthscale,\r\n        'covar_module.outputscale': variance,\r\n    })\r\n    print(\"lengthscale: %.3f, variance: %.3f,   noise: %.5f\" % (model.covar_module.base_kernel.lengthscale.item(),\r\n            model.covar_module.outputscale.item(),\r\n            model.likelihood.noise.item()))\r\n\r\n    # Find optimal model hyperparameters\r\n    model.train()\r\n    likelihood.train()\r\n\r\n    # Use the adam optimizer\r\n    optimizer = torch.optim.Adam([\r\n        {'params': model.parameters()}, \r\n    ], lr=0.01)\r\n\r\n    # \"Loss\" for GPs - the marginal log likelihood\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\n    with gpytorch.settings.fast_computations(covar_root_decomposition=False, log_prob=False, solves=False):\r\n        for i in range(n_iter):\r\n            # Zero gradients from previous iteration\r\n            optimizer.zero_grad()\r\n            # Output from model\r\n            output = model(train_x)\r\n            # Calc loss and backprop gradients\r\n            loss = -mll(output, train_y)\r\n            loss.backward()\r\n\r\n            optimizer.step()\r\n\r\n    # Prediction\r\n    # Get into evaluation (predictive posterior) mode\r\n    model.eval()\r\n    likelihood.eval()\r\n\r\n    # Test points are regularly spaced along [0,1]\r\n    # Make predictions by feeding model through likelihood\r\n    with torch.no_grad(), \\\r\n        gpytorch.settings.fast_computations(covar_root_decomposition=False, log_prob=False, solves=False), \\\r\n        gpytorch.settings.max_cg_iterations(100), \\\r\n        gpytorch.settings.max_preconditioner_size(100):\r\n        \r\n        test_x = torch.linspace(bounds[0,0], bounds[0,1], 1000)\r\n        if use_double:\r\n            test_x = test_x.double()\r\n        observed_pred = likelihood(model(test_x))\r\n\r\n        # Initialize plot\r\n        f, ax = plt.subplots(1, 1, figsize=(8, 3))\r\n\r\n        # Get upper and lower confidence bounds\r\n        var = observed_pred.variance.numpy()\r\n        mean = observed_pred.mean.numpy()\r\n        lower, upper = mean - 2 * np.sqrt(var), mean + 2 * np.sqrt(var)\r\n        # Plot training data as black stars\r\n        ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\r\n        # Plot predictive means as blue line\r\n        ax.plot(test_x.numpy(), mean, 'b')\r\n        # Shade between the lower and upper confidence bounds\r\n        ax.fill_between(test_x.numpy(), lower, upper, alpha=0.5)\r\n        ax.legend(['Observed Data', 'Mean', 'Confidence'])\r\n    return model, {\r\n        'lengthscale': model.covar_module.base_kernel.lengthscale.item(),\r\n        'variance': model.covar_module.outputscale.item(),\r\n        'noise': model.likelihood.noise.item(),\r\n    }\r\n\r\nmodel, params = gpytorch_model(noise=0.0001, lengthscale=0.01, variance=0.8, n_iter=100, use_double=False)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-84-86542a6e657b> in <module>\r\n    122     }\r\n    123 \r\n--> 124 model, params = gpytorch_model(noise=0.0001, lengthscale=0.01, variance=0.8, n_iter=100, use_double=False)\r\n\r\n<ipython-input-84-86542a6e657b> in gpytorch_model(noise, lengthscale, variance, n_iter, use_double)\r\n     72             output = model(train_x)\r\n     73             # Calc loss and backprop gradients\r\n---> 74             loss = -mll(output, train_y)\r\n     75             loss.backward()\r\n     76 \r\n\r\n~/anaconda3/envs/lions/lib/python3.6/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     20 \r\n     21     def __call__(self, *inputs, **kwargs):\r\n---> 22         outputs = self.forward(*inputs, **kwargs)\r\n     23         if isinstance(outputs, list):\r\n     24             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/anaconda3/envs/lions/lib/python3.6/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, output, target, *params)\r\n     26         # Get the log prob of the marginal distribution\r\n     27         output = self.likelihood(output, *params)\r\n---> 28         res = output.log_prob(target)\r\n     29 \r\n     30         # Add terms for SGPR / when inducing points are learned\r\n\r\n~/anaconda3/envs/lions/lib/python3.6/site-packages/gpytorch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    107     def log_prob(self, value):\r\n    108         if settings.fast_computations.log_prob.off():\r\n--> 109             return super().log_prob(value)\r\n    110 \r\n    111         if self._validate_args:\r\n\r\n~/anaconda3/envs/lions/lib/python3.6/site-packages/torch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    186             self._validate_sample(value)\r\n    187         diff = value - self.loc\r\n--> 188         M = _batch_mahalanobis(self._unbroadcasted_scale_tril, diff)\r\n    189         half_log_det = _batch_diag(self._unbroadcasted_scale_tril).log().sum(-1)\r\n    190         return -0.5 * (self._event_shape[0] * math.log(2 * math.pi) + M) - half_log_det\r\n\r\n~/anaconda3/envs/lions/lib/python3.6/site-packages/torch/distributions/multivariate_normal.py in _batch_mahalanobis(bL, bx)\r\n     48     \"\"\"\r\n     49     n = bx.size(-1)\r\n---> 50     bL = bL.expand(bx.shape[bx.dim() - bL.dim() + 1:] + (n,))\r\n     51     flat_L = bL.reshape(-1, n, n)  # shape = b x n x n\r\n     52     flat_x = bx.reshape(-1, flat_L.size(0), n)  # shape = c x b x n\r\n\r\nRuntimeError: The expanded size of the tensor (1000) must match the existing size (100) at non-singleton dimension 1.  Target sizes: [1000, 1000].  Tensor sizes: [1000, 100]\r\n```\r\n\r\n## Expected Behavior\r\n\r\nWe cannot expect it to work under such low noise without high precision but the error is somewhat strange.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\nGPyTorch Version: 0.3.2\r\nPyTorch Version: 1.0.1.post2\r\nComputer OS: MacOS 10.14\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/729/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/729/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/728", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/728/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/728/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/728/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/728", "id": 452927061, "node_id": "MDU6SXNzdWU0NTI5MjcwNjE=", "number": 728, "title": "[Bug] Posterior variance big compare to GPy for large N", "user": {"login": "tmpethick", "id": 544312, "node_id": "MDQ6VXNlcjU0NDMxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/544312?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tmpethick", "html_url": "https://github.com/tmpethick", "followers_url": "https://api.github.com/users/tmpethick/followers", "following_url": "https://api.github.com/users/tmpethick/following{/other_user}", "gists_url": "https://api.github.com/users/tmpethick/gists{/gist_id}", "starred_url": "https://api.github.com/users/tmpethick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tmpethick/subscriptions", "organizations_url": "https://api.github.com/users/tmpethick/orgs", "repos_url": "https://api.github.com/users/tmpethick/repos", "events_url": "https://api.github.com/users/tmpethick/events{/privacy}", "received_events_url": "https://api.github.com/users/tmpethick/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-06-06T09:30:21Z", "updated_at": "2019-06-06T20:56:41Z", "closed_at": "2019-06-06T15:41:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI am trying to fit `f(x) = sin(60 x\u2074)` with a `gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())` kernel with many observations (`N=1000`). I have fixed the hyperparameters but the posterior variance seems to be much bigger than for GPy (see plots further down). We would expect it to approach zero everywhere for this many observations. Do you have a clue from where the instability could come?\r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nimport math\r\nimport numpy as np\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\ndef gpytorch_model(noise=0.5, lengthscale=2.5, variance=2, n_iter=200):\r\n    bounds = np.array([[0,1]])\r\n    train_x = torch.linspace(bounds[0,0], bounds[0,1], 999).double()\r\n    train_y = np.sin(60 * train_x ** 4)\r\n\r\n    class ExactGPModel(gpytorch.models.ExactGP):\r\n        def __init__(self, train_x, train_y, likelihood):\r\n            super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n            self.mean_module = gpytorch.means.ZeroMean()\r\n            self.covar_module = gpytorch.kernels.ScaleKernel(\r\n                gpytorch.kernels.RBFKernel())\r\n\r\n        def forward(self, x):\r\n            mean_x = self.mean_module(x)\r\n            covar_x = self.covar_module(x)\r\n            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n    # initialize likelihood and model\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n    model = ExactGPModel(train_x, train_y, likelihood)\r\n    model = model.double()\r\n\r\n    model.initialize(**{\r\n        'likelihood.noise': noise,\r\n        'covar_module.base_kernel.lengthscale': lengthscale,\r\n        'covar_module.outputscale': variance,\r\n    })\r\n    print(\"lengthscale: %.3f, variance: %.3f,   noise: %.5f\" % (model.covar_module.base_kernel.lengthscale.item(),\r\n            model.covar_module.outputscale.item(),\r\n            model.likelihood.noise.item()))\r\n\r\n    # Find optimal model hyperparameters\r\n    model.train()\r\n    likelihood.train()\r\n\r\n    # Use the adam optimizer\r\n    optimizer = torch.optim.Adam([\r\n        {'params': model.parameters()}, \r\n    ], lr=0.1)\r\n\r\n    # \"Loss\" for GPs - the marginal log likelihood\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n    \r\n    for i in range(n_iter):\r\n        # Zero gradients from previous iteration\r\n        optimizer.zero_grad()\r\n        # Output from model\r\n        output = model(train_x)\r\n        # Calc loss and backprop gradients\r\n        loss = -mll(output, train_y)\r\n        loss.backward()\r\n\r\n        optimizer.step()\r\n\r\n    # Prediction\r\n    # Get into evaluation (predictive posterior) mode\r\n    model.eval()\r\n    likelihood.eval()\r\n\r\n    # Test points are regularly spaced along [0,1]\r\n    # Make predictions by feeding model through likelihood\r\n    with torch.no_grad():\r\n        test_x = torch.linspace(bounds[0,0], bounds[0,1], 1000).double()\r\n        observed_pred = likelihood(model(test_x))\r\n\r\n        # Initialize plot\r\n        f, ax = plt.subplots(1, 1, figsize=(8, 3))\r\n\r\n        # Get upper and lower confidence bounds\r\n        var = observed_pred.variance.numpy()\r\n        mean = observed_pred.mean.numpy()\r\n        lower, upper = mean - 2 * np.sqrt(var), mean + 2 * np.sqrt(var)\r\n        # Plot training data as black stars\r\n        ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\r\n        # Plot predictive means as blue line\r\n        ax.plot(test_x.numpy(), mean, 'b')\r\n        # Shade between the lower and upper confidence bounds\r\n        ax.fill_between(test_x.numpy(), lower, upper, alpha=0.5)\r\n        ax.legend(['Observed Data', 'Mean', 'Confidence'])\r\n    return model, {\r\n        'lengthscale': model.covar_module.base_kernel.lengthscale.item(),\r\n        'variance': model.covar_module.outputscale.item(),\r\n        'noise': model.likelihood.noise.item(),\r\n    }\r\n\r\nmodel, params = gpytorch_model(noise=0.0001, lengthscale=0.015, variance=9, n_iter=0)\r\n```\r\n\r\n** Stack trace/error message **\r\n\r\n## Expected Behavior\r\n\r\nWe expect similar behaviour to GPy:\r\n<img width=\"368\" alt=\"Screenshot 2019-06-06 at 11 16 05\" src=\"https://user-images.githubusercontent.com/544312/59021714-a04fff00-884c-11e9-9ca9-267c37e2042a.png\">\r\n\r\nBut got:\r\n<img width=\"373\" alt=\"Screenshot 2019-06-06 at 11 13 54\" src=\"https://user-images.githubusercontent.com/544312/59021551-4cddb100-884c-11e9-9ea3-618b50e45155.png\">\r\n\r\n\r\n## System information\r\n\r\nGPyTorch Version: 0.3.2\r\nPyTorch Version: 1.0.1.post2\r\nComputer OS: MacOS 10.14\r\n\r\n## Additional context\r\n\r\nCode to reproduce the GPy plot:\r\n```python\r\nimport math\r\nimport torch\r\nimport numpy as np\r\nfrom matplotlib import pyplot as plt\r\nimport GPy\r\n\r\ndef gpy_model(noise=0.5, lengthscale=2.5, variance=2, optimize=True):\r\n    def f(x):\r\n        x = np.asanyarray(x)\r\n        y = where(x == 0, 1.0e-20, x)\r\n        return np.sin(y)/y\r\n\r\n    bounds = np.array([[0,1]])\r\n    train_x = torch.linspace(bounds[0,0], bounds[0,1], 999)\r\n    train_y = np.sin(60 * train_x ** 4)\r\n\r\n    kernel = GPy.kern.RBF(1, ARD=False)\r\n    model = GPy.models.GPRegression(train_x.numpy()[:,None], train_y.numpy()[:,None], kernel=kernel)\r\n    model.Gaussian_noise = noise\r\n    model.kern.lengthscale = lengthscale\r\n    model.kern.variance = variance\r\n\r\n    if optimize:\r\n        model.optimize()\r\n\r\n    test_x = np.linspace(bounds[0,0], bounds[0,1], 1000)\r\n    mean, var = model.predict(test_x[:, None])\r\n    mean = mean[:,0]\r\n    var = var[:,0]\r\n\r\n    # Initialize plot\r\n    f, ax = plt.subplots(1, 1, figsize=(8, 3))\r\n\r\n    # Get upper and lower confidence bounds\r\n    lower, upper = mean - 2 * np.sqrt(var), mean + 2 * np.sqrt(var)\r\n    # Plot training data as black stars\r\n    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\r\n    # Plot predictive means as blue line\r\n    ax.plot(test_x, mean, 'b')\r\n    # Shade between the lower and upper confidence bounds\r\n    ax.fill_between(test_x, lower, upper, alpha=0.5)\r\n    ax.legend(['Observed Data', 'Mean', 'Confidence'])\r\n\r\n    #print(\"l: {}, v: {}, noise: {}\".format(kernel.lengthscale, kernel.variance, model.Gaussian_noise.variance))\r\n    return model, {\r\n        'lengthscale': kernel.lengthscale,\r\n        'noise': model.Gaussian_noise.variance,\r\n        'variance': kernel.variance\r\n    }\r\n\r\nmodel, params = gpy_model(noise=0.0001, lengthscale=0.015, variance=9, optimize=False)\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/728/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/728/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/727", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/727/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/727/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/727/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/727", "id": 452876124, "node_id": "MDU6SXNzdWU0NTI4NzYxMjQ=", "number": 727, "title": "[Bug] Noise-free setting causes CG termination during prediction", "user": {"login": "tmpethick", "id": 544312, "node_id": "MDQ6VXNlcjU0NDMxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/544312?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tmpethick", "html_url": "https://github.com/tmpethick", "followers_url": "https://api.github.com/users/tmpethick/followers", "following_url": "https://api.github.com/users/tmpethick/following{/other_user}", "gists_url": "https://api.github.com/users/tmpethick/gists{/gist_id}", "starred_url": "https://api.github.com/users/tmpethick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tmpethick/subscriptions", "organizations_url": "https://api.github.com/users/tmpethick/orgs", "repos_url": "https://api.github.com/users/tmpethick/repos", "events_url": "https://api.github.com/users/tmpethick/events{/privacy}", "received_events_url": "https://api.github.com/users/tmpethick/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-06T07:36:56Z", "updated_at": "2019-06-06T15:24:36Z", "closed_at": "2019-06-06T15:24:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI am trying to fit `f(x) = sin(60 x\u2074)` with a `gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())` kernel. The maximum likelihood optimization with Adam seems to run correctly but at prediction time CG terminates because of too large norm.\r\n\r\nCrucially this is a noisefree setting. If we were to add `N(0,0.1)` noise there would be no problem. However, GPy can handle the noisefree setting. Can we configure GPyTorch somehow to do the same?\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nimport numpy as np\r\nfrom matplotlib import pyplot as plt\r\n%matplotlib inline\r\n\r\nbounds = np.array([[0,1]])\r\ntrain_x = torch.linspace(bounds[0,0], bounds[0,1], 200)\r\ntrain_y = np.sin(60 * train_x ** 4)\r\n\r\n# We will use the simplest form of GP model, exact inference\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ZeroMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n# initialize likelihood and model\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n# likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=torch.ones(1) * 0.0001)\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n\r\nmodel.initialize(**{\r\n    'likelihood.noise': 0.5,\r\n    'covar_module.base_kernel.lengthscale': 2.5,\r\n    'covar_module.outputscale': 1.5\r\n})\r\nprint(\"Initialized with: lengthscale=%.3f variance=%.3f noise=%.5f\" % (model.covar_module.base_kernel.lengthscale.item(),\r\n        model.covar_module.outputscale.item(),\r\n        model.likelihood.noise.item()))\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()}, \r\n], lr=0.1)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ntraining_iter = 500\r\nfor i in range(training_iter):\r\n    # Zero gradients from previous iteration\r\n    optimizer.zero_grad()\r\n    # Output from model\r\n    output = model(train_x)\r\n    # Calc loss and backprop gradients\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f, variance: %.3f,   noise: %.5f' % (\r\n        i + 1, training_iter, loss.item(),\r\n        model.covar_module.base_kernel.lengthscale.item(),\r\n        model.covar_module.outputscale.item(),\r\n        model.likelihood.noise.item()\r\n    ))\r\n    optimizer.step()\r\n\r\n# Prediction\r\n# Get into evaluation (predictive posterior) mode\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\n# Test points are regularly spaced along [0,1]\r\n# Make predictions by feeding model through likelihood\r\nwith torch.no_grad():\r\n    test_x = torch.linspace(bounds[0,0], bounds[0,1], 1000)\r\n    observed_pred = likelihood(model(test_x))\r\n\r\n    # Initialize plot\r\n    f, ax = plt.subplots(1, 1, figsize=(10, 10))\r\n\r\n    # Get upper and lower confidence bounds\r\n    lower, upper = observed_pred.confidence_region()\r\n    # Plot training data as black stars\r\n    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\r\n    # Plot predictive means as blue line\r\n    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\r\n    # Shade between the lower and upper confidence bounds\r\n    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\r\n    ax.set_ylim([-3, 3])\r\n    ax.legend(['Observed Data', 'Mean', 'Confidence'])\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n .../gpytorch/utils/linear_cg.py:295: UserWarning:CG terminated in 1000 iterations with average residual norm 13342.345703125 which is larger than the tolerance of 0.01 specified by gpytorch.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a gpytorch.settings.max_cg_iterations(value) context.\r\n.../gpytorch/utils/linear_cg.py:295: UserWarning:CG terminated in 1000 iterations with average residual norm 191.66046142578125 which is larger than the tolerance of 0.01 specified by gpytorch.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a gpytorch.settings.max_cg_iterations(value) context.\r\n```\r\n<img width=\"404\" alt=\"Screenshot 2019-06-06 at 09 34 15\" src=\"https://user-images.githubusercontent.com/544312/59015021-48120080-883e-11e9-80f6-a8f964786acf.png\">\r\n\r\n\r\n## Expected Behavior\r\n\r\n<img width=\"217\" alt=\"Screenshot 2019-06-06 at 09 34 46\" src=\"https://user-images.githubusercontent.com/544312/59015057-58c27680-883e-11e9-94c6-fbf78838741b.png\">\r\n\r\n\r\n## System information\r\n\r\nGPyTorch Version: 0.3.2\r\nPyTorch Version: 1.0.1.post2\r\nComputer OS: MacOS 10.14\r\n\r\n## Additional context\r\n\r\nGPy manage to plot it even for `N=1000`.\r\n\r\n```python\r\n%matplotlib inline\r\n\r\nimport math\r\nimport numpy as np\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\nimport GPy\r\n\r\nbounds = np.array([[0,1]])\r\ntrain_x = torch.linspace(bounds[0,0], bounds[0,1], 1000)\r\ntrain_y = np.sin(60 * train_x ** 4)\r\n\r\nkernel = GPy.kern.RBF(1, ARD=False)\r\nmodel = GPy.models.GPRegression(train_x.numpy()[:,None], train_y.numpy()[:,None], kernel=kernel)\r\nmodel.Gaussian_noise = 0.5\r\nmodel.kern.lengthscale = 2.5\r\nmodel.kern.variance = 1.5\r\n\r\nmodel.optimize()\r\n\r\ntest_x = np.linspace(bounds[0,0], bounds[0,1], 1000)\r\nmean, var = model.predict(test_x[:, None])\r\nmean = mean[:,0]\r\nvar = var[:,0]\r\n\r\nf, ax = plt.subplots(1, 1, figsize=(10, 10))\r\n\r\n# Get upper and lower confidence bounds\r\nlower, upper = mean - 2 * np.sqrt(var), mean + 2 * np.sqrt(var)\r\n# Plot training data as black stars\r\nax.plot(train_x.numpy(), train_y.numpy(), 'k*')\r\n# Plot predictive means as blue line\r\nax.plot(test_x, mean, 'b')\r\n# Shade between the lower and upper confidence bounds\r\nax.fill_between(test_x, lower, upper, alpha=0.5)\r\nax.legend(['Observed Data', 'Mean', 'Confidence'])\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/727/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/727/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/722", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/722/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/722/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/722/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/722", "id": 452463210, "node_id": "MDU6SXNzdWU0NTI0NjMyMTA=", "number": 722, "title": "[Bug] Trapped with bad initialization", "user": {"login": "tmpethick", "id": 544312, "node_id": "MDQ6VXNlcjU0NDMxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/544312?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tmpethick", "html_url": "https://github.com/tmpethick", "followers_url": "https://api.github.com/users/tmpethick/followers", "following_url": "https://api.github.com/users/tmpethick/following{/other_user}", "gists_url": "https://api.github.com/users/tmpethick/gists{/gist_id}", "starred_url": "https://api.github.com/users/tmpethick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tmpethick/subscriptions", "organizations_url": "https://api.github.com/users/tmpethick/orgs", "repos_url": "https://api.github.com/users/tmpethick/repos", "events_url": "https://api.github.com/users/tmpethick/events{/privacy}", "received_events_url": "https://api.github.com/users/tmpethick/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-05T12:01:50Z", "updated_at": "2019-06-06T06:26:50Z", "closed_at": "2019-06-06T06:26:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nMy problem is in reproducing result from GPy with GPyTorch when using the same (bad) initialisation for the hyperparameters.\r\nI am using `gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())` as the kernel and setting the lengthscale higher than the domain interval (`l=2.5`).\r\nThe Adam optimizer gets trapped in a local minimum that has close to constant posterior mean.\r\nThis happens for a wide range of training hyperparameters (here with `lr=0.1` and `epochs=500`).\r\nIn contrast GPy manage to escape by finding the more reasonable `l=0.01`. \r\n\r\nIt seems quite crucial for robustness that we are not too dependent on the initialization. Is there any way this can be achieved with GPyTorch?\r\n\r\nPS: I am testing on a function `f(x) = sin(60 x\u2074)` that is increasingly oscillating.\r\nPSS: Thanks for a very well thought out architecture!\r\n\r\n## To reproduce\r\n\r\n*Pulled and modified from documentation example*.\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nimport numpy as np\r\nfrom matplotlib import pyplot as plt\r\n%matplotlib inline\r\n\r\nbounds = np.array([[0,1]])\r\ntrain_x = torch.linspace(bounds[0,0], bounds[0,1], 100)\r\ntrain_y = np.sin(60 * train_x ** 4)\r\n\r\n# We will use the simplest form of GP model, exact inference\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n# initialize likelihood and model\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n# likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=torch.ones(1) * 0.0001)\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n\r\nmodel.initialize(**{\r\n    'likelihood.noise': 0.5,\r\n    'covar_module.base_kernel.lengthscale': 2.5,\r\n    'covar_module.outputscale': 1.5\r\n})\r\nprint(\"Initialized with: lengthscale=%.3f variance=%.3f noise=%.5f\" % (model.covar_module.base_kernel.lengthscale.item(),\r\n        model.covar_module.outputscale.item(),\r\n        model.likelihood.noise.item()))\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()}, \r\n], lr=0.1)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ntraining_iter = 500\r\nfor i in range(training_iter):\r\n    # Zero gradients from previous iteration\r\n    optimizer.zero_grad()\r\n    # Output from model\r\n    output = model(train_x)\r\n    # Calc loss and backprop gradients\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f, variance: %.3f,   noise: %.5f' % (\r\n        i + 1, training_iter, loss.item(),\r\n        model.covar_module.base_kernel.lengthscale.item(),\r\n        model.covar_module.outputscale.item(),\r\n        model.likelihood.noise.item()\r\n    ))\r\n    optimizer.step()\r\n\r\n# Prediction\r\n# Get into evaluation (predictive posterior) mode\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\n# Test points are regularly spaced along [0,1]\r\n# Make predictions by feeding model through likelihood\r\nwith torch.no_grad():\r\n    test_x = torch.linspace(bounds[0,0], bounds[0,1], 1000)\r\n    observed_pred = likelihood(model(test_x))\r\n\r\n    # Initialize plot\r\n    f, ax = plt.subplots(1, 1, figsize=(10, 10))\r\n\r\n    # Get upper and lower confidence bounds\r\n    lower, upper = observed_pred.confidence_region()\r\n    # Plot training data as black stars\r\n    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\r\n    # Plot predictive means as blue line\r\n    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\r\n    # Shade between the lower and upper confidence bounds\r\n    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\r\n    ax.set_ylim([-3, 3])\r\n    ax.legend(['Observed Data', 'Mean', 'Confidence'])\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n// Paste the bad output here!\r\n```\r\n\r\n## Expected Behavior\r\n\r\nWith a lengthscale initalization of `l=2.5` we get trapped whereas we should be able to find `l=0.1`. (see `Additional context` for GPy implementation which manages this with the same initialization).\r\n\r\n## System information\r\n\r\nGPyTorch Version: 0.3.2\r\nPyTorch Version: 1.0.1.post2\r\nComputer OS: MacOS 10.14\r\n\r\n## Additional context\r\n\r\nThis is to created the expected behaviour in GPy (note that GPy is required).\r\n\r\n```\r\n%matplotlib inline\r\n\r\nimport math\r\nimport numpy as np\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\nimport GPy\r\n\r\nbounds = np.array([[0,1]])\r\ntrain_x = torch.linspace(bounds[0,0], bounds[0,1], 100)\r\ntrain_y = np.sin(60 * train_x ** 4)\r\n\r\nkernel = GPy.kern.RBF(1, ARD=False)\r\nmodel = GPy.models.GPRegression(train_x.numpy()[:,None], train_y.numpy()[:,None], kernel=kernel)\r\nmodel.Gaussian_noise = 0.5\r\nmodel.kern.lengthscale = 2.5\r\nmodel.kern.variance = 1.5\r\n\r\nmodel.optimize()\r\n\r\ntest_x = np.linspace(bounds[0,0], bounds[0,1], 1000)\r\nmean, var = model.predict(test_x[:, None])\r\nmean = mean[:,0]\r\nvar = var[:,0]\r\n\r\nf, ax = plt.subplots(1, 1, figsize=(10, 10))\r\n\r\n# Get upper and lower confidence bounds\r\nlower, upper = mean - 2 * np.sqrt(var), mean + 2 * np.sqrt(var)\r\n# Plot training data as black stars\r\nax.plot(train_x.numpy(), train_y.numpy(), 'k*')\r\n# Plot predictive means as blue line\r\nax.plot(test_x, mean, 'b')\r\n# Shade between the lower and upper confidence bounds\r\nax.fill_between(test_x, lower, upper, alpha=0.5)\r\nax.legend(['Observed Data', 'Mean', 'Confidence'])\r\n\r\nmodel\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/722/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/722/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/720", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/720/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/720/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/720/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/720", "id": 452318820, "node_id": "MDU6SXNzdWU0NTIzMTg4MjA=", "number": 720, "title": "[Bug] Product kernel produces error when obtaining diagonal for predictive variance", "user": {"login": "stevenstetzler", "id": 11035971, "node_id": "MDQ6VXNlcjExMDM1OTcx", "avatar_url": "https://avatars.githubusercontent.com/u/11035971?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stevenstetzler", "html_url": "https://github.com/stevenstetzler", "followers_url": "https://api.github.com/users/stevenstetzler/followers", "following_url": "https://api.github.com/users/stevenstetzler/following{/other_user}", "gists_url": "https://api.github.com/users/stevenstetzler/gists{/gist_id}", "starred_url": "https://api.github.com/users/stevenstetzler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stevenstetzler/subscriptions", "organizations_url": "https://api.github.com/users/stevenstetzler/orgs", "repos_url": "https://api.github.com/users/stevenstetzler/repos", "events_url": "https://api.github.com/users/stevenstetzler/events{/privacy}", "received_events_url": "https://api.github.com/users/stevenstetzler/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-05T05:18:49Z", "updated_at": "2019-07-29T16:19:56Z", "closed_at": "2019-07-29T16:19:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nIn some cases when producing predictive variance, I get an error `RuntimeError: The kernel LazyEvaluatedKernelTensor is not equipped to handle and diag. Expected size torch.Size([500]). Got size torch.Size([1, 500])`, where size here refers to the size of data passed to `model(data)`. I've checked the sizes of my inputs, and they are all in order. The issue also appears to go away when I decrease the size of the data set.\r\n\r\n## To reproduce\r\n\r\n**Code snippet to reproduce**\r\n\r\nPlease see attached data file to use the same data. This appears to be a number of data points issue and/or a product kernel issue, so maybe it can be reproduced otherwise.\r\n```python\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\nimport numpy as np\r\n\r\n# Define GP model\r\nclass PeriodicGP(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(PeriodicGP, self).__init__(train_x, train_y, likelihood)\r\n\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        \r\n        covar_prod = gpytorch.kernels.RBFKernel() * gpytorch.kernels.PeriodicKernel()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(covar_prod)\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\ndata = np.loadtxt(\"broken_data.txt\", dtype=float)\r\ntrain_x = torch.tensor(data[:, 0], dtype=torch.float)\r\ntrain_y = torch.tensor(data[:, 1], dtype=torch.float)\r\ntrain_y_err = torch.tensor(data[:, 2], dtype=torch.float)\r\n\r\n# Show the data\r\nplt.errorbar(train_x.detach().numpy(), train_y.detach().numpy(), train_y_err.detach().numpy(), fmt='o')\r\nplt.show()\r\n\r\n# Define likelihood and model\r\nlikelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=train_y_err, learn_additional_noise=False)\r\nmodel = PeriodicGP(train_x, train_y, likelihood)\r\n\r\n# Plot results\r\nmodel.eval(), likelihood.eval()\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    test_x = train_x\r\n    test_y_err = train_y_err\r\n    \r\n    result = model(test_x)\r\n    \r\n    observed_pred = likelihood(result, noise=test_y_err)\r\n    lower, upper = observed_pred.confidence_region()\r\n    \r\n    plt.plot(test_x.detach().numpy(), observed_pred.mean.detach().numpy(), color=\"blue\")\r\n    plt.scatter(train_x, train_y, color=\"k\")\r\n    plt.fill_between(test_x, lower.detach().numpy(), upper.detach().numpy(), alpha=0.5, color=\"C0\")\r\n    plt.show()\r\n```\r\n\r\n**Stack trace/error message**\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-34-2ec9df0172e9> in <module>\r\n      7 \r\n      8     observed_pred = likelihood(result, noise=test_y_err)\r\n----> 9     lower, upper = observed_pred.confidence_region()\r\n     10 \r\n     11     plt.plot(test_x.detach().numpy(), observed_pred.mean.detach().numpy(), color=\"blue\")\r\n\r\n~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/distributions/multivariate_normal.py in confidence_region(self)\r\n     77 \r\n     78         \"\"\"\r\n---> 79         std2 = self.stddev.mul_(2)\r\n     80         mean = self.mean\r\n     81         return mean.sub(std2), mean.add(std2)\r\n\r\n~/.conda/envs/mypy/lib/python3.6/site-packages/torch/distributions/distribution.py in stddev(self)\r\n    109         Returns the standard deviation of the distribution.\r\n    110         \"\"\"\r\n--> 111         return self.variance.sqrt()\r\n    112 \r\n    113     def sample(self, sample_shape=torch.Size()):\r\n\r\n~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/distributions/multivariate_normal.py in variance(self)\r\n    181         if self.islazy:\r\n    182             # overwrite this since torch MVN uses unbroadcasted_scale_tril for this\r\n--> 183             diag = self.lazy_covariance_matrix.diag()\r\n    184             diag = diag.view(diag.shape[:-1] + self._event_shape)\r\n    185             return diag.expand(self._batch_shape + self._event_shape)\r\n\r\n~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/lazy/sum_lazy_tensor.py in diag(self)\r\n     78 \r\n     79     def diag(self):\r\n---> 80         diags = [lazy_tensor.diag().contiguous() for lazy_tensor in self.lazy_tensors]\r\n     81         size = diags[0].size()\r\n     82         res = sum(diag.view(-1) for diag in diags)\r\n\r\n~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/lazy/sum_lazy_tensor.py in <listcomp>(.0)\r\n     78 \r\n     79     def diag(self):\r\n---> 80         diags = [lazy_tensor.diag().contiguous() for lazy_tensor in self.lazy_tensors]\r\n     81         size = diags[0].size()\r\n     82         res = sum(diag.view(-1) for diag in diags)\r\n\r\n~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/lazy/sum_lazy_tensor.py in diag(self)\r\n     78 \r\n     79     def diag(self):\r\n---> 80         diags = [lazy_tensor.diag().contiguous() for lazy_tensor in self.lazy_tensors]\r\n     81         size = diags[0].size()\r\n     82         res = sum(diag.view(-1) for diag in diags)\r\n\r\n~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/lazy/sum_lazy_tensor.py in <listcomp>(.0)\r\n     78 \r\n     79     def diag(self):\r\n---> 80         diags = [lazy_tensor.diag().contiguous() for lazy_tensor in self.lazy_tensors]\r\n     81         size = diags[0].size()\r\n     82         res = sum(diag.view(-1) for diag in diags)\r\n\r\n~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36 \r\n\r\n~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in diag(self)\r\n    248                 raise RuntimeError(\r\n    249                     \"The kernel {} is not equipped to handle and diag. Expected size {}. \"\r\n--> 250                     \"Got size {}\".format(self.__class__.__name__, expected_shape, res.shape)\r\n    251                 )\r\n    252 \r\n\r\nRuntimeError: The kernel LazyEvaluatedKernelTensor is not equipped to handle and diag. Expected size torch.Size([500]). Got size torch.Size([1, 500])\r\n```\r\n\r\nI can resolve this by removing data:\r\n\r\n```python\r\n# take first 10 data points\r\ntrain_x = torch.tensor(data[:, 0], dtype=torch.float)[:10]\r\ntrain_y = torch.tensor(data[:, 1], dtype=torch.float)[:10]\r\ntrain_y_err = torch.tensor(data[:, 2], dtype=torch.float)[:10]\r\n\r\nlikelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=train_y_err, learn_additional_noise=False)\r\nmodel = PeriodicGP(train_x, train_y, likelihood)\r\nmodel.eval(), likelihood.eval()\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    test_x = train_x\r\n    test_y_err = train_y_err\r\n    \r\n    result = model(test_x)\r\n    \r\n    observed_pred = likelihood(result, noise=test_y_err)\r\n    lower, upper = observed_pred.confidence_region()\r\n    \r\n    plt.plot(test_x.detach().numpy(), observed_pred.mean.detach().numpy(), color=\"blue\")\r\n    plt.scatter(train_x, train_y, color=\"k\")\r\n    plt.fill_between(test_x, lower.detach().numpy(), upper.detach().numpy(), alpha=0.5, color=\"C0\")\r\n    plt.show()\r\n```\r\nThis produces the expected result, although I'd expect that the confidence region should be much smaller based on the errors in the data:\r\n![image](https://user-images.githubusercontent.com/11035971/58931476-ae026900-8714-11e9-99ee-417677377642.png)\r\n\r\nI can also resolve this by removing the product nature of the kernel:\r\n\r\n```python\r\nclass PeriodicGP(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(PeriodicGP, self).__init__(train_x, train_y, likelihood)\r\n\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        \r\n        covar_prod = gpytorch.kernels.RBFKernel()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(covar_prod)\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\ntrain_x = torch.tensor(data[:, 0], dtype=torch.float)\r\ntrain_y = torch.tensor(data[:, 1], dtype=torch.float)\r\ntrain_y_err = torch.tensor(data[:, 2], dtype=torch.float)\r\n\r\nplt.errorbar(train_x.detach().numpy(), train_y.detach().numpy(), train_y_err.detach().numpy(), fmt='o')\r\nplt.show()\r\n\r\nlikelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=train_y_err, learn_additional_noise=False)\r\nmodel = PeriodicGP(train_x, train_y, likelihood)\r\n\r\nmodel.eval(), likelihood.eval()\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    test_x = train_x\r\n    test_y_err = train_y_err\r\n    \r\n    result = model(test_x)\r\n    \r\n    observed_pred = likelihood(result, noise=test_y_err)\r\n    lower, upper = observed_pred.confidence_region()\r\n    \r\n    plt.plot(test_x.detach().numpy(), observed_pred.mean.detach().numpy(), color=\"blue\")\r\n    plt.scatter(train_x, train_y, color=\"k\")\r\n    plt.fill_between(test_x, lower.detach().numpy(), upper.detach().numpy(), alpha=0.5, color=\"C0\")\r\n    plt.show()\r\n```\r\nproduces expected results. Again, I'd expect that the confidence region should be much smaller based on the errors in the data.\r\n![image](https://user-images.githubusercontent.com/11035971/58931570-02a5e400-8715-11e9-8a39-5ce3aae1a206.png)\r\n\r\nFinally note that I can still produce the predictive mean, it is just the variance that is breaking:\r\n```python\r\n# using the original kernel and all data\r\nmodel.eval(), likelihood.eval()\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    test_x = train_x\r\n    test_y_err = train_y_err\r\n    \r\n    result = model(test_x)\r\n    \r\n    observed_pred = likelihood(result, noise=test_y_err)\r\n#     lower, upper = observed_pred.confidence_region()\r\n    \r\n    plt.plot(test_x.detach().numpy(), observed_pred.mean.detach().numpy(), color=\"blue\")\r\n    plt.scatter(train_x, train_y, color=\"k\")\r\n#     plt.fill_between(test_x, lower.detach().numpy(), upper.detach().numpy(), alpha=0.5, color=\"C0\")\r\n    plt.show()\r\n```\r\nproduces the expected result:\r\n![image](https://user-images.githubusercontent.com/11035971/58931625-354fdc80-8715-11e9-9866-348a9e98d9b2.png)\r\n\r\n## Expected Behavior\r\n\r\nI expected the variance to be computed correctly, as is done in many other cases with the same data.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n-  GPyTorch Version (run `print(gpytorch.__version__)`)\r\n`0.3.2`\r\n- PyTorch Version (run `print(torch.__version__)`)\r\n`1.1.0`\r\n- Computer OS\r\n`CentOS Linux release 7.6.1810`\r\n\r\n## Additional context\r\n\r\nData:\r\n[broken_data.txt](https://github.com/cornellius-gp/gpytorch/files/3255597/broken_data.txt)\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/720/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/720/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/710", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/710/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/710/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/710/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/710", "id": 449981407, "node_id": "MDU6SXNzdWU0NDk5ODE0MDc=", "number": 710, "title": "[Bug] TypeError when calling `backward` on `gpytorch.functions.logdet` ", "user": {"login": "mshvartsman", "id": 70196, "node_id": "MDQ6VXNlcjcwMTk2", "avatar_url": "https://avatars.githubusercontent.com/u/70196?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mshvartsman", "html_url": "https://github.com/mshvartsman", "followers_url": "https://api.github.com/users/mshvartsman/followers", "following_url": "https://api.github.com/users/mshvartsman/following{/other_user}", "gists_url": "https://api.github.com/users/mshvartsman/gists{/gist_id}", "starred_url": "https://api.github.com/users/mshvartsman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mshvartsman/subscriptions", "organizations_url": "https://api.github.com/users/mshvartsman/orgs", "repos_url": "https://api.github.com/users/mshvartsman/repos", "events_url": "https://api.github.com/users/mshvartsman/events{/privacy}", "received_events_url": "https://api.github.com/users/mshvartsman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-29T19:27:50Z", "updated_at": "2019-05-29T21:44:18Z", "closed_at": "2019-05-29T21:44:18Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI think there's a missing `list()` in https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/functions/_inv_quad_log_det.py#L221. I'm not super familiar with gpytorch internals so hopefully this is correct -- if so, happy to contribute the one-liner fix. \r\n\r\n## To reproduce\r\n\r\n** Code snippet to reproduce **\r\n```python\r\n### works (I'm guessing something dispatches elsewhere for small matrices?)\r\nimport torch\r\nfrom torch.autograd import backward\r\nimport gpytorch\r\nfrom gpytorch.functions import logdet, inv_matmul\r\nn = 100\r\ninp = torch.arange(n, dtype=torch.float)\r\nkern = gpytorch.kernels.RBFKernel()(inp)\r\nld = logdet(kern)\r\nbackward(ld)\r\n\r\n### doesn't work\r\nimport torch\r\nfrom torch.autograd import backward\r\nimport gpytorch\r\nfrom gpytorch.functions import logdet, inv_matmul\r\nn = 1000\r\ninp = torch.arange(n, dtype=torch.float)\r\nkern = gpytorch.kernels.RBFKernel()(inp)\r\nld = logdet(kern)\r\nbackward(ld)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-46-593fbced29ac> in <module>()\r\n      3 kern = gpytorch.kernels.RBFKernel()(inp)\r\n      4 ld = logdet(kern)\r\n----> 5 backward(ld)\r\n\r\n<PATH SNIPPED>/lib/python3.7/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\r\n     91     Variable._execution_engine.run_backward(\r\n     92         tensors, grad_tensors, retain_graph, create_graph,\r\n---> 93         allow_unreachable=True)  # allow_unreachable flag\r\n     94 \r\n     95 \r\n\r\n<PATH SNIPPED>/lib/python3.7/site-packages/torch/autograd/function.py in apply(self, *args)\r\n     75 \r\n     76     def apply(self, *args):\r\n---> 77         return self._forward_cls.backward(self, *args)\r\n     78 \r\n     79 \r\n\r\n<PATH SNIPPED>lib/python3.7/site-packages/gpytorch/functions/_inv_quad_log_det.py in backward(ctx, inv_quad_grad_output, logdet_grad_output)\r\n    221             res = matrix_arg_grads\r\n    222 \r\n--> 223         return tuple([None] * 9 + res)\r\n\r\nTypeError: can only concatenate list (not \"tuple\") to list\r\n```\r\n\r\n## Expected Behavior\r\n\r\nNo error. \r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch version: 0.3.2 <!-- GPyTorch Version (run `print(gpytorch.__version__)` -->\r\n- pytorch version 1.1.0. \r\n- Mac OSX. \r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/710/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/710/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/703", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/703/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/703/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/703/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/703", "id": 446979750, "node_id": "MDU6SXNzdWU0NDY5Nzk3NTA=", "number": 703, "title": "[question] GPflow vs GPyTorch comparison", "user": {"login": "tadejkrivec", "id": 44575819, "node_id": "MDQ6VXNlcjQ0NTc1ODE5", "avatar_url": "https://avatars.githubusercontent.com/u/44575819?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tadejkrivec", "html_url": "https://github.com/tadejkrivec", "followers_url": "https://api.github.com/users/tadejkrivec/followers", "following_url": "https://api.github.com/users/tadejkrivec/following{/other_user}", "gists_url": "https://api.github.com/users/tadejkrivec/gists{/gist_id}", "starred_url": "https://api.github.com/users/tadejkrivec/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tadejkrivec/subscriptions", "organizations_url": "https://api.github.com/users/tadejkrivec/orgs", "repos_url": "https://api.github.com/users/tadejkrivec/repos", "events_url": "https://api.github.com/users/tadejkrivec/events{/privacy}", "received_events_url": "https://api.github.com/users/tadejkrivec/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-22T07:39:33Z", "updated_at": "2019-05-24T07:18:21Z", "closed_at": "2019-05-22T08:04:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nI am trying to compare the GPyTorch and GPflow on some dataset. I am using the same kernel, the same data, and I initialize the kernel hyperparameters to the same values. After that I check if the marginal log likelihood values agree between frameworks. I basically get the same values. After that I ran an Adam optimizer on both models. \r\n\r\n## To reproduce\r\n\r\nThis is the snippet for Adam optimization with GPyTorch:\r\n```python\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n], lr=1)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ntraining_iterations = 10\r\nfor i in range(training_iterations):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)*train_x.shape[0]\r\n    loss.backward()\r\n    optimizer.step()\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, -loss.item()))\r\n```\r\nI get the following loss:\r\n```\r\nIter 1/10 - Loss: -2893.835\r\nIter 2/10 - Loss: -1770.051\r\nIter 3/10 - Loss: -477.718\r\nIter 4/10 - Loss: 926.491\r\nIter 5/10 - Loss: 2390.616\r\nIter 6/10 - Loss: 3882.949\r\nIter 7/10 - Loss: 5386.975\r\nIter 8/10 - Loss: 6898.352\r\nIter 9/10 - Loss: nan\r\nIter 10/10 - Loss: nan\r\n```\r\n\r\n## Expected Behavior\r\nWhereas for GPflow I get the following:\r\n```\r\nGPR with Adam: iteration 1 likelihood -2898.1686\r\nGPR with Adam: iteration 2 likelihood -1769.1999\r\nGPR with Adam: iteration 3 likelihood -478.7015\r\nGPR with Adam: iteration 4 likelihood 926.5689\r\nGPR with Adam: iteration 5 likelihood 2390.6707\r\nGPR with Adam: iteration 6 likelihood 3882.2375\r\nGPR with Adam: iteration 7 likelihood 5386.5491\r\nGPR with Adam: iteration 8 likelihood 6896.0282\r\nGPR with Adam: iteration 9 likelihood 8404.9174\r\nGPR with Adam: iteration 10 likelihood 9904.9957\r\n```\r\n\r\nI think that this has to be some problem with how the marginal log likelihood is calculated? I have tried to run Adam to convergence using GPflow and then initialize the GPyTorch model with the learned parameters and I get nan when trying to calculate the marginal log likelihood.\r\n```\r\ntensor(nan, device='cuda:0', grad_fn=<MulBackward0>)\r\n\r\n/home/user/miniconda/envs/py36/lib/python3.6/site-packages/gpytorch/utils/linear_cg.py:295: UserWarning: CG terminated in 1000 iterations with average residual norm nan which is larger than the tolerance of 1 specified by gpytorch.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a gpytorch.settings.max_cg_iterations(value) context.\r\n  \" a gpytorch.settings.max_cg_iterations(value) context.\".format(k + 1, residual_norm.mean(), tolerance)\r\n```\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version 0.3.2\r\n- PyTorch Version 1.1.0\r\n- Ubuntu 18.04\r\n\r\n## Additional context\r\nI have uploaded the full example on this repo: https://github.com/tadejkrivec/Maglev-GpyTorch/blob/master/Maglev_simple_example.ipynb\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/703/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/703/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/701", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/701/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/701/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/701/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/701", "id": 446299893, "node_id": "MDU6SXNzdWU0NDYyOTk4OTM=", "number": 701, "title": "[Bug] How to debug memory issues with multi-GPU", "user": {"login": "ktran9891", "id": 24300942, "node_id": "MDQ6VXNlcjI0MzAwOTQy", "avatar_url": "https://avatars.githubusercontent.com/u/24300942?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ktran9891", "html_url": "https://github.com/ktran9891", "followers_url": "https://api.github.com/users/ktran9891/followers", "following_url": "https://api.github.com/users/ktran9891/following{/other_user}", "gists_url": "https://api.github.com/users/ktran9891/gists{/gist_id}", "starred_url": "https://api.github.com/users/ktran9891/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ktran9891/subscriptions", "organizations_url": "https://api.github.com/users/ktran9891/orgs", "repos_url": "https://api.github.com/users/ktran9891/repos", "events_url": "https://api.github.com/users/ktran9891/events{/privacy}", "received_events_url": "https://api.github.com/users/ktran9891/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-05-20T20:38:40Z", "updated_at": "2019-05-22T17:51:36Z", "closed_at": "2019-05-22T17:49:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\nI am trying to run the [example notebook](https://github.com/cornellius-gp/gpytorch/blob/master/examples/01_Simple_GP_Regression/Simple_MultiGPU_GP_Regression.ipynb) for multi-GPU regression, but I am running out of memory during the prediction stage. Everything is very well-wrapped, which ironically makes this harder for me to debug.\r\n\r\n## To reproduce\r\n```\r\n# Get into evaluation (predictive posterior) mode\r\nmodel.eval()\r\nlikelihood.eval()\r\n\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    latent_pred = model(test_x)\r\n```\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-8-f87329a69cc1> in <module>\r\n      4 \r\n      5 with torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n----> 6     latent_pred = model(test_x)\r\n\r\n~/miniconda3/envs/gpytorch/lib/python3.7/site-packages/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)\r\n    263             # Make the prediction\r\n    264             with settings._use_eval_tolerance():\r\n--> 265                 predictive_mean, predictive_covar = self.prediction_strategy.exact_prediction(full_mean, full_covar)\r\n    266 \r\n    267             # Reshape predictive mean to match the appropriate event shape\r\n\r\n~/miniconda3/envs/gpytorch/lib/python3.7/site-packages/gpytorch/models/exact_prediction_strategies.py in exact_prediction(self, joint_mean, joint_covar)\r\n    262 \r\n    263         return (\r\n--> 264             self.exact_predictive_mean(test_mean, test_train_covar),\r\n    265             self.exact_predictive_covar(test_test_covar, test_train_covar),\r\n    266         )\r\n\r\n~/miniconda3/envs/gpytorch/lib/python3.7/site-packages/gpytorch/models/exact_prediction_strategies.py in exact_predictive_mean(self, test_mean, test_train_covar)\r\n    279         # For efficiency - we can use addmv in the 2d case\r\n    280         if test_train_covar.dim() == 2:\r\n--> 281             res = torch.addmv(test_mean, delazify(test_train_covar), self.mean_cache)\r\n    282         # In other cases - we'll use the standard infrastructure\r\n    283         else:\r\n\r\n~/miniconda3/envs/gpytorch/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in delazify(obj)\r\n   1745         return obj\r\n   1746     elif isinstance(obj, LazyTensor):\r\n-> 1747         return obj.evaluate()\r\n   1748     else:\r\n   1749         raise TypeError(\"object of class {} cannot be made into a Tensor\".format(obj.__class__.__name__))\r\n\r\n~/miniconda3/envs/gpytorch/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36 \r\n\r\n~/miniconda3/envs/gpytorch/lib/python3.7/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate(self)\r\n    284     @cached\r\n    285     def evaluate(self):\r\n--> 286         return self.evaluate_kernel().evaluate()\r\n    287 \r\n    288     def ndimension(self):\r\n\r\n~/miniconda3/envs/gpytorch/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36 \r\n\r\n~/miniconda3/envs/gpytorch/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in evaluate(self)\r\n    850             eye = torch.eye(num_rows, dtype=self.dtype, device=self.device)\r\n    851             eye = eye.expand(*self.batch_shape, num_rows, num_rows)\r\n--> 852             res = self.transpose(-1, -2).matmul(eye).transpose(-1, -2).contiguous()\r\n    853         else:\r\n    854             eye = torch.eye(num_cols, dtype=self.dtype, device=self.device)\r\n\r\n~/miniconda3/envs/gpytorch/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in matmul(self, other)\r\n   1085 \r\n   1086         func = Matmul(self.representation_tree())\r\n-> 1087         return func(other, *self.representation())\r\n   1088 \r\n   1089     @property\r\n\r\n~/miniconda3/envs/gpytorch/lib/python3.7/site-packages/gpytorch/functions/_matmul.py in forward(self, rhs, *matrix_args)\r\n     19 \r\n     20         lazy_tsr = self.representation_tree(*matrix_args)\r\n---> 21         res = lazy_tsr._matmul(rhs)\r\n     22 \r\n     23         to_save = [orig_rhs] + list(matrix_args)\r\n\r\n~/miniconda3/envs/gpytorch/lib/python3.7/site-packages/gpytorch/lazy/cat_lazy_tensor.py in _matmul(self, rhs)\r\n    254             # copy result back to output device\r\n    255             res_list = [x.to(output_device) for x in res_list]\r\n--> 256             res = torch.sum(torch.stack(res_list), dim=0)\r\n    257         else:\r\n    258             output_shape = _matmul_broadcast_shape(self.shape, rhs.shape)\r\n\r\nRuntimeError: CUDA out of memory. Tried to allocate 2.49 GiB (GPU 0; 11.75 GiB total capacity; 4.18 GiB already allocated; 1.74 GiB free; 382.00 MiB cached)\r\n```\r\n\r\n## Expected Behavior\r\nCreation and assignment of `latent_pred` object\r\n\r\n## System information\r\n- gpytorch=0.3.2\r\n- pytorch=1.1.0\r\n- OS=Ubuntu 18.04.2\r\n\r\n## Additional context\r\nI am guessing that I should be allocating less GPU memory, but I am not sure how to do that. I should also note that my training finished in only 4 iterations, not 14 (as per the output of the example).", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/701/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/701/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/699", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/699/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/699/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/699/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/699", "id": 445749966, "node_id": "MDU6SXNzdWU0NDU3NDk5NjY=", "number": 699, "title": "[Bug] `Interval.check` doesn't check for device compatibility before comparison", "user": {"login": "samuelstanton", "id": 22999782, "node_id": "MDQ6VXNlcjIyOTk5Nzgy", "avatar_url": "https://avatars.githubusercontent.com/u/22999782?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samuelstanton", "html_url": "https://github.com/samuelstanton", "followers_url": "https://api.github.com/users/samuelstanton/followers", "following_url": "https://api.github.com/users/samuelstanton/following{/other_user}", "gists_url": "https://api.github.com/users/samuelstanton/gists{/gist_id}", "starred_url": "https://api.github.com/users/samuelstanton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samuelstanton/subscriptions", "organizations_url": "https://api.github.com/users/samuelstanton/orgs", "repos_url": "https://api.github.com/users/samuelstanton/repos", "events_url": "https://api.github.com/users/samuelstanton/events{/privacy}", "received_events_url": "https://api.github.com/users/samuelstanton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-18T20:09:41Z", "updated_at": "2019-06-06T01:16:49Z", "closed_at": "2019-06-06T01:16:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nIn `Interval.check` and `Interval.check_raw` if `tensor` is on a different device than `self.upper_bound` then the check fails. This use case can occur when initializing GP hypers from data on a GPU. \r\n\r\n## To reproduce\r\n```\r\nimport torch\r\nimport gpytorch\r\n\r\nclass CustomGP(gpytorch.models.ExactGP):\r\n    def __init__(self, inputs, targets, likelihood):\r\n        super().__init__(inputs, targets, likelihood)\r\n        self.likelihood.initialize(noise=targets.var())\r\n\r\nnew_device = torch.device('cuda:0')\r\ntrain_x = torch.rand(30, device=new_device)\r\ntrain_y = torch.rand(30, device=new_device)\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n\r\ngp = CustomGP(train_x, train_y, likelihood).to(new_device)\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-1-82fa0692855f> in <module>()\r\n     12 likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n     13 \r\n---> 14 gp = CustomGP(train_x, train_y, likelihood).to(new_device)\r\n\r\n<ipython-input-1-82fa0692855f> in __init__(self, inputs, targets, likelihood)\r\n      5     def __init__(self, inputs, targets, likelihood):\r\n      6         super().__init__(inputs, targets, likelihood)\r\n----> 7         self.likelihood.initialize(noise=targets.var())\r\n      8 \r\n      9 new_device = torch.device('cuda:0')\r\n\r\n~/Code/gpytorch/gpytorch/module.py in initialize(self, **kwargs)\r\n     76                 raise AttributeError(\"Unknown parameter {p} for {c}\".format(p=name, c=self.__class__.__name__))\r\n     77             elif name not in self._parameters and name not in self._buffers:\r\n---> 78                 setattr(self, name, val)\r\n     79             elif torch.is_tensor(val):\r\n     80                 constraint = self.constraint_for_parameter_name(name)\r\n\r\n~/anaconda3/envs/minerva/lib/python3.7/site-packages/torch/nn/modules/module.py in __setattr__(self, name, value)\r\n    581                     buffers[name] = value\r\n    582                 else:\r\n--> 583                     object.__setattr__(self, name, value)\r\n    584 \r\n    585     def __delattr__(self, name):\r\n\r\n~/Code/gpytorch/gpytorch/likelihoods/gaussian_likelihood.py in noise(self, value)\r\n     68     @noise.setter\r\n     69     def noise(self, value: Tensor) -> None:\r\n---> 70         self.noise_covar.initialize(noise=value)\r\n     71 \r\n     72     @property\r\n\r\n~/Code/gpytorch/gpytorch/module.py in initialize(self, **kwargs)\r\n     76                 raise AttributeError(\"Unknown parameter {p} for {c}\".format(p=name, c=self.__class__.__name__))\r\n     77             elif name not in self._parameters and name not in self._buffers:\r\n---> 78                 setattr(self, name, val)\r\n     79             elif torch.is_tensor(val):\r\n     80                 constraint = self.constraint_for_parameter_name(name)\r\n\r\n~/anaconda3/envs/minerva/lib/python3.7/site-packages/torch/nn/modules/module.py in __setattr__(self, name, value)\r\n    581                     buffers[name] = value\r\n    582                 else:\r\n--> 583                     object.__setattr__(self, name, value)\r\n    584 \r\n    585     def __delattr__(self, name):\r\n\r\n~/Code/gpytorch/gpytorch/likelihoods/noise_models.py in noise(self, value)\r\n     49     @noise.setter\r\n     50     def noise(self, value: Tensor) -> None:\r\n---> 51         self._set_noise(value)\r\n     52 \r\n     53     def _set_noise(self, value: Tensor) -> None:\r\n\r\n~/Code/gpytorch/gpytorch/likelihoods/noise_models.py in _set_noise(self, value)\r\n     54         if not torch.is_tensor(value):\r\n     55             value = torch.as_tensor(value).to(self.raw_noise)\r\n---> 56         self.initialize(raw_noise=self.raw_noise_constraint.inverse_transform(value))\r\n     57 \r\n     58     def forward(\r\n\r\n~/Code/gpytorch/gpytorch/module.py in initialize(self, **kwargs)\r\n     79             elif torch.is_tensor(val):\r\n     80                 constraint = self.constraint_for_parameter_name(name)\r\n---> 81                 if constraint is not None and not constraint.check_raw(val):\r\n     82                     raise RuntimeError(\r\n     83                         \"Attempting to manually set a parameter value that is out of bounds of \"\r\n\r\n~/Code/gpytorch/gpytorch/constraints/constraints.py in check_raw(self, tensor)\r\n     51     def check_raw(self, tensor):\r\n     52         return bool(\r\n---> 53             torch.all((self.transform(tensor) <= self.upper_bound))\r\n     54             and torch.all(self.transform(tensor) >= self.lower_bound)\r\n     55         )\r\n\r\nRuntimeError: Expected object of backend CUDA but got backend CPU for argument #2 'other'\r\n```\r\n\r\n## Expected Behavior\r\n\r\nThis code snippet should simply create an instance of `CustomGP` and then make sure everything is on the GPU.\r\n\r\n## System information\r\n-  GPyTorch Version: 0.3.2\r\n-  PyTorch Version: 1.1.0.dev20190516\r\n-  Ubuntu 16.04 LTS\r\n\r\n## Additional context\r\nI have a patch branch that compares `tensor` to `self.upper_bound.to(tensor.device)` I can do a quick pull request if that is an acceptable fix\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/699/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/699/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/691", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/691/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/691/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/691/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/691", "id": 442470886, "node_id": "MDU6SXNzdWU0NDI0NzA4ODY=", "number": 691, "title": "[Question] How to properly use `SpectralMistureKernel`?", "user": {"login": "scigeek72", "id": 7228135, "node_id": "MDQ6VXNlcjcyMjgxMzU=", "avatar_url": "https://avatars.githubusercontent.com/u/7228135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scigeek72", "html_url": "https://github.com/scigeek72", "followers_url": "https://api.github.com/users/scigeek72/followers", "following_url": "https://api.github.com/users/scigeek72/following{/other_user}", "gists_url": "https://api.github.com/users/scigeek72/gists{/gist_id}", "starred_url": "https://api.github.com/users/scigeek72/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scigeek72/subscriptions", "organizations_url": "https://api.github.com/users/scigeek72/orgs", "repos_url": "https://api.github.com/users/scigeek72/repos", "events_url": "https://api.github.com/users/scigeek72/events{/privacy}", "received_events_url": "https://api.github.com/users/scigeek72/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-09T23:03:45Z", "updated_at": "2019-05-10T02:31:10Z", "closed_at": "2019-05-10T02:31:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "#  Question\r\nI am trying to see if I can use the `SpectralMixtureKernel`.  Since I am still in the learning phase, I am trying out different kernels to get an idea of how all these works. To this end, I am again using the code block for Simple Regression Tutorial, but instead of RBFKernel, I am using SpectralMixtureKernel with appropriate parameter values. According to the documentation, I must have `ard_dum_dim` set to `d` if my input matrix has dimension `n x d`. However, when I do that, even with the code snippet provided (with input dim=5), I am getting the following error:\r\n\r\n```\r\ncovar_module(x)\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-178-e698b2d55a0e>\", line 1, in <module>\r\n    covar_module(x)\r\n\r\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/kernels/kernel.py\", line 430, in __call__\r\n    \"(based on the ard_num_dims argument). Got {}.\".format(self.ard_num_dims, x1_.size(-1))\r\n\r\nRuntimeError: Expected the input to have 1 dimensionality (based on the ard_num_dims argument). Got 5.\r\n```\r\nWhere the code snippet is:\r\n\r\n```\r\nx = torch.randn(10,5)\r\ncovar_module = gpytorch.kernels.SpectralMixtureKernel(num_mixture=4, ard_dum_dim = 5)\r\n\r\n```\r\n\r\nAny suggestions?\r\nThanks. \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/691/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/691/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/684", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/684/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/684/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/684/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/684", "id": 441858992, "node_id": "MDU6SXNzdWU0NDE4NTg5OTI=", "number": 684, "title": "[Bug] ", "user": {"login": "scigeek72", "id": 7228135, "node_id": "MDQ6VXNlcjcyMjgxMzU=", "avatar_url": "https://avatars.githubusercontent.com/u/7228135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scigeek72", "html_url": "https://github.com/scigeek72", "followers_url": "https://api.github.com/users/scigeek72/followers", "following_url": "https://api.github.com/users/scigeek72/following{/other_user}", "gists_url": "https://api.github.com/users/scigeek72/gists{/gist_id}", "starred_url": "https://api.github.com/users/scigeek72/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scigeek72/subscriptions", "organizations_url": "https://api.github.com/users/scigeek72/orgs", "repos_url": "https://api.github.com/users/scigeek72/repos", "events_url": "https://api.github.com/users/scigeek72/events{/privacy}", "received_events_url": "https://api.github.com/users/scigeek72/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-08T18:02:47Z", "updated_at": "2019-05-09T20:57:19Z", "closed_at": "2019-05-09T20:57:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nwhile replicating the simple gp regression tutorial, I am getting the following error: `AttributeError: module 'numpy.polynomial' has no attribute 'hermite'`. Below is the full code and the trace of the error.\r\n\r\nCode\r\n\r\n`likelihood = gpytorch.likelihoods.GaussianLikelihood()`\r\n\r\nTrace\r\n\r\n```\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-120-8d8331bb886d>\", line 1, in <module>\r\n    likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n\r\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/likelihoods/gaussian_likelihood.py\", line 62, in __init__\r\n    super().__init__(noise_covar=noise_covar)\r\n\r\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/likelihoods/gaussian_likelihood.py\", line 24, in __init__\r\n    super().__init__()\r\n\r\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/likelihoods/likelihood.py\", line 48, in __init__\r\n    self.quadrature = GaussHermiteQuadrature1D()\r\n\r\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/utils/quadrature.py\", line 24, in __init__\r\n    locations, weights = self._locs_and_weights(num_locs)\r\n\r\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/utils/quadrature.py\", line 41, in _locs_and_weights\r\n    locations, weights = np.polynomial.hermite.hermgauss(num_locs)\r\n\r\nAttributeError: module 'numpy.polynomial' has no attribute 'hermite'\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/684/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/684/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/679", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/679/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/679/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/679/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/679", "id": 440790848, "node_id": "MDU6SXNzdWU0NDA3OTA4NDg=", "number": 679, "title": "[Bug] MLL bug when batch size = 1", "user": {"login": "KeAWang", "id": 11478740, "node_id": "MDQ6VXNlcjExNDc4NzQw", "avatar_url": "https://avatars.githubusercontent.com/u/11478740?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KeAWang", "html_url": "https://github.com/KeAWang", "followers_url": "https://api.github.com/users/KeAWang/followers", "following_url": "https://api.github.com/users/KeAWang/following{/other_user}", "gists_url": "https://api.github.com/users/KeAWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/KeAWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KeAWang/subscriptions", "organizations_url": "https://api.github.com/users/KeAWang/orgs", "repos_url": "https://api.github.com/users/KeAWang/repos", "events_url": "https://api.github.com/users/KeAWang/events{/privacy}", "received_events_url": "https://api.github.com/users/KeAWang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-06T16:54:28Z", "updated_at": "2019-05-06T17:58:48Z", "closed_at": "2019-05-06T17:03:41Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen using training data of the shape `N x 1`, the `ExactMarginalLogLikelihood` does not return a scalar.  \r\n\r\n## To reproduce\r\n\r\nJust need to unsqueeze the last dimension in the Simple GP regression example\r\n```python\r\nimport math\r\nimport torch\r\nimport gpytorch\r\n\r\n# unsqueeze to make data N x 1 instead of N\r\ntrain_x = torch.linspace(0, 1, 100).unsqueeze(-1)\r\ntrain_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2\r\n\r\nfrom IPython.core.debugger import set_trace\r\n# We will use the simplest form of GP model, exact inference\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n    \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n# initialize likelihood and model\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n\r\nmodel.train()\r\nlikelihood.train()\r\noutput = model(train_x)\r\n\r\nloss = -mll(output, train_y)\r\n\r\n# this will complain because now loss is of size N instead of a scalar\r\nloss.backward()\r\n\r\n```\r\n\r\n** Stack trace/error message **\r\n```\r\nRuntimeError: grad can be implicitly created only for scalar outputs\r\n```\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- <!-- GPyTorch Version (run `print(gpytorch.__version__)` --> 0.3.2\r\n- <!-- PyTorch Version (run `print(torch.__version__)` --> '1.1.0.dev20190506'\r\n- <!-- Computer OS --> Arch Linux", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/679/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/679/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/675", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/675/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/675/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/675/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/675", "id": 440238680, "node_id": "MDU6SXNzdWU0NDAyMzg2ODA=", "number": 675, "title": "[Bug] In grid creation?", "user": {"login": "KeAWang", "id": 11478740, "node_id": "MDQ6VXNlcjExNDc4NzQw", "avatar_url": "https://avatars.githubusercontent.com/u/11478740?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KeAWang", "html_url": "https://github.com/KeAWang", "followers_url": "https://api.github.com/users/KeAWang/followers", "following_url": "https://api.github.com/users/KeAWang/following{/other_user}", "gists_url": "https://api.github.com/users/KeAWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/KeAWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KeAWang/subscriptions", "organizations_url": "https://api.github.com/users/KeAWang/orgs", "repos_url": "https://api.github.com/users/KeAWang/repos", "events_url": "https://api.github.com/users/KeAWang/events{/privacy}", "received_events_url": "https://api.github.com/users/KeAWang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-03T22:01:48Z", "updated_at": "2019-05-03T22:31:32Z", "closed_at": "2019-05-03T22:31:32Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nGrid creation in the repo exceeds the grid bounds. Example: https://github.com/cornellius-gp/gpytorch/blob/db889f1eaa1be3206e57f5a1494ef3fb7f2e3524/test/examples/test_grid_gp_regression.py#L65 and https://github.com/cornellius-gp/gpytorch/blob/5411c905b778280122e2524fc4aafd13cdc7270d/gpytorch/variational/grid_interpolation_variational_strategy.py#L15\r\n\r\n## To reproduce\r\n\r\nCopying the code from the test case, we have \r\n```\r\nimport torch\r\nnum_dim=1\r\ngrid_bounds = [(0, 1)] if num_dim == 1 else [(0, 1), (0, 2)]\r\ngrid_size = 25\r\ngrid = torch.zeros(grid_size, len(grid_bounds))\r\nfor i in range(len(grid_bounds)):\r\n    grid_diff = float(grid_bounds[i][1] - grid_bounds[i][0]) / (grid_size - 2)\r\n    grid[:, i] = torch.linspace(\r\n        grid_bounds[i][0] - grid_diff, grid_bounds[i][1] + grid_diff, grid_size\r\n    )\r\n```\r\nwhich returns the grid \r\n```\r\ntensor([[-0.0435],\r\n        [ 0.0018],\r\n        [ 0.0471],\r\n        [ 0.0924],\r\n        [ 0.1377],\r\n        [ 0.1830],\r\n        [ 0.2283],\r\n        [ 0.2736],\r\n        [ 0.3188],\r\n        [ 0.3641],\r\n        [ 0.4094],\r\n        [ 0.4547],\r\n        [ 0.5000],\r\n        [ 0.5453],\r\n        [ 0.5906],\r\n        [ 0.6359],\r\n        [ 0.6812],\r\n        [ 0.7264],\r\n        [ 0.7717],\r\n        [ 0.8170],\r\n        [ 0.8623],\r\n        [ 0.9076],\r\n        [ 0.9529],\r\n        [ 0.9982],\r\n        [ 1.0435]])\r\n```\r\nwhich clearly exceeds the `grid_bounds`.\r\n\r\n## Expected Behavior\r\n\r\nI believe this should return a grid with all the points within the `grid_bounds`. This can be done by doing \r\n```\r\ntorch.linspace(\r\n        grid_bounds[i][0] - grid_diff, grid_bounds[i][1] + grid_diff, grid_size\r\n    )\r\n```\r\nor\r\n```\r\ntorch.linspace(\r\n        grid_bounds[i][0], grid_bounds[i][1], grid_size\r\n    )\r\n```\r\ninstead. ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/675/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/675/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/672", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/672/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/672/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/672/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/672", "id": 438866353, "node_id": "MDU6SXNzdWU0Mzg4NjYzNTM=", "number": 672, "title": "[Question]", "user": {"login": "Sabina321", "id": 2503234, "node_id": "MDQ6VXNlcjI1MDMyMzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/2503234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Sabina321", "html_url": "https://github.com/Sabina321", "followers_url": "https://api.github.com/users/Sabina321/followers", "following_url": "https://api.github.com/users/Sabina321/following{/other_user}", "gists_url": "https://api.github.com/users/Sabina321/gists{/gist_id}", "starred_url": "https://api.github.com/users/Sabina321/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Sabina321/subscriptions", "organizations_url": "https://api.github.com/users/Sabina321/orgs", "repos_url": "https://api.github.com/users/Sabina321/repos", "events_url": "https://api.github.com/users/Sabina321/events{/privacy}", "received_events_url": "https://api.github.com/users/Sabina321/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-04-30T16:27:22Z", "updated_at": "2019-11-12T20:31:30Z", "closed_at": "2019-11-12T20:31:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, \r\n\r\nWhen optimizing the custom kernel mentioned in  an earlier post, I am having some stability issues. These issues don't seem to come up when using GPy. However, here, I often get an error after only a few iterations of training. When I reduce the learning rate I can get rid of the error but then the parameters are not really learned, the final values are very close to the initialized values.  Also, if instead of placing constraints on the parameters I put priors on them, training can run for more iterations. Are there any tips to make the process more stable? ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/672/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/672/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/669", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/669/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/669/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/669/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/669", "id": 437978023, "node_id": "MDExOlB1bGxSZXF1ZXN0Mjc0MTI5MDY1", "number": 669, "title": "Variational fixes", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-04-27T19:51:02Z", "updated_at": "2019-04-27T20:40:08Z", "closed_at": "2019-04-27T20:40:05Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/669", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/669", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/669.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/669.patch", "merged_at": "2019-04-27T20:40:05Z"}, "body": "Several fixes:\r\n- Fixes an issue with Pyro likelihoods\r\n- Fix issue with preconditioner=0\r\n- Cache prior distribution so we're not recomputing it", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/669/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/669/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/662", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/662/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/662/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/662/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/662", "id": 436213132, "node_id": "MDU6SXNzdWU0MzYyMTMxMzI=", "number": 662, "title": "[Bug] pip install installs torch stable if torch nightlies are present", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-23T14:16:15Z", "updated_at": "2019-04-25T16:36:06Z", "closed_at": "2019-04-25T16:36:06Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Installing nightlies first and then installing gpytorch reverts torch to latest stable:\r\n```\r\npip install -q torch_nightly -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\r\npip install -q git+https://github.com/cornellius-gp/gpytorch.git\r\ntorch.__version__  # 1.0.1.post2\r\n```\r\n\r\nInstalling gpytorch first and then installing nightlies works properly:\r\n```\r\npip install -q git+https://github.com/cornellius-gp/gpytorch.git\r\npip install -q torch_nightly -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\r\ntorch.__version__  # 1.1.0.dev20190423\r\n```\r\n\r\nTaking a step back, we do all this version parsing magic in setup.py [here](https://github.com/cornellius-gp/gpytorch/blob/master/setup.py#L30-L46).\r\nNot really sure why this is necessary, can't we just require this to be `\"torch>=1.0.1\"`? Or is there some issue with the package naming?\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/662/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/662/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/655", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/655/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/655/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/655/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/655", "id": 435514625, "node_id": "MDU6SXNzdWU0MzU1MTQ2MjU=", "number": 655, "title": "ValueError: NonLazyTensor expects a matrix (or batches of matrices) - got a Tensor of size torch.Size([50]).", "user": {"login": "lmao14", "id": 17412680, "node_id": "MDQ6VXNlcjE3NDEyNjgw", "avatar_url": "https://avatars.githubusercontent.com/u/17412680?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lmao14", "html_url": "https://github.com/lmao14", "followers_url": "https://api.github.com/users/lmao14/followers", "following_url": "https://api.github.com/users/lmao14/following{/other_user}", "gists_url": "https://api.github.com/users/lmao14/gists{/gist_id}", "starred_url": "https://api.github.com/users/lmao14/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lmao14/subscriptions", "organizations_url": "https://api.github.com/users/lmao14/orgs", "repos_url": "https://api.github.com/users/lmao14/repos", "events_url": "https://api.github.com/users/lmao14/events{/privacy}", "received_events_url": "https://api.github.com/users/lmao14/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-21T14:23:45Z", "updated_at": "2019-04-22T13:09:48Z", "closed_at": "2019-04-22T13:09:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nHi,\r\nI encounter an error when running SVGP with an additive kernel, which did not happen to me when using gpytorch 0.2.1.\r\n```\r\n~/anaconda3/envs/gpytorch2/lib/python3.6/site-packages/gpytorch/variational/whitened_variational_strategy.py in forward(self, x)\r\n    188 \r\n    189             if self.training:\r\n--> 190                 data_covariance = DiagLazyTensor((data_data_covar.diag() - interp_data_data_var).clamp(0, math.inf))\r\n    191             else:\r\n    192                 neg_induc_data_data_covar = induc_induc_covar.inv_matmul(\r\n```\r\n\r\n** Code snippet to reproduce **\r\n```python\r\nclass SVGPRegressionModel(gpytorch.models.AbstractVariationalGP):\r\n    def __init__(self, inducing_points):\r\n        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(10)\r\n        variational_strategy = gpytorch.variational.WhitenedVariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\r\n        super(SVGPRegressionModel, self).__init__(variational_strategy)\r\n        self.mean_module = gpytorch.means.ZeroMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel() + gpytorch.kernels.MaternKernel(nu=2.5))\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nx = torch.randn(50, 2)\r\nz = torch.randn(10, 2)\r\nmodel = SVGPRegressionModel(z)\r\noutput = model(x)\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/655/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/655/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/639", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/639/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/639/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/639/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/639", "id": 432317957, "node_id": "MDU6SXNzdWU0MzIzMTc5NTc=", "number": 639, "title": "[Bug] ScaleKernel shape issue when evaluating independent batch GP on multi-batch test points", "user": {"login": "sdaulton", "id": 8037929, "node_id": "MDQ6VXNlcjgwMzc5Mjk=", "avatar_url": "https://avatars.githubusercontent.com/u/8037929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sdaulton", "html_url": "https://github.com/sdaulton", "followers_url": "https://api.github.com/users/sdaulton/followers", "following_url": "https://api.github.com/users/sdaulton/following{/other_user}", "gists_url": "https://api.github.com/users/sdaulton/gists{/gist_id}", "starred_url": "https://api.github.com/users/sdaulton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sdaulton/subscriptions", "organizations_url": "https://api.github.com/users/sdaulton/orgs", "repos_url": "https://api.github.com/users/sdaulton/repos", "events_url": "https://api.github.com/users/sdaulton/events{/privacy}", "received_events_url": "https://api.github.com/users/sdaulton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-04-11T23:30:18Z", "updated_at": "2019-04-11T23:34:22Z", "closed_at": "2019-04-11T23:34:22Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nOutputscales in ScaleKernel are not expanded properly for when evaluating a batch mode (`b`) GP with independent hyperparameters for each batch on a multi-batch set of test points (`b' x b x n x d`) .\r\n\r\n## To reproduce\r\n\r\n[Simple_GP_Regression_outputscale_batch_issue.ipynb.txt](https://github.com/cornellius-gp/gpytorch/files/3070978/Simple_GP_Regression_outputscale_batch_issue.ipynb.txt)\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/639/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/639/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/635", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/635/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/635/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/635/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/635", "id": 431722726, "node_id": "MDU6SXNzdWU0MzE3MjI3MjY=", "number": 635, "title": "[Bug] Negative variances when using fast_pred_var()", "user": {"login": "danielrjiang", "id": 18407088, "node_id": "MDQ6VXNlcjE4NDA3MDg4", "avatar_url": "https://avatars.githubusercontent.com/u/18407088?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danielrjiang", "html_url": "https://github.com/danielrjiang", "followers_url": "https://api.github.com/users/danielrjiang/followers", "following_url": "https://api.github.com/users/danielrjiang/following{/other_user}", "gists_url": "https://api.github.com/users/danielrjiang/gists{/gist_id}", "starred_url": "https://api.github.com/users/danielrjiang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danielrjiang/subscriptions", "organizations_url": "https://api.github.com/users/danielrjiang/orgs", "repos_url": "https://api.github.com/users/danielrjiang/repos", "events_url": "https://api.github.com/users/danielrjiang/events{/privacy}", "received_events_url": "https://api.github.com/users/danielrjiang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-04-10T21:24:20Z", "updated_at": "2019-04-12T18:43:43Z", "closed_at": "2019-04-12T18:43:43Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nSeeing negative variances when using fast_pred_var(). Seems to be related to cache-ing: goes away when caches are cleared by using .train().eval(). In addition, when evaluating the variance at some set of points test_x and the evaluating again at a single point in test_x, they may not match.\r\n\r\n## To reproduce\r\n\r\nSee attached notebook and the comments there.\r\n\r\n** Stack trace/error message **\r\n```\r\ntensor([ 1.0139e+00,  8.5046e-02,  8.5050e-02,  5.4592e-01,  8.5045e-02,\r\n         1.1338e+00,  2.0938e+00,  2.3304e+00,  2.3283e+00,  9.9273e-01,\r\n         9.6964e-01, -2.7103e+00, -1.7627e+02, -4.9231e+01, -9.5254e-01,\r\n         6.7344e-01,  1.1548e+00,  8.4972e-02,  1.1811e+00,  2.1131e+00])\r\n```\r\n\r\n## Expected Behavior\r\n\r\nVariances that are positive and match when evaluated in different ways.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- gpytorch 0.2.1\r\n- PyTorch 1.0.0a0\r\n- Linux release 7.5.1804\r\n\r\ncc: @Balandat \r\n[negative_variance.ipynb.txt](https://github.com/cornellius-gp/gpytorch/files/3065928/negative_variance.ipynb.txt)\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/635/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/635/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/630", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/630/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/630/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/630/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/630", "id": 430924621, "node_id": "MDExOlB1bGxSZXF1ZXN0MjY4NzA0NDkx", "number": 630, "title": "Fix setters for non-tensor initialization values", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-04-09T11:53:04Z", "updated_at": "2019-04-09T12:30:52Z", "closed_at": "2019-04-09T12:30:47Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/630", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/630", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/630.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/630.patch", "merged_at": "2019-04-09T12:30:47Z"}, "body": "Previously, if a model was on cuda or using double, these setters would error out when trying to set a value using a python float. This fixes the issue by moving the constructed tensor to the right device/dtype.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/630/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/630/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/629", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/629/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/629/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/629/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/629", "id": 430915096, "node_id": "MDU6SXNzdWU0MzA5MTUwOTY=", "number": 629, "title": "[Bug] Initialize parameters complying with constraints if transform=None", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2019-04-09T11:28:34Z", "updated_at": "2019-05-02T19:03:54Z", "closed_at": "2019-05-02T19:03:54Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nWhen passing `transform=None` into constraints, constraints are not enforced via a transform. Yet the parameter initialization in most places sets initial values to zero, disregarding the constraint. E.g. if you pass `noise_constraint=GreaterThan(1e-4, transform=None` into the `GaussianLikelihood`, then the initial value of the noise is 0. This usually results in nan errors in the first step of fitting. You can manually set the initial value to something more reasonable, but it's kind of cumbersome to have to do that manually every time when instantiating a model.\r\n\r\n## Expected Behavior\r\n\r\nIf a non-enforced constraint is present, the initial value should be chosen in compliance with the constraint in some reasonable fashion, e.g. as the mid point of an `Interval` constraint, or as 2*lower_bound for a `GreaterThan` constraint. \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/629/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/629/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/624", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/624/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/624/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/624/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/624", "id": 430313495, "node_id": "MDU6SXNzdWU0MzAzMTM0OTU=", "number": 624, "title": "Not positive definite covar while initializing variational distribution", "user": {"login": "AntixK", "id": 14088134, "node_id": "MDQ6VXNlcjE0MDg4MTM0", "avatar_url": "https://avatars.githubusercontent.com/u/14088134?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AntixK", "html_url": "https://github.com/AntixK", "followers_url": "https://api.github.com/users/AntixK/followers", "following_url": "https://api.github.com/users/AntixK/following{/other_user}", "gists_url": "https://api.github.com/users/AntixK/gists{/gist_id}", "starred_url": "https://api.github.com/users/AntixK/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AntixK/subscriptions", "organizations_url": "https://api.github.com/users/AntixK/orgs", "repos_url": "https://api.github.com/users/AntixK/repos", "events_url": "https://api.github.com/users/AntixK/events{/privacy}", "received_events_url": "https://api.github.com/users/AntixK/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-04-08T08:12:10Z", "updated_at": "2019-11-12T20:34:09Z", "closed_at": "2019-11-12T20:34:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "When running SVGP or any other custom variational GP model, I encounter this error that says the covatiance matrix of the variational distribution while initialization is not positive definite.\r\nUnlike in  #620, I have let the noise to be the default ones.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport torch\r\nimport gpytorch\r\nfrom gpytorch.models import AbstractVariationalGP\r\nfrom gpytorch.variational import CholeskyVariationalDistribution\r\nfrom gpytorch.variational import VariationalStrategy\r\nfrom gpytorch.mlls.variational_elbo import VariationalELBO\r\nfrom math import exp,pi\r\n\r\nN =  100\r\nM = 50\r\n\r\nRND_SEED = 550\r\ntorch.manual_seed(RND_SEED)\r\n\r\ntrain_x = torch.tensor([100.0000,  29.1457,  89.9497,  70.8543,  79.3970,  69.3467,  64.8241,\r\n         35.6784,  45.7286,  60.8040,  21.6080,  51.7588,  83.9196,  29.6482,\r\n         47.7387,   4.5226,  92.4623,  75.3769,  10.5528,   2.0101,  90.9548,\r\n         28.1407,  33.6683,   9.5477,  72.8643,  88.9447,  63.3166,  96.9849,\r\n          3.0151,  25.1256,  41.2060,  68.8442,  80.4020,  26.1307,  35.1759,\r\n         59.2965,  76.8844,  91.4573,  40.7035,  96.4824,  49.2462,  18.0905,\r\n         85.9296,  40.2010,  48.2412,  59.7990,  50.7538,  67.3367,  38.6935,\r\n         99.4975,  77.8895,  44.2211,  34.1709,  38.1910,   2.5126,  93.4673,\r\n         69.8492,  24.6231,  49.7487,  98.4925,  47.2362,  88.4422,  87.4372,\r\n         67.8392,  95.9799,  68.3417,  31.1558,  15.0754,  32.1608,  75.8794,\r\n         93.9698,   5.5276,  58.7940,  81.4070,  30.1508,  11.5578,  26.6332,\r\n         15.5779,  54.7739,  83.4171,  81.9095,  58.2915,  39.1960,  17.5879,\r\n         97.4874,   6.0302,  56.2814,  36.1809,   7.5377,  31.6583,  46.2312,\r\n         94.4724,  17.0854,  54.2714,  21.1055,  77.3869,  78.3920,   7.0352,\r\n         13.5678,  78.8945])\r\n\r\ntrain_y = torch.tensor([-0.5250,  2.0168, -0.9815,  0.2925,  0.3771,  0.7594,  2.2385, -1.2605,\r\n         0.7819,  0.5837,  0.3003,  0.5934,  0.3341,  0.7612, -0.4951,  0.6401,\r\n        -0.7095, -1.3961, -1.1374, -1.7018, -1.6455,  0.3058,  0.5909, -0.1134,\r\n        -1.4203, -1.2134,  1.2836, -1.7483, -0.5434,  0.4256, -0.0286, -0.0166,\r\n         1.7111,  0.8741, -1.1740,  0.7600, -1.1979, -1.6259, -0.6183, -2.0811,\r\n        -0.6157, -0.6461, -0.8148, -0.9866,  0.3464, -0.1768,  0.9389,  0.4415,\r\n        -1.4143, -0.5450, -1.9407,  0.8691,  0.1064, -1.6399, -1.6331, -0.1329,\r\n         1.1218,  0.3822,  0.8884, -0.7801, -0.5491,  0.0157,  0.4199, -0.0407,\r\n        -1.2449, -0.2507,  0.8594,  0.7633, -0.1199, -2.3864, -0.4349,  0.3531,\r\n        -0.4498,  2.4584,  0.9470, -0.6287,  0.8534,  0.2332, -1.9791,  0.6449,\r\n         3.0610,  0.4349, -1.7569, -0.3121, -1.8278,  1.2081, -0.4701, -0.9048,\r\n         0.4833,  0.9413, -0.1512, -1.3624, -0.4590, -0.8729, -0.1536, -3.0318,\r\n        -1.6477,  0.8311,  0.0656, -0.4176])\r\n\r\nclass SVGPRegressionModel(AbstractVariationalGP):\r\n    def __init__(self, inducing_points):\r\n        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(-1))\r\n        variational_strategy = VariationalStrategy(self,\r\n                                                   inducing_points,\r\n                                                   variational_distribution,\r\n                                                   learn_inducing_locations=True)\r\n        super(SVGPRegressionModel, self).__init__(variational_strategy)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n        \r\n    def forward(self,x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        latent_pred = gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n        return latent_pred\r\n\r\n\r\ninducing_points = torch.tensor([17.0854, 47.7387, 59.7990, 93.4673, 39.1960, 95.9799, 89.9497, 47.2362,\r\n         2.0101, 93.9698, 34.1709, 24.6231, 97.4874, 77.8895, 56.2814, 45.7286,\r\n        49.2462, 85.9296, 46.2312, 60.8040, 30.1508, 54.2714, 17.5879, 94.4724,\r\n        33.6683, 35.1759, 32.1608, 59.2965, 48.2412, 36.1809, 29.6482, 58.7940,\r\n        18.0905,  7.0352, 99.4975, 88.9447, 96.4824, 28.1407, 83.4171, 92.4623,\r\n        26.6332, 38.6935, 38.1910, 40.7035, 64.8241, 69.8492,  2.5126, 13.5678,\r\n        67.8392, 63.3166])\r\n\r\nmodel = SVGPRegressionModel(inducing_points)\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n\r\ndef train(model, train_x, train_y, train_steps):\r\n    model.set_train_data(train_x, train_y, strict=False)\r\n    model.train()\r\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\r\n\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\r\n\r\n    for i in range(train_steps):\r\n        optimizer.zero_grad()\r\n        output = model(train_x)\r\n        loss = -mll(output, train_y)\r\n        loss.backward()\r\n        optimizer.step()\r\n    model.eval()\r\n\r\n\r\ninducing_points = train_x[:M]\r\n\r\nmodel = SVGPRegressionModel(inducing_points)\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},\r\n    {'params': likelihood.parameters()}\r\n], lr=0.01)\r\n\r\nmll = VariationalELBO(likelihood, model, train_y.size(0), combine_terms=False)\r\n\r\ndef train():\r\n    num_iter = 200\r\n    for i in range(num_iter):\r\n        optimizer.zero_grad()\r\n        output = model(train_x)\r\n        # Calc loss and backprop gradients\r\n        log_lik, kl_div, log_prior = mll(output, train_y)\r\n        loss = -(log_lik - kl_div + log_prior)\r\n        loss.backward()\r\n        if i % 50 == 0:\r\n            print('Iter %d - Loss: %.3f [%.3f, %.3f, %.3f]' % (i + 1, loss.item(), log_lik.item(), kl_div.item(), log_prior.item()))\r\n        optimizer.step()\r\ntrain()\r\n```\r\n\r\n**Stack trace/error message**\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-1-e55cac5faeb1> in <module>\r\n    116             print('Iter %d - Loss: %.3f [%.3f, %.3f, %.3f]' % (i + 1, loss.item(), log_lik.item(), kl_div.item(), log_prior.item()))\r\n    117         optimizer.step()\r\n--> 118 train()\r\n\r\n<ipython-input-1-e55cac5faeb1> in train()\r\n    108     for i in range(num_iter):\r\n    109         optimizer.zero_grad()\r\n--> 110         output = model(train_x)\r\n    111         # Calc loss and backprop gradients\r\n    112         log_lik, kl_div, log_prior = mll(output, train_y)\r\n\r\n~\\.conda\\envs\\antixk_full\\lib\\site-packages\\gpytorch\\models\\abstract_variational_gp.py in __call__(self, inputs, **kwargs)\r\n     20             inputs = inputs.unsqueeze(-1)\r\n     21 \r\n---> 22         return self.variational_strategy(inputs)\r\n\r\n~\\.conda\\envs\\antixk_full\\lib\\site-packages\\gpytorch\\variational\\variational_strategy.py in __call__(self, x)\r\n    179 \r\n    180     def __call__(self, x):\r\n--> 181         self.initialize_variational_dist()\r\n    182         if self.training:\r\n    183             if hasattr(self, \"_memoize_cache\"):\r\n\r\n~\\.conda\\envs\\antixk_full\\lib\\site-packages\\gpytorch\\variational\\variational_strategy.py in initialize_variational_dist(self)\r\n     87             eval_prior_dist = torch.distributions.MultivariateNormal(\r\n     88                 loc=prior_dist.mean,\r\n---> 89                 covariance_matrix=psd_safe_cholesky(prior_dist.covariance_matrix),\r\n     90             )\r\n     91             self.variational_distribution.initialize_variational_distribution(eval_prior_dist)\r\n\r\n~\\.conda\\envs\\antixk_full\\lib\\site-packages\\torch\\distributions\\multivariate_normal.py in __init__(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\r\n    129             if precision_matrix is not None:\r\n    130                 self.covariance_matrix = torch.inverse(precision_matrix).expand_as(loc_)\r\n--> 131             self._unbroadcasted_scale_tril = torch.cholesky(self.covariance_matrix)\r\n    132 \r\n    133     def expand(self, batch_shape, _instance=None):\r\n\r\nRuntimeError: Lapack Error in potrf : the leading minor of order 22 is not positive definite at c:\\a\\w\\1\\s\\tmp_conda_3.6_090826\\conda\\conda-bld\\pytorch_1550394668685\\work\\aten\\src\\th\\generic/THTensorLapack.cpp:658\r\n```\r\n\r\n## System information\r\n- GpyTorch version - '0.2.1'\r\n- PyTorch version - '1.0.1'\r\n\r\n## Additional context\r\nThis seems to be dependent on the data and on the number of inducing points `M` relative to the total number of training points `N`. (In the above code, it works when `M` <22)\r\nBut How I go about resolving this issue for any given real-world data?\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/624/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/624/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/621", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/621/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/621/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/621/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/621", "id": 429893780, "node_id": "MDExOlB1bGxSZXF1ZXN0MjY3OTMyMDA5", "number": 621, "title": "Throw error when initializing parameter value to something out of bounds", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-04-05T19:02:07Z", "updated_at": "2019-04-05T22:11:18Z", "closed_at": "2019-04-05T22:11:16Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/621", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/621", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/621.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/621.patch", "merged_at": "2019-04-05T22:11:16Z"}, "body": "Right now, initializing a parameter to a value that is out of its constraint bounds silently initializes it to NaN. For example:\r\n```python\r\nlikelihood = GaussianLikelihood(noise_constraint=GreaterThan(1e-4))  # This is the default\r\nlikelihood.noise = 1e-5  # Out of bounds! Noise value is now nan with no error.\r\n```\r\n\r\nWe now throw an error with a suggestion for what to do in the likelihood case specifically, because that's the only default constraint we have that this would realistically happen for (since all other default constraints are simply `Positive()`.\r\n\r\nFixes #620 ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/621/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/621/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/620", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/620/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/620/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/620/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/620", "id": 429884869, "node_id": "MDU6SXNzdWU0Mjk4ODQ4Njk=", "number": 620, "title": "[Bug] psd_safe_cholesky less stable with small noise", "user": {"login": "neighthan", "id": 12573501, "node_id": "MDQ6VXNlcjEyNTczNTAx", "avatar_url": "https://avatars.githubusercontent.com/u/12573501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neighthan", "html_url": "https://github.com/neighthan", "followers_url": "https://api.github.com/users/neighthan/followers", "following_url": "https://api.github.com/users/neighthan/following{/other_user}", "gists_url": "https://api.github.com/users/neighthan/gists{/gist_id}", "starred_url": "https://api.github.com/users/neighthan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neighthan/subscriptions", "organizations_url": "https://api.github.com/users/neighthan/orgs", "repos_url": "https://api.github.com/users/neighthan/repos", "events_url": "https://api.github.com/users/neighthan/events{/privacy}", "received_events_url": "https://api.github.com/users/neighthan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-04-05T18:36:15Z", "updated_at": "2019-04-05T22:11:16Z", "closed_at": "2019-04-05T22:11:16Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nI'm getting errors (see below) now from `psd_safe_cholesky` which weren't there a few commits back.\r\n\r\n* Current commit has this error: 6a235fb6ec339e77a86a3cb20c715071c71ac9fc\r\n* A recent commit without this error: 308a18094d31d5cd2fbb7d942212669141dd8cec. I'm not sure what the *most* recent commit without this error is, though.\r\n\r\n## To reproduce\r\n\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\ndevice = \"cuda\"\r\n\r\ntrain_x = torch.tensor([\r\n    [-55.5527, -42.9031],\r\n    [ 63.1439, -36.1096],\r\n    [-44.4039, -51.3083],\r\n    [-37.9279,  44.9540],\r\n    [-54.8894,   1.7219],\r\n    [-26.8499, -40.2266],\r\n    [ 17.5439,  26.0574],\r\n    [-31.0171,  -2.4689],\r\n    [ 37.8813, -39.7865],\r\n    [-10.5718,  67.5785],\r\n    [ 13.2326, -45.9986],\r\n    [ 51.3409, -21.4855],\r\n    [ 64.9224, -52.7161],\r\n    [ 13.1864,  63.9087],\r\n    [-67.8713, -59.4553],\r\n    [  3.3758,  13.9108],\r\n    [ 12.1702,  35.1921],\r\n    [ 47.5776,  69.5157],\r\n    [ -7.5170,  59.2905],\r\n    [-34.0096, -51.0971],\r\n    [-43.5709,  14.1764],\r\n    [-17.3790,  57.2735],\r\n    [ 46.1217,   4.4776],\r\n    [ 17.8831,  68.3338],\r\n    [ -0.1228,  61.4203],\r\n    [ 46.7972,  27.2138],\r\n    [-35.2764, -19.0872],\r\n    [ 36.9366,  45.3593],\r\n    [-20.7411,  40.9940],\r\n    [ 16.2726, -29.3061]\r\n], device=device)\r\ntrain_y = torch.tensor([59.1276,  -53.7113,   -1.7330, -105.8712,   10.8977,  -16.1213,\r\n         -43.1551,   55.5215,   32.3309,   87.8219,    4.2356,   28.3534,\r\n         -60.4486,  115.4285,   68.5259,  -64.0631,  -12.9961,   34.0834,\r\n          61.4407,  -28.7934,  -31.1267,   18.5751,  -70.5619,  121.7277,\r\n          90.2278,   73.1477,   36.8967,   48.5388,  -68.2077,    1.3766], device=device)\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y):\r\n        likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\ndef train(model, train_x, train_y, train_steps):\r\n    model.set_train_data(train_x, train_y, strict=False)\r\n    model.train()\r\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\r\n\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\r\n\r\n    for i in range(train_steps):\r\n        optimizer.zero_grad()\r\n        output = model(train_x)\r\n        loss = -mll(output, train_y)\r\n        loss.backward()\r\n        optimizer.step()\r\n    model.eval()\r\n\r\nmodel = ExactGPModel(train_x, train_y)\r\nmodel.to(device)\r\nmodel.likelihood.initialize(noise=1e-5)\r\nmodel.likelihood.noise_covar.raw_noise.requires_grad_(False)\r\ntrain(model, train_x, train_y, train_steps=100)\r\n```\r\n\r\n## Stack traces\r\n\r\nIf `device = \"cpu\"`\"\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-5-dcd721edef0b> in <module>\r\n     73 model.likelihood.initialize(noise=1e-5)\r\n     74 model.likelihood.noise_covar.raw_noise.requires_grad_(False)\r\n---> 75 train(model, train_x, train_y, train_steps=100)\r\n\r\n<ipython-input-5-dcd721edef0b> in train(model, train_x, train_y, train_steps)\r\n     64         optimizer.zero_grad()\r\n     65         output = model(train_x)\r\n---> 66         loss = -mll(output, train_y)\r\n     67         loss.backward()\r\n     68         optimizer.step()\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     20 \r\n     21     def __call__(self, *inputs, **kwargs):\r\n---> 22         outputs = self.forward(*inputs, **kwargs)\r\n     23         if isinstance(outputs, list):\r\n     24             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, output, target, *params)\r\n     26         # Get the log prob of the marginal distribution\r\n     27         output = self.likelihood(output, *params)\r\n---> 28         res = output.log_prob(target)\r\n     29 \r\n     30         # Add terms for SGPR / when inducing points are learned\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    127 \r\n    128         # Get log determininat and first part of quadratic form\r\n--> 129         inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n    130 \r\n    131         res = -0.5 * sum([inv_quad, logdet, diff.size(-1) * math.log(2 * math.pi)])\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/lazy/lazy_tensor.py in inv_quad_logdet(self, inv_quad_rhs, logdet, reduce_inv_quad)\r\n    990             from .chol_lazy_tensor import CholLazyTensor\r\n    991 \r\n--> 992             cholesky = CholLazyTensor(self.cholesky())\r\n    993             return cholesky.inv_quad_logdet(inv_quad_rhs=inv_quad_rhs, logdet=logdet, reduce_inv_quad=reduce_inv_quad)\r\n    994 \r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/lazy/lazy_tensor.py in cholesky(self, upper)\r\n    716             (LazyTensor) Cholesky factor (lower triangular)\r\n    717         \"\"\"\r\n--> 718         res = self._cholesky()\r\n    719         if upper:\r\n    720             res = res.transpose(-1, -2)\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36 \r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/lazy/lazy_tensor.py in _cholesky(self)\r\n    401             evaluated_mat.register_hook(_ensure_symmetric_grad)\r\n    402 \r\n--> 403         cholesky = psd_safe_cholesky(evaluated_mat.double()).to(self.dtype)\r\n    404         return NonLazyTensor(cholesky)\r\n    405 \r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/utils/cholesky.py in psd_safe_cholesky(A, upper, out, jitter)\r\n     44                 continue\r\n     45 \r\n---> 46         raise e\r\n     47 \r\n     48 \r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/utils/cholesky.py in psd_safe_cholesky(A, upper, out, jitter)\r\n     19     \"\"\"\r\n     20     try:\r\n---> 21         L = torch.cholesky(A, upper=upper, out=out)\r\n     22         # TODO: Remove once fixed in pytorch (#16780)\r\n     23         if A.dim() > 2 and A.is_cuda:\r\n\r\nRuntimeError: Lapack Error in potrf : the leading minor of order 1 is not positive definite at /pytorch/aten/src/TH/generic/THTensorLapack.cpp:658\r\n```\r\n\r\nIf `device = \"cuda\"`\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-6-2b962e725013> in <module>\r\n     73 model.likelihood.initialize(noise=1e-5)\r\n     74 model.likelihood.noise_covar.raw_noise.requires_grad_(False)\r\n---> 75 train(model, train_x, train_y, train_steps=100)\r\n\r\n<ipython-input-6-2b962e725013> in train(model, train_x, train_y, train_steps)\r\n     64         optimizer.zero_grad()\r\n     65         output = model(train_x)\r\n---> 66         loss = -mll(output, train_y)\r\n     67         loss.backward()\r\n     68         optimizer.step()\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     20 \r\n     21     def __call__(self, *inputs, **kwargs):\r\n---> 22         outputs = self.forward(*inputs, **kwargs)\r\n     23         if isinstance(outputs, list):\r\n     24             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, output, target, *params)\r\n     26         # Get the log prob of the marginal distribution\r\n     27         output = self.likelihood(output, *params)\r\n---> 28         res = output.log_prob(target)\r\n     29 \r\n     30         # Add terms for SGPR / when inducing points are learned\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    127 \r\n    128         # Get log determininat and first part of quadratic form\r\n--> 129         inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n    130 \r\n    131         res = -0.5 * sum([inv_quad, logdet, diff.size(-1) * math.log(2 * math.pi)])\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/lazy/lazy_tensor.py in inv_quad_logdet(self, inv_quad_rhs, logdet, reduce_inv_quad)\r\n    990             from .chol_lazy_tensor import CholLazyTensor\r\n    991 \r\n--> 992             cholesky = CholLazyTensor(self.cholesky())\r\n    993             return cholesky.inv_quad_logdet(inv_quad_rhs=inv_quad_rhs, logdet=logdet, reduce_inv_quad=reduce_inv_quad)\r\n    994 \r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/lazy/lazy_tensor.py in cholesky(self, upper)\r\n    716             (LazyTensor) Cholesky factor (lower triangular)\r\n    717         \"\"\"\r\n--> 718         res = self._cholesky()\r\n    719         if upper:\r\n    720             res = res.transpose(-1, -2)\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     32         cache_name = name if name is not None else method\r\n     33         if not is_in_cache(self, cache_name):\r\n---> 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))\r\n     35         return get_from_cache(self, cache_name)\r\n     36 \r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/lazy/lazy_tensor.py in _cholesky(self)\r\n    401             evaluated_mat.register_hook(_ensure_symmetric_grad)\r\n    402 \r\n--> 403         cholesky = psd_safe_cholesky(evaluated_mat.double()).to(self.dtype)\r\n    404         return NonLazyTensor(cholesky)\r\n    405 \r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/utils/cholesky.py in psd_safe_cholesky(A, upper, out, jitter)\r\n     44                 continue\r\n     45 \r\n---> 46         raise e\r\n     47 \r\n     48 \r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/src/gpytorch/gpytorch/utils/cholesky.py in psd_safe_cholesky(A, upper, out, jitter)\r\n     19     \"\"\"\r\n     20     try:\r\n---> 21         L = torch.cholesky(A, upper=upper, out=out)\r\n     22         # TODO: Remove once fixed in pytorch (#16780)\r\n     23         if A.dim() > 2 and A.is_cuda:\r\n\r\nRuntimeError: MAGMA potrf : A(1,1) is 0, A cannot be factorized at /pytorch/aten/src/THC/generic/THCTensorMathMagma.cu:597\r\n```\r\n\r\n## Expected Behavior\r\n\r\nTraining is no less stable than it was at, e.g., commit 308a18094d31d5cd2fbb7d942212669141dd8cec.\r\n\r\n## System information\r\n\r\n**Please complete the following information:**\r\n- GPyTorch Version: commit 6a235fb6ec339e77a86a3cb20c715071c71ac9fc\r\n- PyTorch Version: 1.0.1.post2\r\n- OS: Ubuntu 16.04.5\r\n\r\n## Additional context\r\n\r\nRemoving the `model.likelihood` lines makes this work, so it only happens with small noise.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/620/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/620/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/619", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/619/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/619/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/619/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/619", "id": 429731804, "node_id": "MDU6SXNzdWU0Mjk3MzE4MDQ=", "number": 619, "title": "[Bug] RuntimeError: NaNs encountered matrix-vector multiplication", "user": {"login": "akaniklaus", "id": 7537828, "node_id": "MDQ6VXNlcjc1Mzc4Mjg=", "avatar_url": "https://avatars.githubusercontent.com/u/7537828?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akaniklaus", "html_url": "https://github.com/akaniklaus", "followers_url": "https://api.github.com/users/akaniklaus/followers", "following_url": "https://api.github.com/users/akaniklaus/following{/other_user}", "gists_url": "https://api.github.com/users/akaniklaus/gists{/gist_id}", "starred_url": "https://api.github.com/users/akaniklaus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akaniklaus/subscriptions", "organizations_url": "https://api.github.com/users/akaniklaus/orgs", "repos_url": "https://api.github.com/users/akaniklaus/repos", "events_url": "https://api.github.com/users/akaniklaus/events{/privacy}", "received_events_url": "https://api.github.com/users/akaniklaus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-05T12:31:25Z", "updated_at": "2019-04-05T14:00:41Z", "closed_at": "2019-04-05T14:00:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "# \ud83d\udc1b Bug\r\n\r\nRuntimeError: NaNs encountered when trying to perform matrix-vector multiplication\r\n\r\nI am receiving the above error after 12 batches of successful iterations with follows:\r\n\r\n```\r\nclass GPRegressionLayer(GP.models.AbstractVariationalGP):\r\n    def __init__(self, inducing_points):\r\n        variational_strategy = V.WhitenedVariationalStrategy(self, inducing_points,\r\n            V.CholeskyVariationalDistribution(500), learn_inducing_locations=True)\r\n        super(GPRegressionLayer, self).__init__(variational_strategy)\r\n        self.mean_module = GP.means.ConstantMean()\r\n        self.covar_module = GP.kernels.ScaleKernel(GP.kernels.RBFKernel())\r\n    def forward(self, x):\r\n        return GP.distributions.MultivariateNormal(\r\n            self.mean_module(x), self.covar_module(x))\r\n\r\nclass DKLModel(GP.Module):\r\n    def __init__(self, inducing_points, feature_extractor):\r\n        super(DKLModel, self).__init__()\r\n        self.feature_extractor = feature_extractor\r\n        self.gp_layer = GPRegressionLayer(inducing_points)\r\n    def forward(self, x):\r\n        f, q, w, e = self.feature_extractor(x)\r\n        return f[:,:-1], self.gp_layer(f[:,-1]), q, w, e\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/619/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/619/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/613", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/613/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/613/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/613/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/613", "id": 428521613, "node_id": "MDExOlB1bGxSZXF1ZXN0MjY2ODYzNjU2", "number": 613, "title": "Fix warning in psd_safe_cholesky", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-04-03T01:40:35Z", "updated_at": "2019-04-03T03:17:24Z", "closed_at": "2019-04-03T03:17:22Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/613", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/613", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/613.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/613.patch", "merged_at": "2019-04-03T03:17:22Z"}, "body": "This was never reachable due to recent changes. This makes sure it is and adds the appropriate test.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/613/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/613/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/601", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/601/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/601/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/601/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/601", "id": 427175167, "node_id": "MDExOlB1bGxSZXF1ZXN0MjY1ODYzMTA4", "number": 601, "title": "Don't run preconditioner for cholesky solves", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-29T20:57:05Z", "updated_at": "2019-03-30T18:02:35Z", "closed_at": "2019-03-30T18:02:33Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/601", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/601", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/601.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/601.patch", "merged_at": "2019-03-30T18:02:33Z"}, "body": "This is unnecessary and slow.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/601/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/601/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/599", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/599/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/599/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/599/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/599", "id": 426237883, "node_id": "MDExOlB1bGxSZXF1ZXN0MjY1MTQ0ODU1", "number": 599, "title": "Don't cache prior_dist for VI", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-28T00:16:38Z", "updated_at": "2019-03-29T16:28:01Z", "closed_at": "2019-03-29T16:27:58Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/599", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/599", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/599.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/599.patch", "merged_at": "2019-03-29T16:27:57Z"}, "body": "This causes issues with Pyro models", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/599/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/599/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/598", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/598/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/598/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/598/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/598", "id": 426088849, "node_id": "MDU6SXNzdWU0MjYwODg4NDk=", "number": 598, "title": "Error in `psd_safe_cholesky` (when data has low noise?)", "user": {"login": "neighthan", "id": 12573501, "node_id": "MDQ6VXNlcjEyNTczNTAx", "avatar_url": "https://avatars.githubusercontent.com/u/12573501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neighthan", "html_url": "https://github.com/neighthan", "followers_url": "https://api.github.com/users/neighthan/followers", "following_url": "https://api.github.com/users/neighthan/following{/other_user}", "gists_url": "https://api.github.com/users/neighthan/gists{/gist_id}", "starred_url": "https://api.github.com/users/neighthan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neighthan/subscriptions", "organizations_url": "https://api.github.com/users/neighthan/orgs", "repos_url": "https://api.github.com/users/neighthan/repos", "events_url": "https://api.github.com/users/neighthan/events{/privacy}", "received_events_url": "https://api.github.com/users/neighthan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2019-03-27T17:21:38Z", "updated_at": "2019-03-27T20:26:37Z", "closed_at": "2019-03-27T20:26:27Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "It's possible to hit the [`return L`][return] line in `psd_safe_cholesky` without `L` being defined. This happens if `torch.cholesky` throws a `RuntimeError` for both `A` and `Aprime` and `\"singular\"` is not in the error message. Then the user just gets `UnboundLocalError: local variable 'L' referenced before assignment`, which isn't very helpful. I'm not actually sure what error I got that led to this, but perhaps it would be good to change\r\n\r\n```python\r\nif \"singular\" in e.args[0]:\r\n    raise RuntimeError(\"Adding jitter of {} to the diagonal did not make A p.d.\".format(jitter))\r\n```\r\n\r\nto\r\n\r\n```python\r\nif \"singular\" in e.args[0]:\r\n    raise RuntimeError(\"Adding jitter of {} to the diagonal did not make A p.d.\".format(jitter))\r\nelse:  # or skip the else, depending on your coding style\r\n    raise\r\n```\r\n\r\nThis should give the user a more useful error message at least. Or is there anything that would be better to do in this case?\r\n\r\n[return]: https://github.com/cornellius-gp/gpytorch/blob/9a2fb2ef870bf66efc29775245b8ce6c624e45a5/gpytorch/utils/cholesky.py#L43", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/598/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/598/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/591", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/591/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/591/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/591/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/591", "id": 423909358, "node_id": "MDExOlB1bGxSZXF1ZXN0MjYzMzc4Mzcy", "number": 591, "title": "Change likelihood signature, several Pyro fixes", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 623304448, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDg=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}, {"id": 1284087572, "node_id": "MDU6TGFiZWwxMjg0MDg3NTcy", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/breaking%20change", "name": "breaking change", "color": "5319e7", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-03-21T19:42:32Z", "updated_at": "2019-03-26T23:03:43Z", "closed_at": "2019-03-26T23:03:40Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/591", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/591", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/591.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/591.patch", "merged_at": "2019-03-26T23:03:40Z"}, "body": "# Likelihood updates\r\n- [x] `Likelihood.__call__` now compute either marginal or conditional distribution\r\n  - If the input is a Tensor, it assumes that the input is samples from f(x), and computes the conditional distribution `p(y | f(x))`\r\n  - If the input is a gpytorch.distribution.MultivariateNormal, it assumes that the input is the distribution f(x), and computes the marginal distribution `p(y | x)`\r\n- [x] `Likelihood.forward` now defines the conditional likelihood distributions\r\n- [x] `Likelihood.marginal` now \r\n  - [x] Custom `marginal` definitions for Gaussian/MultitaskGaussian/Bernoulli likelihoods\r\n  - [x] Default `marginal` returns a batched distribution, where the batch represents samples from the marginal\r\n- [x] `Likelihood.expected_log_prob` is now a auto-defined function (used for variational inference)\r\n- [x] Use Pyro distributions (if available, otherwise use Torch distributions)\r\n- [x] `BernoulliLikelihood` now expects labels in {0, 1}, rather than {-1, 1}\r\n  - [x] Soft deprecation for old-style labels\r\n  - [x] Update classification tests\r\n\r\n# Pyro fixes\r\n- [x] Use `pyro.plate` for conditional independence of observations\r\n- [x] Fix `pyro_sample_y` for GaussianLikelihoods\r\n\r\n** This will be a breaking change ** for anyone who has defined a custom likelihood. However, most GPyTorch users won't notice any difference.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/591/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/591/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/582", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/582/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/582/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/582/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/582", "id": 422374760, "node_id": "MDU6SXNzdWU0MjIzNzQ3NjA=", "number": 582, "title": "Linear kernel's variance prior is broken", "user": {"login": "sdaulton", "id": 8037929, "node_id": "MDQ6VXNlcjgwMzc5Mjk=", "avatar_url": "https://avatars.githubusercontent.com/u/8037929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sdaulton", "html_url": "https://github.com/sdaulton", "followers_url": "https://api.github.com/users/sdaulton/followers", "following_url": "https://api.github.com/users/sdaulton/following{/other_user}", "gists_url": "https://api.github.com/users/sdaulton/gists{/gist_id}", "starred_url": "https://api.github.com/users/sdaulton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sdaulton/subscriptions", "organizations_url": "https://api.github.com/users/sdaulton/orgs", "repos_url": "https://api.github.com/users/sdaulton/repos", "events_url": "https://api.github.com/users/sdaulton/events{/privacy}", "received_events_url": "https://api.github.com/users/sdaulton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-18T18:39:18Z", "updated_at": "2019-03-18T23:23:22Z", "closed_at": "2019-03-18T23:23:22Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Repro: \r\n[linear_kernel_prior_issue.ipynb.txt](https://github.com/cornellius-gp/gpytorch/files/2979717/linear_kernel_prior_issue.ipynb.txt)\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/582/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/582/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/575", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/575/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/575/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/575/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/575", "id": 421840429, "node_id": "MDU6SXNzdWU0MjE4NDA0Mjk=", "number": 575, "title": "linear kernel breaks when given certain types of active_dims", "user": {"login": "Duane321", "id": 19956442, "node_id": "MDQ6VXNlcjE5OTU2NDQy", "avatar_url": "https://avatars.githubusercontent.com/u/19956442?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Duane321", "html_url": "https://github.com/Duane321", "followers_url": "https://api.github.com/users/Duane321/followers", "following_url": "https://api.github.com/users/Duane321/following{/other_user}", "gists_url": "https://api.github.com/users/Duane321/gists{/gist_id}", "starred_url": "https://api.github.com/users/Duane321/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Duane321/subscriptions", "organizations_url": "https://api.github.com/users/Duane321/orgs", "repos_url": "https://api.github.com/users/Duane321/repos", "events_url": "https://api.github.com/users/Duane321/events{/privacy}", "received_events_url": "https://api.github.com/users/Duane321/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-03-16T18:52:28Z", "updated_at": "2019-03-18T23:17:05Z", "closed_at": "2019-03-18T23:17:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey,\r\n\r\nSo the linear kernel will break with some types of given active_dims arguments. I'll lay those out here.\r\n\r\n```\r\nimport numpy as np\r\nimport gpytorch\r\nimport torch\r\ntorch.set_default_tensor_type('torch.DoubleTensor')\r\n\r\nX = np.array([range(100*10)]).reshape(-1,10)\r\nX = torch.from_numpy(X).to(torch.float64)\r\ny = torch.from_numpy(np.random.normal(size=100)).to(torch.float64)\r\n```\r\n\r\nBelow, I've commented out some active_dims which either work or don't work. \r\n\r\n```\r\nclass GP(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(GP, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n#         active_dims = list(range(1,10)) # Doesn't work!\r\n        active_dims = list(range(3,10)) # Doesn't work!\r\n#         active_dims = [0] + list(range(3,10)) # Doesn't work!\r\n#         active_dims = [0] + list(range(2,10)) # Doesn't work!\r\n#         active_dims = list(range(1)) # Works\r\n#         active_dims = list(range(2)) # Works\r\n#         active_dims = list(range(10)) # Works\r\n        self.linear_kernel = gpytorch.kernels.LinearKernel(num_dimensions=len(active_dims),\r\n                                                           active_dims=active_dims)\r\n            \r\n    def forward(self, x, requested_comp=None):\r\n        \r\n        mean_x = self.mean_module(x)\r\n        linear_kernel_x = self.linear_kernel(x)\r\n        covar_x = linear_kernel_x\r\n        \r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n```\r\n\r\nBefore I get to the error, we set up a few things:\r\n\r\n```\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nlikelihood.initialize(noise=8e-4) \r\nmodel = GP(X, y, likelihood)\r\n\r\nlearning_rate = .1\r\nmodel.train()\r\nlikelihood.train()\r\n\r\noptimizer = torch.optim.Adam([\r\n    {'params': list(model.parameters())[2:]},\r\n], lr=learning_rate)\r\n\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n```\r\nWhen we get into the optimization, it breaks:\r\n\r\n```\r\nfor i in range(100):\r\n    optimizer.zero_grad()\r\n    output = model(X)\r\n    ### Breaks on the next line! ###\r\n    loss = -mll(output, y)\r\n    loss.backward()\r\n    if not i % 30:\r\n        print('i: {0}, Loss: {1}'.format(i, loss.item()))\r\n    optimizer.step()\r\n```\r\n\r\nWith this error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-67-cb234b5fe124> in <module>\r\n     15     output = model(X)\r\n     16     # Calc loss and backprop gradients\r\n---> 17     loss = -mll(output, y)\r\n     18     loss.backward()\r\n     19     if not i % 30:\r\n\r\n~/.virtualenvs/GenRS/lib/python3.7/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     18 \r\n     19     def __call__(self, *inputs, **kwargs):\r\n---> 20         outputs = self.forward(*inputs, **kwargs)\r\n     21         if isinstance(outputs, list):\r\n     22             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n~/.virtualenvs/GenRS/lib/python3.7/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, output, target, *params)\r\n     26         # Get the log prob of the marginal distribution\r\n     27         output = self.likelihood(output, *params)\r\n---> 28         res = output.log_prob(target)\r\n     29 \r\n     30         # Add terms for SGPR / when inducing points are learned\r\n\r\n~/.virtualenvs/GenRS/lib/python3.7/site-packages/gpytorch/distributions/multivariate_normal.py in log_prob(self, value)\r\n    123 \r\n    124         # Get log determininat and first part of quadratic form\r\n--> 125         inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\r\n    126 \r\n    127         res = -0.5 * sum([inv_quad, logdet, diff.size(-1) * math.log(2 * math.pi)])\r\n\r\n~/.virtualenvs/GenRS/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in inv_quad_logdet(self, inv_quad_rhs, logdet, reduce_inv_quad)\r\n    745                 )\r\n    746 \r\n--> 747         args = self.representation()\r\n    748         if inv_quad_rhs is not None:\r\n    749             args = [inv_quad_rhs] + list(args)\r\n\r\n~/.virtualenvs/GenRS/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in representation(self)\r\n    980                 representation.append(arg)\r\n    981             elif hasattr(arg, \"representation\") and callable(arg.representation):  # Is it a LazyTensor?\r\n--> 982                 representation += list(arg.representation())\r\n    983             else:\r\n    984                 raise RuntimeError(\"Representation of a LazyTensor should consist only of Tensors\")\r\n\r\n~/.virtualenvs/GenRS/lib/python3.7/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in representation(self)\r\n    306         # representation\r\n    307         else:\r\n--> 308             return self.evaluate_kernel().representation()\r\n    309 \r\n    310     def representation_tree(self):\r\n\r\n~/.virtualenvs/GenRS/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     15         cache_name = name if name is not None else method\r\n     16         if cache_name not in self._memoize_cache:\r\n---> 17             self._memoize_cache[cache_name] = method(self, *args, **kwargs)\r\n     18         return self._memoize_cache[cache_name]\r\n     19 \r\n\r\n~/.virtualenvs/GenRS/lib/python3.7/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)\r\n    260         with settings.lazily_evaluate_kernels(False):\r\n    261             res = self.kernel(\r\n--> 262                 x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\r\n    263             )\r\n    264         if self.squeeze_row:\r\n\r\n~/.virtualenvs/GenRS/lib/python3.7/site-packages/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, batch_dims, **params)\r\n    313         # Select the active dimensions\r\n    314         if self.active_dims is not None:\r\n--> 315             x1_ = x1_.index_select(-1, self.active_dims)\r\n    316             if x2_ is not None:\r\n    317                 x2_ = x2_.index_select(-1, self.active_dims)\r\n\r\nRuntimeError: invalid argument 3: out of range at /Users/soumith/b101/2019_02_04/wheel_build_dirs/wheel_3.7/pytorch/aten/src/TH/generic/THTensor.cpp:350\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/575/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/575/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/573", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/573/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/573/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/573/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/573", "id": 421747665, "node_id": "MDU6SXNzdWU0MjE3NDc2NjU=", "number": 573, "title": "from_independent_mvns does the wrong thing in batch mode", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-03-16T00:27:04Z", "updated_at": "2019-03-19T14:58:11Z", "closed_at": "2019-03-19T14:58:11Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "The issue is that currently calling `BlockDiagLazyTensor` on `covar_blocks_lazy` results in a batched covariance matrix with wrong block ordering.\r\n\r\nThat is, if `mvn_a` and `mvn_b` are `k`-batched with covariance matrices `C_a1, ..., C_ak` and `C_b1, ..., C_bk`, respectively, then the 1st batch of the joint covariance matrix is \r\n```\r\n   | C_a1 |   0  |\r\n   | 0    | C_a2 |\r\n```\r\n\r\ninstead of\r\n```\r\n   | C_a1 |   0  |\r\n   | 0    | C_b1 |\r\n```\r\netc. \r\n\r\nNot sure if there is an elegant way to fix this in the current setting. @gpleiss, #492 should make that straightforward, right?\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/573/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/573/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/558", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/558/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/558/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/558/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/558", "id": 418921191, "node_id": "MDU6SXNzdWU0MTg5MjExOTE=", "number": 558, "title": "dimension mismatch ScaleKernel + WhiteNoiseKernel ", "user": {"login": "tohein", "id": 19325791, "node_id": "MDQ6VXNlcjE5MzI1Nzkx", "avatar_url": "https://avatars.githubusercontent.com/u/19325791?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tohein", "html_url": "https://github.com/tohein", "followers_url": "https://api.github.com/users/tohein/followers", "following_url": "https://api.github.com/users/tohein/following{/other_user}", "gists_url": "https://api.github.com/users/tohein/gists{/gist_id}", "starred_url": "https://api.github.com/users/tohein/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tohein/subscriptions", "organizations_url": "https://api.github.com/users/tohein/orgs", "repos_url": "https://api.github.com/users/tohein/repos", "events_url": "https://api.github.com/users/tohein/events{/privacy}", "received_events_url": "https://api.github.com/users/tohein/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-03-08T19:17:26Z", "updated_at": "2019-05-06T09:10:31Z", "closed_at": "2019-05-06T09:10:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey,\r\n\r\nI was trying to use a WhiteNoiseKernel with a variance parameter but ran into size mismatch problems. Example: \r\n\r\n```\r\nimport torch\r\nimport gpytorch\r\nfrom gpytorch.models import AbstractVariationalGP\r\nfrom gpytorch.variational import CholeskyVariationalDistribution\r\nfrom gpytorch.variational import VariationalStrategy\r\n\r\nclass GPClassificationModel(AbstractVariationalGP):\r\n    def __init__(self, train_x):\r\n        variational_distribution = CholeskyVariationalDistribution(train_x.size(0))\r\n        variational_strategy = VariationalStrategy(self, train_x, variational_distribution)\r\n        super(GPClassificationModel, self).__init__(variational_strategy)\r\n        self.mean_module = gpytorch.means.ZeroMean()  \r\n        self.covar_module1 = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n        self.covar_module2 = gpytorch.kernels.ScaleKernel(gpytorch.kernels.WhiteNoiseKernel(torch.ones(train_x.size(0))))\r\n        self.covar_module = self.covar_module1 + self.covar_module2\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        latent_pred = gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n        return latent_pred\r\n\r\nmodel = GPClassificationModel(train_x)\r\nlikelihood = gpytorch.likelihoods.BernoulliLikelihood()\r\n\r\ntrain_x = torch.linspace(0, 1, 100)\r\ntrain_y = torch.sign(torch.cos(train_x * (4 * math.pi)))\r\nmodel(train_x)\r\n```\r\n\r\ngives me the following error\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-19-f9c049d8537e> in <module>\r\n     21 train_x = torch.linspace(0, 1, 100)\r\n     22 train_y = torch.sign(torch.cos(train_x * (4 * math.pi)))\r\n---> 23 model(train_x)\r\n\r\n/anaconda3/envs/gpflow/lib/python3.6/site-packages/gpytorch/models/abstract_variational_gp.py in __call__(self, inputs, **kwargs)\r\n     20             inputs = inputs.unsqueeze(-1)\r\n     21 \r\n---> 22         return self.variational_strategy(inputs)\r\n\r\n/anaconda3/envs/gpflow/lib/python3.6/site-packages/gpytorch/variational/variational_strategy.py in __call__(self, x)\r\n    178 \r\n    179     def __call__(self, x):\r\n--> 180         self.initialize_variational_dist()\r\n    181         if self.training:\r\n    182             if hasattr(self, \"_memoize_cache\"):\r\n\r\n/anaconda3/envs/gpflow/lib/python3.6/site-packages/gpytorch/variational/variational_strategy.py in initialize_variational_dist(self)\r\n     83         \"\"\"\r\n     84         if not self.variational_params_initialized.item():\r\n---> 85             prior_dist = self.prior_distribution\r\n     86             eval_prior_dist = torch.distributions.MultivariateNormal(\r\n     87                 loc=prior_dist.mean,\r\n\r\n/anaconda3/envs/gpflow/lib/python3.6/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     15         cache_name = name if name is not None else method\r\n     16         if cache_name not in self._memoize_cache:\r\n---> 17             self._memoize_cache[cache_name] = method(self, *args, **kwargs)\r\n     18         return self._memoize_cache[cache_name]\r\n     19 \r\n\r\n/anaconda3/envs/gpflow/lib/python3.6/site-packages/gpytorch/variational/variational_strategy.py in prior_distribution(self)\r\n     64         out = self.model.forward(self.inducing_points)\r\n     65         res = MultivariateNormal(\r\n---> 66             out.mean, out.lazy_covariance_matrix.evaluate_kernel().add_jitter()\r\n     67         )\r\n     68         return res\r\n\r\n/anaconda3/envs/gpflow/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)\r\n    209                 and self._cached_kernel_eval.size(0) == 1\r\n    210             ):\r\n--> 211                 self._cached_kernel_eval = self._cached_kernel_eval[0]\r\n    212 \r\n    213             self._cached_kernel_eval = lazify(self._cached_kernel_eval)\r\n\r\n/anaconda3/envs/gpflow/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py in __getitem__(self, index)\r\n   1354 \r\n   1355         # Call self._getitem - now that the index has been processed\r\n-> 1356         return self._getitem(*index)\r\n   1357 \r\n   1358     def __matmul__(self, other):\r\n\r\n/anaconda3/envs/gpflow/lib/python3.6/site-packages/gpytorch/lazy/sum_lazy_tensor.py in _getitem(self, *indices)\r\n     25 \r\n     26     def _getitem(self, *indices):\r\n---> 27         results = tuple(lazy_tensor._getitem(*indices) for lazy_tensor in self.lazy_tensors)\r\n     28         if isinstance(results[0], LazyTensor):\r\n     29             return SumLazyTensor(*results)\r\n\r\n/anaconda3/envs/gpflow/lib/python3.6/site-packages/gpytorch/lazy/sum_lazy_tensor.py in <genexpr>(.0)\r\n     25 \r\n     26     def _getitem(self, *indices):\r\n---> 27         results = tuple(lazy_tensor._getitem(*indices) for lazy_tensor in self.lazy_tensors)\r\n     28         if isinstance(results[0], LazyTensor):\r\n     29             return SumLazyTensor(*results)\r\n\r\n/anaconda3/envs/gpflow/lib/python3.6/site-packages/gpytorch/lazy/constant_mul_lazy_tensor.py in _getitem(self, *indices)\r\n     85             constant = constant.view(*constant.shape, *[1] * (base_lazy_tensor.dim() - constant.dim()))\r\n     86 \r\n---> 87         return base_lazy_tensor * constant\r\n     88 \r\n     89     def _matmul(self, rhs):\r\n\r\n/anaconda3/envs/gpflow/lib/python3.6/site-packages/gpytorch/lazy/diag_lazy_tensor.py in __mul__(self, other)\r\n    102             return DiagLazyTensor(self._diag * other._diag)\r\n    103         else:\r\n--> 104             other_diag = other.diag()\r\n    105             new_diag = self._diag * other_diag\r\n    106             corrected_diag = new_diag - other_diag\r\n\r\n/anaconda3/envs/gpflow/lib/python3.6/site-packages/gpytorch/lazy/non_lazy_tensor.py in diag(self)\r\n     55     def diag(self):\r\n     56         if self.tensor.ndimension() < 3:\r\n---> 57             return self.tensor.diag()\r\n     58         else:\r\n     59             row_col_iter = torch.arange(0, self.matrix_shape[-1], dtype=torch.long, device=self.device)\r\n\r\nRuntimeError: Input must be 1-d or 2-d\r\n```\r\nAny idea what I am doing wrong here?", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/558/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/558/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/554", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/554/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/554/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/554/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/554", "id": 417949752, "node_id": "MDU6SXNzdWU0MTc5NDk3NTI=", "number": 554, "title": "Repeated posterior evaluation (and backward) with same base_samples raises second backward issue", "user": {"login": "sdaulton", "id": 8037929, "node_id": "MDQ6VXNlcjgwMzc5Mjk=", "avatar_url": "https://avatars.githubusercontent.com/u/8037929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sdaulton", "html_url": "https://github.com/sdaulton", "followers_url": "https://api.github.com/users/sdaulton/followers", "following_url": "https://api.github.com/users/sdaulton/following{/other_user}", "gists_url": "https://api.github.com/users/sdaulton/gists{/gist_id}", "starred_url": "https://api.github.com/users/sdaulton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sdaulton/subscriptions", "organizations_url": "https://api.github.com/users/sdaulton/orgs", "repos_url": "https://api.github.com/users/sdaulton/repos", "events_url": "https://api.github.com/users/sdaulton/events{/privacy}", "received_events_url": "https://api.github.com/users/sdaulton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2019-03-06T18:34:54Z", "updated_at": "2019-03-13T14:02:37Z", "closed_at": "2019-03-13T14:02:37Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "I am encountering an second backward error when doing repeated posterior evaluations with the same set of base_samples. If I use `detach_test_caches(True)` and `fast_pred_var()`, there is no issue. However, when I do not use `fast_pred_var()` and/or set `detach_test_caches(False)`, then the second backward issue is raised.\r\n\r\nRepro:\r\n[gpytorch_base_samples_caching_backward_issue.ipynb.txt](https://github.com/cornellius-gp/gpytorch/files/2937770/gpytorch_base_samples_caching_backward_issue.ipynb.txt)\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/554/reactions", "total_count": 2, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 2, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/554/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/548", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/548/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/548/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/548/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/548", "id": 417101590, "node_id": "MDU6SXNzdWU0MTcxMDE1OTA=", "number": 548, "title": "Error when using `fast_pred_var` with only 1 training input", "user": {"login": "neighthan", "id": 12573501, "node_id": "MDQ6VXNlcjEyNTczNTAx", "avatar_url": "https://avatars.githubusercontent.com/u/12573501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neighthan", "html_url": "https://github.com/neighthan", "followers_url": "https://api.github.com/users/neighthan/followers", "following_url": "https://api.github.com/users/neighthan/following{/other_user}", "gists_url": "https://api.github.com/users/neighthan/gists{/gist_id}", "starred_url": "https://api.github.com/users/neighthan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neighthan/subscriptions", "organizations_url": "https://api.github.com/users/neighthan/orgs", "repos_url": "https://api.github.com/users/neighthan/repos", "events_url": "https://api.github.com/users/neighthan/events{/privacy}", "received_events_url": "https://api.github.com/users/neighthan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1268252263, "node_id": "MDU6TGFiZWwxMjY4MjUyMjYz", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/good%20first%20issue", "name": "good first issue", "color": "f9d0c4", "default": true, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-03-05T03:40:30Z", "updated_at": "2019-03-16T15:57:26Z", "closed_at": "2019-03-16T15:57:26Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I'm getting an error when I try to use `fast_pred_var` but not when I do predictions without this setting.\r\n\r\nTo reproduce:\r\n\r\n```python\r\nimport torch\r\nimport gpytorch\r\n\r\n# from the gp regression tutorial\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nn_train = 1\r\nn_test = 100\r\nn_features = 3\r\n    \r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\ntrain_x = torch.rand(n_train, n_features)\r\ntrain_y = torch.rand(n_train)\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\n\r\nmodel.eval()\r\nmodel.likelihood.eval()\r\n\r\n# this works fine\r\nmodel(torch.rand(n_test, n_features))\r\n\r\n# this throws the error\r\nwith gpytorch.settings.fast_pred_var():\r\n    model(torch.rand(n_test, n_features))\r\n```\r\n\r\nThe error that I get is\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-1-05bfb3c2646a> in <module>\r\n     27 # this throws the error\r\n     28 with gpytorch.settings.fast_pred_var():\r\n---> 29     model(torch.rand(100, 2))\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/lib/python3.7/site-packages/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)\r\n    262 \r\n    263             predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\r\n--> 264             predictive_covar = self.prediction_strategy.exact_predictive_covar(test_test_covar, test_train_covar)\r\n    265 \r\n    266             if num_tasks > 1:\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/lib/python3.7/site-packages/gpytorch/models/exact_prediction_strategies.py in exact_predictive_covar(self, test_test_covar, test_train_covar)\r\n    324             return test_test_covar + MatmulLazyTensor(test_train_covar, covar_correction_rhs)\r\n    325 \r\n--> 326         precomputed_cache = self.covar_cache\r\n    327         covar_inv_quad_form_root = self._exact_predictive_covar_inv_quad_form_root(precomputed_cache,\r\n    328                                                                                    test_train_covar)\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     15         cache_name = name if name is not None else method\r\n     16         if cache_name not in self._memoize_cache:\r\n---> 17             self._memoize_cache[cache_name] = method(self, *args, **kwargs)\r\n     18         return self._memoize_cache[cache_name]\r\n     19 \r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/lib/python3.7/site-packages/gpytorch/models/exact_prediction_strategies.py in covar_cache(self)\r\n    265             train_train_covar_inv_root = train_train_covar[0].root_inv_decomposition().root.evaluate()\r\n    266         else:\r\n--> 267             train_train_covar_inv_root = train_train_covar.root_inv_decomposition().root.evaluate()\r\n    268 \r\n    269         return self._exact_predictive_covar_inv_quad_form_cache(train_train_covar_inv_root, self._last_test_train_covar)\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)\r\n     15         cache_name = name if name is not None else method\r\n     16         if cache_name not in self._memoize_cache:\r\n---> 17             self._memoize_cache[cache_name] = method(self, *args, **kwargs)\r\n     18         return self._memoize_cache[cache_name]\r\n     19 \r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in root_inv_decomposition(self, initial_vectors, test_vectors)\r\n   1088             inverse=True,\r\n   1089             initial_vectors=initial_vectors,\r\n-> 1090         )(*self.representation())\r\n   1091 \r\n   1092         if initial_vectors is not None and initial_vectors.size(-1) > 1:\r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/lib/python3.7/site-packages/gpytorch/functions/_root_decomposition.py in forward(self, *matrix_args)\r\n     51             matrix_shape=self.matrix_shape,\r\n     52             batch_shape=self.batch_shape,\r\n---> 53             init_vecs=self.initial_vectors,\r\n     54         )\r\n     55 \r\n\r\n~/.cache/pypoetry/virtualenvs/bayes-optim-py3.7/lib/python3.7/site-packages/gpytorch/utils/lanczos.py in lanczos_tridiag(matmul_closure, max_iter, dtype, device, matrix_shape, batch_shape, init_vecs, num_init_vecs, tol)\r\n     80     # Copy over alpha_0 and beta_0 to t_mat\r\n     81     t_mat[0, 0].copy_(alpha_0)\r\n---> 82     t_mat[0, 1].copy_(beta_0)\r\n     83     t_mat[1, 0].copy_(beta_0)\r\n     84 \r\n\r\nIndexError: index 1 is out of bounds for dimension 0 with size 1\r\n```\r\n\r\nI played with this a little bit, and it's only come up for me when I have just a single training input. For now, I just have a workaround where I make sure not to use `fast_pred_var` unless there are multiple training inputs, but it would be great if this always worked.\r\n\r\nGPytorch version: 0.2.1\r\nOS: Ubuntu 16.04\r\nPython: 3.7", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/548/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/548/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/547", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/547/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/547/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/547/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/547", "id": 416328639, "node_id": "MDExOlB1bGxSZXF1ZXN0MjU3NjIwNTUz", "number": 547, "title": "Fix batch_symeig cuda index issue", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-02T00:16:00Z", "updated_at": "2019-03-02T00:21:16Z", "closed_at": "2019-03-02T00:21:09Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/547", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/547", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/547.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/547.patch", "merged_at": "2019-03-02T00:21:09Z"}, "body": "`type_as` does not retain the cuda device index, so the output for small matrices (cpu computation) will be on the default cuda device rather than the one of the input matrix.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/547/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/547/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/545", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/545/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/545/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/545/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/545", "id": 416204639, "node_id": "MDExOlB1bGxSZXF1ZXN0MjU3NTIzOTAx", "number": 545, "title": "Fix index for get_base_samples in interleaved MTMVN", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2019-03-01T17:28:31Z", "updated_at": "2019-03-01T17:35:24Z", "closed_at": "2019-03-01T17:35:21Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/545", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/545", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/545.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/545.patch", "merged_at": "2019-03-01T17:35:21Z"}, "body": "This was overlooked in the previous fix", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/545/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/545/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/544", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/544/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/544/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/544/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/544", "id": 415928745, "node_id": "MDExOlB1bGxSZXF1ZXN0MjU3MzA5ODM5", "number": 544, "title": "More CG improvements", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-01T03:46:19Z", "updated_at": "2019-03-01T17:29:44Z", "closed_at": "2019-03-01T17:29:42Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/544", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/544", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/544.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/544.patch", "merged_at": "2019-03-01T17:29:42Z"}, "body": "- Normalize the vectors before performing solves\r\n- Rather than adding epsilon to all the divisions, does masking to prevent division by zero errors.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/544/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/544/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/537", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/537/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/537/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/537/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/537", "id": 414439231, "node_id": "MDU6SXNzdWU0MTQ0MzkyMzE=", "number": 537, "title": "Inconsistent representation of MultitaskMultivariateNormal covariance", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-02-26T05:34:42Z", "updated_at": "2019-02-26T22:17:37Z", "closed_at": "2019-02-26T22:17:37Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Consider a 2-task model with 3 points each. The shape of the joint covariance matrix `C` is `6x6`, but the current code seems to assume different structures in different places.  \r\n\r\n1. `from_independent_mvns` assumes that `C` has block structure w.r.t. the tasks, i.e. that `C = [[C_a, 0], [0, C_b]]`, where `C_a` and `C_b` are the marginal covariances across the data points of task `a` and `b`, respectively.\r\n\r\n2. `variance` and `rsample` assume that `C` has block structure w.r.t. the data points, i.e. that `C[2*i:2*(i+1), 2*i:2*(i+1)]`  is the covariance across tasks for data point `i`.\r\n\r\nClearly, the two are incompatible. This means that the variances and samples generated for a MTMVN generated from `from_independent_mvns` are incorrect. ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/537/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/537/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/535", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/535/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/535/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/535/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/535", "id": 413627335, "node_id": "MDU6SXNzdWU0MTM2MjczMzU=", "number": 535, "title": "lazily_evaluate_kernels(False) does not work", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-02-23T00:14:50Z", "updated_at": "2019-04-15T15:28:27Z", "closed_at": "2019-04-15T15:28:27Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Repro:\r\n\r\nRun [Simple GP Regression example](https://github.com/cornellius-gp/gpytorch/blob/master/examples/01_Simple_GP_Regression/Simple_GP_Regression.ipynb). Then calling\r\n```\r\nwith torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(False):\r\n    test_x = torch.linspace(0, 1, 51)\r\n    observed_pred = likelihood(model(test_x))\r\n```\r\nresults in the following error:\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-7-17d4be761e30> in <module>()\r\n      1 with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(False):\r\n      2     test_x = torch.linspace(0, 1, 51)\r\n----> 3     observed_pred = likelihood(model(test_x))\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)\r\n    199             )\r\n    200 \r\n--> 201             full_output = super(ExactGP, self).__call__(*full_inputs, **kwargs)\r\n    202             if settings.debug().on():\r\n    203                 if not isinstance(full_output, MultivariateNormal):\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     18 \r\n     19     def __call__(self, *inputs, **kwargs):\r\n---> 20         outputs = self.forward(*inputs, **kwargs)\r\n     21         if isinstance(outputs, list):\r\n     22             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n<ipython-input-3-190c52404ce7> in forward(self, x)\r\n      8     def forward(self, x):\r\n      9         mean_x = self.mean_module(x)\r\n---> 10         covar_x = self.covar_module(x)\r\n     11         return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n     12 \r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, batch_dims, **params)\r\n    382                 res = LazyEvaluatedKernelTensor(self, x1_, x2_, batch_dims=batch_dims, **params)\r\n    383             else:\r\n--> 384                 res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\r\n    385 \r\n    386             # Now we'll make sure that the shape we're getting makes sense\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     18 \r\n     19     def __call__(self, *inputs, **kwargs):\r\n---> 20         outputs = self.forward(*inputs, **kwargs)\r\n     21         if isinstance(outputs, list):\r\n     22             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/kernels/scale_kernel.py in forward(self, x1, x2, batch_dims, diag, **params)\r\n     92             outputscales = outputscales.unsqueeze(1).repeat(1, x1.size(-1)).view(-1)\r\n     93 \r\n---> 94         orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\r\n     95         if torch.is_tensor(orig_output):\r\n     96             outputscales = outputscales.view(-1, *([1] * (orig_output.dim() - 1)))\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, batch_dims, **params)\r\n    405                         raise RuntimeError(\r\n    406                             \"Error with {}.forward. Expected size {}. Got size {}.\".format(\r\n--> 407                                 self.__class__.__name__, expected_shape, res.shape\r\n    408                             )\r\n    409                         )\r\n\r\nRuntimeError: Error with RBFKernel.forward. Expected size torch.Size([151, 151]). Got size torch.Size([1, 151, 151]).\r\n```\r\n\r\nNot sure if this is even supposed to be used anymore - if not let's kill it.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/535/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/535/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/533", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/533/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/533/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/533/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/533", "id": 413609916, "node_id": "MDU6SXNzdWU0MTM2MDk5MTY=", "number": 533, "title": "batch evaluation of Kronecker GP fails when not using fast_pred_var", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-02-22T22:50:27Z", "updated_at": "2019-03-19T14:58:12Z", "closed_at": "2019-03-19T14:58:12Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Repro:\r\n\r\nRun the [Kronecker Multi-Task GP example](https://github.com/cornellius-gp/gpytorch/blob/master/examples/03_Multitask_GP_Regression/Multitask_GP_Regression.ipynb). \r\n\r\nThe following works fine:\r\n```\r\ntest_x = torch.linspace(0, 1, 51).unsqueeze(-1).repeat(2, 1, 1)\r\n\r\nwith gpytorch.settings.fast_pred_var():\r\n    out = likelihood(model(test_x))\r\n```\r\n\r\nBut when not using `fast_pred_var`, i.e. just running `out = likelihood(model(test_x))`, this yields the following `IndexError`:\r\n```\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-22-08b3c9b4435f> in <module>()\r\n----> 1 out = likelihood(model(test_x))\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)\r\n    262 \r\n    263             predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\r\n--> 264             predictive_covar = self.prediction_strategy.exact_predictive_covar(test_test_covar, test_train_covar)\r\n    265 \r\n    266             if num_tasks > 1:\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/models/exact_prediction_strategies.py in exact_predictive_covar(self, test_test_covar, test_train_covar)\r\n    321             test_train_covar = test_train_covar.evaluate()\r\n    322             train_test_covar = test_train_covar.transpose(-1, -2)\r\n--> 323             covar_correction_rhs = train_train_covar.inv_matmul(train_test_covar).mul(-1)\r\n    324             return test_test_covar + MatmulLazyTensor(test_train_covar, covar_correction_rhs)\r\n    325 \r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/lazy_tensor.py in inv_matmul(self, right_tensor, left_tensor)\r\n    685         )\r\n    686         if left_tensor is None:\r\n--> 687             return func(right_tensor, *self.representation())\r\n    688         else:\r\n    689             return func(left_tensor, right_tensor, *self.representation())\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/functions/_inv_matmul.py in forward(self, *args)\r\n     23 \r\n     24         with torch.no_grad():\r\n---> 25             self.preconditioner = lazy_tsr.detach()._inv_matmul_preconditioner()\r\n     26 \r\n     27         self.is_vector = False\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/lazy_tensor.py in _inv_matmul_preconditioner(self)\r\n    331             function: a function on x which performs P^{-1}(x)\r\n    332         \"\"\"\r\n--> 333         base_precond, _ = self._preconditioner()\r\n    334 \r\n    335         if base_precond is not None:\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/added_diag_lazy_tensor.py in _preconditioner(self)\r\n     58         if not hasattr(self, \"_woodbury_cache\"):\r\n     59             max_iter = settings.max_preconditioner_size.value()\r\n---> 60             self._piv_chol_self = pivoted_cholesky.pivoted_cholesky(self._lazy_tensor, max_iter)\r\n     61             if torch.any(torch.isnan(self._piv_chol_self)).item():\r\n     62                 warnings.warn(\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/utils/pivoted_cholesky.py in pivoted_cholesky(matrix, max_iter, error_tol)\r\n     54         L_m.scatter_(-1, pi_m.unsqueeze(-1), max_diag_values.sqrt().unsqueeze_(-1))\r\n     55 \r\n---> 56         row = matrix[(*batch_iters, pi_m.view(-1), slice(None, None, None))]\r\n     57         if isinstance(row, LazyTensor):\r\n     58             row = row.evaluate()\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/lazy_tensor.py in __getitem__(self, index)\r\n   1354 \r\n   1355         # Call self._getitem - now that the index has been processed\r\n-> 1356         return self._getitem(*index)\r\n   1357 \r\n   1358     def __matmul__(self, other):\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/sum_lazy_tensor.py in _getitem(self, *indices)\r\n     25 \r\n     26     def _getitem(self, *indices):\r\n---> 27         results = tuple(lazy_tensor._getitem(*indices) for lazy_tensor in self.lazy_tensors)\r\n     28         if isinstance(results[0], LazyTensor):\r\n     29             return SumLazyTensor(*results)\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/sum_lazy_tensor.py in <genexpr>(.0)\r\n     25 \r\n     26     def _getitem(self, *indices):\r\n---> 27         results = tuple(lazy_tensor._getitem(*indices) for lazy_tensor in self.lazy_tensors)\r\n     28         if isinstance(results[0], LazyTensor):\r\n     29             return SumLazyTensor(*results)\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/block_lazy_tensor.py in _getitem(self, *indices)\r\n    135 \r\n    136                 # Normal case: we have to do some processing on eithe rthe rows or columns\r\n--> 137                 res = new_var._getitem_nonbatch(left_index, right_index, first_tensor_index_dim)\r\n    138                 if (squeeze_left or squeeze_right) and isinstance(res, LazyTensor):\r\n    139                     res = res.evaluate()\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/lazy_tensor.py in _getitem_nonbatch(self, row_index, col_index, first_tensor_index_dim)\r\n    294         left_row_iter = torch.arange(0, self.size()[-2], dtype=torch.long, device=self.device)\r\n    295         right_row_iter = torch.arange(0, self.size()[-1], dtype=torch.long, device=self.device)\r\n--> 296         left_interp_indices = left_row_iter[row_index].unsqueeze(-1)\r\n    297         right_interp_indices = right_row_iter[col_index].unsqueeze(-1)\r\n    298 \r\n\r\nIndexError: index 198 is out of bounds for dimension 0 with size 4\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/533/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/533/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/532", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/532/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/532/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/532/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/532", "id": 413595153, "node_id": "MDU6SXNzdWU0MTM1OTUxNTM=", "number": 532, "title": "batch evaluation of Hadamard Multi-Task GP fails", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-22T21:57:14Z", "updated_at": "2019-03-19T14:58:12Z", "closed_at": "2019-03-19T14:58:12Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "*Note*: This happens both on master and on the `batch_lt3` branch\r\n\r\nRepro:\r\n\r\nFirst run the [Hadamard MTGP example](https://github.com/cornellius-gp/gpytorch/blob/master/examples/03_Multitask_GP_Regression/Hadamard_Multitask_GP_Regression.ipynb).\r\n\r\nThen \r\n```\r\ntest_x = torch.linspace(0, 1, 51).unsqueeze(-1).repeat(2, 1, 1)\r\ntast_i_task1 = torch.full_like(test_x, dtype=torch.long, fill_value=0)\r\n\r\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n    observed_pred_y1 = likelihood(model(test_x, tast_i_task1))\r\n```\r\n\r\nerrors out with \r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-62-28172f8b7beb> in <module>()\r\n      1 with torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n----> 2     observed_pred_y1 = likelihood(model(test_x, tast_i_task1))\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)\r\n    199             )\r\n    200 \r\n--> 201             full_output = super(ExactGP, self).__call__(*full_inputs, **kwargs)\r\n    202             if settings.debug().on():\r\n    203                 if not isinstance(full_output, MultivariateNormal):\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     18 \r\n     19     def __call__(self, *inputs, **kwargs):\r\n---> 20         outputs = self.forward(*inputs, **kwargs)\r\n     21         if isinstance(outputs, list):\r\n     22             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n<ipython-input-52-b565681c3db1> in forward(self, x, i)\r\n     17         covar_i = self.task_covar_module(i)\r\n     18         # Multiply the two together to get the covariance we want\r\n---> 19         covar = covar_x.mul(covar_i)\r\n     20 \r\n     21         return gpytorch.distributions.MultivariateNormal(mean_x, covar)\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/lazy_tensor.py in mul(self, other)\r\n    950                 return self._mul_constant(other.view(*other.shape[:-2]))\r\n    951 \r\n--> 952         return self._mul_matrix(other)\r\n    953 \r\n    954     def ndimension(self):\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/lazy_tensor.py in _mul_matrix(self, other)\r\n    443         \"\"\"\r\n    444         from .mul_lazy_tensor import MulLazyTensor\r\n--> 445         return MulLazyTensor(self, other).evaluate_kernel()\r\n    446 \r\n    447     def _preconditioner(self):\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/lazy_tensor.py in evaluate_kernel(self)\r\n    734         all lazily evaluated kernels actually evaluated.\r\n    735         \"\"\"\r\n--> 736         return self.representation_tree()(*self.representation())\r\n    737 \r\n    738     def inv_matmul(self, right_tensor, left_tensor=None):\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/mul_lazy_tensor.py in representation_tree(self)\r\n    235 \r\n    236     def representation_tree(self):\r\n--> 237         if self.non_lazy_self is not None:\r\n    238             return self.non_lazy_self.representation_tree()\r\n    239         else:\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/mul_lazy_tensor.py in non_lazy_self(self)\r\n     37         if hasattr(self, \"_non_lazy_self\"):\r\n     38             return self._non_lazy_self[0]\r\n---> 39         elif len(self._args) == 1:\r\n     40             return self._args[0]\r\n     41         else:\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/mul_lazy_tensor.py in _args(self)\r\n     54         if not hasattr(self, \"_mul_args_memo\") and not hasattr(self, \"_non_lazy_self\"):\r\n     55             lazy_tensors = sorted(\r\n---> 56                 (lv.evaluate_kernel() for lv in self.lazy_tensors), key=lambda lv: lv.root_decomposition_size()\r\n     57             )\r\n     58 \r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/mul_lazy_tensor.py in <genexpr>(.0)\r\n     54         if not hasattr(self, \"_mul_args_memo\") and not hasattr(self, \"_non_lazy_self\"):\r\n     55             lazy_tensors = sorted(\r\n---> 56                 (lv.evaluate_kernel() for lv in self.lazy_tensors), key=lambda lv: lv.root_decomposition_size()\r\n     57             )\r\n     58 \r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)\r\n    159             with settings.lazily_evaluate_kernels(False):\r\n    160                 self._cached_kernel_eval = self.kernel(\r\n--> 161                     x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\r\n    162                 )\r\n    163 \r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, batch_dims, **params)\r\n    396                 res = LazyEvaluatedKernelTensor(self, x1_, x2_, batch_dims=batch_dims, **params)\r\n    397             else:\r\n--> 398                 res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\r\n    399 \r\n    400             # TODO: remove bach checking once kernels support arbitrary batch dimensions\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n     18 \r\n     19     def __call__(self, *inputs, **kwargs):\r\n---> 20         outputs = self.forward(*inputs, **kwargs)\r\n     21         if isinstance(outputs, list):\r\n     22             return [_validate_module_outputs(output) for output in outputs]\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/kernels/index_kernel.py in forward(self, i1, i2, **params)\r\n     78     def forward(self, i1, i2, **params):\r\n     79         covar_matrix = self._eval_covar_matrix()\r\n---> 80         res = InterpolatedLazyTensor(base_lazy_tensor=covar_matrix, left_interp_indices=i1, right_interp_indices=i2)\r\n     81         return res\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/interpolated_lazy_tensor.py in __init__(self, base_lazy_tensor, left_interp_indices, left_interp_values, right_interp_indices, right_interp_values)\r\n     60             raise RuntimeError(\r\n     61                 \"left interp size ({}) is incompatible with base_lazy_tensor size ({}). Make sure the two \"\r\n---> 62                 \"have the same number of batch dimensions\".format(left_interp_indices.size(), base_lazy_tensor.size())\r\n     63             )\r\n     64         if right_interp_indices.shape[:-2] != base_lazy_tensor.batch_shape:\r\n\r\nRuntimeError: left interp size (torch.Size([2, 251, 1])) is incompatible with base_lazy_tensor size (torch.Size([1, 2, 2])). Make sure the two have the same number of batch dimensions\r\n```\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/532/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/532/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/524", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/524/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/524/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/524/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/524", "id": 412748850, "node_id": "MDU6SXNzdWU0MTI3NDg4NTA=", "number": 524, "title": "Where is `fast_pred_var` moving?", "user": {"login": "neighthan", "id": 12573501, "node_id": "MDQ6VXNlcjEyNTczNTAx", "avatar_url": "https://avatars.githubusercontent.com/u/12573501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neighthan", "html_url": "https://github.com/neighthan", "followers_url": "https://api.github.com/users/neighthan/followers", "following_url": "https://api.github.com/users/neighthan/following{/other_user}", "gists_url": "https://api.github.com/users/neighthan/gists{/gist_id}", "starred_url": "https://api.github.com/users/neighthan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neighthan/subscriptions", "organizations_url": "https://api.github.com/users/neighthan/orgs", "repos_url": "https://api.github.com/users/neighthan/repos", "events_url": "https://api.github.com/users/neighthan/events{/privacy}", "received_events_url": "https://api.github.com/users/neighthan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-02-21T04:55:56Z", "updated_at": "2019-04-15T13:27:07Z", "closed_at": "2019-04-15T13:27:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I received the following warning when using `fast_pred_var`:\r\n\r\n```\r\n/cluster/nhunt/anaconda/envs/bayes_opt/lib/python3.7/site-packages/gpytorch/beta_features.py:17:\r\nDeprecationWarning: `gpytorch.settings.fast_pred_var` has moved to `gpytorch.settings.fast_pred_var`.\r\n```\r\n\r\nIt seems that I'm being warned that `fast_pred_var` has moved to its current location. Was there a typo in the warning about how we should be using this setting now?\r\n\r\n```bash\r\n$ pip list | grep gpytorch\r\ngpytorch           0.2.1\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/524/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/524/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/523", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/523/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/523/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/523/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/523", "id": 412668653, "node_id": "MDU6SXNzdWU0MTI2Njg2NTM=", "number": 523, "title": "ScaleKernel causes base kernel to act like a noise kernel.", "user": {"login": "Duane321", "id": 19956442, "node_id": "MDQ6VXNlcjE5OTU2NDQy", "avatar_url": "https://avatars.githubusercontent.com/u/19956442?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Duane321", "html_url": "https://github.com/Duane321", "followers_url": "https://api.github.com/users/Duane321/followers", "following_url": "https://api.github.com/users/Duane321/following{/other_user}", "gists_url": "https://api.github.com/users/Duane321/gists{/gist_id}", "starred_url": "https://api.github.com/users/Duane321/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Duane321/subscriptions", "organizations_url": "https://api.github.com/users/Duane321/orgs", "repos_url": "https://api.github.com/users/Duane321/repos", "events_url": "https://api.github.com/users/Duane321/events{/privacy}", "received_events_url": "https://api.github.com/users/Duane321/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-02-20T22:57:56Z", "updated_at": "2019-02-21T16:20:45Z", "closed_at": "2019-02-21T16:20:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nFirst, thanks for writing this package. I think it's awesome and I hope to contribute after I'm more familiar.\r\n\r\nThat said, I'm observing what I suspect is odd behavior. In a nutshell, I believe the ScaleKernel causes a kernel to be used like a noise kernel (only being applied to training data).\r\n\r\nI'll try to demonstrate what I mean:\r\n\r\n```\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\n%matplotlib inline\r\n\r\nimport gpytorch\r\nimport torch\r\n\r\ntorch.set_default_tensor_type(\"torch.DoubleTensor\")\r\n```\r\n\r\nNow I'll set up some fake training data:\r\n\r\n```x = np.linspace(0,10,500)\r\nbeta = 10\r\noffset = 2\r\nsin_amplitutde = 20\r\nsin_period = 2\r\nnoise_var = 10\r\n\r\ny = x*beta + offset + np.sin(x*2*np.pi/sin_period)*sin_amplitutde + np.random.normal(0,np.sqrt(noise_var),len(x))\r\n\r\ndef clean_ax(ax):\r\n    ax.grid(True)\r\n    for which in ['top','right']:\r\n        ax.spines[which].set_visible(False)\r\n\r\nfigsize=(10,6)\r\nfig, ax = plt.subplots(figsize=figsize)\r\nax.plot(x,y,'*')\r\nclean_ax(ax)\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/19956442/53130546-7aae1c80-351f-11e9-9fe8-29d9137c825c.png)\r\n\r\nMy goal will be to observe the left 70% of this and predict to the right.\r\n\r\nI can do this with 2 features. One is the x axis and the other is the x axis mod the period length. We'll set up a GP to model the first feature with a linear kernel and the 2nd with an RBF.\r\n\r\n```\r\nsplit_point = int(len(x)*.7)\r\n\r\nX = np.concatenate([x.reshape(-1,1),np.mod(x,sin_period).reshape(-1,1)],axis=1)\r\n\r\ntrain_x = torch.from_numpy(X[:split_point,:]).to(torch.float64)\r\ntrain_y = torch.from_numpy(y[:split_point]).to(torch.float64)\r\n\r\ntest_x = torch.from_numpy(X[split_point:,:]).to(torch.float64)\r\ntest_y = torch.from_numpy(y[split_point:]).to(torch.float64)\r\n```\r\n\r\nNow, this next function will accept a model and produce the predictions in a graph.\r\n\r\n```\r\ndef prediction_graph_for_model(model):\r\n\r\n    model.train() # What does this do?\r\n    likelihood.train()\r\n\r\n    optimizer = torch.optim.Adam([\r\n        {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n    ], lr=0.1)\r\n\r\n    # \"Loss\" for GPs - the marginal log likelihood\r\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\n    training_iter = 200\r\n    for i in range(training_iter):\r\n        # Zero gradients from previous iteration\r\n        optimizer.zero_grad()\r\n        # Output from model\r\n        output = model(train_x)\r\n        # Calc loss and backprop gradients\r\n        loss = -mll(output, train_y)\r\n        loss.backward()\r\n        if not i % 20:\r\n            print('i: {0}, Loss: {1}'.format(i, loss.item()))\r\n        optimizer.step()\r\n        \r\n    # Get into evaluation (predictive posterior) mode\r\n    model.eval()\r\n    likelihood.eval()\r\n\r\n    # Test points are regularly spaced along [0,1]\r\n    # Make predictions by feeding model through likelihood\r\n    with torch.no_grad(), gpytorch.settings.fast_pred_var():\r\n        y_test_pred = likelihood(model(test_x)).mean.numpy()\r\n        y_train_pred = likelihood(model(train_x)).mean.numpy()\r\n\r\n    y_predicted = np.concatenate([y_train_pred,y_test_pred])\r\n    \r\n    figsize = (10, 5)\r\n\r\n    fig, ax = plt.subplots(figsize=figsize)\r\n\r\n\r\n    ax.plot(train_x.numpy()[:,0],train_y.numpy(),'*',color='green',alpha=.5,label='training_data')\r\n    ax.plot(X[:,0],y_predicted,color='blue',alpha=.5,label='predicted')\r\n\r\n    ax.plot(test_x.numpy()[:,0],test_y.numpy(),'*',color='red',alpha=.5,label='actual')\r\n\r\n    clean_ax(ax)\r\n    ax.legend()\r\n    \r\n    return fig, ax\r\n```\r\n\r\nNow we set up the model. The first way will work properly.\r\n\r\n```\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        cov1 = gpytorch.kernels.LinearKernel(num_dimensions=1, active_dims=[0])\r\n        \r\n        #cov2 is the ONLY THING that will change between this model and the broken one.\r\n        cov2 = gpytorch.kernels.RBFKernel(active_dims=[1])\r\n        self.covar_module = cov1 + cov2        \r\n    \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n    \r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\nprediction_graph_for_model(model)\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/19956442/53130660-bea12180-351f-11e9-8667-81007f192178.png)\r\n\r\nNow let's break it. We'll change just cov2 in the previous.\r\n\r\n```\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        cov1 = gpytorch.kernels.LinearKernel(num_dimensions=1, active_dims=[0])\r\n        \r\n        #cov2 is now wrapped in a ScaleKernel\r\n        cov2 = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(active_dims=[1]))\r\n        self.covar_module = cov1 + cov2        \r\n    \r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n    \r\n    \r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\nmodel = ExactGPModel(train_x, train_y, likelihood)\r\nprediction_graph_for_model(model)\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/19956442/53130719-e3959480-351f-11e9-897c-339a21a83f6b.png)\r\n\r\nI've tried a few things to solve this, but I can't get it to work. I'd like ultimately to use the ScaleKernel, but it to extrapolate to the test data as well.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/523/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/523/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/516", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/516/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/516/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/516/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/516", "id": 409455847, "node_id": "MDU6SXNzdWU0MDk0NTU4NDc=", "number": 516, "title": "SKI for multidemnsional output", "user": {"login": "Lazloo", "id": 10186284, "node_id": "MDQ6VXNlcjEwMTg2Mjg0", "avatar_url": "https://avatars.githubusercontent.com/u/10186284?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lazloo", "html_url": "https://github.com/Lazloo", "followers_url": "https://api.github.com/users/Lazloo/followers", "following_url": "https://api.github.com/users/Lazloo/following{/other_user}", "gists_url": "https://api.github.com/users/Lazloo/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lazloo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lazloo/subscriptions", "organizations_url": "https://api.github.com/users/Lazloo/orgs", "repos_url": "https://api.github.com/users/Lazloo/repos", "events_url": "https://api.github.com/users/Lazloo/events{/privacy}", "received_events_url": "https://api.github.com/users/Lazloo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1607679275, "node_id": "MDU6TGFiZWwxNjA3Njc5Mjc1", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/multitask", "name": "multitask", "color": "ffffff", "default": false, "description": "For questions about multitask models"}, {"id": 1607680352, "node_id": "MDU6TGFiZWwxNjA3NjgwMzUy", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/variational", "name": "variational", "color": "ffffff", "default": false, "description": "For questions about variational inference"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-02-12T19:10:50Z", "updated_at": "2019-11-12T20:39:54Z", "closed_at": "2019-11-12T20:39:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey,\r\n\r\nI would like to apply SKI for a data set that is multi-dimensional w.r.t. input and output. However, I feel I stuck an some part. I tried to orintate my code as much as possible on 05_Scalable_GP_Regression_Multidimensional but without the Deep Learning part.\r\n\r\n# My data toy set:\r\n\r\n```\r\nimport math\r\nimport torch\r\nimport numpy as np\r\nimport gpytorch\r\nfrom torch.utils.data import TensorDataset, DataLoader\r\n\r\nn = 20\r\ntrain_x = torch.zeros(pow(n, 2), 2)\r\nfor i in range(n):\r\n    for j in range(n):\r\n        # Each coordinate varies from 0 to 1 in n=100 steps\r\n        train_x[i * n + j][0] = float(i) / (n - 1)\r\n        train_x[i * n + j][1] = float(j) / (n - 1)\r\n\r\ntrain_y_1 = (torch.sin(train_x[:, 0]) + torch.cos(train_x[:, 1]) * (2 * math.pi) + torch.randn_like(train_x[:, 0]).mul(\r\n    0.01)) / 4\r\ntrain_y_2 = torch.sin(train_x[:, 0]) + torch.cos(train_x[:, 1]) * (2 * math.pi) + torch.randn_like(train_x[:, 0]).mul(\r\n    0.01)\r\n\r\ntrain_y = torch.stack([train_y_1, train_y_2], -1)\r\n\r\ntest_x = torch.rand((n, len(train_x.shape)))\r\ntest_y_1 = (torch.sin(test_x[:, 0]) + torch.cos(test_x[:, 1]) * (2 * math.pi) + torch.randn_like(test_x[:, 0]).mul(\r\n    0.01)) / 4\r\ntest_y_2 = torch.sin(test_x[:, 0]) + torch.cos(test_x[:, 1]) * (2 * math.pi) + torch.randn_like(test_x[:, 0]).mul(0.01)\r\ntest_y = torch.stack([test_y_1, test_y_2], -1)\r\n\r\ntrain_x = train_x.unsqueeze(0).repeat(2, 1, 1)\r\ntrain_y = train_y.transpose(-2, -1)\r\ntrain_x = train_x.cuda()\r\ntrain_y = train_y.cuda()\r\n\r\ntrain_dataset = TensorDataset(train_x, train_y)\r\ntrain_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\r\n```\r\n\r\n# Creating the GPRegression class\r\n\r\n```\r\nsoftplus = torch.functional.F.softplus\r\nclass GPRegressionLayer(gpytorch.models.AbstractVariationalGP):\r\n    def __init__(self, grid_size=32, grid_bounds=[(-1, 1)] * 2):\r\n        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(num_inducing_points=grid_size * grid_size)\r\n        variational_strategy = gpytorch.variational.GridInterpolationVariationalStrategy(self,\r\n                                                                    grid_size=grid_size,\r\n                                                                    grid_bounds=grid_bounds,\r\n                                                                    variational_distribution=variational_distribution)\r\n        super(GPRegressionLayer, self).__init__(variational_strategy)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        self.covar_module = gpytorch.kernels.ScaleKernel(\r\n            gpytorch.kernels.RBFKernel(param_transform=softplus), param_transform=softplus\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n# num_features is the number of final features extracted by the neural network, in this case 2.\r\nnum_features = 2\r\nmodel = GPRegressionLayer().cuda()\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood(param_transform=softplus, num_tasks=2).cuda()\r\n```\r\n\r\n# Training \r\n\r\n```\r\nmodel.train()\r\nlikelihood.train()\r\n\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},\r\n], lr=0.1)\r\n\r\nmll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0), combine_terms=False)\r\n\r\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3, 5], gamma=0.1)\r\nnum_epochs = 7\r\nfor i in range(num_epochs):\r\n    scheduler.step()\r\n    # Within each iteration, we will go over each minibatch of data\r\n    for minibatch_i, (x_batch, y_batch) in enumerate(train_loader):\r\n        optimizer.zero_grad()\r\n\r\n        with gpytorch.settings.use_toeplitz(False):\r\n            output = model(x_batch)\r\n            log_lik, kl_div, log_prior = mll(output, y_batch)\r\n            loss = -(log_lik - kl_div + log_prior).sum()\r\n            print('Epoch %d [%d/%d] - Loss: %.3f [%.3f, %.3f, %.3f]' % (i + 1, minibatch_i, len(train_loader),\r\n                                                                        loss.item(), log_lik.item(), kl_div.item(),\r\n                                                                        log_prior.item()))\r\n\r\n        # The actual optimization step\r\n        loss.backward()\r\n        optimizer.step()\r\n```\r\n\r\nUnfortunately this return an error:\r\n\r\n> \r\n>   File \"D:/Programmieren/convolutional_gaussian_process_regression/test_SVG.py\", line 111, in <module>\r\n>     output = model(x_batch)\r\n>   File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\gpytorch\\models\\abstract_variational_gp.py\", line 22, in __call__\r\n>     return self.variational_strategy(inputs)\r\n>   File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\gpytorch\\variational\\variational_strategy.py\", line 186, in __call__\r\n>     return super(VariationalStrategy, self).__call__(x)\r\n>   File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\gpytorch\\module.py\", line 20, in __call__\r\n>     outputs = self.forward(*inputs, **kwargs)\r\n>   File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\gpytorch\\variational\\grid_interpolation_variational_strategy.py\", line 44, in forward\r\n>     interp_indices, interp_values = self._compute_grid(x)\r\n>   File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\gpytorch\\variational\\grid_interpolation_variational_strategy.py\", line 37, in _compute_grid\r\n>     interp_indices, interp_values = Interpolation().interpolate(self.grid, inputs)\r\n>   File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\gpytorch\\utils\\interpolation.py\", line 147, in interpolate\r\n>     dim_interp_values = dim_interp_values.unsqueeze(-1).repeat(1, n_inner_repeat, n_outer_repeat)\r\n> RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/516/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/516/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/513", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/513/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/513/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/513/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/513", "id": 408573901, "node_id": "MDU6SXNzdWU0MDg1NzM5MDE=", "number": 513, "title": "AdditiveStructureKernel does not work in batch mode", "user": {"login": "Lazloo", "id": 10186284, "node_id": "MDQ6VXNlcjEwMTg2Mjg0", "avatar_url": "https://avatars.githubusercontent.com/u/10186284?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lazloo", "html_url": "https://github.com/Lazloo", "followers_url": "https://api.github.com/users/Lazloo/followers", "following_url": "https://api.github.com/users/Lazloo/following{/other_user}", "gists_url": "https://api.github.com/users/Lazloo/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lazloo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lazloo/subscriptions", "organizations_url": "https://api.github.com/users/Lazloo/orgs", "repos_url": "https://api.github.com/users/Lazloo/repos", "events_url": "https://api.github.com/users/Lazloo/events{/privacy}", "received_events_url": "https://api.github.com/users/Lazloo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-02-10T20:15:31Z", "updated_at": "2019-04-15T15:28:27Z", "closed_at": "2019-04-15T15:28:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey,\r\n\r\nI would like to perform \"Scalable GP Regression\" for a data set with multiple output variables. I use the following data set:\r\n\r\n```\r\nimport math\r\nimport torch\r\nimport numpy as np\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\nn = 20\r\ntrain_x = torch.zeros(pow(n, 2), 2)\r\nfor i in range(n):\r\n    for j in range(n):\r\n        # Each coordinate varies from 0 to 1 in n=100 steps\r\n        train_x[i * n + j][0] = float(i) / (n - 1)\r\n        train_x[i * n + j][1] = float(j) / (n - 1)\r\n\r\ntrain_y_1 = (torch.sin(train_x[:, 0]) + torch.cos(train_x[:, 1]) * (2 * math.pi) + torch.randn_like(train_x[:, 0]).mul(\r\n    0.01)) / 4\r\ntrain_y_2 = torch.sin(train_x[:, 0]) + torch.cos(train_x[:, 1]) * (2 * math.pi) + torch.randn_like(train_x[:, 0]).mul(\r\n    0.01)\r\n\r\ntrain_y = torch.stack([train_y_1, train_y_2], -1)\r\n\r\ntest_x = torch.rand((n, len(train_x.shape)))\r\ntest_y_1 = (torch.sin(test_x[:, 0]) + torch.cos(test_x[:, 1]) * (2 * math.pi) + torch.randn_like(test_x[:, 0]).mul(\r\n    0.01)) / 4\r\ntest_y_2 = torch.sin(test_x[:, 0]) + torch.cos(test_x[:, 1]) * (2 * math.pi) + torch.randn_like(test_x[:, 0]).mul(0.01)\r\ntest_y = torch.stack([test_y_1, test_y_2], -1)\r\n\r\ntrain_x = train_x.unsqueeze(0).repeat(2, 1, 1)\r\ntrain_y = train_y.transpose(-2, -1)\r\ntrain_x = train_x.cuda()\r\ntrain_y = train_y.cuda()\r\n```\r\n\r\nAn based on the tutorial I try to train the model usign the following code:\r\n\r\n```\r\nclass MultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n\r\n        grid_size = gpytorch.utils.grid.choose_grid_size(train_x, kronecker_structure=False)\r\n        self.covar_module = gpytorch.kernels.AdditiveStructureKernel(\r\n            gpytorch.kernels.GridInterpolationKernel(\r\n                gpytorch.kernels.ScaleKernel(\r\n                    gpytorch.kernels.MaternKernel(nu=1.5),\r\n                ), grid_size=int(grid_size), num_dims=1\r\n            ), num_dims=train_x.shape[-1]\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood(num_tasks=2).cuda()\r\nmodel = MultitaskGPModel(train_x, train_y, likelihood).cuda()\r\n# model.double()\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n], lr=0.0001)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nn_iter = 50\r\nfor i in range(n_iter):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    # loss = -mll(output, train_y)\r\n    loss = -mll(output, train_y).sum()\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, n_iter, loss.item()))\r\n    optimizer.step()\r\n```\r\n\r\nHowever I get the following error message:\r\n\r\n> RuntimeError: left interp size (torch.Size([4, 400, 4])) is incompatible with base_lazy_tensor size (torch.Size([8, 400, 400])). Make sure the two have the same number of batch dimensions\r\n\r\nCan someone help?", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/513/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/513/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/508", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/508/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/508/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/508/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/508", "id": 407865802, "node_id": "MDExOlB1bGxSZXF1ZXN0MjUxMjQzODM3", "number": 508, "title": "Fix autograd bug with preconditioner, default _getitem", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-07T19:41:41Z", "updated_at": "2019-02-07T20:31:17Z", "closed_at": "2019-02-07T20:31:09Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/508", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/508", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/508.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/508.patch", "merged_at": "2019-02-07T20:31:09Z"}, "body": "For some reason, using the preconditioner in conjunction with the default _getitem causes an autograd error. We definitely should not be computing the backward pass of the preconditioner anyways.\r\n\r\nThis ensures that the preconditioner is detached and that we are not computing its backwards pass.\r\n\r\nCloses #501 ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/508/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/508/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/505", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/505/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/505/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/505/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/505", "id": 407545550, "node_id": "MDExOlB1bGxSZXF1ZXN0MjUwOTk1NTc3", "number": 505, "title": "[WIP] ToeplitzLazyTensor custom _getitem", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-02-07T05:17:41Z", "updated_at": "2019-05-06T19:02:30Z", "closed_at": "2019-02-07T19:09:42Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/505", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/505", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/505.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/505.patch", "merged_at": null}, "body": "This is most of the way there, just need to handle the \"batch index is tensor / scalar\" case. We may also revert back to the default `_getitem` implementation in the case where both the row index and the column index are slices to avoid materializing `O(n^2)` storage.\r\n\r\nFixes #501, although we should fix the underlying issue with the default `_getitem` as well.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/505/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/505/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/503", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/503/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/503/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/503/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/503", "id": 407527792, "node_id": "MDU6SXNzdWU0MDc1Mjc3OTI=", "number": 503, "title": "Fast pred var? More like 1/3 as fast pred var", "user": {"login": "KeAWang", "id": 11478740, "node_id": "MDQ6VXNlcjExNDc4NzQw", "avatar_url": "https://avatars.githubusercontent.com/u/11478740?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KeAWang", "html_url": "https://github.com/KeAWang", "followers_url": "https://api.github.com/users/KeAWang/followers", "following_url": "https://api.github.com/users/KeAWang/following{/other_user}", "gists_url": "https://api.github.com/users/KeAWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/KeAWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KeAWang/subscriptions", "organizations_url": "https://api.github.com/users/KeAWang/orgs", "repos_url": "https://api.github.com/users/KeAWang/repos", "events_url": "https://api.github.com/users/KeAWang/events{/privacy}", "received_events_url": "https://api.github.com/users/KeAWang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-02-07T03:29:16Z", "updated_at": "2019-02-07T19:18:29Z", "closed_at": "2019-02-07T19:18:29Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "It seems that after commit 0ff64169766bd22d1d8cae35ef0ab3f0d6f16e2e, fast_pred_var is now 3x slower.\r\n\r\nUsing the following code\r\n```\r\nmodel.eval()\r\nlikelihood.eval()\r\nimport time\r\n\r\nfor i in range(10):\r\n    start = time.time()\r\n    with gpytorch.settings.fast_pred_var():\r\n        preds = model(test_x)\r\n    print(time.time() - start)\r\n```\r\nI get \r\n```\r\n0.05411267280578613\r\n0.0015854835510253906\r\n0.0012111663818359375\r\n0.0011920928955078125\r\n0.0011920928955078125\r\n0.0011932849884033203\r\n0.0012063980102539062\r\n0.0011904239654541016\r\n0.0011909008026123047\r\n0.00119781494140625\r\n```\r\nfrom the previous commit a1e8bcc26a4b432776620b242023adb7acf206e3.\r\n\r\nOn the other hand, I get\r\n```\r\n0.05980277061462402\r\n0.003302335739135742\r\n0.0028259754180908203\r\n0.0028007030487060547\r\n0.0028228759765625\r\n0.002866983413696289\r\n0.0028259754180908203\r\n0.0033342838287353516\r\n0.0032806396484375\r\n0.003268718719482422\r\n```\r\nfrom the breaking commit 0ff64169766bd22d1d8cae35ef0ab3f0d6f16e2e.\r\n\r\nThe code used to train the model is taken from the official fast_pred_var notebook:\r\n\r\n```\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\n# Make plots inline\r\n%matplotlib inline\r\n\r\nimport urllib.request\r\nimport os.path\r\nfrom scipy.io import loadmat\r\nfrom math import floor\r\n\r\nif not os.path.isfile('skillcraft.mat'):\r\n    print('Downloading \\'skillcraft\\' UCI dataset...')\r\n    urllib.request.urlretrieve('https://drive.google.com/uc?export=download&id=1xQ1vgx_bOsLDQ3RLbJwPxMyJHW7U9Eqd', 'skillcraft.mat')\r\n    \r\ndata = torch.Tensor(loadmat('skillcraft.mat')['data'])\r\nX = data[:, :-1]\r\nX = X - X.min(0)[0]\r\nX = 2 * (X / X.max(0)[0]) - 1\r\ny = data[:, -1]\r\n\r\n# Use the first 80% of the data for training, and the last 20% for testing.\r\ntrain_n = int(floor(0.4*len(X)))\r\n\r\ntrain_x = X[:train_n, :].contiguous().cuda()\r\ntrain_y = y[:train_n].contiguous().cuda()\r\n\r\ntest_x = X[train_n:, :].contiguous().cuda()\r\ntest_y = y[train_n:].contiguous().cuda()\r\n\r\nclass GPRegressionModel(gpytorch.models.ExactGP):\r\n        def __init__(self, train_x, train_y, likelihood):\r\n            super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\r\n            self.mean_module = gpytorch.means.ConstantMean()\r\n            self.covar_module = gpytorch.kernels.ScaleKernel(\r\n                gpytorch.kernels.RBFKernel()\r\n            )\r\n            \r\n        def forward(self, x):\r\n            mean_x = self.mean_module(x)\r\n            covar_x = self.covar_module(x)\r\n            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood().cuda()\r\nmodel = GPRegressionModel(train_x, train_y, likelihood).cuda()\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n], lr=0.1)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ntraining_iterations = 20\r\ndef train():\r\n    for i in range(training_iterations):\r\n        optimizer.zero_grad()\r\n        output = model(train_x)\r\n        loss = -mll(output, train_y)\r\n        loss.backward()\r\n        print('Iter %d/%d - Loss: %.3f' % (i + 1,\r\n                                           training_iterations,\r\n                                           loss.item()))\r\n        optimizer.step()\r\n```\r\n\r\nOn the other hand, this does not appear to affect forward passes without the `fast_pred_var` option. Although that could just because forwards without fast_pred_var are already very slow.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/503/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 1, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/503/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/501", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/501/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/501/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/501/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/501", "id": 407428315, "node_id": "MDU6SXNzdWU0MDc0MjgzMTU=", "number": 501, "title": "Grid kernel has trouble with 1D inputs", "user": {"login": "tadesautels", "id": 15636950, "node_id": "MDQ6VXNlcjE1NjM2OTUw", "avatar_url": "https://avatars.githubusercontent.com/u/15636950?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tadesautels", "html_url": "https://github.com/tadesautels", "followers_url": "https://api.github.com/users/tadesautels/followers", "following_url": "https://api.github.com/users/tadesautels/following{/other_user}", "gists_url": "https://api.github.com/users/tadesautels/gists{/gist_id}", "starred_url": "https://api.github.com/users/tadesautels/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tadesautels/subscriptions", "organizations_url": "https://api.github.com/users/tadesautels/orgs", "repos_url": "https://api.github.com/users/tadesautels/repos", "events_url": "https://api.github.com/users/tadesautels/events{/privacy}", "received_events_url": "https://api.github.com/users/tadesautels/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-02-06T21:00:37Z", "updated_at": "2019-02-08T22:55:29Z", "closed_at": "2019-02-07T20:31:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm new to both PyTorch and GPyTorch, so please forgive me if I'm doing something silly.\r\n\r\n\r\nThe GridKernel seems to have problems with a 1-dimensional input, where 1-dimensional and 2-dimensional inputs are handled differently for some reason.  2- (and 3-) dimensional cases run without the error below.\r\n\r\nWorking example:\r\nFrom the current master branch: \r\nModify the test_grid_gp_regression.py script to create a similar script, here called test_1D_grid_gp_regression.py, where the diff is this:\r\n```\r\n$ diff test_grid_gp_regression.py test_1D_grid_gp_regression.py\r\n15c15\r\n<     train_y = torch.sin((train_x[:, 0] + train_x[:, 1]) * (2 * math.pi)) + torch.randn_like(train_x[:, 0]).mul(0.01)\r\n---\r\n>     train_y = torch.sin((train_x[:, 0]) * (2 * math.pi)) + torch.randn_like(train_x[:, 0]).mul(0.01)\r\n58c58\r\n<         grid_bounds = [(0, 1), (0, 2)]\r\n---\r\n>         grid_bounds = [(0, 1)]\r\n```\r\n\r\nI get the following error when running the test:\r\n```\r\n$ python test_1D_grid_gp_regression.py \r\nE.\r\n======================================================================\r\nERROR: test_grid_gp_mean_abs_error (__main__.TestGridGPRegression)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"test_1D_grid_gp_regression.py\", line 87, in test_grid_gp_mean_abs_error\r\n    loss.backward()\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 102, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 90, in backward\r\n    allow_unreachable=True)  # allow_unreachable flag\r\n  File \"/home/gpytorch/gpytorch/functions/_matmul.py\", line 34, in backward\r\n    rhs = self.saved_tensors[0]\r\nRuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation\r\n\r\n----------------------------------------------------------------------\r\nRan 2 tests in 0.088s\r\n\r\nFAILED (errors=1)\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/501/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/501/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/497", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/497/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/497/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/497/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/497", "id": 406577964, "node_id": "MDExOlB1bGxSZXF1ZXN0MjUwMjQ0Mzky", "number": 497, "title": "Fix bug in grid_size utility for additive structure", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-02-05T00:16:53Z", "updated_at": "2019-02-07T19:11:23Z", "closed_at": "2019-02-07T19:11:20Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/497", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/497", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/497.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/497.patch", "merged_at": null}, "body": "`choose_grid_size` was scaling by the number of dimensions to give reasonable grid sizes for Kronecker structure. We don't need this for additive structure.\r\nThere is now an option in `choose_grid_size` that fixes this.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/497/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/497/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/496", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/496/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/496/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/496/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/496", "id": 406501542, "node_id": "MDU6SXNzdWU0MDY1MDE1NDI=", "number": 496, "title": "NaNs encountered on first iteration", "user": {"login": "Lazloo", "id": 10186284, "node_id": "MDQ6VXNlcjEwMTg2Mjg0", "avatar_url": "https://avatars.githubusercontent.com/u/10186284?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lazloo", "html_url": "https://github.com/Lazloo", "followers_url": "https://api.github.com/users/Lazloo/followers", "following_url": "https://api.github.com/users/Lazloo/following{/other_user}", "gists_url": "https://api.github.com/users/Lazloo/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lazloo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lazloo/subscriptions", "organizations_url": "https://api.github.com/users/Lazloo/orgs", "repos_url": "https://api.github.com/users/Lazloo/repos", "events_url": "https://api.github.com/users/Lazloo/events{/privacy}", "received_events_url": "https://api.github.com/users/Lazloo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-02-04T20:18:24Z", "updated_at": "2019-02-08T22:55:44Z", "closed_at": "2019-02-07T19:55:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey,\r\n\r\nthis question is related to #481. I try to apply gpytorch to a toy data set with two input and two output variables:\r\n\r\n```\r\nimport math\r\nimport torch\r\nimport numpy as np\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\n\r\nn = 20\r\ntrain_x = torch.zeros(pow(n, 2), 2)\r\nfor i in range(n):\r\n    for j in range(n):\r\n        # Each coordinate varies from 0 to 1 in n=100 steps\r\n        train_x[i * n + j][0] = float(i) / (n-1)\r\n        train_x[i * n + j][1] = float(j) / (n-1)\r\n\r\ntrain_y_1 = (torch.sin(train_x[:, 0]) + torch.cos(train_x[:, 1]) * (2 * math.pi) + torch.randn_like(train_x[:, 0]).mul(0.01))/4\r\ntrain_y_2 = torch.sin(train_x[:, 0]) + torch.cos(train_x[:, 1]) * (2 * math.pi) + torch.randn_like(train_x[:, 0]).mul(0.01)\r\n\r\ntrain_y = torch.stack([train_y_1, train_y_2], -1)\r\n\r\ntest_x = torch.rand((n, len(train_x.shape)))\r\ntest_y_1 = (torch.sin(test_x[:, 0]) + torch.cos(test_x[:, 1]) * (2 * math.pi) + torch.randn_like(test_x[:, 0]).mul(0.01))/4\r\ntest_y_2 = torch.sin(test_x[:, 0]) + torch.cos(test_x[:, 1]) * (2 * math.pi) + torch.randn_like(test_x[:, 0]).mul(0.01)\r\ntest_y = torch.stack([test_y_1, test_y_2], -1)\r\n\r\ntrain_x = train_x.unsqueeze(0).repeat(2, 1, 1)\r\ntrain_y = train_y.transpose(-2, -1)\r\n# Own\r\ntorch.manual_seed(1)\r\n```\r\n\r\nFor sacalability I try to use the GridInterpolationKernel\r\n\r\n```\r\nclass MultitaskGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean()\r\n        grid_size = gpytorch.utils.grid.choose_grid_size(train_x)\r\n        self.covar_module = gpytorch.kernels.GridInterpolationKernel(\r\n            gpytorch.kernels.MaternKernel(nu=1.5)\r\n            , grid_size=grid_size, num_dims=train_x.shape[1],\r\n        )\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        # return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\r\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\r\n\r\n# likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood(num_tasks=2)\r\nmodel = MultitaskGPModel(train_x, train_y, likelihood)\r\n\r\n# Find optimal model hyperparameters\r\nmodel.train()\r\nlikelihood.train()\r\n\r\n# Use the adam optimizer\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\r\n], lr=0.1)\r\n\r\n# \"Loss\" for GPs - the marginal log likelihood\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\nn_iter = 50\r\nfor i in range(n_iter):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    # loss = -mll(output, train_y)\r\n    loss = -mll(output, train_y).sum()\r\n    loss.backward()\r\n    # print('Iter %d/%d - Loss: %.3f' % (i + 1, n_iter, loss.item()))\r\n    optimizer.step()\r\n```\r\n\r\nHowever, here I get the Error: \r\n\r\n> RuntimeError: The size of tensor a (2) must match the size of tensor b (400) at non-singleton dimension 0\r\n\r\nWithout the gpytorch.kernels.GridInterpolationKernel everything works fine. Can someone help?\r\n\r\nTHX\r\nLazloo\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/496/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/496/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/483", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/483/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/483/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/483/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/483", "id": 403982600, "node_id": "MDU6SXNzdWU0MDM5ODI2MDA=", "number": 483, "title": "[Test Failure] test_batch_whitened_svgp_gp_regression", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 966002442, "node_id": "MDU6TGFiZWw5NjYwMDI0NDI=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/unit%20tests", "name": "unit tests", "color": "00295b", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2019-01-28T19:59:46Z", "updated_at": "2019-02-04T05:01:14Z", "closed_at": "2019-02-04T05:01:14Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Getting the following test failure on master: \r\n\r\n```\r\nAssertionError: 0.14334218204021454 not less than 0.1\r\n  File \"/usr/local/fbcode/gcc-5-glibc-2.23/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\r\n    yield\r\n  File \"/usr/local/fbcode/gcc-5-glibc-2.23/lib/python3.6/unittest/case.py\", line 605, in run\r\n    testMethod()\r\n  File \"/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/pytorch/gpytorch/test_gpytorch_examples#binary,link-tree/test/examples/test_batch_whitened_svgp_gp_regression.py\", line 167, in test_regression_error_cuda\r\n    self.assertLess(mean_abs_error2.item(), 1e-1)\r\n  File \"/usr/local/fbcode/gcc-5-glibc-2.23/lib/python3.6/unittest/case.py\", line 1208, in assertLess\r\n    self.fail(self._formatMessage(msg, standardMsg))\r\n  File \"/usr/local/fbcode/gcc-5-glibc-2.23/lib/python3.6/unittest/case.py\", line 670, in fail\r\n    raise self.failureException(msg)\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/483/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/483/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/478", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/478/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/478/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/478/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/478", "id": 403313929, "node_id": "MDU6SXNzdWU0MDMzMTM5Mjk=", "number": 478, "title": "Initializing GaussianLikelihood noise broken", "user": {"login": "KeAWang", "id": 11478740, "node_id": "MDQ6VXNlcjExNDc4NzQw", "avatar_url": "https://avatars.githubusercontent.com/u/11478740?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KeAWang", "html_url": "https://github.com/KeAWang", "followers_url": "https://api.github.com/users/KeAWang/followers", "following_url": "https://api.github.com/users/KeAWang/following{/other_user}", "gists_url": "https://api.github.com/users/KeAWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/KeAWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KeAWang/subscriptions", "organizations_url": "https://api.github.com/users/KeAWang/orgs", "repos_url": "https://api.github.com/users/KeAWang/repos", "events_url": "https://api.github.com/users/KeAWang/events{/privacy}", "received_events_url": "https://api.github.com/users/KeAWang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-01-25T20:05:52Z", "updated_at": "2019-01-26T20:30:14Z", "closed_at": "2019-01-26T20:30:14Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "```\r\n>>> import gpytorch\r\n>>> gl = gpytorch.likelihoods.GaussianLikelihood()\r\n>>> gl.initialize(noise=1)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \".../gpytorch/gpytorch/module.py\", line 89, in initialize\r\n    setattr(self, name, val)\r\n  File \"../lib/python3.6/site-packages/torch/nn/modules/module.py\", line 579, in __setattr__\r\n    object.__setattr__(self, name, value)\r\n  File \".../gpytorch/gpytorch/likelihoods/gaussian_likelihood.py\", line 63, in noise\r\n    self.noise_covar.initialize(value)\r\nTypeError: initialize() takes 1 positional argument but 2 were given\r\n```\r\n\r\nraw_noise works though\r\n```\r\n>>> gl.initialize(raw_noise=1)\r\nGaussianLikelihood(\r\n  (noise_covar): HomoskedasticNoise()\r\n)\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/478/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/478/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/475", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/475/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/475/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/475/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/475", "id": 403186413, "node_id": "MDU6SXNzdWU0MDMxODY0MTM=", "number": 475, "title": "Encountered nan in confidence bounds (variational inference)", "user": {"login": "Akella17", "id": 16236287, "node_id": "MDQ6VXNlcjE2MjM2Mjg3", "avatar_url": "https://avatars.githubusercontent.com/u/16236287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Akella17", "html_url": "https://github.com/Akella17", "followers_url": "https://api.github.com/users/Akella17/followers", "following_url": "https://api.github.com/users/Akella17/following{/other_user}", "gists_url": "https://api.github.com/users/Akella17/gists{/gist_id}", "starred_url": "https://api.github.com/users/Akella17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Akella17/subscriptions", "organizations_url": "https://api.github.com/users/Akella17/orgs", "repos_url": "https://api.github.com/users/Akella17/repos", "events_url": "https://api.github.com/users/Akella17/events{/privacy}", "received_events_url": "https://api.github.com/users/Akella17/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-01-25T14:46:19Z", "updated_at": "2019-01-28T14:36:40Z", "closed_at": "2019-01-28T14:36:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "Simple 3D GP Regression using AbstractVariationalGP module and AdditiveGridInterpolationVariationalStrategy:\r\nPlease find the ipython notebook in this link: https://drive.google.com/file/d/1o8IkdLq_nrUF51IFdKyI64ZBLICk5is3/view?usp=sharing\r\nI wanted to know the reason why this might be occurring, and would also like to know if it would have any implications on the overall performance of GP regression (i.e. the kernel means and covariances have been finite and prolonged training seems to fit them better to the training data despite nans in confidence bounds).", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/475/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/475/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/449", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/449/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/449/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/449/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/449", "id": 394913151, "node_id": "MDExOlB1bGxSZXF1ZXN0MjQxNTE2MTk3", "number": 449, "title": "Fix additive regression model", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-12-31T00:22:42Z", "updated_at": "2018-12-31T04:17:30Z", "closed_at": "2018-12-31T04:17:27Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/449", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/449", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/449.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/449.patch", "merged_at": "2018-12-31T04:17:26Z"}, "body": "- Fix issues in the KISS-GP additive regression notebook\r\n- Simplify the interpolation code (we were doing something for CUDA performance that is no longer necessary)", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/449/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/449/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/444", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/444/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/444/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/444/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/444", "id": 394667017, "node_id": "MDExOlB1bGxSZXF1ZXN0MjQxMzU2NTMz", "number": 444, "title": "Fix _unbroadcasted_scale_tril for lazy MVN", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-12-28T16:00:48Z", "updated_at": "2019-01-02T05:57:14Z", "closed_at": "2018-12-31T03:39:03Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/444", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/444", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/444.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/444.patch", "merged_at": null}, "body": "This previously did not use the proper root decomposition (instead it used the full (approximate) covariance matrix). This also makes sure to use the exact cholesky decomposition (as expected by the torch mvn), and not not a low-rank approximation.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/444/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/444/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/438", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/438/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/438/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/438/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/438", "id": 392478558, "node_id": "MDU6SXNzdWUzOTI0Nzg1NTg=", "number": 438, "title": "Numerical issues under new _covar_sq_dist helper", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-12-19T07:49:28Z", "updated_at": "2019-01-16T19:40:23Z", "closed_at": "2019-01-16T19:40:23Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "From #434:\r\n\r\n> I'm happy to switch back, but I want to be very sure that it doesn't affect numerical stability. Can you make sure that we don't have to increase any error bounds on any of the tests?\r\n\r\nUnfortunately, this does significantly affect numerical stability, in particular when using an algorithm for fitting that uses (expanding) line search (such as L-BFGS). With this change many of our tests that previously passed reliably now fail.\r\n\r\nI'm assuming the issue is due to the fact that now the individual components rather than their differences are squared: `x1_norm = x1.pow(2).sum(dim=-1, keepdim=True)`. This causes overflow issues especially when using `torch.float` dtype, so the resulting MVNs have `nan`-valued loc/covar parameters. Switching to `torch.double` fixes many of the instability issues, but that's of course not a good solution when running on the GPU. ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/438/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/438/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/431", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/431/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/431/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/431/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/431", "id": 390441016, "node_id": "MDExOlB1bGxSZXF1ZXN0MjM4MjA3NTQ2", "number": 431, "title": "Simplify and fix batch mode checks", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 867284546, "node_id": "MDU6TGFiZWw4NjcyODQ1NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/refactor", "name": "refactor", "color": "0052cc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-12-12T22:42:43Z", "updated_at": "2018-12-15T03:34:29Z", "closed_at": "2018-12-13T04:15:35Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/431", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/431", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/431.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/431.patch", "merged_at": "2018-12-13T04:15:35Z"}, "body": "This PR dramatically simplifies the batch + multitask checks we did in `ExactGP.__call__` to three lines of code. In addition, it makes progress on handling arbitrary batch dimensions by not explicitly assuming only the first dimension is a batch dimension.\r\n\r\nThis also fixes a bug where we need to update the PredictiveStrategy objects if we expand the train objects to match batch mode test data. We also now use a BatchRepeatLazyTensor to expand `train_train_covar` if needed.\r\n\r\nI also added unit test coverage to `test_batch_gp_regerssion` to make sure this doesn't happen again.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/431/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/431/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/420", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/420/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/420/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/420/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/420", "id": 388840662, "node_id": "MDU6SXNzdWUzODg4NDA2NjI=", "number": 420, "title": "More issues with batch mode in MTGPs", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-12-07T22:45:32Z", "updated_at": "2019-02-22T19:30:40Z", "closed_at": "2019-02-22T19:30:39Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "I'm running into some more issues with (alleged) size incompatibilities when using batch mode for multitask GPs. In particular, \r\n- fitting a MTGP in batch mode fails outright\r\n- fitting a MTPG in non-batch mode works, but evaluating that model in batch mode fails.\r\n\r\nSee [MTGP_batch_errors.ipynb.txt](https://github.com/cornellius-gp/gpytorch/files/2658985/MTGP_batch_errors.ipynb.txt)\r\n\r\n\r\n\r\n@gpleiss, fixing these kind of issues properly without a ton of special casing relies on #369 -  can we prioritize this?  \r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/420/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/420/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/419", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/419/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/419/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/419/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/419", "id": 388788155, "node_id": "MDExOlB1bGxSZXF1ZXN0MjM2OTczMjI3", "number": 419, "title": "Fix dtype bug in MultitaskGaussianLikelihoodKronecker", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-12-07T19:41:30Z", "updated_at": "2018-12-07T19:52:32Z", "closed_at": "2018-12-07T19:52:22Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/419", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/419", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/419.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/419.patch", "merged_at": "2018-12-07T19:52:22Z"}, "body": "This fixes an issue if `MultitaskGaussianLikelihoodKronecker` is used with `torch.double` dtype", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/419/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/419/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/414", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/414/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/414/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/414/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/414", "id": 387989014, "node_id": "MDExOlB1bGxSZXF1ZXN0MjM2MzU2ODUz", "number": 414, "title": "Catch an edge case with batch-> non-batch eval", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-12-05T23:20:23Z", "updated_at": "2018-12-06T14:10:55Z", "closed_at": "2018-12-06T14:10:48Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/414", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/414", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/414.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/414.patch", "merged_at": "2018-12-06T14:10:48Z"}, "body": "This fixes an edge case in which the sequence of operations `batch eval -> non-batch eval` on a non-batch model failed (the reverse sequence succeeded).\r\n\r\nThis special casing is starting to get a little hairy... Not sure if there is a good way of simplifying this. Maybe one way would be to factor out all these check into some utility that takes the `precomputed_cache` and does the appropriate things to it, so the rest of the code can remain relatively clean? \r\n\r\ncc @sdaulton, @bkarrer", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/414/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/414/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/413", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/413/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/413/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/413/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/413", "id": 387911563, "node_id": "MDExOlB1bGxSZXF1ZXN0MjM2Mjk2MjQw", "number": 413, "title": "Diagonal correction for SGPR", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-12-05T19:33:43Z", "updated_at": "2018-12-05T19:37:46Z", "closed_at": "2018-12-05T19:37:40Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/413", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/413", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/413.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/413.patch", "merged_at": "2018-12-05T19:37:39Z"}, "body": "Fixex #257", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/413/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/413/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/405", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/405/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/405/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/405/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/405", "id": 385871196, "node_id": "MDU6SXNzdWUzODU4NzExOTY=", "number": 405, "title": "Module.initialize should work with transformed parameters", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-29T18:37:39Z", "updated_at": "2018-12-03T05:21:31Z", "closed_at": "2018-12-03T05:21:31Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "`Module.initialize` right now only works for actual parameters. It should also work for transformed parameters.\r\n\r\nFor example, the following lines work:\r\n\r\n```python\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood(param_transform=torch.exp)\r\nlikelihood.initialize(raw_noise=math.log(5))\r\nprint(likelihood.noise.item())  #5.\r\n```\r\n\r\nSimilarly:\r\n```python\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood(param_transform=torch.exp)\r\nlikelihood.initialize(raw_noise=torch.tensor(math.log(5)))\r\nprint(likelihood.noise.item())  #5.\r\n```\r\n\r\nThe following line silently errors:\r\n```python\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood(param_transform=torch.exp)\r\nlikelihood.initialize(noise=5)\r\nprint(likelihood.noise.item())  #1.\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/405/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/405/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/398", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/398/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/398/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/398/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/398", "id": 384533570, "node_id": "MDU6SXNzdWUzODQ1MzM1NzA=", "number": 398, "title": "Size mismatch in batch mode GaussianLikelihood", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-11-26T22:13:58Z", "updated_at": "2018-11-29T19:45:19Z", "closed_at": "2018-11-29T19:45:19Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "@Balandat just ran in to an issue that I tracked back to this line:\r\nhttps://github.com/cornellius-gp/gpytorch/blob/00ddfc844820c7682a50919fcdb6eaf4e9c50ab3/gpytorch/likelihoods/gaussian_likelihood.py#L31\r\n\r\nShould this be:\r\n```python\r\nshape = mean.shape\r\n```\r\nHaven't we been letting batch means be `b x n`, meaning shape would be `[b]` and then as written `noise_covar` will be `b x b x b` instead of `b x n x n`?", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/398/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/398/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/364", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/364/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/364/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/364/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/364", "id": 379464672, "node_id": "MDU6SXNzdWUzNzk0NjQ2NzI=", "number": 364, "title": "periodic kernel predictive variance ", "user": {"login": "sumitsk", "id": 7646621, "node_id": "MDQ6VXNlcjc2NDY2MjE=", "avatar_url": "https://avatars.githubusercontent.com/u/7646621?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sumitsk", "html_url": "https://github.com/sumitsk", "followers_url": "https://api.github.com/users/sumitsk/followers", "following_url": "https://api.github.com/users/sumitsk/following{/other_user}", "gists_url": "https://api.github.com/users/sumitsk/gists{/gist_id}", "starred_url": "https://api.github.com/users/sumitsk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sumitsk/subscriptions", "organizations_url": "https://api.github.com/users/sumitsk/orgs", "repos_url": "https://api.github.com/users/sumitsk/repos", "events_url": "https://api.github.com/users/sumitsk/events{/privacy}", "received_events_url": "https://api.github.com/users/sumitsk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-11-10T21:48:29Z", "updated_at": "2018-11-10T23:24:01Z", "closed_at": "2018-11-10T23:24:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "In the simple gp regression notebook, replacing RBF kernel with Periodic Kernel throws this runtime error while making predictions:\r\n\r\n```\r\nThe kernel PeriodicKernel is not equipped to handle and diag. Expected size torch.Size([1, 51]). Got size torch.Size([1, 1, 51]) \r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/364/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/364/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/348", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/348/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/348/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/348/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/348", "id": 377196496, "node_id": "MDU6SXNzdWUzNzcxOTY0OTY=", "number": 348, "title": "GPR fails with LBFGS optimizer ", "user": {"login": "sumitsk", "id": 7646621, "node_id": "MDQ6VXNlcjc2NDY2MjE=", "avatar_url": "https://avatars.githubusercontent.com/u/7646621?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sumitsk", "html_url": "https://github.com/sumitsk", "followers_url": "https://api.github.com/users/sumitsk/followers", "following_url": "https://api.github.com/users/sumitsk/following{/other_user}", "gists_url": "https://api.github.com/users/sumitsk/gists{/gist_id}", "starred_url": "https://api.github.com/users/sumitsk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sumitsk/subscriptions", "organizations_url": "https://api.github.com/users/sumitsk/orgs", "repos_url": "https://api.github.com/users/sumitsk/repos", "events_url": "https://api.github.com/users/sumitsk/events{/privacy}", "received_events_url": "https://api.github.com/users/sumitsk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-11-04T21:25:15Z", "updated_at": "2018-11-29T01:42:09Z", "closed_at": "2018-11-29T01:42:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "Running a simple 1D GP regression (RBF kernel) sporadically throws runtime error when using `LBFGS` optimizer. This happens when MLL loss suddenly increases by a big value. ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/348/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/348/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/343", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/343/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/343/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/343/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/343", "id": 377057971, "node_id": "MDExOlB1bGxSZXF1ZXN0MjI4MTIwNDY0", "number": 343, "title": "Fix interpolation boundary with one test point", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-03T14:12:26Z", "updated_at": "2018-11-04T13:32:20Z", "closed_at": "2018-11-04T13:32:17Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/343", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/343", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/343.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/343.patch", "merged_at": "2018-11-04T13:32:17Z"}, "body": "Fixes #250 . The issue has to do with what I think is strange behavior with calling `torch.nonzero` on scalars:\r\n\r\n```python\r\ntest_scalar = torch.tensor(1.)\r\ntest_vec = torch.tensor([1.])\r\ntorch.nonzero(scalar) # Returns an empty tensor that can't be used for indexing\r\ntorch.nonzero(test_vec) # Returns torch.tensor([0], dtype=torch.int64)\r\n```\r\n\r\nJust trying to work through our back log of issues.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/343/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/343/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/342", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/342/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/342/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/342/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/342", "id": 377012200, "node_id": "MDExOlB1bGxSZXF1ZXN0MjI4MDkyNTAy", "number": 342, "title": "Fix batch vs standard prediction inconsistencies", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-11-03T01:43:49Z", "updated_at": "2018-11-07T18:43:54Z", "closed_at": "2018-11-04T13:37:08Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/342", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/342", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/342.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/342.patch", "merged_at": "2018-11-04T13:37:08Z"}, "body": "Mostly solves #340, with the one exception that I couldn't get it so that we don't have to replicate the caches for batch multitask. Specifically, batch multitask fails without: https://github.com/cornellius-gp/gpytorch/blob/85c4907cc9a8c49cc440d9c19bf7e788fd00ea1c/gpytorch/models/exact_gp.py#L132\r\n\r\nBasically this PR makes two changes:\r\n1. Two of the error checks in LazyTensor.matmul were outright wrong, in the sense that matmul with those sizes works perfectly fine on both standard tensors and lazy tensors. For example this works just fine for both tensors and lazy tensors, despite what the error check said:\r\n    ```python\r\n    mat1 = torch.randn(3, 51, 100)\r\n    mat2 = torch.randn(100)\r\n    res = mat1.matmul(mat2) # Works fine\r\n    ```\r\n2. `exact_predictive_*` now just takes in `non_batch_train` if the train inputs are not batched. This lets us compute the caches without repeating work. The reason I fixed it this way is because I don't think there is a better way to do it without making wasted kernel calls.\r\n\r\n**Note:** This PR doesn't implement the batch-batch mode `b' x b x n x d` that Max wanted because that is way way beyond the scope of just fixing a couple bugs here.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/342/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/342/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/338", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/338/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/338/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/338/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/338", "id": 375088225, "node_id": "MDExOlB1bGxSZXF1ZXN0MjI2NjE2MjYy", "number": 338, "title": "Fix bug in MatmulLazyTensor derivative return", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-29T15:56:54Z", "updated_at": "2018-10-29T16:55:38Z", "closed_at": "2018-10-29T16:55:29Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/338", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/338", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/338.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/338.patch", "merged_at": "2018-10-29T16:55:29Z"}, "body": "On master, `MatmulLazyTensor.quad_form_derivative` fails if the sub lazy tensors return derivatives with mutliple components. This fixes the return value to merge the two derivative components in to a single tuple.\r\n\r\ncc @Balandat ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/338/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/338/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/333", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/333/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/333/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/333/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/333", "id": 372975961, "node_id": "MDExOlB1bGxSZXF1ZXN0MjI1MDE5ODQy", "number": 333, "title": "Throw error if ard_num_dims doesn't match the dimensionality", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-10-23T12:33:18Z", "updated_at": "2018-10-23T12:43:21Z", "closed_at": "2018-10-23T12:43:16Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/333", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/333", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/333.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/333.patch", "merged_at": "2018-10-23T12:43:16Z"}, "body": "Fixes #328 ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/333/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/333/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/324", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/324/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/324/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/324/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/324", "id": 370352964, "node_id": "MDExOlB1bGxSZXF1ZXN0MjIzMDUwMjg4", "number": 324, "title": "Do not squeeze non-batch results in RootDecomposition backward", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-10-15T21:33:56Z", "updated_at": "2018-10-17T12:49:35Z", "closed_at": "2018-10-17T12:49:25Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/324", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/324", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/324.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/324.patch", "merged_at": "2018-10-17T12:49:25Z"}, "body": "This caused issues when computing the gradients of a function computed from the samples drawn from the posterior of a MTGP at a single point.\r\n\r\nI'm kind of surprised that (at least locally) all tests pass, but oh well.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/324/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/324/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/307", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/307/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/307/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/307/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/307", "id": 365548391, "node_id": "MDExOlB1bGxSZXF1ZXN0MjE5NDQzMDUw", "number": 307, "title": "Kernels now take `diag, dim_groups` as arguments (fixes issues with ARD kernels)", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 623304448, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDg=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 11, "created_at": "2018-10-01T16:47:11Z", "updated_at": "2018-10-02T04:30:57Z", "closed_at": "2018-10-02T04:02:07Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/307", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/307", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/307.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/307.patch", "merged_at": "2018-10-02T04:02:07Z"}, "body": "This should fix several issues we have with ARD batch kernels.\r\n\r\nTLDR:\r\n- `Kernel.forward` now takes 4 arguments: `x1`, `x2`, `diag`, and `dim_groups`\r\n  - `diag` tells the kernel to be computed in diagonal mode (variances only, no covariances)\r\n  - `dim_groups=<k>` computes k batches of kernels: each operating on one of `k` subsets of dimensions. (This is to be used with additive kernels, SKI, etc.)\r\n- For most kernel implementations - you won't have to worry about these arguments much. They just need to be passed into `_create_input_grid`\r\n\r\nThe motivation for this: for kernel diagonals and additive kernels, we have been relying on hacking the batch dimension. For example, computing the kernel diagonal of a `n x d` input can be done easily if we make the input `n x 1 x d`. Similarly, additive kernels can be efficiently computed if we make the `n x d` input a `d x n x 1` input and then sum along the batch dimension. This works well if we don't have ARD or batch-specific parameters, but now we do and it causes breaking issues. (See #249)\r\n\r\nTo make sure that this isn't an issue, but also keep everything easily programmable:\r\n- We won't do batch-dimension hacking anymore\r\n- Computing kernel diagonals/additive kernels is now done explicitly by passing in the `dim`/`dim_groups` arguments\r\n- For most kernels, this won't require any extra code. Most kernels now use the `_create_input_grid` helper, which automatically will do the correct thing for the diag/dim_groups modes.\r\n\r\nI've included some documentation in the Kernel base_class to describe this for people who want to code up their own kernels.\r\n\r\nThis is currently a WIP - hopefully will be done in ~4 hours.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/307/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/307/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/296", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/296/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/296/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/296/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/296", "id": 364721890, "node_id": "MDExOlB1bGxSZXF1ZXN0MjE4ODM5NzEw", "number": 296, "title": "Fix LazyTensor.__getitem__", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 966002442, "node_id": "MDU6TGFiZWw5NjYwMDI0NDI=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/unit%20tests", "name": "unit tests", "color": "00295b", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-09-28T02:50:20Z", "updated_at": "2018-09-28T15:19:39Z", "closed_at": "2018-09-28T15:19:35Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/296", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/296", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/296.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/296.patch", "merged_at": "2018-09-28T15:19:34Z"}, "body": "This fixes #159, and is a step towards #236.\r\n\r\n__getitem__ would fail for batch LazyTensors if you supplied two or more tensor-based indices. E.g. `lazy_tensor[torch.tensor([0, 0, 1]), torch.tensor([2, 1, 2]), :]`.\r\n\r\nThis fixes the default LT.__getitem__, all custom LT.__getitem__s, and adds a lot of unit tests.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/296/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/296/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/295", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/295/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/295/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/295/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/295", "id": 364551856, "node_id": "MDExOlB1bGxSZXF1ZXN0MjE4NzExMzQ3", "number": 295, "title": "Fix add diag", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-09-27T16:15:11Z", "updated_at": "2018-09-27T16:47:19Z", "closed_at": "2018-09-27T16:47:16Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/295", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/295", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/295.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/295.patch", "merged_at": "2018-09-27T16:47:16Z"}, "body": "- LazyTensor add_diag now handles lots of different cases (batch mode, scalars, etc.) and unit tests/arg checks for each of them\r\n- `gpytorch.add_diag` now uses the LazyTensor method (no custom torch.tensor method)\r\n\r\nFixes #294 ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/295/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/295/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/292", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/292/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/292/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/292/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/292", "id": 364168416, "node_id": "MDU6SXNzdWUzNjQxNjg0MTY=", "number": 292, "title": "Inconsistent behavior of .diag() method for different Lazy Tensors in batch mode", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-09-26T19:05:59Z", "updated_at": "2018-10-01T14:41:07Z", "closed_at": "2018-10-01T14:41:07Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "E.g: \r\n\r\n```\r\n> cv.lazy_vars\r\n[<gpytorch.lazy.lazy_evaluated_kernel_tensor.LazyEvaluatedKernelTensor at 0x7f6139087278>,\r\n <gpytorch.lazy.matmul_lazy_tensor.MatmulLazyTensor at 0x7f6139087780>]\r\n\r\n> [lv.size() for lv in cv.lazy_vars]\r\n[torch.Size([2, 1, 1]), torch.Size([2, 1, 1])]\r\n\r\n>diags = [lazy_var.diag().contiguous() for lazy_var in cv.lazy_vars]\r\n>[diag.size() for diag in diags]\r\n[torch.Size([2]), torch.Size([2, 1])]\r\n```\r\n\r\nThis causes inconsistencies when using batch mode. My suggestion is to ensure that all `.diag()` calls reduce the last two dimensions of the tensor, i.e. for a `b1 x b2 x n x n` LazyTensor this would return a Tensor of Size `b1 x b2 x n`. This is the same as the behavior of `torch.diagonal(X, dim1=-2, dim2=-1)`.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/292/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/292/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/274", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/274/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/274/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/274/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/274", "id": 361114945, "node_id": "MDU6SXNzdWUzNjExMTQ5NDU=", "number": 274, "title": "Fowarding through RBFKernel in batch-mode broken", "user": {"login": "samuelstanton", "id": 22999782, "node_id": "MDQ6VXNlcjIyOTk5Nzgy", "avatar_url": "https://avatars.githubusercontent.com/u/22999782?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samuelstanton", "html_url": "https://github.com/samuelstanton", "followers_url": "https://api.github.com/users/samuelstanton/followers", "following_url": "https://api.github.com/users/samuelstanton/following{/other_user}", "gists_url": "https://api.github.com/users/samuelstanton/gists{/gist_id}", "starred_url": "https://api.github.com/users/samuelstanton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samuelstanton/subscriptions", "organizations_url": "https://api.github.com/users/samuelstanton/orgs", "repos_url": "https://api.github.com/users/samuelstanton/repos", "events_url": "https://api.github.com/users/samuelstanton/events{/privacy}", "received_events_url": "https://api.github.com/users/samuelstanton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2018-09-18T02:47:04Z", "updated_at": "2018-09-19T21:11:21Z", "closed_at": "2018-09-19T19:49:01Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The recent changes to master have basically completely broken batch mode. This example is for the forward method in `kernels.RBFKernel`. As an example, consider the following code snippet\r\n```\r\nimport torch\r\nimport gpytorch\r\n\r\nclass BatchGP(gpytorch.models.ExactGP):\r\n    def __init__(self, train_inputs, train_targets, likelihood):\r\n        super(BatchGP, self).__init__(train_inputs, train_targets, likelihood)\r\n        self.mean_module = gpytorch.means.ConstantMean(batch_size=2)\r\n        self.covar_module = gpytorch.kernels.RBFKernel(ard_num_dims=3, batch_size=2)\r\n        self.register_parameter('log_outputscale', torch.nn.Parameter(torch.zeros(2, 1, 1)))\r\n        \r\n    def forward(self, inputs):\r\n        inputs = inputs.unsqueeze(0)\r\n        inputs = inputs.expand(2, -1, -1)\r\n        mean = self.mean_module(inputs)\r\n        prescale_covar = self.covar_module(inputs).evaluate()\r\n        covar = self.log_outputscale.exp() * prescale_covar\r\n\r\n        return self.likelihood(gpytorch.random_variables.GaussianRandomVariable(mean, covar))\r\n\r\ntrain_x = torch.rand(5, 3)\r\ntrain_y = torch.rand(5, 2)\r\nlikelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n\r\nbatch_gp = BatchGP(train_x, train_y, likelihood)\r\n\r\nbatch_gp(train_x)\r\n```\r\nOut:\r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-11-bbf86dd62a62> in <module>()\r\n     24 batch_gp = BatchGP(train_x, train_y, likelihood)\r\n     25 \r\n---> 26 batch_gp(train_x)\r\n\r\n~/Code/gpytorch/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)\r\n     79                 if not all(torch.equal(train_input, input) for train_input, input in zip(train_inputs, inputs)):\r\n     80                     raise RuntimeError(\"You must train on the training inputs!\")\r\n---> 81             return super(ExactGP, self).__call__(*inputs, **kwargs)\r\n     82 \r\n     83         # Posterior mode\r\n\r\n~/Code/gpytorch/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n    178 \r\n    179     def __call__(self, *inputs, **kwargs):\r\n--> 180         outputs = self.forward(*inputs, **kwargs)\r\n    181         if torch.is_tensor(outputs) or isinstance(outputs, RandomVariable) or isinstance(outputs, LazyTensor):\r\n    182             return outputs\r\n\r\n<ipython-input-11-bbf86dd62a62> in forward(self, inputs)\r\n     13         inputs = inputs.expand(2, -1, -1)\r\n     14         mean = self.mean_module(inputs)\r\n---> 15         prescale_covar = self.covar_module(inputs).evaluate()\r\n     16         covar = self.log_outputscale.exp() * prescale_covar\r\n     17 \r\n\r\n~/Code/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate(self)\r\n    123 \r\n    124     def evaluate(self):\r\n--> 125         return self.evaluate_kernel().evaluate()\r\n    126 \r\n    127     def exact_predictive_mean(self, full_mean, train_labels, n_train, likelihood, precomputed_cache=None):\r\n\r\n~/Code/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)\r\n    104                 x2 = self.x2\r\n    105 \r\n--> 106             self._cached_kernel_eval = super(Kernel, self.kernel).__call__(x1, x2, **self.params)\r\n    107             if self.squeeze_row:\r\n    108                 self._cached_kernel_eval.squeeze_(-2)\r\n\r\n~/Code/gpytorch/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n    178 \r\n    179     def __call__(self, *inputs, **kwargs):\r\n--> 180         outputs = self.forward(*inputs, **kwargs)\r\n    181         if torch.is_tensor(outputs) or isinstance(outputs, RandomVariable) or isinstance(outputs, LazyTensor):\r\n    182             return outputs\r\n\r\n~/Code/gpytorch/gpytorch/kernels/rbf_kernel.py in forward(self, x1, x2)\r\n     94     def forward(self, x1, x2):\r\n     95         x1_, x2_ = self._create_input_grid(x1, x2)\r\n---> 96         x1_ = x1_.div(self.lengthscale)\r\n     97         x2_ = x2_.div(self.lengthscale)\r\n     98 \r\n\r\nRuntimeError: The size of tensor a (5) must match the size of tensor b (2) at non-singleton dimension 1\r\n```\r\n\r\nIf you go in and look at the dimension of the tensors, `x1_.size()` is `[B x N x 1 x D]` and `self.lengthscale.size()` is `[B x 1 x D]`", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/274/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/274/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/271", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/271/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/271/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/271/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/271", "id": 361041070, "node_id": "MDU6SXNzdWUzNjEwNDEwNzA=", "number": 271, "title": "Lapack Error in TestSimpleGPRegression", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-09-17T20:56:49Z", "updated_at": "2018-09-20T14:36:41Z", "closed_at": "2018-09-20T14:36:41Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "I'm getting a reproducible `RuntimeError: Lapack Error syev : 9 off-diagonal elements didn't converge to zero at caffe2/aten/src/TH/generic/THTensorLapack.cpp:395` in `test_simple_gp_regression.py` with this.\r\n\r\nNot sure whether related to #266 or #270. @gpleiss, could you take a look?", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/271/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/271/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/268", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/268/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/268/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/268/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/268", "id": 359689402, "node_id": "MDU6SXNzdWUzNTk2ODk0MDI=", "number": 268, "title": "Root decomposition fails for simple matrices", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-09-12T23:33:34Z", "updated_at": "2018-11-16T03:27:52Z", "closed_at": "2018-11-16T03:27:52Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Observing the following:\r\n\r\n```\r\nI = torch.eye(4)\r\nNonLazyTensor(I).root_decomposition()\r\n\r\n# this will often return nans, and sometimes an approx. solution\r\ntensor([[nan, nan, nan],\r\n        [nan, nan, nan],\r\n        [nan, nan, nan],\r\n        [nan, nan, nan]])\r\n\r\nInoise = I + 1e-3 * torch.diag(torch.rand(4))\r\nNonLazyTensor(Inoise).root_decomposition()\r\n\r\ntensor([[ 1.6966e-05, -1.0755e-05,  1.0002e+00, -1.2987e-04],\r\n        [-1.0000e+00, -1.4206e-03,  1.3592e-05,  5.5494e-06],\r\n        [ 1.4198e-03, -1.0000e+00, -1.9231e-06, -1.2009e-05],\r\n        [-5.9421e-06,  1.3196e-05, -1.0358e-04, -1.0005e+00]])\r\n\r\nDdiag = torch.ones(4)\r\nDiagLazyTensor(Ddiag).root_decomposition()\r\n\r\n# again most of the time this is nan and sometimes an approx solution\r\ntensor([[nan, nan, nan],\r\n        [nan, nan, nan],\r\n        [nan, nan, nan],\r\n        [nan, nan, nan]])\r\n\r\nDdiagnoise = Ddiag  + 1e-3 * torch.rand(4)\r\nDiagLazyTensor(Ddiagnoise).root_decomposition()\r\n\r\ntensor([[ 0.0002,  1.0002,  0.0010, -0.0000],\r\n        [ 0.9999,  0.0002, -0.0001,  0.0001],\r\n        [ 0.0002,  0.0002, -0.0004, -1.0006],\r\n        [-0.0003, -0.0010,  1.0003, -0.0000]])\r\n\r\n```\r\n\r\nAt least for `DiagLazyTensor` we should just short-circuit the special-case and just return `DiagLazyTensor(torch.sqrt(input_diag))`. Not sure about the other cases, things seem to work reasonably if the matrices have off-diagonal elements.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/268/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/268/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/267", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/267/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/267/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/267/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/267", "id": 359669629, "node_id": "MDU6SXNzdWUzNTk2Njk2Mjk=", "number": 267, "title": "Batch-mode not properly supported by priors", "user": {"login": "samuelstanton", "id": 22999782, "node_id": "MDQ6VXNlcjIyOTk5Nzgy", "avatar_url": "https://avatars.githubusercontent.com/u/22999782?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samuelstanton", "html_url": "https://github.com/samuelstanton", "followers_url": "https://api.github.com/users/samuelstanton/followers", "following_url": "https://api.github.com/users/samuelstanton/following{/other_user}", "gists_url": "https://api.github.com/users/samuelstanton/gists{/gist_id}", "starred_url": "https://api.github.com/users/samuelstanton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samuelstanton/subscriptions", "organizations_url": "https://api.github.com/users/samuelstanton/orgs", "repos_url": "https://api.github.com/users/samuelstanton/repos", "events_url": "https://api.github.com/users/samuelstanton/events{/privacy}", "received_events_url": "https://api.github.com/users/samuelstanton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-09-12T22:04:43Z", "updated_at": "2018-10-02T01:56:41Z", "closed_at": "2018-10-02T01:56:41Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Suppose you create `FooGP`, a subclass of `gpytorch.models.ExactGP` and have an instance `foo_gp`. We specify\r\n```\r\nfoo_gp.covar_module = gpytorch.kernels.RBFKernel(ard_num_dims=D, log_lengthscale_prior=gpytorch.priors.SmoothedBoxPrior(-3, 3), batch_size=B)\r\n```\r\n\r\nCalling `foo_gp.foward()` results in the following error (here `B=5`, `D=6`)\r\n\r\n``` \r\n~/Code/gpytorch/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n    160 \r\n    161     def __call__(self, *inputs, **kwargs):\r\n--> 162         outputs = self.forward(*inputs, **kwargs)\r\n    163         if torch.is_tensor(outputs) or isinstance(outputs, RandomVariable) or isinstance(outputs, LazyVariable):\r\n    164             return outputs\r\n\r\n~/Code/gpytorch/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, output, target)\r\n     62         # Add log probs of priors on the parameters\r\n     63         for _, param, prior in self.named_parameter_priors():\r\n---> 64             res.add_(prior.log_prob(param).sum())\r\n     65         for _, prior, params, transform in self.named_derived_priors():\r\n     66             res.add_(prior.log_prob(transform(*params)).sum())\r\n\r\n~/Code/gpytorch/gpytorch/priors/prior.py in log_prob(self, parameter)\r\n     48     def log_prob(self, parameter):\r\n     49         \"\"\"Returns the log-probability of the parameter value under the prior.\"\"\"\r\n---> 50         return self._log_prob(parameter.exp() if self.log_transform else parameter)\r\n     51 \r\n     52     def _initialize_distributions(self):\r\n\r\n~/Code/gpytorch/gpytorch/priors/smoothed_box_prior.py in _log_prob(self, parameter)\r\n     65     def _log_prob(self, parameter):\r\n     66         # x = \"distances from box`\"\r\n---> 67         X = ((parameter.view(self.a.shape) - self._c).abs_() - self._r).clamp(min=0)\r\n     68         return sum(p.log_prob(x) for p, x in zip(self._tails, X)) - self._M.sum()\r\n     69 \r\n\r\nRuntimeError: invalid argument 2: size '[1]' is invalid for input with 5 elements at /opt/conda/conda-bld/pytorch_1533672544752/work/aten/src/TH/THStorage.cpp:84 \r\n```\r\n\r\nHowever, if we say\r\n```\r\nfoo_gp.covar_module = gpytorch.kernels.RBFKernel(ard_num_dims=D, log_lengthscale_prior=gpytorch.priors.SmoothedBoxPrior(-3, 3, size=(B, D)), batch_size=B)\r\n```\r\n\r\nWe get this error\r\n```\r\n----> 4 test_gp = ExactRBFGP(test_inputs, test_targets, likelihood)\r\n\r\n<ipython-input-49-10157c928ca4> in __init__(self, train_inputs, train_targets, likelihood)\r\n     11         lengthscale_size = (self.batch_size, self.input_dim)\r\n     12         self.covar_module = gpytorch.kernels.RBFKernel(ard_num_dims=self.input_dim,\r\n---> 13                                                        log_lengthscale_prior=gpytorch.priors.SmoothedBoxPrior(-3, 3, size=lengthscale_size),\r\n     14                                                        batch_size=self.batch_size)\r\n     15         outputscale_size = (self.batch_size, 1, 1)\r\n\r\n~/Code/gpytorch/gpytorch/priors/smoothed_box_prior.py in __init__(self, a, b, sigma, log_transform, size)\r\n     26     def __init__(self, a, b, sigma=0.01, log_transform=False, size=None):\r\n     27         if isinstance(a, Number) and isinstance(b, Number):\r\n---> 28             a = torch.full((size or 1,), float(a))\r\n     29             b = torch.full((size or 1,), float(b))\r\n     30         elif not (torch.is_tensor(a) and torch.is_tensor(b)):\r\n\r\nTypeError: 'tuple' object cannot be interpreted as an integer \r\n```\r\n\r\nThis suggests that batch mode is not properly supported by some (all?) priors.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/267/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/267/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/257", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/257/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/257/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/257/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/257", "id": 358775052, "node_id": "MDU6SXNzdWUzNTg3NzUwNTI=", "number": 257, "title": "SGPR should use diagonal correction", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-09-10T20:09:31Z", "updated_at": "2018-12-05T19:38:12Z", "closed_at": "2018-12-05T19:38:12Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/257/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/257/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/250", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/250/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/250/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/250/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/250", "id": 356274771, "node_id": "MDU6SXNzdWUzNTYyNzQ3NzE=", "number": 250, "title": "Multitask KISS-GP single test point error", "user": {"login": "tzoiker", "id": 6230141, "node_id": "MDQ6VXNlcjYyMzAxNDE=", "avatar_url": "https://avatars.githubusercontent.com/u/6230141?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tzoiker", "html_url": "https://github.com/tzoiker", "followers_url": "https://api.github.com/users/tzoiker/followers", "following_url": "https://api.github.com/users/tzoiker/following{/other_user}", "gists_url": "https://api.github.com/users/tzoiker/gists{/gist_id}", "starred_url": "https://api.github.com/users/tzoiker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tzoiker/subscriptions", "organizations_url": "https://api.github.com/users/tzoiker/orgs", "repos_url": "https://api.github.com/users/tzoiker/repos", "events_url": "https://api.github.com/users/tzoiker/events{/privacy}", "received_events_url": "https://api.github.com/users/tzoiker/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-09-02T11:30:45Z", "updated_at": "2018-11-04T13:32:17Z", "closed_at": "2018-11-04T13:32:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "The problem from #247 seems to preserve for the particular single test points, e.g., if the grid is\r\n `[-3.3333, -1.6667,  0.0000,  1.6667,  3.3333]` when provided `grid_size=5` and `grid_bounds=[(-2,2)]`, then prediction will fail on any single test point outside of the range of `[0.0000,  1.6667]` (notebook attached):\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-14-dd2c9e04445d> in <module>()\r\n      1 # Does not work\r\n      2 test_x = torch.FloatTensor([-0.1]).unsqueeze(1)\r\n----> 3 model(test_x)\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)\r\n    142                 n_train=n_train,\r\n    143                 likelihood=self.likelihood,\r\n--> 144                 precomputed_cache=self.mean_cache,\r\n    145             )\r\n    146             predictive_covar, covar_cache = exact_predictive_covar(\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/functions/__init__.py in exact_predictive_mean(full_covar, full_mean, train_labels, n_train, likelihood, precomputed_cache)\r\n     89 \r\n     90         full_covar = NonLazyVariable(full_covar)\r\n---> 91     return full_covar.exact_predictive_mean(full_mean, train_labels, n_train, likelihood, precomputed_cache)\r\n     92 \r\n     93 \r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_variable.py in exact_predictive_mean(self, full_mean, train_labels, n_train, likelihood, precomputed_cache)\r\n    124         else:\r\n    125             return super(LazyEvaluatedKernelVariable, self).exact_predictive_mean(\r\n--> 126                 full_mean, train_labels, n_train, likelihood, precomputed_cache\r\n    127             )\r\n    128 \r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_variable.py in exact_predictive_mean(self, full_mean, train_labels, n_train, likelihood, precomputed_cache)\r\n    427         else:\r\n    428             test_train_covar = self[n_train:, :n_train]\r\n--> 429         res = test_train_covar.matmul(precomputed_cache)\r\n    430         if res.ndimension() == 3:\r\n    431             res = res.squeeze(-1)\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_variable.py in matmul(self, tensor)\r\n    632             raise RuntimeError\r\n    633 \r\n--> 634         func = Matmul(self.representation_tree())\r\n    635         return func(tensor, *self.representation())\r\n    636 \r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_variable.py in representation_tree(self)\r\n    112 \r\n    113     def representation_tree(self):\r\n--> 114         return LazyVariableRepresentationTree(self.evaluate_kernel())\r\n    115 \r\n    116     def evaluate(self):\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_variable.py in evaluate_kernel(self)\r\n     96                 x2 = self.x2\r\n     97 \r\n---> 98             self._cached_kernel_eval = super(Kernel, self.kernel).__call__(x1, x2, **self.params)\r\n     99             if self.squeeze_row:\r\n    100                 self._cached_kernel_eval.squeeze_(-2)\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n    160 \r\n    161     def __call__(self, *inputs, **kwargs):\r\n--> 162         outputs = self.forward(*inputs, **kwargs)\r\n    163         if torch.is_tensor(outputs) or isinstance(outputs, RandomVariable) or isinstance(outputs, LazyVariable):\r\n    164             return outputs\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/kernels/multitask_kernel.py in forward(self, x1, x2)\r\n     61     def forward(self, x1, x2):\r\n     62         covar_i = self.task_covar_module.covar_matrix\r\n---> 63         covar_x = self.data_covar_module.forward(x1, x2)\r\n     64         if covar_x.size(0) == 1:\r\n     65             covar_x = covar_x[0]\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/kernels/grid_interpolation_kernel.py in forward(self, x1, x2, **kwargs)\r\n     56             base_lazy_var = base_lazy_var.repeat(x1.size(0), 1, 1)\r\n     57 \r\n---> 58         left_interp_indices, left_interp_values = self._compute_grid(x1)\r\n     59         if torch.equal(x1.data, x2.data):\r\n     60             right_interp_indices = left_interp_indices\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/kernels/grid_interpolation_kernel.py in _compute_grid(self, inputs)\r\n     39         batch_size, n_data, n_dimensions = inputs.size()\r\n     40         inputs = inputs.view(batch_size * n_data, n_dimensions)\r\n---> 41         interp_indices, interp_values = Interpolation().interpolate(Variable(self.grid), inputs)\r\n     42         interp_indices = interp_indices.view(batch_size, n_data, -1)\r\n     43         interp_values = interp_values.view(batch_size, n_data, -1)\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/utils/interpolation.py in interpolate(self, x_grid, x_target, interp_points)\r\n    114                     dim_interp_values[left_boundary_pts[j], :] = 0\r\n    115                     dim_interp_values[left_boundary_pts[j], closest_from_first[j]] = 1\r\n--> 116                     lower_grid_pt_idxs[left_boundary_pts[j]] = 0\r\n    117 \r\n    118             right_boundary_pts = torch.nonzero(lower_grid_pt_idxs > num_grid_points - num_coefficients)\r\n\r\nIndexError: too many indices for tensor of dimension 0\r\n```\r\n[KISS-GP-multitask.ipynb.zip](https://github.com/cornellius-gp/gpytorch/files/2343245/KISS-GP-multitask.ipynb.zip)", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/250/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/250/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/249", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/249/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/249/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/249/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/249", "id": 356228973, "node_id": "MDU6SXNzdWUzNTYyMjg5NzM=", "number": 249, "title": "KISS-GP + RBF kernel separate lengthscales error", "user": {"login": "tzoiker", "id": 6230141, "node_id": "MDQ6VXNlcjYyMzAxNDE=", "avatar_url": "https://avatars.githubusercontent.com/u/6230141?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tzoiker", "html_url": "https://github.com/tzoiker", "followers_url": "https://api.github.com/users/tzoiker/followers", "following_url": "https://api.github.com/users/tzoiker/following{/other_user}", "gists_url": "https://api.github.com/users/tzoiker/gists{/gist_id}", "starred_url": "https://api.github.com/users/tzoiker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tzoiker/subscriptions", "organizations_url": "https://api.github.com/users/tzoiker/orgs", "repos_url": "https://api.github.com/users/tzoiker/repos", "events_url": "https://api.github.com/users/tzoiker/events{/privacy}", "received_events_url": "https://api.github.com/users/tzoiker/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-09-01T20:01:45Z", "updated_at": "2020-06-08T19:14:30Z", "closed_at": "2018-10-02T04:12:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "In KISS-GP setting with RBF kernel, for example, in 2D case (notebook attached), setting `ard_num_dims=2` gives the following error during loss calculation:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-144-12b763efd692> in <module>()\r\n     19     output = model(train_x)\r\n     20     # TODO: Fix this view call!!\r\n---> 21     loss = -mll(output, train_y)\r\n     22     loss.backward()\r\n     23     print('Iter %d/%d - Loss: %.3f' % (i + 1, n_iter, loss.item()))\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n    160 \r\n    161     def __call__(self, *inputs, **kwargs):\r\n--> 162         outputs = self.forward(*inputs, **kwargs)\r\n    163         if torch.is_tensor(outputs) or isinstance(outputs, RandomVariable) or isinstance(outputs, LazyVariable):\r\n    164             return outputs\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, output, target)\r\n     49 \r\n     50         # Get log determininat and first part of quadratic form\r\n---> 51         inv_quad, log_det = covar.inv_quad_log_det(inv_quad_rhs=(target - mean).unsqueeze(-1), log_det=True)\r\n     52 \r\n     53         # Add terms for SGPR / when inducing points are learned\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_variable.py in inv_quad_log_det(self, inv_quad_rhs, log_det)\r\n    577         matrix_size = self.size(-1)\r\n    578         batch_size = self.size(0) if self.ndimension() == 3 else None\r\n--> 579         tensor_cls = self.tensor_cls\r\n    580 \r\n    581         args = lazy_var.representation()\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_variable.py in tensor_cls(self)\r\n    882     def tensor_cls(self):\r\n    883         if not hasattr(self, \"_tensor_cls\"):\r\n--> 884             first_item = self.representation()[0]\r\n    885             if isinstance(first_item, Variable):\r\n    886                 first_item = first_item.data\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_variable.py in representation(self)\r\n    733                 representation.append(arg)\r\n    734             elif isinstance(arg, LazyVariable):\r\n--> 735                 representation += list(arg.representation())\r\n    736             else:\r\n    737                 raise RuntimeError(\"Representation of a LazyVariable should consist only of Variables\")\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_variable.py in representation(self)\r\n    733                 representation.append(arg)\r\n    734             elif isinstance(arg, LazyVariable):\r\n--> 735                 representation += list(arg.representation())\r\n    736             else:\r\n    737                 raise RuntimeError(\"Representation of a LazyVariable should consist only of Variables\")\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_variable.py in representation(self)\r\n    109 \r\n    110     def representation(self):\r\n--> 111         return self.evaluate_kernel().representation()\r\n    112 \r\n    113     def representation_tree(self):\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_variable.py in evaluate_kernel(self)\r\n     96                 x2 = self.x2\r\n     97 \r\n---> 98             self._cached_kernel_eval = super(Kernel, self.kernel).__call__(x1, x2, **self.params)\r\n     99             if self.squeeze_row:\r\n    100                 self._cached_kernel_eval.squeeze_(-2)\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n    160 \r\n    161     def __call__(self, *inputs, **kwargs):\r\n--> 162         outputs = self.forward(*inputs, **kwargs)\r\n    163         if torch.is_tensor(outputs) or isinstance(outputs, RandomVariable) or isinstance(outputs, LazyVariable):\r\n    164             return outputs\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/kernels/multitask_kernel.py in forward(self, x1, x2)\r\n     61     def forward(self, x1, x2):\r\n     62         covar_i = self.task_covar_module.covar_matrix\r\n---> 63         covar_x = self.data_covar_module.forward(x1, x2)\r\n     64         if covar_x.size(0) == 1:\r\n     65             covar_x = covar_x[0]\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/kernels/grid_interpolation_kernel.py in forward(self, x1, x2, **kwargs)\r\n     52 \r\n     53     def forward(self, x1, x2, **kwargs):\r\n---> 54         base_lazy_var = self._inducing_forward()\r\n     55         if x1.size(0) > 1:\r\n     56             base_lazy_var = base_lazy_var.repeat(x1.size(0), 1, 1)\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/kernels/grid_interpolation_kernel.py in _inducing_forward(self)\r\n     46     def _inducing_forward(self):\r\n     47         inducing_points_var = Variable(self.inducing_points)\r\n---> 48         return super(GridInterpolationKernel, self).forward(inducing_points_var, inducing_points_var)\r\n     49 \r\n     50     def forward_diag(self, x1, x2, **kwargs):\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/kernels/grid_kernel.py in forward(self, x1, x2, **kwargs)\r\n     38             if settings.use_toeplitz.on():\r\n     39                 first_item = grid_var[:, 0:1].contiguous()\r\n---> 40                 covar_columns = self.base_kernel_module(first_item, grid_var, **kwargs).evaluate()\r\n     41                 covars = [ToeplitzLazyVariable(covar_columns[i : i + 1].squeeze(-2)) for i in range(n_dim)]\r\n     42             else:\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_variable.py in evaluate(self)\r\n    115 \r\n    116     def evaluate(self):\r\n--> 117         return self.evaluate_kernel().evaluate()\r\n    118 \r\n    119     def exact_predictive_mean(self, full_mean, train_labels, n_train, likelihood, precomputed_cache=None):\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_variable.py in evaluate_kernel(self)\r\n     96                 x2 = self.x2\r\n     97 \r\n---> 98             self._cached_kernel_eval = super(Kernel, self.kernel).__call__(x1, x2, **self.params)\r\n     99             if self.squeeze_row:\r\n    100                 self._cached_kernel_eval.squeeze_(-2)\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n    160 \r\n    161     def __call__(self, *inputs, **kwargs):\r\n--> 162         outputs = self.forward(*inputs, **kwargs)\r\n    163         if torch.is_tensor(outputs) or isinstance(outputs, RandomVariable) or isinstance(outputs, LazyVariable):\r\n    164             return outputs\r\n\r\n~/anaconda/envs/py3/lib/python3.6/site-packages/gpytorch/kernels/rbf_kernel.py in forward(self, x1, x2)\r\n    104     def forward(self, x1, x2):\r\n    105         lengthscales = self.log_lengthscale.exp().mul(math.sqrt(2)).clamp(self.eps, 1e5)\r\n--> 106         diff = (x1.unsqueeze(2) - x2.unsqueeze(1)).div_(lengthscales.unsqueeze(1))\r\n    107         return diff.pow_(2).sum(-1).mul_(-1).exp_()\r\n\r\nRuntimeError: The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 3\r\n```\r\n\r\nSetting `ard_num_dims=1` or `ard_num_dims=None` works fine, as well as without kernel interpolation. Matern kernel works fine for `ard_num_dims=2`.\r\n\r\n[RBF_ard_num_dims.ipynb.zip](https://github.com/cornellius-gp/gpytorch/files/2342721/RBF_ard_num_dims.ipynb.zip)\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/249/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/249/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/237", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/237/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/237/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/237/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/237", "id": 351701104, "node_id": "MDU6SXNzdWUzNTE3MDExMDQ=", "number": 237, "title": "Batch predictions fail on master", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-08-17T18:47:14Z", "updated_at": "2018-08-28T19:16:10Z", "closed_at": "2018-08-28T19:16:10Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Suppose you fit a GP in batch mode using `1 x n x 1` train_x and `1 x n` train_y. Now I want to predict a `1 x n' x 1` test_x, but that fails with a size mismatch in non_lazy_variable:\r\n\r\n```\r\nRuntimeError: size mismatch, m1: [1 x 1], m2: [100 x 1] at caffe2/aten/src/TH/generic/THTensorMath.cpp:932\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/237/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/237/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/221", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/221/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/221/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/221/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/221", "id": 348043721, "node_id": "MDExOlB1bGxSZXF1ZXN0MjA2NDg3NDk0", "number": 221, "title": "Speed up Root/Matmul LV get_indices", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-08-06T18:59:30Z", "updated_at": "2018-08-07T23:09:17Z", "closed_at": "2018-08-07T23:09:14Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/221", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/221", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/221.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/221.patch", "merged_at": "2018-08-07T23:09:14Z"}, "body": "- When calling `get_indices` with many indices, explicitly evaluate the LazyVariable.\r\n- Remove old Variable references\r\n\r\n`_get_indices` is called during the diag method for variational inference. If we want `m` indices, and the RootLazyVariable is a `n x r` matrix, then the standard `_get_indices` call requires `m * r` memory. If `m` is large (which is usually the case for variational), then this will be extremely memory intensive.\r\n\r\nFix: do whatever requires the least amount of memory:\r\n- If `m * r` > `n x n`, then explicitly evaluate the LazyVariable and then call `_get_indices`.\r\n- Otherwise, use the original `_get_indices` routine.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/221/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/221/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/215", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/215/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/215/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/215/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/215", "id": 347466308, "node_id": "MDU6SXNzdWUzNDc0NjYzMDg=", "number": 215, "title": "KronckerProductLazyVariable only works for square and symmetric matrices", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-08-03T16:49:10Z", "updated_at": "2018-08-04T15:07:34Z", "closed_at": "2018-08-04T15:07:34Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Easy enough to reproduce:\r\n\r\n```python\r\na = torch.randn(5, 3)\r\nb = torch.randn(2, 2)\r\nkplv = KroneckerProductLazyVariable(NonLazyVariable(a), NonLazyVariable(b))\r\nres = kplv._matmul(torch.randn(3 * 2)) # fails\r\n```\r\n\r\nThis is blocking MultitaskKernel from working properly, so I'm trying to solve this now", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/215/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/215/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/205", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/205/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/205/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/205/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/205", "id": 345278124, "node_id": "MDExOlB1bGxSZXF1ZXN0MjA0NDcxNjM0", "number": 205, "title": "Get priors/variational strategies also for children of torch Modules", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-07-27T15:52:08Z", "updated_at": "2018-07-27T16:15:51Z", "closed_at": "2018-07-27T16:00:15Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/205", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/205", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/205.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/205.patch", "merged_at": "2018-07-27T16:00:15Z"}, "body": "Fixes #204 by moving to functional recursion instead of object method recursion.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/205/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/205/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/204", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/204/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/204/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/204/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/204", "id": 345094899, "node_id": "MDU6SXNzdWUzNDUwOTQ4OTk=", "number": 204, "title": "named_parameter_priors won't get priors for children of torch Modules", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-07-27T05:26:17Z", "updated_at": "2018-07-27T16:00:15Z", "closed_at": "2018-07-27T16:00:15Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I think the PR #196  I did fixed things like DKL to at least run, but was a bad fix because we'll fail to get priors for parameters in gpytorch.Modules that are children of torch.nn.Modules. For example, consider AdditiveKernel, which places a bunch of Kernels in a ModuleList. Since named_parameter_priors is a recursive call that won't actually run on the ModuleList because it doesn't exist, we won't actually get priors for the component Kernels even if they are defined.\r\n\r\nOrdinarily I'd just implement a fix, but I'm actually not sure how to deal with this one. Even if we implement an in house ModuleList extension, it seems dangerous and insidious to leave this failure case in, since the intention is that GPyTorch Modules are interoperable with torch ones. Therefore, a recursive version of named_parameter_priors seems not possible -- maybe we have to expand each child of a normal torch Module in the method directly?\r\n\r\n@Balandat ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/204/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/204/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/195", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/195/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/195/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/195/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/195", "id": 344280189, "node_id": "MDU6SXNzdWUzNDQyODAxODk=", "number": 195, "title": "Fully connected layer before mean and covariance modules", "user": {"login": "sumitsk", "id": 7646621, "node_id": "MDQ6VXNlcjc2NDY2MjE=", "avatar_url": "https://avatars.githubusercontent.com/u/7646621?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sumitsk", "html_url": "https://github.com/sumitsk", "followers_url": "https://api.github.com/users/sumitsk/followers", "following_url": "https://api.github.com/users/sumitsk/following{/other_user}", "gists_url": "https://api.github.com/users/sumitsk/gists{/gist_id}", "starred_url": "https://api.github.com/users/sumitsk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sumitsk/subscriptions", "organizations_url": "https://api.github.com/users/sumitsk/orgs", "repos_url": "https://api.github.com/users/sumitsk/repos", "events_url": "https://api.github.com/users/sumitsk/events{/privacy}", "received_events_url": "https://api.github.com/users/sumitsk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1004100399, "node_id": "MDU6TGFiZWwxMDA0MTAwMzk5", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/high%20priority", "name": "high priority", "color": "f4005d", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-07-25T03:35:01Z", "updated_at": "2018-07-25T06:52:44Z", "closed_at": "2018-07-25T05:07:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to do a non-linear transformation of input before forwarding it through mean and covariance modules. Before master branch was merged to priors (commit 1f5491e3edcac6497d3370c8aaef9a9362048a3e), I can add a fully connected layer before passing the input through mean and covariance modules to learn a non-linear representation. For example, the following script worked fine. \r\n\r\n```\r\nimport math\r\nimport torch\r\nimport gpytorch\r\nfrom matplotlib import pyplot as plt\r\n\r\nfrom torch import optim\r\nfrom gpytorch.kernels import RBFKernel\r\nfrom gpytorch.means import ConstantMean\r\nfrom gpytorch.likelihoods import GaussianLikelihood\r\nfrom gpytorch.random_variables import GaussianRandomVariable\r\n\r\ntrain_x = torch.linspace(0, 1, 11)\r\ntrain_y = torch.sin(train_x.data * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2\r\n\r\nclass ExactGPModel(gpytorch.models.ExactGP):\r\n    def __init__(self, train_x, train_y, likelihood):\r\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\r\n        self.mean_module = ConstantMean(constant_bounds=(-10, 10))\r\n        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 5))\r\n        self.fc = torch.nn.Linear(1, 2)\r\n\r\n    def forward(self, x):\r\n        x_ = self.fc(x)\r\n        mean_x = self.mean_module(x_)\r\n        covar_x = self.covar_module(x_)\r\n        return GaussianRandomVariable(mean_x, covar_x)\r\n\r\nlikelihood = GaussianLikelihood(log_noise_bounds=(-5, 5))\r\nmodel = ExactGPModel(train_x.data, train_y.data, likelihood)\r\n\r\nmodel.train()\r\nlikelihood.train()\r\n\r\noptimizer = torch.optim.Adam([\r\n    {'params': model.parameters()},  \r\n], lr=0.1)\r\n\r\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\r\n\r\ntraining_iter = 1000\r\nfor i in range(training_iter):\r\n    optimizer.zero_grad()\r\n    output = model(train_x)\r\n    loss = -mll(output, train_y)\r\n    loss.backward()\r\n    print('Iter %d/%d - Loss: %.3f   log_lengthscale: %.3f   log_noise: %.3f' % (\r\n        i + 1, training_iter, loss.data[0],\r\n        model.covar_module.log_lengthscale.data[0, 0],\r\n        model.likelihood.log_noise.data[0]\r\n    ))\r\n    optimizer.step()\r\n```\r\n\r\nHowever, now I get this runtime error because of the linear fc layer:\r\n`AttributeError: 'Linear' object has no attribute '_get_prior_for'`\r\n\r\nHow can I get this to work with the latest version of gpytorch? DKL does something similar to what I am trying to do but implements AdditiveGridInducingVariationalGP and softmax likelihood, however, in my application I'd like to use ExactGP and gaussian likelihood. Is it possible to do so? \r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/195/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/195/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/191", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/191/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/191/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/191/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/191", "id": 343813235, "node_id": "MDU6SXNzdWUzNDM4MTMyMzU=", "number": 191, "title": "MultitaskGPModel won't scale with size of input", "user": {"login": "rajkumarkarthik", "id": 11140537, "node_id": "MDQ6VXNlcjExMTQwNTM3", "avatar_url": "https://avatars.githubusercontent.com/u/11140537?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rajkumarkarthik", "html_url": "https://github.com/rajkumarkarthik", "followers_url": "https://api.github.com/users/rajkumarkarthik/followers", "following_url": "https://api.github.com/users/rajkumarkarthik/following{/other_user}", "gists_url": "https://api.github.com/users/rajkumarkarthik/gists{/gist_id}", "starred_url": "https://api.github.com/users/rajkumarkarthik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rajkumarkarthik/subscriptions", "organizations_url": "https://api.github.com/users/rajkumarkarthik/orgs", "repos_url": "https://api.github.com/users/rajkumarkarthik/repos", "events_url": "https://api.github.com/users/rajkumarkarthik/events{/privacy}", "received_events_url": "https://api.github.com/users/rajkumarkarthik/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-07-23T22:06:45Z", "updated_at": "2018-07-25T06:49:54Z", "closed_at": "2018-07-25T06:49:54Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "In the basic multi-task model example shown in https://nbviewer.jupyter.org/github/cornellius-gp/gpytorch/blob/master/examples/multitask_gp_regression.ipynb, the code doesn't scale to larger sizes of training data. Specifically, if you changed training data size in cell 2 of the notebook from 11 to 100, the code no longer works. It throws the following error:\r\nRuntimeError: Function InvQuadLogDetLegacyBackward returned an invalid gradient at index 1 - expected shape [200, 9] but got [200, 5]\r\n\r\nCan someone figure out what's going on? Or am I doing this wrong?", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/191/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/191/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/174", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/174/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/174/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/174/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/174", "id": 338731395, "node_id": "MDU6SXNzdWUzMzg3MzEzOTU=", "number": 174, "title": "Predictions flipping sign when calling backward with model in eval mode", "user": {"login": "darbour", "id": 792198, "node_id": "MDQ6VXNlcjc5MjE5OA==", "avatar_url": "https://avatars.githubusercontent.com/u/792198?v=4", "gravatar_id": "", "url": "https://api.github.com/users/darbour", "html_url": "https://github.com/darbour", "followers_url": "https://api.github.com/users/darbour/followers", "following_url": "https://api.github.com/users/darbour/following{/other_user}", "gists_url": "https://api.github.com/users/darbour/gists{/gist_id}", "starred_url": "https://api.github.com/users/darbour/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/darbour/subscriptions", "organizations_url": "https://api.github.com/users/darbour/orgs", "repos_url": "https://api.github.com/users/darbour/repos", "events_url": "https://api.github.com/users/darbour/events{/privacy}", "received_events_url": "https://api.github.com/users/darbour/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2018-07-05T21:26:54Z", "updated_at": "2018-07-09T15:29:30Z", "closed_at": "2018-07-09T01:59:39Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "I am working through a toy problem that attempts to maximize the posterior mean w.r.t. the input parameters. However it seems that after putting the model into evaluation mode, calling backward changes the sign of the gradient w.r.t. the input (it will also change the sign of the predictions). I've attached a NB to reproduce. \r\n[sign_bug.pdf](https://github.com/cornellius-gp/gpytorch/files/2168285/sign_bug.pdf)\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/174/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 1, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/174/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/170", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/170/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/170/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/170/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/170", "id": 336823287, "node_id": "MDU6SXNzdWUzMzY4MjMyODc=", "number": 170, "title": "Invalid gradient shape RuntieError unit test failure on pytorch master", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 859608502, "node_id": "MDU6TGFiZWw4NTk2MDg1MDI=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/compatibility", "name": "compatibility", "color": "ebef7a", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-06-29T00:26:38Z", "updated_at": "2018-07-03T15:54:27Z", "closed_at": "2018-07-03T15:34:31Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Invalid gradient errors appear in unit test on pytorch master, e.g. in test_inv_quad_log_det_many_vectors (test.functions.test_inv_quad_log_det.TestInvQuadLogDetNonBatch)\r\n\r\n```\r\nRuntimeError: invalid gradient at index 0 - expected shape [] but got [1]\r\n  File \"/usr/local/fbcode/gcc-5-glibc-2.23/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\r\n    yield\r\n  File \"/usr/local/fbcode/gcc-5-glibc-2.23/lib/python3.6/unittest/case.py\", line 605, in run\r\n    testMethod()\r\n  File \"/data/users/balandat/fbsource/fbcode/buck-out/dev-nosan/gen/pytorch/gpytorch/test_gpytorch#binary,link-tree/test/functions/test_inv_quad_log_det.py\", line 84, in test_inv_quad_log_det_many_vectors\r\n    actual_inv_quad.backward(gradient=inv_quad_grad_output)\r\n  File \"/data/users/balandat/fbsource/fbcode/buck-out/dev-nosan/gen/pytorch/gpytorch/test_gpytorch#binary,link-tree/torch/tensor.py\", line 93, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n  File \"/data/users/balandat/fbsource/fbcode/buck-out/dev-nosan/gen/pytorch/gpytorch/test_gpytorch#binary,link-tree/torch/autograd/__init__.py\", line 90, in backward\r\n    allow_unreachable=True)  # allow_unreachable flag\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/170/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/170/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/169", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/169/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/169/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/169/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/169", "id": 336822813, "node_id": "MDU6SXNzdWUzMzY4MjI4MTM=", "number": 169, "title": "Require grad on non-floating point tensors breaks on pytorch master", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 859608502, "node_id": "MDU6TGFiZWw4NTk2MDg1MDI=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/compatibility", "name": "compatibility", "color": "ebef7a", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-06-29T00:23:32Z", "updated_at": "2018-06-29T18:18:01Z", "closed_at": "2018-06-29T18:18:01Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "On current pytorch master, gpytorch master breaks b/c of requiring grad from non-floating point tensors, e.g. here: https://github.com/cornellius-gp/gpytorch/blame/9902384d6543c14fa8bf29c3981631aef02da6ad/test/lazy/test_interpolated_lazy_variable.py#L98\r\n\r\nTest failure in e.g. in test_inv_matmul (test.lazy.test_interpolated_lazy_variable.TestInterpolatedLazyVariable)\r\n\r\n```\r\nRuntimeError: Only Tensors of floating point dtype can require gradients\r\n  File \"/usr/local/fbcode/gcc-5-glibc-2.23/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\r\n    yield\r\n  File \"/usr/local/fbcode/gcc-5-glibc-2.23/lib/python3.6/unittest/case.py\", line 605, in run\r\n    testMethod()\r\n  File \"/data/users/balandat/fbsource/fbcode/buck-out/dev-nosan/gen/pytorch/gpytorch/test_gpytorch#binary,link-tree/test/lazy/test_interpolated_lazy_variable.py\", line 98, in test_inv_matmul\r\n    left_interp_indices = Variable(torch.LongTensor([[2, 3], [3, 4], [4, 5]]), requires_grad=True)\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/169/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/169/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/161", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/161/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/161/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/161/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/161", "id": 332826385, "node_id": "MDU6SXNzdWUzMzI4MjYzODU=", "number": 161, "title": "LazyEvaluatedKernelVariable diag runs out of memory for SKI", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-06-15T15:49:29Z", "updated_at": "2018-08-07T15:35:46Z", "closed_at": "2018-08-07T15:35:46Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I pushed a temporary fix to this (a40392a8ce9c3c65a9679da21ec971783c9b6b81) that just special cases this specific issue, but the way we now handle lazily evaluating variances when we don't need the full covariance blows up for SKI.\r\n\r\nThis shouldn't be hard to fix, because the 'fix' implemented in the commit above does the right thing for SKI, anyways. It's really only exact GPs that benefit from the new `LazyEvaluatedKernel.diag()`.\r\n\r\nOnce I have a better solution, I'll revert the temporary fix, but it was a big enough problem that I wanted to get it solved immediately.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/161/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/161/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/159", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/159/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/159/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/159/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/159", "id": 331237890, "node_id": "MDU6SXNzdWUzMzEyMzc4OTA=", "number": 159, "title": "Batch mode InterpolatedLazyVariable __getitem__ doesn't behave like torch.Tensor.__getitem__", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-06-11T15:27:11Z", "updated_at": "2018-09-28T20:13:47Z", "closed_at": "2018-09-28T20:13:46Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "`InterpolatedLazyVariable`'s `__getitem__` method has different behavior than `torch.Tensor` in batch mode. Here's a simple example:\r\n\r\n```python\r\nmatrix = InterpolatedLazyVariable(...) # Some batch mode ILV, say 2 x 10 x 10\r\neval_matrix = matrix.evaluate() # Get a torch.Tensor of the same matrix.\r\n\r\n # Returns a 2 x 11 tensor containing eval_matrix[0, 0, :] and eval_matrix[1, 2, :]\r\nres1 = eval_matrix[[0, 1], [0, 2], :]\r\n\r\n# Returns a 2 x 2 x 11 tensor containing res1 replicated twice.\r\nres2 = matrix[[0, 1], [0, 2], :].evaluate()\r\n```\r\n\r\n@gpleiss ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/159/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/159/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/142", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/142/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/142/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/142/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/142", "id": 325903910, "node_id": "MDU6SXNzdWUzMjU5MDM5MTA=", "number": 142, "title": "Travis CI doesn't actually run Python 2.7 tests", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-23T22:59:41Z", "updated_at": "2018-06-02T20:46:27Z", "closed_at": "2018-06-02T20:44:37Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "See https://travis-ci.org/cornellius-gp/gpytorch/jobs/382926170 for an example (0 tests ran).\r\n\r\nThe Python 3 tests still work fine, but this explains why the Python 2 tests have never failed in recent memory even when the Python 3 tests do :-).\r\n\r\nConsidering a couple of us develop on Python 3, this could theoretically mean we have some undetected backward compatibility issues. I doubt it, though.\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/142/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/142/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/140", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/140/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/140/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/140/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/140", "id": 325415624, "node_id": "MDExOlB1bGxSZXF1ZXN0MTg5NzU1MzQ4", "number": 140, "title": "Pivoted cholesky fixes", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 623304448, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDg=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-22T18:37:57Z", "updated_at": "2018-05-23T01:49:33Z", "closed_at": "2018-05-23T01:49:31Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/140", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/140", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/140.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/140.patch", "merged_at": "2018-05-23T01:49:31Z"}, "body": "- The `_preconditioner` function now also defines the log det correction (rather than the LazyVariable itself)\r\n- The preconditioner works on batched matrices\r\n- The preconditioner uses an approx_diag function (which is exact for most lazy variables, only an approximation for InterpolatedLazyVariables)", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/140/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/140/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/134", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/134/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/134/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/134/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/134", "id": 322441987, "node_id": "MDU6SXNzdWUzMjI0NDE5ODc=", "number": 134, "title": "GPyTorch should handle batched predictions for independent GPs", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 623304448, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDg=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-05-11T21:36:38Z", "updated_at": "2018-06-11T15:31:48Z", "closed_at": "2018-06-11T15:31:48Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I'm spinning off a separate issue from the discussion in #130 . GPyTorch should handle `k x n x d`  training data, `k x n` labels, and `k x t x d` test points **at test time** as though we have `k` separate Gaussian processes, each with a training set and a set of test points. \r\n\r\nI think handling this at training time would be much more challenging since we'd need to call backward on a list of `k` losses, but the use case @Balandat  mentioned has fixed hyperparameters, so we only need test time support.\r\n\r\nI am marking this as a bug, because I believe @samuelstanton has a fix for this, although it may involve some for loops so we may want to fix it a different way. I think Sam mentioned he actually had a batched solution?", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/134/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/134/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/133", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/133/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/133/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/133/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/133", "id": 322287535, "node_id": "MDExOlB1bGxSZXF1ZXN0MTg3NDU2OTAx", "number": 133, "title": "RBF stability improvements", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-05-11T12:59:05Z", "updated_at": "2018-05-11T13:04:00Z", "closed_at": "2018-05-11T13:03:55Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/133", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/133", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/133.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/133.patch", "merged_at": "2018-05-11T13:03:54Z"}, "body": "A few changes:\r\n\r\n1. We divide the lengthscale by 2 before summing the squared dimension-wise distances. This seems to be more numerically stable than dividing by 2 afterwards.\r\n\r\n1. Rather than adding 1e-5 to the lengthscale (to prevent division by zero errors), we're instead using a clamp operation.\r\n\r\nFixes #119 ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/133/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/133/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/120", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/120/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/120/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/120/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/120", "id": 320917357, "node_id": "MDU6SXNzdWUzMjA5MTczNTc=", "number": 120, "title": "DiagLazyVariable Sampling", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-07T19:00:12Z", "updated_at": "2018-05-10T16:42:31Z", "closed_at": "2018-05-10T16:42:31Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://github.com/cornellius-gp/gpytorch/blob/d29e08ebba7f998b7eda1a0f4d670e87363b7e07/gpytorch/lazy/diag_lazy_variable.py#L72\r\n\r\nThis should probably be\r\n```python\r\nsamples = self._diag.unsqueeze(-1).sqrt() * base_samples \r\n```\r\n\r\n? Just making sure I'm not missing something, since I've never used `PsdSumLazyVariable`, which is where I assume this actually gets used.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/120/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/120/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/119", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/119/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/119/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/119/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/119", "id": 320389044, "node_id": "MDU6SXNzdWUzMjAzODkwNDQ=", "number": 119, "title": "RBF Kernel Change Breaks Testing Code", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-05-04T18:53:34Z", "updated_at": "2018-05-11T13:03:54Z", "closed_at": "2018-05-11T13:03:54Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The change to RBFKernel in 84fccd898c45c08279fb5c109e6e234f3a47588a may break something about our prediction code. \r\n\r\nI am not totally sure what the problem is yet, but I isolated this as the problem with `git bisect` and have a reasonable test case where results are significantly worse with the commit in compared to after a revert commit. \r\n\r\nIt seems like the stability issues we encountered when making this change in the past don't come up in the unit tests, but do on some real datasets.\r\n\r\nI can try to push my test case to a branch as well, although it relies on a UCI dataset.\r\n\r\n@Balandat @gpleiss ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/119/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/119/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/106", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/106/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/106/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/106/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/106", "id": 318550104, "node_id": "MDU6SXNzdWUzMTg1NTAxMDQ=", "number": 106, "title": "Hard-coded tensor types in LogNormalCDF", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-04-27T21:07:25Z", "updated_at": "2018-04-30T15:47:04Z", "closed_at": "2018-04-30T15:47:04Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "The tensors initialized in LogNormalCDF are cpu float32 tensors, which causes test a failure when running the GPU test: https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/functions/log_normal_cdf.py#L51 (the adding of r_i fails). \r\n\r\nThis will probably also cause issues when running anything involving LogNormalCDF under a float64 or other data type ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/106/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/106/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/104", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/104/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/104/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/104/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/104", "id": 317766518, "node_id": "MDU6SXNzdWUzMTc3NjY1MTg=", "number": 104, "title": "Model fitting fails when using MaternKernel", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-04-25T19:40:20Z", "updated_at": "2018-04-25T21:35:11Z", "closed_at": "2018-04-25T20:55:53Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Using `self.covar_module = MaternKernel(2.5, log_lengthscale_bounds=(-5, 5))` instead of `RBFKernel(log_lengthscale_bounds=(-5, 5))` in the basic `simple_gp_regression.py` example results in the stack trace below in the first iteration of the optimization:\r\n\r\n```\r\nIter 1/50 - Loss: 1.203   log_lengthscale: 0.000   log_noise: 0.000\r\n---------------------------------------------------------------------------\r\nUnboundLocalError                         Traceback (most recent call last)\r\n<ipython-input-12-0cb2960c7ba2> in <module>()\r\n     18     output = model(train_x)\r\n     19     # Calc loss and backprop gradients\r\n---> 20     loss = -mll(output, train_y)\r\n     21     loss.backward()\r\n     22     print('Iter %d/%d - Loss: %.3f   log_lengthscale: %.3f   log_noise: %.3f' % (\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev-nosan/gen/experimental/ae/bento_kernel_ae_experimental#link-tree/gpytorch/module.py in __call__(self, *inputs, **kwargs)\r\n    159 \r\n    160     def __call__(self, *inputs, **kwargs):\r\n--> 161         outputs = self.forward(*inputs, **kwargs)\r\n    162         if isinstance(outputs, Variable) or isinstance(outputs, RandomVariable) or isinstance(outputs, LazyVariable):\r\n    163             return outputs\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev-nosan/gen/experimental/ae/bento_kernel_ae_experimental#link-tree/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, output, target)\r\n     32 \r\n     33         # Get log determininat and first part of quadratic form\r\n---> 34         inv_quad, log_det = covar.inv_quad_log_det(inv_quad_rhs=target.unsqueeze(-1), log_det=True)\r\n     35         res = -0.5 * sum([\r\n     36             inv_quad,\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev-nosan/gen/experimental/ae/bento_kernel_ae_experimental#link-tree/gpytorch/lazy/lazy_variable.py in inv_quad_log_det(self, inv_quad_rhs, log_det)\r\n    393                                                     log_det=log_det,\r\n    394                                                     preconditioner=self._preconditioner()\r\n--> 395                                                     )(*(list(args) + [inv_quad_rhs]))\r\n    396 \r\n    397     def log_det(self):\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev-nosan/gen/experimental/ae/bento_kernel_ae_experimental#link-tree/gpytorch/utils/function_factory.py in forward(self, *args)\r\n    237                 solves, t_mat = linear_cg(matmul_closure, rhs, n_tridiag=num_random_probes,\r\n    238                                           max_iter=settings.max_lanczos_quadrature_iterations.value(),\r\n--> 239                                           preconditioner=self.preconditioner)\r\n    240             else:\r\n    241                 solves = linear_cg(matmul_closure, rhs, n_tridiag=num_random_probes,\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev-nosan/gen/experimental/ae/bento_kernel_ae_experimental#link-tree/gpytorch/utils/linear_cg.py in linear_cg(matmul_closure, rhs, n_tridiag, tolerance, eps, max_iter, initial_guess, preconditioner)\r\n     88         else:\r\n     89             t_mat = residual.new(n_iter, n_iter, n_tridiag).zero_()\r\n---> 90             alpha_reciprocal = alpha.new(n_tridiag)\r\n     91 \r\n     92         prev_alpha_reciprocal = alpha.new(alpha_reciprocal.size())\r\n\r\nUnboundLocalError: local variable 'alpha' referenced before assignment\r\n```", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/104/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/104/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/102", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/102/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/102/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/102/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/102", "id": 313893010, "node_id": "MDU6SXNzdWUzMTM4OTMwMTA=", "number": 102, "title": "Bug with GridInterpolationKernel and Variables with 'requires_grad=True'", "user": {"login": "samuelstanton", "id": 22999782, "node_id": "MDQ6VXNlcjIyOTk5Nzgy", "avatar_url": "https://avatars.githubusercontent.com/u/22999782?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samuelstanton", "html_url": "https://github.com/samuelstanton", "followers_url": "https://api.github.com/users/samuelstanton/followers", "following_url": "https://api.github.com/users/samuelstanton/following{/other_user}", "gists_url": "https://api.github.com/users/samuelstanton/gists{/gist_id}", "starred_url": "https://api.github.com/users/samuelstanton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samuelstanton/subscriptions", "organizations_url": "https://api.github.com/users/samuelstanton/orgs", "repos_url": "https://api.github.com/users/samuelstanton/repos", "events_url": "https://api.github.com/users/samuelstanton/events{/privacy}", "received_events_url": "https://api.github.com/users/samuelstanton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-04-12T21:24:46Z", "updated_at": "2018-04-16T15:12:41Z", "closed_at": "2018-04-16T15:12:41Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Currently trying to evaluate a GP using GridInterpolationKernel on test points stored as torch.nn.Parameter. \r\n\r\nLine 89 in utils/interpolation.py results in an assertion error from \r\n`assert not ctx.needs_input_grad[2]` in torch/autograd/_functions/tensor.py\r\n\r\nYou can produce this error by putting \r\n`x = Variable(torch.Tensor(1, 2).uniform_(), requires_grad=True)`\r\n`model(x)`\r\nat the end of the kissgp_kronecker_product_regression.ipython notebook in examples.\r\n\r\nThis issue does not occur when using RBFKernel or SpectralMixtureKernel\r\nI reproduced this issue after doing a fresh pull and install of gpytorch, traceback attached.\r\n\r\n[traceback.txt](https://github.com/cornellius-gp/gpytorch/files/1905058/traceback.txt)\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/102/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/102/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/100", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/100/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/100/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/100/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/100", "id": 310154907, "node_id": "MDExOlB1bGxSZXF1ZXN0MTc4NjI0OTkz", "number": 100, "title": "Fixes to variational inference", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 867284546, "node_id": "MDU6TGFiZWw4NjcyODQ1NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/refactor", "name": "refactor", "color": "0052cc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-03-30T19:58:06Z", "updated_at": "2018-03-30T20:46:18Z", "closed_at": "2018-03-30T20:46:14Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/100", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/100", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/100.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/100.patch", "merged_at": "2018-03-30T20:46:14Z"}, "body": "Some small fixes/refactors to variational inference:\r\n\r\n## Features\r\n- The Variational MLL object has an optional `combine_terms` attribute (default true). If you set it to false, the loss returns the two terms (the expected NLL and the KL term) separately.\r\n\r\n## Refactors\r\n- MVN KL divergence can now take a lazy variable for the variational covariance. (For now, we're always using a cholesky lazy variable, but it allows for other LV options in the future).\r\n- The AddedDiagLazyVariable is used for the variational diagonal correction\r\n\r\n## Minor fixes and tweaks\r\n- Remove the old MLL functions from lazy variables\r\n- Fix a transpose issue in SumLazyVariable", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/100/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/100/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/97", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/97/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/97/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/97/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/97", "id": 308042364, "node_id": "MDExOlB1bGxSZXF1ZXN0MTc3MDc5NjQ1", "number": 97, "title": "Function factory tests work on pytorch 0.3 and 0.4", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 859608502, "node_id": "MDU6TGFiZWw4NTk2MDg1MDI=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/compatibility", "name": "compatibility", "color": "ebef7a", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-03-23T14:06:08Z", "updated_at": "2018-03-23T19:34:40Z", "closed_at": "2018-03-23T19:34:23Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/97", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/97", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/97.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/97.patch", "merged_at": "2018-03-23T19:34:23Z"}, "body": "On PyTorch master (0.4-alpha), Indexing a zero-dimensional tensor does not return a numeric value anymore, but a tensor. This caused test failures with assertAlmostEqual of the kind TypeError: type Variable doesn't define __round__ method.\r\n\r\nThis PR fixes these assertion errors, so they work on stable PyTorch (0.3) and PyTorch master.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/97/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/97/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/94", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/94/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/94/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/94/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/94", "id": 307859357, "node_id": "MDU6SXNzdWUzMDc4NTkzNTc=", "number": 94, "title": "Test failure in test_function_factory.py", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-03-23T00:20:14Z", "updated_at": "2018-03-23T15:24:30Z", "closed_at": "2018-03-23T15:24:30Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "The offending line is https://github.com/cornellius-gp/gpytorch/blob/master/test/util/test_function_factory.py#L243\r\n\r\nThe last `.dot` operation errors with \r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-28-1e6c865d4b6a> in <module>()\r\n----> 1 t.test_inv_quad_log_det_many_vectors()\r\n\r\n<ipython-input-25-045795d3c376> in test_inv_quad_log_det_many_vectors(self)\r\n     24     def test_inv_quad_log_det_many_vectors(self):\r\n     25         # Forward pass\r\n---> 26         actual_inv_quad = self.mat_var_clone.inverse().matmul(self.vecs_var_clone).dot(self.vecs_var_clone)\r\n     27         with gpytorch.settings.num_trace_samples(1000):\r\n     28             nlv = NonLazyVariable(self.mat_var)\r\n\r\nRuntimeError: Expected argument self to have 1 dimension, but has 2\r\n```\r\n\r\nI'm not entirely sure what this code does, so I'll leave this for @gpleiss to fix.\r\n\r\nNot sure if that happens on stable pytorch, but it definitely happens on pytorch master. Given that docs back to 0.3.0 state that .dot does not broadcast, I'm assuming this is unrelated though. ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/94/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/94/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/92", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/92/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/92/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/92/events", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/92", "id": 307408363, "node_id": "MDExOlB1bGxSZXF1ZXN0MTc2NjAyMzQ5", "number": 92, "title": "Fix installation issues with anaconda", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-03-21T20:36:02Z", "updated_at": "2018-03-21T20:36:14Z", "closed_at": "2018-03-21T20:36:10Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/pulls/92", "html_url": "https://github.com/cornellius-gp/gpytorch/pull/92", "diff_url": "https://github.com/cornellius-gp/gpytorch/pull/92.diff", "patch_url": "https://github.com/cornellius-gp/gpytorch/pull/92.patch", "merged_at": "2018-03-21T20:36:10Z"}, "body": "`python setup.py install` now looks for anaconda installations of fftw when building.\r\n\r\nFixes #89 and #91 ", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/92/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/92/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/67", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/67/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/67/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/67/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/67", "id": 291391795, "node_id": "MDU6SXNzdWUyOTEzOTE3OTU=", "number": 67, "title": "Cannot compute gradient of variance", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-01-24T23:01:24Z", "updated_at": "2018-01-26T22:27:43Z", "closed_at": "2018-01-26T22:27:43Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "First of all, this package looks really great.\r\n\r\nI'd like to compute the gradient of the variance of a prediction, but this fails with \r\n`RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation`.\r\n\r\nTo repro (here `model` is the trained/conditioned model from the simple_gp_regression.ipynb example):\r\n```\r\n>> test_x = Variable(torch.rand(10), requires_grad=True)\r\n>> output = model(test_x)\r\n\r\n# this works just fine\r\n>> sum_of_means = output.mean().sum()\r\n>> sum_of_means.backward()\r\n>> test_x.grad\r\nVariable containing:\r\n 3.4206\r\n-3.2818\r\n 1.8668\r\n 3.5644\r\n-0.7677\r\n 0.7666\r\n 6.4394\r\n 5.1365\r\n-5.0451\r\n 6.0161\r\n[torch.FloatTensor of size 10]\r\n\r\n# this fails with said error\r\n>> sum_of_vars = output.var().sum()\r\n>> sum_of_vars.backward()\r\n>> test_x.grad\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-18-dad61ee95fc5> in <module>()\r\n      1 sum_of_vars = output.var().sum()\r\n----> 2 sum_of_vars.backward()\r\n      3 test_x.grad\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_dev#link-tree/torch/autograd/variable.py in backward(self, gradient, retain_graph, create_graph, retain_variables)\r\n    165                 Variable.\r\n    166         \"\"\"\r\n--> 167         torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\r\n    168 \r\n    169     def register_hook(self, hook):\r\n\r\n/data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_dev#link-tree/torch/autograd/__init__.py in backward(variables, grad_variables, retain_graph, create_graph, retain_variables)\r\n     97 \r\n     98     Variable._execution_engine.run_backward(\r\n---> 99         variables, grad_variables, retain_graph)\r\n    100 \r\n    101 \r\n\r\nRuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation\r\n```\r\n\r\nI tried to track down where this happens, but didn't get very far (given the less than informative stack trace).\r\n\r\nComputing the gradient of the variance would be really useful for using this package for bayesian optimization.", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/67/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/67/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/61", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/61/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/61/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/61/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/61", "id": 289326952, "node_id": "MDU6SXNzdWUyODkzMjY5NTI=", "number": 61, "title": "Interpolation expects things to be floats", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/milestones/1", "html_url": "https://github.com/cornellius-gp/gpytorch/milestone/1", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/milestones/1/labels", "id": 2983944, "node_id": "MDk6TWlsZXN0b25lMjk4Mzk0NA==", "number": 1, "title": "changes before alpha release", "description": "Proposed changes:\r\n\r\n- Make `GPModel` `ExactGPModel`. This class would then only be used when performing exact inference. All Likelihoods would only be used for variational inference.\r\n\r\n- Refactor variational inference a bit. Rather than strapping on `_variational_strategy` to the outputs (which can be really hacky), I think we should have a `register_variational_parameters` approach.\r\n\r\n- Create a `gpytorch.optim.SVI` class for doing SVI (similar to Pyro). This would just be a thin wrapper around an existing pytorch optimizer, and would make sure to add the appropriate KL terms (and possibly hyperprior terms).\r\n\r\n- Similarly, it might not hurt to also have a `gpytorch.optim.ExactMLL` optimizer as well, which would be a really thin wrapper (this would mostly be for symmetry). \r\n\r\n- A slight refactor to the `.size()` method for lazy variables.\r\n\r\n- Refactor `KroneckerProductLazyVariable`", "creator": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 12, "state": "closed", "created_at": "2017-12-16T16:32:29Z", "updated_at": "2018-09-10T19:57:41Z", "due_on": "2018-02-20T08:00:00Z", "closed_at": "2018-09-10T19:57:41Z"}, "comments": 1, "created_at": "2018-01-17T16:23:37Z", "updated_at": "2018-02-15T21:22:40Z", "closed_at": "2018-02-15T21:22:40Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/61/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/61/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/60", "repository_url": "https://api.github.com/repos/cornellius-gp/gpytorch", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/60/labels{/name}", "comments_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/60/comments", "events_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/60/events", "html_url": "https://github.com/cornellius-gp/gpytorch/issues/60", "id": 288845601, "node_id": "MDU6SXNzdWUyODg4NDU2MDE=", "number": 60, "title": "gradients didn't backward to the end", "user": {"login": "pinle-go", "id": 20688585, "node_id": "MDQ6VXNlcjIwNjg4NTg1", "avatar_url": "https://avatars.githubusercontent.com/u/20688585?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pinle-go", "html_url": "https://github.com/pinle-go", "followers_url": "https://api.github.com/users/pinle-go/followers", "following_url": "https://api.github.com/users/pinle-go/following{/other_user}", "gists_url": "https://api.github.com/users/pinle-go/gists{/gist_id}", "starred_url": "https://api.github.com/users/pinle-go/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pinle-go/subscriptions", "organizations_url": "https://api.github.com/users/pinle-go/orgs", "repos_url": "https://api.github.com/users/pinle-go/repos", "events_url": "https://api.github.com/users/pinle-go/events{/privacy}", "received_events_url": "https://api.github.com/users/pinle-go/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 623304446, "node_id": "MDU6TGFiZWw2MjMzMDQ0NDY=", "url": "https://api.github.com/repos/cornellius-gp/gpytorch/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/milestones/1", "html_url": "https://github.com/cornellius-gp/gpytorch/milestone/1", "labels_url": "https://api.github.com/repos/cornellius-gp/gpytorch/milestones/1/labels", "id": 2983944, "node_id": "MDk6TWlsZXN0b25lMjk4Mzk0NA==", "number": 1, "title": "changes before alpha release", "description": "Proposed changes:\r\n\r\n- Make `GPModel` `ExactGPModel`. This class would then only be used when performing exact inference. All Likelihoods would only be used for variational inference.\r\n\r\n- Refactor variational inference a bit. Rather than strapping on `_variational_strategy` to the outputs (which can be really hacky), I think we should have a `register_variational_parameters` approach.\r\n\r\n- Create a `gpytorch.optim.SVI` class for doing SVI (similar to Pyro). This would just be a thin wrapper around an existing pytorch optimizer, and would make sure to add the appropriate KL terms (and possibly hyperprior terms).\r\n\r\n- Similarly, it might not hurt to also have a `gpytorch.optim.ExactMLL` optimizer as well, which would be a really thin wrapper (this would mostly be for symmetry). \r\n\r\n- A slight refactor to the `.size()` method for lazy variables.\r\n\r\n- Refactor `KroneckerProductLazyVariable`", "creator": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 12, "state": "closed", "created_at": "2017-12-16T16:32:29Z", "updated_at": "2018-09-10T19:57:41Z", "due_on": "2018-02-20T08:00:00Z", "closed_at": "2018-09-10T19:57:41Z"}, "comments": 4, "created_at": "2018-01-16T09:55:35Z", "updated_at": "2018-01-27T16:40:28Z", "closed_at": "2018-01-27T16:40:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "I don't have much experience with the Gaussian process and I found this repo very helpful! I met one problem about the GPModel module. \r\n\r\nWhen the input of the Gaussian process model comes from some embedding layers (which are part of the model), **the embedding layers' weights have no gradients** after the loss backward.\r\n\r\nHere's an example.\r\n\r\n```Python\r\nimport gpytorch\r\nimport torch\r\nfrom gpytorch.kernels import RBFKernel\r\nfrom gpytorch.likelihoods import GaussianLikelihood\r\nfrom gpytorch.means import ConstantMean\r\nfrom gpytorch.random_variables import GaussianRandomVariable\r\nfrom torch import nn\r\nfrom torch.autograd import Variable\r\n\r\n\r\nclass LatentFunction(gpytorch.AdditiveGridInducingPointModule):\r\n    def __init__(self):\r\n        super(LatentFunction, self).__init__(grid_size=100, grid_bounds=[(-10, 10)], n_components=2)\r\n        self.mean_module = ConstantMean(constant_bounds=[-1e-5, 1e-5])\r\n        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 6))\r\n        self.register_parameter('log_outputscale', nn.Parameter(torch.Tensor([0])), bounds=(-5, 6))\r\n\r\n    def forward(self, x):\r\n        mean_x = self.mean_module(x)\r\n        covar_x = self.covar_module(x)\r\n        covar_x = covar_x.mul(self.log_outputscale.exp())\r\n        latent_pred = GaussianRandomVariable(mean_x, covar_x)\r\n        return latent_pred\r\n\r\n\r\nclass GPRegressionModel(gpytorch.GPModel):\r\n    def __init__(self):\r\n        super(GPRegressionModel, self).__init__(GaussianLikelihood())\r\n        self.latent_function = LatentFunction()\r\n\r\n    def forward(self, x):\r\n        return self.latent_function(x)\r\n\r\n\r\nif __name__ == '__main__':\r\n    n = 10\r\n    embs = nn.Embedding(10, 2)\r\n    train_x = (torch.rand(n) * 10).type(torch.LongTensor)\r\n    train_x = Variable(train_x)\r\n    train_x = embs(train_x)\r\n    train_y = (train_x.data[:, :1] - train_x.data[:, 1:]).norm(p=2, dim=1)\r\n    train_y = Variable(train_y)\r\n\r\n    model = GPRegressionModel()\r\n    output = model(train_x)\r\n    loss = -model.marginal_log_likelihood(output, train_y)\r\n    loss.backward()\r\n    print('Embedding has no gradients?', embs.weight.grad is None)\r\n\r\n    if train_x.grad:\r\n        train_x.grad.zero_()\r\n    model = nn.Linear(2, 1)\r\n    output = model(train_x)\r\n    loss = nn.functional.mse_loss(output, train_y)\r\n    loss.backward()\r\n\r\n    print('Linear has no gradients?', embs.weight.grad is None, '\\tnorm:', embs.weight.grad.norm().data[0])\r\n```\r\n\r\nThe output is \r\n> Embedding has no gradients? True \r\n> Linear has no gradients? False \r\n>         norm: 1.098832130432129\r\n\r\nI noticed it extends the \"torch.nn.Module\" class so I expected it has some similar properties like other \"torch.nn.Module\" subclasses (such as Linear Layer or Conv Layer). But looks like it doesn't.\r\n\r\nI don't know if it's the Gaussian process's property or some \"bugs\". Correct me if there are some trivial mistakes.\r\n\r\nMany thanks!", "reactions": {"url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/60/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/cornellius-gp/gpytorch/issues/60/timeline", "performed_via_github_app": null, "state_reason": "completed"}]