[{"url": "https://api.github.com/repos/dask/dask/issues/10160", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/10160/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/10160/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/10160/events", "html_url": "https://github.com/dask/dask/issues/10160", "id": 1658852792, "node_id": "I_kwDOAbcwm85i4BW4", "number": 10160, "title": "`ddf.set_index('col')` fails with pyarrow timestamp dtype column", "user": {"login": "bphillips-exos", "id": 56549508, "node_id": "MDQ6VXNlcjU2NTQ5NTA4", "avatar_url": "https://avatars.githubusercontent.com/u/56549508?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bphillips-exos", "html_url": "https://github.com/bphillips-exos", "followers_url": "https://api.github.com/users/bphillips-exos/followers", "following_url": "https://api.github.com/users/bphillips-exos/following{/other_user}", "gists_url": "https://api.github.com/users/bphillips-exos/gists{/gist_id}", "starred_url": "https://api.github.com/users/bphillips-exos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bphillips-exos/subscriptions", "organizations_url": "https://api.github.com/users/bphillips-exos/orgs", "repos_url": "https://api.github.com/users/bphillips-exos/repos", "events_url": "https://api.github.com/users/bphillips-exos/events{/privacy}", "received_events_url": "https://api.github.com/users/bphillips-exos/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2023-04-07T14:15:58Z", "updated_at": "2023-04-18T01:07:25Z", "closed_at": "2023-04-18T01:07:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Describe the issue**:\r\nThe `set_index` operation fails on dask dataframes when the column dtype is a pyarrow timestamp.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport pandas as pd\r\nimport pyarrow as pa\r\nimport dask.dataframe as dd\r\n\r\nts_series = pd.Series([pd.Timestamp('2022-01-01')], dtype='datetime64[ns]')\r\npa_ts_series = pd.Series(\r\n    data=[pd.Timestamp('2022-01-01')],\r\n    dtype=pd.ArrowDtype(pa.timestamp('ns')),\r\n)\r\n\r\ndf = pd.DataFrame({'ts': ts_series, 'pa_ts': pa_ts_series})\r\n\r\ndf.set_index('ts')  # works\r\ndf.set_index('pa_ts')  # works\r\n\r\nddf = dd.from_pandas(df, npartitions=1)\r\n\r\nddf.set_index('ts')  # works\r\nddf.set_index('pa_ts')  # fails\r\n```\r\n\r\n**Environment**:\r\n\r\n- Pandas version: 2.0.0\r\n- Dask version: 2023.3.2\r\n- Python version: 3.10\r\n\r\n**Traceback**:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/bphillips/workspace/exos-chronos/zz.py\", line 20, in <module>\r\n    ddf.set_index('pa_ts')  # fails\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/core.py\", line 5199, in set_index\r\n    return set_index(\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/shuffle.py\", line 236, in set_index\r\n    return result.map_partitions(M.sort_index)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/core.py\", line 998, in map_partitions\r\n    return map_partitions(func, self, *args, **kwargs)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/core.py\", line 6863, in map_partitions\r\n    meta = _get_meta_map_partitions(args, dfs, func, kwargs, meta, parent_meta)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/core.py\", line 6974, in _get_meta_map_partitions\r\n    meta = _emulate(func, *args, udf=True, **kwargs)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/core.py\", line 6792, in _emulate\r\n    with raise_on_meta_error(funcname(func), udf=udf), check_numeric_only_deprecation():\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/contextlib.py\", line 153, in __exit__\r\n    self.gen.throw(typ, value, traceback)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/utils.py\", line 214, in raise_on_meta_error\r\n    raise ValueError(msg) from e\r\nValueError: Metadata inference failed in `sort_index`.\r\n\r\nYou have supplied a custom function and Dask is unable to \r\ndetermine the type of output that that function returns. \r\n\r\nTo resolve this please provide a meta= keyword.\r\nThe docstring of the Dask function you ran should have more information.\r\n\r\nOriginal error is below:\r\n------------------------\r\nArrowTypeError(\"object of type <class 'str'> cannot be converted to int\")\r\n\r\nTraceback:\r\n---------\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/utils.py\", line 193, in raise_on_meta_error\r\n    yield\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/core.py\", line 6793, in _emulate\r\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/core.py\", line 6773, in _extract_meta\r\n    return tuple(_extract_meta(_x, nonempty) for _x in x)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/core.py\", line 6773, in <genexpr>\r\n    return tuple(_extract_meta(_x, nonempty) for _x in x)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/core.py\", line 6769, in _extract_meta\r\n    return x._meta_nonempty if nonempty else x._meta\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/core.py\", line 558, in _meta_nonempty\r\n    return meta_nonempty(self._meta)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/utils.py\", line 642, in __call__\r\n    return meth(arg, *args, **kwargs)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/backends.py\", line 314, in meta_nonempty_dataframe\r\n    idx = meta_nonempty(x.index)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/utils.py\", line 642, in __call__\r\n    return meth(arg, *args, **kwargs)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/dask/dataframe/backends.py\", line 343, in _nonempty_index\r\n    return pd.Index([\"a\", \"b\"], name=idx.name, dtype=idx.dtype)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 551, in __new__\r\n    arr = sanitize_array(data, None, dtype=dtype, copy=copy)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/pandas/core/construction.py\", line 559, in sanitize_array\r\n    subarr = cls._from_sequence(data, dtype=dtype, copy=copy)\r\n  File \"/Users/bphillips/workspace/exos-chronos/.venv/lib/python3.10/site-packages/pandas/core/arrays/arrow/array.py\", line 253, in _from_sequence\r\n    scalars = pa.array(scalars, type=pa_dtype, from_pandas=True)\r\n  File \"pyarrow/array.pxi\", line 320, in pyarrow.lib.array\r\n  File \"pyarrow/array.pxi\", line 39, in pyarrow.lib._sequence_to_array\r\n  File \"pyarrow/error.pxi\", line 144, in pyarrow.lib.pyarrow_internal_check_status\r\n  File \"pyarrow/error.pxi\", line 123, in pyarrow.lib.check_status\r\n```", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/10160/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/10160/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/10146", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/10146/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/10146/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/10146/events", "html_url": "https://github.com/dask/dask/issues/10146", "id": 1654438499, "node_id": "I_kwDOAbcwm85inLpj", "number": 10146, "title": "Windows-specific failures on `main`", "user": {"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "j-bennet", "id": 637013, "node_id": "MDQ6VXNlcjYzNzAxMw==", "avatar_url": "https://avatars.githubusercontent.com/u/637013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/j-bennet", "html_url": "https://github.com/j-bennet", "followers_url": "https://api.github.com/users/j-bennet/followers", "following_url": "https://api.github.com/users/j-bennet/following{/other_user}", "gists_url": "https://api.github.com/users/j-bennet/gists{/gist_id}", "starred_url": "https://api.github.com/users/j-bennet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/j-bennet/subscriptions", "organizations_url": "https://api.github.com/users/j-bennet/orgs", "repos_url": "https://api.github.com/users/j-bennet/repos", "events_url": "https://api.github.com/users/j-bennet/events{/privacy}", "received_events_url": "https://api.github.com/users/j-bennet/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "j-bennet", "id": 637013, "node_id": "MDQ6VXNlcjYzNzAxMw==", "avatar_url": "https://avatars.githubusercontent.com/u/637013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/j-bennet", "html_url": "https://github.com/j-bennet", "followers_url": "https://api.github.com/users/j-bennet/followers", "following_url": "https://api.github.com/users/j-bennet/following{/other_user}", "gists_url": "https://api.github.com/users/j-bennet/gists{/gist_id}", "starred_url": "https://api.github.com/users/j-bennet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/j-bennet/subscriptions", "organizations_url": "https://api.github.com/users/j-bennet/orgs", "repos_url": "https://api.github.com/users/j-bennet/repos", "events_url": "https://api.github.com/users/j-bennet/events{/privacy}", "received_events_url": "https://api.github.com/users/j-bennet/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2023-04-04T19:15:01Z", "updated_at": "2023-04-10T17:22:02Z", "closed_at": "2023-04-10T17:22:01Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "We've started seeing the following failures on `main` in our Windows Python 3.11 build (see [this CI build](https://github.com/dask/dask/actions/runs/4601771371/jobs/8130021670) for example):\r\n\r\n```\r\nFAILED dask/dataframe/io/tests/test_parquet.py::test_append_known_divisions_to_unknown_divisions_works[fastparquet] - ValueError: Appended dtypes differ.\r\n{('__null_dask_index__', dtype('int32')), ('__null_dask_index__', dtype('int64'))}\r\nFAILED dask/dataframe/io/tests/test_parquet.py::test_append_known_divisions_to_unknown_divisions_works[pyarrow] - ValueError: Appended dtypes differ.\r\n{('x', 'int32'), ('__null_dask_index__', dtype('int64')), ('__null_dask_index__', 'int32'), ('x', dtype('int32')), ('y', dtype('int32')), ('y', 'int32')}\r\nFAILED dask/dataframe/io/tests/test_parquet.py::test_partitioned_preserve_index[fastparquet-fastparquet] - AssertionError: Attributes of DataFrame.iloc[:, 1] (column name=\"B\") are different\r\n\r\nAttribute \"dtype\" are different\r\n[left]:  CategoricalDtype(categories=[0, 1, 2, 3], ordered=False)\r\n[right]: CategoricalDtype(categories=[0, 1, 2, 3], ordered=False)\r\nFAILED dask/dataframe/io/tests/test_parquet.py::test_partitioned_preserve_index[pyarrow-fastparquet] - AssertionError: Attributes of DataFrame.iloc[:, 1] (column name=\"B\") are different\r\n\r\nAttribute \"dtype\" are different\r\n[left]:  CategoricalDtype(categories=[0, 1, 2, 3], ordered=False)\r\n[right]: CategoricalDtype(categories=[0, 1, 2, 3], ordered=False)\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_unique[disk] - AssertionError: Series.index are different\r\n\r\nAttribute \"dtype\" are different\r\n[left]:  int64\r\n[right]: int32\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_unique[tasks] - AssertionError: Series.index are different\r\n\r\nAttribute \"dtype\" are different\r\n[left]:  int64\r\n[right]: int32\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_value_counts[disk-foo] - AssertionError: MultiIndex level [0] are different\r\n\r\nAttribute \"dtype\" are different\r\n[left]:  int64\r\n[right]: int32\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_value_counts[disk-by1] - AssertionError: MultiIndex level [0] are different\r\n\r\nAttribute \"dtype\" are different\r\n[left]:  int64\r\n[right]: int32\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_value_counts[tasks-foo] - AssertionError: MultiIndex level [0] are different\r\n\r\nAttribute \"dtype\" are different\r\n[left]:  int64\r\n[right]: int32\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_value_counts[tasks-by1] - AssertionError: MultiIndex level [0] are different\r\n\r\nAttribute \"dtype\" are different\r\n[left]:  int64\r\n[right]: int32\r\nFAILED dask/dataframe/tests/test_utils_dataframe.py::test_meta_nonempty_index - AssertionError: assert dtype('int32') == 'int64'\r\n +  where dtype('int32') = Index([1, 2], dtype='int32', name='foo').dtype\r\n```\r\n\r\ncc @j-bennet @charlesbluca @rjzamora @phofl do any of you have bandwidth to look into what's causing these? My initial guess would be the `pandas=2.0` release, but that just a guess. ", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/10146/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/10146/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/10144", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/10144/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/10144/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/10144/events", "html_url": "https://github.com/dask/dask/issues/10144", "id": 1654299383, "node_id": "I_kwDOAbcwm85impr3", "number": 10144, "title": "`dask/tests/test_distributed.py::test_default_scheduler_on_worker` failing on `main`", "user": {"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2023-04-04T17:39:29Z", "updated_at": "2023-04-04T20:23:57Z", "closed_at": "2023-04-04T20:23:57Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "`dask/tests/test_distributed.py::test_default_scheduler_on_worker` has started failing on `main` and PRs. See [this build](https://github.com/dask/dask/actions/runs/4607248218/jobs/8141532586?pr=10140) for an example. Testing locally, it appears https://github.com/dask/distributed/pull/7656 is where things started failing.\r\n\r\ncc @gjoseph92 @ntabris @fjetter for visibility ", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/10144/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/10144/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/10127", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/10127/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/10127/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/10127/events", "html_url": "https://github.com/dask/dask/issues/10127", "id": 1647335745, "node_id": "I_kwDOAbcwm85iMFlB", "number": 10127, "title": "Since #10111 groupby numeric_only=False might not raise if a column name is `None`", "user": {"login": "wence-", "id": 1126981, "node_id": "MDQ6VXNlcjExMjY5ODE=", "avatar_url": "https://avatars.githubusercontent.com/u/1126981?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wence-", "html_url": "https://github.com/wence-", "followers_url": "https://api.github.com/users/wence-/followers", "following_url": "https://api.github.com/users/wence-/following{/other_user}", "gists_url": "https://api.github.com/users/wence-/gists{/gist_id}", "starred_url": "https://api.github.com/users/wence-/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wence-/subscriptions", "organizations_url": "https://api.github.com/users/wence-/orgs", "repos_url": "https://api.github.com/users/wence-/repos", "events_url": "https://api.github.com/users/wence-/events{/privacy}", "received_events_url": "https://api.github.com/users/wence-/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2023-03-30T10:23:58Z", "updated_at": "2023-03-30T20:05:30Z", "closed_at": "2023-03-30T20:05:30Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Describe the issue**:\r\n\r\n#10111 avoids the deprecated `GroupBy.dtypes` properties by asking the `GroupBy.Grouper` for its `names`, which are taken as the set of columns that are being grouped on. Unfortunately, this is only non-ambiguous when the dataframe _does not_ have `None` as a column name.\r\n\r\nThe usual case is that someone groups on some list of column names, but one can also group on (say) a function object that assigns each row to a group. In that case, the `grouper.names` property will return `[None]` which is unfortunately indistinguishable from the column named `None`. Now, should one be allowed to have a column whose name is `None`? Probably not, unfortunately for now it is possible.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n\r\ndf = pd.DataFrame({\"a\": [1, 2, 3], None: [\"a\", \"b\", \"c\"]})\r\nddf = dd.from_pandas(df, npartitions=1)\r\n\r\n# I expect this to raise NotImplementedError\r\nddf.groupby(lambda x: x % 2).mean(numeric_only=False).compute()\r\n```\r\nWith 55dfbb0e this raises as expected, but on main it does not.\r\n\r\nUnfortunately, this seems hard to fix without going back to actually doing some compute on `_meta`, but that is probably OK (since it's small).\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/10127/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/10127/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/10118", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/10118/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/10118/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/10118/events", "html_url": "https://github.com/dask/dask/issues/10118", "id": 1642231499, "node_id": "I_kwDOAbcwm85h4nbL", "number": 10118, "title": "`DataFrame.categorize` drops all annotations when computing categories even if low level fusion is deactivated", "user": {"login": "hendrikmakait", "id": 2699097, "node_id": "MDQ6VXNlcjI2OTkwOTc=", "avatar_url": "https://avatars.githubusercontent.com/u/2699097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hendrikmakait", "html_url": "https://github.com/hendrikmakait", "followers_url": "https://api.github.com/users/hendrikmakait/followers", "following_url": "https://api.github.com/users/hendrikmakait/following{/other_user}", "gists_url": "https://api.github.com/users/hendrikmakait/gists{/gist_id}", "starred_url": "https://api.github.com/users/hendrikmakait/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hendrikmakait/subscriptions", "organizations_url": "https://api.github.com/users/hendrikmakait/orgs", "repos_url": "https://api.github.com/users/hendrikmakait/repos", "events_url": "https://api.github.com/users/hendrikmakait/events{/privacy}", "received_events_url": "https://api.github.com/users/hendrikmakait/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2023-03-27T14:39:50Z", "updated_at": "2023-03-27T21:28:58Z", "closed_at": "2023-03-27T21:28:58Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# Problem\r\n\r\n`DataFrame.categorize` drops all annotations from the input graph when computing the categories even if low level fusion is deactivated.\r\n\r\n# Example\r\nSimplified version of https://github.com/dask/distributed/issues/7615#issuecomment-1484828091:\r\n\r\n```python3\r\nfrom __future__ import annotations\r\n\r\nimport dask\r\nimport dask.dataframe as dd\r\nfrom dask.distributed import Client, LocalCluster\r\n\r\n\r\ndef foo():\r\n    cluster = LocalCluster()\r\n    client = Client(cluster)\r\n    df = dask.datasets.timeseries(\r\n        start=\"2000-01-01\",\r\n        end=\"2000-03-01\",\r\n        dtypes={\"x\": float, \"y\": str},\r\n        freq=\"10 s\",\r\n    )\r\n    df = dd.shuffle.shuffle(df, \"x\", shuffle=\"p2p\")\r\n    df = df.categorize(columns=[\"y\"])\r\n    df.compute()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    foo()\r\n```\r\n\r\n# Where do we drop annotations?\r\n\r\nWithin `categorize`, we compute the categories. In this step, we convert from a high-level graph to a low-level one without preserving the annotations:\r\nhttps://github.com/dask/dask/blob/0cbc46ac89b6f6a2cf949f2fd73c4c1175419db5/dask/dataframe/categorical.py#L149-L154\r\n\r\n# Related tickets\r\n* dask/distributed#7615\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/10118/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/10118/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/10100", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/10100/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/10100/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/10100/events", "html_url": "https://github.com/dask/dask/issues/10100", "id": 1634858176, "node_id": "I_kwDOAbcwm85hcfTA", "number": 10100, "title": "CI is broken no module `ipykernel`", "user": {"login": "j-bennet", "id": 637013, "node_id": "MDQ6VXNlcjYzNzAxMw==", "avatar_url": "https://avatars.githubusercontent.com/u/637013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/j-bennet", "html_url": "https://github.com/j-bennet", "followers_url": "https://api.github.com/users/j-bennet/followers", "following_url": "https://api.github.com/users/j-bennet/following{/other_user}", "gists_url": "https://api.github.com/users/j-bennet/gists{/gist_id}", "starred_url": "https://api.github.com/users/j-bennet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/j-bennet/subscriptions", "organizations_url": "https://api.github.com/users/j-bennet/orgs", "repos_url": "https://api.github.com/users/j-bennet/repos", "events_url": "https://api.github.com/users/j-bennet/events{/privacy}", "received_events_url": "https://api.github.com/users/j-bennet/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1887344368, "node_id": "MDU6TGFiZWwxODg3MzQ0MzY4", "url": "https://api.github.com/repos/dask/dask/labels/tests", "name": "tests", "color": "a0f9b4", "default": false, "description": "Unit tests and/or continuous integration"}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-03-22T00:00:35Z", "updated_at": "2023-04-03T20:12:51Z", "closed_at": "2023-04-03T20:12:51Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "New failures in CI:\r\n\r\n```\r\nFAILED dask/tests/test_base.py::test_visualize - ModuleNotFoundError: No module named 'ipykernel'\r\nFAILED dask/tests/test_dot.py::test_cytoscape_graph_custom - ModuleNotFoundError: No module named 'ipykernel'\r\nFAILED dask/tests/test_dot.py::test_cytoscape_graph - ModuleNotFoundError: No module named 'ipykernel'\r\n```\r\n\r\nThis is happening because `ipywidgets` doesn't list `ipykernel` as a dependency anymore:\r\n\r\nhttps://github.com/jupyter-widgets/ipywidgets/issues/3731\r\n\r\nNote that simply adding latest `ipykernel` to reqs would break other things, because of a deprecation:\r\n\r\nhttps://github.com/dask/distributed/issues/7688\r\n\r\nWe need `ipykernel<6.22.0`.", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/10100/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/10100/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/10099", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/10099/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/10099/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/10099/events", "html_url": "https://github.com/dask/dask/issues/10099", "id": 1634344321, "node_id": "I_kwDOAbcwm85hah2B", "number": 10099, "title": "Documentation build failing", "user": {"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386719598, "node_id": "MDU6TGFiZWwzODY3MTk1OTg=", "url": "https://api.github.com/repos/dask/dask/labels/documentation", "name": "documentation", "color": "f9d0c4", "default": true, "description": "Improve or add to documentation"}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-03-21T16:56:05Z", "updated_at": "2023-03-22T15:09:20Z", "closed_at": "2023-03-22T15:09:19Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Our docs build has started failing with\r\n\r\n```\r\nRunning Sphinx v4.5.0\r\nloading translations [en]... done\r\nmaking output directory... done\r\nloading intersphinx inventory from https://docs.python.org/3/objects.inv...\r\nloading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...\r\nloading intersphinx inventory from https://numpy.org/doc/stable/objects.inv...\r\nloading intersphinx inventory from https://asyncssh.readthedocs.io/en/latest/objects.inv...\r\nloading intersphinx inventory from https://distributed.dask.org/en/latest/objects.inv...\r\nloading intersphinx inventory from https://arrow.apache.org/docs/objects.inv...\r\nloading intersphinx inventory from https://zarr.readthedocs.io/en/latest/objects.inv...\r\nloading intersphinx inventory from https://scikit-image.org/docs/dev/objects.inv...\r\nloading intersphinx inventory from https://filesystem-spec.readthedocs.io/en/latest/objects.inv...\r\nloading intersphinx inventory from https://click.palletsprojects.com/en/latest/objects.inv...\r\nloading intersphinx inventory from https://docs.scipy.org/doc/scipy/objects.inv...\r\n[autosummary] generating autosummary for: 10-minutes-to-dask.rst, api.rst, array-api.rst, array-assignment.rst, array-best-practices.rst, array-chunks.rst, array-creation.rst, array-design.rst, array-gufunc.rst, array-overlap.rst, ..., scheduler-overview.rst, scheduling-policy.rst, scheduling.rst, shared.rst, spark.rst, spec.rst, support.rst, understanding-performance.rst, user-interfaces.rst, why.rst\r\n[autosummary] generating autosummary for: /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.array.Array.all.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.array.Array.any.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.array.Array.argmax.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.array.Array.argmin.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.array.Array.argtopk.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.array.Array.astype.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.array.Array.blocks.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.array.Array.choose.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.array.Array.chunks.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.array.Array.chunksize.rst, ..., /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.dataframe.tseries.resample.Resampler.ohlc.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.dataframe.tseries.resample.Resampler.prod.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.dataframe.tseries.resample.Resampler.quantile.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.dataframe.tseries.resample.Resampler.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.dataframe.tseries.resample.Resampler.sem.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.dataframe.tseries.resample.Resampler.size.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.dataframe.tseries.resample.Resampler.std.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.dataframe.tseries.resample.Resampler.sum.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.dataframe.tseries.resample.Resampler.var.rst, /home/docs/checkouts/readthedocs.org/user_builds/dask/checkouts/10098/docs/source/generated/dask.dataframe.utils.make_meta.rst\r\nbuilding [mo]: targets for 0 po files that are out of date\r\nbuilding [html]: targets for 95 source files that are out of date\r\nupdating environment: [new config] 1021 added, 0 changed, 0 removed\r\nreading sources... [  0%] 10-minutes-to-dask\r\nexecuting 10-minutes-to-dask\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/jupyter_sphinx/utils.py\", line 13, in blank_nb\r\n    spec = get_kernel_spec(kernel_name)\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/jupyter_client/kernelspec.py\", line 426, in get_kernel_spec\r\n    return KernelSpecManager().get_kernel_spec(kernel_name)\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/jupyter_client/kernelspec.py\", line 287, in get_kernel_spec\r\n    raise NoSuchKernel(kernel_name)\r\njupyter_client.kernelspec.NoSuchKernel: No such kernel named python3\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/sphinx/cmd/build.py\", line 276, in build_main\r\n    app.build(args.force_all, filenames)\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/sphinx/application.py\", line 330, in build\r\n    self.builder.build_update()\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/sphinx/builders/__init__.py\", line 286, in build_update\r\n    self.build(to_build,\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/sphinx/builders/__init__.py\", line 300, in build\r\n    updated_docnames = set(self.read())\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/sphinx/builders/__init__.py\", line 407, in read\r\n    self._read_serial(docnames)\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/sphinx/builders/__init__.py\", line 428, in _read_serial\r\n    self.read_doc(docname)\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/sphinx/builders/__init__.py\", line 468, in read_doc\r\n    doctree = read_doc(self.app, self.env, self.env.doc2path(docname))\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/sphinx/io.py\", line 181, in read_doc\r\n    pub.publish()\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/docutils/core.py\", line 219, in publish\r\n    self.apply_transforms()\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/docutils/core.py\", line 200, in apply_transforms\r\n    self.document.transformer.apply_transforms()\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/sphinx/transforms/__init__.py\", line 79, in apply_transforms\r\n    super().apply_transforms()\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/docutils/transforms/__init__.py\", line 171, in apply_transforms\r\n    transform.apply(**kwargs)\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/jupyter_sphinx/execute.py\", line 158, in apply\r\n    notebook = execute_cells(\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/jupyter_sphinx/execute.py\", line 288, in execute_cells\r\n    notebook = blank_nb(kernel_name)\r\n  File \"/home/docs/checkouts/readthedocs.org/user_builds/dask/envs/10098/lib/python3.9/site-packages/jupyter_sphinx/utils.py\", line 15, in blank_nb\r\n    raise ExtensionError(\"Unable to find kernel\", orig_exc=e)\r\nsphinx.errors.ExtensionError: Unable to find kernel (exception: No such kernel named python3)\r\n\r\nExtension error:\r\nUnable to find kernel (exception: No such kernel named python3)\r\n```\r\n\r\nSee [this build](https://readthedocs.org/projects/dask/builds/19854932/) for an example", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/10099/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/10099/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/10058", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/10058/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/10058/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/10058/events", "html_url": "https://github.com/dask/dask/issues/10058", "id": 1622698144, "node_id": "I_kwDOAbcwm85guGig", "number": 10058, "title": "Broken link in docs developer contributing guide", "user": {"login": "GenevieveBuckley", "id": 30920819, "node_id": "MDQ6VXNlcjMwOTIwODE5", "avatar_url": "https://avatars.githubusercontent.com/u/30920819?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GenevieveBuckley", "html_url": "https://github.com/GenevieveBuckley", "followers_url": "https://api.github.com/users/GenevieveBuckley/followers", "following_url": "https://api.github.com/users/GenevieveBuckley/following{/other_user}", "gists_url": "https://api.github.com/users/GenevieveBuckley/gists{/gist_id}", "starred_url": "https://api.github.com/users/GenevieveBuckley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GenevieveBuckley/subscriptions", "organizations_url": "https://api.github.com/users/GenevieveBuckley/orgs", "repos_url": "https://api.github.com/users/GenevieveBuckley/repos", "events_url": "https://api.github.com/users/GenevieveBuckley/events{/privacy}", "received_events_url": "https://api.github.com/users/GenevieveBuckley/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386719598, "node_id": "MDU6TGFiZWwzODY3MTk1OTg=", "url": "https://api.github.com/repos/dask/dask/labels/documentation", "name": "documentation", "color": "f9d0c4", "default": true, "description": "Improve or add to documentation"}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2023-03-14T04:22:31Z", "updated_at": "2023-03-14T18:46:33Z", "closed_at": "2023-03-14T18:46:33Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "There is a broken link in the docs. In the [developer guide](https://docs.dask.org/en/stable/develop.html?highlight=gpu%20ci#gpu-ci), from the file [dask/docs/source/develop.rst](https://github.com/dask/dask/blob/main/docs/source/develop.rst), it says:\r\n> For more information about gpuCI please consult the `docs page\r\n<https://docs.rapids.ai/gpuci>`_\r\n\r\n...but this link redirects to \"Page Not Found\".\r\n\r\nI've searched the website and [docs repository](), but cannot find where this information is anymore. \r\nThere used to be a file called `rapidsai/docs/gpuci/gpuci.md`, with the title \"gpuCI Usage Docs\" (page first introduced [here](https://github.com/rapidsai/docs/commit/9a7a85eeb853838e6574367894c8327e8969c3e9)).\r\n\r\nAt first I thought that page might have been moved somewhere else, like to a different folder in the repo. But the more I search, the more I'm starting to think that perhaps it's been deleted from the rapids docs altogether?", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/10058/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/10058/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/10043", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/10043/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/10043/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/10043/events", "html_url": "https://github.com/dask/dask/pull/10043", "id": 1617873833, "node_id": "PR_kwDOAbcwm85Ltbly", "number": 10043, "title": "Avoid using `dd.shuffle` in groupby-apply", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}, {"id": 4410724893, "node_id": "LA_kwDOAbcwm88AAAABBuZSHQ", "url": "https://api.github.com/repos/dask/dask/labels/gpu", "name": "gpu", "color": "3D0CD2", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2023-03-09T19:29:59Z", "updated_at": "2023-03-24T18:27:45Z", "closed_at": "2023-03-24T18:27:10Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/10043", "html_url": "https://github.com/dask/dask/pull/10043", "diff_url": "https://github.com/dask/dask/pull/10043.diff", "patch_url": "https://github.com/dask/dask/pull/10043.patch", "merged_at": "2023-03-24T18:27:10Z"}, "body": "Some RAPIDS developers have been seing p2p errors while using the \"cudf\" backend (which does not support the p2p method just yet). This PR tweaks `_GroupBy._shuffle` to effectively use `self.obj.shuffle` instead of `dd.shuffle` to make sure `dask_cudf` has the opportunity to set the appropriate default algorithm.\r\n\r\ncc @charlesbluca \r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/10043/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/10043/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/10042", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/10042/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/10042/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/10042/events", "html_url": "https://github.com/dask/dask/pull/10042", "id": 1617456604, "node_id": "PR_kwDOAbcwm85LsAhT", "number": 10042, "title": "Fix handling of missing min/max parquet statistics during filtering", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2023-03-09T15:19:34Z", "updated_at": "2023-03-27T16:01:32Z", "closed_at": "2023-03-27T16:01:28Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/10042", "html_url": "https://github.com/dask/dask/pull/10042", "diff_url": "https://github.com/dask/dask/pull/10042.diff", "patch_url": "https://github.com/dask/dask/pull/10042.patch", "merged_at": "2023-03-27T16:01:27Z"}, "body": "Tweaks logic in `apply_filters`, and improves test coverage for filtering on columns with missing min/max statistics.\r\n\r\n- [x] Closes #9975\r\n- [x] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/10042/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/10042/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/10036", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/10036/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/10036/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/10036/events", "html_url": "https://github.com/dask/dask/issues/10036", "id": 1615590653, "node_id": "I_kwDOAbcwm85gS_T9", "number": 10036, "title": "`pyarrow_compat` tests failing with `pandas` 2.0", "user": {"login": "github-actions[bot]", "id": 41898282, "node_id": "MDM6Qm90NDE4OTgyODI=", "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/github-actions%5Bbot%5D", "html_url": "https://github.com/apps/github-actions", "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers", "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos", "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 1887344368, "node_id": "MDU6TGFiZWwxODg3MzQ0MzY4", "url": "https://api.github.com/repos/dask/dask/labels/tests", "name": "tests", "color": "a0f9b4", "default": false, "description": "Unit tests and/or continuous integration"}, {"id": 2949860090, "node_id": "MDU6TGFiZWwyOTQ5ODYwMDkw", "url": "https://api.github.com/repos/dask/dask/labels/upstream", "name": "upstream", "color": "DDF8B0", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2023-03-08T16:50:27Z", "updated_at": "2023-03-17T17:31:21Z", "closed_at": "2023-03-17T17:31:21Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "[Workflow Run URL](https://github.com/dask/dask/actions/runs/4411557822)\n<details><summary>Python 3.10 Test Summary</summary>\n\n```\ndask/dataframe/tests/test_pyarrow_compat.py::test_pickle_roundtrip[uint8]: assert 23526 > (12161 * 3)\n +  where 23526 = len(b\"\\x80\\x04\\x95\\xdb[\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94M\\x10'\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x05uint8\\x94\\x85\\x94R\\x94M\\x10'K\\xc8K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xf...x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x00\\x01c\\x01\\x00\\x01\\x00\\x01\\x00\\x01\\x00\\x00\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x00\\x01c\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14M\\x10'h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00M\\x10'K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.\")\n +  and   12161 = len(b\"\\x80\\x04\\x95v/\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94K\\x02\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x05uint8\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff...\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x02\\x01\\x00\\x01c\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94ah&\\x8c\\x05uint8\\x94\\x85\\x94R\\x94\\x86\\x94R\\x94\\x8c\\x06_dtype\\x94\\x8c\\x1epandas.core.arrays.arrow.dtype\\x94\\x8c\\nArrowDtype\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x07storage\\x94\\x8c\\x07pyarrow\\x94\\x8c\\rpyarrow_dtype\\x94h&\\x8c\\x05uint8\\x94\\x85\\x94R\\x94ub\\x8c\\x05_data\\x94h$(h&\\x8c\\x05uint8\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(Nh,h/C\\x02\\x01\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14K\\x02h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00K\\x02K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.\")\ndask/dataframe/tests/test_pyarrow_compat.py::test_pickle_roundtrip[uint16]: assert 43530 > (22167 * 3)\n +  where 43530 = len(b\"\\x80\\x04\\x95\\xff\\xa9\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94M\\x10'\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x06uint16\\x94\\x85\\x94R\\x94M\\x10'K\\xc8K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xf...\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x00\\x00\\x01\\x00c\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14M\\x10'h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00M\\x10'K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.\")\n +  and   22167 = len(b'\\x80\\x04\\x95\\x8cV\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94K\\x02\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x06uint16\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff...0\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x02\\x00\\x01\\x00\\x00\\x00\\x01\\x00c\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94ah&\\x8c\\x06uint16\\x94\\x85\\x94R\\x94\\x86\\x94R\\x94\\x8c\\x06_dtype\\x94\\x8c\\x1epandas.core.arrays.arrow.dtype\\x94\\x8c\\nArrowDtype\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x07storage\\x94\\x8c\\x07pyarrow\\x94\\x8c\\rpyarrow_dtype\\x94h&\\x8c\\x06uint16\\x94\\x85\\x94R\\x94ub\\x8c\\x05_data\\x94h$(h&\\x8c\\x06uint16\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(Nh,h/C\\x04\\x01\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14K\\x02h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00K\\x02K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.')\ndask/dataframe/tests/test_pyarrow_compat.py::test_pickle_roundtrip[uint32]: assert 83539 > (42171 * 3)\n +  where 83539 = len(b\"\\x80\\x04\\x95cE\\x01\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94M\\x10'\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x06uint32\\x94\\x85\\x94R\\x94M\\x10'K\\xc8K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\...\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00c\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e\\x95\\xdc\\x00\\x00\\x00\\x00\\x00\\x00\\x00]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14M\\x10'h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00M\\x10'K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.\")\n +  and   42171 = len(b'\\x80\\x04\\x95\\xb0\\xa4\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94K\\x02\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x06uint32\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\...0\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00c\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94ah&\\x8c\\x06uint32\\x94\\x85\\x94R\\x94\\x86\\x94R\\x94\\x8c\\x06_dtype\\x94\\x8c\\x1epandas.core.arrays.arrow.dtype\\x94\\x8c\\nArrowDtype\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x07storage\\x94\\x8c\\x07pyarrow\\x94\\x8c\\rpyarrow_dtype\\x94h&\\x8c\\x06uint32\\x94\\x85\\x94R\\x94ub\\x8c\\x05_data\\x94h$(h&\\x8c\\x06uint32\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(Nh,h/C\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14K\\x02h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00K\\x02K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.')\ndask/dataframe/tests/test_pyarrow_compat.py::test_pickle_roundtrip[uint64]: assert 163548 > (82188 * 3)\n +  where 163548 = len(b\"\\x80\\x04\\x95\\xbc\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94M\\x10'\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x06uint64\\x94\\x85\\x94R\\x94M\\x10'K\\xc8K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xf...\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x95\\xe6\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14M\\x10'h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00M\\x10'K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.\")\n +  and   82188 = len(b'\\x80\\x04\\x95\\xba\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94K\\x02\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x06uint64\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\...0\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x95\\xb9\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94ah&\\x8c\\x06uint64\\x94\\x85\\x94R\\x94\\x86\\x94R\\x94\\x8c\\x06_dtype\\x94\\x8c\\x1epandas.core.arrays.arrow.dtype\\x94\\x8c\\nArrowDtype\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x07storage\\x94\\x8c\\x07pyarrow\\x94\\x8c\\rpyarrow_dtype\\x94h&\\x8c\\x06uint64\\x94\\x85\\x94R\\x94ub\\x8c\\x05_data\\x94h$(h&\\x8c\\x06uint64\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(Nh,h/C\\x10\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14K\\x02h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00K\\x02K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.')\ndask/dataframe/tests/test_pyarrow_compat.py::test_pickle_roundtrip[int8]: assert 23522 > (12157 * 3)\n +  where 23522 = len(b\"\\x80\\x04\\x95\\xd7[\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94M\\x10'\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x04int8\\x94\\x85\\x94R\\x94M\\x10'K\\xc8K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff...xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\x00\\x01c\\x01\\x00\\x01\\x00\\x01\\x00\\x01\\x00\\x00\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\x00\\x01c\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14M\\x10'h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00M\\x10'K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.\")\n +  and   12157 = len(b\"\\x80\\x04\\x95r/\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94K\\x02\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x04int8\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\...xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\xfe\\xff\\x00\\x01c\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94ah&\\x8c\\x04int8\\x94\\x85\\x94R\\x94\\x86\\x94R\\x94\\x8c\\x06_dtype\\x94\\x8c\\x1epandas.core.arrays.arrow.dtype\\x94\\x8c\\nArrowDtype\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x07storage\\x94\\x8c\\x07pyarrow\\x94\\x8c\\rpyarrow_dtype\\x94h&\\x8c\\x04int8\\x94\\x85\\x94R\\x94ub\\x8c\\x05_data\\x94h$(h&\\x8c\\x04int8\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(Nh,h/C\\x02\\x01\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14K\\x02h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00K\\x02K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.\")\ndask/dataframe/tests/test_pyarrow_compat.py::test_pickle_roundtrip[int16]: assert 43526 > (22163 * 3)\n +  where 43526 = len(b\"\\x80\\x04\\x95\\xfb\\xa9\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94M\\x10'\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x05int16\\x94\\x85\\x94R\\x94M\\x10'K\\xc8K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff...\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00c\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14M\\x10'h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00M\\x10'K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.\")\n +  and   22163 = len(b'\\x80\\x04\\x95\\x88V\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94K\\x02\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x05int16\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\...\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00c\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94ah&\\x8c\\x05int16\\x94\\x85\\x94R\\x94\\x86\\x94R\\x94\\x8c\\x06_dtype\\x94\\x8c\\x1epandas.core.arrays.arrow.dtype\\x94\\x8c\\nArrowDtype\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x07storage\\x94\\x8c\\x07pyarrow\\x94\\x8c\\rpyarrow_dtype\\x94h&\\x8c\\x05int16\\x94\\x85\\x94R\\x94ub\\x8c\\x05_data\\x94h$(h&\\x8c\\x05int16\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(Nh,h/C\\x04\\x01\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14K\\x02h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00K\\x02K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.')\ndask/dataframe/tests/test_pyarrow_compat.py::test_pickle_roundtrip[int32]: assert 83535 > (42167 * 3)\n +  where 83535 = len(b\"\\x80\\x04\\x95_E\\x01\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94M\\x10'\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x05int32\\x94\\x85\\x94R\\x94M\\x10'K\\xc8K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x...\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00c\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e\\x95\\xdc\\x00\\x00\\x00\\x00\\x00\\x00\\x00]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14M\\x10'h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00M\\x10'K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.\")\n +  and   42167 = len(b'\\x80\\x04\\x95\\xac\\xa4\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94K\\x02\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x05int32\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\x...\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00c\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94ah&\\x8c\\x05int32\\x94\\x85\\x94R\\x94\\x86\\x94R\\x94\\x8c\\x06_dtype\\x94\\x8c\\x1epandas.core.arrays.arrow.dtype\\x94\\x8c\\nArrowDtype\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x07storage\\x94\\x8c\\x07pyarrow\\x94\\x8c\\rpyarrow_dtype\\x94h&\\x8c\\x05int32\\x94\\x85\\x94R\\x94ub\\x8c\\x05_data\\x94h$(h&\\x8c\\x05int32\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(Nh,h/C\\x08\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14K\\x02h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00K\\x02K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.')\ndask/dataframe/tests/test_pyarrow_compat.py::test_pickle_roundtrip[int64]: assert 163544 > (82184 * 3)\n +  where 163544 = len(b\"\\x80\\x04\\x95\\xbb\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94M\\x10'\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x05int64\\x94\\x85\\x94R\\x94M\\x10'K\\xc8K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff...\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x95\\xe6\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14M\\x10'h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00M\\x10'K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.\")\n +  and   82184 = len(b'\\x80\\x04\\x95\\xb9\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94K\\x02\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x05int64\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\x...\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x95\\xb6\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94ah&\\x8c\\x05int64\\x94\\x85\\x94R\\x94\\x86\\x94R\\x94\\x8c\\x06_dtype\\x94\\x8c\\x1epandas.core.arrays.arrow.dtype\\x94\\x8c\\nArrowDtype\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x07storage\\x94\\x8c\\x07pyarrow\\x94\\x8c\\rpyarrow_dtype\\x94h&\\x8c\\x05int64\\x94\\x85\\x94R\\x94ub\\x8c\\x05_data\\x94h$(h&\\x8c\\x05int64\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(Nh,h/C\\x10\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14K\\x02h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00K\\x02K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.')\ndask/dataframe/tests/test_pyarrow_compat.py::test_pickle_roundtrip[float]: assert 83535 > (42167 * 3)\n +  where 83535 = len(b\"\\x80\\x04\\x95_E\\x01\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94M\\x10'\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x05float\\x94\\x85\\x94R\\x94M\\x10'K\\xc8K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x...x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00?\\x00\\x00\\xc7B\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e\\x95\\xdc\\x00\\x00\\x00\\x00\\x00\\x00\\x00]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14M\\x10'h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00M\\x10'K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.\")\n +  and   42167 = len(b'\\x80\\x04\\x95\\xac\\xa4\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94K\\x02\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x05float\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\x...c0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\xc0\\x00\\x00\\x80\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00?\\x00\\x00\\xc7B\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94ah&\\x8c\\x05float\\x94\\x85\\x94R\\x94\\x86\\x94R\\x94\\x8c\\x06_dtype\\x94\\x8c\\x1epandas.core.arrays.arrow.dtype\\x94\\x8c\\nArrowDtype\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x07storage\\x94\\x8c\\x07pyarrow\\x94\\x8c\\rpyarrow_dtype\\x94h&\\x8c\\x05float\\x94\\x85\\x94R\\x94ub\\x8c\\x05_data\\x94h$(h&\\x8c\\x05float\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(Nh,h/C\\x08\\x00\\x00\\x80?\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14K\\x02h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00K\\x02K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.')\ndask/dataframe/tests/test_pyarrow_compat.py::test_pickle_roundtrip[double]: assert 163548 > (82188 * 3)\n +  where 163548 = len(b\"\\x80\\x04\\x95\\xbc\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94M\\x10'\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x06double\\x94\\x85\\x94R\\x94M\\x10'K\\xc8K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xf...00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xe0?\\x00\\x00\\x00\\x00\\x00\\xe0X@\\x95\\xe6\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14M\\x10'h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00M\\x10'K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.\")\n +  and   82188 = len(b'\\x80\\x04\\x95\\xba\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x12pandas.core.series\\x94\\x8c\\x06Series\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x04_mgr\\x94\\x8c\\x1epandas.core.internals.managers\\x94\\x8c\\x12SingleBlockManager\\x94\\x93\\x94)\\x81\\x94(]\\x94\\x8c\\x18pandas.core.indexes.base\\x94\\x8c\\n_new_Index\\x94\\x93\\x94\\x8c\\x19pandas.core.indexes.range\\x94\\x8c\\nRangeIndex\\x94\\x93\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x05start\\x94K\\x00\\x8c\\x04stop\\x94K\\x02\\x8c\\x04step\\x94K\\x01u\\x86\\x94R\\x94a]\\x94\\x8c\\x1epandas.core.arrays.arrow.array\\x94\\x8c\\x13ArrowExtensionArray\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\t_pa_array\\x94\\x8c\\x0bpyarrow.lib\\x94\\x8c\\rchunked_array\\x94\\x93\\x94]\\x94h\\x1f\\x8c\\x0e_restore_array\\x94\\x93\\x94(h\\x1f\\x8c\\x0etype_for_alias\\x94\\x93\\x94\\x8c\\x06double\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(h\\x1f\\x8c\\tpy_buffer\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\xe2\\x04\\x00\\x00\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xef\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xdf\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\...00\\x00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\xf0\\xbf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xe0?\\x00\\x00\\x00\\x00\\x00\\xe0X@\\x95\\xb9\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94ah&\\x8c\\x06double\\x94\\x85\\x94R\\x94\\x86\\x94R\\x94\\x8c\\x06_dtype\\x94\\x8c\\x1epandas.core.arrays.arrow.dtype\\x94\\x8c\\nArrowDtype\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x07storage\\x94\\x8c\\x07pyarrow\\x94\\x8c\\rpyarrow_dtype\\x94h&\\x8c\\x06double\\x94\\x85\\x94R\\x94ub\\x8c\\x05_data\\x94h$(h&\\x8c\\x06double\\x94\\x85\\x94R\\x94K\\x02K\\x00K\\x00]\\x94(Nh,h/C\\x10\\x00\\x00\\x00\\x00\\x00\\x00\\xf0?\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94\\x85\\x94R\\x94e]\\x94Nt\\x94\\x85\\x94R\\x94uba]\\x94h\\rh\\x10}\\x94(h\\x12Nh\\x13K\\x00h\\x14K\\x02h\\x15K\\x01u\\x86\\x94R\\x94a}\\x94\\x8c\\x060.14.1\\x94}\\x94(\\x8c\\x04axes\\x94h\\n\\x8c\\x06blocks\\x94]\\x94}\\x94(\\x8c\\x06values\\x94h\\x1c\\x8c\\x08mgr_locs\\x94h-\\x8c\\x05slice\\x94\\x93\\x94K\\x00K\\x02K\\x01\\x87\\x94R\\x94uaust\\x94b\\x8c\\x04_typ\\x94\\x8c\\x06series\\x94\\x8c\\t_metadata\\x94]\\x94h\\x12a\\x8c\\x05attrs\\x94}\\x94\\x8c\\x06_flags\\x94}\\x94\\x8c\\x17allows_duplicate_labels\\x94\\x88sh\\x12Nub.')\n+ 32 failing tests\n```\n\n</details>\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/10036/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/10036/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/10025", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/10025/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/10025/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/10025/events", "html_url": "https://github.com/dask/dask/issues/10025", "id": 1612388081, "node_id": "I_kwDOAbcwm85gGxbx", "number": 10025, "title": "[pyarrow strings] consistently handle `string[pyarrow]` in `MultiIndex`", "user": {"login": "j-bennet", "id": 637013, "node_id": "MDQ6VXNlcjYzNzAxMw==", "avatar_url": "https://avatars.githubusercontent.com/u/637013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/j-bennet", "html_url": "https://github.com/j-bennet", "followers_url": "https://api.github.com/users/j-bennet/followers", "following_url": "https://api.github.com/users/j-bennet/following{/other_user}", "gists_url": "https://api.github.com/users/j-bennet/gists{/gist_id}", "starred_url": "https://api.github.com/users/j-bennet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/j-bennet/subscriptions", "organizations_url": "https://api.github.com/users/j-bennet/orgs", "repos_url": "https://api.github.com/users/j-bennet/repos", "events_url": "https://api.github.com/users/j-bennet/events{/privacy}", "received_events_url": "https://api.github.com/users/j-bennet/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 1887344368, "node_id": "MDU6TGFiZWwxODg3MzQ0MzY4", "url": "https://api.github.com/repos/dask/dask/labels/tests", "name": "tests", "color": "a0f9b4", "default": false, "description": "Unit tests and/or continuous integration"}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2023-03-06T23:20:41Z", "updated_at": "2023-03-10T05:16:52Z", "closed_at": "2023-03-10T05:16:52Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Describe the issue**:\r\n\r\nFollow-up for https://github.com/dask/dask/pull/10000.\r\n\r\nThese tests failed with `pyarrow` strings and were xfailed, but we still need a fix:\r\n\r\n```\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_multiprocessing[disk] - AssertionError: MultiIndex level [0] are different\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_multiprocessing[tasks] - AssertionError: MultiIndex level [0] are different\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_dropna_with_agg[disk-True] - AssertionError: MultiIndex level [0] are different\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_dropna_with_agg[disk-False] - AssertionError: MultiIndex level [0] are different\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_dropna_with_agg[tasks-True] - AssertionError: MultiIndex level [0] are different\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_dropna_with_agg[tasks-False] - AssertionError: MultiIndex level [0] are different\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_sort_argument[disk-True-count-by4] - AssertionError: MultiIndex level [1] are different\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_sort_argument[disk-False-count-by4] - AssertionError: MultiIndex level [1] are different\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_sort_argument[tasks-True-count-by4] - AssertionError: MultiIndex level [1] are different\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_sort_argument[tasks-False-count-by4] - AssertionError: MultiIndex level [1] are different\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_slice_getitem[disk-3-by0] - AssertionError: MultiIndex level [0] are different\r\nFAILED dask/dataframe/tests/test_groupby.py::test_groupby_slice_getitem[tasks-3-by0] - AssertionError: MultiIndex level [0] are different\r\nFAILED dask/dataframe/tests/test_rolling.py::test_groupby_rolling - AssertionError: MultiIndex level [0] are different\r\n```\r\n\r\nIt looks like when we're grouping on multiple columns in Dask, the resulting `MultiIndex` inherits the `string[pyarrow]` dtype from its parent columns.\r\n\r\nHowever, in `Frame` constructor, we don't use this dtype to convert the `MultiIndex` yet.\r\n\r\n**Environment**:\r\n\r\n- Dask version:\r\n- Python version:\r\n- Operating System:\r\n- Install method (conda, pip, source):\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/10025/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/10025/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9993", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9993/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9993/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9993/events", "html_url": "https://github.com/dask/dask/issues/9993", "id": 1596106726, "node_id": "I_kwDOAbcwm85fIqfm", "number": 9993, "title": "join works in Pandas but fails in Dask", "user": {"login": "twrightsman", "id": 6300973, "node_id": "MDQ6VXNlcjYzMDA5NzM=", "avatar_url": "https://avatars.githubusercontent.com/u/6300973?v=4", "gravatar_id": "", "url": "https://api.github.com/users/twrightsman", "html_url": "https://github.com/twrightsman", "followers_url": "https://api.github.com/users/twrightsman/followers", "following_url": "https://api.github.com/users/twrightsman/following{/other_user}", "gists_url": "https://api.github.com/users/twrightsman/gists{/gist_id}", "starred_url": "https://api.github.com/users/twrightsman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/twrightsman/subscriptions", "organizations_url": "https://api.github.com/users/twrightsman/orgs", "repos_url": "https://api.github.com/users/twrightsman/repos", "events_url": "https://api.github.com/users/twrightsman/events{/privacy}", "received_events_url": "https://api.github.com/users/twrightsman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2023-02-23T02:14:56Z", "updated_at": "2023-02-24T17:22:09Z", "closed_at": "2023-02-24T17:22:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Describe the issue**:\r\n\r\nI'm trying to join two larger-than-memory dataframes in Dask but get an error regarding mismatched columns. However, the same join operation works in Pandas on a smaller subset.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\n\r\ndata_fake_pd = pd.DataFrame(data = {'group': ['a', 'b', 'a', 'b', 'b'], 'value': [1.5, 0.2, 0.8, 0.01, 0.4]})\r\npassed_pd = data_fake_pd.groupby('group').apply(lambda subdata: ((subdata['value'] < 0.5).sum() / len(subdata)) > 0.5).rename('passed')\r\njoined_pd = data_fake_pd.join(passed_pd, on = 'group')\r\n\r\ndata_fake_dd = dd.from_pandas(data_fake_pd, npartitions = 2)\r\npassed_dd = data_fake_dd.groupby('group').apply(lambda subdata: ((subdata['value'] < 0.5).sum() / len(subdata)) > 0.5, meta = pd.Series(name = 'value', dtype = bool)).rename('passed')\r\njoined_dd = data_fake_dd.join(passed_dd, on = 'group', how = 'inner')\r\njoined_dd.compute()\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nTraceback:\r\n\r\n```\r\n  File \"/home/twrightsman/.conda/envs/dask-env/lib/python3.10/site-packages/dask/dataframe/utils.py\", line 429, in check_matching_columns\r\n    raise ValueError(\r\nValueError: The columns in the computed data do not match the columns in the provided metadata\r\n  Extra:   ['group']\r\n  Missing: [0]\r\n```\r\n\r\n`joined_dd` gives the expected correct meta, but fails to do the actual computation:\r\n\r\n```\r\n>>> joined_pd\r\n  group  value  passed\r\n0     a   1.50   False\r\n1     b   0.20    True\r\n2     a   0.80   False\r\n3     b   0.01    True\r\n4     b   0.40    True\r\n>>> joined_dd\r\nDask DataFrame Structure:\r\n                group    value passed\r\nnpartitions=2                        \r\n               object  float64   bool\r\n                  ...      ...    ...\r\n                  ...      ...    ...\r\nDask Name: merge_chunk, 16 graph layers\r\n```\r\n\r\nComputing both join operands before joining works as expected.\r\n\r\n```\r\n>>> data_fake_dd.compute().join(passed_dd.compute(), on = 'group', how = 'inner')\r\n  group  value  passed\r\n0     a   1.50   False\r\n2     a   0.80   False\r\n1     b   0.20    True\r\n3     b   0.01    True\r\n4     b   0.40    True\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2023.2.0\r\n- Python version: 3.10.8\r\n- Operating System: Linux\r\n- Install method (conda, pip, source): conda\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9993/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9993/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9966", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9966/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9966/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9966/events", "html_url": "https://github.com/dask/dask/issues/9966", "id": 1586758028, "node_id": "I_kwDOAbcwm85elAGM", "number": 9966, "title": "Categorical column dtype is not preserved during parquet roundtrip with pandas 2.0", "user": {"login": "j-bennet", "id": 637013, "node_id": "MDQ6VXNlcjYzNzAxMw==", "avatar_url": "https://avatars.githubusercontent.com/u/637013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/j-bennet", "html_url": "https://github.com/j-bennet", "followers_url": "https://api.github.com/users/j-bennet/followers", "following_url": "https://api.github.com/users/j-bennet/following{/other_user}", "gists_url": "https://api.github.com/users/j-bennet/gists{/gist_id}", "starred_url": "https://api.github.com/users/j-bennet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/j-bennet/subscriptions", "organizations_url": "https://api.github.com/users/j-bennet/orgs", "repos_url": "https://api.github.com/users/j-bennet/repos", "events_url": "https://api.github.com/users/j-bennet/events{/privacy}", "received_events_url": "https://api.github.com/users/j-bennet/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2023-02-15T23:45:27Z", "updated_at": "2023-04-03T22:09:00Z", "closed_at": "2023-04-03T22:09:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Describe the issue**:\r\n\r\nWith `pandas==2.0`, when reading parquet with partitioning on an integer column, the column is read back as a `CategoryDtype`, but its `dtype` is not consistent with `pyarrow`.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\nSee better example in [this comment](https://github.com/dask/dask/issues/9966#issuecomment-1432485259).\r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\nfrom pyarrow.dataset import HivePartitioning, write_dataset\r\n\r\ndf = pd.DataFrame({\"col1\": [1, 2], \"col2\": [\"a\", \"b\"]})\r\n\r\npa_path = \"foo.parquet\"\r\ntable = pa.Table.from_pandas(df)\r\n\r\n# specify that partitioning column has int32 dtype\r\npartitioning = HivePartitioning(pa.schema([(\"col1\", pa.int32())]))\r\n\r\n# write partitioned dataset with pyarrow\r\nwrite_dataset(\r\n    data=table,\r\n    base_dir=pa_path,\r\n    basename_template=\"part.{i}.parquet\",\r\n    format=\"parquet\",\r\n    partitioning=partitioning,\r\n)\r\n\r\n# check that reading pyarrow-written data is the same for pyarrow and dask\r\ndf_dask = dd.read_parquet(pa_path, engine=\"pyarrow\").compute()\r\ntable2 = pq.read_table(pa_path)\r\ndf_arrow = table2.to_pandas()\r\nprint(f\"{df_dask['col1'].dtype.categories=}\")\r\nprint(f\"{df_arrow['col1'].dtype.categories=}\")\r\nprint(f\"{table2=}\")\r\n```\r\n\r\nThis prints:\r\n\r\n```\r\ndf_dask['col1'].dtype.categories=Index([1, 2], dtype='int64')\r\ndf_arrow['col1'].dtype.categories=Index([1, 2], dtype='int32')\r\ntable2=pyarrow.Table\r\ncol2: string\r\ncol1: dictionary<values=int32, indices=int32, ordered=0>\r\n----\r\ncol2: [[\"a\"],[\"b\"]]\r\ncol1: [  -- dictionary:\r\n[1,2]  -- indices:\r\n[0],  -- dictionary:\r\n[1,2]  -- indices:\r\n[1]]\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nThis happens with pandas 2.0. With 1.5, `categories` were of dtype `int64`, whether they were read with `pyarrow` or `dask`.\r\n\r\nThe problem remains when specifying `engine=\"fastparquet\"` with `dd.read_parquet`.\r\n\r\n* Xref https://github.com/dask/dask/issues/9736.\r\n\r\nThis is responsible for a failing test with upstream pandas 2.0:\r\n\r\n```\r\ndask/dataframe/io/tests/test_parquet.py::test_roundtrip_partitioned_pyarrow_dataset[fastparquet]: AssertionError: Attributes of DataFrame.iloc[:, 0] (column name=\"col1\") are different\r\n\r\nAttribute \"dtype\" are different\r\n[left]:  CategoricalDtype(categories=[1, 2], ordered=False)\r\n[right]: CategoricalDtype(categories=[1, 2], ordered=False)\r\ndask/dataframe/io/tests/test_parquet.py::test_roundtrip_partitioned_pyarrow_dataset[pyarrow]: AssertionError: Attributes of DataFrame.iloc[:, 0] (column name=\"col1\") are different\r\n\r\nAttribute \"dtype\" are different\r\n[left]:  CategoricalDtype(categories=[1, 2], ordered=False)\r\n[right]: CategoricalDtype(categories=[1, 2], ordered=False)\r\ndask/dataframe/tests/test_arithmetics_reduction.py::test_datetime_std_across_axis1_null_results[False]: TypeError: float() argument must be a string or a real number, not 'Timestamp'\r\ndask/dataframe/tests/test_arithmetics_reduction.py::test_datetime_std_across_axis1_null_results[True]: TypeError: float() argument must be a string or a real number, not 'Timestamp'\r\ndask/dataframe/tests/test_groupby.py::test_groupby_unaligned_index[disk]: AssertionError: assert FrozenList(['a', None]) == FrozenList([None])\r\n  At index 0 diff: 'a' != None\r\n  Left contains one more item: None\r\n  Full diff:\r\n  - FrozenList([None])\r\n  + FrozenList(['a', None])\r\n  ?             +++++\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2023.2.0+11.g0890b96b\r\n- Python version: 3.11\r\n- Operating System: macOS\r\n- Install method (conda, pip, source): conda\r\n\r\ncc @jrbourbeau @rjzamora ", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9966/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9966/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9901", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9901/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9901/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9901/events", "html_url": "https://github.com/dask/dask/issues/9901", "id": 1564572364, "node_id": "I_kwDOAbcwm85dQXrM", "number": 9901, "title": "DataFrame.categorize() doesn't pick up current_client", "user": {"login": "crusaderky", "id": 6213168, "node_id": "MDQ6VXNlcjYyMTMxNjg=", "avatar_url": "https://avatars.githubusercontent.com/u/6213168?v=4", "gravatar_id": "", "url": "https://api.github.com/users/crusaderky", "html_url": "https://github.com/crusaderky", "followers_url": "https://api.github.com/users/crusaderky/followers", "following_url": "https://api.github.com/users/crusaderky/following{/other_user}", "gists_url": "https://api.github.com/users/crusaderky/gists{/gist_id}", "starred_url": "https://api.github.com/users/crusaderky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/crusaderky/subscriptions", "organizations_url": "https://api.github.com/users/crusaderky/orgs", "repos_url": "https://api.github.com/users/crusaderky/repos", "events_url": "https://api.github.com/users/crusaderky/events{/privacy}", "received_events_url": "https://api.github.com/users/crusaderky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 162914698, "node_id": "MDU6TGFiZWwxNjI5MTQ2OTg=", "url": "https://api.github.com/repos/dask/dask/labels/good%20first%20issue", "name": "good first issue", "color": "159818", "default": true, "description": "Clearly described and easy to accomplish. Good for beginners to the project."}, {"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-01-31T15:48:13Z", "updated_at": "2023-01-31T16:36:07Z", "closed_at": "2023-01-31T16:36:07Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "`categorize()` correctly picks up the default client when it internally calls compute, but it misbehaves if the user is using a `current_client()` context.\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport distributed\r\n\r\nclient = distributed.Client(set_as_default=False)\r\ndf = dd.from_dict({\"x\": [\"foo\", \"bar\", \"foo\"]}, npartitions=2)\r\n\r\nwith client.as_current():\r\n    df = df.persist()\r\n    df = df.categorize(columns=[\"x\"])\r\n```\r\n```\r\nFile ~/miniconda3/envs/coiled-runtime/lib/python3.10/site-packages/dask/dataframe/core.py:5059 [...], in DataFrame.categorize(self, columns, index, split_every, **kwargs)\r\nFile ~/miniconda3/envs/coiled-runtime/lib/python3.10/site-packages/dask/dataframe/categorical.py:152, in categorize(df, columns, index, split_every, **kwargs)\r\nFile ~/miniconda3/envs/coiled-runtime/lib/python3.10/site-packages/dask/base.py:341, in compute_as_if_collection(cls, dsk, keys, scheduler, get, **kwargs)\r\nFile ~/miniconda3/envs/coiled-runtime/lib/python3.10/site-packages/dask/threaded.py:89, in get(dsk, keys, cache, num_workers, pool, **kwargs)\r\nFile ~/miniconda3/envs/coiled-runtime/lib/python3.10/site-packages/dask/local.py:511, in get_async(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\r\nFile ~/miniconda3/envs/coiled-runtime/lib/python3.10/site-packages/dask/local.py:319, in reraise(exc, tb)\r\nFile ~/miniconda3/envs/coiled-runtime/lib/python3.10/site-packages/dask/local.py:224, in execute_task(key, task_info, dumps, File ~/miniconda3/envs/coiled-runtime/lib/python3.10/site-packages/dask/core.py:119, in _execute_task(arg, cache, dsk)\r\nFile ~/miniconda3/envs/coiled-runtime/lib/python3.10/site-packages/dask/dataframe/categorical.py:52, in _get_categories(df, columns, index)\r\n\r\nTypeError: 'Future' object is not subscriptable\r\n```\r\nNote local.py in the stack trace, which ought not to be involved.\r\n\r\n# Workaround\r\n```python\r\n    df = df.categorize(columns=[\"x\"], scheduler=distributed.get_client())\r\n```", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9901/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9901/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9871", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9871/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9871/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9871/events", "html_url": "https://github.com/dask/dask/pull/9871", "id": 1555432592, "node_id": "PR_kwDOAbcwm85Icxol", "number": 9871, "title": "Fix serialization bug in `BroadcastJoinLayer`", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2156573524, "node_id": "MDU6TGFiZWwyMTU2NTczNTI0", "url": "https://api.github.com/repos/dask/dask/labels/highlevelgraph", "name": "highlevelgraph", "color": "8c24d6", "default": false, "description": "Issues relating to HighLevelGraphs."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2023-01-24T18:05:40Z", "updated_at": "2023-01-26T21:35:08Z", "closed_at": "2023-01-26T21:35:05Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/9871", "html_url": "https://github.com/dask/dask/pull/9871", "diff_url": "https://github.com/dask/dask/pull/9871.diff", "patch_url": "https://github.com/dask/dask/pull/9871.patch", "merged_at": "2023-01-26T21:35:04Z"}, "body": "The current logic used to serialize a `BroadcastJoinLayer` object does not work when `left_on` and/or `right_on` are lists. The simple fix used here is to always covert these arguments from lists to tuples.\r\n\r\n- [x] Closes #9870\r\n- [x] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9871/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9871/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/9852", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9852/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9852/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9852/events", "html_url": "https://github.com/dask/dask/pull/9852", "id": 1549629851, "node_id": "PR_kwDOAbcwm85IJlT9", "number": 9852, "title": "Satisfy `broadcast` argument in `DataFrame.merge`", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2023-01-19T17:35:06Z", "updated_at": "2023-01-25T16:34:44Z", "closed_at": "2023-01-25T14:27:01Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/9852", "html_url": "https://github.com/dask/dask/pull/9852", "diff_url": "https://github.com/dask/dask/pull/9852.diff", "patch_url": "https://github.com/dask/dask/pull/9852.patch", "merged_at": "2023-01-25T14:27:01Z"}, "body": "Minimal change needed to ensure `broadcast=True` will be satisfied when the broadcast algorithm is not prohibited by the `how` or `shuffle` arguments.\r\n\r\n- [x] Closes #9851\r\n- [x] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9852/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9852/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/9851", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9851/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9851/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9851/events", "html_url": "https://github.com/dask/dask/issues/9851", "id": 1549610290, "node_id": "I_kwDOAbcwm85cXS0y", "number": 9851, "title": "Dataframe merge does not always satisfy broadcast argument", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-01-19T17:23:08Z", "updated_at": "2023-01-25T14:27:02Z", "closed_at": "2023-01-25T14:27:02Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "**Describe the issue**:\r\n\r\nThe `dask.dataframe.merge` API should use a broadcast-based merge when `broadcast=True`. The only exception should be when a broadcast-based algorithm is prohibited for the specified `how` and/or `shuffle` arguments. Within the current `dd.merge` implementation, the broadcast-based merge is only used when `shuffle=\"tasks\"` is explicitly specified. My stance is that this is a bug.  \r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nfrom dask.utils_test import hlg_layer\r\n\r\nleft = dd.from_dict({\"a\": [1, 2] * 100, \"b_left\": range(200)}, npartitions=20)\r\nright = dd.from_dict({\"a\": [2, 1] * 10, \"b_right\": range(20)}, npartitions=2)\r\n\r\nresult = dd.merge(left, right, broadcast=True)\r\nassert hlg_layer(result.dask, \"bcast-join\")  # FAILS\r\n\r\nresult = dd.merge(left, right, broadcast=True, shuffle=\"tasks\")\r\nassert hlg_layer(result.dask, \"bcast-join\")  # PASSES\r\n```", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9851/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9851/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9845", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9845/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9845/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9845/events", "html_url": "https://github.com/dask/dask/issues/9845", "id": 1537076657, "node_id": "I_kwDOAbcwm85bne2x", "number": 9845, "title": "read_parquet filter bug with nulls", "user": {"login": "ayushdg", "id": 19949207, "node_id": "MDQ6VXNlcjE5OTQ5MjA3", "avatar_url": "https://avatars.githubusercontent.com/u/19949207?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ayushdg", "html_url": "https://github.com/ayushdg", "followers_url": "https://api.github.com/users/ayushdg/followers", "following_url": "https://api.github.com/users/ayushdg/following{/other_user}", "gists_url": "https://api.github.com/users/ayushdg/gists{/gist_id}", "starred_url": "https://api.github.com/users/ayushdg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ayushdg/subscriptions", "organizations_url": "https://api.github.com/users/ayushdg/orgs", "repos_url": "https://api.github.com/users/ayushdg/repos", "events_url": "https://api.github.com/users/ayushdg/events{/privacy}", "received_events_url": "https://api.github.com/users/ayushdg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 22, "created_at": "2023-01-17T21:46:45Z", "updated_at": "2023-03-08T18:54:18Z", "closed_at": "2023-03-07T19:48:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**Describe the issue**:\r\nWhen using `dd.read_parquet` on a column with nulls: filtering on null equality doesn't work, `!=` on another value also ends up removing nulls\r\n\r\n**Minimal Complete Verifiable Example**:\r\n```python\r\ndd.read_parquet(\"test.parquet\", filters=[(\"a\", \"==\", np.nan)]).compute() # empty\r\ndd.read_parquet(\"test.parquet\", filters=[(\"a\", \"!=\", np.nan)]).compute() # works\r\ndd.read_parquet(\"test.parquet\", filters=[(\"a\", \"!=\", 1)]).compute() # empty\r\ndd.read_parquet(\"test.parquet\", filters=[(\"a\", \"==\", None)]).compute() # empty\r\ndd.read_parquet(\"test.parquet\", filters=[(\"b\", \"!=\", 2 )]).compute() # 13 rows instead of 14\r\ndd.read_parquet(\"test.parquet\", filters=[(\"c\", \"!=\", \"a\")]).compute() # empty\r\ndd.read_parquet(\"test.parquet\", filters=[(\"c\", \"!=\", None)]).compute() # empty\r\ndd.read_parquet(\"test.parquet\", filters=[(\"c\", \"!=\", \"\")]).compute() # works\r\n```\r\n\r\nFor table creation:\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\n\r\nfrom dask import dataframe as dd\r\n\r\ndf = pd.DataFrame()\r\ndf[\"a\"] = [1, None]*5 + [None]*5\r\ndf[\"b\"] = np.arange(14).tolist() + [None]\r\ndf[\"c\"] = [\"a\", None]*2 + [None]*11\r\npa_table = pa.Table.from_pandas(df)\r\npq.write_table(pa_table, \"test.parquet\", row_group_size=10)\r\n```\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2023.1.1\r\n- Python version: 3.9\r\n- Operating System: ubuntu 20.04\r\n- Install method (conda, pip, source): pip\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9845/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9845/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9715", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9715/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9715/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9715/events", "html_url": "https://github.com/dask/dask/issues/9715", "id": 1476153715, "node_id": "I_kwDOAbcwm85X_FFz", "number": 9715, "title": "Multi-character series names not handled correctly in groupby", "user": {"login": "wence-", "id": 1126981, "node_id": "MDQ6VXNlcjExMjY5ODE=", "avatar_url": "https://avatars.githubusercontent.com/u/1126981?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wence-", "html_url": "https://github.com/wence-", "followers_url": "https://api.github.com/users/wence-/followers", "following_url": "https://api.github.com/users/wence-/following{/other_user}", "gists_url": "https://api.github.com/users/wence-/gists{/gist_id}", "starred_url": "https://api.github.com/users/wence-/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wence-/subscriptions", "organizations_url": "https://api.github.com/users/wence-/orgs", "repos_url": "https://api.github.com/users/wence-/repos", "events_url": "https://api.github.com/users/wence-/events{/privacy}", "received_events_url": "https://api.github.com/users/wence-/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-12-05T09:53:33Z", "updated_at": "2022-12-06T18:32:48Z", "closed_at": "2022-12-06T18:32:48Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Describe the issue**:\r\n\r\nThis is a corner case of #9313, which was fixed for the case of dataframes (and series as long as they had single-character names).\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\nfrom dask.dataframe.utils import assert_eq\r\n\r\ndf = pd.DataFrame({\"aa\": [1, 2, 1, 3, 4, 1, 2]})\r\nddf = dd.from_pandas(df, npartitions=3)\r\n\r\nassert_eq(df.groupby(\"aa\").aa.cumsum(), ddf.groupby(\"aa\").aa.cumsum())\r\n\r\n# AssertionError: Series are different\r\n#\r\n# Series values are different (14.28571 %)\r\n# [index]: [0, 1, 2, 3, 4, 5, 6]\r\n# [left]:  [1, 2, 2, 3, 4, 3, 4]\r\n# [right]: [1, 2, 2, 3, 4, 2, 4]\r\n#                          ^\r\n```\r\n\r\nThe problem is that the check for matching column names introduced in #9430 fails in the case that `meta` is a series with a name of more than one character, since the set intersection explodes the name in that case and we don't notice a match:\r\n\r\n```python\r\n        columns = meta.name if is_series_like(meta) else meta.columns\r\n        by_cols = self.by if isinstance(self.by, list) else [self.by]\r\n\r\n        # in the series case, columns is a str, and set(columns) is a set of single characters\r\n        if columns is not None and set(columns).intersection(set(by_cols)):\r\n```\r\n\r\nFix incoming.", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9715/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9715/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9701", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9701/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9701/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9701/events", "html_url": "https://github.com/dask/dask/pull/9701", "id": 1468806910, "node_id": "PR_kwDOAbcwm85D7WVf", "number": 9701, "title": "Fix flaky `test_dataframe_aggregations_multilevel`", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-11-29T22:56:58Z", "updated_at": "2022-12-01T02:20:46Z", "closed_at": "2022-12-01T00:26:47Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/9701", "html_url": "https://github.com/dask/dask/pull/9701", "diff_url": "https://github.com/dask/dask/pull/9701.diff", "patch_url": "https://github.com/dask/dask/pull/9701.patch", "merged_at": "2022-12-01T00:26:47Z"}, "body": "I'm struggling to reproduce the [recent groupby CI failures](https://github.com/dask/dask/actions/runs/3576903148/jobs/6015263282) locally. However, it seems possible that these errors could be the result of `_mul_cols` being passed an empty group within `apply`. This PR adds a possible fix if this happens to be the root cause.\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9701/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9701/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/9690", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9690/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9690/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9690/events", "html_url": "https://github.com/dask/dask/issues/9690", "id": 1461757844, "node_id": "I_kwDOAbcwm85XIKeU", "number": 9690, "title": "2022.11.1: pytest is failing", "user": {"login": "kloczek", "id": 31284574, "node_id": "MDQ6VXNlcjMxMjg0NTc0", "avatar_url": "https://avatars.githubusercontent.com/u/31284574?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kloczek", "html_url": "https://github.com/kloczek", "followers_url": "https://api.github.com/users/kloczek/followers", "following_url": "https://api.github.com/users/kloczek/following{/other_user}", "gists_url": "https://api.github.com/users/kloczek/gists{/gist_id}", "starred_url": "https://api.github.com/users/kloczek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kloczek/subscriptions", "organizations_url": "https://api.github.com/users/kloczek/orgs", "repos_url": "https://api.github.com/users/kloczek/repos", "events_url": "https://api.github.com/users/kloczek/events{/privacy}", "received_events_url": "https://api.github.com/users/kloczek/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 1342320181, "node_id": "MDU6TGFiZWwxMzQyMzIwMTgx", "url": "https://api.github.com/repos/dask/dask/labels/needs%20info", "name": "needs info", "color": "d0cfcc", "default": false, "description": "Needs further information from the user"}, {"id": 1887344368, "node_id": "MDU6TGFiZWwxODg3MzQ0MzY4", "url": "https://api.github.com/repos/dask/dask/labels/tests", "name": "tests", "color": "a0f9b4", "default": false, "description": "Unit tests and/or continuous integration"}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "phobson", "id": 1163939, "node_id": "MDQ6VXNlcjExNjM5Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1163939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phobson", "html_url": "https://github.com/phobson", "followers_url": "https://api.github.com/users/phobson/followers", "following_url": "https://api.github.com/users/phobson/following{/other_user}", "gists_url": "https://api.github.com/users/phobson/gists{/gist_id}", "starred_url": "https://api.github.com/users/phobson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phobson/subscriptions", "organizations_url": "https://api.github.com/users/phobson/orgs", "repos_url": "https://api.github.com/users/phobson/repos", "events_url": "https://api.github.com/users/phobson/events{/privacy}", "received_events_url": "https://api.github.com/users/phobson/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "phobson", "id": 1163939, "node_id": "MDQ6VXNlcjExNjM5Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1163939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phobson", "html_url": "https://github.com/phobson", "followers_url": "https://api.github.com/users/phobson/followers", "following_url": "https://api.github.com/users/phobson/following{/other_user}", "gists_url": "https://api.github.com/users/phobson/gists{/gist_id}", "starred_url": "https://api.github.com/users/phobson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phobson/subscriptions", "organizations_url": "https://api.github.com/users/phobson/orgs", "repos_url": "https://api.github.com/users/phobson/repos", "events_url": "https://api.github.com/users/phobson/events{/privacy}", "received_events_url": "https://api.github.com/users/phobson/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2022-11-23T13:22:28Z", "updated_at": "2022-12-23T11:17:58Z", "closed_at": "2022-12-23T11:17:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Describe the issue**:\r\npytest is failing in some units.\r\n\r\n**Environment**:\r\n\r\n- Dask version: \r\n- Python version: 3.8.15\r\n- Operating System: Linux x86/64\r\n- Install method (conda, pip, source): VCS tar ball\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9690/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9690/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9679", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9679/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9679/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9679/events", "html_url": "https://github.com/dask/dask/issues/9679", "id": 1455637910, "node_id": "I_kwDOAbcwm85Ww0WW", "number": 9679, "title": "fft fails for all netcdf files imported with xarray", "user": {"login": "nvogtvincent", "id": 22178225, "node_id": "MDQ6VXNlcjIyMTc4MjI1", "avatar_url": "https://avatars.githubusercontent.com/u/22178225?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nvogtvincent", "html_url": "https://github.com/nvogtvincent", "followers_url": "https://api.github.com/users/nvogtvincent/followers", "following_url": "https://api.github.com/users/nvogtvincent/following{/other_user}", "gists_url": "https://api.github.com/users/nvogtvincent/gists{/gist_id}", "starred_url": "https://api.github.com/users/nvogtvincent/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nvogtvincent/subscriptions", "organizations_url": "https://api.github.com/users/nvogtvincent/orgs", "repos_url": "https://api.github.com/users/nvogtvincent/repos", "events_url": "https://api.github.com/users/nvogtvincent/events{/privacy}", "received_events_url": "https://api.github.com/users/nvogtvincent/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-11-18T18:53:19Z", "updated_at": "2022-11-22T21:56:36Z", "closed_at": "2022-11-22T21:56:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**Describe the issue**:\r\nDask fft raises a `DataArray.map_blocks() got an unexpected keyword argument 'dtype'` error when operating on any dask array imported via `xr.open_dataset`\r\n\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\nUsing the sample netcdf file `ECMWF_ERA-40_subset.nc` available [here](https://www.unidata.ucar.edu/software/netcdf/examples/files.html):\r\n\r\n```python\r\nimport xarray as xr\r\nimport dask.array as da\r\n\r\n# Load netcdf file\r\nds = xr.open_dataset('ECMWF_ERA-40_subset.nc', chunks={'longitude': 20, 'latitude': 20})\r\n\r\n# Carry out fft\r\nds_fft = da.fft.fft(ds.tp, axis=0)\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.11.0\r\n- Python version: 3.10.6\r\n- Operating System: Ubuntu\r\n- Install method (conda, pip, source): conda via clean install\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9679/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9679/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9661", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9661/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9661/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9661/events", "html_url": "https://github.com/dask/dask/pull/9661", "id": 1448927846, "node_id": "PR_kwDOAbcwm85C4nhq", "number": 9661, "title": "Remove statistics-based set_index logic from read_parquet", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-11-14T23:33:41Z", "updated_at": "2022-12-01T14:17:58Z", "closed_at": "2022-12-01T09:54:32Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/9661", "html_url": "https://github.com/dask/dask/pull/9661", "diff_url": "https://github.com/dask/dask/pull/9661.diff", "patch_url": "https://github.com/dask/dask/pull/9661.patch", "merged_at": "2022-12-01T09:54:32Z"}, "body": "`dd.read_parquet` will only gather statistics for columns that either (1) have been designated as an index or (2) are being filtered. For this reason, it no longer makes sense to auto-infer an index that was not specified in the pandas metadata or by the user (via `dd.read_parquet(..., index=)`). By using statistics to automatically set an arbitrary sorted column as the index, we open ourselves up to problematic/surprising behavior (see https://github.com/dask-contrib/dask-sql/pull/903#discussion_r1022035461).\r\n\r\n\r\nThis PR proposes that we officially remove the logic use to automatically select an index column using statistics.\r\n\r\n- [ ] Closes #xxxx\r\n- [ ] Tests added / passed\r\n- [ ] Passes `pre-commit run --all-files`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9661/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9661/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/9646", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9646/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9646/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9646/events", "html_url": "https://github.com/dask/dask/pull/9646", "id": 1444060058, "node_id": "PR_kwDOAbcwm85CoRNv", "number": 9646, "title": "Fix groupby-aggregation when grouping on an index by name", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-11-10T14:59:21Z", "updated_at": "2022-11-21T21:32:24Z", "closed_at": "2022-11-21T20:59:17Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/9646", "html_url": "https://github.com/dask/dask/pull/9646", "diff_url": "https://github.com/dask/dask/pull/9646.diff", "patch_url": "https://github.com/dask/dask/pull/9646.patch", "merged_at": "2022-11-21T20:59:17Z"}, "body": "Simple fix for groupby-aggregation column-projection bug (leave out index names in explicit `getitem` operation).\r\n\r\n- [x] Closes #9643\r\n- [x] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9646/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9646/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/9645", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9645/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9645/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9645/events", "html_url": "https://github.com/dask/dask/issues/9645", "id": 1444042370, "node_id": "I_kwDOAbcwm85WElaC", "number": 9645, "title": "padding datetime arrays with missing values", "user": {"login": "keewis", "id": 14808389, "node_id": "MDQ6VXNlcjE0ODA4Mzg5", "avatar_url": "https://avatars.githubusercontent.com/u/14808389?v=4", "gravatar_id": "", "url": "https://api.github.com/users/keewis", "html_url": "https://github.com/keewis", "followers_url": "https://api.github.com/users/keewis/followers", "following_url": "https://api.github.com/users/keewis/following{/other_user}", "gists_url": "https://api.github.com/users/keewis/gists{/gist_id}", "starred_url": "https://api.github.com/users/keewis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/keewis/subscriptions", "organizations_url": "https://api.github.com/users/keewis/orgs", "repos_url": "https://api.github.com/users/keewis/repos", "events_url": "https://api.github.com/users/keewis/events{/privacy}", "received_events_url": "https://api.github.com/users/keewis/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3468123446, "node_id": "LA_kwDOAbcwm87Ot102", "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention", "name": "needs attention", "color": "6d626c", "default": false, "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2022-11-10T14:49:38Z", "updated_at": "2023-03-07T18:51:20Z", "closed_at": "2023-03-07T18:51:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Describe the issue**:\r\n\r\nTrying to pad with `NaT` (the `nan`-equivalent for datetime dtypes) results in a `TypeError`:\r\n```pytb\r\nTypeError: `pad_value` must be composed of integral typed values.\r\n```\r\nThis is the case for `np.datetime64(\"NaT\")`, `np.array(\"NaT\", dtype=\"datetime64\")` and `np.array([\"NaT\"], dtype=\"datetime64\")`\r\n\r\nI think the reason for this is that `dask.array.creation.expand_pad_value` checks if the value is an instance of `Number` or `Sequence`, but that evaluates to `False` for dtype instances and 0d arrays.\r\n\r\n<details><summary><b>Minimal Complete Verifiable Example</b></summary>\r\n\r\n```python\r\nIn [1]: import dask.array as da\r\n   ...: import pandas as pd\r\n   ...: import numpy as np\r\n\r\nIn [2]: a = da.from_array(\r\n   ...:     pd.date_range(\"2022-04-01\", freq=\"s\", periods=15).to_numpy(), chunks=(5,)\r\n   ...: )\r\n   ...: a\r\nOut[2]: dask.array<array, shape=(15,), dtype=datetime64[ns], chunksize=(5,), chunktype=numpy.ndarray>\r\n\r\nIn [3]: np.pad(a, (1, 1), mode=\"constant\", constant_values=np.datetime64(\"NaT\"))\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nCell In [3], line 1\r\n----> 1 np.pad(a, (1, 1), mode=\"constant\", constant_values=np.datetime64(\"NaT\"))\r\n\r\nFile <__array_function__ internals>:180, in pad(*args, **kwargs)\r\n\r\nFile .../dask/array/core.py:1760, in Array.__array_function__(self, func, types, args, kwargs)\r\n   1757 if has_keyword(da_func, \"like\"):\r\n   1758     kwargs[\"like\"] = self\r\n-> 1760 return da_func(*args, **kwargs)\r\n\r\nFile .../dask/array/creation.py:1231, in pad(array, pad_width, mode, **kwargs)\r\n   1229 elif mode == \"constant\":\r\n   1230     kwargs.setdefault(\"constant_values\", 0)\r\n-> 1231     return pad_edge(array, pad_width, mode, **kwargs)\r\n   1232 elif mode == \"linear_ramp\":\r\n   1233     kwargs.setdefault(\"end_values\", 0)\r\n\r\nFile .../dask/array/creation.py:966, in pad_edge(array, pad_width, mode, **kwargs)\r\n    959 def pad_edge(array, pad_width, mode, **kwargs):\r\n    960     \"\"\"\r\n    961     Helper function for padding edges.\r\n    962 \r\n    963     Handles the cases where the only the values on the edge are needed.\r\n    964     \"\"\"\r\n--> 966     kwargs = {k: expand_pad_value(array, v) for k, v in kwargs.items()}\r\n    968     result = array\r\n    969     for d in range(array.ndim):\r\n\r\nFile .../dask/array/creation.py:966, in <dictcomp>(.0)\r\n    959 def pad_edge(array, pad_width, mode, **kwargs):\r\n    960     \"\"\"\r\n    961     Helper function for padding edges.\r\n    962 \r\n    963     Handles the cases where the only the values on the edge are needed.\r\n    964     \"\"\"\r\n--> 966     kwargs = {k: expand_pad_value(array, v) for k, v in kwargs.items()}\r\n    968     result = array\r\n    969     for d in range(array.ndim):\r\n\r\nFile .../dask/array/creation.py:912, in expand_pad_value(array, pad_value)\r\n    910     pad_value = array.ndim * (tuple(pad_value[0]),)\r\n    911 else:\r\n--> 912     raise TypeError(\"`pad_value` must be composed of integral typed values.\")\r\n    914 return pad_value\r\n\r\nTypeError: `pad_value` must be composed of integral typed values.\r\n```\r\n\r\n</details>\r\n\r\n**Anything else we need to know?**:\r\n\r\nI wonder if 0d arrays could be considered scalars in general? That would also help fixing xarray-contrib/pint-xarray#186\r\n\r\n**Environment**:\r\n\r\n- Dask version: `2022.10.2+11.g9d624c6df`\r\n- Python version: `3.10.6`\r\n- Operating System: `ubuntu 22.04`\r\n- Install method (conda, pip, source): `pip install -e <path to git checkout>`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9645/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9645/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9643", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9643/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9643/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9643/events", "html_url": "https://github.com/dask/dask/issues/9643", "id": 1444005130, "node_id": "I_kwDOAbcwm85WEcUK", "number": 9643, "title": "Groupby aggregations fail when grouping on index by name", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-11-10T14:27:29Z", "updated_at": "2022-11-21T20:59:18Z", "closed_at": "2022-11-21T20:59:18Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "**Describe the issue**:\r\nAs pointed out in [this comment](https://github.com/dask/dask/pull/9442#issuecomment-1310001867) (thanks @odovad !), the changes in  [9442](https://github.com/dask/dask/pull/9442) do not properly handle the case that we are grouping on the index by name.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n\r\npdf = pd.DataFrame(\r\n    {\"a\": [1, 2, 3, 4, 5, 6, 7, 8, 9], \"b\": [4, 5, 6, 3, 2, 1, 0, 0, 0]},\r\n    index=[0, 1, 3, 5, 6, 8, 9, 9, 9],\r\n)\r\nddf = dd.from_pandas(pdf, npartitions=3)\r\n\r\nddf2 = ddf.set_index(\"a\")\r\nddf2.groupby(\"a\").agg({\"b\": \"mean\"})\r\n```\r\n\r\nResult: `KeyError: \"['a'] not in index\"`", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9643/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9643/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9641", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9641/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9641/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9641/events", "html_url": "https://github.com/dask/dask/issues/9641", "id": 1442387993, "node_id": "I_kwDOAbcwm85V-RgZ", "number": 9641, "title": "`sort_values()` can fail with `Timestamp` data", "user": {"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-11-09T16:23:51Z", "updated_at": "2022-11-14T22:28:10Z", "closed_at": "2022-11-14T22:28:10Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The following `sort_values()` computation fails using the latest `dask` `main` branch and `pandas=1.5.0` \r\n\r\n```python\r\nfrom pandas import Timestamp\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n\r\ndf = pd.DataFrame.from_records(\r\n       [[Timestamp('2002-01-11 21:00:01+0000', tz='UTC'), 4223, 54719.0],\r\n       [Timestamp('2002-01-14 21:00:01+0000', tz='UTC'), 6942, 19223.0],\r\n       [Timestamp('2002-01-15 21:00:01+0000', tz='UTC'), 12551, 72865.0],\r\n       [Timestamp('2002-01-23 21:00:01+0000', tz='UTC'), 6005, 57670.0],\r\n       [Timestamp('2002-01-29 21:00:01+0000', tz='UTC'), 2043, 58600.0],\r\n       [Timestamp('2002-02-01 21:00:01+0000', tz='UTC'), 6909, 8459.0],\r\n       [Timestamp('2002-01-14 21:00:01+0000', tz='UTC'), 5326, 77339.0],\r\n       [Timestamp('2002-01-14 21:00:01+0000', tz='UTC'), 4711, 54135.0],\r\n       [Timestamp('2002-01-22 21:00:01+0000', tz='UTC'), 103, 57627.0],\r\n       [Timestamp('2002-01-30 21:00:01+0000', tz='UTC'), 16862, 54458.0],\r\n       [Timestamp('2002-01-31 21:00:01+0000', tz='UTC'), 4143, 56280.0]],\r\n    columns=[\"time\", \"id1\", \"id2\"]\r\n)\r\ndd.from_pandas(df, npartitions=2).sort_values(\"time\").compute()\r\n```\r\n\r\nwith `TypeError: value should be a 'Timestamp', 'NaT', or array of those. Got 'StringArray' instead.` (full traceback below)\r\n\r\n<details>\r\n<summary>Traceback:</summary>\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/Users/james/projects/dask/dask/dask/dataframe/shuffle.py\", line 851, in set_partitions_pre\r\n    partitions = divisions.searchsorted(s, side=\"right\") - 1\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/pandas/core/series.py\", line 3054, in searchsorted\r\n    return base.IndexOpsMixin.searchsorted(self, value, side=side, sorter=sorter)\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/pandas/core/base.py\", line 1296, in searchsorted\r\n    return values.searchsorted(value, side=side, sorter=sorter)\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/pandas/core/arrays/_mixins.py\", line 238, in searchsorted\r\n    npvalue = self._validate_searchsorted_value(value)\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py\", line 782, in _validate_searchsorted_value\r\n    value = self._validate_listlike(value)\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py\", line 774, in _validate_listlike\r\n    raise TypeError(msg)\r\nTypeError: value should be a 'Timestamp', 'NaT', or array of those. Got 'StringArray' instead.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/james/projects/dask/dask/test.py\", line 19, in <module>\r\n    dd.from_pandas(df, npartitions=2).sort_values(\"time\").compute()\r\n  File \"/Users/james/projects/dask/dask/dask/base.py\", line 315, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/Users/james/projects/dask/dask/dask/base.py\", line 600, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/Users/james/projects/dask/dask/dask/threaded.py\", line 89, in get\r\n    results = get_async(\r\n  File \"/Users/james/projects/dask/dask/dask/local.py\", line 511, in get_async\r\n    raise_exception(exc, tb)\r\n  File \"/Users/james/projects/dask/dask/dask/local.py\", line 319, in reraise\r\n    raise exc\r\n  File \"/Users/james/projects/dask/dask/dask/local.py\", line 224, in execute_task\r\n    result = _execute_task(task, data)\r\n  File \"/Users/james/projects/dask/dask/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/Users/james/projects/dask/dask/dask/optimization.py\", line 990, in __call__\r\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n  File \"/Users/james/projects/dask/dask/dask/core.py\", line 149, in get\r\n    result = _execute_task(task, cache)\r\n  File \"/Users/james/projects/dask/dask/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/Users/james/projects/dask/dask/dask/core.py\", line 119, in <genexpr>\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/Users/james/projects/dask/dask/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/Users/james/projects/dask/dask/dask/utils.py\", line 71, in apply\r\n    return func(*args, **kwargs)\r\n  File \"/Users/james/projects/dask/dask/dask/dataframe/core.py\", line 6773, in apply_and_enforce\r\n    df = func(*args, **kwargs)\r\n  File \"/Users/james/projects/dask/dask/dask/dataframe/shuffle.py\", line 859, in set_partitions_pre\r\n    partitions[not_null] = divisions.searchsorted(s[not_null], side=\"right\") - 1\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/pandas/core/series.py\", line 3054, in searchsorted\r\n    return base.IndexOpsMixin.searchsorted(self, value, side=side, sorter=sorter)\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/pandas/core/base.py\", line 1296, in searchsorted\r\n    return values.searchsorted(value, side=side, sorter=sorter)\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/pandas/core/arrays/_mixins.py\", line 238, in searchsorted\r\n    npvalue = self._validate_searchsorted_value(value)\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py\", line 782, in _validate_searchsorted_value\r\n    value = self._validate_listlike(value)\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py\", line 774, in _validate_listlike\r\n    raise TypeError(msg)\r\nTypeError: value should be a 'Timestamp', 'NaT', or array of those. Got 'StringArray' instead.\r\n```\r\n\r\n</details>", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9641/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9641/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9615", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9615/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9615/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9615/events", "html_url": "https://github.com/dask/dask/issues/9615", "id": 1431886627, "node_id": "I_kwDOAbcwm85VWNsj", "number": 9615, "title": "Fully support partial functions as aggregations", "user": {"login": "ChrisJar", "id": 13131098, "node_id": "MDQ6VXNlcjEzMTMxMDk4", "avatar_url": "https://avatars.githubusercontent.com/u/13131098?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ChrisJar", "html_url": "https://github.com/ChrisJar", "followers_url": "https://api.github.com/users/ChrisJar/followers", "following_url": "https://api.github.com/users/ChrisJar/following{/other_user}", "gists_url": "https://api.github.com/users/ChrisJar/gists{/gist_id}", "starred_url": "https://api.github.com/users/ChrisJar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ChrisJar/subscriptions", "organizations_url": "https://api.github.com/users/ChrisJar/orgs", "repos_url": "https://api.github.com/users/ChrisJar/repos", "events_url": "https://api.github.com/users/ChrisJar/events{/privacy}", "received_events_url": "https://api.github.com/users/ChrisJar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-11-01T18:28:34Z", "updated_at": "2022-12-12T23:20:32Z", "closed_at": "2022-12-12T23:20:32Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- Please do a quick search of existing issues to make sure that this has not been asked before. -->\r\nCurrently in `dask.dataframe`, Dask ignores any arguments given to a function in a `partial` when performing an aggregation.\r\n\r\nFor example:\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\nimport dask.dataframe as dd\r\nfrom functools import partial\r\n\r\ndf = pd.DataFrame({\r\n    \"a\": [5, 4, 3, 5, 4, 2, 3, 2],\r\n    \"b\": [1, 2, 5, 6, 9, 2, 6, 8],\r\n})\r\nddf = dd.from_pandas(df, npartitions=1)\r\nddf.groupby(\"a\").agg(partial(np.std, ddof=-2)).compute()\r\n```\r\nreturns\r\n```\r\n          b\r\na          \r\n5  3.535534\r\n4  4.949747\r\n3  0.707107\r\n2  4.242641\r\n```\r\nwhereas in pandas:\r\n```python\r\ndf.groupby(\"a\").agg(partial(np.std, ddof=-2))\r\n```\r\nreturns:\r\n```\r\n          b\r\na          \r\n2  2.121320\r\n3  0.353553\r\n4  2.474874\r\n5  1.767767\r\n```\r\nThe discrepancy is because Dask ignores the`ddof` argument and defualts to `ddof=1`. It'd be great if there were some way for Dask to recognize and take those arguments into account like Pandas does.", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9615/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9615/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9614", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9614/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9614/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9614/events", "html_url": "https://github.com/dask/dask/pull/9614", "id": 1431487905, "node_id": "PR_kwDOAbcwm85B-EpX", "number": 9614, "title": "Fix read_csv behavior for `header=0` and `names`", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-11-01T14:04:38Z", "updated_at": "2022-11-02T18:44:15Z", "closed_at": "2022-11-02T18:30:52Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/9614", "html_url": "https://github.com/dask/dask/pull/9614", "diff_url": "https://github.com/dask/dask/pull/9614.diff", "patch_url": "https://github.com/dask/dask/pull/9614.patch", "merged_at": "2022-11-02T18:30:52Z"}, "body": "This PR modifies the behavior of `read_csv` to avoid prepending the header to byte-ranges when `names` is specified.\r\n\r\n- [x] Closes #9610\r\n- [x] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9614/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9614/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/9610", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9610/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9610/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9610/events", "html_url": "https://github.com/dask/dask/issues/9610", "id": 1428997239, "node_id": "I_kwDOAbcwm85VLMR3", "number": 9610, "title": "Weird behavior with .read_csv(header=0)", "user": {"login": "cryptohabitat", "id": 55636038, "node_id": "MDQ6VXNlcjU1NjM2MDM4", "avatar_url": "https://avatars.githubusercontent.com/u/55636038?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cryptohabitat", "html_url": "https://github.com/cryptohabitat", "followers_url": "https://api.github.com/users/cryptohabitat/followers", "following_url": "https://api.github.com/users/cryptohabitat/following{/other_user}", "gists_url": "https://api.github.com/users/cryptohabitat/gists{/gist_id}", "starred_url": "https://api.github.com/users/cryptohabitat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cryptohabitat/subscriptions", "organizations_url": "https://api.github.com/users/cryptohabitat/orgs", "repos_url": "https://api.github.com/users/cryptohabitat/repos", "events_url": "https://api.github.com/users/cryptohabitat/events{/privacy}", "received_events_url": "https://api.github.com/users/cryptohabitat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2022-10-30T19:52:35Z", "updated_at": "2022-11-02T18:30:53Z", "closed_at": "2022-11-02T18:30:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "So I was testing both a pandas and a dask solution for an assignment of parsing a CSV file, when I found a weird behavior with dask.read_csv().\r\n\r\nA) Let's assume we have the next CSV file (input.csv) with 13 unique rows.\r\n\r\n`1 city1,date,193` < This 193 value will be important going forward\r\n`2 city2,date,14`\r\n`(...)`\r\n`13 city13,date,18`\r\n\r\nGiven this CSV file, we run this script\r\n\r\n`df = dd.read_csv(\"input.csv\", header=0, names=[\"city\", \"date\", \"sales\"], usecols=[\"city\", \"sales\"], blocksize=16 * 1024 * 1024)`\r\n`result = df.groupby(\"city\").sum()`\r\n`result = result.compute().to_csv(\"./output.csv\")`\r\n\r\nThis give us an output CSV file with 2 columns, city and sales, and 12 rows. **The CSV has not header info in line 1**, and because of the (header=0) we're \"skipping\" the first line and city1 is missing. It was my error to put the header=0 there, but everything is working as intended here.\r\n\r\nBut **groupby().sum()** in the second line is not doing anything since we just have 13, unique rows. So I replicated those lines 780k times, ending with a 10.140.000 rows file.\r\n\r\nThis is where things start to get messy.\r\n\r\nRemember, city1 have a sales value = 193. Given the new input file, the output file should have a value for city1 = 150539807. This is 193 * 779.999 (We have the same rows 780k times, but we're skipping the first line, which is a city1 row)\r\n\r\n**However**, the result for city1 in the output file is 150542123. So it's looks like if additional 12 rows for city1 are being parsed.\r\n\r\nWhat if instead of 780k times, I repeat the rows half of it (390k times)? The additional rows also halts, and additional 6 rows are parsed.\r\n\r\nHalts again, repeat the rows 195k times, and value for city1 is 37634807, which is exactly 193 * 194.999, cause first rows is skipped. So issue disappears at this point.\r\n\r\nBut if I replicate the rows 194.999/998 times, or even adds up to 195.001/002 times, first line is not skipped and we also have an additional row in total count.\r\n\r\nAll other 12 cities values are always, in all cases, what they should be.\r\n\r\nWhy is this happening? It's really weird.\r\n\r\nIf I run the same script but just with pandas, the first line is always skipped and total count for the city rows is exactly what should be.\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.10.0\r\n- Python version: 3.11.0\r\n- Operating System: Windows 10.0.19043\r\n- Install method (conda, pip, source): pip\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9610/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9610/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9591", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9591/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9591/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9591/events", "html_url": "https://github.com/dask/dask/issues/9591", "id": 1422015558, "node_id": "I_kwDOAbcwm85UwjxG", "number": 9591, "title": "dd.read_parquet with filters fails with TypeError", "user": {"login": "sushi30", "id": 26347589, "node_id": "MDQ6VXNlcjI2MzQ3NTg5", "avatar_url": "https://avatars.githubusercontent.com/u/26347589?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sushi30", "html_url": "https://github.com/sushi30", "followers_url": "https://api.github.com/users/sushi30/followers", "following_url": "https://api.github.com/users/sushi30/following{/other_user}", "gists_url": "https://api.github.com/users/sushi30/gists{/gist_id}", "starred_url": "https://api.github.com/users/sushi30/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sushi30/subscriptions", "organizations_url": "https://api.github.com/users/sushi30/orgs", "repos_url": "https://api.github.com/users/sushi30/repos", "events_url": "https://api.github.com/users/sushi30/events{/privacy}", "received_events_url": "https://api.github.com/users/sushi30/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "phobson", "id": 1163939, "node_id": "MDQ6VXNlcjExNjM5Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1163939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phobson", "html_url": "https://github.com/phobson", "followers_url": "https://api.github.com/users/phobson/followers", "following_url": "https://api.github.com/users/phobson/following{/other_user}", "gists_url": "https://api.github.com/users/phobson/gists{/gist_id}", "starred_url": "https://api.github.com/users/phobson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phobson/subscriptions", "organizations_url": "https://api.github.com/users/phobson/orgs", "repos_url": "https://api.github.com/users/phobson/repos", "events_url": "https://api.github.com/users/phobson/events{/privacy}", "received_events_url": "https://api.github.com/users/phobson/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "phobson", "id": 1163939, "node_id": "MDQ6VXNlcjExNjM5Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1163939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phobson", "html_url": "https://github.com/phobson", "followers_url": "https://api.github.com/users/phobson/followers", "following_url": "https://api.github.com/users/phobson/following{/other_user}", "gists_url": "https://api.github.com/users/phobson/gists{/gist_id}", "starred_url": "https://api.github.com/users/phobson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phobson/subscriptions", "organizations_url": "https://api.github.com/users/phobson/orgs", "repos_url": "https://api.github.com/users/phobson/repos", "events_url": "https://api.github.com/users/phobson/events{/privacy}", "received_events_url": "https://api.github.com/users/phobson/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 21, "created_at": "2022-10-25T07:44:57Z", "updated_at": "2022-12-08T16:18:07Z", "closed_at": "2022-12-08T16:14:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nWhen using `dd.read_parquet` with the `filters` argument, task fails with: `TypeError: object of type 'NoneType' has no len()`.\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**Describe the issue**:\r\n\r\nAfter upgrading to `fastparquet==0.8.3`, this example fails. With `fastparquet==0.7.2` it succeeds.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nfrom dask.distributed import Client\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\n\r\n\r\ndef main():\r\n    client = Client()\r\n    df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\r\n    ddf = dd.from_pandas(df, npartitions=2)\r\n    ddf.to_parquet(\"./result/\", engine=\"fastparquet\", partition_on=[\"a\"])\r\n    df2 = dd.read_parquet(\"./result/\", engine=\"fastparquet\")\r\n    df2.head()  # this is fine :)\r\n    df2 = dd.read_parquet(\"./result/\", engine=\"fastparquet\", filters=[(\"a\", \">\", 1)])\r\n    df2.head()  # this fails :(\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.10.0\r\n- Python version: 3.10\r\n- Operating System: Windows/Linux (os dask docker image)\r\n- Install method (conda, pip, source): pip on windows\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9591/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9591/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9577", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9577/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9577/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9577/events", "html_url": "https://github.com/dask/dask/issues/9577", "id": 1413309018, "node_id": "I_kwDOAbcwm85UPWJa", "number": 9577, "title": "Outer or right merges with missing values can fail with meta mismatches", "user": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-10-18T14:15:30Z", "updated_at": "2022-10-18T17:28:02Z", "closed_at": "2022-10-18T17:28:02Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "When merging two dataframes on a specific column, it is sometimes that case that individual chunks of the left or right frame are empty. This can happen, for instance, if the values in the right frame do not exist in the left (for a given set of divisions).\r\n\r\nAs is sometimes the case, pandas can give a different answer when one of the two frames are empty (here, the left frame). There is an upstream bug report here: https://github.com/pandas-dev/pandas/issues/9937. So you can wind up with a case where some partitions have the wrong shape due to an empty partition for a given set of divisions, even though the overall merge is non-empty. A minimal reproducer:\r\n\r\n```python\r\nimport pandas\r\nimport dask.dataframe as dd\r\n\r\n# Two dataframes, both with \"a\" columns. By design, not all values in one\r\n# exist in the other, so some of the chunk-wise merges will be with an empty frame.\r\nleft = pandas.DataFrame({\"a\": [1, 1, 2, 2], \"val\": [5, 6, 7, 8]})\r\nright = pandas.DataFrame({\"a\": [2, 2, 3, 3], \"val\": [11, 12, 13, 14]})\r\n\r\n# More partitions than values, ensure empty frames.\r\ndd_left = dd.from_pandas(left, npartitions=4)\r\ndd_right = dd.from_pandas(right, npartitions=4)\r\n\r\nmerged = dd_left.merge(dd_right, on=\"a\", how=\"right\")\r\nmerged.map_partitions(lambda x: x, meta = merged._meta).compute()  # Fails due to meta mismatch!\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: `main`\r\n- Python version: 3.8\r\n- Operating System: ubuntu\r\n- Install method (conda, pip, source): source\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9577/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9577/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9570", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9570/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9570/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9570/events", "html_url": "https://github.com/dask/dask/pull/9570", "id": 1407872157, "node_id": "PR_kwDOAbcwm85AvV3s", "number": 9570, "title": "Avoid `pandas` constructors in `dask.dataframe.core`", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}, {"id": 4410724893, "node_id": "LA_kwDOAbcwm88AAAABBuZSHQ", "url": "https://api.github.com/repos/dask/dask/labels/gpu", "name": "gpu", "color": "3D0CD2", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2022-10-13T14:07:36Z", "updated_at": "2022-11-10T22:10:31Z", "closed_at": "2022-11-10T22:00:13Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/9570", "html_url": "https://github.com/dask/dask/pull/9570", "diff_url": "https://github.com/dask/dask/pull/9570.diff", "patch_url": "https://github.com/dask/dask/pull/9570.patch", "merged_at": "2022-11-10T22:00:13Z"}, "body": "There are many places in dask.dataframe where `pd.DataFrame`/`pd.Series` constructors are used explicitly. This PR proposes the addition of `serial_frame_constructor` and `serial_series_constrictor` utilities that take in an optional `like` parameter to determine which `DataFrame`/`Series` constructor to use (i.e. `pandas` or `cudf`). Default is `pandas.DataFrame` and `pandas.Series`.\r\n\r\nThe optional `like` argument is currently expected to be a serial `DataFrame`, serial `Series`, `DataFrame` collection, or `Series` collection.  It may also make sense to handle a numpy/cupy Array or Array collection (along the lines of @quasiben's suggestion in [#11889](https://github.com/rapidsai/cudf/issues/11889)).  Howeer, that feature will probablty require the addition of a new `array_to_frame` diispatch as well (or something similar).\r\n\r\n- [x] Closes [#11889](https://github.com/rapidsai/cudf/issues/11889)\r\n- [ ] Tests added / passed\r\n- [ ] Passes `pre-commit run --all-files`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9570/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9570/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/9567", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9567/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9567/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9567/events", "html_url": "https://github.com/dask/dask/issues/9567", "id": 1405789071, "node_id": "I_kwDOAbcwm85TyqOP", "number": 9567, "title": "Non-working implicit dask dataframe promotion in map_overlap", "user": {"login": "epizut", "id": 1694892, "node_id": "MDQ6VXNlcjE2OTQ4OTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1694892?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epizut", "html_url": "https://github.com/epizut", "followers_url": "https://api.github.com/users/epizut/followers", "following_url": "https://api.github.com/users/epizut/following{/other_user}", "gists_url": "https://api.github.com/users/epizut/gists{/gist_id}", "starred_url": "https://api.github.com/users/epizut/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epizut/subscriptions", "organizations_url": "https://api.github.com/users/epizut/orgs", "repos_url": "https://api.github.com/users/epizut/repos", "events_url": "https://api.github.com/users/epizut/events{/privacy}", "received_events_url": "https://api.github.com/users/epizut/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3468123446, "node_id": "LA_kwDOAbcwm87Ot102", "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention", "name": "needs attention", "color": "6d626c", "default": false, "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-10-12T08:26:05Z", "updated_at": "2022-11-30T21:46:26Z", "closed_at": "2022-11-30T21:46:26Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "_map_overlap()_ is unable to handle raw pandas DataFrame, unlike _map_partition()_.\r\n\r\n```\r\nimport dask.dataframe\r\nimport pandas as pd\r\n\r\ndf = pd.util.testing.makeMixedDataFrame()\r\n\r\n# Works  fine\r\ndask.dataframe.map_partitions(lambda df: df, df)\r\n\r\n# Raises \"IndexError: list index out of range\"\r\ndask.dataframe.rolling.map_overlap(lambda df: df, df, before=0, after=0)\r\n```\r\n![image](https://user-images.githubusercontent.com/1694892/195291225-3961d434-7c67-43e4-a265-6d3258ec988e.png)\r\n\r\n\r\nIt looks like it should be working as we can see the following code in _map_overlap()_:\r\n```\r\nif align_dataframes:\r\n    args = _maybe_from_pandas(args)\r\n```\r\n\r\nI can work on a PR if needed.", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9567/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9567/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9540", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9540/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9540/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9540/events", "html_url": "https://github.com/dask/dask/pull/9540", "id": 1395442393, "node_id": "PR_kwDOAbcwm85AF8KH", "number": 9540, "title": "Ensure pickle-able binops in `delayed`", "user": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1968982461, "node_id": "MDU6TGFiZWwxOTY4OTgyNDYx", "url": "https://api.github.com/repos/dask/dask/labels/delayed", "name": "delayed", "color": "4f6edd", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-10-03T23:06:48Z", "updated_at": "2022-10-04T16:35:07Z", "closed_at": "2022-10-04T16:35:07Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/9540", "html_url": "https://github.com/dask/dask/pull/9540", "diff_url": "https://github.com/dask/dask/pull/9540.diff", "patch_url": "https://github.com/dask/dask/pull/9540.patch", "merged_at": "2022-10-04T16:35:07Z"}, "body": "Avoid un-pickle-able local functions in delayed. Adds a new CI check to avoid breaking this.\r\n\r\n- [x] Closes #9536 \r\n- [x] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9540/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9540/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/9536", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9536/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9536/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9536/events", "html_url": "https://github.com/dask/dask/issues/9536", "id": 1394879147, "node_id": "I_kwDOAbcwm85TJCqr", "number": 9536, "title": "`dask` fails to import when `tokenize.ensure-deterministic` is `True`", "user": {"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2022-10-03T14:55:12Z", "updated_at": "2022-10-04T16:35:08Z", "closed_at": "2022-10-04T16:35:08Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "When `tokenize.ensure-deterministic` is set to `True`, `dask` fails to import\r\n\r\n```python\r\nDASK_TOKENIZE__ENSURE_DETERMINISTIC=\"True\" python -c 'import dask; print(dask.__version__)'\r\nTraceback (most recent call last):\r\n  File \"/Users/james/projects/dask/dask/dask/base.py\", line 1037, in normalize_function\r\n    return function_cache[func]\r\nKeyError: <function right.<locals>._inner at 0x10ce74a60>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/Users/james/projects/dask/dask/dask/__init__.py\", line 12, in <module>\r\n    from dask.delayed import delayed\r\n  File \"/Users/james/projects/dask/dask/dask/delayed.py\", line 765, in <module>\r\n    Delayed._bind_operator(op)\r\n  File \"/Users/james/projects/dask/dask/dask/utils.py\", line 1299, in _bind_operator\r\n    setattr(cls, rmeth, cls._get_binary_operator(op, inv=True))\r\n  File \"/Users/james/projects/dask/dask/dask/delayed.py\", line 644, in _get_binary_operator\r\n    method = delayed(right(op) if inv else op, pure=True)\r\n  File \"cytoolz/functoolz.pyx\", line 250, in cytoolz.functoolz.curry.__call__\r\n  File \"/Users/james/projects/dask/dask/dask/delayed.py\", line 488, in delayed\r\n    token = tokenize(obj, nout, pure=pure)\r\n  File \"/Users/james/projects/dask/dask/dask/delayed.py\", line 261, in tokenize\r\n    return _tokenize(*args, **kwargs)\r\n  File \"/Users/james/projects/dask/dask/dask/base.py\", line 931, in tokenize\r\n    hasher = _md5(str(tuple(map(normalize_token, args))).encode())\r\n  File \"/Users/james/projects/dask/dask/dask/utils.py\", line 639, in __call__\r\n    return meth(arg, *args, **kwargs)\r\n  File \"/Users/james/projects/dask/dask/dask/base.py\", line 1016, in normalize_object\r\n    return normalize_function(o)\r\n  File \"/Users/james/projects/dask/dask/dask/base.py\", line 1039, in normalize_function\r\n    result = _normalize_function(func)\r\n  File \"/Users/james/projects/dask/dask/dask/base.py\", line 1080, in _normalize_function\r\n    raise RuntimeError(\r\nRuntimeError: Function <function right.<locals>._inner at 0x10ce74a60> may not be deterministically hashed by cloudpickle. See: https://github.com/cloudpipe/cloudpickle/issues/385 for more information.\r\n```", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9536/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9536/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9533", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9533/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9533/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9533/events", "html_url": "https://github.com/dask/dask/issues/9533", "id": 1392962061, "node_id": "I_kwDOAbcwm85TBuoN", "number": 9533, "title": "Array.copy is not a no-op", "user": {"login": "djhoese", "id": 1828519, "node_id": "MDQ6VXNlcjE4Mjg1MTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1828519?v=4", "gravatar_id": "", "url": "https://api.github.com/users/djhoese", "html_url": "https://github.com/djhoese", "followers_url": "https://api.github.com/users/djhoese/followers", "following_url": "https://api.github.com/users/djhoese/following{/other_user}", "gists_url": "https://api.github.com/users/djhoese/gists{/gist_id}", "starred_url": "https://api.github.com/users/djhoese/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/djhoese/subscriptions", "organizations_url": "https://api.github.com/users/djhoese/orgs", "repos_url": "https://api.github.com/users/djhoese/repos", "events_url": "https://api.github.com/users/djhoese/events{/privacy}", "received_events_url": "https://api.github.com/users/djhoese/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 386719598, "node_id": "MDU6TGFiZWwzODY3MTk1OTg=", "url": "https://api.github.com/repos/dask/dask/labels/documentation", "name": "documentation", "color": "f9d0c4", "default": true, "description": "Improve or add to documentation"}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2022-09-30T20:11:55Z", "updated_at": "2022-10-14T15:41:50Z", "closed_at": "2022-10-14T15:41:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**Describe the issue**:\r\n\r\nThe `Array.copy` docs say that `.copy()` is a no-op. However, if you actually do a copy a task is added to the graph and the `.name` of the original and new arrays are not equal.\r\n\r\nhttps://docs.dask.org/en/stable/generated/dask.array.Array.copy.html\r\n\r\nSee the example below.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.array as da\r\na = da.zeros(5)\r\nb = a.copy()\r\n```\r\n\r\n![orig_array](https://user-images.githubusercontent.com/1828519/193348368-93806016-39d4-44e9-b9c7-3a34a69bf376.png)\r\n\r\n![copied_array](https://user-images.githubusercontent.com/1828519/193348388-9b6928e5-7d63-4e51-8f66-481b19ec561f.png)\r\n\r\n**Anything else we need to know?**:\r\n\r\nIn the pyresample library we have custom objects that can contain dask arrays. In the `__eq__` of these methods we do a shortcut to avoid having to compute `a == b` by doing `a.name == b.name` if the objects are dask arrays. In a lot of our use cases a and b are relatively large arrays that are loaded from files on disk.\r\n\r\nThis is coming up as a problem for me with xarray where after new behavior to their deep copy logic, dask arrays are now being copied. See https://github.com/pydata/xarray/issues/7111 and https://github.com/pydata/xarray/pull/7089.\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.9.1\r\n- Python version: 3.10\r\n- Operating System: PopOS\r\n- Install method (conda, pip, source): conda-forge\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9533/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9533/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9526", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9526/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9526/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9526/events", "html_url": "https://github.com/dask/dask/issues/9526", "id": 1391042277, "node_id": "I_kwDOAbcwm85S6Z7l", "number": 9526, "title": "dask array of integers allows assigning np.nan", "user": {"login": "ivirshup", "id": 8238804, "node_id": "MDQ6VXNlcjgyMzg4MDQ=", "avatar_url": "https://avatars.githubusercontent.com/u/8238804?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ivirshup", "html_url": "https://github.com/ivirshup", "followers_url": "https://api.github.com/users/ivirshup/followers", "following_url": "https://api.github.com/users/ivirshup/following{/other_user}", "gists_url": "https://api.github.com/users/ivirshup/gists{/gist_id}", "starred_url": "https://api.github.com/users/ivirshup/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ivirshup/subscriptions", "organizations_url": "https://api.github.com/users/ivirshup/orgs", "repos_url": "https://api.github.com/users/ivirshup/repos", "events_url": "https://api.github.com/users/ivirshup/events{/privacy}", "received_events_url": "https://api.github.com/users/ivirshup/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-09-29T15:11:30Z", "updated_at": "2022-10-05T16:25:59Z", "closed_at": "2022-10-05T15:07:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Describe the issue**:\r\n\r\nAssigning np.nan to a dask array with integer dtypes does not throw an error.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.array as da, numpy as np\r\n\r\ndask_array = da.ones((3, 3), dtype=int)\r\ndask_array[:, 1] = np.nan\r\ndask_array.compute()\r\n```\r\n\r\n```\r\narray([[                   1, -9223372036854775808,                    1],\r\n       [                   1, -9223372036854775808,                    1],\r\n       [                   1, -9223372036854775808,                    1]])\r\n```\r\n\r\nThis fails with numpy arrays:\r\n\r\n```python\r\nnp_array = np.ones((3, 3), dtype=int)\r\nnp_array[:, 1] = np.nan\r\n```\r\n\r\n```pytb\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nInput In [26], in <cell line: 2>()\r\n      1 np_array = np.ones((3, 3), dtype=int)\r\n----> 2 np_array[:, 1] = np.nan\r\n\r\nValueError: cannot convert float NaN to integer\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nI was surprised to find that numpy allows assigning other floating point values to an integer array without complaining:\r\n\r\n```python\r\nnp_array[:, 1] = 5.5\r\nnp_array\r\n```\r\n\r\n```\r\narray([[1, 5, 1],\r\n       [1, 5, 1],\r\n       [1, 5, 1]])\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.9.1\r\n- Python version: Python 3.9.12 (main, Mar 26 2022, 15:52:10) [Clang 13.0.0 (clang-1300.0.29.30)]\r\n- Operating System: macOS-11.6.8-x86_64-i386-64bit\r\n- Install method (conda, pip, source): pip\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9526/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9526/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9514", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9514/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9514/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9514/events", "html_url": "https://github.com/dask/dask/issues/9514", "id": 1384169627, "node_id": "I_kwDOAbcwm85SgMCb", "number": 9514, "title": "Selecting columns from a timeseries DataFrame changes the data", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-09-23T18:34:36Z", "updated_at": "2022-10-04T20:03:08Z", "closed_at": "2022-10-04T20:03:08Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "**What happened**:\r\n\r\nSelecting columns from a `DataFrame` created by `dask.datasets.timeseries` can sometimes change the data in those columns. It seems likely that the problem has something to do with `optimize_dataframe_getitem`, because using `compute(optimize_graph=False)` avoids the unexpected behavior.\r\n\r\n**What you expected to happen**:\r\n\r\nSelecting columns should **never** change the values in those columns.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask\r\nimport dask.dataframe as dd\r\n\r\nddf = dask.datasets.timeseries(\r\n    end='2000-01-02',\r\n    freq='3600s',\r\n    partition_freq='1d',\r\n    seed=1,\r\n)\r\n\r\ncolumns = [\"x\"]\r\ndd.assert_eq(\r\n    ddf[columns].compute(),\r\n    ddf.compute()[columns],\r\n)\r\n```\r\n\r\nThis fails! (and moving to an earlier Dask version doesn't seem to resolve the problem)", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9514/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 1}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9514/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9490", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9490/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9490/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9490/events", "html_url": "https://github.com/dask/dask/issues/9490", "id": 1372996998, "node_id": "I_kwDOAbcwm85R1kWG", "number": 9490, "title": "Can no longer provide `split_out=None` as a default in `groupby.aggregate`", "user": {"login": "wence-", "id": 1126981, "node_id": "MDQ6VXNlcjExMjY5ODE=", "avatar_url": "https://avatars.githubusercontent.com/u/1126981?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wence-", "html_url": "https://github.com/wence-", "followers_url": "https://api.github.com/users/wence-/followers", "following_url": "https://api.github.com/users/wence-/following{/other_user}", "gists_url": "https://api.github.com/users/wence-/gists{/gist_id}", "starred_url": "https://api.github.com/users/wence-/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wence-/subscriptions", "organizations_url": "https://api.github.com/users/wence-/orgs", "repos_url": "https://api.github.com/users/wence-/repos", "events_url": "https://api.github.com/users/wence-/events{/privacy}", "received_events_url": "https://api.github.com/users/wence-/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2022-09-14T13:32:49Z", "updated_at": "2022-09-14T21:24:41Z", "closed_at": "2022-09-14T21:24:41Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**What happened**:\r\n\r\nSince a combination of #9453 and #9302, one can no longer provide `split_out=None` to `groupby.aggregate` to obtain the default `split_out` value (eventually `split_out=None` defaults to `split_out=1` deep inside `apply_concat_apply`).\r\n\r\n(cc @rjzamora, @ian-r-rose)\r\n\r\n**What you expected to happen**:\r\n\r\n`split_out=None` should default to something sensible. The question arises as to whether one should change the API of all the aggregate functions to default to `split_out=None` rather than `split_out=1` or if we should just handle it locally. (The lack of true option-types in Python bites again \ud83d\ude22)\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.dataframe\r\nimport pandas as pd\r\n\r\ndf = pd.DataFrame({\"grouping\": [1, 2, 1, 1, 3, 2, 1, 1], \"a\": list(range(8))})\r\n\r\nddf = dask.dataframe.from_pandas(df)\r\n\r\ngroups = ddf.groupby(\"grouping\").aggregate(\"sum\", split_out=None).compute()\r\n\r\nTypeError                                 Traceback (most recent call last)\r\nInput In [5], in <cell line: 1>()\r\n----> 1 ddf.groupby(\"grouping\").aggregate(\"sum\", split_out=None).compute()\r\n\r\nFile ~/Documents/src/dask/dask/dataframe/groupby.py:2265, in DataFrameGroupBy.aggregate(self, arg, split_every, split_out, shuffle)\r\n   2262 if arg == \"size\":\r\n   2263     return self.size()\r\n-> 2265 return super().aggregate(\r\n   2266     arg, split_every=split_every, split_out=split_out, shuffle=shuffle\r\n   2267 )\r\n\r\nFile ~/Documents/src/dask/dask/dataframe/groupby.py:1685, in _GroupBy.aggregate(self, arg, split_every, split_out, shuffle)\r\n   1682 @_aggregate_docstring()\r\n   1683 def aggregate(self, arg, split_every=None, split_out=1, shuffle=None):\r\n   1684     if shuffle is None:\r\n-> 1685         if split_out > 1:\r\n   1686             shuffle = shuffle or config.get(\"shuffle\", None) or \"tasks\"\r\n   1687         else:\r\n\r\nTypeError: '>' not supported between instances of 'NoneType' and 'int'\r\n```\r\n\r\nA similar issue occurs in `apply_concat_apply` as well:\r\n\r\n```\r\ndask.dataframe.core.aca(ddf, chunk=len, aggregate=sum, combine=sum, sort=True)\r\nin apply_concat_apply(args, chunk, aggregate, combine, meta, token, chunk_kwargs, aggregate_kwargs, combine_kwargs, split_every, split_out, split_out_setup, split_out_setup_kwargs, sort, ignore_index, **kwargs)\r\n   6447 # Handle sort behavior\r\n   6448 if sort is not None:\r\n-> 6449     if sort and split_out > 1:\r\n   6450         raise NotImplementedError(\r\n   6451             \"Cannot guarantee sorted keys for `split_out>1`.\"\r\n   6452             \" Try using split_out=1, or grouping with sort=False.\"\r\n   6453         )\r\n   6454     aggregate_kwargs = aggregate_kwargs or {}\r\n\r\nTypeError: '>' not supported between instances of 'NoneType' and 'int'\r\n```", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9490/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9490/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9488", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9488/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9488/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9488/events", "html_url": "https://github.com/dask/dask/issues/9488", "id": 1372115974, "node_id": "I_kwDOAbcwm85RyNQG", "number": 9488, "title": "Chunks with size literals (`\"20 MiB\"`) can result in significantly different chunk sizes than requested", "user": {"login": "gjoseph92", "id": 3309802, "node_id": "MDQ6VXNlcjMzMDk4MDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3309802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gjoseph92", "html_url": "https://github.com/gjoseph92", "followers_url": "https://api.github.com/users/gjoseph92/followers", "following_url": "https://api.github.com/users/gjoseph92/following{/other_user}", "gists_url": "https://api.github.com/users/gjoseph92/gists{/gist_id}", "starred_url": "https://api.github.com/users/gjoseph92/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gjoseph92/subscriptions", "organizations_url": "https://api.github.com/users/gjoseph92/orgs", "repos_url": "https://api.github.com/users/gjoseph92/repos", "events_url": "https://api.github.com/users/gjoseph92/events{/privacy}", "received_events_url": "https://api.github.com/users/gjoseph92/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 16, "created_at": "2022-09-13T23:25:34Z", "updated_at": "2022-09-23T20:32:13Z", "closed_at": "2022-09-23T20:32:13Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "When using chunksizes defined in numbers of bytes, the chunksize chosen is extremely sensitive to minor perturbations in the shape of the overall array. In this example, increasing the array shape by 1 switches the chunk sizes from being the requested size, to being far smaller than the requested size and having 4x more chunks:\r\n\r\n```python\r\n>>> import dask.array as da\r\n>>> from dask.utils import format_bytes\r\n\r\n>>> a1 = da.random.random((97936, 97936), chunks=(\"20 MiB\", \"20 MiB\"))\r\n>>> a1.npartitions\r\n3721\r\n>>> format_bytes(a1.blocks[0, 0].nbytes)\r\n'20.00 MiB'\r\n\r\n>>> # increase shape by 1 along both dimensions (97936 -> 97937)\r\n>>> a1 = da.random.random((97937, 97937), chunks=(\"20 MiB\", \"20 MiB\"))\r\n>>> a1.npartitions  # 4x more chunks than previous\r\n14161\r\n>>> format_bytes(a1.blocks[0, 0].nbytes)  # 4x smaller chunks than previous, and nowhere near requested 20MiB size\r\n'5.17 MiB'\r\n```\r\n\r\nThis was discovered in https://github.com/coiled/coiled-runtime/issues/316#issuecomment-1245623435, where the size of the array is set relative to the total cluster memory. Tiny, natural perturbations in total cluster memory (on the order of 1 MB) were causing the graph to have wildly different numbers of tasks, and runtimes.\r\n\r\nFor a more minimal reproducer, consider:\r\n\r\n```python\r\n>>> from dask.array.core import normalize_chunks\r\n\r\n>>> normalize_chunks(\"10 B\", (101,), dtype=bool)\r\n((10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1),)\r\n\r\n>>> normalize_chunks(\"10 B\", (102,), dtype=bool)\r\n((6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6),)\r\n\r\n>>> normalize_chunks(\"10 B\", (103,), dtype=bool)\r\n((10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 3),)\r\n```\r\n\r\nIn most cases, we get 11 chunks: 10 of exactly the requested size, and the last one holding whatever remainder was needed.\r\n\r\nBut in the case of a 102-length array, dask tries to get very clever: it recognizes that by picking a different chunksize, all the chunks could be the same size (instead of having one differently-sized chunk for the remainder at the end). So we get 17 chunks instead of 11, and each chunk is 40% smaller than we asked for.\r\n\r\ncc @ian-r-rose @jsignell @jrbourbeau ", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9488/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9488/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9486", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9486/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9486/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9486/events", "html_url": "https://github.com/dask/dask/pull/9486", "id": 1372066649, "node_id": "PR_kwDOAbcwm84-5aXC", "number": 9486, "title": "Groupby sort upstream compatibility", "user": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 2949860090, "node_id": "MDU6TGFiZWwyOTQ5ODYwMDkw", "url": "https://api.github.com/repos/dask/dask/labels/upstream", "name": "upstream", "color": "DDF8B0", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2022-09-13T22:24:58Z", "updated_at": "2022-09-23T17:08:10Z", "closed_at": "2022-09-22T18:48:19Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/9486", "html_url": "https://github.com/dask/dask/pull/9486", "diff_url": "https://github.com/dask/dask/pull/9486.diff", "patch_url": "https://github.com/dask/dask/pull/9486.patch", "merged_at": "2022-09-22T18:48:19Z"}, "body": "Fixes #9428, sort of. The [pandas GroupBy](https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.groupby.html) defaults to `sort=True`, and `None` is not a valid input. Dask's implementation has `sort=None` as a default, so when we started to pass `self.sort` down, that got truthied to `False`. So #9302 inadvertently switched sorting of intermediate partitions from `True` to `False`, which was not obvious at the time! In the interests of upstream compatibility, this PR changes the default for `sort` to `True`. I've also updated the defaults for `dropna` and `observed` while I'm here to match upstream defaults.\r\n\r\nThat being said, we probably *don't* want to sort intermediate partitions when doing a groupby/agg, since that is extra work. So this PR also reintroduces the idea of #9386, but doing it deliberately this time :)\r\n\r\nSome justification, based on some quick pandas performance measurements:\r\n\r\n```python\r\nimport dask.datasets\r\n\r\n# Create a pandas dataframe with a lot of groups, dask is just used for expediency\r\ndf = dask.datasets.timeseries(id_lam=1e18).compute()\r\n\r\n# Groupby/agg on integer column\r\n%time df.groupby(\"id\", sort=True).agg({\"x\": \"sum\", \"y\": \"mean\"})   # 1.7 s\r\n%time df.groupby(\"id\", sort=False).agg({\"x\": \"sum\", \"y\": \"mean\"})  # 500 ms\r\n\r\n# Groupby/agg on string[python] column\r\ndf2 = df.assign(id=df.id.astype(\"string[python]\"))\r\n\r\n%time df2.groupby(\"id\", sort=True).agg({\"x\": \"sum\", \"y\": \"mean\"})  # 9.4 s\r\n%time df2.groupby(\"id\", sort=False).agg({\"x\": \"sum\", \"y\": \"mean\"})  # 1.6 s\r\n\r\n# Groupby/agg on string[pyarrow] column\r\ndf3 = df.assign(id=df.id.astype(\"string[pyarrow]\"))\r\n\r\n%time df3.groupby(\"id\", sort=True).agg({\"x\": \"sum\", \"y\": \"mean\"})  # 7.7 s\r\n%time df3.groupby(\"id\", sort=False).agg({\"x\": \"sum\", \"y\": \"mean\"})  # 1.2 s\r\n\r\n# Groupby/agg on integer categorical column\r\ndf4 = df.assign(id=df.id.astype(\"category\"))\r\n\r\n%time df4.groupby(\"id\", sort=True).agg({\"x\": \"sum\", \"y\": \"mean\"})  # 700 ms\r\n%time df4.groupby(\"id\", sort=False).agg({\"x\": \"sum\", \"y\": \"mean\"})  # 1.4 s\r\n\r\n# Groupby/agg on string categorical column\r\ndf5 = df.assign(id=df.id.astype(\"string[python]\").astype(\"category\"))\r\n\r\n%time df5.groupby(\"id\", sort=True).agg({\"x\": \"sum\", \"y\": \"mean\"})  # 1.6 s\r\n%time df5.groupby(\"id\", sort=False).agg({\"x\": \"sum\", \"y\": \"mean\"})  # 10.3 s\r\n```\r\n\r\nNote that in almost all cases, it's significantly faster to set `sort=False`. The major exception is with categoricals, which, bizarrely, are much faster with `sort=True`! This seems to be an upstream performance issue in pandas, possibly related to https://github.com/pandas-dev/pandas/issues/32976, where a cythonized fast-path is being missed.\r\n\r\nI don't think we should be targeting categoricals specifically here, especially since it's likely not a fundamental performance gap, so I'm more comfortable just saying that generally `sort=False` for intermediate partitions is a better option here. I mostly bring up categoricals because that is the case that was being caught in #9428. So even though this PR won't fix that specific regression, I feel that this is the more correct and maintainable thing to do here.\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9486/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9486/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/9478", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9478/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9478/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9478/events", "html_url": "https://github.com/dask/dask/issues/9478", "id": 1366958343, "node_id": "I_kwDOAbcwm85ReiEH", "number": 9478, "title": "Diagnostics graphs are not time aligned", "user": {"login": "djhoese", "id": 1828519, "node_id": "MDQ6VXNlcjE4Mjg1MTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1828519?v=4", "gravatar_id": "", "url": "https://api.github.com/users/djhoese", "html_url": "https://github.com/djhoese", "followers_url": "https://api.github.com/users/djhoese/followers", "following_url": "https://api.github.com/users/djhoese/following{/other_user}", "gists_url": "https://api.github.com/users/djhoese/gists{/gist_id}", "starred_url": "https://api.github.com/users/djhoese/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/djhoese/subscriptions", "organizations_url": "https://api.github.com/users/djhoese/orgs", "repos_url": "https://api.github.com/users/djhoese/repos", "events_url": "https://api.github.com/users/djhoese/events{/privacy}", "received_events_url": "https://api.github.com/users/djhoese/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 3468123446, "node_id": "LA_kwDOAbcwm87Ot102", "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention", "name": "needs attention", "color": "6d626c", "default": false, "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-09-08T20:37:24Z", "updated_at": "2023-02-23T18:53:06Z", "closed_at": "2023-02-23T18:53:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**What happened**:\r\n\r\nWhile working with some dask-based code I used the `Profiler`, `ResourceProfiler`, and `CacheProfiler` to debug which tasks were not as dask-friendly as I'd like. The code being run takes a non-negligible amount of time to generate the dask array. This means the resource profiler is collecting information for a while before the other profiles have seen their first task being computed/cached. This results in the resource (CPU/memory) plot not being aligned with the task-based Profiler and CacheProfiler plots. The latter plots are plotted on the left even though they didn't start at that point in time.\r\n\r\nIf you run the below code and open the two HTML files it creates (you might need to zoom out on the plots), you'll see that the \"nostartertask\" plot shows the dask tasks executing at time 0 even though those tasks weren't executed until 5 seconds later. The \"startertask\" plots show that if the \"starter task\" is used as a \"reference\" for time 0 then things line up a little better.\r\n\r\n### No Starter Task\r\n\r\n![image](https://user-images.githubusercontent.com/1828519/189220663-6aad0121-aad2-4e86-b613-902416c0f6f2.png)\r\n\r\n### With Starter Task\r\n\r\n![image](https://user-images.githubusercontent.com/1828519/189220712-a596d8b6-e817-4153-8053-f7060df6fe9f.png)\r\n\r\n**What you expected to happen**:\r\n\r\nWhen visualizing Profilers/diagnostic tools together, they should be aligned to the same time range.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport time\r\n\r\nimport dask.array as da\r\nfrom dask.diagnostics import ResourceProfiler, Profiler, CacheProfiler, visualize\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    with Profiler() as prof, ResourceProfiler() as rprof, CacheProfiler() as cprof:\r\n        # da.random.random((100, 100), chunks=10).compute()\r\n        time.sleep(5)\r\n        da.random.random((100, 100), chunks=10).compute()\r\n    filename = '/tmp/debug_diagnostics_nostartertask.html'\r\n    visualize([rprof, prof, cprof], filename=filename, show=False)\r\n    print(f\"file://{filename}\")\r\n\r\n    with Profiler() as prof, ResourceProfiler() as rprof, CacheProfiler() as cprof:\r\n        da.random.random((100, 100), chunks=10).compute()\r\n        time.sleep(5)\r\n        da.random.random((100, 100), chunks=10).compute()\r\n    filename = '/tmp/debug_diagnostics_startertask.html'\r\n    visualize([rprof, prof, cprof], filename=filename, show=False)\r\n    print(f\"file://{filename}\")\r\n\r\n\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.4.0\r\n- Python version: 3.9\r\n- Operating System: PopOS (Ubuntu)\r\n- Install method (conda, pip, source): conda-forge\r\n\r\nEdit: Just tested with 2022.9.0 and same results.", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9478/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9478/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9477", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9477/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9477/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9477/events", "html_url": "https://github.com/dask/dask/issues/9477", "id": 1366922101, "node_id": "I_kwDOAbcwm85ReZN1", "number": 9477, "title": "Groupby aggregations fail with `string[pyarrow]` and `p2p` shuffle", "user": {"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-09-08T20:01:26Z", "updated_at": "2022-09-08T20:17:44Z", "closed_at": "2022-09-08T20:17:44Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "@rjzamora and I saw today that using the new shuffle-based groupby-aggregation algorithm with `p2p` shuffling and `string[pyarrow]` dtypes runs into issues. See the reproducer below:\r\n\r\n```python\r\nfrom dask.datasets import timeseries\r\nfrom distributed import Client\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    with Client():\r\n        ddf = timeseries(dtypes={\"x\": float, \"y\": str})\r\n        ddf = ddf.astype({\"y\": \"string[pyarrow]\"})\r\n\r\n        ddf.groupby(\"y\").agg({\"x\": \"mean\"}, shuffle=\"p2p\").compute()\r\n\r\n```\r\n\r\nfails with \r\n\r\n```python\r\n...\r\n...\r\n  File \"/Users/james/projects/dask/distributed/distributed/shuffle/shuffle_extension.py\", line 352, in _get_shuffle\r\n    schema=pa.Schema.from_pandas(empty).serialize().to_pybytes()\r\n  File \"pyarrow/types.pxi\", line 1690, in pyarrow.lib.Schema.from_pandas\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/pyarrow/pandas_compat.py\", line 544, in dataframe_to_types\r\n    type_ = pa.array(c.head(0), from_pandas=True).type\r\nAttributeError: 'Index' object has no attribute 'head'\r\n```\r\n\r\n<details>\r\n<summary>Full traceback:</summary>\r\n\r\n```\r\n2022-09-08 14:57:15,593 - distributed.worker - WARNING - Compute Failed\r\nKey:       ('shuffle_transfer-2766e99ad1002468f827e3a647a7caf4', 0)\r\nFunction:  subgraph_callable-b461f7cf-7f41-4bf3-8f42-3ca9ddba\r\nargs:      (        count-x-caf6abc2c5c9c7a4c1b06ad5806fad59  sum-x-9f523534b383db420c8cfd35ee5a7c27  _partitions\r\ny\r\nXavier                                      3294                              -27.045405            2\r\nOliver                                      3300                              -53.233624            2\r\nHannah                                      3378                              -23.227861            2\r\nLaura                                       3314                               41.832917            1\r\nYvonne                                      3395                               27.688311            1\r\n...                                          ...                                     ...          ...\r\nEdith                                       3384                              -16.384580            2\r\nXavier                                      3350                               41\r\nkwargs:    {}\r\nException: 'AttributeError(\"\\'Index\\' object has no attribute \\'head\\'\")'\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/james/projects/dask/dask/test.py\", line 10, in <module>\r\n    ddf.groupby(\"y\").agg({\"x\": \"mean\"}, shuffle=\"p2p\").compute()\r\n  File \"/Users/james/projects/dask/dask/dask/base.py\", line 315, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/Users/james/projects/dask/dask/dask/base.py\", line 600, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/Users/james/projects/dask/distributed/distributed/client.py\", line 3052, in get\r\n    results = self.gather(packed, asynchronous=asynchronous, direct=direct)\r\n  File \"/Users/james/projects/dask/distributed/distributed/client.py\", line 2226, in gather\r\n    return self.sync(\r\n  File \"/Users/james/projects/dask/distributed/distributed/utils.py\", line 339, in sync\r\n    return sync(\r\n  File \"/Users/james/projects/dask/distributed/distributed/utils.py\", line 406, in sync\r\n    raise exc.with_traceback(tb)\r\n  File \"/Users/james/projects/dask/distributed/distributed/utils.py\", line 379, in f\r\n    result = yield future\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/tornado/gen.py\", line 762, in run\r\n    value = future.result()\r\n  File \"/Users/james/projects/dask/distributed/distributed/client.py\", line 2089, in _gather\r\n    raise exception.with_traceback(traceback)\r\n  File \"/Users/james/projects/dask/dask/dask/optimization.py\", line 990, in __call__\r\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n  File \"/Users/james/projects/dask/dask/dask/core.py\", line 149, in get\r\n    result = _execute_task(task, cache)\r\n  File \"/Users/james/projects/dask/dask/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/Users/james/projects/dask/dask/dask/utils.py\", line 71, in apply\r\n    return func(*args, **kwargs)\r\n  File \"/Users/james/projects/dask/distributed/distributed/shuffle/shuffle.py\", line 42, in shuffle_transfer\r\n    get_ext().add_partition(input, id, npartitions=npartitions, column=column)\r\n  File \"/Users/james/projects/dask/distributed/distributed/shuffle/shuffle_extension.py\", line 286, in add_partition\r\n    shuffle = self.get_shuffle(\r\n  File \"/Users/james/projects/dask/distributed/distributed/shuffle/shuffle_extension.py\", line 389, in get_shuffle\r\n    return sync(\r\n  File \"/Users/james/projects/dask/distributed/distributed/utils.py\", line 406, in sync\r\n    raise exc.with_traceback(tb)\r\n  File \"/Users/james/projects/dask/distributed/distributed/utils.py\", line 379, in f\r\n    result = yield future\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/tornado/gen.py\", line 762, in run\r\n    value = future.result()\r\n  File \"/Users/james/projects/dask/distributed/distributed/shuffle/shuffle_extension.py\", line 352, in _get_shuffle\r\n    schema=pa.Schema.from_pandas(empty).serialize().to_pybytes()\r\n  File \"pyarrow/types.pxi\", line 1690, in pyarrow.lib.Schema.from_pandas\r\n  File \"/Users/james/mambaforge/envs/dask/lib/python3.10/site-packages/pyarrow/pandas_compat.py\", line 544, in dataframe_to_types\r\n    type_ = pa.array(c.head(0), from_pandas=True).type\r\nAttributeError: 'Index' object has no attribute 'head'\r\n```\r\n\r\n</details>\r\n\r\nPackage versions:\r\n\r\n- `dask`: `main` branch\r\n- `distributed`: `main` branch\r\n- `pyarrow`: 9.0.0", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9477/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9477/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9445", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9445/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9445/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9445/events", "html_url": "https://github.com/dask/dask/issues/9445", "id": 1357062326, "node_id": "I_kwDOAbcwm85Q4yC2", "number": 9445, "title": "ValueError with dataframe.read_csv when running with fsspec 2022.8.0 but not fsspec 2022.7.1", "user": {"login": "kiramt", "id": 18192472, "node_id": "MDQ6VXNlcjE4MTkyNDcy", "avatar_url": "https://avatars.githubusercontent.com/u/18192472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kiramt", "html_url": "https://github.com/kiramt", "followers_url": "https://api.github.com/users/kiramt/followers", "following_url": "https://api.github.com/users/kiramt/following{/other_user}", "gists_url": "https://api.github.com/users/kiramt/gists{/gist_id}", "starred_url": "https://api.github.com/users/kiramt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kiramt/subscriptions", "organizations_url": "https://api.github.com/users/kiramt/orgs", "repos_url": "https://api.github.com/users/kiramt/repos", "events_url": "https://api.github.com/users/kiramt/events{/privacy}", "received_events_url": "https://api.github.com/users/kiramt/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 1342320181, "node_id": "MDU6TGFiZWwxMzQyMzIwMTgx", "url": "https://api.github.com/repos/dask/dask/labels/needs%20info", "name": "needs info", "color": "d0cfcc", "default": false, "description": "Needs further information from the user"}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-08-31T09:27:03Z", "updated_at": "2022-09-01T12:06:50Z", "closed_at": "2022-09-01T12:06:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n\r\n**What happened**:\r\nI called dask.dataframe.read_csv and a ValueError was raised.\r\n\r\n**What you expected to happen**:\r\nI expected the call to read the csv file without error.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\n> python                                                                                                                                         09:56:14\r\nPython 3.9.12 (main, Mar 26 2022, 15:51:15)\r\n[Clang 13.1.6 (clang-1316.0.21.2)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import dask.dataframe as dd\r\n>>> df = dd.read_csv(\"predict.txt\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"../.venv/lib/python3.9/site-packages/dask/dataframe/io/csv.py\", line 744, in read\r\n    return read_pandas(\r\n  File \"../.venv/lib/python3.9/site-packages/dask/dataframe/io/csv.py\", line 548, in read_pandas\r\n    b_out = read_bytes(\r\n  File \"../.venv/lib/python3.9/site-packages/dask/bytes/core.py\", line 149, in read_bytes\r\n    values = [\r\n  File \"../.venv/lib/python3.9/site-packages/dask/bytes/core.py\", line 150, in <listcomp>\r\n    delayed_read(\r\n  File \"../.venv/lib/python3.9/site-packages/dask/delayed.py\", line 695, in __call__\r\n    return call_function(\r\n  File \"../.venv/lib/python3.9/site-packages/dask/delayed.py\", line 662, in call_function\r\n    args2, collections = unzip(map(unpack_collections, args), 2)\r\n  File \"../.venv/lib/python3.9/site-packages/dask/delayed.py\", line 38, in unzip\r\n    out = list(zip(*ls))\r\n  File \"../.venv/lib/python3.9/site-packages/dask/delayed.py\", line 93, in unpack_collections\r\n    if is_dask_collection(expr):\r\n  File \"../.venv/lib/python3.9/site-packages/dask/base.py\", line 187, in is_dask_collection\r\n    return x.__dask_graph__() is not None\r\n  File \"../.venv/lib/python3.9/site-packages/fsspec/core.py\", line 212, in __getattr__\r\n    return getattr(self.f, item)\r\n  File \"../.venv/lib/python3.9/site-packages/fsspec/core.py\", line 149, in f\r\n    raise ValueError(\r\nValueError: I/O operation on closed file. Please call open() or use a with context\r\n```\r\n\r\n**Anything else we need to know?**:\r\nThe call fails when the fsspec dependency uses fsspec 2022.8.0 but works with fsspec 2022.7.1\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.8.1\r\n- Python version: 3.9.12\r\n- Operating System: macOS / debian\r\n- Install method (conda, pip, source): pip\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9445/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9445/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9435", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9435/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9435/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9435/events", "html_url": "https://github.com/dask/dask/issues/9435", "id": 1351974705, "node_id": "I_kwDOAbcwm85QlX8x", "number": 9435, "title": "Failure loading Parquet dataset with None values in partitoned column", "user": {"login": "Andreas5739738", "id": 35989246, "node_id": "MDQ6VXNlcjM1OTg5MjQ2", "avatar_url": "https://avatars.githubusercontent.com/u/35989246?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Andreas5739738", "html_url": "https://github.com/Andreas5739738", "followers_url": "https://api.github.com/users/Andreas5739738/followers", "following_url": "https://api.github.com/users/Andreas5739738/following{/other_user}", "gists_url": "https://api.github.com/users/Andreas5739738/gists{/gist_id}", "starred_url": "https://api.github.com/users/Andreas5739738/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Andreas5739738/subscriptions", "organizations_url": "https://api.github.com/users/Andreas5739738/orgs", "repos_url": "https://api.github.com/users/Andreas5739738/repos", "events_url": "https://api.github.com/users/Andreas5739738/events{/privacy}", "received_events_url": "https://api.github.com/users/Andreas5739738/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3468123446, "node_id": "LA_kwDOAbcwm87Ot102", "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention", "name": "needs attention", "color": "6d626c", "default": false, "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-08-26T09:00:08Z", "updated_at": "2023-04-04T13:20:11Z", "closed_at": "2023-04-04T13:20:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What happened**: Dask raises an exception when trying to to load a partitioned Parquet file with None values in the partitioned column.\r\n\r\n**What you expected to happen**: Dask loads the Parquet file, restoring any None values. In case this is not technically possible due to pyarrow limitations, Dask provides a way to specify data types manually in order to bypass the failing automatic type detection.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport pyspark\r\nfrom pyspark.sql import SparkSession\r\nspark = SparkSession.builder.getOrCreate()\r\ndf = spark.createDataFrame([(20,'John'), (25, 'Joe'), (None, 'Jane')], ['Age', 'Name'])\r\ndf.write.parquet('people-partitioned.parquet', partitionBy='Age')\r\n\r\nimport dask.dataframe as dd\r\ndd.read_parquet('people-partitioned.parquet', engine='arrow').compute()\r\n```\r\n\r\nResult:\r\n```\r\n---------------------------------------------------------------------------\r\nArrowInvalid                              Traceback (most recent call last)\r\n[...]\r\n~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/pyarrow/_dataset.pyx in pyarrow._dataset.DatasetFactory.finish()\r\n~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/pyarrow/error.pxi in pyarrow.lib.pyarrow_internal_check_status()\r\n~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/pyarrow/error.pxi in pyarrow.lib.check_status()\r\nArrowInvalid: No non-null segments were available for field 'Age'; couldn't infer type\r\n```\r\n\r\n\r\n**Anything else we need to know?**:\r\n\r\nWhen using fastparquet engine, no exception is raised, but the column value None is incorrectly replaced by __HIVE_DEFAULT_PARTITION__ in the loaded dataframe:\r\n\r\n```python\r\nimport pyspark\r\nfrom pyspark.sql import SparkSession\r\nspark = SparkSession.builder.getOrCreate()\r\ndf = spark.createDataFrame([(20,'John'), (25, 'Joe'), (None, 'Jane')], ['Age', 'Name'])\r\ndf.write.parquet('people-partitioned.parquet', partitionBy='Age')\r\n\r\nimport dask.dataframe as dd\r\ndd.read_parquet('people-partitioned.parquet', engine='fastparquet').compute()\r\n```\r\n\r\nResult:\r\n```\r\nName\tAge\r\n0\tJohn\t20\r\n0\tJoe\t25\r\n0\tJane\t__HIVE_DEFAULT_PARTITION__\r\n```\r\n\r\nWhen attempting to load the dataset in Fastparquet directly, I am running into another error (https://github.com/dask/fastparquet/issues/803).\r\n\r\n**Environment**:\r\n\r\n- Dask version: '2022.8.1'\r\n- pyrrow version: '9.0.0'\r\n- Python version: '3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) \\n[GCC 9.4.0]'\r\n- Operating System: Linux\r\n- Install method (conda, pip, source): pip\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9435/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9435/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9413", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9413/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9413/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9413/events", "html_url": "https://github.com/dask/dask/pull/9413", "id": 1346766849, "node_id": "PR_kwDOAbcwm849lK1i", "number": 9413, "title": "Fix caching-related MaterializedLayer.cull performance regression", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2156573524, "node_id": "MDU6TGFiZWwyMTU2NTczNTI0", "url": "https://api.github.com/repos/dask/dask/labels/highlevelgraph", "name": "highlevelgraph", "color": "8c24d6", "default": false, "description": "Issues relating to HighLevelGraphs."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-08-22T17:36:47Z", "updated_at": "2022-08-24T15:26:56Z", "closed_at": "2022-08-24T14:48:25Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/9413", "html_url": "https://github.com/dask/dask/pull/9413", "diff_url": "https://github.com/dask/dask/pull/9413.diff", "patch_url": "https://github.com/dask/dask/pull/9413.patch", "merged_at": "2022-08-24T14:48:24Z"}, "body": "This PR fixes a performance regression introduced by #9267\r\n\r\nIn #9267, we stopped adding `culled_deps` (the  [output](https://github.com/dask/dask/blob/57ff5c2e9c550e3c76592b0affa0d45e88375e12/dask/highlevelgraph.py#L950) of `layer.cull`) to the cache of all known HLG key dependencies.  This is because `culled_deps` is typically meant to define **external** key dependencies rather than **direct** key dependencies in the low-level graph (which typically requires graph materialization to know). \r\n\r\nThe problem with #9267 is that (1) `culled_deps` **does** correspond to direct dependencies for the special case of `MaterializedLayer`, and (2) skipping the `culled_deps` caching results in significant graph-optimization overhead. In other words, we went a bit too far in #9267, and stopped optimizing some cases that **should** be safe.\r\n\r\nThis PR introduces a simple fix: Allow `culled_deps` caching for the \"safe\" case of `MaterializedLayer.cull`.\r\n\r\n- [x] Closes #9389 \r\n- [x] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9413/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 1, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9413/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/9411", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9411/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9411/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9411/events", "html_url": "https://github.com/dask/dask/issues/9411", "id": 1346162837, "node_id": "I_kwDOAbcwm85QPNCV", "number": 9411, "title": "Filtering on a Python list is 2 orders of magnitude slower than filtering on a numpy array", "user": {"login": "RogerThomas", "id": 3211163, "node_id": "MDQ6VXNlcjMyMTExNjM=", "avatar_url": "https://avatars.githubusercontent.com/u/3211163?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RogerThomas", "html_url": "https://github.com/RogerThomas", "followers_url": "https://api.github.com/users/RogerThomas/followers", "following_url": "https://api.github.com/users/RogerThomas/following{/other_user}", "gists_url": "https://api.github.com/users/RogerThomas/gists{/gist_id}", "starred_url": "https://api.github.com/users/RogerThomas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RogerThomas/subscriptions", "organizations_url": "https://api.github.com/users/RogerThomas/orgs", "repos_url": "https://api.github.com/users/RogerThomas/repos", "events_url": "https://api.github.com/users/RogerThomas/events{/privacy}", "received_events_url": "https://api.github.com/users/RogerThomas/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 386719400, "node_id": "MDU6TGFiZWwzODY3MTk0MDA=", "url": "https://api.github.com/repos/dask/dask/labels/scheduler", "name": "scheduler", "color": "D10945", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, {"login": "hayesgb", "id": 12595382, "node_id": "MDQ6VXNlcjEyNTk1Mzgy", "avatar_url": "https://avatars.githubusercontent.com/u/12595382?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hayesgb", "html_url": "https://github.com/hayesgb", "followers_url": "https://api.github.com/users/hayesgb/followers", "following_url": "https://api.github.com/users/hayesgb/following{/other_user}", "gists_url": "https://api.github.com/users/hayesgb/gists{/gist_id}", "starred_url": "https://api.github.com/users/hayesgb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hayesgb/subscriptions", "organizations_url": "https://api.github.com/users/hayesgb/orgs", "repos_url": "https://api.github.com/users/hayesgb/repos", "events_url": "https://api.github.com/users/hayesgb/events{/privacy}", "received_events_url": "https://api.github.com/users/hayesgb/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2022-08-22T10:17:38Z", "updated_at": "2022-09-13T14:34:51Z", "closed_at": "2022-09-13T14:34:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What happened**:\r\nFiltering on a list of integers vs a numpy array on the example below is nearly 200 times slower \r\nFrom the example below I get\r\n\r\n```\r\nPandas with list took: 0.573s, len: 3,934,884\r\nPandas with array took: 0.366s, len: 3,934,884\r\nDask with list took: 41.739s, len: 3,934,884\r\nDask with array took: 0.240s, len: 3,934,884\r\n```\r\n\r\n**What you expected to happen**:\r\n\r\nFiltering on a list vs an array shouldn't be that different in Dask, I would expect it to be a bit slower, but not nearly 200 times slower.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport time\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom dask.dataframe import from_pandas\r\nfrom distributed import LocalCluster, Client\r\n\r\n\r\ndef main():\r\n    n = 10_000_000\r\n    rs = np.random.RandomState(42)\r\n    a_column_unique_values = np.arange(1, n // 10)\r\n    df = pd.DataFrame({\"A\": rs.choice(a_column_unique_values, n), \"B\": rs.random(n)})\r\n\r\n    filter_values_list = sorted(\r\n        rs.choice(a_column_unique_values, len(a_column_unique_values) // 2).tolist()\r\n    )\r\n    filter_values_array = np.array(filter_values_list, dtype=\"i8\")\r\n    print(f\"Len filter: {len(filter_values_list):,}\")\r\n\r\n    t1 = time.time()\r\n    tmp_df = df[df[\"A\"].isin(filter_values_list)].copy()\r\n    len_after_filter = len(tmp_df)\r\n    print(f\"Pandas with list took: {time.time() - t1:,.3f}s, len: {len_after_filter:,}\")\r\n\r\n    t1 = time.time()\r\n    tmp_df = df[df[\"A\"].isin(filter_values_array)].copy()\r\n    len_after_filter = len(tmp_df)\r\n    print(f\"Pandas with array took: {time.time() - t1:,.3f}s, len: {len_after_filter:,}\")\r\n\r\n    with LocalCluster(n_workers=4, processes=True, threads_per_worker=1) as local_cluster:\r\n        with Client(local_cluster):\r\n            ddf = from_pandas(df, npartitions=8).persist()\r\n\r\n            t1 = time.time()\r\n            tmp_ddf = ddf[ddf[\"A\"].isin(filter_values_list)].copy()\r\n            len_after_filter = len(tmp_ddf)\r\n            t2 = time.time()\r\n            print(f\"Dask with list took: {t2-t1:,.3f}s, len: {len_after_filter:,}\")\r\n\r\n            t1 = time.time()\r\n            tmp_ddf = ddf[ddf[\"A\"].isin(filter_values_array)].copy()\r\n            len_after_filter = len(tmp_ddf)\r\n            t2 = time.time()\r\n            print(f\"Dask with array took: {t2-t1:,.3f}s, len: {len_after_filter:,}\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.8.1\r\n- Python version:  3.9.13\r\n- Operating System: MacOS\r\n- Install method (conda, pip, source): pip", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9411/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9411/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9376", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9376/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9376/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9376/events", "html_url": "https://github.com/dask/dask/issues/9376", "id": 1337164177, "node_id": "I_kwDOAbcwm85Ps4GR", "number": 9376, "title": "`SeriesGroupBy` cumulative functions on `axis=1` don't raise an error", "user": {"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2022-08-12T12:46:37Z", "updated_at": "2022-08-16T02:43:56Z", "closed_at": "2022-08-16T02:43:56Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\n\r\nDask DataFrame `SeriesGroupBy` cumulative functions: `cumsum`, `cumprod`, and `cumcount` currently produce outputs when used with `axis=1`. While the pandas equivalents raise a error\r\n\r\n```ValueError: No axis named 1 for object type Series```\r\n\r\nwhich makes sense.\r\n\r\n**What you expected to happen**:\r\n\r\nDask should also raise relevant errors, and stay consistent with pandas\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\n\r\ndf = pd.DataFrame(\r\n    {\r\n        \"x\": [4, 0, 3, 3, 3, 1, 3, 2, 4, 0],\r\n        \"a\": [4, 0, 3, 3, 3, 1, 3, 2, 4, 0],\r\n    }\r\n)\r\n\r\nddf = dd.from_pandas(df, npartitions=2)\r\n\r\n\r\n#\r\n# pandas\r\n#\r\n\r\ndf_grouped = pdf.groupby(\"x\").a.cumsum(\r\n    axis=1\r\n)  # ValueError: No axis named 1 for object type Series\r\n\r\ndf_grouped = pdf.groupby(\"x\").a.cumprod(\r\n    axis=1\r\n)  # ValueError: No axis named 1 for object type Series\r\n\r\ndf_grouped = pdf.groupby(\"x\").a.cumcount(\r\n    axis=1\r\n)  # TypeError: cumcount() got an unexpected keyword argument 'axis'\r\n\r\n\r\n#\r\n# Dask\r\n#\r\n\r\nddf.groupby(\"x\").a.cumsum(axis=1).compute()\r\n#    x  a\r\n# 0  4  8\r\n# 1  0  0\r\n# 2  3  6\r\n# 3  3  6\r\n# 4  3  6\r\n# 5  1  2\r\n# 6  3  6\r\n# 7  2  4\r\n# 8  4  8\r\n# 9  0  0\r\n\r\nddf.groupby(\"x\").a.cumprod(axis=1).compute()\r\n#    x   a\r\n# 0  4  16\r\n# 1  0   0\r\n# 2  3   9\r\n# 3  3   9\r\n# 4  3   9\r\n# 5  1   1\r\n# 6  3   9\r\n# 7  2   4\r\n# 8  4  16\r\n# 9  0   0\r\n\r\nddf.groupby(\"x\").a.cumcount(axis=1).compute()\r\n# 0    0\r\n# 1    0\r\n# 2    0\r\n# 3    1\r\n# 4    2\r\n# 5    0\r\n# 6    3\r\n# 7    0\r\n# 8    1\r\n# 9    1\r\n# dtype: int64\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nWe noticed this while diagnosing #9313\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.8.0\r\n- Python version: 3.9\r\n- Operating System: macOS\r\n- Install method (conda, pip, source): conda\r\n\r\n<!-- If you are reporting an issue such as scale stability, cluster deadlock.\r\nPlease provide a cluster dump state with this issue, by running client.dump_cluster_state()\r\n\r\nhttps://distributed.dask.org/en/stable/api.html?highlight=dump_cluster_state#distributed.Client.dump_cluster_state\r\n\r\n-->\r\n\r\n<details>\r\n<summary>Cluster Dump State:</summary>\r\n\r\n</details>", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9376/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9376/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9359", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9359/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9359/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9359/events", "html_url": "https://github.com/dask/dask/issues/9359", "id": 1330931474, "node_id": "I_kwDOAbcwm85PVGcS", "number": 9359, "title": "GroupBy get_group KeyError when category and npartitions >1", "user": {"login": "ba05", "id": 38542612, "node_id": "MDQ6VXNlcjM4NTQyNjEy", "avatar_url": "https://avatars.githubusercontent.com/u/38542612?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ba05", "html_url": "https://github.com/ba05", "followers_url": "https://api.github.com/users/ba05/followers", "following_url": "https://api.github.com/users/ba05/following{/other_user}", "gists_url": "https://api.github.com/users/ba05/gists{/gist_id}", "starred_url": "https://api.github.com/users/ba05/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ba05/subscriptions", "organizations_url": "https://api.github.com/users/ba05/orgs", "repos_url": "https://api.github.com/users/ba05/repos", "events_url": "https://api.github.com/users/ba05/events{/privacy}", "received_events_url": "https://api.github.com/users/ba05/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2022-08-07T06:51:38Z", "updated_at": "2022-09-02T00:24:25Z", "closed_at": "2022-09-02T00:24:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "Appears there is an issue when using groupby get_group and the group was derived from a pandas categorical type. Only get error when npartitions is >1. Possibly related to #[5847](https://github.com/dask/dask/issues/5847)\r\n\r\n````python\r\ndef checker(npartitions, toCategory):\r\n    import dask.dataframe as dd\r\n    import pandas as pd\r\n\r\n    df = pd.DataFrame({'make':['a','b','c'], 'model': [2,5,7]})\r\n    \r\n    if toCategory:\r\n        df['make'] = df['make'].astype('category')\r\n        \r\n    dd = dd.from_pandas(df, npartitions=npartitions)\r\n    \r\n    gbCol = 'make'\r\n    for g in dd[gbCol].unique().compute():\r\n        dd.groupby(gbCol).get_group(g).min(numeric_only=True).compute()\r\n    return\r\n\r\nchecker(npartitions=2, toCategory=True)  # doesnt work, KeyError: 'a', 2 partitions\r\nchecker(npartitions=2, toCategory=False) # works\r\nchecker(npartitions=1, toCategory=True)  # works, only 1 partition\r\nchecker(npartitions=1, toCategory=False) # works\r\n````\r\n**Traceback**:\r\n````python-traceback\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\User1\\AppData\\Local\\Temp\\ipykernel_5608\\2821702366.py\", line 18, in <cell line: 18>\r\n    checker(npartitions=2, toCategory=True)  # doesnt work, KeyError: 'a', 2 partitions\r\n\r\n  File \"C:\\Users\\User1\\AppData\\Local\\Temp\\ipykernel_5608\\2821702366.py\", line 15, in checker\r\n    dd.groupby(gbCol).get_group(g).min(numeric_only=True).compute() #get their associated group which is dataframe type\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\base.py\", line 315, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\base.py\", line 598, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\threaded.py\", line 89, in get\r\n    results = get_async(\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\local.py\", line 511, in get_async\r\n    raise_exception(exc, tb)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\local.py\", line 319, in reraise\r\n    raise exc\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\local.py\", line 224, in execute_task\r\n    result = _execute_task(task, data)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\optimization.py\", line 990, in __call__\r\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\core.py\", line 149, in get\r\n    result = _execute_task(task, cache)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\core.py\", line 119, in <genexpr>\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\core.py\", line 113, in _execute_task\r\n    return [_execute_task(a, cache) for a in arg]\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\core.py\", line 113, in <listcomp>\r\n    return [_execute_task(a, cache) for a in arg]\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\core.py\", line 119, in <genexpr>\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\core.py\", line 113, in _execute_task\r\n    return [_execute_task(a, cache) for a in arg]\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\core.py\", line 113, in <listcomp>\r\n    return [_execute_task(a, cache) for a in arg]\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\utils.py\", line 71, in apply\r\n    return func(*args, **kwargs)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\dataframe\\core.py\", line 6650, in apply_and_enforce\r\n    df = func(*args, **kwargs)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\dask\\dataframe\\groupby.py\", line 239, in _groupby_get_group\r\n    return grouped.get_group(get_key)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\env3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 747, in get_group\r\n    raise KeyError(name)\r\n\r\nKeyError: 'a'\r\n````\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.8.0\r\n- Python version: 3.10\r\n- Operating System: Windows 10\r\n- Install method (conda, pip, source): conda", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9359/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9359/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9349", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9349/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9349/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9349/events", "html_url": "https://github.com/dask/dask/pull/9349", "id": 1327664765, "node_id": "PR_kwDOAbcwm848ma3f", "number": 9349, "title": "Fix bag sampling when there are some smaller partitions", "user": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862273, "node_id": "MDU6TGFiZWwyNDI4NjIyNzM=", "url": "https://api.github.com/repos/dask/dask/labels/bag", "name": "bag", "color": "0052cc", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-08-03T19:06:36Z", "updated_at": "2022-08-09T13:59:04Z", "closed_at": "2022-08-09T13:59:04Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/9349", "html_url": "https://github.com/dask/dask/pull/9349", "diff_url": "https://github.com/dask/dask/pull/9349.diff", "patch_url": "https://github.com/dask/dask/pull/9349.patch", "merged_at": "2022-08-09T13:59:04Z"}, "body": "Fixes the rest of #9249. Currently, if you have some imbalanced partitions in a bag such that some of them are small, and then sample from that bag with a `k` larger than those partitions, you can run into the error in #9249. The error message isn't correct in that case.\r\n\r\nI still need to write some tests and also sit down with a pencil and paper to convince myself and others that this doesn't bias the sampling, so marking as a draft until I can get around to that.\r\n\r\n- [x] Closes #9249\r\n- [x] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9349/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9349/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/9339", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9339/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9339/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9339/events", "html_url": "https://github.com/dask/dask/issues/9339", "id": 1326022226, "node_id": "I_kwDOAbcwm85PCX5S", "number": 9339, "title": "`ddf.set_index` with `sorted=True` drops rows", "user": {"login": "jsignell", "id": 4806877, "node_id": "MDQ6VXNlcjQ4MDY4Nzc=", "avatar_url": "https://avatars.githubusercontent.com/u/4806877?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsignell", "html_url": "https://github.com/jsignell", "followers_url": "https://api.github.com/users/jsignell/followers", "following_url": "https://api.github.com/users/jsignell/following{/other_user}", "gists_url": "https://api.github.com/users/jsignell/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsignell/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsignell/subscriptions", "organizations_url": "https://api.github.com/users/jsignell/orgs", "repos_url": "https://api.github.com/users/jsignell/repos", "events_url": "https://api.github.com/users/jsignell/events{/privacy}", "received_events_url": "https://api.github.com/users/jsignell/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-08-02T15:26:26Z", "updated_at": "2022-09-15T20:27:58Z", "closed_at": "2022-09-15T20:27:58Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Hi. I see the same issue, but I don't have empty partitions. Can someone explain why I lost records after `set_index`?\r\n```\r\ndf = pd.DataFrame({\r\n    'ts': [1, 1, 2, 2, 3, 3, 3, 3],\r\n    'value': 'abc'\r\n})\r\nddf = dd.from_pandas(df, npartitions=3)\r\nddf = ddf.set_index('ts', sorted=True)\r\nprint(ddf.compute())\r\n```\r\n```\r\n   value\r\nts      \r\n1    abc\r\n1    abc\r\n2    abc\r\n2    abc\r\n3    abc\r\n3    abc\r\n```\r\nDask: 2022.5.0\r\nPython: 3.10.4\r\nOS: macOS Monterey 12.1\r\nInstall method: pip\r\n\r\n_Originally posted by @vdytyniak-exos in https://github.com/dask/dask/issues/8735#issuecomment-1185587580_", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9339/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 1, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9339/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9328", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9328/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9328/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9328/events", "html_url": "https://github.com/dask/dask/issues/9328", "id": 1321129734, "node_id": "I_kwDOAbcwm85OvtcG", "number": 9328, "title": "Writing to parquet with `.set_index(\"col\", drop=False)` yields: `ValueError(f\"cannot insert {column}, already exists\")`", "user": {"login": "asmith26", "id": 6988036, "node_id": "MDQ6VXNlcjY5ODgwMzY=", "avatar_url": "https://avatars.githubusercontent.com/u/6988036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asmith26", "html_url": "https://github.com/asmith26", "followers_url": "https://api.github.com/users/asmith26/followers", "following_url": "https://api.github.com/users/asmith26/following{/other_user}", "gists_url": "https://api.github.com/users/asmith26/gists{/gist_id}", "starred_url": "https://api.github.com/users/asmith26/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asmith26/subscriptions", "organizations_url": "https://api.github.com/users/asmith26/orgs", "repos_url": "https://api.github.com/users/asmith26/repos", "events_url": "https://api.github.com/users/asmith26/events{/privacy}", "received_events_url": "https://api.github.com/users/asmith26/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2022-07-28T15:30:01Z", "updated_at": "2022-07-28T18:47:01Z", "closed_at": "2022-07-28T18:47:01Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**What happened**:\r\nWriting to parquet with `.set_index(\"col\", drop=False)` yields: `ValueError(f\"cannot insert {column}, already exists\")`. Interestingly when `drop=True` it works.\r\n\r\n**What you expected to happen**:\r\nI thought I would be able to set_index with `drop=False`.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\n\r\n(dd.from_pandas(pd.DataFrame({\"Idx\": list(range(10))}), npartitions=1)\r\n .set_index(\"Idx\", drop=False)\r\n .to_parquet(\"ddf.parquet\"))\r\n```\r\n\r\n**Anything else we need to know?**:\r\nThanks for any help! :)\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.7.1  \r\n- Python version: 3.10.4\r\n- Operating System: Ubuntu\r\n- Install method (conda, pip, source): mamba", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9328/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9328/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9324", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9324/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9324/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9324/events", "html_url": "https://github.com/dask/dask/issues/9324", "id": 1320049704, "node_id": "I_kwDOAbcwm85Orlwo", "number": 9324, "title": "`delayed` can't handle some `dataclasses` as inputs", "user": {"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1968982461, "node_id": "MDU6TGFiZWwxOTY4OTgyNDYx", "url": "https://api.github.com/repos/dask/dask/labels/delayed", "name": "delayed", "color": "4f6edd", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "hendrikmakait", "id": 2699097, "node_id": "MDQ6VXNlcjI2OTkwOTc=", "avatar_url": "https://avatars.githubusercontent.com/u/2699097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hendrikmakait", "html_url": "https://github.com/hendrikmakait", "followers_url": "https://api.github.com/users/hendrikmakait/followers", "following_url": "https://api.github.com/users/hendrikmakait/following{/other_user}", "gists_url": "https://api.github.com/users/hendrikmakait/gists{/gist_id}", "starred_url": "https://api.github.com/users/hendrikmakait/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hendrikmakait/subscriptions", "organizations_url": "https://api.github.com/users/hendrikmakait/orgs", "repos_url": "https://api.github.com/users/hendrikmakait/repos", "events_url": "https://api.github.com/users/hendrikmakait/events{/privacy}", "received_events_url": "https://api.github.com/users/hendrikmakait/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "hendrikmakait", "id": 2699097, "node_id": "MDQ6VXNlcjI2OTkwOTc=", "avatar_url": "https://avatars.githubusercontent.com/u/2699097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hendrikmakait", "html_url": "https://github.com/hendrikmakait", "followers_url": "https://api.github.com/users/hendrikmakait/followers", "following_url": "https://api.github.com/users/hendrikmakait/following{/other_user}", "gists_url": "https://api.github.com/users/hendrikmakait/gists{/gist_id}", "starred_url": "https://api.github.com/users/hendrikmakait/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hendrikmakait/subscriptions", "organizations_url": "https://api.github.com/users/hendrikmakait/orgs", "repos_url": "https://api.github.com/users/hendrikmakait/repos", "events_url": "https://api.github.com/users/hendrikmakait/events{/privacy}", "received_events_url": "https://api.github.com/users/hendrikmakait/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2022-07-27T19:44:45Z", "updated_at": "2022-08-09T18:46:22Z", "closed_at": "2022-08-09T18:46:21Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Someone reported offline that the following snippet fails:\r\n\r\n```python\r\nfrom dask import delayed\r\nfrom dataclasses import dataclass\r\n\r\n@delayed\r\ndef noop(x):\r\n    return x\r\n\r\n\r\n@dataclass\r\nclass MyDataClass:\r\n    arg1: int\r\n    def __init__(self, arg):\r\n        self.arg1 = arg\r\n\r\nd = noop(MyDataClass(1))\r\nd.compute()\r\n```\r\n\r\nwith this traceback:\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/Users/james/projects/dask/dask/test.py\", line 16, in <module>\r\n    d.compute()\r\n  File \"/Users/james/projects/dask/dask/dask/base.py\", line 315, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/Users/james/projects/dask/dask/dask/base.py\", line 598, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/Users/james/projects/dask/dask/dask/threaded.py\", line 89, in get\r\n    results = get_async(\r\n  File \"/Users/james/projects/dask/dask/dask/local.py\", line 511, in get_async\r\n    raise_exception(exc, tb)\r\n  File \"/Users/james/projects/dask/dask/dask/local.py\", line 319, in reraise\r\n    raise exc\r\n  File \"/Users/james/projects/dask/dask/dask/local.py\", line 224, in execute_task\r\n    result = _execute_task(task, data)\r\n  File \"/Users/james/projects/dask/dask/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/Users/james/projects/dask/dask/dask/core.py\", line 119, in <genexpr>\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/Users/james/projects/dask/dask/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/Users/james/projects/dask/dask/dask/utils.py\", line 41, in apply\r\n    return func(*args, **kwargs)\r\nTypeError: MyDataClass.__init__() got an unexpected keyword argument 'arg1'\r\n```\r\n\r\nI've not looked deeply into this yet, but after quickly skimming it looks like this section of code \r\n\r\nhttps://github.com/dask/dask/blob/335882ef60f646c3aeb9234c431a6e1a87224eed/dask/delayed.py#L113-L122\r\n\r\nif where this start to go awry", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9324/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9324/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9315", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9315/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9315/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9315/events", "html_url": "https://github.com/dask/dask/issues/9315", "id": 1318987161, "node_id": "I_kwDOAbcwm85OniWZ", "number": 9315, "title": "Simple `cumsum` code is failing for CuPy.", "user": {"login": "jcfaracco", "id": 1130815, "node_id": "MDQ6VXNlcjExMzA4MTU=", "avatar_url": "https://avatars.githubusercontent.com/u/1130815?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jcfaracco", "html_url": "https://github.com/jcfaracco", "followers_url": "https://api.github.com/users/jcfaracco/followers", "following_url": "https://api.github.com/users/jcfaracco/following{/other_user}", "gists_url": "https://api.github.com/users/jcfaracco/gists{/gist_id}", "starred_url": "https://api.github.com/users/jcfaracco/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jcfaracco/subscriptions", "organizations_url": "https://api.github.com/users/jcfaracco/orgs", "repos_url": "https://api.github.com/users/jcfaracco/repos", "events_url": "https://api.github.com/users/jcfaracco/events{/privacy}", "received_events_url": "https://api.github.com/users/jcfaracco/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-07-27T03:57:55Z", "updated_at": "2022-08-03T14:57:10Z", "closed_at": "2022-08-03T14:57:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\n\r\nA simple code using Dask's `cumsum` function is throwing an issue if the input array is CuPy.\r\n\r\n**What you expected to happen**:\r\n\r\nA simple code should work fine for Dask.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport cupy as cp\r\nimport dask.array as da\r\n\r\nA = cp.array([[1,2,3], [4,5,6]])\r\n\r\nDA = da.from_array(A, chunks=(1, 1))\r\n\r\nDAC = DA.cumsum(axis=0)\r\n\r\nDAC.compute()\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nThis is the error below after executing the code above:\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/tmp/test_cumsum.py\", line 10, in <module>\r\n    DAC.compute()\r\n  File \"/root/micromamba/envs/dasf/lib/python3.9/site-packages/dask/base.py\", line 312, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/root/micromamba/envs/dasf/lib/python3.9/site-packages/dask/base.py\", line 600, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/root/micromamba/envs/dasf/lib/python3.9/site-packages/dask/threaded.py\", line 81, in get\r\n    results = get_async(\r\n  File \"/root/micromamba/envs/dasf/lib/python3.9/site-packages/dask/local.py\", line 508, in get_async\r\n    raise_exception(exc, tb)\r\n  File \"/root/micromamba/envs/dasf/lib/python3.9/site-packages/dask/local.py\", line 316, in reraise\r\n    raise exc\r\n  File \"/root/micromamba/envs/dasf/lib/python3.9/site-packages/dask/local.py\", line 221, in execute_task\r\n    result = _execute_task(task, data)\r\n  File \"/root/micromamba/envs/dasf/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/root/micromamba/envs/dasf/lib/python3.9/site-packages/dask/array/reductions.py\", line 1507, in _cumsum_merge\r\n    return a + b\r\n  File \"cupy/_core/core.pyx\", line 1591, in cupy._core.core.ndarray.__array_ufunc__\r\n  File \"cupy/_core/_kernel.pyx\", line 1218, in cupy._core._kernel.ufunc.__call__\r\n  File \"cupy/_core/_kernel.pyx\", line 138, in cupy._core._kernel._preprocess_args\r\n  File \"cupy/_core/_kernel.pyx\", line 124, in cupy._core._kernel._preprocess_arg\r\nTypeError: Unsupported type <class 'numpy.ndarray'>\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.5.2\r\n- Python version: 3.9.13\r\n- CuPy version: 10.6.0\r\n- Operating System: Ubuntu 20.04\r\n- Install method (conda, pip, source): miniconda (see the error output)", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9315/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9315/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9313", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9313/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9313/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9313/events", "html_url": "https://github.com/dask/dask/issues/9313", "id": 1318463960, "node_id": "I_kwDOAbcwm85OlinY", "number": 9313, "title": "`cumsum` results differ from pandas for series groupbys", "user": {"login": "brandon-b-miller", "id": 53796099, "node_id": "MDQ6VXNlcjUzNzk2MDk5", "avatar_url": "https://avatars.githubusercontent.com/u/53796099?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brandon-b-miller", "html_url": "https://github.com/brandon-b-miller", "followers_url": "https://api.github.com/users/brandon-b-miller/followers", "following_url": "https://api.github.com/users/brandon-b-miller/following{/other_user}", "gists_url": "https://api.github.com/users/brandon-b-miller/gists{/gist_id}", "starred_url": "https://api.github.com/users/brandon-b-miller/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brandon-b-miller/subscriptions", "organizations_url": "https://api.github.com/users/brandon-b-miller/orgs", "repos_url": "https://api.github.com/users/brandon-b-miller/repos", "events_url": "https://api.github.com/users/brandon-b-miller/events{/privacy}", "received_events_url": "https://api.github.com/users/brandon-b-miller/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2022-07-26T16:09:06Z", "updated_at": "2022-12-02T22:48:54Z", "closed_at": "2022-09-02T00:38:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**What happened**:\r\nI noticed that taking the cumulative sum of a pandas series groupby and an equivalent dask series groupby returns numerically different results.\r\n\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\nimport dask.dataframe as dd\r\n\r\nnp.random.seed(0)\r\nsize=10\r\nnpartitions=2\r\n\r\n\r\npdf = pd.DataFrame(\r\n    {\r\n        \"xx\": np.random.randint(0, 5, size=size),\r\n        \"x\": np.random.normal(size=size),\r\n        \"y\": np.random.normal(size=size),\r\n    }\r\n)\r\n\r\nddf = dd.from_pandas(pdf, npartitions=npartitions)\r\n\r\npdf_grouped = pdf.groupby('xx').xx\r\nddf_grouped = ddf.groupby('xx').xx\r\n\r\nprint(pdf_grouped.cumsum())\r\nprint(ddf_grouped.cumsum().compute())\r\n\r\n```\r\n```\r\n0     4\r\n1     0\r\n2     3\r\n3     6\r\n4     9\r\n5     1\r\n6    12\r\n7     2\r\n8     8\r\n9     0\r\nName: xx, dtype: int64\r\n0    4\r\n1    0\r\n2    3\r\n3    6\r\n4    9\r\n5    1\r\n6    6\r\n7    2\r\n8    8\r\n9    0\r\nName: xx, dtype: int64\r\n```\r\n\r\n\r\n**Anything else we need to know?**:\r\nI get the right results when `npartitions=1.` \r\n\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.7.0+16.gedfa91e22\r\n- Python version: 3.9.13 \r\n- Operating System: Ubuntu 18.04.6 LTS\r\n- Install method: conda", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9313/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9313/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9301", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9301/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9301/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9301/events", "html_url": "https://github.com/dask/dask/issues/9301", "id": 1315703894, "node_id": "I_kwDOAbcwm85ObAxW", "number": 9301, "title": "Mask preserving *_like functions", "user": {"login": "rcomer", "id": 10599679, "node_id": "MDQ6VXNlcjEwNTk5Njc5", "avatar_url": "https://avatars.githubusercontent.com/u/10599679?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rcomer", "html_url": "https://github.com/rcomer", "followers_url": "https://api.github.com/users/rcomer/followers", "following_url": "https://api.github.com/users/rcomer/following{/other_user}", "gists_url": "https://api.github.com/users/rcomer/gists{/gist_id}", "starred_url": "https://api.github.com/users/rcomer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rcomer/subscriptions", "organizations_url": "https://api.github.com/users/rcomer/orgs", "repos_url": "https://api.github.com/users/rcomer/repos", "events_url": "https://api.github.com/users/rcomer/events{/privacy}", "received_events_url": "https://api.github.com/users/rcomer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-07-23T17:07:25Z", "updated_at": "2022-08-17T13:46:07Z", "closed_at": "2022-08-17T13:46:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- Please do a quick search of existing issues to make sure that this has not been asked before. -->\r\nIt would be useful to have versions of `ones_like`, `zeros_like` and `empty_like` that preserve masks when applied to masked dask arrays.  Currently (version 2022.7.1) we have\r\n\r\n```python\r\nimport dask.array as da\r\n\r\narray = da.ma.masked_array([2, 3, 4], mask=[0, 0, 1])\r\nprint(da.ones_like(array).compute())\r\n```\r\n```\r\n[1 1 1]\r\n```\r\nwhereas numpy's version preserves the mask\r\n```python\r\nimport numpy as np\r\n\r\nprint(np.ones_like(array.compute()))\r\n```\r\n```\r\n[1 1 --]\r\n```\r\n\r\nI notice there are several functions in `dask.array.ma` that just apply `map_blocks` to the `numpy.ma` version of the function.  So perhaps the simplest thing would be to implement `dask.array.ma.ones_like`, etc. that way.  If it really is that simple, I'd be happy to open a PR.", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9301/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9301/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9291", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9291/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9291/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9291/events", "html_url": "https://github.com/dask/dask/issues/9291", "id": 1309491462, "node_id": "I_kwDOAbcwm85ODUEG", "number": 9291, "title": "Exception while providing a categorical dictionary meta", "user": {"login": "epizut", "id": 1694892, "node_id": "MDQ6VXNlcjE2OTQ4OTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1694892?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epizut", "html_url": "https://github.com/epizut", "followers_url": "https://api.github.com/users/epizut/followers", "following_url": "https://api.github.com/users/epizut/following{/other_user}", "gists_url": "https://api.github.com/users/epizut/gists{/gist_id}", "starred_url": "https://api.github.com/users/epizut/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epizut/subscriptions", "organizations_url": "https://api.github.com/users/epizut/orgs", "repos_url": "https://api.github.com/users/epizut/repos", "events_url": "https://api.github.com/users/epizut/events{/privacy}", "received_events_url": "https://api.github.com/users/epizut/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2022-07-19T13:03:57Z", "updated_at": "2022-08-12T08:08:38Z", "closed_at": "2022-08-12T03:20:51Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "There is an exception when forcing *name* to be an unknown category instead of a string object dtype.\r\n\r\n```python\r\nimport dask\r\ndd = dask.datasets.timeseries()\r\ndd = dd.map_partitions(lambda part: part, meta={'id': 'int32', 'name': 'str', 'x': 'float64', 'y': 'float64'})      # Ok\r\ndd = dd.map_partitions(lambda part: part, meta={'id': 'int32', 'name': 'category', 'x': 'float64', 'y': 'float64'}) # Raise\r\n```\r\n![image](https://user-images.githubusercontent.com/1694892/179756928-b7e9b03a-1863-48e4-9fbb-805c613cec72.png)\r\n\r\n\r\n\r\n**Environment**:\r\n\r\n- Dask version:  2022.7.0\r\n- Python version: 3.9\r\n- Operating System: Window 10\r\n- Install method (conda, pip, source): pip\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9291/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9291/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9286", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9286/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9286/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9286/events", "html_url": "https://github.com/dask/dask/issues/9286", "id": 1307496201, "node_id": "I_kwDOAbcwm85N7s8J", "number": 9286, "title": "Memory usage TypeError with Index", "user": {"login": "SrSoto", "id": 32357712, "node_id": "MDQ6VXNlcjMyMzU3NzEy", "avatar_url": "https://avatars.githubusercontent.com/u/32357712?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SrSoto", "html_url": "https://github.com/SrSoto", "followers_url": "https://api.github.com/users/SrSoto/followers", "following_url": "https://api.github.com/users/SrSoto/following{/other_user}", "gists_url": "https://api.github.com/users/SrSoto/gists{/gist_id}", "starred_url": "https://api.github.com/users/SrSoto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SrSoto/subscriptions", "organizations_url": "https://api.github.com/users/SrSoto/orgs", "repos_url": "https://api.github.com/users/SrSoto/repos", "events_url": "https://api.github.com/users/SrSoto/events{/privacy}", "received_events_url": "https://api.github.com/users/SrSoto/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-07-18T07:04:45Z", "updated_at": "2022-07-26T14:22:36Z", "closed_at": "2022-07-26T14:22:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "Dask's `memory_usage` function is giving a `TypeError` depending on the order we call `compute` and `memory_usage`. I am concerned this function is rarely of direct usage, but we were doing some tests with Dask's `sizeof` function and metrics of managed and unmanaged memory (we are spotting some differences between estimated sizes that I'll give report soon)\r\n\r\nThe following MCVE tries to compare `memory_usage` call before and after callling `compute` but fails on Dask case.\r\n\r\n```python\r\nimport pandas as pd\r\nfrom dask.dataframe import from_pandas\r\nser = pd.Series([f\"2020-01-{i}\" for i in range(1,10)])\r\nser_ts = ser.astype(\"datetime64[ns]\")\r\ndf = pd.DataFrame({'a': ser, 'b': ser_ts}).set_index('b')\r\nddf = from_pandas(df, npartitions=2)\r\nprint(\"-- memory_usage on Pandas DataFrame --\")\r\nprint(ddf.compute().memory_usage())\r\nprint(\"-- memory_usage on Dask DataFrame --\")\r\nprint(ddf.memory_usage().compute())\r\nprint(\"-- memory_usage on Pandas Index --\")\r\nprint(ddf.compute().index.memory_usage())\r\nprint(\"-- memory_usage on Dask Index --\")\r\nprint(ddf.index.memory_usage().compute())\r\n```\r\n\r\nExecuting this code leads to the following exception:\r\n\r\n```python\r\nTypeError: memory_usage() got an unexpected keyword argument 'index'\r\n```\r\n\r\n<details>\r\n<summary>Full traceback</summary>\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n~/anaconda3/envs/3.9testing/lib/python3.9/site-packages/dask/dataframe/utils.py in raise_on_meta_error(funcname, udf)\r\n    181     try:\r\n--> 182         yield\r\n    183     except Exception as e:\r\n\r\n~/anaconda3/envs/3.9testing/lib/python3.9/site-packages/dask/dataframe/core.py in _emulate(func, udf, *args, **kwargs)\r\n   6348     with raise_on_meta_error(funcname(func), udf=udf):\r\n-> 6349         return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n   6350 \r\n\r\n~/anaconda3/envs/3.9testing/lib/python3.9/site-packages/dask/utils.py in __call__(self, _methodcaller__obj, *args, **kwargs)\r\n   1052     def __call__(self, __obj, *args, **kwargs):\r\n-> 1053         return getattr(__obj, self.method)(*args, **kwargs)\r\n   1054 \r\n\r\nTypeError: memory_usage() got an unexpected keyword argument 'index'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-46-8a9d393d6d85> in <module>\r\n     12 print(ddf.compute().index.memory_usage())\r\n     13 print(\"-- memory_usage on Dask Index --\")\r\n---> 14 print(ddf.index.memory_usage().compute())\r\n\r\n~/anaconda3/envs/3.9testing/lib/python3.9/site-packages/dask/dataframe/core.py in memory_usage(self, index, deep)\r\n   3990     @derived_from(pd.Series)\r\n   3991     def memory_usage(self, index=True, deep=False):\r\n-> 3992         result = self.map_partitions(\r\n   3993             M.memory_usage, index=index, deep=deep, enforce_metadata=False\r\n   3994         )\r\n\r\n~/anaconda3/envs/3.9testing/lib/python3.9/site-packages/dask/dataframe/core.py in map_partitions(self, func, *args, **kwargs)\r\n    855         None as the division.\r\n    856         \"\"\"\r\n--> 857         return map_partitions(func, self, *args, **kwargs)\r\n    858 \r\n    859     @insert_meta_param_description(pad=12)\r\n\r\n~/anaconda3/envs/3.9testing/lib/python3.9/site-packages/dask/dataframe/core.py in map_partitions(func, meta, enforce_metadata, transform_divisions, align_dataframes, *args, **kwargs)\r\n   6422         # Use non-normalized kwargs here, as we want the real values (not\r\n   6423         # delayed values)\r\n-> 6424         meta = _emulate(func, *args, udf=True, **kwargs)\r\n   6425         meta_is_emulated = True\r\n   6426     else:\r\n\r\n~/anaconda3/envs/3.9testing/lib/python3.9/site-packages/dask/dataframe/core.py in _emulate(func, udf, *args, **kwargs)\r\n   6347     \"\"\"\r\n   6348     with raise_on_meta_error(funcname(func), udf=udf):\r\n-> 6349         return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n   6350 \r\n   6351 \r\n\r\n~/anaconda3/envs/3.9testing/lib/python3.9/contextlib.py in __exit__(self, typ, value, traceback)\r\n    135                 value = typ()\r\n    136             try:\r\n--> 137                 self.gen.throw(typ, value, traceback)\r\n    138             except StopIteration as exc:\r\n    139                 # Suppress StopIteration *unless* it's the same exception that\r\n\r\n~/anaconda3/envs/3.9testing/lib/python3.9/site-packages/dask/dataframe/utils.py in raise_on_meta_error(funcname, udf)\r\n    201         )\r\n    202         msg = msg.format(f\" in `{funcname}`\" if funcname else \"\", repr(e), tb)\r\n--> 203         raise ValueError(msg) from e\r\n    204 \r\n    205 \r\n\r\nValueError: Metadata inference failed in `memory_usage`.\r\n\r\nYou have supplied a custom function and Dask is unable to \r\ndetermine the type of output that that function returns. \r\n\r\nTo resolve this please provide a meta= keyword.\r\nThe docstring of the Dask function you ran should have more information.\r\n\r\nOriginal error is below:\r\n------------------------\r\nTypeError(\"memory_usage() got an unexpected keyword argument 'index'\")\r\n\r\nTraceback:\r\n---------\r\n  File \"/home/manuel.soto/anaconda3/envs/3.9testing/lib/python3.9/site-packages/dask/dataframe/utils.py\", line 182, in raise_on_meta_error\r\n    yield\r\n  File \"/home/manuel.soto/anaconda3/envs/3.9testing/lib/python3.9/site-packages/dask/dataframe/core.py\", line 6349, in _emulate\r\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n  File \"/home/manuel.soto/anaconda3/envs/3.9testing/lib/python3.9/site-packages/dask/utils.py\", line 1053, in __call__\r\n    return getattr(__obj, self.method)(*args, **kwargs)\r\n```\r\n</details>\r\n\r\n\r\nStudying `memory_usage` code, it is possible that this problem is caused by an incorrect delegation of this method, calling the function of `memory_usage` from a `Series` instead of an `Index`, as the `index` argument has no sense in the second case (this may be because of the `MethodCache` calling the incorrect found function).\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.6.0\r\n- Python version: 3.9.7\r\n- Operating System: Ubuntu 21.04\r\n- Install method (conda, pip, source): pip\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9286/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9286/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9279", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9279/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9279/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9279/events", "html_url": "https://github.com/dask/dask/issues/9279", "id": 1306218290, "node_id": "I_kwDOAbcwm85N208y", "number": 9279, "title": "Config widget broken?", "user": {"login": "mrocklin", "id": 306380, "node_id": "MDQ6VXNlcjMwNjM4MA==", "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrocklin", "html_url": "https://github.com/mrocklin", "followers_url": "https://api.github.com/users/mrocklin/followers", "following_url": "https://api.github.com/users/mrocklin/following{/other_user}", "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions", "organizations_url": "https://api.github.com/users/mrocklin/orgs", "repos_url": "https://api.github.com/users/mrocklin/repos", "events_url": "https://api.github.com/users/mrocklin/events{/privacy}", "received_events_url": "https://api.github.com/users/mrocklin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386719598, "node_id": "MDU6TGFiZWwzODY3MTk1OTg=", "url": "https://api.github.com/repos/dask/dask/labels/documentation", "name": "documentation", "color": "f9d0c4", "default": true, "description": "Improve or add to documentation"}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-07-15T16:16:31Z", "updated_at": "2022-07-26T14:27:22Z", "closed_at": "2022-07-26T14:27:22Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "![image](https://user-images.githubusercontent.com/306380/179264604-82d25c7b-f612-4a5c-8458-68993dc00229.png)\r\n\r\ncc @jacobtomlinson @scharlottej13 ", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9279/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9279/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9258", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9258/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9258/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9258/events", "html_url": "https://github.com/dask/dask/issues/9258", "id": 1300523391, "node_id": "I_kwDOAbcwm85NhGl_", "number": 9258, "title": "get_dummies error: order of columns does not match", "user": {"login": "lodo1995", "id": 13088092, "node_id": "MDQ6VXNlcjEzMDg4MDky", "avatar_url": "https://avatars.githubusercontent.com/u/13088092?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lodo1995", "html_url": "https://github.com/lodo1995", "followers_url": "https://api.github.com/users/lodo1995/followers", "following_url": "https://api.github.com/users/lodo1995/following{/other_user}", "gists_url": "https://api.github.com/users/lodo1995/gists{/gist_id}", "starred_url": "https://api.github.com/users/lodo1995/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lodo1995/subscriptions", "organizations_url": "https://api.github.com/users/lodo1995/orgs", "repos_url": "https://api.github.com/users/lodo1995/repos", "events_url": "https://api.github.com/users/lodo1995/events{/privacy}", "received_events_url": "https://api.github.com/users/lodo1995/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, {"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2022-07-11T10:37:23Z", "updated_at": "2022-07-19T20:04:06Z", "closed_at": "2022-07-19T20:04:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What happened**:\r\nWhen applying `categorize` and then `get_dummies` to columns that originally had a numerical data type, in some cases `get_dummies` fails with\r\n```\r\nValueError: The columns in the computed data do not match the columns in the provided metadata\r\nOrder of columns does not match\r\n```\r\n\r\nI could not find the exact pattern behind these failures (happens on real-world data only on some columns, with no clear pattern), but I managed to produce a tiny example that exhibits the issue.\r\n\r\n**What you expected to happen**:\r\n`get_dummies` works without exceptions.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n\r\ndata = pd.DataFrame(data={\r\n    'a': [0.0, 0.0, 1.0, 1.0, 0.0],\r\n    'b': [1.0, 0.0, 1.0, 0.0, 1.0]\r\n})\r\n\r\ndata = dd.from_pandas(data, npartitions=2)\r\n\r\nCAT = ['a', 'b']\r\ndata[CAT] = data[CAT].categorize(CAT)\r\n\r\ndd.get_dummies(data[CAT]).compute()\r\n```\r\n\r\n**Traceback**:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<redacted>/src/test_dd.py\", line 16, in <module>\r\n    dd.get_dummies(data[CAT]).compute()\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/base.py\", line 292, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/base.py\", line 575, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/threaded.py\", line 81, in get\r\n    results = get_async(\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/local.py\", line 508, in get_async\r\n    raise_exception(exc, tb)\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/local.py\", line 316, in reraise\r\n    raise exc\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/local.py\", line 221, in execute_task\r\n    result = _execute_task(task, data)\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/optimization.py\", line 990, in __call__\r\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/core.py\", line 149, in get\r\n    result = _execute_task(task, cache)\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/utils.py\", line 40, in apply\r\n    return func(*args, **kwargs)\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/dataframe/core.py\", line 6436, in apply_and_enforce\r\n    check_matching_columns(meta, df)\r\n  File \"<redacted>/lib/python3.9/site-packages/dask/dataframe/utils.py\", line 415, in check_matching_columns\r\n    raise ValueError(\r\nValueError: The columns in the computed data do not match the columns in the provided metadata\r\nOrder of columns does not match\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.05.00\r\n- Python version: 3.9.12\r\n- Operating System: Ubuntu 20.04\r\n- Install method (conda, pip, source): conda", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9258/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9258/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9252", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9252/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9252/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9252/events", "html_url": "https://github.com/dask/dask/pull/9252", "id": 1297786107, "node_id": "PR_kwDOAbcwm847CpwJ", "number": 9252, "title": "Fix bug when filtering on partitioned column with pyarrow", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-07-07T17:05:09Z", "updated_at": "2022-07-12T22:10:54Z", "closed_at": "2022-07-12T21:42:10Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/9252", "html_url": "https://github.com/dask/dask/pull/9252", "diff_url": "https://github.com/dask/dask/pull/9252.diff", "patch_url": "https://github.com/dask/dask/pull/9252.patch", "merged_at": "2022-07-12T21:42:09Z"}, "body": "- [x] Closes #9246\r\n- [x] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n\r\nAdds test coverage for filtering on a partitioned column, and fixes #9246", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9252/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9252/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/9249", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9249/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9249/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9249/events", "html_url": "https://github.com/dask/dask/issues/9249", "id": 1297105645, "node_id": "I_kwDOAbcwm85NUELt", "number": 9249, "title": "`dask.bag.random.sample` throws various errors", "user": {"login": "MaximLippeveld", "id": 8209122, "node_id": "MDQ6VXNlcjgyMDkxMjI=", "avatar_url": "https://avatars.githubusercontent.com/u/8209122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MaximLippeveld", "html_url": "https://github.com/MaximLippeveld", "followers_url": "https://api.github.com/users/MaximLippeveld/followers", "following_url": "https://api.github.com/users/MaximLippeveld/following{/other_user}", "gists_url": "https://api.github.com/users/MaximLippeveld/gists{/gist_id}", "starred_url": "https://api.github.com/users/MaximLippeveld/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MaximLippeveld/subscriptions", "organizations_url": "https://api.github.com/users/MaximLippeveld/orgs", "repos_url": "https://api.github.com/users/MaximLippeveld/repos", "events_url": "https://api.github.com/users/MaximLippeveld/events{/privacy}", "received_events_url": "https://api.github.com/users/MaximLippeveld/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862273, "node_id": "MDU6TGFiZWwyNDI4NjIyNzM=", "url": "https://api.github.com/repos/dask/dask/labels/bag", "name": "bag", "color": "0052cc", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, {"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2022-07-07T09:39:21Z", "updated_at": "2022-08-09T13:59:05Z", "closed_at": "2022-08-09T13:59:05Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**What happened**: I want to undersample items in a Bag using `dask.bag.random.sample`\r\n\r\n**What you expected to happen**: Receive a Bag with specified amount of items.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.bag\r\nfrom dask.bag import random\r\n\r\n\r\ndef main():\r\n\r\n    bag = dask.bag.range(n=100, npartitions=10)\r\n    bag2 = random.sample(bag, k=10)\r\n    bag2.compute() # throws ValueError: too many values to unpack (expected 2)\r\n\r\n    bag = dask.bag.range(n=10, npartitions=10)\r\n    bag2 = random.sample(bag, k=3)\r\n    bag2.compute() # throws ValueError: Sample larger than population or is negative\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n**Anything else we need to know?**: \r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.6.1\r\n- Python version: 3.9.10\r\n- Operating System: Fedora 34\r\n- Install method (conda, pip, source): pip", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9249/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9249/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9246", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9246/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9246/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9246/events", "html_url": "https://github.com/dask/dask/issues/9246", "id": 1297087407, "node_id": "I_kwDOAbcwm85NT_uv", "number": 9246, "title": "Filters in read_parquet are not working in the latest dask version", "user": {"login": "SultanOrazbayev", "id": 20208402, "node_id": "MDQ6VXNlcjIwMjA4NDAy", "avatar_url": "https://avatars.githubusercontent.com/u/20208402?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SultanOrazbayev", "html_url": "https://github.com/SultanOrazbayev", "followers_url": "https://api.github.com/users/SultanOrazbayev/followers", "following_url": "https://api.github.com/users/SultanOrazbayev/following{/other_user}", "gists_url": "https://api.github.com/users/SultanOrazbayev/gists{/gist_id}", "starred_url": "https://api.github.com/users/SultanOrazbayev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SultanOrazbayev/subscriptions", "organizations_url": "https://api.github.com/users/SultanOrazbayev/orgs", "repos_url": "https://api.github.com/users/SultanOrazbayev/repos", "events_url": "https://api.github.com/users/SultanOrazbayev/events{/privacy}", "received_events_url": "https://api.github.com/users/SultanOrazbayev/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2022-07-07T09:24:17Z", "updated_at": "2022-07-12T21:42:09Z", "closed_at": "2022-07-12T21:42:09Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "While trying to reproduce code from [this answer](https://stackoverflow.com/a/72892141/10693596) with different dask versions I ran into inconsistent behavior.\r\n\r\nConsider this snippet:\r\n\r\n```python\r\nfrom dask.dataframe import read_parquet\r\nfrom dask.datasets import timeseries\r\n\r\ndf = timeseries(end=\"2000-01-03\", seed=0).reset_index()\r\ndf[\"date\"] = df[\"timestamp\"].dt.date.astype(\"str\")\r\ndf.to_parquet(\"test.pqt\", partition_on=[\"id\", \"date\"])\r\nrare_id = df[\"id\"].value_counts().compute().tail(1).index.values[0]\r\n\r\nddf = read_parquet(\"test.pqt\", filters=[[(\"id\", \"==\", rare_id)]], engine=\"pyarrow\")\r\nprint(ddf.npartitions)  # 1 when using environment 2 defined below, but 491 when using environment 1 (latest dask)\r\n```\r\n\r\nEnvironment 1:\r\n\r\n```yaml\r\nname: dask\r\nchannels:\r\n- conda-forge\r\ndependencies:\r\n- python=3.10\r\n- ipykernel=6.4.1\r\n- dask=2022.6.1\r\n- pyarrow=8.0.0\r\n- fastparquet=0.8.1\r\n- pandas=1.4.3\r\n```\r\n\r\nEnvironment 2:\r\n\r\n```yaml\r\nname: dask2\r\nchannels:\r\n- conda-forge\r\ndependencies:\r\n- python=3.10\r\n- ipykernel=6.4.1\r\n- dask=2022.1.0\r\n- pyarrow=8.0.0\r\n- fastparquet=0.8.1\r\n- pandas=1.4.3\r\n```\r\n\r\nJust in case, here's the output of the fancy new `.show_versions()`:\r\n\r\n```python\r\nimport dask\r\n\r\ndask.utils.show_versions()\r\n# {\r\n#   \"Python\": \"3.10.5\",\r\n#   \"Platform\": \"Darwin\",\r\n#   \"dask\": \"2022.6.1\",\r\n#   \"distributed\": \"2022.6.1\",\r\n#   \"numpy\": \"1.23.0\",\r\n#   \"pandas\": \"1.4.3\",\r\n#   \"cloudpickle\": \"2.1.0\",\r\n#   \"fsspec\": \"2022.5.0\",\r\n#   \"bokeh\": \"2.4.3\",\r\n#   \"fastparquet\": \"0.8.1\",\r\n#   \"pyarrow\": \"8.0.0\",\r\n#   \"zarr\": null\r\n# }\r\n```", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9246/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9246/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9238", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9238/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9238/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9238/events", "html_url": "https://github.com/dask/dask/issues/9238", "id": 1293056387, "node_id": "I_kwDOAbcwm85NEnmD", "number": 9238, "title": "The \"dask.array.Array.__reduce__\" method loses the information stored in the \"meta\" attribute. ", "user": {"login": "fbriol", "id": 397386, "node_id": "MDQ6VXNlcjM5NzM4Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/397386?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fbriol", "html_url": "https://github.com/fbriol", "followers_url": "https://api.github.com/users/fbriol/followers", "following_url": "https://api.github.com/users/fbriol/following{/other_user}", "gists_url": "https://api.github.com/users/fbriol/gists{/gist_id}", "starred_url": "https://api.github.com/users/fbriol/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fbriol/subscriptions", "organizations_url": "https://api.github.com/users/fbriol/orgs", "repos_url": "https://api.github.com/users/fbriol/repos", "events_url": "https://api.github.com/users/fbriol/events{/privacy}", "received_events_url": "https://api.github.com/users/fbriol/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-07-04T11:45:29Z", "updated_at": "2022-07-26T15:26:15Z", "closed_at": "2022-07-26T15:26:15Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "```python\r\n\r\nimport dask.array\r\nimport numpy\r\n\r\narr = numpy.arange(10)\r\narr = dask.array.from_array(numpy.ma.MaskedArray(arr, mask=arr % 2 == 0))\r\nassert isinstance(arr._meta, numpy.ma.MaskedArray)\r\nother = pickle.loads(pickle.dumps(arr))\r\nassert isinstance(arr._meta, numpy.ndarray)\r\nnumpy.ma.all(arr.compute() == other.compute())\r\n```\r\n\r\n[dask.array.Array.__reduce__](https://github.com/dask/dask/blob/1a760229fc18c0c7df41669a13a329a287215819/dask/array/core.py#L1378) doesn't propagate ``_meta``.\r\n``_meta`` is [set to numpy.ndarray](https://github.com/dask/dask/blob/1a760229fc18c0c7df41669a13a329a287215819/dask/array/utils.py#L51) because it's None when the object is reconstructed.\r\n\r\nThis behavior implies that it is impossible to determine whether the array is masked before the graph is calculated.\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9238/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9238/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9218", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9218/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9218/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9218/events", "html_url": "https://github.com/dask/dask/issues/9218", "id": 1284406733, "node_id": "I_kwDOAbcwm85Mjn3N", "number": 9218, "title": "Using ddf.from_pandas with chunksize=1 results in one partition having two rows", "user": {"login": "orf", "id": 1027207, "node_id": "MDQ6VXNlcjEwMjcyMDc=", "avatar_url": "https://avatars.githubusercontent.com/u/1027207?v=4", "gravatar_id": "", "url": "https://api.github.com/users/orf", "html_url": "https://github.com/orf", "followers_url": "https://api.github.com/users/orf/followers", "following_url": "https://api.github.com/users/orf/following{/other_user}", "gists_url": "https://api.github.com/users/orf/gists{/gist_id}", "starred_url": "https://api.github.com/users/orf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/orf/subscriptions", "organizations_url": "https://api.github.com/users/orf/orgs", "repos_url": "https://api.github.com/users/orf/repos", "events_url": "https://api.github.com/users/orf/events{/privacy}", "received_events_url": "https://api.github.com/users/orf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-06-25T02:01:46Z", "updated_at": "2022-08-03T21:59:59Z", "closed_at": "2022-08-03T21:59:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What happened**: When creating a ddf using `from_pandas(chunksize=1)` not all partitions have 1 row. The last partition has two rows in it.\r\n\r\n**What you expected to happen**: The dataframe should be evenly split into 10 partitions\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.dataframe as ddf\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nif __name__ == \"__main__\":\r\n    df = pd.DataFrame(np.random.randint(0, 10, size=(10, 4)), columns=list('ABCD'))\r\n    dataset: ddf.DataFrame = ddf.from_pandas(df, chunksize=1).persist()\r\n    # get each partition length\r\n    num_rows = dataset.map_partitions(lambda df: len(df)).compute()\r\n    print(list(num_rows))\r\n```\r\n\r\nResults in \r\n\r\n```\r\n[1, 1, 1, 1, 1, 1, 1, 1, 2]\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.6.1\r\n- Python version: 3.10\r\n- Operating System: MacOS\r\n- Install method (conda, pip, source): Pip", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9218/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9218/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9186", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9186/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9186/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9186/events", "html_url": "https://github.com/dask/dask/issues/9186", "id": 1271072802, "node_id": "I_kwDOAbcwm85Lwwgi", "number": 9186, "title": "to_parquet fails for nullable dtype index", "user": {"login": "bnaul", "id": 903655, "node_id": "MDQ6VXNlcjkwMzY1NQ==", "avatar_url": "https://avatars.githubusercontent.com/u/903655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bnaul", "html_url": "https://github.com/bnaul", "followers_url": "https://api.github.com/users/bnaul/followers", "following_url": "https://api.github.com/users/bnaul/following{/other_user}", "gists_url": "https://api.github.com/users/bnaul/gists{/gist_id}", "starred_url": "https://api.github.com/users/bnaul/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bnaul/subscriptions", "organizations_url": "https://api.github.com/users/bnaul/orgs", "repos_url": "https://api.github.com/users/bnaul/repos", "events_url": "https://api.github.com/users/bnaul/events{/privacy}", "received_events_url": "https://api.github.com/users/bnaul/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 2949860090, "node_id": "MDU6TGFiZWwyOTQ5ODYwMDkw", "url": "https://api.github.com/repos/dask/dask/labels/upstream", "name": "upstream", "color": "DDF8B0", "default": false, "description": ""}, {"id": 3468123446, "node_id": "LA_kwDOAbcwm87Ot102", "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention", "name": "needs attention", "color": "6d626c", "default": false, "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2022-06-14T16:41:15Z", "updated_at": "2022-09-28T14:55:04Z", "closed_at": "2022-09-28T14:55:03Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "`git bisect` traced this back to #9131:\r\n```\r\nimport dask.dataframe as dd, pandas as pd\r\n\r\ndd.from_pandas(pd.DataFrame({\"a\": [1, 2]}, index=pd.Index([\"A\", \"B\"], dtype=\"string\")), npartitions=1).to_parquet(\"/tmp/to_parquet_test/\")\r\n\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-10-d12a786a20e0> in <module>\r\n      1 import dask.dataframe as dd, pandas as pd\r\n----> 2 dd.from_pandas(pd.DataFrame({\"a\": [1, 2]}, index=pd.Index([\"A\", \"B\"], dtype=\"string\")), npartitions=1).to_parquet(\"/tmp/to_parquet_test/\")\r\n\r\n~/model/.venv/lib/python3.9/site-packages/dask/dataframe/core.py in to_parquet(self, path, *args, **kwargs)\r\n\r\n~/model/.venv/lib/python3.9/site-packages/dask/dataframe/io/parquet/core.py in to_parquet(df, path, engine, compression, write_index, append, overwrite, ignore_divisions, partition_on, storage_options, custom_metadata, write_metadata_file, compute, compute_kwargs, schema, name_function, **kwargs)\r\n\r\n~/model/.venv/lib/python3.9/site-packages/dask/dataframe/io/parquet/arrow.py in initialize_write(cls, df, fs, path, append, partition_on, ignore_divisions, division_info, schema, index_cols, **kwargs)\r\n\r\n~/model/.venv/lib/python3.9/site-packages/dask/utils.py in __call__(self, arg, *args, **kwargs)\r\n\r\n~/model/.venv/lib/python3.9/site-packages/dask/dataframe/backends.py in get_pyarrow_schema_pandas(obj)\r\n\r\n~/model/.venv/lib/python3.9/site-packages/pyarrow/types.pxi in pyarrow.lib.Schema.from_pandas()\r\n\r\n~/model/.venv/lib/python3.9/site-packages/pyarrow/pandas_compat.py in dataframe_to_types(df, preserve_index, columns)\r\n    527             type_ = pa.array(c, from_pandas=True).type\r\n    528         elif _pandas_api.is_extension_array_dtype(values):\r\n--> 529             type_ = pa.array(c.head(0), from_pandas=True).type\r\n    530         else:\r\n    531             values, type_ = get_datetimetz_type(values, c.dtype, None)\r\n\r\nAttributeError: 'Index' object has no attribute 'head'\r\n```\r\n\r\nRemoving `dtype=\"string\"` fixes the issue.\r\n\r\nI can't quite make out whether the mistaken assumption is in dask or pyarrow...? But regardless since it worked prior to #9131 it seems like dask should be able to work around the issue. \r\n\r\ncc @jcrist ", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9186/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9186/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9183", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9183/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9183/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9183/events", "html_url": "https://github.com/dask/dask/issues/9183", "id": 1269424258, "node_id": "I_kwDOAbcwm85LqeCC", "number": 9183, "title": "Inconsistent output from np.squeeze on dtype=object dask array vs numpy array", "user": {"login": "magnunor", "id": 1690979, "node_id": "MDQ6VXNlcjE2OTA5Nzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1690979?v=4", "gravatar_id": "", "url": "https://api.github.com/users/magnunor", "html_url": "https://github.com/magnunor", "followers_url": "https://api.github.com/users/magnunor/followers", "following_url": "https://api.github.com/users/magnunor/following{/other_user}", "gists_url": "https://api.github.com/users/magnunor/gists{/gist_id}", "starred_url": "https://api.github.com/users/magnunor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/magnunor/subscriptions", "organizations_url": "https://api.github.com/users/magnunor/orgs", "repos_url": "https://api.github.com/users/magnunor/repos", "events_url": "https://api.github.com/users/magnunor/events{/privacy}", "received_events_url": "https://api.github.com/users/magnunor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, {"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2022-06-13T13:16:33Z", "updated_at": "2022-07-22T12:53:50Z", "closed_at": "2022-07-22T12:53:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "There is some inconsistency with applying `np.squeeze` on a dask array, as opposed to a numpy array, both with `dtype=object` and with a 1-size dimension. I'm not sure if this is a bug or not, so reporting it here.\r\n\r\n## Example\r\n\r\n```python\r\nimport numpy as np\r\nimport dask.array as da\r\ndata = np.empty(1, dtype=object)\r\ndata[0] = np.array((10, 5))\r\ndata_dask = da.from_array(data, chunks=(1,))\r\noutput0 = np.squeeze(data_dask.compute())\r\noutput1 = np.squeeze(data_dask).compute()\r\nprint(output0.__repr__())\r\nprint(output1.__repr__())\r\n```\r\n\r\nGives the output:\r\n```python\r\narray(array([10,  5]), dtype=object)\r\narray([10,  5])\r\n```\r\n\r\n-------------\r\n\r\nUsing `da.squeeze` gives the same result for both the dask array and the numpy array.\r\n\r\n```python\r\ndata = np.empty(1, dtype=object)\r\ndata[0] = np.array((10, 5))\r\ndata_dask = da.from_array(data, chunks=(1,))\r\noutput0 = da.squeeze(data_dask.compute())\r\noutput1 = da.squeeze(data_dask).compute()\r\nprint(output0.__repr__())\r\nprint(output1.__repr__())\r\n```\r\n\r\nOutput:\r\n```python\r\narray([10,  5])\r\narray([10,  5])\r\n```\r\n\r\n--------\r\n\r\n- Python 3.9.13\r\n- Dask 2022.6.0\r\n- Numpy 1.22.4 (I also tested 1.23.0rc3)\r\n\r\n--------\r\n\r\nRelated bug reports, resulting from this: https://github.com/pyxem/pyxem/issues/851 , https://github.com/pyxem/pyxem/pull/852, https://github.com/hyperspy/hyperspy/issues/2956", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9183/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9183/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9181", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9181/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9181/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9181/events", "html_url": "https://github.com/dask/dask/issues/9181", "id": 1267686740, "node_id": "I_kwDOAbcwm85Lj11U", "number": 9181, "title": "Possible race condition in `dask.utils:Dispatch.dispatch`", "user": {"login": "zklaus", "id": 1185813, "node_id": "MDQ6VXNlcjExODU4MTM=", "avatar_url": "https://avatars.githubusercontent.com/u/1185813?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zklaus", "html_url": "https://github.com/zklaus", "followers_url": "https://api.github.com/users/zklaus/followers", "following_url": "https://api.github.com/users/zklaus/following{/other_user}", "gists_url": "https://api.github.com/users/zklaus/gists{/gist_id}", "starred_url": "https://api.github.com/users/zklaus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zklaus/subscriptions", "organizations_url": "https://api.github.com/users/zklaus/orgs", "repos_url": "https://api.github.com/users/zklaus/repos", "events_url": "https://api.github.com/users/zklaus/events{/privacy}", "received_events_url": "https://api.github.com/users/zklaus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1342304743, "node_id": "MDU6TGFiZWwxMzQyMzA0NzQz", "url": "https://api.github.com/repos/dask/dask/labels/core", "name": "core", "color": "000000", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2022-06-10T15:14:23Z", "updated_at": "2022-10-14T02:43:53Z", "closed_at": "2022-10-14T02:43:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\nWhen using a large number of tasks with `np.ma.core.MaskedArray` blocks, sometimes the scheduler loses the ability to deserialize them. I think I have tracked this down to a possible race condition in [`dask.utils:Dispatch.dispatch`](https://github.com/dask/dask/blob/71aa6ffb3cfdc2a7dcfbc5f5ed91b20f7735c7fd/dask/utils.py#L578), where the lazy registration function is popped off before the registration. If another dispatch happens between those two events, the implementation is not yet in `self._lookup`, but also the lazy registration function is no longer present and thus dask concludes that it can not deserialize the item.\r\n\r\n**What you expected to happen**:\r\nThat dask/distributed retains the ability to deserialize masked arrays.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\nI don't have a complete verifiable example due to the tricky nature of reproducing race conditions.\r\n\r\n**Environment**:\r\n\r\n- Dask version: `main`\r\n- Python version: Python 3.8.13 | packaged by conda-forge\r\n- Operating System: Linux\r\n- Install method (conda, pip, source): Conda environment + dask and distributed source\r\n\r\n<!-- If you are reporting an issue such as scale stability, cluster deadlock.\r\nPlease provide a cluster dump state with this issue, by running client.dump_cluster_state()\r\n\r\nhttps://distributed.dask.org/en/stable/api.html?highlight=dump_cluster_state#distributed.Client.dump_cluster_state\r\n\r\n-->\r\n\r\n<details>\r\n<summary>Cluster Dump State:</summary>\r\n\r\n</details>", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9181/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9181/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9166", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9166/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9166/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9166/events", "html_url": "https://github.com/dask/dask/issues/9166", "id": 1262219783, "node_id": "I_kwDOAbcwm85LO_IH", "number": 9166, "title": "`DataFrame.to_parquet()` doesn't support passing in filesystem", "user": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 162914698, "node_id": "MDU6TGFiZWwxNjI5MTQ2OTg=", "url": "https://api.github.com/repos/dask/dask/labels/good%20first%20issue", "name": "good first issue", "color": "159818", "default": true, "description": "Clearly described and easy to accomplish. Good for beginners to the project."}, {"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-06-06T18:42:22Z", "updated_at": "2022-06-06T19:19:11Z", "closed_at": "2022-06-06T18:48:42Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "It seems that passing in a custom filesystem to `DataFrame.to_parquet()` is currently broken:\r\n\r\n```python\r\nimport dask.datasets\r\nfrom fsspec.implementations.local import LocalFileSystem\r\n\r\nddf = dask.datasets.timeseries()\r\nddf.to_parquet(\"ts.parquet\", fs=LocalFileSystem())\r\n```\r\n- Dask version: `main`\r\n\r\n\r\nproduces: \r\n```python-traceback\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-1-112111c276a1> in <module>\r\n      3 \r\n      4 ddf = dask.datasets.timeseries()\r\n----> 5 ddf.to_parquet(\"ts.parquet\", fs=LocalFileSystem())\r\n\r\n~/dask/dask/dask/dataframe/core.py in to_parquet(self, path, *args, **kwargs)\r\n   5037         from dask.dataframe.io import to_parquet\r\n   5038 \r\n-> 5039         return to_parquet(self, path, *args, **kwargs)\r\n   5040 \r\n   5041     def to_orc(self, path, *args, **kwargs):\r\n\r\n~/dask/dask/dask/dataframe/io/parquet/core.py in to_parquet(df, path, engine, compression, write_index, append, overwrite, ignore_divisions, partition_on, storage_options, custom_metadata, write_metadata_file, compute, compute_kwargs, schema, name_function, **kwargs)\r\n    842     # Engine-specific initialization steps to write the dataset.\r\n    843     # Possibly create parquet metadata, and load existing stuff if appending\r\n--> 844     i_offset, fmd, metadata_file_exists, extra_write_kwargs = engine.initialize_write(\r\n    845         df,\r\n    846         fs,\r\n\r\nTypeError: initialize_write() got multiple values for argument 'fs'\r\n\r\n```", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9166/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9166/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9163", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9163/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9163/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9163/events", "html_url": "https://github.com/dask/dask/issues/9163", "id": 1261872397, "node_id": "I_kwDOAbcwm85LNqUN", "number": 9163, "title": "Pyarrow string bug", "user": {"login": "nlhkh", "id": 3459416, "node_id": "MDQ6VXNlcjM0NTk0MTY=", "avatar_url": "https://avatars.githubusercontent.com/u/3459416?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nlhkh", "html_url": "https://github.com/nlhkh", "followers_url": "https://api.github.com/users/nlhkh/followers", "following_url": "https://api.github.com/users/nlhkh/following{/other_user}", "gists_url": "https://api.github.com/users/nlhkh/gists{/gist_id}", "starred_url": "https://api.github.com/users/nlhkh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nlhkh/subscriptions", "organizations_url": "https://api.github.com/users/nlhkh/orgs", "repos_url": "https://api.github.com/users/nlhkh/repos", "events_url": "https://api.github.com/users/nlhkh/events{/privacy}", "received_events_url": "https://api.github.com/users/nlhkh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-06-06T13:48:04Z", "updated_at": "2022-06-07T17:50:43Z", "closed_at": "2022-06-07T17:50:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "```python\r\n# Running in distributed cluster\r\ndata = pd.util.testing.makeCustomDataframe(nrows=1000, ncols=10).reset_index()\r\ndata[[\"R0\", \"C_l0_g0\", \"C_l0_g1\", \"C_l0_g2\", \"C_l0_g3\", \"C_l0_g4\", \"C_l0_g5\" ,\"C_l0_g6\", \"C_l0_g7\", \"C_l0_g8\", \"C_l0_g9\"]] = data[[\"R0\", \"C_l0_g0\", \"C_l0_g1\", \"C_l0_g2\", \"C_l0_g3\", \"C_l0_g4\", \"C_l0_g5\" ,\"C_l0_g6\", \"C_l0_g7\", \"C_l0_g8\", \"C_l0_g9\"]].astype(\"string[pyarrow]\")\r\ndata = dd.from_pandas(data, npartitions=128)\r\ndata = data.persist()\r\ndata.groupby([\"R0\", \"C_l0_g0\", \"C_l0_g1\", \"C_l0_g2\", \"C_l0_g3\", \"C_l0_g4\", \"C_l0_g5\" ,\"C_l0_g6\"]).apply(lambda d: pd.DataFrame([sum(d[\"C_l0_g9\"].str.len())], columns=[\"length\"]), meta={\"length\": \"int32\"}).compute()\r\n```\r\n\r\n**What happened**:\r\nIn the example above, an error that seems to relate to pyarrow string happened. It kills the workers, and scheduler, and the whole python process exits.\r\n```\r\npyarrow.lib.ArrowInvalid: Buffer #0 too small in array of type string and length 3: expected at least 2 byte(s), got 1\r\n```\r\nNotice the `nrows` argument. If you change that to a small number of rows, such as 300, then it is okay. If the nrows is about 1000, it starts to break.\r\n\r\n**What you expected to happen**:\r\nThe computation should happen successfully. If run without a distributed cluster, this will complete successfully, and the output is\r\n<img width=\"649\" alt=\"image\" src=\"https://user-images.githubusercontent.com/3459416/172172645-68759936-532d-430d-b159-20c1759dc43d.png\">\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.1.1, 2022.5.1, 2022.5.2\r\n- Pandas version: 1.3.5\r\n- Pyarrow version: 7.0.0, 8.0.0\r\n- Python version: 3.8\r\n- Operating System: MacOS, Ubuntu 22.04\r\n- Install method (conda, pip, source): pip in conda environment\r\n\r\n\r\n<details>\r\n<summary>Cluster Dump State:</summary>\r\nWorkers are restarted\r\n</details>", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9163/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9163/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9162", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9162/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9162/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9162/events", "html_url": "https://github.com/dask/dask/issues/9162", "id": 1260848308, "node_id": "I_kwDOAbcwm85LJwS0", "number": 9162, "title": "Cannot create a lagged variable with dask-cuDF", "user": {"login": "shawnbrar", "id": 59639827, "node_id": "MDQ6VXNlcjU5NjM5ODI3", "avatar_url": "https://avatars.githubusercontent.com/u/59639827?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shawnbrar", "html_url": "https://github.com/shawnbrar", "followers_url": "https://api.github.com/users/shawnbrar/followers", "following_url": "https://api.github.com/users/shawnbrar/following{/other_user}", "gists_url": "https://api.github.com/users/shawnbrar/gists{/gist_id}", "starred_url": "https://api.github.com/users/shawnbrar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shawnbrar/subscriptions", "organizations_url": "https://api.github.com/users/shawnbrar/orgs", "repos_url": "https://api.github.com/users/shawnbrar/repos", "events_url": "https://api.github.com/users/shawnbrar/events{/privacy}", "received_events_url": "https://api.github.com/users/shawnbrar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 1342320181, "node_id": "MDU6TGFiZWwxMzQyMzIwMTgx", "url": "https://api.github.com/repos/dask/dask/labels/needs%20info", "name": "needs info", "color": "d0cfcc", "default": false, "description": "Needs further information from the user"}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "galipremsagar", "id": 11664259, "node_id": "MDQ6VXNlcjExNjY0MjU5", "avatar_url": "https://avatars.githubusercontent.com/u/11664259?v=4", "gravatar_id": "", "url": "https://api.github.com/users/galipremsagar", "html_url": "https://github.com/galipremsagar", "followers_url": "https://api.github.com/users/galipremsagar/followers", "following_url": "https://api.github.com/users/galipremsagar/following{/other_user}", "gists_url": "https://api.github.com/users/galipremsagar/gists{/gist_id}", "starred_url": "https://api.github.com/users/galipremsagar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/galipremsagar/subscriptions", "organizations_url": "https://api.github.com/users/galipremsagar/orgs", "repos_url": "https://api.github.com/users/galipremsagar/repos", "events_url": "https://api.github.com/users/galipremsagar/events{/privacy}", "received_events_url": "https://api.github.com/users/galipremsagar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "galipremsagar", "id": 11664259, "node_id": "MDQ6VXNlcjExNjY0MjU5", "avatar_url": "https://avatars.githubusercontent.com/u/11664259?v=4", "gravatar_id": "", "url": "https://api.github.com/users/galipremsagar", "html_url": "https://github.com/galipremsagar", "followers_url": "https://api.github.com/users/galipremsagar/followers", "following_url": "https://api.github.com/users/galipremsagar/following{/other_user}", "gists_url": "https://api.github.com/users/galipremsagar/gists{/gist_id}", "starred_url": "https://api.github.com/users/galipremsagar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/galipremsagar/subscriptions", "organizations_url": "https://api.github.com/users/galipremsagar/orgs", "repos_url": "https://api.github.com/users/galipremsagar/repos", "events_url": "https://api.github.com/users/galipremsagar/events{/privacy}", "received_events_url": "https://api.github.com/users/galipremsagar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2022-06-04T17:18:06Z", "updated_at": "2022-06-16T07:53:45Z", "closed_at": "2022-06-16T07:52:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have the following `dask_cudf.core.DataFrame`:-\r\n\r\n    import pandas as pd\r\n    import numpy as np\r\n    import dask_cudf\r\n    import cudf\r\n\r\n\r\n    data = {\"x\":range(1,21), \"nor\":np.random.normal(2, 4, 20), \"unif\":np.random.uniform(size = 20)}\r\n    df = cudf.DataFrame(data)\r\n    ddf = dask_cudf.from_cudf(df, npartitions = 2)\r\n    ddf.compute()\r\n\r\nI wanted to create 1st till 5th lagged values for the columns `nor` and `unif`. I create them the following way:-\r\n\r\n    colz = [\"nor\", \"unif\"]\r\n    ddf[[s + \"_\" + str(1) for s in colz]] = ddf[colz].shift(1)\r\n    ddf[[s + \"_\" + str(2) for s in colz]] = ddf[colz].shift(2)\r\n\r\nI can create the first and the second lagged values, but not more than that. When I run `shift` with a value more than 2, I get the following error::-\r\n\r\n        /usr/local/lib/python3.7/site-packages/dask/dataframe/utils.py in raise_on_meta_error(funcname, udf)\r\n        175     try:\r\n    --> 176         yield\r\n        177     except Exception as e:\r\n\r\n    /usr/local/lib/python3.7/site-packages/dask/dataframe/core.py in _emulate(func, udf, *args, **kwargs)\r\n       5832     with raise_on_meta_error(funcname(func), udf=udf):\r\n    -> 5833         return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n       5834\r\n\r\n    /usr/local/lib/python3.7/site-packages/dask/utils.py in __call__(self, _methodcaller__obj, *args, **kwargs)\r\n       1020     def __call__(self, __obj, *args, **kwargs):\r\n    -> 1021         return getattr(__obj, self.method)(*args, **kwargs)\r\n       1022\r\n\r\n    /usr/local/lib/python3.7/site-packages/cudf/core/frame.py in shift(self, periods, freq, axis, fill_value)\r\n       1787         assert axis in (None, 0) and freq is None\r\n    -> 1788         return self._shift(periods)\r\n       1789\r\n\r\n    /usr/local/lib/python3.7/site-packages/cudf/core/frame.py in _shift(self, offset, fill_value)\r\n       1792         return self.__class__._from_data(\r\n    -> 1793             zip(self._column_names, data_columns), self._index\r\n       1794         )\r\n\r\n    /usr/local/lib/python3.7/site-packages/cudf/core/dataframe.py in _from_data(cls, data, index, columns)\r\n        817     ) -> DataFrame:\r\n    --> 818         out = super()._from_data(data, index)\r\n        819         if index is None:\r\n\r\n    /usr/local/lib/python3.7/site-packages/cudf/core/frame.py in _from_data(cls, data, index)\r\n        139         obj = cls.__new__(cls)\r\n    --> 140         Frame.__init__(obj, data, index)\r\n        141         return obj\r\n\r\n    /usr/local/lib/python3.7/site-packages/cudf/core/frame.py in __init__(self, data, index)\r\n         77             data = {}\r\n    ---> 78         self._data = cudf.core.column_accessor.ColumnAccessor(data)\r\n         79         self._index = index\r\n\r\n    /usr/local/lib/python3.7/site-packages/cudf/core/column_accessor.py in __init__(self, data, multiindex, level_names)\r\n        120             if data:\r\n    --> 121                 data = dict(data)\r\n        122                 # Faster than next(iter(data.values()))\r\n\r\n    /usr/local/lib/python3.7/site-packages/cudf/core/frame.py in <genexpr>(.0)\r\n       1790     def _shift(self, offset, fill_value=None):\r\n    -> 1791         data_columns = (col.shift(offset, fill_value) for col in self._columns)\r\n       1792         return self.__class__._from_data(\r\n\r\n    /usr/local/lib/python3.7/site-packages/cudf/core/column/column.py in shift(self, offset, fill_value)\r\n        390     def shift(self, offset: int, fill_value: ScalarLike) -> ColumnBase:\r\n    --> 391         return libcudf.copying.shift(self, offset, fill_value)\r\n        392\r\n\r\n    cudf/_lib/copying.pyx in cudf._lib.copying.shift()\r\n\r\n    RuntimeError: parallel_for failed: cudaErrorInvalidConfiguration: invalid configuration argument\r\n\r\n    The above exception was the direct cause of the following exception:\r\n\r\n    ValueError                                Traceback (most recent call last)\r\n    <ipython-input-13-27823eac1e8a> in <module>()\r\n          2 ddf[[s + \"_\" + str(1) for s in colz]] = ddf[colz].shift(1)\r\n          3 ddf[[s + \"_\" + str(2) for s in colz]] = ddf[colz].shift(2)\r\n    ----> 4 ddf[[s + \"_\" + str(3) for s in colz]] = ddf[colz].shift(3)\r\n\r\n    /usr/local/lib/python3.7/site-packages/dask/dataframe/core.py in shift(self, periods, freq, axis)\r\n       1683             before, after = (periods, 0) if periods > 0 else (0, -periods)\r\n       1684             return self.map_overlap(\r\n    -> 1685                 M.shift, before, after, token=\"shift\", periods=periods\r\n       1686             )\r\n       1687\r\n\r\n    /usr/local/lib/python3.7/site-packages/dask/dataframe/core.py in map_overlap(self, func, before, after, *args, **kwargs)\r\n        840         from .rolling import map_overlap\r\n        841\r\n    --> 842         return map_overlap(func, self, before, after, *args, **kwargs)\r\n        843\r\n        844     def memory_usage_per_partition(self, index=True, deep=False):\r\n\r\n    /usr/local/lib/python3.7/site-packages/dask/dataframe/rolling.py in map_overlap(func, df, before, after, *args, **kwargs)\r\n        102         meta = kwargs.pop(\"meta\")\r\n        103     else:\r\n    --> 104         meta = _emulate(func, df, *args, **kwargs)\r\n        105     meta = make_meta(meta, index=df._meta.index, parent_meta=df._meta)\r\n        106\r\n\r\n    /usr/local/lib/python3.7/site-packages/dask/dataframe/core.py in _emulate(func, udf, *args, **kwargs)\r\n       5831     \"\"\"\r\n       5832     with raise_on_meta_error(funcname(func), udf=udf):\r\n    -> 5833         return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n       5834\r\n       5835\r\n\r\n    /usr/lib/python3.7/contextlib.py in __exit__(self, type, value, traceback)\r\n        128                 value = type()\r\n        129             try:\r\n    --> 130                 self.gen.throw(type, value, traceback)\r\n        131             except StopIteration as exc:\r\n        132                 # Suppress StopIteration *unless* it's the same exception that\r\n\r\n    /usr/local/lib/python3.7/site-packages/dask/dataframe/utils.py in raise_on_meta_error(funcname, udf)\r\n        195         )\r\n        196         msg = msg.format(f\" in `{funcname}`\" if funcname else \"\", repr(e), tb)\r\n    --> 197         raise ValueError(msg) from e\r\n        198\r\n        199\r\n\r\n    cudf/_lib/copying.pyx in cudf._lib.copying.shift()\r\n\r\n    RuntimeError: parallel_for failed: cudaErrorInvalidConfiguration: invalid configuration argument\r\n\r\n    The above exception was the direct cause of the following exception:\r\n\r\n    ValueError                                Traceback (most recent call last)\r\n    /usr/local/lib/python3.7/site-packages/dask/dataframe/utils.py in raise_on_meta_error(funcname, udf)\r\n        195         )\r\n        196         msg = msg.format(f\" in `{funcname}`\" if funcname else \"\", repr(e), tb)\r\n    --> 197         raise ValueError(msg) from e\r\n        198\r\n        199\r\n\r\n    ValueError: Metadata inference failed in `shift`.\r\n\r\n    Original error is below:\r\n    ------------------------\r\n    RuntimeError('parallel_for failed: cudaErrorInvalidConfiguration: invalid configuration argument')\r\n\r\n    Traceback:\r\n    ---------\r\n      File \"/usr/local/lib/python3.7/site-packages/dask/dataframe/utils.py\", line 176, in raise_on_meta_error\r\n        yield\r\n      File \"/usr/local/lib/python3.7/site-packages/dask/dataframe/core.py\", line 5833, in _emulate\r\n        return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n      File \"/usr/local/lib/python3.7/site-packages/dask/utils.py\", line 1021, in __call__\r\n        return getattr(__obj, self.method)(*args, **kwargs)\r\n      File \"/usr/local/lib/python3.7/site-packages/cudf/core/frame.py\", line 1788, in shift\r\n        return self._shift(periods)\r\n      File \"/usr/local/lib/python3.7/site-packages/cudf/core/frame.py\", line 1793, in _shift\r\n        zip(self._column_names, data_columns), self._index\r\n      File \"/usr/local/lib/python3.7/site-packages/cudf/core/dataframe.py\", line 818, in _from_data\r\n        out = super()._from_data(data, index)\r\n      File \"/usr/local/lib/python3.7/site-packages/cudf/core/frame.py\", line 140, in _from_data\r\n        Frame.__init__(obj, data, index)\r\n      File \"/usr/local/lib/python3.7/site-packages/cudf/core/frame.py\", line 78, in __init__\r\n        self._data = cudf.core.column_accessor.ColumnAccessor(data)\r\n      File \"/usr/local/lib/python3.7/site-packages/cudf/core/column_accessor.py\", line 121, in __init__\r\n        data = dict(data)\r\n      File \"/usr/local/lib/python3.7/site-packages/cudf/core/frame.py\", line 1791, in <genexpr>\r\n        data_columns = (col.shift(offset, fill_value) for col in self._columns)\r\n      File \"/usr/local/lib/python3.7/site-packages/cudf/core/column/column.py\", line 391, in shift\r\n        return libcudf.copying.shift(self, offset, fill_value)\r\n      File \"cudf/_lib/copying.pyx\", line 633, in cudf._lib.copying.shift\r\n\r\nI can't seem to understand why this is happening.\r\n\r\nI have installed the nvidia `rapids` library on google colab.", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9162/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9162/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9142", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9142/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9142/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9142/events", "html_url": "https://github.com/dask/dask/issues/9142", "id": 1251296307, "node_id": "I_kwDOAbcwm85KlUQz", "number": 9142, "title": "`pyarrow` partition logic error", "user": {"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 1887344368, "node_id": "MDU6TGFiZWwxODg3MzQ0MzY4", "url": "https://api.github.com/repos/dask/dask/labels/tests", "name": "tests", "color": "a0f9b4", "default": false, "description": "Unit tests and/or continuous integration"}, {"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-05-27T21:38:31Z", "updated_at": "2022-05-27T23:47:57Z", "closed_at": "2022-05-27T23:27:30Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Following https://github.com/dask/dask/pull/9041 being merged, we started seeing several tests fail on `main` (e.g. `dask/dataframe/io/parquet/arrow.py::test_split_row_groups[pyarrow]` with the following error:\r\n\r\n```python\r\n_______________________________________________________________ test_split_row_groups[pyarrow] _______________________________________________________________\r\n\r\ntmpdir = local('/private/var/folders/k_/lx1rdvqn253gd1wrcx__5frm0000gn/T/pytest-of-james/pytest-5/test_split_row_groups_pyarrow_0'), engine = 'pyarrow'\r\n\r\n    @PYARROW_MARK\r\n    def test_split_row_groups(tmpdir, engine):\r\n        \"\"\"Test split_row_groups read_parquet kwarg\"\"\"\r\n        tmp = str(tmpdir)\r\n        df = pd.DataFrame(\r\n            {\"i32\": np.arange(800, dtype=np.int32), \"f\": np.arange(800, dtype=np.float64)}\r\n        )\r\n        df.index.name = \"index\"\r\n\r\n        half = len(df) // 2\r\n        dd.from_pandas(df.iloc[:half], npartitions=2).to_parquet(\r\n            tmp, engine=\"pyarrow\", row_group_size=100\r\n        )\r\n\r\n>       ddf3 = dd.read_parquet(tmp, engine=engine, split_row_groups=True)\r\n\r\ndask/dataframe/io/tests/test_parquet.py:2652:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\ndask/dataframe/io/parquet/core.py:464: in read_parquet\r\n    read_metadata_result = engine.read_metadata(\r\ndask/dataframe/io/parquet/arrow.py:340: in read_metadata\r\n    dataset_info = cls._collect_dataset_info(\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\ncls = <class 'dask.dataframe.io.parquet.arrow.ArrowDatasetEngine'>\r\npaths = ['/private/var/folders/k_/lx1rdvqn253gd1wrcx__5frm0000gn/T/pytest-of-james/pytest-5/test_split_row_groups_pyarrow_0/pa...r/folders/k_/lx1rdvqn253gd1wrcx__5frm0000gn/T/pytest-of-james/pytest-5/test_split_row_groups_pyarrow_0/part.1.parquet']\r\nfs = <fsspec.implementations.local.LocalFileSystem object at 0x15ea645b0>, categories = None, index = None, gather_statistics = False, filters = None\r\nsplit_row_groups = True, chunksize = None, aggregate_files = None, ignore_metadata_file = False, metadata_task_size = None\r\nparquet_file_extension = ('.parq', '.parquet', '.pq'), kwargs = {}\r\n\r\n    @classmethod\r\n    def _collect_dataset_info(\r\n        cls,\r\n        paths,\r\n        fs,\r\n        categories,\r\n        index,\r\n        gather_statistics,\r\n        filters,\r\n        split_row_groups,\r\n        chunksize,\r\n        aggregate_files,\r\n        ignore_metadata_file,\r\n        metadata_task_size,\r\n        parquet_file_extension,\r\n        kwargs,\r\n    ):\r\n        \"\"\"pyarrow.dataset version of _collect_dataset_info\r\n        Use pyarrow.dataset API to construct a dictionary of all\r\n        general information needed to read the dataset.\r\n        \"\"\"\r\n\r\n        # Use pyarrow.dataset API\r\n        ds = None\r\n        valid_paths = None  # Only used if `paths` is a list containing _metadata\r\n\r\n        # Extract \"supported\" key-word arguments from `kwargs`\r\n        (\r\n            _dataset_kwargs,\r\n            read_kwargs,\r\n            user_kwargs,\r\n        ) = _split_user_options(**kwargs)\r\n\r\n        if \"partitioning\" not in _dataset_kwargs:\r\n            _dataset_kwargs[\"partitioning\"] = \"hive\"\r\n\r\n        if \"format\" not in _dataset_kwargs:\r\n            _dataset_kwargs[\"format\"] = pa_ds.ParquetFileFormat()\r\n\r\n        # Case-dependent pyarrow.dataset creation\r\n        has_metadata_file = False\r\n        if len(paths) == 1 and fs.isdir(paths[0]):\r\n\r\n            # Use _analyze_paths to avoid relative-path\r\n            # problems (see GH#5608)\r\n            paths, base, fns = _sort_and_analyze_paths(paths, fs)\r\n            paths = fs.sep.join([base, fns[0]])\r\n\r\n            meta_path = fs.sep.join([paths, \"_metadata\"])\r\n            if not ignore_metadata_file and fs.exists(meta_path):\r\n                # Use _metadata file\r\n                ds = pa_ds.parquet_dataset(\r\n                    meta_path,\r\n                    filesystem=fs,\r\n                    **_dataset_kwargs,\r\n                )\r\n                has_metadata_file = True\r\n            elif parquet_file_extension:\r\n                # Need to materialize all paths if we are missing the _metadata file\r\n                # Raise error if all files have been filtered by extension\r\n                len0 = len(paths)\r\n                paths = [\r\n                    path\r\n                    for path in fs.find(paths)\r\n                    if path.endswith(parquet_file_extension)\r\n                ]\r\n                if len0 and paths == []:\r\n                    raise ValueError(\r\n                        \"No files satisfy the `parquet_file_extension` criteria \"\r\n                        f\"(files must end with {parquet_file_extension}).\"\r\n                    )\r\n\r\n        elif len(paths) > 1:\r\n            paths, base, fns = _sort_and_analyze_paths(paths, fs)\r\n            meta_path = fs.sep.join([base, \"_metadata\"])\r\n            if \"_metadata\" in fns:\r\n                # Pyarrow cannot handle \"_metadata\" when `paths` is a list\r\n                # Use _metadata file\r\n                if not ignore_metadata_file:\r\n                    ds = pa_ds.parquet_dataset(\r\n                        meta_path,\r\n                        filesystem=fs,\r\n                        **_dataset_kwargs,\r\n                    )\r\n                    has_metadata_file = True\r\n\r\n                # Populate valid_paths, since the original path list\r\n                # must be used to filter the _metadata-based dataset\r\n                fns.remove(\"_metadata\")\r\n                valid_paths = fns\r\n\r\n        # Final \"catch-all\" pyarrow.dataset call\r\n        if ds is None:\r\n            ds = pa_ds.dataset(\r\n                paths,\r\n                filesystem=fs,\r\n                **_dataset_kwargs,\r\n            )\r\n\r\n        # Deal with directory partitioning\r\n        # Get all partition keys (without filters) to populate partition_obj\r\n        partition_obj = []  # See `partition_info` description below\r\n        hive_categories = defaultdict(list)\r\n        file_frag = None\r\n        for file_frag in ds.get_fragments():\r\n            if partitioning_supported:\r\n                # Can avoid manual category discovery for pyarrow>=5.0.0\r\n                break\r\n            keys = pa_ds._get_partition_keys(file_frag.partition_expression)\r\n            if not (keys or hive_categories):\r\n                break  # Bail - This is not a hive-partitioned dataset\r\n            for k, v in keys.items():\r\n                if v not in hive_categories[k]:\r\n                    hive_categories[k].append(v)\r\n\r\n        physical_schema = ds.schema\r\n        if file_frag is not None:\r\n            physical_schema = file_frag.physical_schema\r\n\r\n            # Check/correct order of `categories` using last file_frag\r\n            # TODO: Remove this after pyarrow>=5.0.0 is required\r\n            #\r\n            # Note that `_get_partition_keys` does NOT preserve the\r\n            # partition-hierarchy order of the keys. Therefore, we\r\n            # use custom logic to determine the \"correct\" oredering\r\n            # of the `categories` output.\r\n            #\r\n            # Example (why we need to \"reorder\" `categories`):\r\n            #\r\n            #    # Fragment path has \"hive\" structure\r\n            #    file_frag.path\r\n            #\r\n            #        '/data/path/b=x/c=x/part.1.parquet'\r\n            #\r\n            #    # `categories` may NOT preserve the hierachy order\r\n            #    categories.keys()\r\n            #\r\n            #        dict_keys(['c', 'b'])\r\n            #\r\n            cat_keys = [\r\n                part.split(\"=\")[0]\r\n                for part in file_frag.path.split(fs.sep)\r\n                if \"=\" in part\r\n            ]\r\n            if set(hive_categories) == set(cat_keys):\r\n                hive_categories = {\r\n                    k: hive_categories[k] for k in cat_keys if k in hive_categories\r\n                }\r\n\r\n        if partitioning_supported and ds.partitioning.dictionaries:\r\n            # Use ds.partitioning for pyarrow>=5.0.0\r\n            partition_names = list(ds.partitioning.schema.names)\r\n            for i, name in enumerate(partition_names):\r\n                partition_obj.append(\r\n>                   PartitionObj(name, ds.partitioning.dictionaries[i].to_pandas())\r\n                )\r\nE               AttributeError: 'NoneType' object has no attribute 'to_pandas'\r\n\r\ndask/dataframe/io/parquet/arrow.py:917: AttributeError\r\n```\r\n\r\nI should also note that locally I didn't see this error when using `pyarrow=7`, but do with `pyarrow=8` (released two days ago)\r\n\r\ncc @rjzamora @jcrist ", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9142/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9142/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9135", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9135/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9135/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9135/events", "html_url": "https://github.com/dask/dask/issues/9135", "id": 1250749103, "node_id": "I_kwDOAbcwm85KjOqv", "number": 9135, "title": "normalize_token does not raise warning for function with non-deterministic hash", "user": {"login": "LunarLanding", "id": 4441338, "node_id": "MDQ6VXNlcjQ0NDEzMzg=", "avatar_url": "https://avatars.githubusercontent.com/u/4441338?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LunarLanding", "html_url": "https://github.com/LunarLanding", "followers_url": "https://api.github.com/users/LunarLanding/followers", "following_url": "https://api.github.com/users/LunarLanding/following{/other_user}", "gists_url": "https://api.github.com/users/LunarLanding/gists{/gist_id}", "starred_url": "https://api.github.com/users/LunarLanding/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LunarLanding/subscriptions", "organizations_url": "https://api.github.com/users/LunarLanding/orgs", "repos_url": "https://api.github.com/users/LunarLanding/repos", "events_url": "https://api.github.com/users/LunarLanding/events{/privacy}", "received_events_url": "https://api.github.com/users/LunarLanding/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1342304743, "node_id": "MDU6TGFiZWwxMzQyMzA0NzQz", "url": "https://api.github.com/repos/dask/dask/labels/core", "name": "core", "color": "000000", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2022-05-27T13:07:39Z", "updated_at": "2022-06-06T19:22:43Z", "closed_at": "2022-06-06T19:22:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\nimport dask.config\r\nfrom dask.base import tokenize\r\na,b = (\r\n    lambda a: a,\r\n    lambda a: a,\r\n)\r\nwith dask.config.set({\"tokenize.ensure-deterministic\":True}):\r\n    print(tokenize(a)==tokenize(b))\r\nstr(a),str(b)\r\n```\r\nGives:\r\n```\r\nFalse\r\n('<function <lambda> at 0x14a0d079fee0>',\r\n '<function <lambda> at 0x14a0ca90cc10>')\r\n```\r\nThis is because of the last lines here, where the code gives up by using `str(func)`: \r\nhttps://github.com/dask/dask/blob/c60b1f757a3b92361504833cf0417e9c77b82514/dask/base.py#L1043-L1069", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9135/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9135/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9122", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9122/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9122/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9122/events", "html_url": "https://github.com/dask/dask/issues/9122", "id": 1246293247, "node_id": "I_kwDOAbcwm85KSOz_", "number": 9122, "title": "cumsum() doesn't work on tables with >1 partition and columns with identical names", "user": {"login": "faulaire", "id": 306648, "node_id": "MDQ6VXNlcjMwNjY0OA==", "avatar_url": "https://avatars.githubusercontent.com/u/306648?v=4", "gravatar_id": "", "url": "https://api.github.com/users/faulaire", "html_url": "https://github.com/faulaire", "followers_url": "https://api.github.com/users/faulaire/followers", "following_url": "https://api.github.com/users/faulaire/following{/other_user}", "gists_url": "https://api.github.com/users/faulaire/gists{/gist_id}", "starred_url": "https://api.github.com/users/faulaire/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/faulaire/subscriptions", "organizations_url": "https://api.github.com/users/faulaire/orgs", "repos_url": "https://api.github.com/users/faulaire/repos", "events_url": "https://api.github.com/users/faulaire/events{/privacy}", "received_events_url": "https://api.github.com/users/faulaire/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 162914698, "node_id": "MDU6TGFiZWwxNjI5MTQ2OTg=", "url": "https://api.github.com/repos/dask/dask/labels/good%20first%20issue", "name": "good first issue", "color": "159818", "default": true, "description": "Clearly described and easy to accomplish. Good for beginners to the project."}, {"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2022-05-24T09:53:18Z", "updated_at": "2022-11-30T14:28:16Z", "closed_at": "2022-11-30T14:28:16Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "cumsum on a dask dataframe with multiple partitions and columns with identical names raise an exception\r\n\r\nTo reproduce:\r\n\r\n```python\r\nimport dask\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\n\r\nobj = pd.DataFrame([[0, 1, 2],\r\n                    [3, 4, 5],\r\n                    [6, 7, 8]], columns=['a', 'b', 'b'])\r\ndask_df = dd.from_pandas(obj, npartitions=3)\r\ndask_df.cumsum().compute()\r\n```\r\n\r\nException raised:\r\n\r\n```\r\nFile ~\\workspace\\jupyter\\jupyter\\lib\\site-packages\\dask\\dataframe\\core.py:6851, in _take_last.<locals>._last_valid(s)\r\n   6849 for i in range(1, min(10, len(s) + 1)):\r\n   6850     val = s.iloc[-i]\r\n-> 6851     if not pd.isnull(val):\r\n   6852         return val\r\n   6853 else:\r\n\r\nFile ~\\workspace\\jupyter\\jupyter\\lib\\site-packages\\pandas\\core\\generic.py:1527, in NDFrame.__nonzero__(self)\r\n   1525 @final\r\n   1526 def __nonzero__(self):\r\n-> 1527     raise ValueError(\r\n   1528         f\"The truth value of a {type(self).__name__} is ambiguous. \"\r\n   1529         \"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\r\n   1530     )\r\n\r\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.05.0\r\n- Python version: 3.9\r\n- Operating System: Linux Centos\r\n- Install method (conda, pip, source): pip\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9122/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9122/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9118", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9118/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9118/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9118/events", "html_url": "https://github.com/dask/dask/issues/9118", "id": 1245536088, "node_id": "I_kwDOAbcwm85KPV9Y", "number": 9118, "title": "Cannot set index to a column with a `period` dtype", "user": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3468123446, "node_id": "LA_kwDOAbcwm87Ot102", "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention", "name": "needs attention", "color": "6d626c", "default": false, "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-05-23T18:14:58Z", "updated_at": "2022-10-18T20:39:34Z", "closed_at": "2022-10-18T20:39:34Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**What happened**:\r\nDask.dataframe errors when trying to call `dd.set_index` with a `period` dtype.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pandas\r\n\r\ndf = pandas.DataFrame({\r\n    \"a\": range(10),\r\n    \"b\": pandas.period_range(start=\"2022-05-23\", periods=10, freq=\"1D\")\r\n})\r\ndd.from_pandas(df, npartitions=2).set_index(\"b\")\r\n```\r\n\r\nwhich produces\r\n\r\n<details>\r\n\r\n```python-traceback\r\n---------------------------------------------------------------------------\r\nFile ~/miniconda3/envs/parquet/lib/python3.9/site-packages/dask/dataframe/core.py:4714, in DataFrame.set_index(***failed resolving arguments***)\r\n   4711 else:\r\n   4712     from dask.dataframe.shuffle import set_index\r\n-> 4714     return set_index(\r\n   4715         self,\r\n   4716         other,\r\n   4717         drop=drop,\r\n   4718         npartitions=npartitions,\r\n   4719         divisions=divisions,\r\n   4720         **kwargs,\r\n   4721     )\r\n\r\nFile ~/miniconda3/envs/parquet/lib/python3.9/site-packages/dask/dataframe/shuffle.py:220, in set_index(df, index, npartitions, shuffle, compute, drop, upsample, divisions, partition_size, **kwargs)\r\n    217     index2 = index\r\n    219 if divisions is None:\r\n--> 220     divisions, mins, maxes = _calculate_divisions(\r\n    221         df, index2, repartition, npartitions, upsample, partition_size\r\n    222     )\r\n    224     if (\r\n    225         mins == sorted(mins)\r\n    226         and maxes == sorted(maxes)\r\n    227         and all(mx < mn for mx, mn in zip(maxes[:-1], mins[1:]))\r\n    228         and npartitions == df.npartitions\r\n    229     ):\r\n    230         divisions = mins + [maxes[-1]]\r\n\r\nFile ~/miniconda3/envs/parquet/lib/python3.9/site-packages/dask/dataframe/shuffle.py:42, in _calculate_divisions(df, partition_col, repartition, npartitions, upsample, partition_size)\r\n     40 mins = partition_col.map_partitions(M.min)\r\n     41 maxes = partition_col.map_partitions(M.max)\r\n---> 42 divisions, sizes, mins, maxes = compute(divisions, sizes, mins, maxes)\r\n     43 divisions = methods.tolist(divisions)\r\n     44 if type(sizes) is not list:\r\n\r\nFile ~/miniconda3/envs/parquet/lib/python3.9/site-packages/dask/base.py:575, in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)\r\n    572     keys.append(x.__dask_keys__())\r\n    573     postcomputes.append(x.__dask_postcompute__())\r\n--> 575 results = schedule(dsk, keys, **kwargs)\r\n    576 return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n\r\nFile ~/miniconda3/envs/parquet/lib/python3.9/site-packages/dask/threaded.py:81, in get(dsk, result, cache, num_workers, pool, **kwargs)\r\n     78     elif isinstance(pool, multiprocessing.pool.Pool):\r\n     79         pool = MultiprocessingPoolExecutor(pool)\r\n---> 81 results = get_async(\r\n     82     pool.submit,\r\n     83     pool._max_workers,\r\n     84     dsk,\r\n     85     result,\r\n     86     cache=cache,\r\n     87     get_id=_thread_get_id,\r\n     88     pack_exception=pack_exception,\r\n     89     **kwargs,\r\n     90 )\r\n     92 # Cleanup pools associated to dead threads\r\n     93 with pools_lock:\r\n\r\nFile ~/miniconda3/envs/parquet/lib/python3.9/site-packages/dask/local.py:508, in get_async(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\r\n    506         _execute_task(task, data)  # Re-execute locally\r\n    507     else:\r\n--> 508         raise_exception(exc, tb)\r\n    509 res, worker_id = loads(res_info)\r\n    510 state[\"cache\"][key] = res\r\n\r\nFile ~/miniconda3/envs/parquet/lib/python3.9/site-packages/dask/local.py:316, in reraise(exc, tb)\r\n    314 if exc.__traceback__ is not tb:\r\n    315     raise exc.with_traceback(tb)\r\n--> 316 raise exc\r\n\r\nFile ~/miniconda3/envs/parquet/lib/python3.9/site-packages/dask/local.py:221, in execute_task(key, task_info, dumps, loads, get_id, pack_exception)\r\n    219 try:\r\n    220     task, data = loads(task_info)\r\n--> 221     result = _execute_task(task, data)\r\n    222     id = get_id()\r\n    223     result = dumps((result, id))\r\n\r\nFile ~/miniconda3/envs/parquet/lib/python3.9/site-packages/dask/core.py:119, in _execute_task(arg, cache, dsk)\r\n    115     func, args = arg[0], arg[1:]\r\n    116     # Note: Don't assign the subtask results to a variable. numpy detects\r\n    117     # temporaries by their reference count and can execute certain\r\n    118     # operations in-place.\r\n--> 119     return func(*(_execute_task(a, cache) for a in args))\r\n    120 elif not ishashable(arg):\r\n    121     return arg\r\n\r\nFile ~/miniconda3/envs/parquet/lib/python3.9/site-packages/dask/dataframe/partitionquantiles.py:417, in percentiles_summary(df, num_old, num_new, upsample, state)\r\n    415     data = data.cat.codes\r\n    416     interpolation = \"nearest\"\r\n--> 417 elif isinstance(data.dtype, pd.core.dtypes.dtypes.DatetimeTZDtype) or np.issubdtype(\r\n    418     data.dtype, np.integer\r\n    419 ):\r\n    420     interpolation = \"nearest\"\r\n    421 vals, n = _percentile(data, qs, interpolation=interpolation)\r\n\r\nFile ~/miniconda3/envs/parquet/lib/python3.9/site-packages/numpy/core/numerictypes.py:416, in issubdtype(arg1, arg2)\r\n    358 r\"\"\"\r\n    359 Returns True if first argument is a typecode lower/equal in type hierarchy.\r\n    360 \r\n   (...)\r\n    413 \r\n    414 \"\"\"\r\n    415 if not issubclass_(arg1, generic):\r\n--> 416     arg1 = dtype(arg1).type\r\n    417 if not issubclass_(arg2, generic):\r\n    418     arg2 = dtype(arg2).type\r\n\r\nTypeError: Cannot interpret 'period[D]' as a data type\r\n```\r\n\r\n</details>\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.5.0\r\n- Python version: 3.9\r\n- Operating System: ubuntu\r\n- Install method (conda, pip, source): pip", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9118/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9118/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9104", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9104/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9104/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9104/events", "html_url": "https://github.com/dask/dask/issues/9104", "id": 1242155911, "node_id": "I_kwDOAbcwm85KCcuH", "number": 9104, "title": "read_parquet column projection not working as expected", "user": {"login": "bnaul", "id": 903655, "node_id": "MDQ6VXNlcjkwMzY1NQ==", "avatar_url": "https://avatars.githubusercontent.com/u/903655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bnaul", "html_url": "https://github.com/bnaul", "followers_url": "https://api.github.com/users/bnaul/followers", "following_url": "https://api.github.com/users/bnaul/following{/other_user}", "gists_url": "https://api.github.com/users/bnaul/gists{/gist_id}", "starred_url": "https://api.github.com/users/bnaul/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bnaul/subscriptions", "organizations_url": "https://api.github.com/users/bnaul/orgs", "repos_url": "https://api.github.com/users/bnaul/repos", "events_url": "https://api.github.com/users/bnaul/events{/privacy}", "received_events_url": "https://api.github.com/users/bnaul/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "jcrist", "id": 2783717, "node_id": "MDQ6VXNlcjI3ODM3MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/2783717?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jcrist", "html_url": "https://github.com/jcrist", "followers_url": "https://api.github.com/users/jcrist/followers", "following_url": "https://api.github.com/users/jcrist/following{/other_user}", "gists_url": "https://api.github.com/users/jcrist/gists{/gist_id}", "starred_url": "https://api.github.com/users/jcrist/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jcrist/subscriptions", "organizations_url": "https://api.github.com/users/jcrist/orgs", "repos_url": "https://api.github.com/users/jcrist/repos", "events_url": "https://api.github.com/users/jcrist/events{/privacy}", "received_events_url": "https://api.github.com/users/jcrist/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jcrist", "id": 2783717, "node_id": "MDQ6VXNlcjI3ODM3MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/2783717?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jcrist", "html_url": "https://github.com/jcrist", "followers_url": "https://api.github.com/users/jcrist/followers", "following_url": "https://api.github.com/users/jcrist/following{/other_user}", "gists_url": "https://api.github.com/users/jcrist/gists{/gist_id}", "starred_url": "https://api.github.com/users/jcrist/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jcrist/subscriptions", "organizations_url": "https://api.github.com/users/jcrist/orgs", "repos_url": "https://api.github.com/users/jcrist/repos", "events_url": "https://api.github.com/users/jcrist/events{/privacy}", "received_events_url": "https://api.github.com/users/jcrist/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2022-05-19T18:21:25Z", "updated_at": "2022-05-20T03:17:27Z", "closed_at": "2022-05-20T03:17:27Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\nFiltering out columns after calling `read_parquet` still causes the entire dataset to be loaded for downstream operations:\r\n```\r\n%%time\r\ndd.read_parquet(\r\n    \"s3://nyc-tlc/trip data/fhv_tripdata_2015*.parquet\",\r\n)[[]].sum().compute()\r\nCPU times: user 24 s, sys: 8.82 s, total: 32.8 s\r\nWall time: 1min 15s\r\nOut[4]: Series([], dtype: float64)\r\n```\r\n\r\n**What you expected to happen**:\r\nFrom my interpretation of #8692 we should get the same performance as\r\n```\r\n%%time\r\ndd.read_parquet(\r\n     \"s3://nyc-tlc/trip data/fhv_tripdata_2015*.parquet\",\r\n      columns=[]\r\n).sum().compute()\r\nCPU times: user 147 ms, sys: 20.6 ms, total: 167 ms\r\nWall time: 706 ms\r\nOut[5]: Series([], dtype: float64)\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.05.0\r\n- Python version: 3.9.12\r\n- PyArrow version: 8.0.0\r\n\r\nHave not yet checked this behavior for any past dask versions.\r\n\r\ncc: @rjzamora @martindurant @jcrist from #8692", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9104/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9104/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9086", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9086/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9086/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9086/events", "html_url": "https://github.com/dask/dask/issues/9086", "id": 1235912676, "node_id": "I_kwDOAbcwm85Jqofk", "number": 9086, "title": "How do I initialize processes in `dask`'s multi-process scheduler?", "user": {"login": "ParticularMiner", "id": 78448465, "node_id": "MDQ6VXNlcjc4NDQ4NDY1", "avatar_url": "https://avatars.githubusercontent.com/u/78448465?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ParticularMiner", "html_url": "https://github.com/ParticularMiner", "followers_url": "https://api.github.com/users/ParticularMiner/followers", "following_url": "https://api.github.com/users/ParticularMiner/following{/other_user}", "gists_url": "https://api.github.com/users/ParticularMiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/ParticularMiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ParticularMiner/subscriptions", "organizations_url": "https://api.github.com/users/ParticularMiner/orgs", "repos_url": "https://api.github.com/users/ParticularMiner/repos", "events_url": "https://api.github.com/users/ParticularMiner/events{/privacy}", "received_events_url": "https://api.github.com/users/ParticularMiner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386719400, "node_id": "MDU6TGFiZWwzODY3MTk0MDA=", "url": "https://api.github.com/repos/dask/dask/labels/scheduler", "name": "scheduler", "color": "D10945", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-05-14T08:17:41Z", "updated_at": "2022-05-19T20:29:52Z", "closed_at": "2022-05-19T20:29:52Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The following code-snippet works for single and multi-threaded schedulers.  But not for multi-process schedulers.  And probably not for distributed-memory schedulers either.\r\n```python\r\npims.ImageIOReader.class_priority = 100  # we set this very high in order to force dask-image's imread() to use this reader [via pims.open()]\r\nrgb_frames = dask_image.imread.imread('/path/to/video/file.mpg')  # uses ImageIOReader\r\n\r\nrgb_frames.compute(scheduler='single-threaded')  # works\r\nrgb_frames.compute(scheduler='threading')  # works\r\nrgb_frames.compute(scheduler='processes')  # does not work\r\n```\r\n\r\n_Originally posted by @ParticularMiner in https://github.com/dask/dask-image/issues/262#issuecomment-1125729240_", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9086/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9086/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9072", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9072/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9072/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9072/events", "html_url": "https://github.com/dask/dask/issues/9072", "id": 1233995988, "node_id": "I_kwDOAbcwm85JjUjU", "number": 9072, "title": "Msgpack TypeError when performing dask-geopandas sjoin", "user": {"login": "rrpelgrim", "id": 68642378, "node_id": "MDQ6VXNlcjY4NjQyMzc4", "avatar_url": "https://avatars.githubusercontent.com/u/68642378?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rrpelgrim", "html_url": "https://github.com/rrpelgrim", "followers_url": "https://api.github.com/users/rrpelgrim/followers", "following_url": "https://api.github.com/users/rrpelgrim/following{/other_user}", "gists_url": "https://api.github.com/users/rrpelgrim/gists{/gist_id}", "starred_url": "https://api.github.com/users/rrpelgrim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rrpelgrim/subscriptions", "organizations_url": "https://api.github.com/users/rrpelgrim/orgs", "repos_url": "https://api.github.com/users/rrpelgrim/repos", "events_url": "https://api.github.com/users/rrpelgrim/events{/privacy}", "received_events_url": "https://api.github.com/users/rrpelgrim/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2022-05-12T13:34:12Z", "updated_at": "2022-05-19T16:27:28Z", "closed_at": "2022-05-19T16:27:28Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**What happened**:\r\nPerforming a spatial join with `dask-geopandas` fails with a `msgpack` TypeError.\r\n\r\n**Minimal Complete Verifiable Example**:\r\nNot quite an MCVE, but the code below produces the error. Notebook + environment.yml [here](https://github.com/coiled/coiled-resources/blob/rrp-spatialjoin/spatial-join/debugging.ipynb).\r\n\r\n```python\r\nfrom coiled.v2 import Cluster\r\n\r\ncluster = Cluster(\r\n    name=\"spatial-join\",\r\n    software=\"coiled-examples/spatial-join\",\r\n    n_workers=50,\r\n    worker_memory=\"16Gib\",\r\n)\r\n\r\nfrom distributed import Client\r\nclient = Client(cluster)\r\n\r\nimport dask.dataframe as dd\r\n\r\nddf = dd.read_parquet(\r\n    \"s3://coiled-datasets/dask-book/nyc-tlc/2009-2013/*\",\r\n    engine=\"pyarrow\",\r\n    storage_options={\"anon\": True},\r\n)\r\n\r\nimport dask_geopandas\r\n\r\nddf = ddf.set_geometry(\r\n    dask_geopandas.points_from_xy(ddf, \"pickup_longitude\", \"pickup_latitude\"),\r\n)\r\n\r\nddf = ddf.set_crs(4326)\r\n\r\nimport geopandas as gpd\r\n\r\nngbhoods = gpd.read_file(\r\n    \"CHS_2009_DOHMH_2010B/CHS_2009_DOHMH_2010B.shp\"\r\n)\r\nngbhoods = ngbhoods[[\"FIRST_UHF_\", \"UHF_CODE\", \"geometry\"]]\r\nngbhoods = ngbhoods[:34]\r\nngbhoods = ngbhoods.to_crs(epsg=4326)\r\n\r\njoined = ddf.sjoin(ngbhoods, predicate=\"within\")\r\n\r\njoined1.head()\r\n```\r\n\r\nTRACEBACK:\r\n```\r\ndistributed.protocol.core - CRITICAL - Failed to Serialize\r\nTraceback (most recent call last):\r\n  File \"/Users/rpelgrim/mambaforge/envs/dask-dataframe/lib/python3.9/site-packages/distributed/protocol/core.py\", line 76, in dumps\r\n    frames[0] = msgpack.dumps(msg, default=_encode_default, use_bin_type=True)\r\n  File \"/Users/rpelgrim/mambaforge/envs/dask-dataframe/lib/python3.9/site-packages/msgpack/__init__.py\", line 35, in packb\r\n    return Packer(**kwargs).pack(o)\r\n  File \"msgpack/_packer.pyx\", line 294, in msgpack._cmsgpack.Packer.pack\r\n  File \"msgpack/_packer.pyx\", line 300, in msgpack._cmsgpack.Packer.pack\r\n  File \"msgpack/_packer.pyx\", line 297, in msgpack._cmsgpack.Packer.pack\r\n  File \"msgpack/_packer.pyx\", line 264, in msgpack._cmsgpack.Packer._pack\r\n  File \"msgpack/_packer.pyx\", line 231, in msgpack._cmsgpack.Packer._pack\r\n  File \"msgpack/_packer.pyx\", line 231, in msgpack._cmsgpack.Packer._pack\r\n  File \"msgpack/_packer.pyx\", line 264, in msgpack._cmsgpack.Packer._pack\r\n  File \"msgpack/_packer.pyx\", line 231, in msgpack._cmsgpack.Packer._pack\r\n  File \"msgpack/_packer.pyx\", line 231, in msgpack._cmsgpack.Packer._pack\r\n  File \"msgpack/_packer.pyx\", line 231, in msgpack._cmsgpack.Packer._pack\r\n  File \"msgpack/_packer.pyx\", line 264, in msgpack._cmsgpack.Packer._pack\r\n  File \"msgpack/_packer.pyx\", line 264, in msgpack._cmsgpack.Packer._pack\r\n  File \"msgpack/_packer.pyx\", line 291, in msgpack._cmsgpack.Packer._pack\r\nTypeError: can not serialize 'numpy.int64' object\r\ndistributed.comm.utils - INFO - Unserializable Message: [{'op': 'update-graph-hlg', 'hlg': {'layers': [{'__module__': 'dask.blockwise', '__name__': 'Blockwise', 'state': {'output': '_set_crs-6ca0659b532951365eb2f3c74d7d5dda', 'output_indices': ('.0',), 'func': b'\\x80\\x04\\x95\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x8c\\x11dask.optimization\\x94\\x8c\\x10SubgraphCallable\\x94\\x93\\x94(}\\x94(\\x8c)_set_crs-6ca0659b532951365eb2f3c74d7d5dda\\x94\\x8cEpoints_from_xy-set_geometry-_set_crs-6ca0659b532951365eb2f3c74d7d5dda\\x94\\x8c0read-parquet-520df5ddd4d8ac310c949ff50485dcbb_.\r\n```\r\n\r\n**Anything else we need to know?**:\r\n- Paired with @crusaderky briefly. We confirmed that `dd.from_pandas(ngbhoods, npartitions=1).compute()` works so it can make a roundtrip fine. His first instinct is that something is likely off in `dask.dataframe` where it's letting `numpy.int64` slip to `msgpack`.\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.01.0\r\n- Python version: 3.9.7\r\n- Operating System: MacOS\r\n- Install method (conda, pip, source): conda\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9072/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9072/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9058", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9058/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9058/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9058/events", "html_url": "https://github.com/dask/dask/issues/9058", "id": 1230367278, "node_id": "I_kwDOAbcwm85JVeou", "number": 9058, "title": "New Collections protocol breaks xarray objects", "user": {"login": "dcherian", "id": 2448579, "node_id": "MDQ6VXNlcjI0NDg1Nzk=", "avatar_url": "https://avatars.githubusercontent.com/u/2448579?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dcherian", "html_url": "https://github.com/dcherian", "followers_url": "https://api.github.com/users/dcherian/followers", "following_url": "https://api.github.com/users/dcherian/following{/other_user}", "gists_url": "https://api.github.com/users/dcherian/gists{/gist_id}", "starred_url": "https://api.github.com/users/dcherian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dcherian/subscriptions", "organizations_url": "https://api.github.com/users/dcherian/orgs", "repos_url": "https://api.github.com/users/dcherian/repos", "events_url": "https://api.github.com/users/dcherian/events{/privacy}", "received_events_url": "https://api.github.com/users/dcherian/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1342304743, "node_id": "MDU6TGFiZWwxMzQyMzA0NzQz", "url": "https://api.github.com/repos/dask/dask/labels/core", "name": "core", "color": "000000", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}, {"id": 3798450415, "node_id": "LA_kwDOAbcwm87iZ8Dv", "url": "https://api.github.com/repos/dask/dask/labels/p1", "name": "p1", "color": "ff5233", "default": false, "description": "Affects a large population and inhibits work"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-05-09T23:14:44Z", "updated_at": "2022-05-10T14:30:47Z", "closed_at": "2022-05-10T14:30:47Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The recent merge of the new Collections protocol (#8674) broke Xarray's tests (https://github.com/pydata/xarray/issues/6578)\r\n\r\nXarray objects [return None](https://github.com/pydata/xarray/blob/4b76831124f8cd11463c9e4ecfdc6842654cf810/xarray/core/dataset.py#L701-L714) from `__dask_graph__` if there no dask arrays being wrapped.\r\n\r\nIt seems like the current version of `is_dask_collection` only checks for the presence of `__dask_graph__`. Xarray objects are a case where this check is not sufficient (they look like dask collections in general, you can call `dask.visualize` and `dask.compute` on xarray objects).\r\n\r\nIt isn't clear to me that there is a good solution other than explicitly checking the return value in `is_dask_collection` but if there is something we could do on the Xarray side, please let us know!\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9058/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9058/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9046", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9046/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9046/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9046/events", "html_url": "https://github.com/dask/dask/issues/9046", "id": 1227422234, "node_id": "I_kwDOAbcwm85JKPoa", "number": 9046, "title": "Implicit data type conversion after concat", "user": {"login": "patefon", "id": 1763680, "node_id": "MDQ6VXNlcjE3NjM2ODA=", "avatar_url": "https://avatars.githubusercontent.com/u/1763680?v=4", "gravatar_id": "", "url": "https://api.github.com/users/patefon", "html_url": "https://github.com/patefon", "followers_url": "https://api.github.com/users/patefon/followers", "following_url": "https://api.github.com/users/patefon/following{/other_user}", "gists_url": "https://api.github.com/users/patefon/gists{/gist_id}", "starred_url": "https://api.github.com/users/patefon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/patefon/subscriptions", "organizations_url": "https://api.github.com/users/patefon/orgs", "repos_url": "https://api.github.com/users/patefon/repos", "events_url": "https://api.github.com/users/patefon/events{/privacy}", "received_events_url": "https://api.github.com/users/patefon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3468123446, "node_id": "LA_kwDOAbcwm87Ot102", "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention", "name": "needs attention", "color": "6d626c", "default": false, "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "ncclementi", "id": 7526622, "node_id": "MDQ6VXNlcjc1MjY2MjI=", "avatar_url": "https://avatars.githubusercontent.com/u/7526622?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ncclementi", "html_url": "https://github.com/ncclementi", "followers_url": "https://api.github.com/users/ncclementi/followers", "following_url": "https://api.github.com/users/ncclementi/following{/other_user}", "gists_url": "https://api.github.com/users/ncclementi/gists{/gist_id}", "starred_url": "https://api.github.com/users/ncclementi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ncclementi/subscriptions", "organizations_url": "https://api.github.com/users/ncclementi/orgs", "repos_url": "https://api.github.com/users/ncclementi/repos", "events_url": "https://api.github.com/users/ncclementi/events{/privacy}", "received_events_url": "https://api.github.com/users/ncclementi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ncclementi", "id": 7526622, "node_id": "MDQ6VXNlcjc1MjY2MjI=", "avatar_url": "https://avatars.githubusercontent.com/u/7526622?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ncclementi", "html_url": "https://github.com/ncclementi", "followers_url": "https://api.github.com/users/ncclementi/followers", "following_url": "https://api.github.com/users/ncclementi/following{/other_user}", "gists_url": "https://api.github.com/users/ncclementi/gists{/gist_id}", "starred_url": "https://api.github.com/users/ncclementi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ncclementi/subscriptions", "organizations_url": "https://api.github.com/users/ncclementi/orgs", "repos_url": "https://api.github.com/users/ncclementi/repos", "events_url": "https://api.github.com/users/ncclementi/events{/privacy}", "received_events_url": "https://api.github.com/users/ncclementi/received_events", "type": "User", "site_admin": false}, {"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2022-05-06T05:02:55Z", "updated_at": "2022-06-28T17:22:42Z", "closed_at": "2022-06-28T17:22:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What happened**: \r\nDask implicitly converts column datatypes after DF's concat, when one of DF's is empty.\r\n\r\n**What you expected to happen**:\r\nWarning (at-least) or exception if dtype converted or same dtype for columns (this how it works in Pandas)\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\n\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n\r\nsample_data = [\r\n  {'col_int64': 100},\r\n  {'col_int64': 200},\r\n  {'col_int64': 300},\r\n]\r\n\r\ndef main():\r\n\r\n  # let's dummy pandas df with int64 col\r\n  pandas_df = pd.DataFrame(sample_data, dtype='int64')\r\n  assert pandas_df.dtypes['col_int64'] == 'int64'\r\n\r\n  print('\\nPandas :: Types before DF concat:')\r\n  print(pandas_df.dtypes)\r\n  print()\r\n\r\n  # init empty pandas dataframe\r\n  empty_pandas_df = pd.DataFrame([])\r\n\r\n  # concat dummy dataframe with empty\r\n  df = pd.concat([pandas_df, empty_pandas_df])\r\n  assert df.dtypes['col_int64'] == 'int64'\r\n\r\n  print('\\nPandas :: after DF concat:')\r\n  print(df.dtypes)\r\n  print()\r\n\r\n  # now let's try Dask\r\n  dask_df = dd.from_pandas(pandas_df, npartitions=1)\r\n  assert dask_df.dtypes['col_int64'] == 'int64'\r\n\r\n  print('\\nDask :: Types before DF concat:')\r\n  print(dask_df.dtypes)\r\n  print()\r\n\r\n  # init empty dask\r\n  empty_dask_df = dd.from_pandas(empty_pandas_df, npartitions=1)\r\n\r\n  # concat with empty\r\n  df = dd.concat([dask_df, empty_dask_df])\r\n  print('\\nDask :: Types after DF concat:')\r\n  print(df.dtypes)\r\n  print()\r\n  if df.dtypes['col_int64'] != 'int64':\r\n    print(f'Silently converted to {df.dtypes[\"col_int64\"]}\\n\\n')\r\n\r\nmain()\r\n\r\n### output:\r\n\r\n# Pandas :: Types before DF concat:\r\n# col_int64    int64\r\n# dtype: object\r\n\r\n\r\n# Pandas :: after DF concat:\r\n# col_int64    int64\r\n# dtype: object\r\n\r\n\r\n# Dask :: Types before DF concat:\r\n# col_int64    int64\r\n# dtype: object\r\n\r\n\r\n# Dask :: Types after DF concat:\r\n# col_int64    float64\r\n# dtype: object\r\n\r\n# Silently converted to float64\r\n\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version:  2022.5.0\r\n- Python version: 3.9.10\r\n- Operating System: OSX\r\n- Install method (conda, pip, source): pip", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9046/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9046/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9026", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9026/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9026/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9026/events", "html_url": "https://github.com/dask/dask/issues/9026", "id": 1226498978, "node_id": "I_kwDOAbcwm85JGuOi", "number": 9026, "title": "Bug in array assignment when the mask has been hardened", "user": {"login": "davidhassell", "id": 8126576, "node_id": "MDQ6VXNlcjgxMjY1NzY=", "avatar_url": "https://avatars.githubusercontent.com/u/8126576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidhassell", "html_url": "https://github.com/davidhassell", "followers_url": "https://api.github.com/users/davidhassell/followers", "following_url": "https://api.github.com/users/davidhassell/following{/other_user}", "gists_url": "https://api.github.com/users/davidhassell/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidhassell/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidhassell/subscriptions", "organizations_url": "https://api.github.com/users/davidhassell/orgs", "repos_url": "https://api.github.com/users/davidhassell/repos", "events_url": "https://api.github.com/users/davidhassell/events{/privacy}", "received_events_url": "https://api.github.com/users/davidhassell/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-05-05T10:38:21Z", "updated_at": "2022-05-05T15:12:48Z", "closed_at": "2022-05-05T15:12:48Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hello,\r\n\r\n**What happened**:\r\n\r\nIt's quite a particular set of circumstances: For an integer array with a hardened mask, when assigning the numpy masked constant to a range of two or more elements that already includes a masked value, then a datatype casting error is raised.\r\n\r\nEverything is fine if instead the mask is soft and/or the array is of floats.\r\n\r\n**What you expected to happen**:\r\n\r\nThe \"re-masking\" of the already masked element should have worked silently.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.array as da\r\nimport numpy as np\r\n\r\n# Numpy works:\r\na = np.ma.array([1, 2, 3, 4], dtype=int)\r\na.harden_mask()\r\na[0] = np.ma.masked\r\na[0:2] = np.ma.masked\r\nprint('NUMPY:', repr(a))\r\n# NUMPY: masked_array(data=[--, --, 3, 4],\r\n#              mask=[ True,  True,  True,  True],\r\n#        fill_value=999999,\r\n#             dtype=int64)\r\n\r\n# The equivalent dask operations don't work:\r\na = np.ma.array([1, 2, 3, 4], dtype=int)\r\na.harden_mask()\r\nx = da.from_array(a)\r\nx[0] = np.ma.masked\r\nx[0:2] = np.ma.masked\r\nprint('DASK :', repr(x.compute()))\r\n# Traceback\r\n#     ...\r\n# TypeError: Cannot cast scalar from dtype('float64') to dtype('int64') according to the rule 'same_kind'\r\n```\r\n\r\n\r\n**Anything else we need to know?**:\r\n\r\nI don't fully appreciate what numpy is doing here, other than when the peculiar circumstance are met, it appears to be sensitive as to whether or not it is assigning a scalar or a 0-d array to the data beneath the mask. A mismatch in data types with the assignment value only seems to matter if the value is a 0-d array, rather than a scalar:\r\n\r\n```python\r\na = np.ma.array([1, 2, 3, 4], dtype=int)\r\na.harden_mask()\r\na[0] = np.ma.masked_all(())    # 0-d float, different to dtype of a\r\na[0:2] = np.ma.masked_all(())  # 0-d float, different to dtype of a\r\nprint('NUMPY :', repr(a))\r\n# Traceback\r\n#     ...\r\n# TypeError: Cannot cast scalar from dtype('float64') to dtype('int64') according to the rule 'same_kind'\r\n```\r\n\r\n```python\r\na = np.ma.array([1, 2, 3, 4], dtype=int)\r\na.harden_mask()\r\na[0] = np.ma.masked_all((), dtype=int)    # 0-d int, same dtype as a\r\na[0:2] = np.ma.masked_all((), dtype=int)  # 0-d int, same dtype as a\r\nprint('NUMPY :', repr(a))\r\n# NUMPY: masked_array(data=[--, --, 3, 4],\r\n#              mask=[ True,  True,  True,  True],\r\n#        fill_value=999999,\r\n#             dtype=int64)\r\n```\r\nThis is relevant because dask doesn't actually assign `np.ma.masked` (which is a float), rather it replaces it with  `np.ma.masked_all(())` (https://github.com/dask/dask/blob/2022.05.0/dask/array/core.py#L1816-L1818) when it _should_ replace it with `np.ma.masked_all((), dtype=self.dtype)` instead:\r\n\r\n```python\r\n# Dask works here:\r\na = np.ma.array([1, 2, 3, 4], dtype=int)\r\na.harden_mask()\r\nx = da.from_array(a)\r\nx[0] = np.ma.masked_all((), dtype=int)\r\nx[0:2] = np.ma.masked_all((), dtype=int)\r\nprint('DASK :', repr(x.compute()))\r\n# DASK : masked_array(data=[--, --, 3, 4],\r\n#              mask=[ True,  True, False, False],\r\n#        fill_value=999999)\r\n```\r\n\r\nPR to implement this change to follow ...\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.05.0\r\n- Python version: Python 3.9.5 \r\n- Operating System: Linux\r\n- Install method (conda, pip, source): pip", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9026/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9026/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9018", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9018/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9018/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9018/events", "html_url": "https://github.com/dask/dask/issues/9018", "id": 1224495858, "node_id": "I_kwDOAbcwm85I_FLy", "number": 9018, "title": "dataframe assert_eq sorts the inputs when asserting equality", "user": {"login": "ayushdg", "id": 19949207, "node_id": "MDQ6VXNlcjE5OTQ5MjA3", "avatar_url": "https://avatars.githubusercontent.com/u/19949207?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ayushdg", "html_url": "https://github.com/ayushdg", "followers_url": "https://api.github.com/users/ayushdg/followers", "following_url": "https://api.github.com/users/ayushdg/following{/other_user}", "gists_url": "https://api.github.com/users/ayushdg/gists{/gist_id}", "starred_url": "https://api.github.com/users/ayushdg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ayushdg/subscriptions", "organizations_url": "https://api.github.com/users/ayushdg/orgs", "repos_url": "https://api.github.com/users/ayushdg/repos", "events_url": "https://api.github.com/users/ayushdg/events{/privacy}", "received_events_url": "https://api.github.com/users/ayushdg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2022-05-03T19:00:19Z", "updated_at": "2022-06-07T14:47:03Z", "closed_at": "2022-06-07T14:47:03Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\n`dask.dataframe.utils.assert_eq` sorts the two inputs when asserting equality between two dataframes.\r\n\r\nThis can be problematic in tests such as this where the tests would pass irrespective of whether the sort succeeded or not. https://github.com/dask/dask/blob/bc43d692e8f5fc55e6d81c91053598bd89f79267/dask/dataframe/tests/test_shuffle.py#L1353 \r\n\r\n\r\n**What you expected to happen**:\r\nOne possible solution could be to add a param to the `assert_eq` method that allows to control whether we ignore ordering or not and sort based on that. The default for now could be set to `ignore_ordering=True` so as to not change existing behavior.\r\n\r\nRelevant modification here: https://github.com/dask/dask/blob/4d6a5f08c45be56302f696ca4ef6038a1cd1e734/dask/dataframe/utils.py#L549\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nfrom dask import dataframe as dd\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\n\r\ndf = pd.DataFrame()\r\ndf[\"a\"] = [5,4,3,2,1] * 20\r\ndf[\"b\"] = np.arange(100,  200)\r\nddf = dd.from_pandas(df, npartitions=10)\r\nsorted_ddf = ddf.sort_values([\"a\"])\r\ndd.assert_eq(df, sorted_ddf)\r\n```\r\n\r\n**Anything else we need to know?**:\r\nN/A\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.4.1\r\n- Python version: 3.8\r\n- Operating System: Ubuntu 20.04\r\n- Install method (conda, pip, source): conda\r\n\r\n<!-- If you are reporting an issue such as scale stability, cluster deadlock.\r\nPlease provide a cluster dump state with this issue, by running client.dump_cluster_state()\r\n\r\nhttps://distributed.dask.org/en/stable/api.html?highlight=dump_cluster_state#distributed.Client.dump_cluster_state\r\n\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9018/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9018/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9016", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9016/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9016/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9016/events", "html_url": "https://github.com/dask/dask/issues/9016", "id": 1224226030, "node_id": "I_kwDOAbcwm85I-DTu", "number": 9016, "title": "cannot use bind after map_blocks with block_id argument", "user": {"login": "bjudkewitz", "id": 18418343, "node_id": "MDQ6VXNlcjE4NDE4MzQz", "avatar_url": "https://avatars.githubusercontent.com/u/18418343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bjudkewitz", "html_url": "https://github.com/bjudkewitz", "followers_url": "https://api.github.com/users/bjudkewitz/followers", "following_url": "https://api.github.com/users/bjudkewitz/following{/other_user}", "gists_url": "https://api.github.com/users/bjudkewitz/gists{/gist_id}", "starred_url": "https://api.github.com/users/bjudkewitz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bjudkewitz/subscriptions", "organizations_url": "https://api.github.com/users/bjudkewitz/orgs", "repos_url": "https://api.github.com/users/bjudkewitz/repos", "events_url": "https://api.github.com/users/bjudkewitz/events{/privacy}", "received_events_url": "https://api.github.com/users/bjudkewitz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-05-03T15:05:53Z", "updated_at": "2022-05-13T07:58:46Z", "closed_at": "2022-05-12T12:45:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "While executing code like in the minimal example below (using local scheduler)\r\n```\r\nfrom dask.graph_manipulation import bind\r\nimport dask.array as da\r\n\r\na = da.zeros((2,3,4), dtype='int')\r\nb = a.map_blocks(lambda x, block_id=None: x)\r\nbind(b, a)\r\n```\r\nI get an unexpected error\r\n<details>\r\n<summary>Click for error message</summary>\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nInput In [839], in <cell line: 3>()\r\n      1 d1 = da.ones((3,4,6), chunks=(-1,1,2), dtype='float32')\r\n      2 d12 = d1.map_blocks(lambda x: x)\r\n----> 3 out, cp = accumulate_blocks(d1.astype('float32'), np.add, 1)\r\n      4 out\r\n\r\nInput In [836], in accumulate_blocks(arr, loop_fcn, axis)\r\n     41 #arr.map_blocks(block_fcn, dtype='bool', meta=np.array(True), chunks=(1,)*arr.ndim)\r\n     42 #return temp0, out\r\n     43 after_block_fcn = bind(out, out)\r\n---> 44 out = bind(out.map_blocks(retrieve, dtype=dtype, chunks=tuple(newchunks)), after_block_fcn)\r\n     45 return out\r\n\r\nFile ~/miniconda3/envs/work_env2/lib/python3.9/site-packages/dask/graph_manipulation.py:300, in bind(children, parents, omit, seed, assume_layers, split_every)\r\n    296     omit_keys = {key for coll in omit for key in coll.__dask_graph__()}\r\n    298 unpacked_children, repack = unpack_collections(children)\r\n    299 return repack(\r\n--> 300     [\r\n    301         _bind_one(child, blocker, omit_layers, omit_keys, seed)\r\n    302         for child in unpacked_children\r\n    303     ]\r\n    304 )[0]\r\n\r\nFile ~/miniconda3/envs/work_env2/lib/python3.9/site-packages/dask/graph_manipulation.py:301, in <listcomp>(.0)\r\n    296     omit_keys = {key for coll in omit for key in coll.__dask_graph__()}\r\n    298 unpacked_children, repack = unpack_collections(children)\r\n    299 return repack(\r\n    300     [\r\n--> 301         _bind_one(child, blocker, omit_layers, omit_keys, seed)\r\n    302         for child in unpacked_children\r\n    303     ]\r\n    304 )[0]\r\n\r\nFile ~/miniconda3/envs/work_env2/lib/python3.9/site-packages/dask/graph_manipulation.py:372, in _bind_one(child, blocker, omit_layers, omit_keys, seed)\r\n    369 layers_to_clone |= layer_deps_to_clone\r\n    370 layers_to_copy_verbatim |= layer_deps_to_omit\r\n--> 372 new_layers[new_layer_name], is_bound = layer.clone(\r\n    373     keys=clone_keys, seed=seed, bind_to=blocker_key\r\n    374 )\r\n    375 new_dep = {\r\n    376     clone_key(dep, seed=seed) for dep in layer_deps_to_clone\r\n    377 } | layer_deps_to_omit\r\n    378 if is_bound:\r\n\r\nFile ~/miniconda3/envs/work_env2/lib/python3.9/site-packages/dask/blockwise.py:767, in Blockwise.clone(self, keys, seed, bind_to)\r\n    765 indices = []\r\n    766 for k, idxv in self.indices:\r\n--> 767     if k in names:\r\n    768         is_leaf = False\r\n    769         k = clone_key(k, seed)\r\n\r\nTypeError: unhashable type: 'list'\r\n</details>\r\n\r\nThis error disappears when removing the block_id argument from the map function:\r\n\r\n```\r\na = da.zeros((2,3,4), dtype='int')\r\nb = a.map_blocks(lambda x: x)  #instead of: lambda x, block_id=None: x\r\nbind(b, a)\r\n```\r\n\r\nUnlike in the minimal example above, I do need block_id, so removing this argument is not an option. How can the error be explained?", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9016/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9016/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9006", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9006/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9006/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9006/events", "html_url": "https://github.com/dask/dask/issues/9006", "id": 1221799934, "node_id": "I_kwDOAbcwm85I0y_-", "number": 9006, "title": "`dd.to_timedelta` fails", "user": {"login": "SultanOrazbayev", "id": 20208402, "node_id": "MDQ6VXNlcjIwMjA4NDAy", "avatar_url": "https://avatars.githubusercontent.com/u/20208402?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SultanOrazbayev", "html_url": "https://github.com/SultanOrazbayev", "followers_url": "https://api.github.com/users/SultanOrazbayev/followers", "following_url": "https://api.github.com/users/SultanOrazbayev/following{/other_user}", "gists_url": "https://api.github.com/users/SultanOrazbayev/gists{/gist_id}", "starred_url": "https://api.github.com/users/SultanOrazbayev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SultanOrazbayev/subscriptions", "organizations_url": "https://api.github.com/users/SultanOrazbayev/orgs", "repos_url": "https://api.github.com/users/SultanOrazbayev/repos", "events_url": "https://api.github.com/users/SultanOrazbayev/events{/privacy}", "received_events_url": "https://api.github.com/users/SultanOrazbayev/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pavithraes", "id": 33131404, "node_id": "MDQ6VXNlcjMzMTMxNDA0", "avatar_url": "https://avatars.githubusercontent.com/u/33131404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithraes", "html_url": "https://github.com/pavithraes", "followers_url": "https://api.github.com/users/pavithraes/followers", "following_url": "https://api.github.com/users/pavithraes/following{/other_user}", "gists_url": "https://api.github.com/users/pavithraes/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithraes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithraes/subscriptions", "organizations_url": "https://api.github.com/users/pavithraes/orgs", "repos_url": "https://api.github.com/users/pavithraes/repos", "events_url": "https://api.github.com/users/pavithraes/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithraes/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2022-04-30T10:40:22Z", "updated_at": "2022-06-17T08:05:17Z", "closed_at": "2022-05-02T21:11:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I am trying to convert a column into timedelta, it's possible to do a workaround using pandas, but also wanted to flag the bug here:\r\n\r\n```python\r\nfrom dask.dataframe import to_timedelta\r\nfrom pandas import to_timedelta as to_timedelta_pandas\r\n\r\ntest = \"1 day 1 hour\"\r\nprint(to_timedelta_pandas(test))  # 1 days 01:00:00\r\nprint(to_timedelta(test))  # fails\r\n```\r\n\r\nHere's the traceback:\r\n\r\n```pytb\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\nInput In [108], in <cell line: 6>()\r\n      4 test = \"1 day 1 hour\"\r\n      5 print(to_timedelta_pandas(test)) # 1 days 01:00:00\r\n----> 6 print(to_timedelta(test))\r\n\r\nFile ~/miniconda/envs/coiled_to_datetime/lib/python3.10/site-packages/dask/dataframe/core.py:7438, in to_timedelta(arg, unit, errors)\r\n   7435 @wraps(pd.to_timedelta)\r\n   7436 def to_timedelta(arg, unit=\"ns\", errors=\"raise\"):\r\n   7437     meta = pd.Series([pd.Timedelta(1, unit=unit)])\r\n-> 7438     return map_partitions(pd.to_timedelta, arg, unit=unit, errors=errors, meta=meta)\r\n\r\nFile ~/miniconda/envs/coiled_to_datetime/lib/python3.10/site-packages/dask/dataframe/core.py:6374, in map_partitions(func, meta, enforce_metadata, transform_divisions, align_dataframes, *args, **kwargs)\r\n   6371         simple = False\r\n   6373 if align_dataframes:\r\n-> 6374     divisions = dfs[0].divisions\r\n   6375 else:\r\n   6376     # Unaligned, dfs is a mix of 1 partition and 1+ partition dataframes,\r\n   6377     # use longest divisions found\r\n   6378     divisions = max((d.divisions for d in dfs), key=len)\r\n\r\nIndexError: list index out of range\r\n```\r\n\r\nMy guess is that the bug is in these lines (assuming  default `unit` to be `ns`):\r\n\r\nhttps://github.com/dask/dask/blob/2869a85a032c501db86f781bd6cc990b79475fe3/dask/dataframe/core.py#L7435-L7438\r\n\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.4.2\r\n- Python version: 3.10\r\n- Install method (conda, pip, source): conda", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9006/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9006/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/9003", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/9003/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/9003/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/9003/events", "html_url": "https://github.com/dask/dask/issues/9003", "id": 1221066452, "node_id": "I_kwDOAbcwm85Ix_7U", "number": 9003, "title": "Unpredictable TypeError when computing on dataframe with datetime column", "user": {"login": "JnsLns", "id": 45421730, "node_id": "MDQ6VXNlcjQ1NDIxNzMw", "avatar_url": "https://avatars.githubusercontent.com/u/45421730?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JnsLns", "html_url": "https://github.com/JnsLns", "followers_url": "https://api.github.com/users/JnsLns/followers", "following_url": "https://api.github.com/users/JnsLns/following{/other_user}", "gists_url": "https://api.github.com/users/JnsLns/gists{/gist_id}", "starred_url": "https://api.github.com/users/JnsLns/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JnsLns/subscriptions", "organizations_url": "https://api.github.com/users/JnsLns/orgs", "repos_url": "https://api.github.com/users/JnsLns/repos", "events_url": "https://api.github.com/users/JnsLns/events{/privacy}", "received_events_url": "https://api.github.com/users/JnsLns/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2022-04-29T15:18:05Z", "updated_at": "2022-12-06T17:31:56Z", "closed_at": "2022-12-06T17:31:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "This is a very strange error that I cannot provide lots of information for. I have tried various conversions of the time columns (e.g. to int64) but the result does not change. \r\n\r\n**What happened**: `TypeError` is thrown when applying `sort_values` to a very simple dataframe of datetime objects. Very minor changes in the data make the error disappear or reappear  (single digits, removing any row in the dataframe, or changing partition number). \r\n\r\n**Minimal Complete Verifiable Example**: \r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n\r\n# Completes without exception\r\ndts = pd.to_datetime(\r\n['2022-04-23 00:00:00.618000+00:00',\r\n'2022-04-23 00:00:03.199000+00:00',\r\n'2022-04-23 00:00:03.463000+00:00',\r\n'2022-04-23 00:00:02.396000+00:00',\r\n'2022-04-23 00:00:02.623000+00:01',]  # <-- Only difference to the next block is the last digit here\r\n)\r\ndf = pd.DataFrame(dict(ts=dts))\r\nddf = dd.from_pandas(df, npartitions=2)\r\nddf.sort_values(by='ts').compute()         \r\n\r\n\r\n# Throws TypeError\r\ndts = pd.to_datetime(\r\n['2022-04-23 00:00:00.618000+00:00',\r\n'2022-04-23 00:00:03.199000+00:00',\r\n'2022-04-23 00:00:03.463000+00:00',\r\n'2022-04-23 00:00:02.396000+00:00',\r\n'2022-04-23 00:00:02.623000+00:00',]\r\n)\r\ndf = pd.DataFrame(dict(ts=dts))\r\nddf = dd.from_pandas(df, npartitions=2)\r\nddf.sort_values(by='ts').compute()            # TypeError: value should be a 'Timestamp', 'NaT', or array of those. Got 'StringArray' instead.\r\n\r\n```\r\n**Anything else we need to know?**: The error originally occurred with a large dataset and many partitions, so it is not related to the small data size in the example.\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.04.1\r\n- Python version: 3.9.1\r\n- Operating System: Debian GNU/Linux 11 (bullseye)\r\n- Install method (conda, pip, source): pip\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/9003/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/9003/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8999", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8999/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8999/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8999/events", "html_url": "https://github.com/dask/dask/issues/8999", "id": 1220624014, "node_id": "I_kwDOAbcwm85IwT6O", "number": 8999, "title": "Results of dask.multi.merge_asof depends on npartitions", "user": {"login": "JnsLns", "id": 45421730, "node_id": "MDQ6VXNlcjQ1NDIxNzMw", "avatar_url": "https://avatars.githubusercontent.com/u/45421730?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JnsLns", "html_url": "https://github.com/JnsLns", "followers_url": "https://api.github.com/users/JnsLns/followers", "following_url": "https://api.github.com/users/JnsLns/following{/other_user}", "gists_url": "https://api.github.com/users/JnsLns/gists{/gist_id}", "starred_url": "https://api.github.com/users/JnsLns/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JnsLns/subscriptions", "organizations_url": "https://api.github.com/users/JnsLns/orgs", "repos_url": "https://api.github.com/users/JnsLns/repos", "events_url": "https://api.github.com/users/JnsLns/events{/privacy}", "received_events_url": "https://api.github.com/users/JnsLns/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3468123446, "node_id": "LA_kwDOAbcwm87Ot102", "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention", "name": "needs attention", "color": "6d626c", "default": false, "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-04-29T11:49:23Z", "updated_at": "2022-09-15T20:27:59Z", "closed_at": "2022-09-15T20:27:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What happened**: Results of `merge_asof` differ depending on npartitions of the dataframe. In particular, it seems the result misses rows when the number of partitions is equal to or greater than the number of rows in the dataframe. (I am aware that setting the number of partitions higher than row count does not make sense, yet I did not expect it to lead to this behavior). \r\n\r\n**What you expected to happen**: Identical results of `merge_asof` independent from npartitions of the dataframe. Or, if this issue is restricted to the case where npartitions>number of rows, an exception or warning telling the user that it may lead to undefined behavior.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n\r\ndf = pd.DataFrame(dict(ts=[pd.to_datetime('1-1-2020')]*3, foo=[1,2,3]))\r\n    \r\nfor npartitions in range(1,5):\r\n    ddf = dd.from_pandas(df, npartitions=npartitions)\r\n    result = dd.multi.merge_asof(left=ddf, right=ddf, on='ts').compute()\r\n    print(result)\r\n\r\n# Output\r\n#          ts  foo_x  foo_y\r\n# 0 2020-01-01      1      3\r\n# 1 2020-01-01      2      3\r\n# 2 2020-01-01      3      3\r\n#           ts  foo_x  foo_y\r\n# 0 2020-01-01      1      3\r\n# 1 2020-01-01      2      3\r\n# 2 2020-01-01      3      3\r\n#           ts  foo_x  foo_y\r\n# 0 2020-01-01      2      3\r\n# 1 2020-01-01      3      3\r\n#           ts  foo_x  foo_y\r\n# 0 2020-01-01      2      3\r\n# 1 2020-01-01      3      3\r\n```\r\n**What else do we need to know**: As far as I could verify, the issue only appears when the timestamps in the `on` column are identical.\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.04.1\r\n- Python version: 3.9.1\r\n- Operating System: Debian GNU/Linux 11 (bullseye)\r\n- Install method (conda, pip, source): pip\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8999/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8999/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8978", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8978/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8978/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8978/events", "html_url": "https://github.com/dask/dask/issues/8978", "id": 1214520940, "node_id": "I_kwDOAbcwm85IZB5s", "number": 8978, "title": "`Blockwise.clone` doesn't handle (iterable) literal arguments correctly", "user": {"login": "JSKenyon", "id": 6582745, "node_id": "MDQ6VXNlcjY1ODI3NDU=", "avatar_url": "https://avatars.githubusercontent.com/u/6582745?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JSKenyon", "html_url": "https://github.com/JSKenyon", "followers_url": "https://api.github.com/users/JSKenyon/followers", "following_url": "https://api.github.com/users/JSKenyon/following{/other_user}", "gists_url": "https://api.github.com/users/JSKenyon/gists{/gist_id}", "starred_url": "https://api.github.com/users/JSKenyon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JSKenyon/subscriptions", "organizations_url": "https://api.github.com/users/JSKenyon/orgs", "repos_url": "https://api.github.com/users/JSKenyon/repos", "events_url": "https://api.github.com/users/JSKenyon/events{/privacy}", "received_events_url": "https://api.github.com/users/JSKenyon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-04-25T13:33:36Z", "updated_at": "2022-05-09T14:00:47Z", "closed_at": "2022-05-09T14:00:47Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**What happened**:\r\nCalling `dask.graph_manipulation.clone` on the result of a `dask.array.blockwise` operation with a (iterable) literal argument results in a `ValueError`.\r\n\r\n**What you expected to happen**:\r\nThe `dask.graph_manipulation.clone` operation to succeed.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n```python\r\nimport dask.array as da\r\nfrom dask.graph_manipulation import clone\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    x = da.ones(10)\r\n    y = (1,)\r\n\r\n    z = da.blockwise(lambda x, y: x + y[0], \"r\",\r\n                     x, \"r\",\r\n                     y, None)\r\n\r\n    clone(z)\r\n```\r\n\r\n**Anything else we need to know?**:\r\nThe above produces:\r\n```\r\nTypeError: unhashable type: 'list'\r\n```\r\n\r\nI have traced the problem to:\r\nhttps://github.com/dask/dask/blob/1ccd1a4f96afa1fe89ea93dcfe66517319b0664d/dask/blockwise.py#L812-L817\r\n\r\nIn the above, the conditional `if k in names` causes the `ValueError` when `k` is not hashable.\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.4.1\r\n- Python version: 3.8.10\r\n- Operating System: Ubuntu 20.04\r\n- Install method (conda, pip, source): pip", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8978/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8978/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8972", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8972/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8972/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8972/events", "html_url": "https://github.com/dask/dask/pull/8972", "id": 1213179783, "node_id": "PR_kwDOAbcwm842qgmZ", "number": 8972, "title": "Stringify BlockwiseDepDict mapping values when produces_keys=True", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2156573524, "node_id": "MDU6TGFiZWwyMTU2NTczNTI0", "url": "https://api.github.com/repos/dask/dask/labels/highlevelgraph", "name": "highlevelgraph", "color": "8c24d6", "default": false, "description": "Issues relating to HighLevelGraphs."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2022-04-23T03:30:07Z", "updated_at": "2022-04-25T20:13:10Z", "closed_at": "2022-04-25T20:13:07Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/8972", "html_url": "https://github.com/dask/dask/pull/8972", "diff_url": "https://github.com/dask/dask/pull/8972.diff", "patch_url": "https://github.com/dask/dask/pull/8972.patch", "merged_at": "2022-04-25T20:13:07Z"}, "body": "Follow-up bug fix for #8852 - The recent `from_delayed` change ended up [causing a CI failure in dask_cudf](https://gpuci.gpuopenanalytics.com/job/rapidsai/job/gpuci/job/cudf/job/prb/job/cudf-gpu-test/CUDA=11.2,GPU_LABEL=driver-495,LINUX_VER=ubuntu18.04,PYTHON=3.9/7667/testReport/dask_cudf.tests/test_distributed/test_basic_True_/), because the `Delayed` object keys (those defined in the `BlockwiseDepDict` mapping) are never \"stringified\" before making it to the scheduler.  This is fine when the `Delayed`-object key is already a string. However, it is **not** okay when the `Delayed` object is created from a `DataFrame.from_delayed()` call, because the keys will be tuples in this case. \r\n\r\nThis PR adds a step to stringify the the values in the `BlockwiseDepDict` mapping when `produces_keys=True`. It also adds a relevant test.", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8972/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8972/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/8964", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8964/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8964/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8964/events", "html_url": "https://github.com/dask/dask/issues/8964", "id": 1210858264, "node_id": "I_kwDOAbcwm85ILDsY", "number": 8964, "title": "ValueError in set_index when uint32 is used and npartitions=1", "user": {"login": "martinfleis", "id": 36797143, "node_id": "MDQ6VXNlcjM2Nzk3MTQz", "avatar_url": "https://avatars.githubusercontent.com/u/36797143?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinfleis", "html_url": "https://github.com/martinfleis", "followers_url": "https://api.github.com/users/martinfleis/followers", "following_url": "https://api.github.com/users/martinfleis/following{/other_user}", "gists_url": "https://api.github.com/users/martinfleis/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinfleis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinfleis/subscriptions", "organizations_url": "https://api.github.com/users/martinfleis/orgs", "repos_url": "https://api.github.com/users/martinfleis/repos", "events_url": "https://api.github.com/users/martinfleis/events{/privacy}", "received_events_url": "https://api.github.com/users/martinfleis/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3468123446, "node_id": "LA_kwDOAbcwm87Ot102", "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention", "name": "needs attention", "color": "6d626c", "default": false, "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-04-21T10:51:22Z", "updated_at": "2022-12-06T17:33:38Z", "closed_at": "2022-12-06T17:33:38Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\ndask-geopandas CI (https://github.com/geopandas/dask-geopandas/issues/187) catched rather obscure bug affecting `set_index` if the dataframe has a single partition and it is being sorted using a Series with specific values in `uint32` dtype.\r\n\r\n**What you expected to happen**:\r\n\r\n`set_index` should normally work as it does with different dtypes or multiple partitions.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport pandas\r\nimport dask\r\n\r\ndf = pandas.DataFrame({\r\n    'name': {0: 'Fiji', 1: 'Tanzania', 2: 'W. Sahara'},\r\n    'pop_est': {0: 920938, 1: 53950935, 2: 603253}\r\n    }\r\n)\r\nby = pandas.Series([359229013, 3689290724, 1799843020], dtype='uint32')\r\nddf = dask.dataframe.from_pandas(df, npartitions=1)\r\nby = dask.dataframe.from_pandas(by, npartitions=1)\r\nddf.set_index(by)\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/var/folders/2f/fhks6w_d0k556plcv3rfmshw0000gn/T/ipykernel_55061/3509087227.py in <module>\r\n      7 ddf = dask.dataframe.from_pandas(df, npartitions=1)\r\n      8 by = dask.dataframe.from_pandas(by, npartitions=1)\r\n----> 9 ddf.set_index(by)\r\n\r\n~/mambaforge/envs/geo_dev/lib/python3.9/site-packages/dask/dataframe/core.py in set_index(***failed resolving arguments***)\r\n   4698             from dask.dataframe.shuffle import set_index\r\n   4699 \r\n-> 4700             return set_index(\r\n   4701                 self,\r\n   4702                 other,\r\n\r\n~/mambaforge/envs/geo_dev/lib/python3.9/site-packages/dask/dataframe/shuffle.py in set_index(df, index, npartitions, shuffle, compute, drop, upsample, divisions, partition_size, **kwargs)\r\n    229         ):\r\n    230             divisions = mins + [maxes[-1]]\r\n--> 231             result = set_sorted_index(df, index, drop=drop, divisions=divisions)\r\n    232             return result.map_partitions(M.sort_index)\r\n    233 \r\n\r\n~/mambaforge/envs/geo_dev/lib/python3.9/site-packages/dask/dataframe/shuffle.py in set_sorted_index(df, index, drop, divisions, **kwargs)\r\n   1103         raise ValueError(msg)\r\n   1104 \r\n-> 1105     result.divisions = tuple(divisions)\r\n   1106     return result\r\n\r\n~/mambaforge/envs/geo_dev/lib/python3.9/site-packages/dask/dataframe/core.py in __setattr__(self, key, value)\r\n   4442             self[key] = value\r\n   4443         else:\r\n-> 4444             object.__setattr__(self, key, value)\r\n   4445 \r\n   4446     def __getattr__(self, key):\r\n\r\n~/mambaforge/envs/geo_dev/lib/python3.9/site-packages/dask/dataframe/core.py in divisions(self, value)\r\n    408             if not (is_categorical_dtype(index_dtype) and index_dtype.ordered):\r\n    409                 if value != tuple(sorted(value)):\r\n--> 410                     raise ValueError(\"divisions must be sorted\")\r\n    411 \r\n    412         self._divisions = value\r\n\r\nValueError: divisions must be sorted\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nThe issue was introduced in 2022.4.0.\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.4.1, main\r\n- Python version: 3.9.12 \r\n- Operating System: any\r\n- Install method (conda, pip, source): conda, source", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8964/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8964/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8955", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8955/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8955/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8955/events", "html_url": "https://github.com/dask/dask/issues/8955", "id": 1209803615, "node_id": "I_kwDOAbcwm85IHCNf", "number": 8955, "title": "Recursion error in DataFrame.set_index", "user": {"login": "bnaul", "id": 903655, "node_id": "MDQ6VXNlcjkwMzY1NQ==", "avatar_url": "https://avatars.githubusercontent.com/u/903655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bnaul", "html_url": "https://github.com/bnaul", "followers_url": "https://api.github.com/users/bnaul/followers", "following_url": "https://api.github.com/users/bnaul/following{/other_user}", "gists_url": "https://api.github.com/users/bnaul/gists{/gist_id}", "starred_url": "https://api.github.com/users/bnaul/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bnaul/subscriptions", "organizations_url": "https://api.github.com/users/bnaul/orgs", "repos_url": "https://api.github.com/users/bnaul/repos", "events_url": "https://api.github.com/users/bnaul/events{/privacy}", "received_events_url": "https://api.github.com/users/bnaul/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "phobson", "id": 1163939, "node_id": "MDQ6VXNlcjExNjM5Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1163939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phobson", "html_url": "https://github.com/phobson", "followers_url": "https://api.github.com/users/phobson/followers", "following_url": "https://api.github.com/users/phobson/following{/other_user}", "gists_url": "https://api.github.com/users/phobson/gists{/gist_id}", "starred_url": "https://api.github.com/users/phobson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phobson/subscriptions", "organizations_url": "https://api.github.com/users/phobson/orgs", "repos_url": "https://api.github.com/users/phobson/repos", "events_url": "https://api.github.com/users/phobson/events{/privacy}", "received_events_url": "https://api.github.com/users/phobson/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "phobson", "id": 1163939, "node_id": "MDQ6VXNlcjExNjM5Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1163939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phobson", "html_url": "https://github.com/phobson", "followers_url": "https://api.github.com/users/phobson/followers", "following_url": "https://api.github.com/users/phobson/following{/other_user}", "gists_url": "https://api.github.com/users/phobson/gists{/gist_id}", "starred_url": "https://api.github.com/users/phobson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phobson/subscriptions", "organizations_url": "https://api.github.com/users/phobson/orgs", "repos_url": "https://api.github.com/users/phobson/repos", "events_url": "https://api.github.com/users/phobson/events{/privacy}", "received_events_url": "https://api.github.com/users/phobson/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2022-04-20T14:51:28Z", "updated_at": "2022-04-26T13:24:30Z", "closed_at": "2022-04-26T13:24:30Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "`git bisect` traced this regression back to #8517:\r\n\r\n```\r\nimport dask, distributed\r\nclient = distributed.Client()\r\n# Create an already-sorted index; reset first so we can actually call .set_index()\r\nddf = dask.datasets.timeseries(end=\"2000-07-01\").reset_index().astype({\"timestamp\": str})\r\nddf = ddf.set_index(\"timestamp\", sorted=True)\r\nddf.to_csv(\"/tmp/dask_test/\")\r\n```\r\npre-#8517, this finishes in ~30s on my laptop; post-#8517, it fails with\r\n```\r\n---------------------------------------------------------------------------\r\nException                                 Traceback (most recent call last)\r\n<ipython-input-4-29e339cba513> in <module>\r\n      1 from uuid import uuid4\r\n----> 2 ddf.to_csv(f\"gs://model_bigquery_tmp/{uuid4().hex}/\")\r\n\r\n~/Dropbox/Documents/dask/dask/dataframe/core.py in to_csv(self, filename, **kwargs)\r\n   1621         from .io import to_csv\r\n   1622 \r\n-> 1623         return to_csv(self, filename, **kwargs)\r\n   1624 \r\n   1625     def to_sql(\r\n\r\n~/Dropbox/Documents/dask/dask/dataframe/io/csv.py in to_csv(df, filename, single_file, encoding, mode, name_function, compression, compute, scheduler, storage_options, header_first_partition_only, compute_kwargs, **kwargs)\r\n    955         import dask\r\n    956 \r\n--> 957         return list(dask.compute(*values, **compute_kwargs))\r\n    958     else:\r\n    959         return values\r\n\r\n~/Dropbox/Documents/dask/dask/base.py in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)\r\n    573         postcomputes.append(x.__dask_postcompute__())\r\n    574 \r\n--> 575     results = schedule(dsk, keys, **kwargs)\r\n    576     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    577 \r\n\r\n~/Dropbox/Documents/distributed/distributed/client.py in get(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\r\n   3002                     should_rejoin = False\r\n   3003             try:\r\n-> 3004                 results = self.gather(packed, asynchronous=asynchronous, direct=direct)\r\n   3005             finally:\r\n   3006                 for f in futures.values():\r\n\r\n~/Dropbox/Documents/distributed/distributed/client.py in gather(self, futures, errors, direct, asynchronous)\r\n   2176             else:\r\n   2177                 local_worker = None\r\n-> 2178             return self.sync(\r\n   2179                 self._gather,\r\n   2180                 futures,\r\n\r\n~/Dropbox/Documents/distributed/distributed/utils.py in sync(self, func, asynchronous, callback_timeout, *args, **kwargs)\r\n    307             return future\r\n    308         else:\r\n--> 309             return sync(\r\n    310                 self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\r\n    311             )\r\n\r\n~/Dropbox/Documents/distributed/distributed/utils.py in sync(loop, func, callback_timeout, *args, **kwargs)\r\n    374     if error:\r\n    375         typ, exc, tb = error\r\n--> 376         raise exc.with_traceback(tb)\r\n    377     else:\r\n    378         return result\r\n\r\n~/Dropbox/Documents/distributed/distributed/utils.py in f()\r\n    347                 future = asyncio.wait_for(future, callback_timeout)\r\n    348             future = asyncio.ensure_future(future)\r\n--> 349             result = yield future\r\n    350         except Exception:\r\n    351             error = sys.exc_info()\r\n\r\n~/model/.venv/lib/python3.9/site-packages/tornado/gen.py in run(self)\r\n    760 \r\n    761                     try:\r\n--> 762                         value = future.result()\r\n    763                     except Exception:\r\n    764                         exc_info = sys.exc_info()\r\n\r\n~/Dropbox/Documents/distributed/distributed/client.py in _gather(self, futures, errors, direct, local_worker)\r\n   2039                             exc = CancelledError(key)\r\n   2040                         else:\r\n-> 2041                             raise exception.with_traceback(traceback)\r\n   2042                         raise exc\r\n   2043                     if errors == \"skip\":\r\n\r\nException: RecursionError('maximum recursion depth exceeded in __instancecheck__')\r\n```\r\nand also eats up an enormous amount of memory in the process (reaches several times higher than peak memory in the older version before giving up).\r\n\r\nI haven't been able to reproduce the same error without the `distributed.Client()`, the computation seems to just hang forever with other schedulers...will keep playing around with the size of dataset/partitions and see if I can get something breaking w/o `distributed`.\r\n\r\nEDIT: it did finally complete after ~10 minutes with `scheduler=\"threads\"` (compared to ~90s on 2022.2.1), no recursion error\r\nEDIT 2: couldn't reproduce the error w/ `processes` but I did manage to brick my OS by using so much memory \ud83d\ude05 \r\n\r\ncc @jsignell @gjoseph92 ", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8955/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8955/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8951", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8951/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8951/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8951/events", "html_url": "https://github.com/dask/dask/issues/8951", "id": 1208509502, "node_id": "I_kwDOAbcwm85ICGQ-", "number": 8951, "title": "is_monotonic_increasing (resp. decreasing) still fails in some cases", "user": {"login": "jorloplaz", "id": 12827365, "node_id": "MDQ6VXNlcjEyODI3MzY1", "avatar_url": "https://avatars.githubusercontent.com/u/12827365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jorloplaz", "html_url": "https://github.com/jorloplaz", "followers_url": "https://api.github.com/users/jorloplaz/followers", "following_url": "https://api.github.com/users/jorloplaz/following{/other_user}", "gists_url": "https://api.github.com/users/jorloplaz/gists{/gist_id}", "starred_url": "https://api.github.com/users/jorloplaz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jorloplaz/subscriptions", "organizations_url": "https://api.github.com/users/jorloplaz/orgs", "repos_url": "https://api.github.com/users/jorloplaz/repos", "events_url": "https://api.github.com/users/jorloplaz/events{/privacy}", "received_events_url": "https://api.github.com/users/jorloplaz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-04-19T15:15:13Z", "updated_at": "2022-05-11T15:59:18Z", "closed_at": "2022-05-11T15:59:18Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**What happened**: after merging #8897, `is_monotonic_increasing` still fails in some circumstances, throwing a surprising error about `first` and `last` columns not being there.\r\n\r\n**What you expected to happen**: shouldn't fail at all.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n<details>\r\n<summary>Code</summary>\r\n\r\n```python\r\n# imports\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\nfrom dask import delayed\r\n\r\n# simple function to create one partition for each date\r\n@delayed\r\ndef create_partition(date, values):\r\n     index = pd.DatetimeIndex([date] * len(values), name=\"date\")\r\n     frame = pd.DataFrame({\"foo\": values}, index=index)\r\n     return frame\r\n\r\n# fix dates (8 days) and values\r\ndates = pd.date_range(\"2020-01-01\", \"2020-01-08\", freq=\"D\")\r\nvalues = [1, 2, 3]\r\n\r\n# this works fine and yields True\r\nddf = dd.from_delayed(dfs=[create_partition(date, values) for date in dates], divisions=list(dates)+[dates[-1]], verify_meta=False)\r\nprint(ddf.index.is_monotonic_increasing.compute())\r\n\r\n# however, with 9 days the same code crashes!!!\r\ndates = pd.date_range(\"2020-01-01\", \"2020-01-09\", freq=\"D\")     # 9 instead of 8\r\nddf = dd.from_delayed(dfs=[create_partition(date, values) for date in dates], divisions=list(dates)+[dates[-1]], verify_meta=False)\r\nprint(ddf.index.is_monotonic_increasing.compute())\r\n```\r\n</details>\r\n\r\n<details>\r\n<summary>Full error trace</summary>\r\n\r\n```python\r\n>>> print(ddf.index.is_monotonic_increasing.compute())\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/dask/base.py\", line 292, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/dask/base.py\", line 575, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/assuming `split_every=8` if called with `None`python3.9/site-packages/dask/threaded.py\", line 81, in get\r\n    results = get_async(\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/dask/local.py\", line 508, in get_async\r\n    raise_exception(exc, tb)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/dask/local.py\", line 316, in reraise\r\n    raise exc\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/dask/local.py\", line 221, in execute_task\r\n    result = _execute_task(task, data)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/toolz/functoolz.py\", line 630, in pipe\r\n    data = func(data)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/dask/dataframe/methods.py\", line 457, in monotonic_increasing_aggregate\r\n    concatenated[[\"first\", \"last\"]].to_numpy().ravel()\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/pandas/core/series.py\", line 984, in __getitem__\r\n    return self._get_with(key)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/pandas/core/series.py\", line 1024, in _get_with\r\n    return self.loc[key]\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/pandas/core/indexing.py\", line 967, in __getitem__\r\n    return self._getitem_axis(maybe_callable, axis=axis)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1191, in _getitem_axis\r\n    return self._getitem_iterable(key, axis=axis)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1132, in _getitem_iterable\r\n    keyarr, indexer = self._get_listlike_indexer(key, axis)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1327, in _get_listlike_indexer\r\n    keyarr, indexer = ax._get_indexer_strict(key, axis_name)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 5782, in _get_indexer_strict\r\n    self._raise_if_missing(keyarr, indexer, axis_name)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML-dev/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 5842, in _raise_if_missingassuming `split_every=8` if called with `None`\r\n\r\n    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\r\nKeyError: \"None of [Index(['first', 'last'], dtype='object')] are in the [index]\"\r\n```\r\n</details>\r\n\r\n**Anything else we need to know?**: the striking fact that it fails with 9 days but not with 8 (or less) points to the [aca method assuming `split_every=8` if called with `split_every=None`](https://github.com/dask/dask/blob/b0e234f65577a35ae4d78e0569ee3f44235f6089/dask/dataframe/core.py#L6100), which is [what `is_monotonic_increasing` does](https://github.com/dask/dask/blob/b0e234f65577a35ae4d78e0569ee3f44235f6089/dask/dataframe/core.py#L3999). \r\n\r\nThe [aggregating function `monotonic_increasing_aggregate`](https://github.com/dask/dask/blob/b0e234f65577a35ae4d78e0569ee3f44235f6089/dask/dataframe/methods.py#L457) assumes that columns  `first` and `last` have been obtained by the [chunking function `monotonic_increasing_chunk`](https://github.com/dask/dask/blob/b0e234f65577a35ae4d78e0569ee3f44235f6089/dask/dataframe/methods.py#L452). However, it seems that splitting is ruining this somehow... \r\n\r\n**Note this doesn't have to do with empty partitions, as `create_partition` is creating non-empty partitions for all dates.**\r\n\r\n**Same comments are applicable for `is_monotonic_decreasing`.**\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.04.1\r\n- Python version: 3.9.12\r\n- Operating System: Ubuntu\r\n- Install method (conda, pip, source): Conda", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8951/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8951/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8947", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8947/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8947/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8947/events", "html_url": "https://github.com/dask/dask/issues/8947", "id": 1208155577, "node_id": "I_kwDOAbcwm85IAv25", "number": 8947, "title": "`full` inconsistency with NumPy for `dtype=None`", "user": {"login": "tomwhite", "id": 85085, "node_id": "MDQ6VXNlcjg1MDg1", "avatar_url": "https://avatars.githubusercontent.com/u/85085?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tomwhite", "html_url": "https://github.com/tomwhite", "followers_url": "https://api.github.com/users/tomwhite/followers", "following_url": "https://api.github.com/users/tomwhite/following{/other_user}", "gists_url": "https://api.github.com/users/tomwhite/gists{/gist_id}", "starred_url": "https://api.github.com/users/tomwhite/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tomwhite/subscriptions", "organizations_url": "https://api.github.com/users/tomwhite/orgs", "repos_url": "https://api.github.com/users/tomwhite/repos", "events_url": "https://api.github.com/users/tomwhite/events{/privacy}", "received_events_url": "https://api.github.com/users/tomwhite/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-04-19T10:34:29Z", "updated_at": "2022-04-28T19:17:25Z", "closed_at": "2022-04-28T19:17:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**: Calling `full` with an integer fill value and `dtype=None` returns a float array rather than an int array, which is what happens in NumPy.\r\n\r\n**What you expected to happen**: Behaviour the same as NumPy.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\n>>> import numpy as np\r\n>>> np.full(1, 0, dtype=None).dtype\r\ndtype('int64')\r\n>>> import dask.array as da\r\n>>> da.full(1, 0, dtype=None).dtype\r\ndtype('float64')\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version: main\r\n- Python version: 3.8\r\n- Operating System: mac\r\n- Install method (conda, pip, source): source\r\n\r\n<!-- If you are reporting an issue such as scale stability, cluster deadlock.\r\nPlease provide a cluster dump state with this issue, by running client.dump_cluster_state()\r\n\r\nhttps://distributed.dask.org/en/stable/api.html?highlight=dump_cluster_state#distributed.Client.dump_cluster_state\r\n\r\n-->\r\n\r\n<details>\r\n<summary>Cluster Dump State:</summary>\r\n\r\n</details>", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8947/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8947/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8929", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8929/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8929/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8929/events", "html_url": "https://github.com/dask/dask/issues/8929", "id": 1204380586, "node_id": "I_kwDOAbcwm85HyWOq", "number": 8929, "title": "`argmin` errors on 0-dimensional input", "user": {"login": "tomwhite", "id": 85085, "node_id": "MDQ6VXNlcjg1MDg1", "avatar_url": "https://avatars.githubusercontent.com/u/85085?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tomwhite", "html_url": "https://github.com/tomwhite", "followers_url": "https://api.github.com/users/tomwhite/followers", "following_url": "https://api.github.com/users/tomwhite/following{/other_user}", "gists_url": "https://api.github.com/users/tomwhite/gists{/gist_id}", "starred_url": "https://api.github.com/users/tomwhite/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tomwhite/subscriptions", "organizations_url": "https://api.github.com/users/tomwhite/orgs", "repos_url": "https://api.github.com/users/tomwhite/repos", "events_url": "https://api.github.com/users/tomwhite/events{/privacy}", "received_events_url": "https://api.github.com/users/tomwhite/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-04-14T10:56:29Z", "updated_at": "2022-04-19T13:12:24Z", "closed_at": "2022-04-19T13:12:24Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**: `argmin` gives an error when NumPy doesn't on the same input.\r\n\r\n**What you expected to happen**: Behaviour the same as NumPy.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\n>>> import numpy as np\r\n>>> x = np.array(1)\r\n>>> np.argmin(x)\r\n0\r\n>>> import dask.array as da\r\n>>> x = da.from_array(x)\r\n>>> da.argmin(x).compute()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/tom/projects-workspace/dask/dask/base.py\", line 292, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/Users/tom/projects-workspace/dask/dask/base.py\", line 575, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/Users/tom/projects-workspace/dask/dask/threaded.py\", line 81, in get\r\n    results = get_async(\r\n  File \"/Users/tom/projects-workspace/dask/dask/local.py\", line 508, in get_async\r\n    raise_exception(exc, tb)\r\n  File \"/Users/tom/projects-workspace/dask/dask/local.py\", line 316, in reraise\r\n    raise exc\r\n  File \"/Users/tom/projects-workspace/dask/dask/local.py\", line 221, in execute_task\r\n    result = _execute_task(task, data)\r\n  File \"/Users/tom/projects-workspace/dask/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/Users/tom/projects-workspace/dask/dask/core.py\", line 119, in <genexpr>\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/Users/tom/projects-workspace/dask/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/Users/tom/projects-workspace/dask/dask/array/reductions.py\", line 1038, in arg_chunk\r\n    arg[:] = np.ravel_multi_index(total_ind, total_shape)\r\n  File \"<__array_function__ internals>\", line 180, in ravel_multi_index\r\nValueError: At least one iterator operand must be non-NULL\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version: main\r\n- Python version: 3.8\r\n- Operating System: mac\r\n- Install method (conda, pip, source): source\r\n\r\n<!-- If you are reporting an issue such as scale stability, cluster deadlock.\r\nPlease provide a cluster dump state with this issue, by running client.dump_cluster_state()\r\n\r\nhttps://distributed.dask.org/en/stable/api.html?highlight=dump_cluster_state#distributed.Client.dump_cluster_state\r\n\r\n-->\r\n\r\n<details>\r\n<summary>Cluster Dump State:</summary>\r\n\r\n</details>", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8929/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8929/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8902", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8902/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8902/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8902/events", "html_url": "https://github.com/dask/dask/issues/8902", "id": 1196573046, "node_id": "I_kwDOAbcwm85HUkF2", "number": 8902, "title": "`da.from_array` only uses custom getter if `inline_array=True` in 2022.4.0", "user": {"login": "ludwigschwardt", "id": 392144, "node_id": "MDQ6VXNlcjM5MjE0NA==", "avatar_url": "https://avatars.githubusercontent.com/u/392144?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ludwigschwardt", "html_url": "https://github.com/ludwigschwardt", "followers_url": "https://api.github.com/users/ludwigschwardt/followers", "following_url": "https://api.github.com/users/ludwigschwardt/following{/other_user}", "gists_url": "https://api.github.com/users/ludwigschwardt/gists{/gist_id}", "starred_url": "https://api.github.com/users/ludwigschwardt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ludwigschwardt/subscriptions", "organizations_url": "https://api.github.com/users/ludwigschwardt/orgs", "repos_url": "https://api.github.com/users/ludwigschwardt/repos", "events_url": "https://api.github.com/users/ludwigschwardt/events{/privacy}", "received_events_url": "https://api.github.com/users/ludwigschwardt/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-04-07T21:10:12Z", "updated_at": "2022-04-08T18:44:56Z", "closed_at": "2022-04-08T18:44:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "The recent #8827 (released in 2022.4.0) changed `da.core.graph_from_arraylike` to contain the following snippet:\r\n```Python\r\n    if inline_array:\r\n        layer = core_blockwise(\r\n            getitem,  # <----------- custom getter\r\n            name,\r\n            out_ind,\r\n            arr,\r\n            None,\r\n            ArraySliceDep(chunks),\r\n            out_ind,\r\n            numblocks={},\r\n            **kwargs,\r\n        )\r\n        return HighLevelGraph.from_collections(name, layer)\r\n    else:\r\n        original_name = \"original-\" + name\r\n\r\n        layers = {}\r\n        layers[original_name] = MaterializedLayer({original_name: arr})\r\n        layers[name] = core_blockwise(\r\n            getter,  # <----------- default getter\r\n            name,\r\n            out_ind,\r\n            original_name,\r\n            None,\r\n            ArraySliceDep(chunks),\r\n            out_ind,\r\n            numblocks={},\r\n            **kwargs,\r\n        )\r\n```\r\nIt looks like the custom getter is ignored by default, i.e. when `inline_array=False`. \r\n\r\nIs this expected or perhaps a typo?\r\n\r\nThis probably explains vaexio/vaex#2003.", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8902/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8902/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8880", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8880/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8880/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8880/events", "html_url": "https://github.com/dask/dask/issues/8880", "id": 1192891477, "node_id": "I_kwDOAbcwm85HGhRV", "number": 8880, "title": "is_monotonic fails with empty partitions", "user": {"login": "jorloplaz", "id": 12827365, "node_id": "MDQ6VXNlcjEyODI3MzY1", "avatar_url": "https://avatars.githubusercontent.com/u/12827365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jorloplaz", "html_url": "https://github.com/jorloplaz", "followers_url": "https://api.github.com/users/jorloplaz/followers", "following_url": "https://api.github.com/users/jorloplaz/following{/other_user}", "gists_url": "https://api.github.com/users/jorloplaz/gists{/gist_id}", "starred_url": "https://api.github.com/users/jorloplaz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jorloplaz/subscriptions", "organizations_url": "https://api.github.com/users/jorloplaz/orgs", "repos_url": "https://api.github.com/users/jorloplaz/repos", "events_url": "https://api.github.com/users/jorloplaz/events{/privacy}", "received_events_url": "https://api.github.com/users/jorloplaz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-04-05T09:44:39Z", "updated_at": "2022-04-11T17:51:34Z", "closed_at": "2022-04-11T17:51:34Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**What happened**: if a dataframe has empty partitions the method `is_monotonic` crashes, both for the index and for columns.\r\n\r\n**What you expected to happen**: empty partitions should be ignored while checking for sortedness and monotonicity. In the particular case of a 0-rows dataframe, Pandas equivalent behaves as expected (i.e., yielding `True`).\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\n>>> import dask.dataframe as dd\r\n>>> import pandas as pd\r\n\r\n# Simple 2-partitioned frame\r\n>>> ddf = dd.from_pandas(pd.DataFrame({'a': [1, 2, 3, 4], 'b': [4, 3, 2, 1]}), npartitions=2)\r\n>>> ddf.npartitions\r\n2\r\n>>> ddf.divisions\r\n(0, 2, 3)\r\n>>> for p in ddf.partitions:\r\n...     print(p.compute())\r\n   a  b\r\n0  1  4\r\n1  2  3\r\n   a  b\r\n2  3  2\r\n3  4  1\r\n\r\n# Non-empty partitions work fine, for index/columns and for whole frame or individual partitions\r\n>>> ddf.partitions[0]['a'].is_monotonic.compute()\r\nTrue\r\n>>> ddf.partitions[1].index.is_monotonic_increasing.compute()           # is_monotonic_increasing is alias for is_monotonic\r\nTrue\r\n>>> ddf['b'].is_monotonic_decreasing.compute()           # decreasing for checking descending order instead of ascending\r\nTrue\r\n>>> ddf.index.is_monotonic_decreasing.compute()           # it is increasing, not decreasing\r\nFalse\r\n\r\n# In Pandas everything is fine\r\n>>> ddf[ddf['a'] >= 3].index.compute().is_monotonic_increasing       # 'a' >= 3 to get rid of 1st partition\r\nTrue\r\n>>> ddf[ddf['a'] >= 3]['a'].compute().is_monotonic\r\nTrue\r\n>>> ddf[ddf['a'] >= 3]['b'].compute().is_monotonic_decreasing\r\nTrue\r\n>>> ddf[ddf['a'] >= 5].index.compute().is_monotonic                # 'a' >= 5 to yield an empty frame\r\nTrue\r\n>>> ddf[ddf['a'] >= 5]['b'].compute().is_monotonic_decreasing\r\nTrue\r\n\r\n# In Dask empty partitions fail\r\n>>> ddf[ddf['a'] >= 3]['a'].is_monotonic.compute()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/base.py\", line 292, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/base.py\", line 575, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/threaded.py\", line 81, in get\r\n    results = get_async(\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/local.py\", line 508, in get_async\r\n    raise_exception(exc, tb)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/local.py\", line 316, in reraise\r\n    raise exc\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/local.py\", line 221, in execute_task\r\n    result = _execute_task(task, data)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/optimization.py\", line 990, in __call__\r\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/core.py\", line 149, in get\r\n    result = _execute_task(task, cache)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/dataframe/methods.py\", line 448, in monotonic_increasing_chunk\r\n    data=[[x.is_monotonic_increasing, data[0], data[-1]]],\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/pandas/core/indexing.py\", line 967, in __getitem__\r\n    return self._getitem_axis(maybe_callable, axis=axis)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1520, in _getitem_axis\r\n    self._validate_integer(key, axis)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1452, in _validate_integer\r\n    raise IndexError(\"single positional indexer is out-of-bounds\")\r\n    \r\n# With index it fails with a different message, but the underlying problem is the same\r\n>>> ddf[ddf['a'] >= 3].index.is_monotonic.compute()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/base.py\", line 292, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/base.py\", line 575, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/threaded.py\", line 81, in get\r\n    results = get_async(\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/local.py\", line 508, in get_async\r\n    raise_exception(exc, tb)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/local.py\", line 316, in reraise\r\n    raise exc\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/local.py\", line 221, in execute_task\r\n    result = _execute_task(task, data)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/optimization.py\", line 990, in __call__\r\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/core.py\", line 149, in get\r\n    result = _execute_task(task, cache)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/dataframe/methods.py\", line 448, in monotonic_increasing_chunk\r\n    data=[[x.is_monotonic_increasing, data[0], data[-1]]],\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 5039, in __getitem__\r\n    return getitem(key)\r\nIndexError: index 0 is out of bounds for axis 0 with size 0\r\n\r\n# Same happens with a totally empty frame\r\n>>> ddf[ddf['a'] >= 5]['b'].is_monotonic_decreasing.compute()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/base.py\", line 292, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/base.py\", line 575, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/threaded.py\", line 81, in get\r\n    results = get_async(\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/local.py\", line 508, in get_async\r\n    raise_exception(exc, tb)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/local.py\", line 316, in reraise\r\n    raise exc\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/local.py\", line 221, in execute_task\r\n    result = _execute_task(task, data)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/optimization.py\", line 990, in __call__\r\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/core.py\", line 149, in get\r\n    result = _execute_task(task, cache)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/dataframe/methods.py\", line 463, in monotonic_decreasing_chunk\r\n    data=[[x.is_monotonic_decreasing, data[0], data[-1]]],\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/pandas/core/indexing.py\", line 967, in __getitem__\r\n    return self._getitem_axis(maybe_callable, axis=axis)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1520, in _getitem_axis\r\n    self._validate_integer(key, axis)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1452, in _validate_integer\r\n    raise IndexError(\"single positional indexer is out-of-bounds\")\r\nIndexError: single positional indexer is out-of-bounds\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nThe error seems clear. The conflicting lines are `data=[[x.is_monotonic_increasing, data[0], data[-1]]]` and `data=[[x.is_monotonic_decreasing, data[0], data[-1]]]`, which crash for any empty partition, as there is no `data[0]` nor `data[-1]`. \r\n\r\nFor those particular partitions, both methods should give `True` without accessing data, as Pandas does.\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.04.0\r\n- Python version: 3.9.12\r\n- Operating System: Ubuntu\r\n- Install method (conda, pip, source): Pip\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8880/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8880/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8879", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8879/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8879/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8879/events", "html_url": "https://github.com/dask/dask/issues/8879", "id": 1192760057, "node_id": "I_kwDOAbcwm85HGBL5", "number": 8879, "title": "set_index(sorted=True) fails with an empty frame", "user": {"login": "jorloplaz", "id": 12827365, "node_id": "MDQ6VXNlcjEyODI3MzY1", "avatar_url": "https://avatars.githubusercontent.com/u/12827365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jorloplaz", "html_url": "https://github.com/jorloplaz", "followers_url": "https://api.github.com/users/jorloplaz/followers", "following_url": "https://api.github.com/users/jorloplaz/following{/other_user}", "gists_url": "https://api.github.com/users/jorloplaz/gists{/gist_id}", "starred_url": "https://api.github.com/users/jorloplaz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jorloplaz/subscriptions", "organizations_url": "https://api.github.com/users/jorloplaz/orgs", "repos_url": "https://api.github.com/users/jorloplaz/repos", "events_url": "https://api.github.com/users/jorloplaz/events{/privacy}", "received_events_url": "https://api.github.com/users/jorloplaz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3468123446, "node_id": "LA_kwDOAbcwm87Ot102", "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention", "name": "needs attention", "color": "6d626c", "default": false, "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-04-05T07:47:49Z", "updated_at": "2022-08-10T12:00:39Z", "closed_at": "2022-08-10T12:00:39Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**What happened**: when trying to set an index on an empty frame, it works fine with `set_index(sorted=False)` -except for `divisions` being set to `nan`-, but it crashes with `set_index(sorted=True)`.\r\n\r\n**What you expected to happen**: given that it's empty, it should yield the same result. It's a bit ambiguous whether an empty frame's index is \"sorted\" or not (see discussion below), but certainly it shouldn't crash like this.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\n>>> import dask.dataframe as dd\r\n>>> import pandas as pd\r\n\r\n>>> ddf = dd.from_pandas(pd.DataFrame({'a': [], 'b': []}), npartitions=1)\r\n>>> ddf.compute()\r\nEmpty DataFrame\r\nColumns: [a, b]\r\nIndex: []\r\n>>> ddf.divisions\r\n(None, None)\r\n\r\n>>> ddf.set_index('a').compute()\r\nEmpty DataFrame\r\nColumns: [b]\r\nIndex: []\r\n>>> ddf.set_index('a').divisions\r\n(nan, nan)\r\n\r\n>>> ddf.set_index('a', sorted=True).compute()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/dataframe/core.py\", line 4689, in set_index\r\n    return set_sorted_index(\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/dataframe/shuffle.py\", line 1092, in set_sorted_index\r\n    return compute_and_set_divisions(result, **kwargs)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/dataframe/shuffle.py\", line 1072, in compute_and_set_divisions\r\n    return fix_overlap(df, mins, maxes, lens)\r\n  File \"/home/jorge.lopez/anaconda3/envs/AML/lib/python3.9/site-packages/dask/dataframe/shuffle.py\", line 990, in fix_overlap\r\n    divisions = tuple(mins) + (maxes[-1],)\r\nIndexError: list index out of range\r\n```\r\n\r\n**Anything else we need to know?**: \r\n\r\nThis is probably a side effect of #8517 , which made some changes in `fix_overlap`, the method that eventually fails. The difference between `set_index(sorted=False)` and `set_index(sorted=True)` is that the latter calls `set_sorted_index` and `compute_and_set_divisions`, as can be seen in the trace above.\r\n\r\nIMHO, and following a [discussion about divisions](https://github.com/dask/dask/issues/8845#issuecomment-1081584276) in #8845, **when a dataframe is empty then divisions should always be cleared, as we have no idea which are the `mins` and the `maxes` and the concept of `divisions` themselves doesn't make much sense**. \r\n\r\nThis is what makes the code fail in `fix_overlap` while trying to access the first position of the `mins` and `maxes`, when that position doesn't even exist. The case with `sorted=False` works, but note that `divisions` become `(nan, nan)` instead of `(None, None)`, which is probably not what we want!\r\n\r\nNote also that this fact makes the concept of \"sortedness\" ambiguous, but for the particular case of a no-rows dataframe, I think it should be considered as sorted (same as in Python `all([])` is `True`), and do nothing but:\r\n\r\n1. Move the requested column to be the index.\r\n2. Clear `divisions`, setting all of them to `None` (there's nothing to calculate, no quantiles to consider, etc).\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.04.0\r\n- Python version: 3.9.12\r\n- Operating System: Ubuntu\r\n- Install method (conda, pip, source): Pip", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8879/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8879/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8866", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8866/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8866/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8866/events", "html_url": "https://github.com/dask/dask/issues/8866", "id": 1187967271, "node_id": "I_kwDOAbcwm85GzvEn", "number": 8866, "title": "`da.from_array` doesn't work as expected for scalar masked numpy array inputs ", "user": {"login": "davidhassell", "id": 8126576, "node_id": "MDQ6VXNlcjgxMjY1NzY=", "avatar_url": "https://avatars.githubusercontent.com/u/8126576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidhassell", "html_url": "https://github.com/davidhassell", "followers_url": "https://api.github.com/users/davidhassell/followers", "following_url": "https://api.github.com/users/davidhassell/following{/other_user}", "gists_url": "https://api.github.com/users/davidhassell/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidhassell/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidhassell/subscriptions", "organizations_url": "https://api.github.com/users/davidhassell/orgs", "repos_url": "https://api.github.com/users/davidhassell/repos", "events_url": "https://api.github.com/users/davidhassell/events{/privacy}", "received_events_url": "https://api.github.com/users/davidhassell/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-03-31T11:56:23Z", "updated_at": "2022-04-07T16:40:35Z", "closed_at": "2022-04-07T16:40:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hello,\r\n\r\nI've noticed some unexpected behaviour when passing scalar masked numpy arrays to `da.from_array`, e.g. `x = da.from_array(np.ma.array(9, mask=True))`. When `x` is computed, we don't get the same numpy array input back, rather we get the `np.ma.masked` constant. This is problematic for because\r\n\r\n1. `np.ma.masked` is a float, which may be a different dtype from the dask array\r\n2. `np.ma.masked`  can not be sliced, unlike a numpy scalar array\r\n\r\n#### Reproducer\r\n\r\n```python\r\nimport numpy as np\r\nimport dask as da\r\na = np.ma.array(9, mask=True)  # 0-d\r\nx = da.from_array(a)\r\n\r\nprint('\\nnumpy input =', repr(a))\r\nprint('\\ndask =', repr(x))\r\nprint('\\ndask dtype =', x.dtype)\r\nprint('\\ndask computed =', repr(x.compute()))\r\nprint('\\ndask computed dtype =', x.compute().dtype)\r\n```\r\n\r\nGives output:\r\n```\r\nnumpy input = masked_array(data=--,\r\n             mask=True,\r\n       fill_value=999999,\r\n            dtype=int64)\r\n\r\ndask = dask.array<array, shape=(), dtype=int64, chunksize=(), chunktype=numpy.MaskedArray>\r\n\r\ndask dtype = int64\r\n\r\ndask computed = masked\r\n\r\ndask computed dtype = float64\r\n```\r\nOther size one masked arrays are not affected\r\n```python\r\nimport numpy as np\r\nimport dask as da\r\na = np.ma.array([9], mask=[True])  # 1-d\r\nx = da.from_array(a)\r\n\r\nprint('\\nnumpy input =', repr(a))\r\nprint('\\ndask =', repr(x))\r\nprint('\\ndask dtype =', x.dtype)\r\nprint('\\ndask computed =', repr(x.compute()))\r\nprint('\\ndask computed dtype =', x.compute().dtype)\r\n```\r\n\r\nGives output:\r\n```\r\nnumpy input = masked_array(data=[--],\r\n             mask=[ True],\r\n       fill_value=999999,\r\n            dtype=int64)\r\n\r\ndask = dask.array<array, shape=(1,), dtype=int64, chunksize=(1,), chunktype=numpy.MaskedArray>\r\n\r\ndask dtype = int64\r\n\r\ndask computed = masked_array(data=[--],\r\n             mask=[ True],\r\n       fill_value=999999,\r\n            dtype=int64)\r\n\r\ndask computed dtype = int64\r\n```\r\n\r\n#### Possible solution\r\n\r\nThis seems to occur because the scalar masked array input is sliced with `()` during it's passage through `da.from_array`:\r\n\r\n```python\r\n>>> x = da.from_array(np.ma.array(9, mask=True))\r\n>>> dict(x.dask)\r\n{'original-array-27cd77571adb3b50d0abe2275510329d': masked_array(data=--,\r\n              mask=True,\r\n        fill_value=999999,\r\n             dtype=int64),\r\n ('array-27cd77571adb3b50d0abe2275510329d',): (subgraph_callable-98ef2ccb-7037-4a4a-9d58-9417f3808eb6,\r\n  'original-array-27cd77571adb3b50d0abe2275510329d',\r\n  ())}\r\n```\r\n\r\nIn fact, the 1-d masked case is also sliced, but with `slice(0, 1)` so that everything works as expected:\r\n\r\n```python\r\n>>> x = da.from_array(np.ma.array([9], mask=[True])) # 1-d\r\n>>> dict(x.dask)\r\n{'original-array-5534b77f07bda580d7a7709dec8ce5af': masked_array(data=[--],\r\n              mask=[ True],\r\n        fill_value=999999,\r\n             dtype=int64),\r\n ('array-5534b77f07bda580d7a7709dec8ce5af',\r\n  0): (subgraph_callable-1334e14f-ad05-4fdb-9dcb-54a8c20644e4, 'original-array-5534b77f07bda580d7a7709dec8ce5af', (slice(0, 1, None),))}\r\n```\r\nI wonder if the reason behind this is that numpy masked arrays do _not_ have type `np.ndarray`, rather they are `np.ma.core.MaskedArray`:\r\n\r\n```python\r\n>>> b = np.ma.arange(9)\r\n>>> type(b) is np.ndarray\r\nFalse\r\n>>> type(b) is np.ma.core.MaskedArray\r\nTrue\r\n```\r\nand this means that from_array's `is_ndarray` variable (https://github.com/dask/dask/blob/2022.03.0/dask/array/core.py#L3293) is currently  False for these cases, rather than it being True so that we end up in the `# No slicing needed` clause (https://github.com/dask/dask/blob/2022.03.0/dask/array/core.py#L3306).\r\n\r\nA solution could be to replace  `is_ndarray = type(x) is np.ndarray` with \r\n\r\n```python\r\n    is_ndarray = type(x) in (np.ndarray, np.ma.core.MaskedArray)\r\n```\r\n\r\nI have tested this and it solves the use case I've described, and doesn't seem to make anything else fail.\r\n\r\nIf you think that this is all above board, I'm happy to make a PR with new unit tests.\r\n\r\nMany thanks,\r\nDavid", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8866/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8866/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8856", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8856/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8856/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8856/events", "html_url": "https://github.com/dask/dask/issues/8856", "id": 1185268354, "node_id": "I_kwDOAbcwm85GpcKC", "number": 8856, "title": "Cannot auto-chunk with string dtype", "user": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 162914698, "node_id": "MDU6TGFiZWwxNjI5MTQ2OTg=", "url": "https://api.github.com/repos/dask/dask/labels/good%20first%20issue", "name": "good first issue", "color": "159818", "default": true, "description": "Clearly described and easy to accomplish. Good for beginners to the project."}, {"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-03-29T18:42:00Z", "updated_at": "2022-03-31T13:03:30Z", "closed_at": "2022-03-31T13:03:30Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Auto-chunking involves reasoning about dtype size, but for flexible dtypes like unicode strings that is not necessarily known. From the [numpy docs](https://numpy.org/doc/stable/reference/generated/numpy.dtype.itemsize.html#numpy-dtype-itemsize):\r\n\r\n> For 18 of the 21 types this number is fixed by the data-type. For the flexible data-types, this number can be anything.\r\n\r\nIn particular, it seems that `itemsize` for a string type is set to zero (not a real size, probably better to not interpret it). So if we then try to auto-chunk when a string dtype is used, we get a divide by zero error.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.array as da\r\n\r\nda.full(1, \"value\")\r\n```\r\n\r\nProduces:\r\n\r\n```python-traceback\r\n~/dask/dask/dask/array/wrap.py in full(shape, fill_value, *args, **kwargs)\r\n    198         else:\r\n    199             kwargs[\"dtype\"] = type(fill_value)\r\n--> 200     return _full(shape=shape, fill_value=fill_value, *args, **kwargs)\r\n    201 \r\n    202 \r\n\r\n~/dask/dask/dask/array/wrap.py in wrap_func_shape_as_first_arg(func, *args, **kwargs)\r\n     58         )\r\n     59 \r\n---> 60     parsed = _parse_wrap_args(func, args, kwargs, shape)\r\n     61     shape = parsed[\"shape\"]\r\n     62     dtype = parsed[\"dtype\"]\r\n\r\n~/dask/dask/dask/array/wrap.py in _parse_wrap_args(func, args, kwargs, shape)\r\n     28     dtype = np.dtype(dtype)\r\n     29 \r\n---> 30     chunks = normalize_chunks(chunks, shape, dtype=dtype)\r\n     31 \r\n     32     name = name or funcname(func) + \"-\" + tokenize(\r\n\r\n~/dask/dask/dask/array/core.py in normalize_chunks(chunks, shape, limit, dtype, previous_chunks)\r\n   2901 \r\n   2902     if any(c == \"auto\" for c in chunks):\r\n-> 2903         chunks = auto_chunks(chunks, shape, limit, dtype, previous_chunks)\r\n   2904 \r\n   2905     if shape is not None:\r\n\r\n~/dask/dask/dask/array/core.py in auto_chunks(chunks, shape, limit, dtype, previous_chunks)\r\n   3066 \r\n   3067     else:\r\n-> 3068         size = (limit / dtype.itemsize / largest_block) ** (1 / len(autos))\r\n   3069         small = [i for i in autos if shape[i] < size]\r\n   3070         if small:\r\n\r\nZeroDivisionError: division by zero\r\n\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: `main`\r\n\r\nI suppose we could add some logic around trying to choose a sensible `itemsize` for string dtypes. But probably the best short-term fix is to just provide a useful error if `dtype.itemsize` is zero, suggesting that the user provide a chunk size.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8856/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8856/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8830", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8830/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8830/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8830/events", "html_url": "https://github.com/dask/dask/issues/8830", "id": 1176846882, "node_id": "I_kwDOAbcwm85GJUIi", "number": 8830, "title": "Unwanted aggregation `map_blocks`", "user": {"login": "jsignell", "id": 4806877, "node_id": "MDQ6VXNlcjQ4MDY4Nzc=", "avatar_url": "https://avatars.githubusercontent.com/u/4806877?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsignell", "html_url": "https://github.com/jsignell", "followers_url": "https://api.github.com/users/jsignell/followers", "following_url": "https://api.github.com/users/jsignell/following{/other_user}", "gists_url": "https://api.github.com/users/jsignell/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsignell/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsignell/subscriptions", "organizations_url": "https://api.github.com/users/jsignell/orgs", "repos_url": "https://api.github.com/users/jsignell/repos", "events_url": "https://api.github.com/users/jsignell/events{/privacy}", "received_events_url": "https://api.github.com/users/jsignell/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2022-03-22T14:10:13Z", "updated_at": "2022-04-01T13:49:37Z", "closed_at": "2022-04-01T13:49:37Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\n\r\nWhile working on https://github.com/dask/dask/issues/8822 I tried to use `drop_axis=True` in `map_blocks` and ran into an issue where `map_blocks` aggregated the results from each block rather than concatenating them.\r\n\r\n**What you expected to happen**:\r\n\r\nThe output should contain one output per block. \r\n\r\n```python\r\narray([1., 2., 3.])\r\n```\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport numpy as np\r\nimport dask.array as da\r\n\r\narray = da.from_array([1,1,2,2,2,3,3,3,3,3], chunks=((2,3,5)))\r\narray.map_blocks(np.mean, drop_axis=[0]).compute()\r\n# 2.3\r\n```\r\n\r\nPing @rjzamora for blockwise insight. \r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8830/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8830/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8824", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8824/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8824/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8824/events", "html_url": "https://github.com/dask/dask/pull/8824", "id": 1172748507, "node_id": "PR_kwDOAbcwm840nc_n", "number": 8824, "title": "Fix bug when applying \"not equal\" predicate in read_parquet", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-03-17T18:42:49Z", "updated_at": "2022-03-18T16:12:27Z", "closed_at": "2022-03-18T15:48:31Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/8824", "html_url": "https://github.com/dask/dask/pull/8824", "diff_url": "https://github.com/dask/dask/pull/8824.diff", "patch_url": "https://github.com/dask/dask/pull/8824.patch", "merged_at": "2022-03-18T15:48:31Z"}, "body": "The logic for `\"!=\"` is currently missing from the filtering code in `read_parquet`.  This currently results in **all** data being dropped when `\"!=\"` is included in the `filters` argument. This PR includes a simple fix and adds test coverage.\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8824/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8824/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/8786", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8786/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8786/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8786/events", "html_url": "https://github.com/dask/dask/pull/8786", "id": 1161575068, "node_id": "PR_kwDOAbcwm840DMsm", "number": 8786, "title": "Fix serialization bug in DataFrameTreeReduction", "user": {"login": "rjzamora", "id": 20461013, "node_id": "MDQ6VXNlcjIwNDYxMDEz", "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjzamora", "html_url": "https://github.com/rjzamora", "followers_url": "https://api.github.com/users/rjzamora/followers", "following_url": "https://api.github.com/users/rjzamora/following{/other_user}", "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions", "organizations_url": "https://api.github.com/users/rjzamora/orgs", "repos_url": "https://api.github.com/users/rjzamora/repos", "events_url": "https://api.github.com/users/rjzamora/events{/privacy}", "received_events_url": "https://api.github.com/users/rjzamora/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2156573524, "node_id": "MDU6TGFiZWwyMTU2NTczNTI0", "url": "https://api.github.com/repos/dask/dask/labels/highlevelgraph", "name": "highlevelgraph", "color": "8c24d6", "default": false, "description": "Issues relating to HighLevelGraphs."}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}, {"id": 3798450414, "node_id": "LA_kwDOAbcwm87iZ8Du", "url": "https://api.github.com/repos/dask/dask/labels/needs%20review", "name": "needs review", "color": "8c918c", "default": false, "description": "Needs review from a contributor."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-03-07T15:32:42Z", "updated_at": "2022-03-07T20:12:49Z", "closed_at": "2022-03-07T18:48:26Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/8786", "html_url": "https://github.com/dask/dask/pull/8786", "diff_url": "https://github.com/dask/dask/pull/8786.diff", "patch_url": "https://github.com/dask/dask/pull/8786.patch", "merged_at": "2022-03-07T18:48:25Z"}, "body": "Adds missing `split_every` attribute to `DataFrameTreeReduction.__dask_distributed_pack__`.  Further motivation for the simplification proposed in #8672 :)\r\n\r\n- [x] Closes #8773\r\n- [x] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8786/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8786/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/8783", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8783/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8783/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8783/events", "html_url": "https://github.com/dask/dask/issues/8783", "id": 1160446216, "node_id": "I_kwDOAbcwm85FKwEI", "number": 8783, "title": "dask.base.clone_key loses prefix if it has no token", "user": {"login": "abergou", "id": 1166198, "node_id": "MDQ6VXNlcjExNjYxOTg=", "avatar_url": "https://avatars.githubusercontent.com/u/1166198?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abergou", "html_url": "https://github.com/abergou", "followers_url": "https://api.github.com/users/abergou/followers", "following_url": "https://api.github.com/users/abergou/following{/other_user}", "gists_url": "https://api.github.com/users/abergou/gists{/gist_id}", "starred_url": "https://api.github.com/users/abergou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abergou/subscriptions", "organizations_url": "https://api.github.com/users/abergou/orgs", "repos_url": "https://api.github.com/users/abergou/repos", "events_url": "https://api.github.com/users/abergou/events{/privacy}", "received_events_url": "https://api.github.com/users/abergou/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "crusaderky", "id": 6213168, "node_id": "MDQ6VXNlcjYyMTMxNjg=", "avatar_url": "https://avatars.githubusercontent.com/u/6213168?v=4", "gravatar_id": "", "url": "https://api.github.com/users/crusaderky", "html_url": "https://github.com/crusaderky", "followers_url": "https://api.github.com/users/crusaderky/followers", "following_url": "https://api.github.com/users/crusaderky/following{/other_user}", "gists_url": "https://api.github.com/users/crusaderky/gists{/gist_id}", "starred_url": "https://api.github.com/users/crusaderky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/crusaderky/subscriptions", "organizations_url": "https://api.github.com/users/crusaderky/orgs", "repos_url": "https://api.github.com/users/crusaderky/repos", "events_url": "https://api.github.com/users/crusaderky/events{/privacy}", "received_events_url": "https://api.github.com/users/crusaderky/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "crusaderky", "id": 6213168, "node_id": "MDQ6VXNlcjYyMTMxNjg=", "avatar_url": "https://avatars.githubusercontent.com/u/6213168?v=4", "gravatar_id": "", "url": "https://api.github.com/users/crusaderky", "html_url": "https://github.com/crusaderky", "followers_url": "https://api.github.com/users/crusaderky/followers", "following_url": "https://api.github.com/users/crusaderky/following{/other_user}", "gists_url": "https://api.github.com/users/crusaderky/gists{/gist_id}", "starred_url": "https://api.github.com/users/crusaderky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/crusaderky/subscriptions", "organizations_url": "https://api.github.com/users/crusaderky/orgs", "repos_url": "https://api.github.com/users/crusaderky/repos", "events_url": "https://api.github.com/users/crusaderky/events{/privacy}", "received_events_url": "https://api.github.com/users/crusaderky/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2022-03-05T21:07:01Z", "updated_at": "2022-03-09T17:17:37Z", "closed_at": "2022-03-09T16:47:52Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "When someone crafts custom names for dask collections that only have a prefix and no token component then if graph_manipulation tools are applied to this graph dask loses the task prefix information. I would naively expect this information to be retained.\r\n\r\n```python\r\n>>> import time\r\n>>> import dask\r\n>>> foo = dask.delayed(time.sleep)(2, dask_key_name='foo')\r\n>>> bar = dask.delayed(time.sleep)(2, dask_key_name='bar')\r\n>>> baz = dask.graph_manipulation.bind(bar, foo)\r\n>>> baz.__dask_keys__()\r\n['5dc691d9294b96130150c87dd588e2d1']\r\n```\r\nI would expect baz's dask key's to start with `bar-`.\r\n\r\n\r\nCompare this with:\r\n```python\r\n>>> import time\r\n>>> import dask\r\n>>> foo = dask.delayed(time.sleep)(2, dask_key_name='foo-1')\r\n>>> bar = dask.delayed(time.sleep)(2, dask_key_name='bar-1')\r\n>>> baz = dask.graph_manipulation.bind(bar, foo)\r\n>>> baz.__dask_keys__()\r\n['bar-b7c920f2028f0832fe5db041c2c40883']\r\n```\r\n\r\nI believe the issue is in `dask.base.clone_key`. It's currently:\r\n```python\r\ndef clone_key(key, seed):\r\n    \"\"\"Clone a key from a Dask collection, producing a new key with the same prefix and\r\n    indices and a token which a deterministic function of the previous token and seed.\r\n\r\n    Examples\r\n    --------\r\n    >>> clone_key(\"inc-cbb1eca3bafafbb3e8b2419c4eebb387\", 123)  # doctest: +SKIP\r\n    'inc-1d291de52f5045f8a969743daea271fd'\r\n    >>> clone_key((\"sum-cbb1eca3bafafbb3e8b2419c4eebb387\", 4, 3), 123)  # doctest: +SKIP\r\n    ('sum-f0962cc58ef4415689a86cc1d4cc1723', 4, 3)\r\n    \"\"\"\r\n    if isinstance(key, tuple) and key and isinstance(key[0], str):\r\n        return (clone_key(key[0], seed),) + key[1:]\r\n    if isinstance(key, str):\r\n        prefix = key_split(key)\r\n        token = key[len(prefix) + 1 :]\r\n        if token:\r\n            return prefix + \"-\" + tokenize(token, seed)\r\n        else:\r\n            return tokenize(key, seed)\r\n    raise TypeError(f\"Expected str or tuple[str, Hashable, ...]; got {key}\")\r\n```\r\nbut I think it should be:\r\n```python\r\ndef clone_key(key, seed):\r\n    \"\"\"Clone a key from a Dask collection, producing a new key with the same prefix and\r\n    indices and a token which a deterministic function of the previous token and seed.\r\n\r\n    Examples\r\n    --------\r\n    >>> clone_key(\"inc-cbb1eca3bafafbb3e8b2419c4eebb387\", 123)  # doctest: +SKIP\r\n    'inc-1d291de52f5045f8a969743daea271fd'\r\n    >>> clone_key((\"sum-cbb1eca3bafafbb3e8b2419c4eebb387\", 4, 3), 123)  # doctest: +SKIP\r\n    ('sum-f0962cc58ef4415689a86cc1d4cc1723', 4, 3)\r\n    \"\"\"\r\n    if isinstance(key, tuple) and key and isinstance(key[0], str):\r\n        return (clone_key(key[0], seed),) + key[1:]\r\n    if isinstance(key, str):\r\n        prefix = key_split(key)\r\n        token = key[len(prefix) + 1 :]\r\n        if token:\r\n            return prefix + \"-\" + tokenize(token, seed)\r\n        else:\r\n            return prefix + \"-\" + tokenize(key, seed)\r\n    raise TypeError(f\"Expected str or tuple[str, Hashable, ...]; got {key}\")\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.02.1\r\n- Python version: 3.9\r\n- Operating System: linux\r\n- Install method (conda, pip, source): pip\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8783/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8783/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8779", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8779/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8779/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8779/events", "html_url": "https://github.com/dask/dask/issues/8779", "id": 1159948425, "node_id": "I_kwDOAbcwm85FI2iJ", "number": 8779, "title": "`dataframe.percentiles_summary` cannot handle pandas `\"string\"` data type", "user": {"login": "scharlottej13", "id": 8620816, "node_id": "MDQ6VXNlcjg2MjA4MTY=", "avatar_url": "https://avatars.githubusercontent.com/u/8620816?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scharlottej13", "html_url": "https://github.com/scharlottej13", "followers_url": "https://api.github.com/users/scharlottej13/followers", "following_url": "https://api.github.com/users/scharlottej13/following{/other_user}", "gists_url": "https://api.github.com/users/scharlottej13/gists{/gist_id}", "starred_url": "https://api.github.com/users/scharlottej13/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scharlottej13/subscriptions", "organizations_url": "https://api.github.com/users/scharlottej13/orgs", "repos_url": "https://api.github.com/users/scharlottej13/repos", "events_url": "https://api.github.com/users/scharlottej13/events{/privacy}", "received_events_url": "https://api.github.com/users/scharlottej13/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-03-04T18:55:33Z", "updated_at": "2022-03-09T18:20:24Z", "closed_at": "2022-03-09T18:20:24Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Noticed this when answering [this question on Stack Overflow](https://stackoverflow.com/a/71345190/17015034), [`percentiles_summary`](https://github.com/dask/dask/blob/a27b437da2594fd5c15f85736aa520feb726ddbd/dask/dataframe/partitionquantiles.py#L386-L432), which is used to set new partition divisions for shuffle operations, does not know how to handle [pandas `\"string\"` data types](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html).\r\n\r\n**What happened**:\r\nThe following snippet produces `TypeError: Cannot interpret 'string[python]' as a data type`:\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n                                                                    \r\ndata = {\"calories\": [420, \"hi\", 390], \"duration\": [50, 40, 45]}                               \r\ndf = pd.DataFrame(data)                                          \r\nddf = dd.from_pandas(df, npartitions=2)\r\n\r\nddf = ddf.astype({\"calories\": \"string\"}).set_index('calories')\r\n```\r\n<details>\r\n<summary>Full traceback:</summary>\r\n\r\n```python-traceback\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n/var/folders/hf/2s7qjx7j5ndc5220_qxv8y800000gn/T/ipykernel_81716/3824196896.py in <module>\r\n      6 ddf = dd.from_pandas(df, npartitions=2)\r\n      7 \r\n----> 8 ddf = ddf.astype({\"calories\": \"string\"}).set_index('calories')\r\n\r\n~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/dataframe/core.py in set_index(***failed resolving arguments***)\r\n   4607             from .shuffle import set_index\r\n   4608 \r\n-> 4609             return set_index(\r\n   4610                 self,\r\n   4611                 other,\r\n\r\n~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/dataframe/shuffle.py in set_index(df, index, npartitions, shuffle, compute, drop, upsample, divisions, partition_size, **kwargs)\r\n    213 \r\n    214     if divisions is None:\r\n--> 215         divisions, mins, maxes = _calculate_divisions(\r\n    216             df, index2, repartition, npartitions, upsample, partition_size\r\n    217         )\r\n\r\n~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/dataframe/shuffle.py in _calculate_divisions(df, partition_col, repartition, npartitions, upsample, partition_size)\r\n     38     mins = partition_col.map_partitions(M.min)\r\n     39     maxes = partition_col.map_partitions(M.max)\r\n---> 40     divisions, sizes, mins, maxes = base.compute(divisions, sizes, mins, maxes)\r\n     41     divisions = methods.tolist(divisions)\r\n     42     if type(sizes) is not list:\r\n\r\n~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/base.py in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)\r\n    571         postcomputes.append(x.__dask_postcompute__())\r\n    572 \r\n--> 573     results = schedule(dsk, keys, **kwargs)\r\n    574     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    575 \r\n\r\n~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/threaded.py in get(dsk, result, cache, num_workers, pool, **kwargs)\r\n     79             pool = MultiprocessingPoolExecutor(pool)\r\n     80 \r\n---> 81     results = get_async(\r\n     82         pool.submit,\r\n     83         pool._max_workers,\r\n\r\n~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/local.py in get_async(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\r\n    504                             _execute_task(task, data)  # Re-execute locally\r\n    505                         else:\r\n--> 506                             raise_exception(exc, tb)\r\n    507                     res, worker_id = loads(res_info)\r\n    508                     state[\"cache\"][key] = res\r\n\r\n~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/local.py in reraise(exc, tb)\r\n    312     if exc.__traceback__ is not tb:\r\n    313         raise exc.with_traceback(tb)\r\n--> 314     raise exc\r\n    315 \r\n    316 \r\n\r\n~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/local.py in execute_task(key, task_info, dumps, loads, get_id, pack_exception)\r\n    217     try:\r\n    218         task, data = loads(task_info)\r\n--> 219         result = _execute_task(task, data)\r\n    220         id = get_id()\r\n    221         result = dumps((result, id))\r\n\r\n~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/core.py in _execute_task(arg, cache, dsk)\r\n    117         # temporaries by their reference count and can execute certain\r\n    118         # operations in-place.\r\n--> 119         return func(*(_execute_task(a, cache) for a in args))\r\n    120     elif not ishashable(arg):\r\n    121         return arg\r\n\r\n~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/dataframe/partitionquantiles.py in percentiles_summary(df, num_old, num_new, upsample, state)\r\n    415         data = data.cat.codes\r\n    416         interpolation = \"nearest\"\r\n--> 417     elif isinstance(data.dtype, pd.core.dtypes.dtypes.DatetimeTZDtype) or np.issubdtype(\r\n    418         data.dtype, np.integer\r\n    419     ):\r\n\r\n~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/numpy/core/numerictypes.py in issubdtype(arg1, arg2)\r\n    417     \"\"\"\r\n    418     if not issubclass_(arg1, generic):\r\n--> 419         arg1 = dtype(arg1).type\r\n    420     if not issubclass_(arg2, generic):\r\n    421         arg2 = dtype(arg2).type\r\n\r\nTypeError: Cannot interpret 'string[python]' as a data type\r\n```\r\n</details>\r\n\r\n**What you expected to happen**:\r\nThis works if you use `str` instead:\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n                                                                    \r\ndata = {\"calories\": [420, \"hi\", 390], \"duration\": [50, 40, 45]}                               \r\ndf = pd.DataFrame(data)                                          \r\nddf = dd.from_pandas(df, npartitions=2)\r\n\r\nddf = ddf.astype({\"calories\": str}).set_index('calories')\r\n```\r\nand also works in pandas:\r\n```python\r\nimport pandas as pd\r\n                                                                    \r\ndata = {\"calories\": [420, \"hi\", 390], \"duration\": [50, 40, 45]}                               \r\ndf = pd.DataFrame(data)                                          \r\ndf = df.astype({\"calories\": \"string\"}).set_index(\"calories\")\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.02.1\r\n- pandas version: 1.4.0\r\n- Python version: 3.9\r\n- Operating System: MacOS\r\n- Install method (conda, pip, source):", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8779/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8779/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8773", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8773/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8773/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8773/events", "html_url": "https://github.com/dask/dask/issues/8773", "id": 1157385656, "node_id": "I_kwDOAbcwm85E_E24", "number": 8773, "title": "Series Aggregation called Multiple Times, Must Support Recursive Nature", "user": {"login": "DamianBarabonkovQC", "id": 65635505, "node_id": "MDQ6VXNlcjY1NjM1NTA1", "avatar_url": "https://avatars.githubusercontent.com/u/65635505?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DamianBarabonkovQC", "html_url": "https://github.com/DamianBarabonkovQC", "followers_url": "https://api.github.com/users/DamianBarabonkovQC/followers", "following_url": "https://api.github.com/users/DamianBarabonkovQC/following{/other_user}", "gists_url": "https://api.github.com/users/DamianBarabonkovQC/gists{/gist_id}", "starred_url": "https://api.github.com/users/DamianBarabonkovQC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DamianBarabonkovQC/subscriptions", "organizations_url": "https://api.github.com/users/DamianBarabonkovQC/orgs", "repos_url": "https://api.github.com/users/DamianBarabonkovQC/repos", "events_url": "https://api.github.com/users/DamianBarabonkovQC/events{/privacy}", "received_events_url": "https://api.github.com/users/DamianBarabonkovQC/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-03-02T15:58:40Z", "updated_at": "2022-03-07T18:48:25Z", "closed_at": "2022-03-07T18:48:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\n\r\nWith the latest Dask version 2022.02.0, whenever a Series is aggregated, the aggregator is called multiple times in a recursive nature. This was not the case before 2022.02.0. This recursive nature means that the aggregator function must return values that it should be able to later accept again.\r\n\r\n**What you expected to happen**:\r\n\r\nIn Dask 2022.01.0 and before, the aggregator did not need to handle this recursive nature. It could return a value which it did not need to accept in a future call.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nfrom dask import distributed\r\nimport pandas as pd\r\n\r\nclass SomeObject():\r\n    def __init__(self, val):\r\n        self.val = val\r\n        # Print for clarity what is going on\r\n        print(self.val)\r\n\r\n    def __str__(self):\r\n        return f\"Value: {self.val}\"\r\n\r\ndef _id(x):\r\n    return x\r\n\r\ndef aggregate_something(df_mps):\r\n    return SomeObject(df_mps.sum().sum())\r\n\r\ndef main():\r\n    # If you comment out this line, things work fine\r\n    client = distributed.Client()\r\n\r\n    N = 170\r\n    series = pd.Series(data=[1] * N, index=range(2, N + 2))\r\n    dask_series = dd.from_pandas(series, npartitions=100)\r\n\r\n    res = dask_series.reduction(\r\n        chunk=_id,\r\n        aggregate=aggregate_something,\r\n        split_every=False,\r\n        token=\"commit-dataset\",\r\n        meta=object,\r\n    )\r\n\r\n    print(res.compute())\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nThe *broken* output with Dask 2022.02.0:\r\n\r\n<details>\r\n<summary>2022.02.0 Output</summary>\r\n\r\n```bash\r\n272000.0\r\n272000.0\r\n68000.0\r\n272000.0\r\n272000.0\r\n272000.0\r\n272000.0\r\ndistributed.worker - WARNING - Compute Failed\r\nFunction:  execute_task\r\nargs:      ((<function pipe at 0x7f90e95f7670>, [<__main__.SomeObject object at 0x7f90e363a220>, <__main__.SomeObject object at 0x7f90e363a280>, <__main__.SomeObject object at 0x7f90269cb9a0>, <__main__.SomeObject object at 0x7f90e363ae20>, <__main__.SomeObject object at 0x7f90122909a0>, <__main__.SomeObject object at 0x7f90e363aa30>, <__main__.SomeObject object at 0x7f9011e5f190>], functools.partial(<function _concat at 0x7f9056c23430>, ignore_index=False), functools.partial(<function _reduction_aggregate at 0x7f9056c4ab80>, aca_aggregate=<function aggregate_something at 0x7f9011d5f3a0>)))\r\nkwargs:    {}\r\nException: 'TypeError(\"unsupported operand type(s) for +: \\'SomeObject\\' and \\'SomeObject\\'\")'\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/X931300/debugging/playground_dask/dask_kartothek_reduction_failure.py\", line 37, in <module>\r\n    main()\r\n  File \"/home/X931300/debugging/playground_dask/dask_kartothek_reduction_failure.py\", line 34, in main\r\n    print(res.compute(scheduler=\"distributed\"))\r\n  File \"/home/X931300/debugging/dask/dask/base.py\", line 291, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/home/X931300/debugging/dask/dask/base.py\", line 574, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/tmp/debug/lib/python3.9/site-packages/distributed/client.py\", line 3010, in get\r\n    results = self.gather(packed, asynchronous=asynchronous, direct=direct)\r\n  File \"/tmp/debug/lib/python3.9/site-packages/distributed/client.py\", line 2162, in gather\r\n    return self.sync(\r\n  File \"/tmp/debug/lib/python3.9/site-packages/distributed/utils.py\", line 311, in sync\r\n    return sync(\r\n  File \"/tmp/debug/lib/python3.9/site-packages/distributed/utils.py\", line 378, in sync\r\n    raise exc.with_traceback(tb)\r\n  File \"/tmp/debug/lib/python3.9/site-packages/distributed/utils.py\", line 351, in f\r\n    result = yield future\r\n  File \"/tmp/debug/lib/python3.9/site-packages/tornado/gen.py\", line 762, in run\r\n    value = future.result()\r\n  File \"/tmp/debug/lib/python3.9/site-packages/distributed/client.py\", line 2025, in _gather\r\n    raise exception.with_traceback(traceback)\r\n  File \"/tmp/debug/lib/python3.9/site-packages/toolz/functoolz.py\", line 630, in pipe\r\n    data = func(data)\r\n  File \"/home/X931300/debugging/dask/dask/dataframe/core.py\", line 7136, in _reduction_aggregate\r\n    return aca_aggregate(x, **kwargs)\r\n  File \"/home/X931300/debugging/playground_dask/dask_kartothek_reduction_failure.py\", line 18, in aggregate_something\r\n    return SomeObject(df_mps.sum().sum())\r\n  File \"/tmp/debug/lib/python3.9/site-packages/pandas/core/generic.py\", line 10708, in sum\r\n    return NDFrame.sum(\r\n  File \"/tmp/debug/lib/python3.9/site-packages/pandas/core/generic.py\", line 10446, in sum\r\n    return self._min_count_stat_function(\r\n  File \"/tmp/debug/lib/python3.9/site-packages/pandas/core/generic.py\", line 10428, in _min_count_stat_function\r\n    return self._reduce(\r\n  File \"/tmp/debug/lib/python3.9/site-packages/pandas/core/series.py\", line 4392, in _reduce\r\n    return op(delegate, skipna=skipna, **kwds)\r\n  File \"/tmp/debug/lib/python3.9/site-packages/pandas/core/nanops.py\", line 94, in _f\r\n    return f(*args, **kwargs)\r\n  File \"/tmp/debug/lib/python3.9/site-packages/pandas/core/nanops.py\", line 411, in new_func\r\n    result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\r\n  File \"/tmp/debug/lib/python3.9/site-packages/pandas/core/nanops.py\", line 591, in nansum\r\n    the_sum = values.sum(axis, dtype=dtype_sum)\r\n  File \"/tmp/debug/lib/python3.9/site-packages/numpy/core/_methods.py\", line 48, in _sum\r\n    return umr_sum(a, axis, dtype, out, keepdims, initial, where)\r\nTypeError: unsupported operand type(s) for +: 'SomeObject' and 'SomeObject'\r\n```\r\n</details>\r\n\r\nThe *previous* output with Dask 2022.01.0:\r\n\r\n<details>\r\n<summary>2022.01.0 Output</summary>\r\n\r\n```bash\r\n1700000.0\r\nValue: 1700000.0\r\n```\r\n\r\n</details>\r\n\r\n**Anything else we need to know?**:\r\n\r\nThis bug presented itself in the [Kartothek v4.0.3](https://github.com/JDASoftwareGroup/kartothek/tree/db840b52f28746f128e6aadee2103e6021db0e1a) library, specifically in a Dask Series reduction operation to update Kartothek's metadata [here](https://github.com/JDASoftwareGroup/kartothek/blob/v4.0.3/kartothek/io/dask/dataframe.py#L449). The reduction function it uses `_commit_update_from_reduction` ultimately ends up [here](_commit_update_from_reduction) which takes in a list of lists of [MetaPartition](https://github.com/JDASoftwareGroup/kartothek/blob/v4.0.3/kartothek/io_components/metapartition.py#L203) objects and returns a [DatasetMetadata](https://github.com/JDASoftwareGroup/kartothek/blob/4d20267393d44a31a895077f81f52f1f730557c4/kartothek/core/dataset.py#L502) object. The important thing to note is that this function is not recursive-ready -- it cannot be recursed on the value it outputs, the new requirement of a Dask Series reduction function.\r\n\r\nThe PR in Dask which introduces this altered behavior is: https://github.com/dask/dask/pull/8468 . All commit before that PR did not have this issue.\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.02.0\r\n- Python version: Python 3.9.10\r\n- Operating System: Ubuntu 20.04.3 LTS\r\n- Install method (conda, pip, source): source\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8773/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8773/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8753", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8753/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8753/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8753/events", "html_url": "https://github.com/dask/dask/issues/8753", "id": 1149078493, "node_id": "I_kwDOAbcwm85EfYvd", "number": 8753, "title": "Much slower (100 x) xarray.open_mfdataset  + compute after upgrading to dask > 2022.1.0", "user": {"login": "espenairmine", "id": 51234981, "node_id": "MDQ6VXNlcjUxMjM0OTgx", "avatar_url": "https://avatars.githubusercontent.com/u/51234981?v=4", "gravatar_id": "", "url": "https://api.github.com/users/espenairmine", "html_url": "https://github.com/espenairmine", "followers_url": "https://api.github.com/users/espenairmine/followers", "following_url": "https://api.github.com/users/espenairmine/following{/other_user}", "gists_url": "https://api.github.com/users/espenairmine/gists{/gist_id}", "starred_url": "https://api.github.com/users/espenairmine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/espenairmine/subscriptions", "organizations_url": "https://api.github.com/users/espenairmine/orgs", "repos_url": "https://api.github.com/users/espenairmine/repos", "events_url": "https://api.github.com/users/espenairmine/events{/privacy}", "received_events_url": "https://api.github.com/users/espenairmine/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}, {"id": 3798450416, "node_id": "LA_kwDOAbcwm87iZ8Dw", "url": "https://api.github.com/repos/dask/dask/labels/p2", "name": "p2", "color": "ffc133", "default": false, "description": "Affects more than a few users but doesn't prevent core functions"}], "state": "closed", "locked": false, "assignee": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2022-02-24T09:53:58Z", "updated_at": "2022-03-24T16:00:42Z", "closed_at": "2022-03-24T16:00:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "We're  opening 3-5 netcdf files, each 200-300mb.\r\n\r\nRunning on Azure AKS,  python 3.8\r\nxarray==0.21.1\r\ndask==2022.1.1\r\n\r\n```\r\n  def _get_forecast_dataframe(self, request: Any, lat: float, lon: float) -> Union[pd.DataFrame, None]:\r\n        \"\"\"Get a DataFrame with four day forecast\"\"\"\r\n        ds = xr.open_mfdataset(self.local_paths)\r\n        times = ds.time.data\r\n        lats = ds.lat.data\r\n        lons = ds.lon.data\r\n        vars = [ds[v] for v in ds.variables if v not in [\"lat\", \"lon\", \"time\", \"crs\"]]\r\n        forcecast= [v for v in vars if v.long_name.startswith(\"forecast\")]\r\n        tss = {v.name: v.sel(lat=lat, lon=lon, method=\"nearest\").compute() for v in forcecast}\r\n        df = pd.DataFrame(data=tss, index=times)\r\n        return df\r\n```\r\n\r\nThis call executes in 300-400ms with dask <= 2022.1.0\r\nAfter upgrading, automatic if package version not pinned, the call takes 20-30 sec \r\n\r\n**What happened**:\r\n\r\nAfter upgrading (automatically), our processes had close to 100x longer call times\r\n\r\n**What you expected to happen**:\r\n\r\nUpgrading having no negative performance impact\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```\r\nimport xarray as xr\r\n\r\n# weather files from Norwegian Met Service\r\n# if specified not available , download from https://thredds.met.no/thredds/catalog/metpplatest/catalog.xml\r\n# download to /mnt/data, or update path below\r\n\r\nurl= \"https://thredds.met.no/thredds/fileServer/metpplatest/met_forecast_1_0km_nordic_20220225T11Z.nc\"\r\n\r\ndef compute(lat: float, lon: float):\r\n    ds = xr.open_mfdataset(\"/mnt/data/met*.nc\")\r\n    lats = ds.x.data\r\n    lons = ds.y.data\r\n    if lat < lats[0] or lat > lats[-1]:\r\n        print(\"lat out-of-bounds\")\r\n    if lon < lons[0] or lon > lons[-1]:\r\n        print(\"lon out-of-bounds\")\r\n    vars = [ds[v] for v in ds.variables if v  in [\"air_pressure_at_sea_level\"]]\r\n    tss = {v.name: v.sel(x=lat, y=lon, method=\"nearest\").compute() for v in vars}\r\n    print(tss)\r\n\r\nif __name__ == \"__main__\":\r\n    compute(0, 0)\r\n```\r\n\r\nTiming with dask==2202.2:\r\n\r\nroot@d93a10d88800:/workspace/airmine# time python test-dask.py\r\n\r\nreal    0m3.689s\r\nuser    0m3.045s\r\nsys     0m1.761s\r\n\r\nTiming with dask==2202.1\r\nroot@d93a10d88800:/workspace/airmine# time python test-dask.py\r\n\r\nreal    0m0.972s\r\nuser    0m0.962s\r\nsys     0m1.165s\r\n\r\nThis is with opening a single file, we typically open an array\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\nVERSION=\"20.04.2 LTS (Focal Fossa)\r\nPython 3.8.5 [GCC 9.3.0] on linux\r\nxarray==0.21.1\r\ndask==2022.1.1\r\nInstalled with pip -r requirements\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8753/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8753/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8749", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8749/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8749/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8749/events", "html_url": "https://github.com/dask/dask/issues/8749", "id": 1147099611, "node_id": "I_kwDOAbcwm85EX1nb", "number": 8749, "title": "Groupby Shift produces incorrect result", "user": {"login": "kbushman", "id": 18200283, "node_id": "MDQ6VXNlcjE4MjAwMjgz", "avatar_url": "https://avatars.githubusercontent.com/u/18200283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kbushman", "html_url": "https://github.com/kbushman", "followers_url": "https://api.github.com/users/kbushman/followers", "following_url": "https://api.github.com/users/kbushman/following{/other_user}", "gists_url": "https://api.github.com/users/kbushman/gists{/gist_id}", "starred_url": "https://api.github.com/users/kbushman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kbushman/subscriptions", "organizations_url": "https://api.github.com/users/kbushman/orgs", "repos_url": "https://api.github.com/users/kbushman/repos", "events_url": "https://api.github.com/users/kbushman/events{/privacy}", "received_events_url": "https://api.github.com/users/kbushman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2022-02-22T16:10:16Z", "updated_at": "2022-03-08T20:46:22Z", "closed_at": "2022-03-08T20:46:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\n\r\nData shifts to incorrect location when using groupby shift operation.\r\n\r\n**What you expected to happen**:\r\n\r\nData should be shifted along the sorted index within each group.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\ndf1 = pd.DataFrame(\r\n    {\r\n        \"a\": [1, 2, 3, 4],\r\n        \"b\": [2, 1, 2, 1],\r\n        \"c\": [None, None, 10, 20]\r\n    }\r\n)\r\nddf1 = dd.from_pandas(df1, npartitions=1)\r\ndf2 = pd.DataFrame(\r\n    {\r\n        \"a\": [5, 6],\r\n        \"b\": [2, 1],\r\n        \"c\": [30, 40]\r\n    }\r\n)\r\nddf2 = dd.from_pandas(df2, npartitions=1)\r\ndf3 = pd.concat([df1, df2])\r\nddf3 = dd.concat([ddf1, ddf2])\r\n\r\ndf3 = df3.set_index(\"a\").sort_index()\r\nddf3 = ddf3.set_index(\"a\")\r\n\r\n\r\nwith pytest.warns(UserWarning):\r\n    assert_eq(\r\n        df3.groupby(\"b\")[\"c\"].shift(1),\r\n        ddf3.groupby(\"b\")[\"c\"].shift(1),\r\n    )\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nThere is a comment in the source code that \"If the grouper does not align with the index then this causes a full shuffle.  The order of rows within each group may not be preserved.\" Although this is fine for apply/transform, preserving order is vital to the correctness of the shift operation.\r\n\r\n**Potential solution**:\r\n\r\nSort each partition after shuffling. From dask/dataframe/groupby.py shift method:\r\n\r\n```python\r\n        if should_shuffle:\r\n            sort_idx = df.index.name\r\n            df2, by = self._shuffle(meta)\r\n            df2 = df2.map_partitions(lambda x: x.sort_values(sort_idx))\r\n```\r\n\r\n\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.2.0\r\n- Python version: 3.8.2\r\n- Operating System: Mac OS\r\n- Install method (conda, pip, source): pip", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8749/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8749/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8745", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8745/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8745/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8745/events", "html_url": "https://github.com/dask/dask/pull/8745", "id": 1146193608, "node_id": "PR_kwDOAbcwm84zP7se", "number": 8745, "title": "Move creation of sqlalchemy connection for picklability", "user": {"login": "jsignell", "id": 4806877, "node_id": "MDQ6VXNlcjQ4MDY4Nzc=", "avatar_url": "https://avatars.githubusercontent.com/u/4806877?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsignell", "html_url": "https://github.com/jsignell", "followers_url": "https://api.github.com/users/jsignell/followers", "following_url": "https://api.github.com/users/jsignell/following{/other_user}", "gists_url": "https://api.github.com/users/jsignell/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsignell/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsignell/subscriptions", "organizations_url": "https://api.github.com/users/jsignell/orgs", "repos_url": "https://api.github.com/users/jsignell/repos", "events_url": "https://api.github.com/users/jsignell/events{/privacy}", "received_events_url": "https://api.github.com/users/jsignell/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-02-21T20:17:05Z", "updated_at": "2022-02-24T13:29:23Z", "closed_at": "2022-02-23T22:31:24Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/8745", "html_url": "https://github.com/dask/dask/pull/8745", "diff_url": "https://github.com/dask/dask/pull/8745.diff", "patch_url": "https://github.com/dask/dask/pull/8745.patch", "merged_at": "2022-02-23T22:31:24Z"}, "body": "- [x] Closes #8738\r\n- [x] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n\r\nI'll add a test of picklability now. But wanted to put this up so people can check it.", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8745/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8745/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/8738", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8738/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8738/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8738/events", "html_url": "https://github.com/dask/dask/issues/8738", "id": 1143306083, "node_id": "I_kwDOAbcwm85EJXdj", "number": 8738, "title": "to_sql sqlalchemy pickle error with 2022.2.0", "user": {"login": "mgsnuno", "id": 1495173, "node_id": "MDQ6VXNlcjE0OTUxNzM=", "avatar_url": "https://avatars.githubusercontent.com/u/1495173?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mgsnuno", "html_url": "https://github.com/mgsnuno", "followers_url": "https://api.github.com/users/mgsnuno/followers", "following_url": "https://api.github.com/users/mgsnuno/following{/other_user}", "gists_url": "https://api.github.com/users/mgsnuno/gists{/gist_id}", "starred_url": "https://api.github.com/users/mgsnuno/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mgsnuno/subscriptions", "organizations_url": "https://api.github.com/users/mgsnuno/orgs", "repos_url": "https://api.github.com/users/mgsnuno/repos", "events_url": "https://api.github.com/users/mgsnuno/events{/privacy}", "received_events_url": "https://api.github.com/users/mgsnuno/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-02-18T15:55:21Z", "updated_at": "2022-02-23T22:31:24Z", "closed_at": "2022-02-23T22:31:24Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**What happened**:\r\nto_sql sqlalchemy pickle error with dask 2022.2.0\r\n\r\n**What you expected to happen**:\r\nto_sql produces no pickle error with 2022.1.1\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\nfrom dask.distributed import Client\r\n\r\nclient = Client()\r\n\r\ndata = dd.from_pandas(pd.DataFrame([1, 2, 3, 4]), chunksize=20000)\r\ndata.to_sql(\r\n    \"testtest\",\r\n    uri=str(sqlengine.url),\r\n    if_exists=\"replace\",\r\n    schema=None,\r\n    index=False,\r\n)\r\n```\r\n\r\n<details>\r\n<summary>Traceback</summary>\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.9/site-packages/distributed/worker.py\", line 4442, in dumps_function\r\n    result = cache_dumps[func]\r\n  File \"/opt/conda/lib/python3.9/site-packages/distributed/utils.py\", line 1360, in __getitem__\r\n    value = super().__getitem__(key)\r\n  File \"/opt/conda/lib/python3.9/collections/__init__.py\", line 1058, in __getitem__\r\n    raise KeyError(key)\r\nKeyError: <function to_sql.<locals>.make_meta at 0x7f05284b3af0>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.9/site-packages/distributed/protocol/pickle.py\", line 49, in dumps\r\n    result = pickle.dumps(x, **dump_kwargs)\r\nAttributeError: Can't pickle local object 'to_sql.<locals>.make_meta'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/opt/conda/lib/python3.9/site-packages/dask/dataframe/core.py\", line 1580, in to_sql\r\n    return to_sql(\r\n  File \"/opt/conda/lib/python3.9/site-packages/dask/dataframe/io/sql.py\", line 850, in to_sql\r\n    dask.compute(result)\r\n  File \"/opt/conda/lib/python3.9/site-packages/dask/base.py\", line 573, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/opt/conda/lib/python3.9/site-packages/distributed/client.py\", line 2974, in get\r\n    futures = self._graph_to_futures(\r\n  File \"/opt/conda/lib/python3.9/site-packages/distributed/client.py\", line 2882, in _graph_to_futures\r\n    dsk = dsk.__dask_distributed_pack__(self, keyset, annotations)\r\n  File \"/opt/conda/lib/python3.9/site-packages/dask/highlevelgraph.py\", line 1054, in __dask_distributed_pack__\r\n    \"state\": layer.__dask_distributed_pack__(\r\n  File \"/opt/conda/lib/python3.9/site-packages/dask/highlevelgraph.py\", line 425, in __dask_distributed_pack__\r\n    dsk = toolz.valmap(dumps_task, dsk)\r\n  File \"cytoolz/dicttoolz.pyx\", line 178, in cytoolz.dicttoolz.valmap\r\n  File \"cytoolz/dicttoolz.pyx\", line 203, in cytoolz.dicttoolz.valmap\r\n  File \"/opt/conda/lib/python3.9/site-packages/distributed/worker.py\", line 4480, in dumps_task\r\n    return {\"function\": dumps_function(task[0]), \"args\": warn_dumps(task[1:])}\r\n  File \"/opt/conda/lib/python3.9/site-packages/distributed/worker.py\", line 4444, in dumps_function\r\n    result = pickle.dumps(func, protocol=4)\r\n  File \"/opt/conda/lib/python3.9/site-packages/distributed/protocol/pickle.py\", line 60, in dumps\r\n    result = cloudpickle.dumps(x, **dump_kwargs)\r\n  File \"/opt/conda/lib/python3.9/site-packages/cloudpickle/cloudpickle_fast.py\", line 73, in dumps\r\n    cp.dump(obj)\r\n  File \"/opt/conda/lib/python3.9/site-packages/cloudpickle/cloudpickle_fast.py\", line 602, in dump\r\n    return Pickler.dump(self, obj)\r\nTypeError: cannot pickle 'sqlalchemy.cprocessors.UnicodeResultProcessor' object\r\n```\r\n</details>\r\n\r\n**Anything else we need to know?**:\r\ntested with SQLAlchemy 1.4.31\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.2.0\r\n- Python version: 3.9.10\r\n- Operating System: linux\r\n- Install method (conda, pip, source): conda/mamba\r\n\r\n<!-- If you are reporting an issue such as scale stability, cluster deadlock.\r\nPlease provide a cluster dump state with this issue, by running client.dump_cluster_state()\r\n\r\nhttps://distributed.dask.org/en/stable/api.html?highlight=dump_cluster_state#distributed.Client.dump_cluster_state\r\n\r\n-->", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8738/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8738/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8712", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8712/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8712/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8712/events", "html_url": "https://github.com/dask/dask/issues/8712", "id": 1132545318, "node_id": "I_kwDOAbcwm85DgUUm", "number": 8712, "title": "Sampling from Dataframe for frac < npartitions / nrows", "user": {"login": "sissnad", "id": 53600650, "node_id": "MDQ6VXNlcjUzNjAwNjUw", "avatar_url": "https://avatars.githubusercontent.com/u/53600650?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sissnad", "html_url": "https://github.com/sissnad", "followers_url": "https://api.github.com/users/sissnad/followers", "following_url": "https://api.github.com/users/sissnad/following{/other_user}", "gists_url": "https://api.github.com/users/sissnad/gists{/gist_id}", "starred_url": "https://api.github.com/users/sissnad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sissnad/subscriptions", "organizations_url": "https://api.github.com/users/sissnad/orgs", "repos_url": "https://api.github.com/users/sissnad/repos", "events_url": "https://api.github.com/users/sissnad/events{/privacy}", "received_events_url": "https://api.github.com/users/sissnad/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 386719598, "node_id": "MDU6TGFiZWwzODY3MTk1OTg=", "url": "https://api.github.com/repos/dask/dask/labels/documentation", "name": "documentation", "color": "f9d0c4", "default": true, "description": "Improve or add to documentation"}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "phobson", "id": 1163939, "node_id": "MDQ6VXNlcjExNjM5Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1163939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phobson", "html_url": "https://github.com/phobson", "followers_url": "https://api.github.com/users/phobson/followers", "following_url": "https://api.github.com/users/phobson/following{/other_user}", "gists_url": "https://api.github.com/users/phobson/gists{/gist_id}", "starred_url": "https://api.github.com/users/phobson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phobson/subscriptions", "organizations_url": "https://api.github.com/users/phobson/orgs", "repos_url": "https://api.github.com/users/phobson/repos", "events_url": "https://api.github.com/users/phobson/events{/privacy}", "received_events_url": "https://api.github.com/users/phobson/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "phobson", "id": 1163939, "node_id": "MDQ6VXNlcjExNjM5Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1163939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phobson", "html_url": "https://github.com/phobson", "followers_url": "https://api.github.com/users/phobson/followers", "following_url": "https://api.github.com/users/phobson/following{/other_user}", "gists_url": "https://api.github.com/users/phobson/gists{/gist_id}", "starred_url": "https://api.github.com/users/phobson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phobson/subscriptions", "organizations_url": "https://api.github.com/users/phobson/orgs", "repos_url": "https://api.github.com/users/phobson/repos", "events_url": "https://api.github.com/users/phobson/events{/privacy}", "received_events_url": "https://api.github.com/users/phobson/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2022-02-11T12:42:09Z", "updated_at": "2022-04-01T19:44:55Z", "closed_at": "2022-04-01T19:44:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**What happened**:\r\nI have been trying to sample rows from a dataframe using `sample(frac)` and realised that it does only work properly if the parameter `frac >= npartitions / nrows`, where `nrows` is the number of rows of the dataframe. For example, for `frac = 1 / nrows` `sample(frac)` returns a sample of `sample size = npartitions` instead of 1.\r\n \r\n**What you expected to happen**:\r\nI expected sample size to be `frac * nrows` . For example, if `frac = 1 / nrows`, then `sample size = 1`.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n\r\ndf = dd.from_pandas(pd.DataFrame({'test':range(0,100)}), npartitions= 10)\r\nprint(f'Expectation | Result')\r\nprint(f'--------------------')\r\nfor numerator in (1, 5, 9, 10, 20, 30, 50):\r\n    sample = df.sample(frac= numerator/100)\r\n    print(f'{numerator:^11} | {len(sample):^7}')\r\n```\r\n\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.1.1\r\n- Python version: 3.8.9\r\n- Operating System: MacOS\r\n- Install method (conda, pip, source): pipenv\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8712/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8712/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8702", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8702/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8702/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8702/events", "html_url": "https://github.com/dask/dask/issues/8702", "id": 1129306732, "node_id": "I_kwDOAbcwm85DT9ps", "number": 8702, "title": "Scipy's `gmres` fails to converge with Dask Array", "user": {"login": "phobson", "id": 1163939, "node_id": "MDQ6VXNlcjExNjM5Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1163939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phobson", "html_url": "https://github.com/phobson", "followers_url": "https://api.github.com/users/phobson/followers", "following_url": "https://api.github.com/users/phobson/following{/other_user}", "gists_url": "https://api.github.com/users/phobson/gists{/gist_id}", "starred_url": "https://api.github.com/users/phobson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phobson/subscriptions", "organizations_url": "https://api.github.com/users/phobson/orgs", "repos_url": "https://api.github.com/users/phobson/repos", "events_url": "https://api.github.com/users/phobson/events{/privacy}", "received_events_url": "https://api.github.com/users/phobson/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2022-02-10T01:38:27Z", "updated_at": "2022-03-03T17:08:59Z", "closed_at": "2022-03-03T17:08:59Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\nDuring a review of https://github.com/dask/dask/pull/8694, I noticed that scipy's `gmres` fails to converge on a solution with even a small dask array after several minutes. The task graph grows seemingly boundlessly\r\n\r\n![image](https://user-images.githubusercontent.com/1163939/153312892-1b88d0f6-56f2-4d97-a8f4-748bab6c6324.png)\r\n\r\n**What you expected to happen**:\r\n\r\n`gmres` should converge seemingly instantly\r\n\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport numpy as np\r\nfrom scipy.sparse.linalg import gmres\r\nfrom scipy.sparse.linalg._interface import MatrixLinearOperator\r\n\r\nfrom dask.distributed import Client\r\nimport dask.array as da\r\n\r\nnp.random.seed(0)\r\nx_np = np.random.random(size=(40, 40))\r\n\r\nwith Client(n_workers=4) as client:\r\n    x = da.from_array(x_np, chunks=(4, 4))\r\n    A = MatrixLinearOperator(x)\r\n    b = np.random.random(40)\r\n    result =  gmres(A, b)\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.1.1\r\n- Python version: 3.9.10\r\n- Scipy version: 1.18.0\r\n- Operating System: Mac OS 12.2 (21D49) with the M1 Pro chip\r\n- Install method (conda, pip, source): conda (mambaforge in particular)\r\n\r\n<details>\r\n<summary>Full env</summary>\r\n\r\n```text\r\n# packages in environment at /Users/paul/mambaforge/envs/hydro:\r\n#\r\n# Name                    Version                   Build  Channel\r\naiohttp                   3.8.1            py39h5161555_0    conda-forge\r\naiosignal                 1.2.0              pyhd8ed1ab_0    conda-forge\r\nanyio                     3.5.0            py39h2804cbe_0    conda-forge\r\nappnope                   0.1.2            py39h2804cbe_2    conda-forge\r\nargon2-cffi               21.3.0             pyhd8ed1ab_0    conda-forge\r\nargon2-cffi-bindings      21.2.0           py39h5161555_1    conda-forge\r\nasttokens                 2.0.5              pyhd8ed1ab_0    conda-forge\r\nasync-timeout             4.0.2              pyhd8ed1ab_0    conda-forge\r\nattrs                     21.4.0             pyhd8ed1ab_0    conda-forge\r\nbabel                     2.9.1              pyh44b312d_0    conda-forge\r\nbackcall                  0.2.0              pyh9f0ad1d_0    conda-forge\r\nbackports                 1.0                        py_2    conda-forge\r\nbackports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge\r\nblack                     22.1.0             pyhd8ed1ab_0    conda-forge\r\nbleach                    4.1.0              pyhd8ed1ab_0    conda-forge\r\nbokeh                     2.4.2            py39h2804cbe_0    conda-forge\r\nbrotli                    1.0.9                h3422bc3_6    conda-forge\r\nbrotli-bin                1.0.9                h3422bc3_6    conda-forge\r\nbrotlipy                  0.7.0           py39h5161555_1003    conda-forge\r\nbzip2                     1.0.8                h3422bc3_4    conda-forge\r\nca-certificates           2021.10.8            h4653dfc_0    conda-forge\r\ncertifi                   2021.10.8        py39h2804cbe_1    conda-forge\r\ncffi                      1.15.0           py39h52b1de0_0    conda-forge\r\ncharset-normalizer        2.0.11             pyhd8ed1ab_0    conda-forge\r\nclick                     8.0.3            py39h2804cbe_1    conda-forge\r\ncloudpickle               2.0.0              pyhd8ed1ab_0    conda-forge\r\ncloudside                 0.1                       dev_0    <develop>\r\ncryptography              36.0.1           py39hfb8cd70_0    conda-forge\r\ncycler                    0.11.0             pyhd8ed1ab_0    conda-forge\r\ncytoolz                   0.11.2           py39h5161555_1    conda-forge\r\ndask                      2022.1.1           pyhd8ed1ab_0    conda-forge\r\ndask-core                 2022.1.1           pyhd8ed1ab_0    conda-forge\r\ndask-labextension         5.2.0              pyhd8ed1ab_0    conda-forge\r\ndataclasses               0.8                pyhc8e2a94_3    conda-forge\r\ndebugpy                   1.5.1            py39hfb83b0d_0    conda-forge\r\ndecorator                 5.1.1              pyhd8ed1ab_0    conda-forge\r\ndefusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\r\ndistributed               2022.1.1         py39h2804cbe_0    conda-forge\r\nentrypoints               0.4                pyhd8ed1ab_0    conda-forge\r\nexecuting                 0.8.2              pyhd8ed1ab_0    conda-forge\r\nflit-core                 3.6.0              pyhd8ed1ab_0    conda-forge\r\nfonttools                 4.29.1           py39h5161555_0    conda-forge\r\nfreetype                  2.10.4               h17b34a0_1    conda-forge\r\nfribidi                   1.0.10               h27ca646_0    conda-forge\r\nfrozenlist                1.3.0            py39h5161555_0    conda-forge\r\nfsspec                    2022.1.0           pyhd8ed1ab_0    conda-forge\r\ngiflib                    5.2.1                h27ca646_2    conda-forge\r\nheapdict                  1.0.1                      py_0    conda-forge\r\nidna                      3.3                pyhd8ed1ab_0    conda-forge\r\nimportlib-metadata        4.10.1           py39h2804cbe_0    conda-forge\r\nimportlib_resources       5.4.0              pyhd8ed1ab_0    conda-forge\r\niniconfig                 1.1.1              pyh9f0ad1d_0    conda-forge\r\nipykernel                 6.9.0            py39h32adebf_0    conda-forge\r\nipython                   8.0.1            py39h2804cbe_0    conda-forge\r\nipython_genutils          0.2.0                      py_1    conda-forge\r\njbig                      2.1               h3422bc3_2003    conda-forge\r\njedi                      0.18.1           py39h2804cbe_0    conda-forge\r\njinja2                    3.0.3              pyhd8ed1ab_0    conda-forge\r\njpeg                      9e                   h3422bc3_0    conda-forge\r\njson5                     0.9.5              pyh9f0ad1d_0    conda-forge\r\njsonschema                4.4.0              pyhd8ed1ab_0    conda-forge\r\njupyter-server-proxy      3.2.1              pyhd8ed1ab_0    conda-forge\r\njupyter_client            7.1.2              pyhd8ed1ab_0    conda-forge\r\njupyter_core              4.9.1            py39h2804cbe_1    conda-forge\r\njupyter_server            1.13.5             pyhd8ed1ab_0    conda-forge\r\njupyterlab                3.2.9              pyhd8ed1ab_0    conda-forge\r\njupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge\r\njupyterlab_server         2.10.3             pyhd8ed1ab_0    conda-forge\r\nkiwisolver                1.3.2            py39h4d2d688_1    conda-forge\r\nlcms2                     2.12                 had6a04f_0    conda-forge\r\nlerc                      3.0                  hbdafb3b_0    conda-forge\r\nlibblas                   3.9.0           13_osxarm64_openblas    conda-forge\r\nlibbrotlicommon           1.0.9                h3422bc3_6    conda-forge\r\nlibbrotlidec              1.0.9                h3422bc3_6    conda-forge\r\nlibbrotlienc              1.0.9                h3422bc3_6    conda-forge\r\nlibcblas                  3.9.0           13_osxarm64_openblas    conda-forge\r\nlibcxx                    12.0.1               h168391b_1    conda-forge\r\nlibdeflate                1.8                  h3422bc3_0    conda-forge\r\nlibffi                    3.4.2                h3422bc3_5    conda-forge\r\nlibgfortran               5.0.0.dev0      11_0_1_hf114ba7_23    conda-forge\r\nlibgfortran5              11.0.1.dev0         hf114ba7_23    conda-forge\r\nliblapack                 3.9.0           13_osxarm64_openblas    conda-forge\r\nlibopenblas               0.3.18          openmp_h5dd58f0_0    conda-forge\r\nlibpng                    1.6.37               hf7e6567_2    conda-forge\r\nlibsodium                 1.0.18               h27ca646_1    conda-forge\r\nlibtiff                   4.3.0                h74060c4_2    conda-forge\r\nlibwebp                   1.2.2                h0d20362_0    conda-forge\r\nlibwebp-base              1.2.2                h3422bc3_1    conda-forge\r\nlibxcb                    1.13              h9b22ae9_1004    conda-forge\r\nlibzlib                   1.2.11            hee7b306_1013    conda-forge\r\nllvm-openmp               12.0.1               hf3c4609_1    conda-forge\r\nlocket                    0.2.0                      py_2    conda-forge\r\nlz4-c                     1.9.3                hbdafb3b_1    conda-forge\r\nmarkupsafe                2.0.1            py39h5161555_1    conda-forge\r\nmatplotlib                3.5.1            py39hdf13c20_0    conda-forge\r\nmatplotlib-base           3.5.1            py39h5aa4fe7_0    conda-forge\r\nmatplotlib-inline         0.1.3              pyhd8ed1ab_0    conda-forge\r\nmetar                     1.9.0              pyhd8ed1ab_0    conda-forge\r\nmistune                   0.8.4           py39h5161555_1005    conda-forge\r\nmsgpack-python            1.0.3            py39h4d2d688_0    conda-forge\r\nmultidict                 6.0.2            py39h5161555_0    conda-forge\r\nmunkres                   1.1.4              pyh9f0ad1d_0    conda-forge\r\nmypy_extensions           0.4.3            py39h2804cbe_4    conda-forge\r\nnbclassic                 0.3.5              pyhd8ed1ab_0    conda-forge\r\nnbclient                  0.5.10             pyhd8ed1ab_1    conda-forge\r\nnbconvert                 6.4.1            py39h2804cbe_0    conda-forge\r\nnbformat                  5.1.3              pyhd8ed1ab_0    conda-forge\r\nncurses                   6.3                  hc470f4d_0    conda-forge\r\nnest-asyncio              1.5.4              pyhd8ed1ab_0    conda-forge\r\nnotebook                  6.4.8              pyha770c72_0    conda-forge\r\nnumpy                     1.22.2           py39h61a45d2_0    conda-forge\r\nopenjpeg                  2.4.0                h062765e_1    conda-forge\r\nopenssl                   1.1.1l               h3422bc3_0    conda-forge\r\npackaging                 21.3               pyhd8ed1ab_0    conda-forge\r\npandas                    1.4.0            py39h7f752ed_0    conda-forge\r\npandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\r\nparso                     0.8.3              pyhd8ed1ab_0    conda-forge\r\npartd                     1.2.0              pyhd8ed1ab_0    conda-forge\r\npathspec                  0.9.0              pyhd8ed1ab_0    conda-forge\r\npexpect                   4.8.0              pyh9f0ad1d_2    conda-forge\r\npickleshare               0.7.5                   py_1003    conda-forge\r\npillow                    9.0.1            py39hcb29f89_0    conda-forge\r\npip                       22.0.3             pyhd8ed1ab_0    conda-forge\r\nplatformdirs              2.4.1              pyhd8ed1ab_1    conda-forge\r\npluggy                    1.0.0            py39h2804cbe_2    conda-forge\r\nprometheus_client         0.13.1             pyhd8ed1ab_0    conda-forge\r\nprompt-toolkit            3.0.26             pyha770c72_0    conda-forge\r\npsutil                    5.9.0            py39h5161555_0    conda-forge\r\npthread-stubs             0.4               h27ca646_1001    conda-forge\r\nptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\r\npure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge\r\npy                        1.11.0             pyh6c4a22f_0    conda-forge\r\npycparser                 2.21               pyhd8ed1ab_0    conda-forge\r\npygments                  2.11.2             pyhd8ed1ab_0    conda-forge\r\npyopenssl                 22.0.0             pyhd8ed1ab_0    conda-forge\r\npyparsing                 3.0.7              pyhd8ed1ab_0    conda-forge\r\npyrsistent                0.18.1           py39h5161555_0    conda-forge\r\npysocks                   1.7.1            py39h2804cbe_4    conda-forge\r\npytest                    7.0.0            py39h2804cbe_0    conda-forge\r\npython                    3.9.10          hd16f9c5_2_cpython    conda-forge\r\npython-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\r\npython_abi                3.9                      2_cp39    conda-forge\r\npytz                      2021.3             pyhd8ed1ab_0    conda-forge\r\npyyaml                    6.0              py39h5161555_3    conda-forge\r\npyzmq                     22.3.0           py39h02c6a76_1    conda-forge\r\nreadline                  8.1                  hedafd6a_0    conda-forge\r\nrequests                  2.27.1             pyhd8ed1ab_0    conda-forge\r\nscipy                     1.8.0            py39h5060c3b_1    conda-forge\r\nsend2trash                1.8.0              pyhd8ed1ab_0    conda-forge\r\nsetuptools                59.8.0           py39h2804cbe_0    conda-forge\r\nsimpervisor               0.4                pyhd8ed1ab_0    conda-forge\r\nsix                       1.16.0             pyh6c4a22f_0    conda-forge\r\nsniffio                   1.2.0            py39h2804cbe_2    conda-forge\r\nsortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge\r\nsqlite                    3.37.0               h72a2b83_0    conda-forge\r\nstack_data                0.1.4              pyhd8ed1ab_0    conda-forge\r\ntblib                     1.7.0              pyhd8ed1ab_0    conda-forge\r\nterminado                 0.13.1           py39h2804cbe_0    conda-forge\r\ntestpath                  0.5.0              pyhd8ed1ab_0    conda-forge\r\ntk                        8.6.11               he1e0b03_1    conda-forge\r\ntomli                     2.0.0              pyhd8ed1ab_1    conda-forge\r\ntoolz                     0.11.2             pyhd8ed1ab_0    conda-forge\r\ntornado                   6.1              py39h5161555_2    conda-forge\r\ntraitlets                 5.1.1              pyhd8ed1ab_0    conda-forge\r\ntyped-ast                 1.5.2            py39h5161555_0    conda-forge\r\ntyping-extensions         4.0.1                hd8ed1ab_0    conda-forge\r\ntyping_extensions         4.0.1              pyha770c72_0    conda-forge\r\ntzdata                    2021e                he74cb21_0    conda-forge\r\nunicodedata2              14.0.0           py39h5161555_0    conda-forge\r\nurllib3                   1.26.8             pyhd8ed1ab_1    conda-forge\r\nwcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\r\nwebencodings              0.5.1                      py_1    conda-forge\r\nwebsocket-client          1.2.3              pyhd8ed1ab_0    conda-forge\r\nwheel                     0.37.1             pyhd8ed1ab_0    conda-forge\r\nxorg-libxau               1.0.9                h27ca646_0    conda-forge\r\nxorg-libxdmcp             1.1.3                h27ca646_0    conda-forge\r\nxz                        5.2.5                h642e427_1    conda-forge\r\nyaml                      0.2.5                h3422bc3_2    conda-forge\r\nyarl                      1.7.2            py39h5161555_1    conda-forge\r\nzeromq                    4.3.4                hbdafb3b_1    conda-forge\r\nzict                      2.0.0                      py_0    conda-forge\r\nzipp                      3.7.0              pyhd8ed1ab_1    conda-forge\r\nzlib                      1.2.11            hee7b306_1013    conda-forge\r\nzstd                      1.5.2                h861e0a7_0    conda-forge\r\n\r\n```\r\n</details>\r\n\r\n<!-- If you are reporting an issue such as scale stability, cluster deadlock.\r\nPlease provide a cluster dump state with this issue, by running client.dump_cluster_state()\r\n\r\nhttps://distributed.dask.org/en/stable/api.html?highlight=dump_cluster_state#distributed.Client.dump_cluster_state\r\n\r\n-->\r\n\r\n<details>\r\n<summary>Cluster Dump State:</summary>\r\n\r\n</details>", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8702/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8702/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8666", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8666/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8666/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8666/events", "html_url": "https://github.com/dask/dask/issues/8666", "id": 1125097907, "node_id": "I_kwDOAbcwm85DD6Gz", "number": 8666, "title": "Column mistmatch prevents append to partitioned parquet dataset with `engine=fastparquet`", "user": {"login": "erinov1", "id": 46730637, "node_id": "MDQ6VXNlcjQ2NzMwNjM3", "avatar_url": "https://avatars.githubusercontent.com/u/46730637?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erinov1", "html_url": "https://github.com/erinov1", "followers_url": "https://api.github.com/users/erinov1/followers", "following_url": "https://api.github.com/users/erinov1/following{/other_user}", "gists_url": "https://api.github.com/users/erinov1/gists{/gist_id}", "starred_url": "https://api.github.com/users/erinov1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erinov1/subscriptions", "organizations_url": "https://api.github.com/users/erinov1/orgs", "repos_url": "https://api.github.com/users/erinov1/repos", "events_url": "https://api.github.com/users/erinov1/events{/privacy}", "received_events_url": "https://api.github.com/users/erinov1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 365513534, "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=", "url": "https://api.github.com/repos/dask/dask/labels/io", "name": "io", "color": "6f871c", "default": false, "description": ""}, {"id": 2949099791, "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx", "url": "https://api.github.com/repos/dask/dask/labels/parquet", "name": "parquet", "color": "77A66C", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2022-02-06T04:02:12Z", "updated_at": "2022-02-21T17:04:58Z", "closed_at": "2022-02-21T17:04:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm unable to append to an existing partitioned parquet dataset when using `engine=fastparquet`, although it works fine with `engine=pyarrow`.\r\n\r\nMWE:\r\n\r\nThe second `to_parquet` call fails:\r\n```\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\ndf = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [1, 1, 2, 2]})\r\ndf = dd.from_pandas(df, npartitions=1)\r\n\r\ndf.to_parquet(\r\n    \"dataset\", \r\n    partition_on=\"B\",\r\n    engine=\"fastparquet\",\r\n    write_index=False,\r\n)\r\ndf.to_parquet(\r\n    \"dataset\", \r\n    partition_on=\"B\",\r\n    engine=\"fastparquet\", \r\n    write_index=False,\r\n    append=True # <----- append!\r\n)\r\n```\r\nTail of traceback:\r\n\r\n```\r\nFile ~/Library/Caches/pypoetry/virtualenvs/project-GfuZs_x0-py3.8/lib/python3.8/site-packages/dask/dataframe/io/parquet/fastparquet.py:1089, in FastParquetEngine.initialize_write(cls, df, fs, path, append, partition_on, ignore_divisions, division_info, schema, object_encoding, index_cols, **kwargs)\r\n   1083     raise ValueError(\r\n   1084         \"Requested file scheme is hive, but existing file scheme is not.\"\r\n   1085     )\r\n   1086 elif (set(pf.columns) != set(df.columns) - set(partition_on)) or (\r\n   1087     set(partition_on) != set(pf.cats)\r\n   1088 ):\r\n-> 1089     raise ValueError(\r\n   1090         \"Appended columns not the same.\\n\"\r\n   1091         \"Previous: {} | New: {}\".format(pf.columns, list(df.columns))\r\n   1092     )\r\n   1093 elif (pd.Series(pf.dtypes).loc[pf.columns] != df[pf.columns].dtypes).any():\r\n   1094     raise ValueError(\r\n   1095         \"Appended dtypes differ.\\n{}\".format(\r\n   1096             set(pf.dtypes.items()) ^ set(df.dtypes.iteritems())\r\n   1097         )\r\n   1098     )\r\n\r\nValueError: Appended columns not the same.\r\nPrevious: ['A'] | New: ['A', 'B']\r\n```\r\nThere is some issue involving the column `B` used for partitioning. On the other hand, the same code works fine with `engine=pyarrow`.\r\n\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2021.12.0\r\n- Fastparquet version: 0.8.0\r\n- Python version: 3.8\r\n- Operating System: OSX", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8666/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8666/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/8637", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8637/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8637/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8637/events", "html_url": "https://github.com/dask/dask/pull/8637", "id": 1118192648, "node_id": "PR_kwDOAbcwm84xxrxK", "number": 8637, "title": "Result of reducing an array should not depend on its chunk-structure!!!", "user": {"login": "ParticularMiner", "id": 78448465, "node_id": "MDQ6VXNlcjc4NDQ4NDY1", "avatar_url": "https://avatars.githubusercontent.com/u/78448465?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ParticularMiner", "html_url": "https://github.com/ParticularMiner", "followers_url": "https://api.github.com/users/ParticularMiner/followers", "following_url": "https://api.github.com/users/ParticularMiner/following{/other_user}", "gists_url": "https://api.github.com/users/ParticularMiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/ParticularMiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ParticularMiner/subscriptions", "organizations_url": "https://api.github.com/users/ParticularMiner/orgs", "repos_url": "https://api.github.com/users/ParticularMiner/repos", "events_url": "https://api.github.com/users/ParticularMiner/events{/privacy}", "received_events_url": "https://api.github.com/users/ParticularMiner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}, {"id": 3798450416, "node_id": "LA_kwDOAbcwm87iZ8Dw", "url": "https://api.github.com/repos/dask/dask/labels/p2", "name": "p2", "color": "ffc133", "default": false, "description": "Affects more than a few users but doesn't prevent core functions"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2022-01-29T11:33:38Z", "updated_at": "2022-02-10T14:20:28Z", "closed_at": "2022-02-10T14:20:27Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/8637", "html_url": "https://github.com/dask/dask/pull/8637", "diff_url": "https://github.com/dask/dask/pull/8637.diff", "patch_url": "https://github.com/dask/dask/pull/8637.patch", "merged_at": "2022-02-10T14:20:27Z"}, "body": "- [x] Closes #8541\r\n- [x] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n\r\nIt's taken me a while to find a good example to motivate the seriousness of #8541 and prove that it is in fact a bug.  I think I might have found one now.  \r\n\r\nAs the source-code currently stands, running the following code to reduce an array gives different results depending on the chunk-structure of the array `x`:\r\n\r\n```python\r\nimport dask.array as da\r\nimport numpy as np\r\n\r\n\r\na, b = 6, 6\r\narray = np.arange(a*b).reshape(a, b)\r\n# Reducing an array should not depend on its chunking pattern!!!\r\nfor chunks in [\r\n    ((3, 3), (2, 1, 2, 1)),\r\n    ((2, 1, 2, 1), (3, 3)),\r\n]:\r\n    x = da.from_array(array, chunks=chunks)\r\n    x_0 = da.reduction(\r\n        x,\r\n        lambda x, axis, keepdims: x,\r\n        lambda x, axis, keepdims: x,\r\n        keepdims=True,\r\n        axis=(0, 1),\r\n        dtype=x.dtype,\r\n        meta=np.array([[]])\r\n    ).compute()\r\n    print(f\"{x_0=}\\n\")\r\n```\r\n\r\nOutput:\r\n```python\r\nx_0=array(\r\n      [[ 0,  1,  2],\r\n       [ 6,  7,  8],\r\n       [12, 13, 14],\r\n       [18, 19, 20],\r\n       [24, 25, 26],\r\n       [30, 31, 32],\r\n       [ 3,  4,  5],\r\n       [ 9, 10, 11],\r\n       [15, 16, 17],\r\n       [21, 22, 23],\r\n       [27, 28, 29],\r\n       [33, 34, 35]]\r\n)\r\n\r\nx_0=array(\r\n      [[ 0,  1,  2,  3,  4,  5],\r\n       [ 6,  7,  8,  9, 10, 11],\r\n       [12, 13, 14, 15, 16, 17],\r\n       [18, 19, 20, 21, 22, 23],\r\n       [24, 25, 26, 27, 28, 29],\r\n       [30, 31, 32, 33, 34, 35]]\r\n)\r\n```\r\n\r\nThis PR fixes this bug yielding the correct output:\r\n```python\r\nx_0=array(\r\n      [[ 0,  1,  2,  3,  4,  5],\r\n       [ 6,  7,  8,  9, 10, 11],\r\n       [12, 13, 14, 15, 16, 17],\r\n       [18, 19, 20, 21, 22, 23],\r\n       [24, 25, 26, 27, 28, 29],\r\n       [30, 31, 32, 33, 34, 35]]\r\n)\r\n\r\nx_0=array(\r\n      [[ 0,  1,  2,  3,  4,  5],\r\n       [ 6,  7,  8,  9, 10, 11],\r\n       [12, 13, 14, 15, 16, 17],\r\n       [18, 19, 20, 21, 22, 23],\r\n       [24, 25, 26, 27, 28, 29],\r\n       [30, 31, 32, 33, 34, 35]]\r\n)\r\n```\r\n\r\nI think the reason why `dask` has gotten away with this bug for so long is that in most cases implemented in `dask/array/reductions.py` (for example, `sum`, `mean`, etc.) the reduction operation is *axis-independent*.  The bug only shows up in \"axis-dependent reductions\". ", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8637/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8637/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/8527", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8527/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8527/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8527/events", "html_url": "https://github.com/dask/dask/pull/8527", "id": 1092783741, "node_id": "PR_kwDOAbcwm84weyqR", "number": 8527, "title": "Fix for `normalize_function` `dataclass` methods", "user": {"login": "scharlottej13", "id": 8620816, "node_id": "MDQ6VXNlcjg2MjA4MTY=", "avatar_url": "https://avatars.githubusercontent.com/u/8620816?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scharlottej13", "html_url": "https://github.com/scharlottej13", "followers_url": "https://api.github.com/users/scharlottej13/followers", "following_url": "https://api.github.com/users/scharlottej13/following{/other_user}", "gists_url": "https://api.github.com/users/scharlottej13/gists{/gist_id}", "starred_url": "https://api.github.com/users/scharlottej13/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scharlottej13/subscriptions", "organizations_url": "https://api.github.com/users/scharlottej13/orgs", "repos_url": "https://api.github.com/users/scharlottej13/repos", "events_url": "https://api.github.com/users/scharlottej13/events{/privacy}", "received_events_url": "https://api.github.com/users/scharlottej13/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1342304743, "node_id": "MDU6TGFiZWwxMzQyMzA0NzQz", "url": "https://api.github.com/repos/dask/dask/labels/core", "name": "core", "color": "000000", "default": false, "description": ""}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2022-01-03T20:07:38Z", "updated_at": "2022-10-04T16:02:10Z", "closed_at": "2022-02-23T01:29:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/8527", "html_url": "https://github.com/dask/dask/pull/8527", "diff_url": "https://github.com/dask/dask/pull/8527.diff", "patch_url": "https://github.com/dask/dask/pull/8527.patch", "merged_at": "2022-02-23T01:29:20Z"}, "body": "- [ ]  see what fails w/ this change (see #8376)\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8527/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8527/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/8517", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8517/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8517/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8517/events", "html_url": "https://github.com/dask/dask/pull/8517", "id": 1087876697, "node_id": "PR_kwDOAbcwm84wPP1L", "number": 8517, "title": "Add `ddf.compute_current_divisions` to get divisions on a sorted index or column", "user": {"login": "jsignell", "id": 4806877, "node_id": "MDQ6VXNlcjQ4MDY4Nzc=", "avatar_url": "https://avatars.githubusercontent.com/u/4806877?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsignell", "html_url": "https://github.com/jsignell", "followers_url": "https://api.github.com/users/jsignell/followers", "following_url": "https://api.github.com/users/jsignell/following{/other_user}", "gists_url": "https://api.github.com/users/jsignell/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsignell/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsignell/subscriptions", "organizations_url": "https://api.github.com/users/jsignell/orgs", "repos_url": "https://api.github.com/users/jsignell/repos", "events_url": "https://api.github.com/users/jsignell/events{/privacy}", "received_events_url": "https://api.github.com/users/jsignell/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}, {"id": 3798450420, "node_id": "LA_kwDOAbcwm87iZ8D0", "url": "https://api.github.com/repos/dask/dask/labels/feature", "name": "feature", "color": "b0f0fa", "default": false, "description": "Something is missing"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2021-12-23T17:09:46Z", "updated_at": "2022-03-08T22:08:53Z", "closed_at": "2022-03-08T22:08:49Z", "author_association": "MEMBER", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/8517", "html_url": "https://github.com/dask/dask/pull/8517", "diff_url": "https://github.com/dask/dask/pull/8517.diff", "patch_url": "https://github.com/dask/dask/pull/8517.patch", "merged_at": "2022-03-08T22:08:48Z"}, "body": "- [ ] Towards #8435\r\n- [ ] Tests added / passed\r\n- [x] Passes `pre-commit run --all-files`\r\n\r\nThe goal of this is to create a well documented method for calculating divisions. The idea is that people can use this method and save the result rather than recalculating divisions potentially ever time they set an index.\r\n\r\nIn my understanding #8435 describes a future state where setting index is split into separate pieces that are all explicit:\r\n\r\n - (if needed) shuffle so that the data is sorted by new index column\r\n - calculate divisions for the partitions of that new index column\r\n - set the index to the new column and divisions to new divisions\r\n\r\nHere are some examples that I think would be better supported by this new flow:\r\n\r\nStart by reading in from a single csv file. This results in a RangeIndex and no partitions\r\n```python\r\nimport dask\r\nimport dask.dataframe as dd\r\n\r\n# write a single csv to a file\r\ndask.datasets.timeseries(freq=\"1H\").compute().to_csv(\"timeseries.csv\")\r\n\r\n# read in from the file and repartition\r\nddf = dd.read_csv(\"timeseries.csv\").repartition(npartitions=3)\r\nddf.divisions\r\n# (None, None, None, None)\r\n```\r\n\r\n## Sorted index\r\n```python\r\n# get the divisions of the dataframe index\r\ndivisions = ddf.ccompute_current_divisions()\r\n# (0, 240, 480, 719)\r\n\r\n# set the divisions on the dataframe\r\nddf.divisions = divisions\r\n```\r\n\r\n## Sorted column\r\n```python\r\n# get the divisions of timestamp\r\ndivisions = ddf.compute_current_divisions(\"timestamp\")\r\n# ('2000-01-01 00:00:00',\r\n#  '2000-01-11 00:00:00',\r\n#  '2000-01-21 00:00:00',\r\n#  '2000-01-30 23:00:00')\r\n\r\n# set the index and divisions on the dataframe\r\nddf = ddf.set_index(\"timestamp\", divisions=divisions)\r\n```\r\n## Unsorted column\r\n```python\r\n# sort dataframe by new index column\r\nddf = ddf.sort_values(\"name\")\r\n\r\n# get the divisions of name\r\ndivisions = ddf.compute_current_divisions(\"name\")\r\n# ('Alice', 'Hannah', 'Norbert', 'Zelda')\r\n\r\n# set the index and divisions on the dataframe\r\nddf = ddf.set_index(\"name\", divisions=divisions)\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8517/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8517/timeline", "performed_via_github_app": null, "state_reason": null}, {"url": "https://api.github.com/repos/dask/dask/issues/8458", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/8458/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/8458/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/8458/events", "html_url": "https://github.com/dask/dask/issues/8458", "id": 1071225193, "node_id": "I_kwDOAbcwm84_2Zlp", "number": 8458, "title": "merge_asof works incorrectly (with reproducible example)", "user": {"login": "kdubovikov", "id": 832185, "node_id": "MDQ6VXNlcjgzMjE4NQ==", "avatar_url": "https://avatars.githubusercontent.com/u/832185?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kdubovikov", "html_url": "https://github.com/kdubovikov", "followers_url": "https://api.github.com/users/kdubovikov/followers", "following_url": "https://api.github.com/users/kdubovikov/following{/other_user}", "gists_url": "https://api.github.com/users/kdubovikov/gists{/gist_id}", "starred_url": "https://api.github.com/users/kdubovikov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kdubovikov/subscriptions", "organizations_url": "https://api.github.com/users/kdubovikov/orgs", "repos_url": "https://api.github.com/users/kdubovikov/repos", "events_url": "https://api.github.com/users/kdubovikov/events{/privacy}", "received_events_url": "https://api.github.com/users/kdubovikov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862289, "node_id": "MDU6TGFiZWwyNDI4NjIyODk=", "url": "https://api.github.com/repos/dask/dask/labels/dataframe", "name": "dataframe", "color": "fbca04", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, {"login": "scharlottej13", "id": 8620816, "node_id": "MDQ6VXNlcjg2MjA4MTY=", "avatar_url": "https://avatars.githubusercontent.com/u/8620816?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scharlottej13", "html_url": "https://github.com/scharlottej13", "followers_url": "https://api.github.com/users/scharlottej13/followers", "following_url": "https://api.github.com/users/scharlottej13/following{/other_user}", "gists_url": "https://api.github.com/users/scharlottej13/gists{/gist_id}", "starred_url": "https://api.github.com/users/scharlottej13/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scharlottej13/subscriptions", "organizations_url": "https://api.github.com/users/scharlottej13/orgs", "repos_url": "https://api.github.com/users/scharlottej13/repos", "events_url": "https://api.github.com/users/scharlottej13/events{/privacy}", "received_events_url": "https://api.github.com/users/scharlottej13/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2021-12-04T14:54:29Z", "updated_at": "2022-03-30T15:12:25Z", "closed_at": "2022-03-30T15:12:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to implement the following logic in dask: https://stackoverflow.com/questions/58810517/pd-merge-asof-with-multiple-matches-per-time-period. The idea is to have merge_asof with multiple matches per time period if the right table contains more than one matching record.\r\n\r\nIn the following example, I try to find all matching events for given payments within a time window before each payment.\r\n\r\nI find that my code works correctly with Pandas, but Dask returns invalid results:\r\n\r\n**UPDATE** I have noticed, that merge_asof with pandas dataframes returns \"right_on\" column. And with dask dataframes it does not. That might be the cause of the problem\r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\nfrom datetime import datetime\r\nfrom dask.distributed import Client\r\nimport numpy as np\r\n\r\ndef merge_payments_events(payments_dd, events_dd, window):\r\n    payments_sorted = payments_dd.sort_values('BORN_DATE')\r\n    events_sorted = events_dd.sort_values('time_event')\r\n\r\n    left_merge = dd.merge_asof(\r\n        payments_sorted, \r\n        events_sorted, \r\n        left_by=['CLIENT_UID'],\r\n        right_by=['CLIENT_UID'], \r\n        left_on='BORN_DATE', \r\n        right_on='time_event',\r\n        tolerance=pd.Timedelta(window), \r\n        direction='backward'\r\n    ).reset_index()\r\n\r\n    right_merge = dd.merge_asof(\r\n        events_sorted, \r\n        payments_sorted, \r\n        left_by=['CLIENT_UID'],\r\n        right_by=['CLIENT_UID'], \r\n        left_on='time_event', \r\n        right_on='BORN_DATE', \r\n        tolerance=pd.Timedelta(window), \r\n        direction='forward'\r\n    ).reset_index()\r\n\r\n    payments_events = left_merge.merge(right_merge, how='outer').dropna(subset=['BORN_DATE'])\r\n    return payments_events\r\n\r\n\r\ndef random_dates(start, end, n, unit='D', seed=None):\r\n    if not seed:  # from piR's answer\r\n        np.random.seed(0)\r\n\r\n    ndays = (end - start).days + 1\r\n    return pd.to_timedelta(np.random.rand(n) * ndays, unit=unit) + start\r\n\r\n\r\nclient = Client()\r\nprint(client.dashboard_link)\r\n\r\nn_payments = 100_000\r\nn_events = 200_000\r\n\r\npayments = pd.DataFrame({\r\n    'BORN_DATE': random_dates(datetime(2021, 1, 1), datetime(2021, 1, 3), n_payments, unit='min'),\r\n    'CLIENT_UID': np.random.randint(1, 10_000, n_payments),\r\n    'id': np.arange(0, n_payments)\r\n})\r\n\r\nevents = pd.DataFrame({\r\n    'time_event': random_dates(datetime(2021, 1, 1), datetime(2021, 1, 3), n_events, unit='min'),\r\n    'CLIENT_UID': np.random.randint(1, 10_000, n_events)\r\n})\r\n\r\npayments_dd = dd.from_pandas(payments, npartitions=10)\r\nevents_dd = dd.from_pandas(events, npartitions=10)\r\n\r\nprint(\"Computed by dask\")\r\ndask_result = merge_payments_events(payments_dd, events_dd, window='1h')\\\r\n    .dropna(subset=['BORN_DATE']).groupby(['id', 'BORN_DATE'])\\\r\n    .count()\\\r\n    .compute()\\\r\n    .value_counts()\r\n\r\nprint(dask_result)\r\n\r\nprint(\"Computed by pandas\")\r\npandas_result = merge_payments_events(payments, events, window='1h')\\\r\n    .dropna(subset=['BORN_DATE'])\\\r\n    .groupby(['id', 'BORN_DATE'])\\\r\n    .count()\\\r\n    .value_counts()\r\n\r\nprint(pandas_result)\r\n```\r\n\r\nI see the following output:\r\n```\r\nComputed by dask\r\nindex  CLIENT_UID  time_event\r\n1      1           0             100000\r\ndtype: int64\r\n\r\nComputed by pandas\r\nindex  CLIENT_UID  time_event\r\n1      1           1             30423\r\n2      2           2             23115\r\n3      3           3             14966\r\n4      4           4              9568\r\n5      5           5              6114\r\n1      1           0              4926\r\n6      6           6              3885\r\n7      7           7              2533\r\n8      8           8              1668\r\n9      9           9              1018\r\n10     10          10              655\r\n11     11          11              401\r\n12     12          12              273\r\n13     13          13              170\r\n14     14          14              108\r\n15     15          15               66\r\n16     16          16               37\r\n17     17          17               25\r\n18     18          18               22\r\n19     19          19                9\r\n20     20          20                8\r\n21     21          21                6\r\n24     24          24                2\r\n22     22          22                1\r\n23     23          23                1\r\ndtype: int64\r\n```\r\n\r\nDask seems to ignore all matches\r\n\r\n- Dask version: 2021.11.2\r\n- Python version: 3.8\r\n- Operating System: macos\r\n- Install method (conda, pip, source): pip\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/8458/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/8458/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/dask/dask/issues/7980", "repository_url": "https://api.github.com/repos/dask/dask", "labels_url": "https://api.github.com/repos/dask/dask/issues/7980/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask/issues/7980/comments", "events_url": "https://api.github.com/repos/dask/dask/issues/7980/events", "html_url": "https://github.com/dask/dask/pull/7980", "id": 958697518, "node_id": "MDExOlB1bGxSZXF1ZXN0NzAxOTM0MTgy", "number": 7980, "title": "Quick fix for unbounded memory usage in tensordot ", "user": {"login": "GenevieveBuckley", "id": 30920819, "node_id": "MDQ6VXNlcjMwOTIwODE5", "avatar_url": "https://avatars.githubusercontent.com/u/30920819?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GenevieveBuckley", "html_url": "https://github.com/GenevieveBuckley", "followers_url": "https://api.github.com/users/GenevieveBuckley/followers", "following_url": "https://api.github.com/users/GenevieveBuckley/following{/other_user}", "gists_url": "https://api.github.com/users/GenevieveBuckley/gists{/gist_id}", "starred_url": "https://api.github.com/users/GenevieveBuckley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GenevieveBuckley/subscriptions", "organizations_url": "https://api.github.com/users/GenevieveBuckley/orgs", "repos_url": "https://api.github.com/users/GenevieveBuckley/repos", "events_url": "https://api.github.com/users/GenevieveBuckley/events{/privacy}", "received_events_url": "https://api.github.com/users/GenevieveBuckley/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 242862305, "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=", "url": "https://api.github.com/repos/dask/dask/labels/array", "name": "array", "color": "006b75", "default": false, "description": null}, {"id": 3798450413, "node_id": "LA_kwDOAbcwm87iZ8Dt", "url": "https://api.github.com/repos/dask/dask/labels/bug", "name": "bug", "color": "faadaf", "default": true, "description": "Something is broken"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 56, "created_at": "2021-08-03T04:01:37Z", "updated_at": "2022-03-18T05:56:25Z", "closed_at": "2022-03-15T21:26:21Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/dask/dask/pulls/7980", "html_url": "https://github.com/dask/dask/pull/7980", "diff_url": "https://github.com/dask/dask/pull/7980.diff", "patch_url": "https://github.com/dask/dask/pull/7980.patch", "merged_at": "2022-03-15T21:26:20Z"}, "body": "This is a quick fix for issue https://github.com/dask/dask/issues/6916\r\n\r\nIt removes the memory problem for non-sparse array types. Note that tensordot with sparse arrays still needs a proper fix for the memory issues observed after https://github.com/dask/dask/pull/6846\r\n\r\n- [ ] Related to issue #https://github.com/dask/dask/issues/6916\r\n- [x] Tests ~added~ / passed\r\n- [x] Passes `black dask` / `flake8 dask` / `isort dask`\r\n", "reactions": {"url": "https://api.github.com/repos/dask/dask/issues/7980/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/dask/dask/issues/7980/timeline", "performed_via_github_app": null, "state_reason": null}]