[{"url": "https://api.github.com/repos/horovod/horovod/issues/3903", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3903/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3903/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3903/events", "html_url": "https://github.com/horovod/horovod/issues/3903", "id": 1686237360, "node_id": "I_kwDOBfOI785kgfCw", "number": 3903, "title": "Horovod distributed optimizer is not working.", "user": {"login": "Shup-46", "id": 102753110, "node_id": "U_kgDOBh_jVg", "avatar_url": "https://avatars.githubusercontent.com/u/102753110?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Shup-46", "html_url": "https://github.com/Shup-46", "followers_url": "https://api.github.com/users/Shup-46/followers", "following_url": "https://api.github.com/users/Shup-46/following{/other_user}", "gists_url": "https://api.github.com/users/Shup-46/gists{/gist_id}", "starred_url": "https://api.github.com/users/Shup-46/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Shup-46/subscriptions", "organizations_url": "https://api.github.com/users/Shup-46/orgs", "repos_url": "https://api.github.com/users/Shup-46/repos", "events_url": "https://api.github.com/users/Shup-46/events{/privacy}", "received_events_url": "https://api.github.com/users/Shup-46/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-04-27T06:59:02Z", "updated_at": "2023-04-27T09:20:47Z", "closed_at": "2023-04-27T09:20:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.12.0\r\n3. Horovod version: 0.27.0\r\n\r\n**Bug report:**\r\nHorovod distributed optimizer is not working even after trying  SGD, Optimizer, etc. nothing is working.\r\n![image](https://user-images.githubusercontent.com/102753110/234783409-b354b07b-451f-4d4c-9c04-2b890df63187.png)\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3903/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3903/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3881", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3881/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3881/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3881/events", "html_url": "https://github.com/horovod/horovod/issues/3881", "id": 1657605030, "node_id": "I_kwDOBfOI785izQum", "number": 3881, "title": "Follow Tensorflow evolution in \"examples/keras/keras_mnist_tf2.py\"", "user": {"login": "PierrickPochelu", "id": 44296854, "node_id": "MDQ6VXNlcjQ0Mjk2ODU0", "avatar_url": "https://avatars.githubusercontent.com/u/44296854?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PierrickPochelu", "html_url": "https://github.com/PierrickPochelu", "followers_url": "https://api.github.com/users/PierrickPochelu/followers", "following_url": "https://api.github.com/users/PierrickPochelu/following{/other_user}", "gists_url": "https://api.github.com/users/PierrickPochelu/gists{/gist_id}", "starred_url": "https://api.github.com/users/PierrickPochelu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PierrickPochelu/subscriptions", "organizations_url": "https://api.github.com/users/PierrickPochelu/orgs", "repos_url": "https://api.github.com/users/PierrickPochelu/repos", "events_url": "https://api.github.com/users/PierrickPochelu/events{/privacy}", "received_events_url": "https://api.github.com/users/PierrickPochelu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-04-06T15:06:58Z", "updated_at": "2023-04-21T09:37:18Z", "closed_at": "2023-04-21T09:35:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\nTensorflow version: 2.12\r\nHorovod version: 0.27.0\r\nPython version: 3.10\r\n\r\n**Bug report:**\r\ntf.Session is not compatible with last tf versions. I propose this new code under the block tagged \"# NEW TF2\".\r\n\r\n**Solution**\r\n```\r\nimport keras\r\nfrom keras.datasets import mnist\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense, Dropout, Flatten\r\nfrom keras.layers import Conv2D, MaxPooling2D\r\nfrom keras import backend as K\r\nimport math\r\nimport tensorflow as tf\r\nimport horovod.keras as hvd\r\n\r\n# Horovod: initialize Horovod.\r\nhvd.init()\r\n\r\n# OLD TF2\r\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\r\n#config = tf.compat.v1.ConfigProto()\r\n#config.gpu_options.allow_growth = True\r\n#config.gpu_options.visible_device_list = str(hvd.local_rank())\r\n#K.set_session(tf.Session(config=config))\r\n\r\n# NEW TF2\r\n# Pin GPU to be used to process local rank (one GPU per process)\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus:\r\n        tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\r\n        tf.config.experimental.set_memory_growth(gpus[hvd.local_rank()], True)\r\n\r\nbatch_size = 128\r\nnum_classes = 10\r\n\r\n# Horovod: adjust number of epochs based on number of GPUs.\r\nepochs = int(math.ceil(12.0 / hvd.size()))\r\n\r\n# Input image dimensions\r\nimg_rows, img_cols = 28, 28\r\n\r\n# The data, shuffled and split between train and test sets\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\nif K.image_data_format() == 'channels_first':\r\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n    input_shape = (1, img_rows, img_cols)\r\nelse:\r\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\r\n    input_shape = (img_rows, img_cols, 1)\r\n\r\nx_train = x_train.astype('float32')\r\nx_test = x_test.astype('float32')\r\nx_train /= 255\r\nx_test /= 255\r\nprint('x_train shape:', x_train.shape)\r\nprint(x_train.shape[0], 'train samples')\r\nprint(x_test.shape[0], 'test samples')\r\n\r\n# Convert class vectors to binary class matrices\r\ny_train = keras.utils.to_categorical(y_train, num_classes)\r\ny_test = keras.utils.to_categorical(y_test, num_classes)\r\n\r\nmodel = Sequential()\r\nmodel.add(Conv2D(32, kernel_size=(3, 3),\r\n                 activation='relu',\r\n                 input_shape=input_shape))\r\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\nmodel.add(Dropout(0.25))\r\nmodel.add(Flatten())\r\nmodel.add(Dense(128, activation='relu'))\r\nmodel.add(Dropout(0.5))\r\nmodel.add(Dense(num_classes, activation='softmax'))\r\n\r\n# Horovod: adjust learning rate based on number of GPUs.\r\nopt = keras.optimizers.Adadelta(1.0 * hvd.size())\r\n\r\n# Horovod: add Horovod Distributed Optimizer.\r\nopt = hvd.DistributedOptimizer(opt)\r\n\r\nmodel.compile(loss=keras.losses.categorical_crossentropy,\r\n              optimizer=opt,\r\n              metrics=['accuracy'])\r\n\r\ncallbacks = [\r\n    # Horovod: broadcast initial variable states from rank 0 to all other processes.\r\n    # This is necessary to ensure consistent initialization of all workers when\r\n    # training is started with random weights or restored from a checkpoint.\r\n    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\r\n]\r\n\r\n# Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\r\nif hvd.rank() == 0:\r\n    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\r\n\r\nmodel.fit(x_train, y_train,\r\n          batch_size=batch_size,\r\n          callbacks=callbacks,\r\n          epochs=epochs,\r\n          verbose=1 if hvd.rank() == 0 else 0,\r\n          validation_data=(x_test, y_test))\r\nscore = model.evaluate(x_test, y_test, verbose=0)\r\nprint('Test loss:', score[0])\r\nprint('Test accuracy:', score[1])\r\n\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3881/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3881/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3861", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3861/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3861/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3861/events", "html_url": "https://github.com/horovod/horovod/issues/3861", "id": 1622099780, "node_id": "I_kwDOBfOI785gr0dE", "number": 3861, "title": "Build error with latest Tensorflow head commit", "user": {"login": "mahmoud-abuzaina", "id": 24963061, "node_id": "MDQ6VXNlcjI0OTYzMDYx", "avatar_url": "https://avatars.githubusercontent.com/u/24963061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mahmoud-abuzaina", "html_url": "https://github.com/mahmoud-abuzaina", "followers_url": "https://api.github.com/users/mahmoud-abuzaina/followers", "following_url": "https://api.github.com/users/mahmoud-abuzaina/following{/other_user}", "gists_url": "https://api.github.com/users/mahmoud-abuzaina/gists{/gist_id}", "starred_url": "https://api.github.com/users/mahmoud-abuzaina/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mahmoud-abuzaina/subscriptions", "organizations_url": "https://api.github.com/users/mahmoud-abuzaina/orgs", "repos_url": "https://api.github.com/users/mahmoud-abuzaina/repos", "events_url": "https://api.github.com/users/mahmoud-abuzaina/events{/privacy}", "received_events_url": "https://api.github.com/users/mahmoud-abuzaina/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2023-03-13T19:13:20Z", "updated_at": "2023-04-04T16:16:48Z", "closed_at": "2023-04-04T16:16:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n3. Framework version: head commit\r\n4. Horovod version: head commit\r\n5. MPI version:\r\n6. CUDA version:\r\n7. NCCL version:\r\n8. Python version: 3.9\r\n9. Spark / PySpark version:\r\n10. Ray version:\r\n11. OS and version: Ubuntu 20.04\r\n12. GCC version: 9.4.0\r\n13. CMake version: 3.16.3\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n   Yes\r\n3. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n4. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n5. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nHorovod build fails with latest Tensorflow head commit. [This TF commit](https://github.com/intel-innersource/frameworks.ai.tensorflow.private-tensorflow/commit/980747f3fba63b847c39c774f3201c3e69248552) seems causing below error:\r\n`      /tmp/pip-req-build-w5l58v3a/horovod/tensorflow/mpi_ops.cc:1104:55: error: cannot convert \u00e2\u20ac\u02dcconst bool\u00e2\u20ac\u2122 to \u00e2\u20ac\u02dctensorflow::Var**\u00e2\u20ac\u2122\r\n       1104 |                                                       sparse, &var);\r\n            |                                                       ^~~~~~\r\n            |                                                       |\r\n            |                                                       const bool`", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3861/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3861/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3850", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3850/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3850/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3850/events", "html_url": "https://github.com/horovod/horovod/issues/3850", "id": 1588176643, "node_id": "I_kwDOBfOI785eqacD", "number": 3850, "title": "Docker build horovod-nvtabular fails", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-02-16T18:34:51Z", "updated_at": "2023-02-17T09:35:01Z", "closed_at": "2023-02-17T09:35:01Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "`pip` installing `cudf-cu11` results in an error:\r\n```\r\n#12 [ 7/37] RUN pip install --no-cache-dir cudf-cu11 dask-cudf-cu11 --extra-index-url=https://pypi.ngc.nvidia.com/\r\n#12 1.247 Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com/\r\n#12 2.285 Collecting cudf-cu11\r\n#12 2.391   Downloading cudf_cu11-23.2.0.tar.gz (6.5 kB)\r\n#12 2.525     ERROR: Command errored out with exit status 1:\r\n#12 2.525      command: /usr/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-lwkt7jbg/cudf-cu11/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-lwkt7jbg/cudf-cu11/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-install-lwkt7jbg/cudf-cu11/pip-egg-info\r\n#12 2.525          cwd: /tmp/pip-install-lwkt7jbg/cudf-cu11/\r\n#12 2.525     Complete output (5 lines):\r\n#12 2.525     Traceback (most recent call last):\r\n#12 2.525       File \"<string>\", line 1, in <module>\r\n#12 2.525       File \"/tmp/pip-install-lwkt7jbg/cudf-cu11/setup.py\", line 137, in <module>\r\n#12 2.525         raise RuntimeError(open(\"ERROR.txt\", \"r\").read())\r\n#12 2.525     FileNotFoundError: [Errno 2] No such file or directory: 'ERROR.txt'\r\n#12 2.525     ----------------------------------------\r\n```\r\nhttps://github.com/horovod/horovod/actions/runs/4192929617/jobs/7277248027", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3850/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3850/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3849", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3849/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3849/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3849/events", "html_url": "https://github.com/horovod/horovod/issues/3849", "id": 1587403535, "node_id": "I_kwDOBfOI785endsP", "number": 3849, "title": "Ray test errors with head framework versions: protobuf incompatibility", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 5149003637, "node_id": "LA_kwDOBfOI788AAAABMuePdQ", "url": "https://api.github.com/repos/horovod/horovod/labels/ray", "name": "ray", "color": "4AD2DF", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2023-02-16T10:14:20Z", "updated_at": "2023-02-18T14:54:55Z", "closed_at": "2023-02-18T14:54:55Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "```\r\n___________________ ERROR collecting test/single/test_ray.py ___________________\r\ntest_ray.py:10: in <module>\r\n    import ray\r\n/usr/local/lib/python3.8/dist-packages/ray/__init__.py:77: in <module>\r\n    import ray._raylet  # noqa: E402\r\npython/ray/_raylet.pyx:103: in init ray._raylet\r\n    ???\r\n/usr/local/lib/python3.8/dist-packages/ray/_private/gcs_utils.py:1: in <module>\r\n    from ray.core.generated.common_pb2 import ErrorType\r\n/usr/local/lib/python3.8/dist-packages/ray/core/generated/common_pb2.py:33: in <module>\r\n    _descriptor.EnumValueDescriptor(\r\n/usr/local/lib/python3.8/dist-packages/google/protobuf/descriptor.py:755: in __new__\r\n    _message.Message._CheckCalledFromGeneratedFile()\r\nE   TypeError: Descriptors cannot not be created directly.\r\nE   If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\r\nE   If you cannot immediately regenerate your protos, some other possible workarounds are:\r\nE    1. Downgrade the protobuf package to 3.20.x or lower.\r\nE    2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\r\nE   \r\nE   More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\r\n```\r\nexample from https://github.com/horovod/horovod/actions/runs/4172644709/jobs/7226444407", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3849/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3849/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3844", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3844/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3844/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3844/events", "html_url": "https://github.com/horovod/horovod/issues/3844", "id": 1581974540, "node_id": "I_kwDOBfOI785eSwQM", "number": 3844, "title": "I can run the script on one machine, but error occurs on two machines.", "user": {"login": "caiduoduo12138", "id": 55495912, "node_id": "MDQ6VXNlcjU1NDk1OTEy", "avatar_url": "https://avatars.githubusercontent.com/u/55495912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caiduoduo12138", "html_url": "https://github.com/caiduoduo12138", "followers_url": "https://api.github.com/users/caiduoduo12138/followers", "following_url": "https://api.github.com/users/caiduoduo12138/following{/other_user}", "gists_url": "https://api.github.com/users/caiduoduo12138/gists{/gist_id}", "starred_url": "https://api.github.com/users/caiduoduo12138/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caiduoduo12138/subscriptions", "organizations_url": "https://api.github.com/users/caiduoduo12138/orgs", "repos_url": "https://api.github.com/users/caiduoduo12138/repos", "events_url": "https://api.github.com/users/caiduoduo12138/events{/privacy}", "received_events_url": "https://api.github.com/users/caiduoduo12138/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2023-02-13T09:30:47Z", "updated_at": "2023-02-14T03:29:31Z", "closed_at": "2023-02-14T03:29:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework:  PyTorch\r\n2. Framework version:1.12\r\n3. Horovod version:0.22.0\r\n4. MPI version:4.0.7\r\n5. CUDA version:11.6\r\n6. NCCL version:2.11.4\r\n7. Python version:3.8\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version:ubuntu20.04\r\n11. GCC version:9.4.0\r\n12. CMake version:3.16.3\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? it is not hang\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? \r\nit is not docker\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? yes\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\nThe script is successfully running on the single macniche.(horovodrun -np 8 -H localhost:8  python3 pytorch_mnist.py)\r\nHowever, when I run the script(horovodrun -np 2 -H 10.250.2.12:1,10.250.2.8:1 python3 pytorch_mnist.py), error occurs. The log is before(NCCL_DEBUG=info)\r\nThe ssh can connect the other machine(eg: ssh 10.250.2.12 or ssh 10.250.2.8)\r\n\r\n[log-debug.txt](https://github.com/horovod/horovod/files/10720682/log-debug.txt)\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3844/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3844/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3842", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3842/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3842/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3842/events", "html_url": "https://github.com/horovod/horovod/issues/3842", "id": 1575366878, "node_id": "I_kwDOBfOI785d5jDe", "number": 3842, "title": "Problem with using MPI for training-related communications on Horovod + Ray", "user": {"login": "KinanAlAttar", "id": 50109313, "node_id": "MDQ6VXNlcjUwMTA5MzEz", "avatar_url": "https://avatars.githubusercontent.com/u/50109313?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KinanAlAttar", "html_url": "https://github.com/KinanAlAttar", "followers_url": "https://api.github.com/users/KinanAlAttar/followers", "following_url": "https://api.github.com/users/KinanAlAttar/following{/other_user}", "gists_url": "https://api.github.com/users/KinanAlAttar/gists{/gist_id}", "starred_url": "https://api.github.com/users/KinanAlAttar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KinanAlAttar/subscriptions", "organizations_url": "https://api.github.com/users/KinanAlAttar/orgs", "repos_url": "https://api.github.com/users/KinanAlAttar/repos", "events_url": "https://api.github.com/users/KinanAlAttar/events{/privacy}", "received_events_url": "https://api.github.com/users/KinanAlAttar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 5149003637, "node_id": "LA_kwDOBfOI788AAAABMuePdQ", "url": "https://api.github.com/repos/horovod/horovod/labels/ray", "name": "ray", "color": "4AD2DF", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2023-02-08T02:46:57Z", "updated_at": "2023-02-22T20:23:05Z", "closed_at": "2023-02-22T20:23:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.5.0\r\n3. Horovod version: 0.23.0\r\n4. MPI version: MVAPICH2 2.3.7/mpi4py 3.1.4 \r\n5. CUDA version: 11.2\r\n6. NCCL version: N/A\r\n7. Python version: 3.7.15\r\n8. Spark / PySpark version: N/A\r\n9. Ray version: 2.2.0\r\n10. OS and version: Centos 7\r\n11. GCC version: 9.4.0\r\n12. CMake version: 3.22.2\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\nIssue #3055 is sort of related\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\nN/A\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\nN/A\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\nN/A\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nI'm trying to run horovod + ray in such a way where I can leverage MPI for training-related communication. In the next lines, I will go through the build command I used, the error I got, and finally the program I'm running (which is really `pytorch_synthetic_benchmark.py` with ray). I'm running the application on a ray cluster of three nodes, a head node and two worker node.\r\n\r\n-- The build command I used,\r\n`HOROVOD_WITH_PYTORCH=1 HOROVOD_GPU_OPERATIONS=MPI HOROVOD_WITH_GLOO=1 HOROVOD_WITHOUT_TENSORFLOW=1 HOROVOD_WITH_MPI=1 CC=$(which mpicc) CXX=$(which mp\r\nicxx) pip install -e .`\r\n\r\n-- command I'm running,\r\n`mpirun_rsh --np 2 --hostfile hostfile python pytorch_synthetic_benchmark.py`\r\n\r\n```\r\ncat hostfile\r\ngpu01\r\ngpu02\r\ngpu03\r\n```\r\n\r\n-- The output of the command,\r\n```\r\n2023-02-07 21:53:23,535 INFO worker.py:1352 -- Connecting to existing Ray cluster at address: 10.1.1.1:6379...\r\n2023-02-07 21:53:23,543 INFO worker.py:1538 -- Connected to Ray cluster.\r\n2023-02-07 21:53:24,353 INFO worker.py:1352 -- Connecting to existing Ray cluster at address: 10.1.1.1:6379...\r\n2023-02-07 21:53:24,365 INFO worker.py:1538 -- Connected to Ray cluster.\r\n\r\nTraceback (most recent call last):\r\n  File \"pytorch_synthetic_benchmark.py\", line 139, in <module>\r\n    executor.start()\r\n  File \"/home/alattar.2/quentin-horvod-tar/deepinstrospect/horovod/ray/runner.py\", line 320, in start\r\n    return self._maybe_call_ray(self.adapter.start, **kwargs_)\r\n  File \"/home/alattar.2/quentin-horvod-tar/deepinstrospect/horovod/ray/runner.py\", line 419, in _maybe_call_ray\r\n    return driver_func(**kwargs)\r\n  File \"/home/alattar.2/quentin-horvod-tar/deepinstrospect/horovod/ray/runner.py\", line 563, in start\r\n    node_workers=node_workers)\r\n  File \"/home/alattar.2/quentin-horvod-tar/deepinstrospect/horovod/ray/utils.py\", line 72, in detect_nics\r\n    settings)\r\n  File \"/home/alattar.2/quentin-horvod-tar/deepinstrospect/horovod/ray/driver_service.py\", line 59, in _driver_fn\r\n    return _run_probe(driver, settings, num_hosts)\r\n  File \"/home/alattar.2/quentin-horvod-tar/deepinstrospect/horovod/runner/driver/driver_service.py\", line 126, in _run_probe\r\n    driver.wait_for_initial_registration(settings.start_timeout)\r\n  File \"/home/alattar.2/quentin-horvod-tar/deepinstrospect/horovod/runner/common/service/driver_service.py\", line 166, in wait_for_initial_registration\r\n    timeout.check_time_out_for('tasks to start')\r\n  File \"/home/alattar.2/quentin-horvod-tar/deepinstrospect/horovod/runner/common/util/timeout.py\", line 37, in check_time_out_for\r\n    self._timeout\r\nException: Timed out waiting for tasks to start. Please check connectivity between servers. You may need to increase the --start-timeout parameter if you have too many servers. Timeout after 30 seconds.\r\n2023-02-07 21:53:54,964 ERROR worker.py:401 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): ray::BaseHorovodWorker.execute() (pid=24246, ip=10.1.1.2, repr=<horovod.ray.worker.BaseHorovodWorker object at 0x2b9471081ad0>)\r\n  File \"/home/alattar.2/quentin-horvod-tar/deepinstrospect/horovod/ray/driver_service.py\", line 11, in execute_task_fn\r\n    _task_fn(index, num_hosts, driver_addresses, settings)\r\n  File \"/home/alattar.2/quentin-horvod-tar/deepinstrospect/horovod/runner/task_fn.py\", line 31, in _task_fn\r\n    task.wait_for_initial_registration(settings.start_timeout)\r\n  File \"/home/alattar.2/quentin-horvod-tar/deepinstrospect/horovod/runner/common/service/task_service.py\", line 253, in wait_for_initial_registration\r\n    timeout.check_time_out_for('tasks to start')\r\n  File \"/home/alattar.2/quentin-horvod-tar/deepinstrospect/horovod/runner/common/util/timeout.py\", line 37, in check_time_out_for\r\n    self._timeout\r\nException: Timed out waiting for tasks to start. Please check connectivity between servers. You may need to increase the --start-timeout parameter if you have too many servers. Timeout after 30 seconds.\r\n[gpu01.cluster:mpispawn_0][child_handler] MPI process (rank: 0, pid: 25620) exited with status 1\r\n```\r\n\r\nThe file I'm running,\r\n```python\r\nimport argparse\r\n#import torch.backends.cudnn as cudnn\r\nimport torch.nn.functional as F\r\nimport torch.optim as optim\r\nimport torch.utils.data.distributed\r\nfrom torchvision import models\r\nimport horovod.torch as hvd\r\nimport timeit\r\nimport numpy as np\r\n\r\n# Benchmark settings\r\nparser = argparse.ArgumentParser(description='PyTorch Synthetic Benchmark',\r\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\r\nparser.add_argument('--fp16-allreduce', action='store_true', default=False,\r\n                    help='use fp16 compression during allreduce')\r\n\r\nparser.add_argument('--model', type=str, default='resnet50',\r\n                    help='model to benchmark')\r\nparser.add_argument('--batch-size', type=int, default=1,\r\n                    help='input batch size')\r\n\r\nparser.add_argument('--num-warmup-batches', type=int, default=1,\r\n                    help='number of warm-up batches that don\\'t count towards benchmark')\r\nparser.add_argument('--num-batches-per-iter', type=int, default=1,\r\n                    help='number of batches per benchmark iteration')\r\nparser.add_argument('--num-iters', type=int, default=1,\r\n                    help='number of benchmark iterations')\r\n\r\nparser.add_argument('--no-cuda', action='store_true', default=False,\r\n                    help='disables CUDA training')\r\n\r\nparser.add_argument('--use-adasum', action='store_true', default=False,\r\n                    help='use adasum algorithm to do reduction')\r\n\r\nargs = parser.parse_args()\r\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\r\n\r\n\r\ndef benchmark_step(optimizer, model, data, target):\r\n    optimizer.zero_grad()\r\n    output = model(data)\r\n    loss = F.cross_entropy(output, target)\r\n    loss.backward()\r\n    optimizer.step()\r\n\r\n\r\ndef log(s, nl=True):\r\n    if hvd.rank() != 0:\r\n        return\r\n    print(s, end='\\n' if nl else '')\r\n\r\n\r\ndef start_bench():\r\n    hvd.init()\r\n\r\n    if args.cuda:\r\n        # Horovod: pin GPU to local rank.\r\n        torch.cuda.set_device(hvd.local_rank())\r\n\r\n    #cudnn.benchmark = False\r\n\r\n    # Set up standard model.\r\n    model = getattr(models, args.model)()\r\n\r\n    # By default, Adasum doesn't need scaling up learning rate.\r\n    lr_scaler = hvd.size() if not args.use_adasum else 1\r\n\r\n    optimizer = optim.SGD(model.parameters(), lr=0.01 * lr_scaler)\r\n\r\n    if args.cuda:\r\n        # Move model to GPU.\r\n        model.cuda()\r\n        # If using GPU Adasum allreduce, scale learning rate by local_size.\r\n        if args.use_adasum and hvd.nccl_built():\r\n            lr_scaler = hvd.local_size()\r\n\r\n    # Horovod: (optional) compression algorithm.\r\n    compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\r\n\r\n    # Horovod: wrap optimizer with DistributedOptimizer.\r\n    optimizer = hvd.DistributedOptimizer(optimizer,\r\n                                         named_parameters=model.named_parameters(),\r\n                                         compression=compression,\r\n                                         op=hvd.Adasum if args.use_adasum else hvd.Average)\r\n\r\n    # Horovod: broadcast parameters & optimizer state.\r\n    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\n    hvd.broadcast_optimizer_state(optimizer, root_rank=0)\r\n\r\n    # Set up fixed fake data\r\n    data = torch.randn(args.batch_size, 3, 224, 224)\r\n    target = torch.LongTensor(args.batch_size).random_() % 1000\r\n    if args.cuda:\r\n        data, target = data.cuda(), target.cuda()\r\n\r\n    log('Model: %s' % args.model)\r\n    log('Batch size: %d' % args.batch_size)\r\n    device = 'GPU' if args.cuda else 'CPU'\r\n    log('Number of %ss: %d' % (device, hvd.size()))\r\n\r\n    # Warm-up\r\n    log('Running warmup...')\r\n    timeit.timeit(lambda: benchmark_step(optimizer, model, data, target), number=args.num_warmup_batches)\r\n\r\n    # Benchmark\r\n    log('Running benchmark...')\r\n    img_secs = []\r\n    for x in range(args.num_iters):\r\n        time = timeit.timeit(lambda: benchmark_step(optimizer, model, data, target), number=args.num_batches_per_iter)\r\n        img_sec = args.batch_size * args.num_batches_per_iter / time\r\n        log('Iter #%d: %.1f img/sec per %s' % (x, img_sec, device))\r\n        img_secs.append(img_sec)\r\n\r\n    # Results\r\n    img_sec_mean = np.mean(img_secs)\r\n    img_sec_conf = 1.96 * np.std(img_secs)\r\n    log('Img/sec per %s: %.1f +-%.1f' % (device, img_sec_mean, img_sec_conf))\r\n    log('Total img/sec on %d %s(s): %.1f +-%.1f' %\r\n        (hvd.size(), device, hvd.size() * img_sec_mean, hvd.size() * img_sec_conf))\r\n\r\nif __name__ == '__main__':\r\n    from horovod.ray import RayExecutor\r\n    import ray\r\n\r\n    ray.init()\r\n\r\n    num_hosts=3\r\n    num_workers_per_host=1\r\n\r\n    settings=RayExecutor.create_settings(ssh_identity_file=\"./hostfile\")\r\n    executor = RayExecutor(\r\n        settings,\r\n        #num_hosts=num_hosts,\r\n        #num_workers_per_host=num_workers_per_host,\r\n        gpus_per_worker=1,\r\n        num_workers=2,\r\n        use_gpu=True)\r\n\r\n    executor.start()\r\n    executor.run(start_bench)\r\n    executor.shutdown()\r\n```\r\n\r\nI'm not sure where I'm going wrong here. Would highly appreciate it if you can help identify anything obvious that I may be missing here.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3842/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3842/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3838", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3838/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3838/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3838/events", "html_url": "https://github.com/horovod/horovod/issues/3838", "id": 1571082057, "node_id": "I_kwDOBfOI785dpM9J", "number": 3838, "title": "[ROCm] /horovod/common/operations.cc:1808: Error: `status` not declared during build", "user": {"login": "R0n12", "id": 59843980, "node_id": "MDQ6VXNlcjU5ODQzOTgw", "avatar_url": "https://avatars.githubusercontent.com/u/59843980?v=4", "gravatar_id": "", "url": "https://api.github.com/users/R0n12", "html_url": "https://github.com/R0n12", "followers_url": "https://api.github.com/users/R0n12/followers", "following_url": "https://api.github.com/users/R0n12/following{/other_user}", "gists_url": "https://api.github.com/users/R0n12/gists{/gist_id}", "starred_url": "https://api.github.com/users/R0n12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/R0n12/subscriptions", "organizations_url": "https://api.github.com/users/R0n12/orgs", "repos_url": "https://api.github.com/users/R0n12/repos", "events_url": "https://api.github.com/users/R0n12/events{/privacy}", "received_events_url": "https://api.github.com/users/R0n12/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2023-02-04T19:04:16Z", "updated_at": "2023-02-06T16:04:11Z", "closed_at": "2023-02-06T16:04:11Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: v1.12.1_src\r\n3. Horovod version: v0.27.0\r\n4. MPI version: N/A\r\n5. ROCm version: 5.1.1\r\n6. NCCL version: N/A\r\n7. Python version: 3.9.16\r\n8. Spark / PySpark version: N/A\r\n9. Ray version: N/A\r\n10. OS and version:\r\n11. GCC version: 10.3.0\r\n12. CMake version: 3.22.2\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nBuilding Horovod v0.27.0 with PyTorch-ROCm produces the following error:\r\n\r\n```\r\n[ 79%] Building CXX object horovod/torch/CMakeFiles/pytorch.dir/__/common/optim/gaussian_process.cc.o\r\ncd /home/xu.3304/horovod/build/temp.linux-x86_64-cpython-39/RelWithDebInfo/horovod/torch && /opt/gcc/10.3.0/bin/g++ -DEIGEN_MPL2_ONLY=1 -DHAVE_GLOO=1 -DHAVE_GPU=1 -DHAVE_NCCL=1 -DHAVE_ROCM=1 -DHOROVOD_GPU_ALLGATHER=78 -DHOROVOD_GPU_ALLREDUCE=78 -DHOROVOD_GPU_ALLTOALL=78 -DHOROVOD_GPU_BROADCAST=78 -DHOROVOD_GPU_REDUCESCATTER=78 -DPYTORCH_VERSION=1012000000 -DTORCH_API_INCLUDE_EXTENSION_H=1 -D__HIP_PLATFORM_AMD__=1 -D__HIP_PLATFORM_HCC__=1 -Dpytorch_EXPORTS -I/home/xu.3304/horovod/third_party/HTTPRequest/include -I/home/xu.3304/horovod/third_party/boost/assert/include -I/home/xu.3304/horovod/third_party/boost/config/include -I/home/xu.3304/horovod/third_party/boost/core/include -I/home/xu.3304/horovod/third_party/boost/detail/include -I/home/xu.3304/horovod/third_party/boost/iterator/include -I/home/xu.3304/horovod/third_party/boost/lockfree/include -I/home/xu.3304/horovod/third_party/boost/mpl/include -I/home/xu.3304/horovod/third_party/boost/parameter/include -I/home/xu.3304/horovod/third_party/boost/predef/include -I/home/xu.3304/horovod/third_party/boost/preprocessor/include -I/home/xu.3304/horovod/third_party/boost/static_assert/include -I/home/xu.3304/horovod/third_party/boost/type_traits/include -I/home/xu.3304/horovod/third_party/boost/utility/include -I/home/xu.3304/horovod/third_party/lbfgs/include -I/home/xu.3304/horovod/third_party/gloo -I/home/xu.3304/horovod/third_party/eigen -I/home/xu.3304/horovod/third_party/flatbuffers/include -isystem /opt/rocm-5.1.1/include -isystem /opt/rocm-5.1.1/rccl/include -isystem /home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.27.0/lib/python3.9/site-packages/torch/include -isystem /home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.27.0/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.27.0/lib/python3.9/site-packages/torch/include/TH -isystem /home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.27.0/lib/python3.9/site-packages/torch/include/THC -isystem /home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.27.0/lib/python3.9/site-packages/torch/include/THH -isystem /opt/rocm-5.1.1/miopen/include -isystem /opt/rocm-5.1.1/hip/include -isystem /home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.27.0/include/python3.9 -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -D_GLIBCXX_USE_CXX11_ABI=1 -D__HIP_PLATFORM_HCC__=1  -pthread -fPIC -Wall -ftree-vectorize -mf16c -mavx -mfma -O3 -g -DNDEBUG -fPIC -std=c++14 -MD -MT horovod/torch/CMakeFiles/pytorch.dir/__/common/optim/gaussian_process.cc.o -MF CMakeFiles/pytorch.dir/__/common/optim/gaussian_process.cc.o.d -o CMakeFiles/pytorch.dir/__/common/optim/gaussian_process.cc.o -c /home/xu.3304/horovod/horovod/common/optim/gaussian_process.cc\r\n/home/xu.3304/horovod/horovod/common/operations.cc: In function \u2018horovod::common::Status horovod::common::EnqueueTensorReducescatters(std::vector<std::shared_ptr<horovod::common::OpContext> >&, std::vector<std::shared_ptr<horovod::common::Tensor> >&, std::vector<horovod::common::ReadyEventList>&, std::vector<std::__cxx11::basic_string<char> >&, int, std::vector<std::function<void(const horovod::common::Status&)> >&, horovod::common::ReduceOp, int32_t, double, double)\u2019:\r\n/home/xu.3304/horovod/horovod/common/operations.cc:1808:12: error: \u2018status\u2019 was not declared in this scope; did you mean \u2018Status\u2019?\r\n 1808 |     return status.Aborted(\"AVERAGE not allowed.\");\r\n      |            ^~~~~~\r\n      |            Status\r\n```\r\nThe error is pretty straightforward, it happens at `horovod/common/operations.cc`, the function `EnqueueTensorReducescatters` doesn't declare a `status`\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3838/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3838/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3837", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3837/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3837/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3837/events", "html_url": "https://github.com/horovod/horovod/issues/3837", "id": 1568549929, "node_id": "I_kwDOBfOI785dfiwp", "number": 3837, "title": "[ROCm] torch/adapter_v2.cc requring cuda_runtime_api.h on ROCm builds", "user": {"login": "R0n12", "id": 59843980, "node_id": "MDQ6VXNlcjU5ODQzOTgw", "avatar_url": "https://avatars.githubusercontent.com/u/59843980?v=4", "gravatar_id": "", "url": "https://api.github.com/users/R0n12", "html_url": "https://github.com/R0n12", "followers_url": "https://api.github.com/users/R0n12/followers", "following_url": "https://api.github.com/users/R0n12/following{/other_user}", "gists_url": "https://api.github.com/users/R0n12/gists{/gist_id}", "starred_url": "https://api.github.com/users/R0n12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/R0n12/subscriptions", "organizations_url": "https://api.github.com/users/R0n12/orgs", "repos_url": "https://api.github.com/users/R0n12/repos", "events_url": "https://api.github.com/users/R0n12/events{/privacy}", "received_events_url": "https://api.github.com/users/R0n12/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/7", "html_url": "https://github.com/horovod/horovod/milestone/7", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/7/labels", "id": 8991643, "node_id": "MI_kwDOBfOI784AiTOb", "number": 7, "title": "v0.28.0", "description": "All issues and pull requests that we want to see in this release.", "creator": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 7, "state": "open", "created_at": "2023-02-01T15:30:46Z", "updated_at": "2023-04-27T21:53:40Z", "due_on": null, "closed_at": null}, "comments": 7, "created_at": "2023-02-02T18:19:58Z", "updated_at": "2023-02-16T10:16:21Z", "closed_at": "2023-02-16T10:16:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: v1.12.1_src\r\n3. Horovod version: v0.26.1\r\n4. MPI version: MVAPICH2-GDR-v2.3.7-ROCm\r\n5. ROCm version: 5.1.1\r\n6. NCCL version: N/A\r\n7. Python version: 3.9.16\r\n8. Spark / PySpark version: N/A\r\n9. Ray version: N/A\r\n10. OS and version: Rocky Linux release 8.5 (Green Obsidian)\r\n11. GCC version: 10.3.0\r\n12. CMake version: 3.22.2\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\nYes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nCompilation Error:\r\n\r\nBuiding `horovod/torch/CMakeFiles/pytorch.dir/adapter_v2.cc.o` requires `cuda_runtime_api.h`\r\n\r\n```\r\n[ 97%] Building CXX object horovod/torch/CMakeFiles/pytorch.dir/adapter_v2.cc.o\r\ncd /home/xu.3304/horovod/build/temp.linux-x86_64-cpython-39/RelWithDebInfo/horovod/torch && /home/xu.3304/mvapich2-install/amd/gdr2.3.7_rocm5.1.1_gcc10.3.0/bin/mpicxx -DEIGEN_MPL2_ONLY=1 -DHAVE_GPU=1 -DHAVE_MPI=1 -DHAVE_ROCM=1 -DHOROVOD_GPU_ALLREDUCE=77 -DPYTORCH_VERSION=1012000000 -DTORCH_API_INCLUDE_EXTENSION_H=1 -Dpytorch_EXPORTS -I/home/xu.3304/horovod/third_party/HTTPRequest/include -I/home/xu.3304/horovod/third_party/boost/assert/include -I/home/xu.3304/horovod/third_party/boost/config/include -I/home/xu.3304/horovod/third_party/boost/core/include -I/home/xu.3304/horovod/third_party/boost/detail/include -I/home/xu.3304/horovod/third_party/boost/iterator/include -I/home/xu.3304/horovod/third_party/boost/lockfree/include -I/home/xu.3304/horovod/third_party/boost/mpl/include -I/home/xu.3304/horovod/third_party/boost/parameter/include -I/home/xu.3304/horovod/third_party/boost/predef/include -I/home/xu.3304/horovod/third_party/boost/preprocessor/include -I/home/xu.3304/horovod/third_party/boost/static_assert/include -I/home/xu.3304/horovod/third_party/boost/type_traits/include -I/home/xu.3304/horovod/third_party/boost/utility/include -I/home/xu.3304/horovod/third_party/lbfgs/include -I/home/xu.3304/horovod/third_party/eigen -I/home/xu.3304/horovod/third_party/flatbuffers/include -isystem /opt/rocm-5.1.1/include -isystem /home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.26.1-mv2gdr2.3.7rocm/lib/python3.9/site-packages/torch/include -isystem /home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.26.1-mv2gdr2.3.7rocm/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.26.1-mv2gdr2.3.7rocm/lib/python3.9/site-packages/torch/include/TH -isystem /home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.26.1-mv2gdr2.3.7rocm/lib/python3.9/site-packages/torch/include/THC -isystem /home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.26.1-mv2gdr2.3.7rocm/lib/python3.9/site-packages/torch/include/THH -isystem /opt/rocm-5.1.1/miopen/include -isystem /home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.26.1-mv2gdr2.3.7rocm/include/python3.9 -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -D_GLIBCXX_USE_CXX11_ABI=1 -D__HIP_PLATFORM_HCC__=1  -pthread -fPIC -Wall -ftree-vectorize -mf16c -mavx -mfma -O3 -g -DNDEBUG -fPIC -std=c++14 -MD -MT horovod/torch/CMakeFiles/pytorch.dir/adapter_v2.cc.o -MF CMakeFiles/pytorch.dir/adapter_v2.cc.o.d -o CMakeFiles/pytorch.dir/adapter_v2.cc.o -c /home/xu.3304/horovod/horovod/torch/adapter_v2.cc\r\nIn file included from /home/xu.3304/horovod/horovod/torch/adapter_v2.cc:17:\r\n/home/xu.3304/miniconda3/envs/torch1.12.1-hvd0.26.1-mv2gdr2.3.7rocm/lib/python3.9/site-packages/torch/include/c10/cuda/CUDAStream.h:6:10: fatal error: cuda_runtime_api.h: No such file or directory\r\n    6 | #include <cuda_runtime_api.h>\r\n      |          ^~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\n```\r\nNote: This is a pure ROCm build\r\n1. MVAPICH2-GDR backend is built from source with only ROCm support\r\n2. Pytorch v1.12.1 is built from source with MVAPICH2-GDR as backend and is a pure ROCm build\r\n3. Since all components are built from ROCm, should the condition change when checking if there's a CUDA header? There won't be a `cuda_runtime_api.h` for a ROCm built pytorch. Please correct me if I am wrong.\r\n4. I noticed that the file is hipified but the version didn't get picked up during building\r\n```\r\n/home/xu.3304/horovod/horovod/torch/adapter_v2.cc -> /home/xu.3304/horovod/horovod/torch/adapter_v2_hip.cc [ok]\r\n```\r\n\r\nHorovod build from source command: \r\n```\r\nHOROVOD_ROCM_HOME=/opt/rocm-$ROCM_VERSION \\\r\nCC=$(which mpicc) \\\r\nCXX=$(which mpicxx) \\\r\nHOROVOD_WITHOUT_GLOO=1 \\\r\nHOROVOD_WITH_MPI=1 \\\r\nHOROVOD_GPU=ROCM \\\r\nHOROVOD_GPU_ALLREDUCE=MPI \\\r\nHOROVOD_WITHOUT_TENSORFLOW=1 \\\r\nHOROVOD_WITH_PYTORCH=1 \\\r\nHOROVOD_WITHOUT_MXNET=1 \\\r\n/home/xu.3304/miniconda3/envs/$CONDA_ENV/bin/python setup.py install\r\n```\r\nI have attached a full horovod install log.\r\n[hvd0.26.1_torch1.12.1_gdr2.3.7_rocm5.1.1_gcc10.3.0.log](https://github.com/horovod/horovod/files/10572012/hvd0.26.1_torch1.12.1_gdr2.3.7_rocm5.1.1_gcc10.3.0.log)\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3837/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3837/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3831", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3831/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3831/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3831/events", "html_url": "https://github.com/horovod/horovod/issues/3831", "id": 1563278511, "node_id": "I_kwDOBfOI785dLbyv", "number": 3831, "title": "NCCL WARN Cuda failure 'CUDA driver is a stub library', then segfault", "user": {"login": "thomas-bouvier", "id": 2392649, "node_id": "MDQ6VXNlcjIzOTI2NDk=", "avatar_url": "https://avatars.githubusercontent.com/u/2392649?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thomas-bouvier", "html_url": "https://github.com/thomas-bouvier", "followers_url": "https://api.github.com/users/thomas-bouvier/followers", "following_url": "https://api.github.com/users/thomas-bouvier/following{/other_user}", "gists_url": "https://api.github.com/users/thomas-bouvier/gists{/gist_id}", "starred_url": "https://api.github.com/users/thomas-bouvier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thomas-bouvier/subscriptions", "organizations_url": "https://api.github.com/users/thomas-bouvier/orgs", "repos_url": "https://api.github.com/users/thomas-bouvier/repos", "events_url": "https://api.github.com/users/thomas-bouvier/events{/privacy}", "received_events_url": "https://api.github.com/users/thomas-bouvier/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 24, "created_at": "2023-01-30T22:02:11Z", "updated_at": "2023-03-21T08:46:43Z", "closed_at": "2023-03-21T08:46:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello :)\r\n\r\n**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.13.1\r\n3. Horovod version: 0.26.1\r\n4. MPI version: OpenMPI 4.1.2\r\n5. CUDA version: 11.8, driver 510.47.03\r\n6. NCCL version: 2.16.2-1\r\n7. Python version: 3.10\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version: debian11 skylake_avx512\r\n11. GCC version: gcc 10.2.1\r\n12. CMake version: I'm using [Spack](https://github.com/thomas-bouvier/spack/tree/update-nccl-v2.15.5-1%2Cv2.16.2-1)\r\n\r\n\r\n**Bug report:**\r\n\r\nMy Horovod program segfaults when using >= 2 GPUs.\r\n\r\nOriginally, I was using NCCL 2.14.3-1 but experienced the exact same issue as in https://github.com/horovod/horovod/issues/3625#issuecomment-1199308169. Same `NCCL WARN Cuda failure 'CUDA driver is a stub library'` lines, and many `NCCL WARN AllReduce : invalid root 0 (root should be in the 0..-1 range)` as well. `nccl-tests` with MPI were passing just fine.\r\n\r\nAs suggested in the above issue, I updated NCCL to version 2.16.2-1. `nccl-tests` with MPI are still passing. Now I get a different output, but I still have the message about the stub library, and the segfault too:\r\n\r\n```console\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO Bootstrap : Using lo:127.0.0.1<0>\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO cudaDriverVersion 11060\r\n[1,0]<stdout>:NCCL version 2.16.2+cuda11.8\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO cudaDriverVersion 11060\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO NET/IB : No device found.\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO NET/Socket : Using [0]lo:127.0.0.1<0>\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO Using network Socket\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO Bootstrap : Using lo:127.0.0.1<0>\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO NET/IB : No device found.\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO NET/Socket : Using [0]lo:127.0.0.1<0>\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO Using network Socket\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO Setting affinity for GPU 0 to 5555,55555555\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO Setting affinity for GPU 1 to aaaa,aaaaaaaa\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO P2P Chunksize set to 131072\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO Channel 00/02 :    0   1\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO Channel 01/02 :    0   1\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO P2P Chunksize set to 131072\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO Channel 00 : 1[d8000] -> 0[3b000] via SHM/direct/direct\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO Channel 01 : 1[d8000] -> 0[3b000] via SHM/direct/direct\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO Channel 00 : 0[3b000] -> 1[d8000] via SHM/direct/direct\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO Channel 01 : 0[3b000] -> 1[d8000] via SHM/direct/direct\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO Connected all rings\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO Connected all trees\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO Connected all rings\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO Connected all trees\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO comm 0x7fc6dc31f250 rank 1 nranks 2 cudaDev 1 busId d8000 commId 0x46ac7a7b06477097 - Init COMPLETE\r\n[1,1]<stdout>:\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] misc/strongstream.cc:60 NCCL WARN Cuda failure 'CUDA driver is a stub library'\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO enqueue.cc:1516 -> 1\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO enqueue.cc:1557 -> 1\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO enqueue.cc:1562 -> 1\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO comm 0x7fa378352620 rank 0 nranks 2 cudaDev 0 busId 3b000 commId 0x46ac7a7b06477097 - Init COMPLETE\r\n[1,0]<stdout>:\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] misc/strongstream.cc:60 NCCL WARN Cuda failure 'CUDA driver is a stub library'\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO enqueue.cc:1516 -> 1\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO enqueue.cc:1557 -> 1\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO enqueue.cc:1562 -> 1\r\n[1,0]<stdout>:chifflot-7:11200:11372 [0] NCCL INFO [Service thread] Connection closed by localRank 0\r\n[1,1]<stdout>:chifflot-7:11201:11371 [1] NCCL INFO [Service thread] Connection closed by localRank 1\r\n[1,0]<stdout>:chifflot-7:11200:11230 [0] NCCL INFO comm 0x7fa378352620 rank 0 nranks 2 cudaDev 0 busId 3b000 - Abort COMPLETE\r\n[1,0]<stderr>:[chifflot-7:11200] *** Process received signal ***\r\n[1,0]<stderr>:[chifflot-7:11200] Signal: Segmentation fault (11)\r\n[1,0]<stderr>:[chifflot-7:11200] Signal code: Invalid permissions (2)\r\n[1,0]<stderr>:[chifflot-7:11200] Failing at address: 0x7fa2b7400000\r\n[1,0]<stderr>:[chifflot-7:11200] [ 0] [1,0]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(+0x38d60)[0x7fa441d52d60]\r\n[1,0]<stderr>:[chifflot-7:11200] [ 1] [1,0]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(+0x16c435)[0x7fa3b4ed6435]\r\n[1,0]<stderr>:[chifflot-7:11200] [ 2] [1,0]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(+0x180a89)[0x7fa3b4eeaa89]\r\n[1,0]<stderr>:[chifflot-7:11200] [ 3] [1,0]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(+0x1b260a)[0x7fa3b4f1c60a]\r\n[1,0]<stderr>:[chifflot-7:11200] [ 4] [1,0]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(_ZN7horovod6common13NCCLBroadcast7ExecuteERSt6vectorINS0_16TensorTableEntryESaIS3_EERKNS0_8Respon\r\nseE+0x17b)[0x7fa3b4ea41eb]\r\n[1,0]<stderr>:[chifflot-7:11200] [ 5] [1,0]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(_ZNK7horovod6common16OperationManager16ExecuteBroadcastERSt6vectorINS0_16TensorTableEntryESaIS3_E\r\nERKNS0_8ResponseE+0x65)[0x7fa3b4e64ef5]\r\n[1,0]<stderr>:[chifflot-7:11200] [ 6] [1,0]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(_ZNK7horovod6common16OperationManager16ExecuteOperationERSt6vectorINS0_16TensorTableEntryESaIS3_E\r\nERKNS0_8ResponseERNS0_10ProcessSetE+0x131)[0x7fa3b4e65221]\r\n[1,0]<stderr>:[chifflot-7:11200] [ 7] [1,0]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(+0xd1000)[0x7fa3b4e3b000]\r\n[1,0]<stderr>:[chifflot-7:11200] [ 8] [1,0]<stderr>:/lib/x86_64-linux-gnu/libstdc++.so.6(+0xceed0)[0x7fa41b990ed0]\r\n[1,0]<stderr>:[chifflot-7:11200] [ 9] [1,0]<stderr>:/lib/x86_64-linux-gnu/libpthread.so.0(+0x7ea7)[0x7fa441cf0ea7]\r\n[1,0]<stderr>:[chifflot-7:11200] [10] [1,0]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(clone+0x3f)[0x7fa441e16a2f]\r\n[1,0]<stderr>:[chifflot-7:11200] *** End of error message ***\r\n[1,1]<stdout>:chifflot-7:11201:11231 [1] NCCL INFO comm 0x7fc6dc31f250 rank 1 nranks 2 cudaDev 1 busId d8000 - Abort COMPLETE\r\n[1,1]<stderr>:[chifflot-7:11201] *** Process received signal ***\r\n[1,1]<stderr>:[chifflot-7:11201] Signal: Segmentation fault (11)\r\n[1,1]<stderr>:[chifflot-7:11201] Signal code: Invalid permissions (2)\r\n[1,1]<stderr>:[chifflot-7:11201] Failing at address: 0x7fc621400000\r\n[1,1]<stderr>:[chifflot-7:11201] [ 0] [1,1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(+0x38d60)[0x7fc798644d60]\r\n[1,1]<stderr>:[chifflot-7:11201] [ 1] [1,1]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(+0x16c435)[0x7fc70b7c8435]\r\n[1,1]<stderr>:[chifflot-7:11201] [ 2] [1,1]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(+0x180a89)[0x7fc70b7dca89]\r\n[1,1]<stderr>:[chifflot-7:11201] [ 3] [1,1]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(+0x1b260a)[0x7fc70b80e60a]\r\n[1,1]<stderr>:[chifflot-7:11201] [ 4] [1,1]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(_ZN7horovod6common13NCCLBroadcast7ExecuteERSt6vectorINS0_16TensorTableEntryESaIS3_EERKNS0_8Respon\r\nseE+0x17b)[0x7fc70b7961eb]\r\n[1,1]<stderr>:[chifflot-7:11201] [ 5] [1,1]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(_ZNK7horovod6common16OperationManager16ExecuteBroadcastERSt6vectorINS0_16TensorTableEntryESaIS3_E\r\nERKNS0_8ResponseE+0x65)[0x7fc70b756ef5]\r\n[1,1]<stderr>:[chifflot-7:11201] [ 6] [1,1]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(_ZNK7horovod6common16OperationManager16ExecuteOperationERSt6vectorINS0_16TensorTableEntryESaIS3_E\r\nERKNS0_8ResponseERNS0_10ProcessSetE+0x131)[0x7fc70b757221]\r\n[1,1]<stderr>:[chifflot-7:11201] [ 7] [1,1]<stderr>:/mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so(+0xd1000)[0x7fc70b72d000]\r\n[1,1]<stderr>:[chifflot-7:11201] [ 8] [1,1]<stderr>:/lib/x86_64-linux-gnu/libstdc++.so.6(+0xceed0)[0x7fc772282ed0]\r\n[1,1]<stderr>:[chifflot-7:11201] [ 9] [1,1]<stderr>:/lib/x86_64-linux-gnu/libpthread.so.0(+0x7ea7)[0x7fc7985e2ea7]\r\n[1,1]<stderr>:[chifflot-7:11201] [10] [1,1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(clone+0x3f)[0x7fc798708a2f]\r\n[1,1]<stderr>:[chifflot-7:11201] *** End of error message ***\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun noticed that process rank 0 with PID 0 on node chifflot-7 exited on signal 11 (Segmentation fault).\r\n--------------------------------------------------------------------------\r\n```\r\n\r\nI'm building NCCL using this [Spack recipe](https://github.com/thomas-bouvier/spack/blob/c843626579dac9a6d239b882ac453dee7409a0fe/var/spack/repos/builtin/packages/nccl/package.py#L83-L84). It's not setting the variable `CUDARTLIB`, so I'm using the default static cudart. Only `CUDA_HOME` and `NVCC_GENCODE` are set.\r\n\r\nTo any useful purpose, here are `ldd` outputs on `mpi_lib_v2.cpython-310-x86_64-linux-gnu.so` and `libnccl.so`\r\n```console\r\nroot@chifflot-7:~# ldd /mnt/view/._chifflot/mkuvyhc3htu55b3xw45mermtmwilbcxm/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so\r\n        linux-vdso.so.1 (0x00007ffc7bfa9000)\r\n        libmpi.so.40 => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/openmpi-4.1.2-yc24rf6lhsmvpfvfb57euroc2dzjbvlh/lib/libmpi.so.40 (0x00007fa2f9bc7000)\r\n        libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fa2f9bc1000)\r\n        libc10.so => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/py-torch-1.13.1-iiydbxc5lly4qozdd4pzii2wcg3megbx/lib/python3.10/site-packages/torch/lib/libc10.so (0x00007fa2f9b2d000)\r\n        libtorch_cpu.so => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/py-torch-1.13.1-iiydbxc5lly4qozdd4pzii2wcg3megbx/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so (0x00007fa2ef7f1000)\r\n        libtorch_python.so => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/py-torch-1.13.1-iiydbxc5lly4qozdd4pzii2wcg3megbx/lib/python3.10/site-packages/torch/lib/libtorch_python.so (0x00007fa2ee7fe000)\r\n        libcudart.so.11.0 => /mnt/view/chifflot/lib64/libcudart.so.11.0 (0x00007fa2ee557000)\r\n        libc10_cuda.so => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/py-torch-1.13.1-iiydbxc5lly4qozdd4pzii2wcg3megbx/lib/python3.10/site-packages/torch/lib/libc10_cuda.so (0x00007fa2ee505000)\r\n        libstdc++.so.6 => /lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007fa2ee338000)\r\n        libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007fa2ee1f2000)\r\n        libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007fa2ee1d8000)\r\n        libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fa2ee1b6000)\r\n        libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fa2edfe1000)\r\n        /lib64/ld-linux-x86-64.so.2 (0x00007fa306f83000)\r\n        libopen-rte.so.40 => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/openmpi-4.1.2-yc24rf6lhsmvpfvfb57euroc2dzjbvlh/lib/libopen-rte.so.40 (0x00007fa2edec0000)\r\n        libopen-pal.so.40 => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/openmpi-4.1.2-yc24rf6lhsmvpfvfb57euroc2dzjbvlh/lib/libopen-pal.so.40 (0x00007fa2eddbf000)\r\n        librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007fa2eddb5000)\r\n        libhwloc.so.15 => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/hwloc-2.9.0-rvdki5t5gfkr4dti4fwbdkczq3t6q33a/lib/libhwloc.so.15 (0x00007fa2edd56000)\r\n        libnuma.so.1 => /mnt/view/chifflot/lib/libnuma.so.1 (0x00007fa2edd46000)\r\n        libgomp.so.1 => /lib/x86_64-linux-gnu/libgomp.so.1 (0x00007fa2edd06000)\r\n        libmkl_intel_lp64.so => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/intel-mkl-2020.4.304-lqjdl27yt4zmixe5fsoh4rsocvxij2pe/compilers_and_libraries_2020.4.304/linux/mkl/lib/intel64/libmkl_intel_lp64.so (0x00007fa2ecfe3000)\r\n        libmkl_gnu_thread.so => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/intel-mkl-2020.4.304-lqjdl27yt4zmixe5fsoh4rsocvxij2pe/compilers_and_libraries_2020.4.304/linux/mkl/lib/intel64/libmkl_gnu_thread.so (0x00007fa2eb283000)\r\n        libmkl_core.so => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/intel-mkl-2020.4.304-lqjdl27yt4zmixe5fsoh4rsocvxij2pe/compilers_and_libraries_2020.4.304/linux/mkl/lib/intel64/libmkl_core.so (0x00007fa2e6c42000)\r\n        libpthreadpool.so => /mnt/view/chifflot/lib/libpthreadpool.so (0x00007fa2e6c2c000)\r\n        libcupti.so.11.8 => /mnt/view/chifflot/extras/CUPTI/lib64/libcupti.so.11.8 (0x00007fa2e6315000)\r\n        libprotobuf.so.32 => /mnt/view/chifflot/lib/libprotobuf.so.32 (0x00007fa2e6036000)\r\n        libshm.so => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/py-torch-1.13.1-iiydbxc5lly4qozdd4pzii2wcg3megbx/lib/python3.10/site-packages/torch/lib/libshm.so (0x00007fa2e6029000)\r\n        libtorch.so => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/py-torch-1.13.1-iiydbxc5lly4qozdd4pzii2wcg3megbx/lib/python3.10/site-packages/torch/lib/libtorch.so (0x00007fa2e6023000)\r\n        libnvToolsExt.so.1 => /mnt/view/chifflot/lib64/libnvToolsExt.so.1 (0x00007fa2e5e19000)\r\n        libtorch_cuda.so => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/py-torch-1.13.1-iiydbxc5lly4qozdd4pzii2wcg3megbx/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so (0x00007fa2ddc22000)\r\n        libcudnn.so.8 => /mnt/view/chifflot/lib/libcudnn.so.8 (0x00007fa2dd9fc000)\r\n        libz.so.1 => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/zlib-1.2.13-e75jktqhj7dcp2epinxpwpjgnhzhmu4m/lib/libz.so.1 (0x00007fa2dd9e0000)\r\n        libevent_core-2.1.so.7 => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/libevent-2.1.12-ku4matsr7hgmkpsoid3wgic4rpd5mlim/lib/libevent_core-2.1.so.7 (0x00007fa2dd9a9000)\r\n        libpmix.so.2 => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/pmix-4.1.2-77vkstnvrdakoccfvldhjdrqmf2d6bv2/lib/libpmix.so.2 (0x00007fa2dd7bd000)\r\n        libnl-3.so.200 => /lib/x86_64-linux-gnu/libnl-3.so.200 (0x00007fa2dd798000)\r\n        libutil.so.1 => /lib/x86_64-linux-gnu/libutil.so.1 (0x00007fa2dd793000)\r\n        libevent_pthreads-2.1.so.7 => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/libevent-2.1.12-ku4matsr7hgmkpsoid3wgic4rpd5mlim/lib/libevent_pthreads-2.1.so.7 (0x00007fa2dd78e000)\r\n        libpciaccess.so.0 => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/libpciaccess-0.16-eri7r7b7x7lhdk6pshh3gexctncobspu/lib/libpciaccess.so.0 (0x00007fa2dd783000)\r\n        libxml2.so.2 => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/libxml2-2.10.3-54horkxecocmzn7d67capix2bzbdifwi/lib/libxml2.so.2 (0x00007fa2dd61c000)\r\n        libcusparse.so.11 => /mnt/view/chifflot/lib64/libcusparse.so.11 (0x00007fa2cc922000)\r\n        libcurand.so.10 => /mnt/view/chifflot/lib64/libcurand.so.10 (0x00007fa2c6046000)\r\n        libnccl.so.2 => /mnt/view/chifflot/lib/libnccl.so.2 (0x00007fa2c286e000)\r\n        libcufft.so.10 => /mnt/view/chifflot/lib64/libcufft.so.10 (0x00007fa2b1993000)\r\n        libcublas.so.11 => /mnt/view/chifflot/lib64/libcublas.so.11 (0x00007fa2abd35000)\r\n        liblzma.so.5 => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/xz-5.2.7-ztgghh34ttfay75k7ynw7mvoxijyyedt/lib/liblzma.so.5 (0x00007fa2abd0a000)\r\n        libiconv.so.2 => /mnt/spack/linux-debian11-skylake_avx512/gcc-10.2.1/libiconv-1.17-bak2ds42kec64yaeuk36uzuv5lopxnen/lib/libiconv.so.2 (0x00007fa2abbfc000)\r\n        libcublasLt.so.11 => /mnt/view/chifflot/lib64/libcublasLt.so.11 (0x00007fa287676000)\r\n```\r\n\r\n```console\r\nroot@chifflot-7:~# ldd /mnt/view/chifflot/lib/libnccl.so.2\r\n        linux-vdso.so.1 (0x00007ffe1eeab000)\r\n        libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f134b6ec000)\r\n        librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f134b6e2000)\r\n        libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f134b6dc000)\r\n        libstdc++.so.6 => /lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f134b50d000)\r\n        libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f134b3c9000)\r\n        libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f134b3af000)\r\n        libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f134b1da000)\r\n        /lib64/ld-linux-x86-64.so.2 (0x00007f134ef03000)\r\n```\r\n\r\nWhat could go wrong here? Thanks!", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3831/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3831/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3829", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3829/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3829/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3829/events", "html_url": "https://github.com/horovod/horovod/issues/3829", "id": 1560058656, "node_id": "I_kwDOBfOI785c_Jsg", "number": 3829, "title": "Spark tests fail with AttributeError: 'pyarrow.lib.Schema' object has no attribute 'to_arrow_schema'", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2023-01-27T16:33:29Z", "updated_at": "2023-01-28T02:38:02Z", "closed_at": "2023-01-28T02:38:02Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Spark tests fail with\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/horovod/examples/spark/pytorch/pytorch_spark_mnist.py\", line 122, in <module>\r\n    torch_model = torch_estimator.fit(train_df).setOutputCols(['label_prob'])\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/estimator.py\", line 35, in fit\r\n    return super(HorovodEstimator, self).fit(df, params)\r\n  File \"/usr/local/lib/python3.8/dist-packages/pyspark/ml/base.py\", line 205, in fit\r\n    return self._fit(dataset)\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/estimator.py\", line 68, in _fit\r\n    with util.prepare_data(backend.num_processes(),\r\n  File \"/usr/lib/python3.8/contextlib.py\", line 113, in __enter__\r\n    return next(self.gen)\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/util.py\", line 735, in prepare_data\r\n    dataset_idx = _get_or_create_dataset(key, store, df, feature_columns, label_columns,\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/util.py\", line 672, in _get_or_create_dataset\r\n    train_rows, val_rows, pq_metadata, avg_row_size = get_simple_meta_from_parquet(\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/util.py\", line 495, in get_simple_meta_from_parquet\r\n    train_data_schema = train_data.schema.to_arrow_schema()\r\nAttributeError: 'pyarrow.lib.Schema' object has no attribute 'to_arrow_schema'\r\n```\r\nhttps://github.com/horovod/horovod/actions/runs/4025636527/jobs/6919132641\r\n\r\nIt's probably related to the 11.0 release of pyarrow. https://pypi.org/project/pyarrow/#history", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3829/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3829/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3825", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3825/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3825/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3825/events", "html_url": "https://github.com/horovod/horovod/issues/3825", "id": 1557074908, "node_id": "I_kwDOBfOI785czxPc", "number": 3825, "title": "CI for tf-head: package `tf-nightly-gpu` must be replaced by `tf-nightly`", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2023-01-25T18:08:12Z", "updated_at": "2023-01-26T10:04:22Z", "closed_at": "2023-01-26T10:04:22Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Example: https://github.com/horovod/horovod/actions/runs/4007634282/jobs/6882833168\r\n\r\n```\r\n2023-01-25T18:03:55.7944804Z #39 1.522       =========================================================\r\n2023-01-25T18:03:55.7945146Z #39 1.522       The \"tf-nightly-gpu\" package has been removed!\r\n2023-01-25T18:03:55.7945386Z #39 1.522       \r\n2023-01-25T18:03:55.7945680Z #39 1.522       Please install \"tf-nightly\" instead.\r\n2023-01-25T18:03:55.7945896Z #39 1.522       \r\n2023-01-25T18:03:55.7946153Z #39 1.522       Other than the name, the two packages have been identical\r\n2023-01-25T18:03:55.7946550Z #39 1.522       since tf-nightly 2.1, or roughly since Sep 2019. For more\r\n2023-01-25T18:03:55.7947051Z #39 1.522       information, see: pypi.org/project/tf-nightly-gpu\r\n2023-01-25T18:03:55.7947364Z #39 1.522       =========================================================\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3825/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3825/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3823", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3823/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3823/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3823/events", "html_url": "https://github.com/horovod/horovod/issues/3823", "id": 1556517266, "node_id": "I_kwDOBfOI785cxpGS", "number": 3823, "title": "horovod with tensorflow, PBS, MPI and an ssh identity file fails cause of shuffled arguments for ssh", "user": {"login": "afluegel9", "id": 97666499, "node_id": "U_kgDOBdJFww", "avatar_url": "https://avatars.githubusercontent.com/u/97666499?v=4", "gravatar_id": "", "url": "https://api.github.com/users/afluegel9", "html_url": "https://github.com/afluegel9", "followers_url": "https://api.github.com/users/afluegel9/followers", "following_url": "https://api.github.com/users/afluegel9/following{/other_user}", "gists_url": "https://api.github.com/users/afluegel9/gists{/gist_id}", "starred_url": "https://api.github.com/users/afluegel9/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/afluegel9/subscriptions", "organizations_url": "https://api.github.com/users/afluegel9/orgs", "repos_url": "https://api.github.com/users/afluegel9/repos", "events_url": "https://api.github.com/users/afluegel9/events{/privacy}", "received_events_url": "https://api.github.com/users/afluegel9/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-01-25T11:51:55Z", "updated_at": "2023-01-31T12:43:08Z", "closed_at": "2023-01-31T12:43:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: tensorflow\r\n2. Framework version: 2.8.2\r\n3. Horovod version: 0.26.1\r\n4. MPI version: openmpi-4.1.2_SLE15_ucx-1.C.1\r\n5. CUDA version: 11.7\r\n6. NCCL version: not used\r\n7. Python version: 3.9.6\r\n8. Spark / PySpark version: not used\r\n9. Ray version: not used\r\n10. OS and version: Linux SLES 15 SP 3\r\n11. GCC version: 7.5.0\r\n12. CMake version: 3.17.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? no hang.\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? no docker used\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? sure\r\n\r\n**Bug report:**\r\nWe use horovodrun to submit to PBS with mpirun and openMPI.\r\nThe PBS submit is (reduced to the beef):\r\nqsub -j n -m eb -o stdout.$$ -e stderr.$$ -N HOROVOD -P my-project -l longname=HOROVOD -q our-cluster -l ncpus=40 -l mem=100gb -l place=scatter:excl << \"EOF\"\r\ncd \"$PBS_O_WORKDIR\"\r\n# construct argument for -H of horovodrun\r\nHOSTS_FOR_HOROVOD=\"\"\r\nSEP=\"\"\r\nfor H in `cat \"$PBS_NODEFILE\"` ; do\r\n  HOSTS_FOR_HOROVOD=\"$HOSTS_FOR_HOROVOD$SEP$H:1\"\r\n  SEP=\",\"\r\ndone\r\n\r\n# environment for PBS and open MPI\r\nunset PBS_ENVIRONMENT\r\nunset PBS_NODEFILE\r\n\r\nexport OMPI_MCA_plm=rsh\r\nexport OMPI_MCA_plm_rsh_agent=$PBS_EXEC/bin/pbs_remsh  # rsh command used for openmpi\r\nexport PBS_RSHCOMMAND=\"/usr/bin/ssh -i $HOME/.ssh/id_mpi -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o ChallengeResponseAuthentication=no\"                               # rsh command for pbs_attach called from pbs_remsh\r\n\r\nexec horovodrun -i $HOME/.ssh/id_mpi --mpi --mpi-threads-disable -np 5 -H $HOSTS_FOR_HOROVOD python tf_cnn_benchmarks.py --data_format=NCHW --device=CPU --xla=false --num_intra_threads=16 --num_inter_threads=2 --mkl=true --variable_update=horovod --data_dir=$HOME/tensorflow/benchmark/data/cifar-10-batches-py --data_name=cifar10 --model=resnet110 --distortions=true --optimizer=sgd -num_warmup_batches=1 --display_every=10 --print_training_accuracy=true --num_epochs=1 --batch_size=1024 --init_learning_rate=3.20 --learning_rate_decay_factor=0.9 --num_epochs_per_decay=5 --minimum_learning_rate=0.01 --num_learning_rate_warmup_epochs=1\r\nEOF\r\n\r\nIn the stderr.$$ file i see the following error for each of the hosts in $PBS_NODEFILE:\r\nWarning: Identity file PBS_CONF_FILE=/etc/pbs.conf not accessible: No such file or directory.\r\nunknown option -- j\r\nusage: ssh [-46AaCfGgKkMNnqsTtVvXxYy] [-B bind_interface]\r\n           [-b bind_address] [-c cipher_spec] [-D [bind_address:]port]\r\n           [-E log_file] [-e escape_char] [-F configfile] [-I pkcs11]\r\n           [-i identity_file] [-J [user@]host[:port]] [-L address]\r\n           [-l login_name] [-m mac_spec] [-O ctl_cmd] [-o option] [-p port]\r\n           [-Q query_option] [-R address] [-S ctl_path] [-W host:port]\r\n           [-w local_tun[:remote_tun]] destination [command]\r\n\r\nHuuuh ? Where's the -j coming from ? Why is PBS_CONF_FILE=/etc/pbs.conf considered the identity file ?\r\nstracing shows this call to ssh (anonymized):\r\n[pid 3037] execve(\"/usr/bin/ssh\", [\"/usr/bin/ssh\", \"-i\", \"/home/myusername/.ssh/id_mpi\", \"-o\", \"StrictHostKeyChecking=no\", \"-o\", \"KbdInteractiveAuthentication=no\", \"-o\", \"ChallengeResponseAuthentication=no\", \"-n\", \"-i\", \"PBS_CONF_FILE=/etc/pbs.conf\", \"/opt/pbs/bin/pbs_attach\", \"-j\", \"1307246.node289\", \"/home/myusername/.ssh/id_mpi\", \"node1\", \"orted\", \"-mca\", \"ess\", \"\\\"env\\\"\", \"-mca\", \"ess_base_jobid\", \"\\\"2484797440\\\"\", \"-mca\", \"ess_base_vpid\", \"3\", \"-mca\", \"ess_base_num_procs\", \"\\\"5\\\"\", \"-mca\", \"orte_node_regex\", \"\\\"node[4:1,2,3,4]@0(5)\\\"\", \"-mca\", \"orte_hnp_uri\", \"\\\"2484797440.0;tcp://10.10.10.10:54331\\\"\", \"-mca\", \"pml\", \"\\\"ob1\\\"\", \"-mca\", \"btl\", \"\\\"^openib\\\"\", \"-mca\", \"btl_tcp_if_include\", \"\\\"bond0\\\"\", \"-mca\", \"plm\", \"\\\"rsh\\\"\", \"--tree-spawn\", \"-mca\", \"routed\", \"\\\"radix\\\"\", \"-mca\", \"orte_parent_uri\", \"\\\"2484797440.0;tcp://10.10.10.10:54331\\\"\", \"-mca\", \"plm_rsh_agent\", \"\\\"/opt/pbs/bin/pbs_remsh\\\"\", \"-mca\", \"plm_rsh_args\", \"\\\"-i\", \"/home/myusername/.ssh/id_mpi\\\"\", \"-mca\", \"orte_tag_output\", \"\\\"1\\\"\", \"-mca\", \"hwloc_base_binding_policy\", \"\\\"none\\\"\", \"-mca\", \"rmaps_base_mapping_policy\", \"\\\"slot\\\"\", \"-mca\", \"pmix\", \"\\\"^s1,s2,cray,isolated\\\"\"], [\"KMP_VERSION=TRUE\", \"OS=Linux_x86_64\", \"LD_LIBRARY_PATH=/opt/openmpi/openmpi-4.1.2_SLE15_ucx-1.C.1/lib\", \"HOSTTYPE=x86_64\", \"PBS_O_LANG=en_US.UTF-8\", \"PBS_SERVER=node1\", \"LANG=en_US.UTF-8\", \"HFI_NO_BACKTRACE=1\", \"PBS_O_SLOTS_PER_VNODE=8\", \"HOSTNAME=node1\", \"OLDPWD=/home/myusername/proj/tensorflow-tests/test-programs/cifar10/cpu\", \"PBS_O_HOME=/home/myusername\", \"AWS_PROFILE=MYUSERNAME\", \"CSHEDIT=emacs\", \"PBS_JOBID=1307246.node289\", \"ENVIRONMENT=BATCH\", \"GPG_TTY=not a tty\", \"HOROVOD_MPI_THREADS_DISABLE=1\", \"COLORTERM=1\", \"PBS_JOBNAME=HOROVOD\", \"NCPUS=8\", \"OMPI_MCA_orte_tag_output=1\", \"PBS_EXEC=/opt/pbs\", \"MACHTYPE=x86_64-suse-linux\", \"PBS_O_PATH=/bin:/usr/bin:/usr/sbin:/usr/lib/mit/bin:\"..., \"HN=node289\", \"OSTYPE=linux\", \"OMPI_MCA_plm=rsh\", \"PBS_O_WORKDIR=/home/myusername/proj/tensorflow-tests/test-programs/cifar10/cpu\", \"USER=myusername\", \"PAGER=less\", \"LC_COLLATE=C\", \"OMPI_MCA_plm_rsh_agent=/opt/pbs/bin/pbs_remsh\", \"MORE=-sl\", \"PBS_TASKNUM=1\", \"PWD=/home/myusername/proj/tensorflow-tests/tensorflow/benchmark/benchmarks-master/scripts/tf_cnn_benchmarks\", \"OMPI_MCA_plm_rsh_args=-i /home/myusername/.ssh/id_mpi\", \"HOME=/home/myusername\", \"HOST=node289.ourdomain.org\", \"XNLSPATH=/usr/share/X11/nls\", \"PBS_MOMPORT=10003\", \"IPATH_NO_BACKTRACE=1\", \"HISTFILE=/home/myusername/.sh_history_linux\", \"MKL_DEBUG=0\", \"PBS_JOBCOOKIE=0000000041D42137000000004ADE03A9\", \"PBS_O_SHELL=/bin/bash\", \"PROFILEREAD=true\", \"TMPDIR=/share/tmp/scratch\", \"PBS_HOME=/opt/pbs\", \"PMIX_MCA_mca_base_component_show_load_errors=1\", \"OMPI_MCA_pml=ob1\",\"MAIL=/home/myusername/.mbox\", \"LESSKEY=/etc/lesskey.bin\", \"SHELL=/bin/bash\", \"OMPI_MCA_btl_tcp_if_include=bond0\", \"MKL_VERBOSE=1\", \"OMPI_MCA_hwloc_base_binding_policy=none\", \"OMPI_MCA_rmaps_base_mapping_policy=slot\", \"PYTHONSTARTUP=/etc/pythonstart\", \"SHLVL=3\", \"PBS_O_HOST=node289.ourdomain.org\", \"G_FILENAME_ENCODING=@locale,UTF-8,ISO-8859-15,CP1252\", \"MKLDNN_VERBOSE=0\", \"PBS_O_SYSTEM=Linux\", \"MANPATH=/usr/share/man:/opt/util/SLE15/usr/share/man\", \"PBS_O_LOGNAME=myusername\", \"PBS_NODENUM=0\", \"PBS_JOBDIR=/home/myusername\", \"LOGNAME=myusername\", \"PATH=/home/myusername/tf282_cpu/bin:/bin:/usr/bin:/usr/sbin:/usr/lib/\"..., , \"PBS_QUEUE=our-cluster\", \"G_BROKEN_FILENAMES=1\", \"HISTSIZE=1000\", \"CPU=x86_64\", \"PBS_RSHCOMMAND=/usr/bin/ssh -i /home/myusername/.ssh/id_mpi -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o ChallengeResponseAuthentication=no\", \"PBS_O_MAIL=/home/myusername/.mbox\", \"OMP_NUM_THREADS=1\", \"LESSOPEN=lessopen.sh %s\", \"OMPI_MCA_btl=^openib\" ] <unfinished ...>\r\n\r\nI would assume, that the order of the first arguments is wrong, one \"-i\" and one time the id-file is superfluous and all in all it should be:\r\n\"/usr/bin/ssh\", \"-i\", \"/home/myusername/.ssh/id_mpi\", \"-o\", \"StrictHostKeyChecking=no\", \"-o\", \"KbdInteractiveAuthentication=no\", \"-o\", \"ChallengeResponseAuthentication=no\", \"-n\", \"node1\", \"PBS_CONF_FILE=/etc/pbs.conf\", \"/opt/pbs/bin/pbs_attach\", \"-j\", \"1307246.node289\", \"orted\", \"-mca\", ...\r\n\r\nThe issue might be in https://github.com/horovod/horovod/blob/master/horovod/runner/util/remote.py , but i'm not sure.\r\nHowever, the problem does not occur, if no identity file needs to be given and a default identity file can be used or in general password-less ssh is possible without supplying an identity file explicitely on the commandline.\r\nThe issue can be avoided by inserting one line to [horovod/runner/launch.py](https://github.com/horovod/horovod/blob/master/horovod/runner/launch.py#L85):\r\n*** /home/myusername/tf282_gpu/lib/python3.9/site-packages/horovod/runner/launch.py   2023-01-19 14:33:04.350538000 +0100\r\n--- /home/myusername/tf282_cpu/lib/python3.9/site-packages/horovod/runner/launch.py   2023-01-24 18:09:51.209094000 +0100\r\n***************\r\n*** 84,87 ****\r\n--- 84,88 ----\r\n          return exit_code, output_msg\r\n  \r\n+     return True\r\n      args_list = [[get_remote_command(local_command='true',\r\n                                       host=host_address,\r\n\r\nThis just skips the ssh test.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3823/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3823/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3821", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3821/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3821/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3821/events", "html_url": "https://github.com/horovod/horovod/issues/3821", "id": 1551320238, "node_id": "I_kwDOBfOI785cd0Su", "number": 3821, "title": "No Controller and Tensor Operations in --check-build command output", "user": {"login": "PurvangL", "id": 104454645, "node_id": "U_kgDOBjnZ9Q", "avatar_url": "https://avatars.githubusercontent.com/u/104454645?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PurvangL", "html_url": "https://github.com/PurvangL", "followers_url": "https://api.github.com/users/PurvangL/followers", "following_url": "https://api.github.com/users/PurvangL/following{/other_user}", "gists_url": "https://api.github.com/users/PurvangL/gists{/gist_id}", "starred_url": "https://api.github.com/users/PurvangL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PurvangL/subscriptions", "organizations_url": "https://api.github.com/users/PurvangL/orgs", "repos_url": "https://api.github.com/users/PurvangL/repos", "events_url": "https://api.github.com/users/PurvangL/events{/privacy}", "received_events_url": "https://api.github.com/users/PurvangL/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2023-01-20T19:08:27Z", "updated_at": "2023-01-25T20:02:18Z", "closed_at": "2023-01-25T20:02:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) : Tensorflow\r\n2. Framework version: 2.9\r\n3. Horovod version: latest\r\n4. MPI version: mpi4py=3.1.4 \r\n5. CUDA version: 11.6\r\n6. NCCL version: 2.16.2-1+cuda12.0 \r\n7. Python version: 3.8.10\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version: Ubuntu 20\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? na\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? no\r\n4. Did you check if you question is answered in the [troubleshooting guide] yes (https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nHOROVOD_GPU_OPERATIONS=NCCL HOROVOD_WITH_MPI=1 HOROVOD_WITH_TENSORFLOW=1 pip install --no-cache-dir horovod[tensorflow]\r\n\r\n<img width=\"1507\" alt=\"image\" src=\"https://user-images.githubusercontent.com/104454645/213785064-13e3bf60-5c5d-43fc-a9ff-2c666ba87320.png\">\r\n\r\nNo controller is present as well as tensor operations library. \r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3821/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3821/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3811", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3811/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3811/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3811/events", "html_url": "https://github.com/horovod/horovod/issues/3811", "id": 1524844778, "node_id": "I_kwDOBfOI785a40jq", "number": 3811, "title": "Horovod Issue with Tensorboard", "user": {"login": "andrejfd", "id": 111071978, "node_id": "U_kgDOBp7S6g", "avatar_url": "https://avatars.githubusercontent.com/u/111071978?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrejfd", "html_url": "https://github.com/andrejfd", "followers_url": "https://api.github.com/users/andrejfd/followers", "following_url": "https://api.github.com/users/andrejfd/following{/other_user}", "gists_url": "https://api.github.com/users/andrejfd/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrejfd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrejfd/subscriptions", "organizations_url": "https://api.github.com/users/andrejfd/orgs", "repos_url": "https://api.github.com/users/andrejfd/repos", "events_url": "https://api.github.com/users/andrejfd/events{/privacy}", "received_events_url": "https://api.github.com/users/andrejfd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-01-09T02:57:20Z", "updated_at": "2023-01-11T20:36:28Z", "closed_at": "2023-01-11T20:36:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\nTensorflow\r\n3. Framework version:\r\n2.9.1\r\n5. Horovod version:\r\n0.25.0\r\n7. MPI version:\r\n4.1.4\r\n9. CUDA version:\r\n11.4\r\n11. NCCL version:\r\n2.10.3\r\n13. Python version:\r\n3.9.5\r\n15. Spark / PySpark version:\r\n3.3.0\r\n17. Ray version:\r\nN/A\r\n19. OS and version:\r\nUbuntu 20.04.5 LTS (Databricks on AWS)\r\n21. GCC version:\r\n9.4.0\r\n23. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\nYes I found this: https://github.com/horovod/horovod/issues/99 , and followed instructions which did not fix issue\r\n3. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\nN/A\r\n5. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\nN/A\r\n7. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\nYes\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\n\r\nRunning Tensorboard on horovod in a custom training loop using `tf.summary.writers` does not output the result of my scalers until the END of training, which is not the desired behavior.\r\n\r\nIn my fit function:\r\n\r\n```\r\nif hvd.rank() == 0:\r\n            print(\"Setting up tf summary writers...\")\r\n            train_writer = tf.summary.create_file_writer(self.log_dir + 'train')\r\n            test_writer = tf.summary.create_file_writer(self.log_dir + 'test')\r\n            print(\"Complete\")\r\n\r\nfor epoch in epochs:\r\n\r\n\t# train code here...\r\n\r\n\tif hvd.rank() == 0:\r\n                with train_writer.as_default():\r\n                    tf.summary.scalar('loss', train_loss, step=epoch)\r\n                    tf.summary.scalar('time [s]', timedelta(seconds=train_end_time - train_start_time).seconds, step=epoch)\r\n                    for m in range(len(self.metric_names)):\r\n                        print('Writing training: ' + str(self.metric_names[m]))\r\n                        tf.summary.scalar(self.metric_names[m], train_metric_results[m], step=epoch)\r\n\r\n\r\n                with test_writer.as_default():\r\n                    tf.summary.scalar('loss', validation_loss, step=epoch)\r\n                    tf.summary.scalar('time [s]', timedelta(seconds=perf_counter()-train_end_time).seconds, step=epoch)\r\n                    for m in range(len(self.metric_names)):\r\n                         print('Writing validation: ' + str(self.metric_names[m]))\r\n                         tf.summary.scalar(self.metric_names[m], validation_metric_results[m], step=epoch)\r\n                \r\n                train_writer.flush()\r\n                print(\"Train Writer Flushed\")\r\n                test_writer.flush()\r\n                print(\"Test Writer Flushed\")\r\n```\r\n\r\nI have reproduced on local and other multi-gpu machines (non-horovod) and gotten the proper results, but here the training needs to complete before any files are written.\r\n\r\nI know this is specific to `tf.summary.writer` because other things such as `checkpointing` seem to work completely find.\r\n\r\nI am running on Databricks and saving to dbfs.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3811/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3811/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3810", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3810/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3810/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3810/events", "html_url": "https://github.com/horovod/horovod/issues/3810", "id": 1523382314, "node_id": "I_kwDOBfOI785azPgq", "number": 3810, "title": "TF/Keras 2.11 isn\u2019t currently working with `KerasEstimator` in horovod 0.26.1 even using legacy optimizer", "user": {"login": "wenfeiy-db", "id": 87323464, "node_id": "MDQ6VXNlcjg3MzIzNDY0", "avatar_url": "https://avatars.githubusercontent.com/u/87323464?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wenfeiy-db", "html_url": "https://github.com/wenfeiy-db", "followers_url": "https://api.github.com/users/wenfeiy-db/followers", "following_url": "https://api.github.com/users/wenfeiy-db/following{/other_user}", "gists_url": "https://api.github.com/users/wenfeiy-db/gists{/gist_id}", "starred_url": "https://api.github.com/users/wenfeiy-db/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wenfeiy-db/subscriptions", "organizations_url": "https://api.github.com/users/wenfeiy-db/orgs", "repos_url": "https://api.github.com/users/wenfeiy-db/repos", "events_url": "https://api.github.com/users/wenfeiy-db/events{/privacy}", "received_events_url": "https://api.github.com/users/wenfeiy-db/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-01-07T01:23:34Z", "updated_at": "2023-02-01T18:13:14Z", "closed_at": "2023-02-01T18:13:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: keras\r\n2. Framework version: 2.11\r\n3. Horovod version: 0.26.1\r\n4. MPI version: 4.1.4\r\n5. CUDA version: 11.0.3-1\r\n6. NCCL version: 2.10.3-1\r\n7. Python version: 3.8\r\n\r\n**Bug report:**\r\nWith keras=2.11 and horovod 0.26.1, `horovod.spark.keras.KerasEstimator` doesn't work even when using legacy optimizer. It has the following error message\r\n```\r\nTraceback (most recent call last):\r\n[1,2]<stderr>:  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\r\n[1,2]<stderr>:    return _run_code(code, main_globals, None,\r\n[1,2]<stderr>:  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\r\n[1,2]<stderr>:    exec(code, run_globals)\r\n[1,2]<stderr>:  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/horovod/spark/task/mpirun_exec_fn.py\", line 52, in <module>\r\n[1,2]<stderr>:    main(codec.loads_base64(sys.argv[1]), codec.loads_base64(sys.argv[2]))\r\n[1,2]<stderr>:  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/horovod/spark/task/mpirun_exec_fn.py\", line 45, in main\r\n[1,2]<stderr>:    task_exec(driver_addresses, settings, 'OMPI_COMM_WORLD_RANK', 'OMPI_COMM_WORLD_LOCAL_RANK')\r\n[1,2]<stderr>:  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/horovod/spark/task/__init__.py\", line 61, in task_exec\r\n[1,2]<stderr>:    result = fn(*args, **kwargs)\r\n[1,2]<stderr>:  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/horovod/spark/keras/remote.py\", line 136, in train\r\n[1,2]<stderr>:    model = deserialize_keras_model(\r\n[1,2]<stderr>:  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/horovod/spark/keras/remote.py\", line 299, in deserialize_keras_model\r\n[1,2]<stderr>:    return load_model_fn(f)\r\n[1,2]<stderr>:  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/horovod/spark/keras/remote.py\", line 137, in <lambda>\r\n[1,2]<stderr>:    serialized_model, lambda x: hvd.load_model(x))\r\n[1,2]<stderr>:  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/horovod/tensorflow/keras/__init__.py\", line 274, in load_model\r\n[1,2]<stderr>:    return _impl.load_model(keras, wrap_optimizer, _OPTIMIZER_MODULES, filepath, custom_optimizers, custom_objects)\r\n[1,2]<stderr>:  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/horovod/_keras/__init__.py\", line 272, in load_model\r\n[1,2]<stderr>:    return keras.models.load_model(filepath, custom_objects=horovod_objects)\r\n[1,2]<stderr>:  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\r\n[1,2]<stderr>:    raise e.with_traceback(filtered_tb) from None\r\n[1,2]<stderr>:  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/horovod/tensorflow/keras/__init__.py\", line 273, in <lambda>\r\n[1,2]<stderr>:    return lambda **kwargs: DistributedOptimizer(cls(**kwargs), compression=compression)\r\n[1,2]<stderr>:ValueError[1,2]<stderr>:: decay is deprecated in the new Keras optimizer, pleasecheck the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.Adadelta.\r\n```\r\nWe found this [PR](https://sourcegraph.com/github.com/horovod/horovod/-/commit/02685064a2b6201a4250f2e25ec7418ea8a59d8f?visible=5) seems to solve the issue. And if we install horovod from master it works. Given this, could we make a patch release that include the linked PR?\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3810/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3810/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3809", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3809/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3809/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3809/events", "html_url": "https://github.com/horovod/horovod/issues/3809", "id": 1522626256, "node_id": "I_kwDOBfOI785awW7Q", "number": 3809, "title": "CI: Build pipelines for macOS fail", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2023-01-06T13:51:01Z", "updated_at": "2023-01-12T20:54:18Z", "closed_at": "2023-01-12T20:54:18Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "It looks like `pyenv` fails to build Python 3.7.7 because it can't find the `clang++` compiler (but the log is incomplete, there may be more).\r\n```\r\nInstalling Python-3.7.7...\r\npatching file Misc/NEWS.d/next/macOS/2020-06-24-13-51-57.bpo-41100.mcHdc5.rst\r\npatching file configure\r\nHunk #1 succeeded at 3374 (offset -52 lines).\r\npatching file configure.ac\r\nHunk #1 succeeded at 490 (offset -20 lines).\r\npython-build: use tcl-tk from homebrew\r\npython-build: use readline from homebrew\r\npython-build: use zlib from xcode sdk\r\n\r\nBUILD FAILED (OS X 12.6.2 using python-build 20180424)\r\n\r\nInspect or clean up the working tree at /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/python-build.20230106010328.4626\r\nResults logged to /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/python-build.20230106010328.4626.log\r\n\r\nLast 10 log lines:\r\nchecking for --with-cxx-main=<compiler>... no\r\nchecking for clang++... no\r\nconfigure:\r\n\r\n  By default, distutils will build C++ extension modules with \"clang++\".\r\n  If this is not intended, then set CXX on the configure command line.\r\n  \r\nchecking for the platform triplet based on compiler characteristics... darwin\r\nconfigure: error: internal configure error for the platform triplet, please file a bug report\r\nmake: *** No targets specified and no makefile found.  Stop.\r\n```\r\nSimilar comments in https://github.com/pyenv/pyenv/issues/2143", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3809/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3809/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3804", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3804/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3804/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3804/events", "html_url": "https://github.com/horovod/horovod/issues/3804", "id": 1519481690, "node_id": "I_kwDOBfOI785akXNa", "number": 3804, "title": "CI: Builds fail with Numpy 1.24", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-01-04T19:39:33Z", "updated_at": "2023-01-05T23:11:10Z", "closed_at": "2023-01-05T23:11:10Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Builds with Python versions newer than 3.7 fail because Numpy have changed their API in release 1.24 and some package requirements aren't restrictive enough.\r\n\r\nhttps://github.com/horovod/horovod/actions/runs/3837009090\r\n```\r\n# ...\r\n2023-01-03T19:09:52.2227909Z #29 28.83   File \"/usr/local/lib/python3.8/dist-packages/pandas/_testing.py\", line 24, in <module>\r\n2023-01-03T19:09:52.2228233Z #29 28.83     import pandas._libs.testing as _testing\r\n2023-01-03T19:09:52.2228836Z #29 28.83   File \"pandas/_libs/testing.pyx\", line 10, in init pandas._libs.testing\r\n2023-01-03T19:09:52.2229288Z #29 28.83   File \"/usr/local/lib/python3.8/dist-packages/numpy/__init__.py\", line 284, in __getattr__\r\n2023-01-03T19:09:52.2229635Z #29 28.83     raise AttributeError(\"module {!r} has no attribute \"\r\n2023-01-03T19:09:52.2230033Z #29 28.83 AttributeError: module 'numpy' has no attribute 'bool'\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3804/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3804/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3798", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3798/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3798/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3798/events", "html_url": "https://github.com/horovod/horovod/issues/3798", "id": 1503152808, "node_id": "I_kwDOBfOI785ZmEqo", "number": 3798, "title": "Horovod does not compile with newer gcc versions", "user": {"login": "sehoffmann", "id": 1858546, "node_id": "MDQ6VXNlcjE4NTg1NDY=", "avatar_url": "https://avatars.githubusercontent.com/u/1858546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sehoffmann", "html_url": "https://github.com/sehoffmann", "followers_url": "https://api.github.com/users/sehoffmann/followers", "following_url": "https://api.github.com/users/sehoffmann/following{/other_user}", "gists_url": "https://api.github.com/users/sehoffmann/gists{/gist_id}", "starred_url": "https://api.github.com/users/sehoffmann/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sehoffmann/subscriptions", "organizations_url": "https://api.github.com/users/sehoffmann/orgs", "repos_url": "https://api.github.com/users/sehoffmann/repos", "events_url": "https://api.github.com/users/sehoffmann/events{/privacy}", "received_events_url": "https://api.github.com/users/sehoffmann/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-12-19T15:31:01Z", "updated_at": "2022-12-19T15:32:32Z", "closed_at": "2022-12-19T15:32:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "`common/half.h l.76` : `  *res = *reinterpret_cast<float const*>(&f);`\r\n\r\n> warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n\r\nThrows error because of  `-Wall`. Also notice that this warning is there for a reason; have yet to encounter a compiler that really utilizes strict aliasing, but at least according to the standard this is UB. See https://stackoverflow.com/questions/98650/what-is-the-strict-aliasing-rule. The correct way is to use `std::memcpy` (stupid, I know, especially since 99.99% of all c++/c code out there gives a **** about strict aliasing - rightfully in my opinion, but thats a different topic)\r\n\r\n> g++ --version\r\ng++ (conda-forge gcc 11.3.0-19) 11.3.0\r\nCopyright (C) 2021 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3798/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3798/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3797", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3797/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3797/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3797/events", "html_url": "https://github.com/horovod/horovod/issues/3797", "id": 1486910992, "node_id": "I_kwDOBfOI785YoHYQ", "number": 3797, "title": "CI: Docker image build for horovod-nvtabular runs into time out", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-12-09T15:04:47Z", "updated_at": "2023-01-16T09:56:32Z", "closed_at": "2023-01-16T09:56:32Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Ex.: https://github.com/horovod/horovod/actions/runs/3656223581/jobs/6181962659\r\n\r\n```\r\n#12 151.5 Solving environment: ...working... \r\nError: The action has timed out.\r\n```\r\n\r\nIf Docker time stamps in that log are to be believed, then it seems to hang there at the Conda environment stage for > 50 minutes.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3797/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3797/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3795", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3795/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3795/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3795/events", "html_url": "https://github.com/horovod/horovod/issues/3795", "id": 1486850739, "node_id": "I_kwDOBfOI785Yn4qz", "number": 3795, "title": "Seen with tf-head: ModuleNotFoundError: No module named 'keras.optimizers.optimizer_v2'", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-12-09T14:25:50Z", "updated_at": "2022-12-10T09:54:00Z", "closed_at": "2022-12-10T09:54:00Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Problem with tf-head / Keras seen in CI, for instance at https://github.com/horovod/horovod/actions/runs/3656223581/jobs/6180240570\r\n\r\n```\r\n___________ ERROR collecting test/parallel/test_tensorflow_keras.py ____________\r\nImportError while importing test module '/horovod/test/parallel/test_tensorflow_keras.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.8/importlib/__init__.py:127: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntest_tensorflow_keras.py:36: in <module>\r\n    from keras.optimizers.optimizer_v2 import optimizer_v2\r\nE   ModuleNotFoundError: No module named 'keras.optimizers.optimizer_v2'\r\n```\r\n```\r\n___________ ERROR collecting test/parallel/test_tensorflow2_keras.py ___________\r\nImportError while importing test module '/horovod/test/parallel/test_tensorflow2_keras.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.8/importlib/__init__.py:127: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntest_tensorflow2_keras.py:35: in <module>\r\n    from keras.optimizers.optimizer_v2 import optimizer_v2\r\nE   ModuleNotFoundError: No module named 'keras.optimizers.optimizer_v2'\r\n\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3795/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3795/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3793", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3793/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3793/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3793/events", "html_url": "https://github.com/horovod/horovod/issues/3793", "id": 1484999323, "node_id": "I_kwDOBfOI785Yg0qb", "number": 3793, "title": "CI: Spark tests fail on TF 1.15 trying to parse \"invalid\" Keras version '2.2.4-tf'", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2022-12-08T16:36:22Z", "updated_at": "2022-12-09T09:37:14Z", "closed_at": "2022-12-09T09:37:14Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "```\r\n________________________ SparkKerasTests.test_fit_model ________________________\r\nself = <test_spark_keras.SparkKerasTests testMethod=test_fit_model>\r\n\r\n    def test_fit_model(self):\r\n        model = create_xor_model()\r\n>       optimizer = get_sgd_optimizer()\r\n\r\ntest_spark_keras.py:98: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\ntest_spark_keras.py:83: in get_sgd_optimizer\r\n    if version.parse(tf.keras.__version__) < version.parse(\"2.11\"):\r\n/usr/local/lib/python3.7/dist-packages/packaging/version.py:52: in parse\r\n    return Version(version)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <[AttributeError(\"'Version' object has no attribute '_version'\") raised in repr()] Version object at 0x7fdfd7528090>\r\nversion = '2.2.4-tf'\r\n\r\n    def __init__(self, version: str) -> None:\r\n        \"\"\"Initialize a Version object.\r\n    \r\n        :param version:\r\n            The string representation of a version which will be parsed and normalized\r\n            before use.\r\n        :raises InvalidVersion:\r\n            If the ``version`` does not conform to PEP 440 in any way then this\r\n            exception will be raised.\r\n        \"\"\"\r\n    \r\n        # Validate the version and parse it into pieces\r\n        match = self._regex.search(version)\r\n        if not match:\r\n>           raise InvalidVersion(f\"Invalid version: '{version}'\")\r\nE           packaging.version.InvalidVersion: Invalid version: '2.2.4-tf'\r\n\r\n/usr/local/lib/python3.7/dist-packages/packaging/version.py:197: InvalidVersion\r\n```\r\n\r\nSeen for `Build and Test (test-cpu-gloo-py3_7-tf1_15_5-keras2_2_4-torch1_8_1-mxnet1_5_1_p0-pyspark3_3_1)`: https://github.com/horovod/horovod/actions/runs/3647365170/jobs/6159518835\r\n\r\nPresumably this is related to https://github.com/pypa/packaging/pull/407 in `packaging` version 22.0, released recently: https://github.com/pypa/packaging/releases/tag/22.0\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3793/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3793/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3782", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3782/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3782/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3782/events", "html_url": "https://github.com/horovod/horovod/issues/3782", "id": 1460172591, "node_id": "I_kwDOBfOI785XCHcv", "number": 3782, "title": "GPU Usage Extremely Low using Horovod Runner on Databricks ", "user": {"login": "andrejfd", "id": 111071978, "node_id": "U_kgDOBp7S6g", "avatar_url": "https://avatars.githubusercontent.com/u/111071978?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrejfd", "html_url": "https://github.com/andrejfd", "followers_url": "https://api.github.com/users/andrejfd/followers", "following_url": "https://api.github.com/users/andrejfd/following{/other_user}", "gists_url": "https://api.github.com/users/andrejfd/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrejfd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrejfd/subscriptions", "organizations_url": "https://api.github.com/users/andrejfd/orgs", "repos_url": "https://api.github.com/users/andrejfd/repos", "events_url": "https://api.github.com/users/andrejfd/events{/privacy}", "received_events_url": "https://api.github.com/users/andrejfd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-11-22T16:19:26Z", "updated_at": "2023-01-09T02:57:45Z", "closed_at": "2023-01-09T02:57:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\nTensorFlow\r\n2. Framework version:\r\n2.9.1\r\n3. Horovod version:\r\n0.25.0\r\n4. MPI version:\r\n(Open MPI) 4.1.4\r\n5. CUDA version:\r\n11.4\r\n6. NCCL version:\r\n2.9.9\r\n7. Python version:\r\n3.9.5\r\n8. Spark / PySpark version:\r\nDatabricks 11.3 LTS ML, Apache Spar 3.3.0, Scala 2.12\r\n9. Ray version:\r\nN/A\r\n10. OS and version:\r\nUbuntu 20.04.5 LTS\r\n11. GCC version:\r\n9.4.0\r\n12. CMake version:\r\n3.16.3\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\nYes, similar issues but not same using horovod runner.\r\n\r\n3. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\nN/A\r\n5. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\nN/A\r\n7. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\nYes\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nI am using Horovod runner in databricks runtime, and do not seem to reach any sort of optimal GPU usage.\r\n\r\nBoth on multiple workers, driver with 4 GPUs, and tested with driver and single GPU.\r\n\r\nRunning with V100s on AWS and seems peak memory usage for my application reaches 2000MiB/16160MiB as output in nvidia-smi.\r\n\r\nI am using petastorm as a dataloader and then horovodrunner to train the model.\r\n\r\nEven with `hr.run(train)` with `np=-1` I get 2000MiB max during training, what could this be?\r\n\r\nWhen I run on the driver node with 1 GPU, I get about 3x it/s faster performance.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3782/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3782/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3779", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3779/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3779/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3779/events", "html_url": "https://github.com/horovod/horovod/issues/3779", "id": 1457001489, "node_id": "I_kwDOBfOI785W2BQR", "number": 3779, "title": "Using nccl 2.15.1+cuda11.8 results in test failures in multiple tests", "user": {"login": "Tixxx", "id": 26332583, "node_id": "MDQ6VXNlcjI2MzMyNTgz", "avatar_url": "https://avatars.githubusercontent.com/u/26332583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tixxx", "html_url": "https://github.com/Tixxx", "followers_url": "https://api.github.com/users/Tixxx/followers", "following_url": "https://api.github.com/users/Tixxx/following{/other_user}", "gists_url": "https://api.github.com/users/Tixxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tixxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tixxx/subscriptions", "organizations_url": "https://api.github.com/users/Tixxx/orgs", "repos_url": "https://api.github.com/users/Tixxx/repos", "events_url": "https://api.github.com/users/Tixxx/events{/privacy}", "received_events_url": "https://api.github.com/users/Tixxx/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Tixxx", "id": 26332583, "node_id": "MDQ6VXNlcjI2MzMyNTgz", "avatar_url": "https://avatars.githubusercontent.com/u/26332583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tixxx", "html_url": "https://github.com/Tixxx", "followers_url": "https://api.github.com/users/Tixxx/followers", "following_url": "https://api.github.com/users/Tixxx/following{/other_user}", "gists_url": "https://api.github.com/users/Tixxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tixxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tixxx/subscriptions", "organizations_url": "https://api.github.com/users/Tixxx/orgs", "repos_url": "https://api.github.com/users/Tixxx/repos", "events_url": "https://api.github.com/users/Tixxx/events{/privacy}", "received_events_url": "https://api.github.com/users/Tixxx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Tixxx", "id": 26332583, "node_id": "MDQ6VXNlcjI2MzMyNTgz", "avatar_url": "https://avatars.githubusercontent.com/u/26332583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tixxx", "html_url": "https://github.com/Tixxx", "followers_url": "https://api.github.com/users/Tixxx/followers", "following_url": "https://api.github.com/users/Tixxx/following{/other_user}", "gists_url": "https://api.github.com/users/Tixxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tixxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tixxx/subscriptions", "organizations_url": "https://api.github.com/users/Tixxx/orgs", "repos_url": "https://api.github.com/users/Tixxx/repos", "events_url": "https://api.github.com/users/Tixxx/events{/privacy}", "received_events_url": "https://api.github.com/users/Tixxx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2022-11-20T18:31:46Z", "updated_at": "2023-04-27T20:16:59Z", "closed_at": "2023-04-27T20:16:59Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version: tf and pytorch nightly\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version: 11.8\r\n6. NCCL version: 2.15.1+cuda11.8\r\n7. Python version:\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version:\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nWhen using nccl 2.15.1+cuda11.8, some tests fail with nccl errors, this is one of the examples below:\r\n\r\n\r\n[0]<stdout>:___________________ ComputeWorkerTest.test_single_dispatcher ___________________\r\n--\r\n\u00a0 | [0]<stdout>:\r\n\u00a0 | [1]<stdout>:test_compute_worker.py:73: in do_test_worker\r\n\u00a0 | [0]<stdout>:self = <test_compute_worker.ComputeWorkerTest testMethod=test_single_dispatcher>\r\n\u00a0 | [1]<stdout>:    self.do_test_worker_compute_side(dispatchers, processing_mode=processing_mode, reuse_dataset=reuse_dataset, round_robin=round_robin)\r\n\u00a0 | [0]<stdout>:\r\n\u00a0 | [1]<stdout>:test_compute_worker.py:91: in do_test_worker_compute_side\r\n\u00a0 | [0]<stdout>:    def test_single_dispatcher(self):\r\n\u00a0 | [1]<stdout>:    cluster_shape = hvd.allgather_object((self.rank, self.size), name='test_start')\r\n\u00a0 | [0]<stdout>:>       self.do_test_worker(1, reuse_dataset=False, round_robin=False)\r\n\u00a0 | [1]<stdout>:/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/functions.py:212: in allgather_object\r\n\u00a0 | [0]<stdout>:\r\n\u00a0 | [1]<stdout>:    sizes = to_numpy(allgather(sz, name=name + '.sz', process_set=process_set))\r\n\u00a0 | [0]<stdout>:test_compute_worker.py:53:\r\n\u00a0 | [1]<stdout>:/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/mpi_ops.py:222: in allgather\r\n\u00a0 | [0]<stdout>:_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\u00a0 | [1]<stdout>:    return MPI_LIB.horovod_allgather(tensor, name=name,\r\n\u00a0 | [0]<stdout>:test_compute_worker.py:73: in do_test_worker\r\n\u00a0 | [1]<stdout>:<string>:357: in horovod_allgather\r\n\u00a0 | [0]<stdout>:    self.do_test_worker_compute_side(dispatchers, processing_mode=processing_mode, reuse_dataset=reuse_dataset, round_robin=round_robin)\r\n\u00a0 | [1]<stdout>:    ???\r\n\u00a0 | [0]<stdout>:test_compute_worker.py:91: in do_test_worker_compute_side\r\n\u00a0 | [1]<stdout>:_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\u00a0 | [0]<stdout>:    cluster_shape = hvd.allgather_object((self.rank, self.size), name='test_start')\r\n\u00a0 | [1]<stdout>:\r\n\u00a0 | [0]<stdout>:/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/functions.py:212: in allgather_object\r\n\u00a0 | [1]<stdout>:e = _NotOkStatusException(), name = 'test_start.sz'\r\n\u00a0 | [0]<stdout>:    sizes = to_numpy(allgather(sz, name=name + '.sz', process_set=process_set))\r\n\u00a0 | [1]<stdout>:\r\n\u00a0 | [0]<stdout>:/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/mpi_ops.py:222: in allgather\r\n\u00a0 | [1]<stdout>:    def raise_from_not_ok_status(e, name):\r\n\u00a0 | [0]<stdout>:    return MPI_LIB.horovod_allgather(tensor, name=name,\r\n\u00a0 | [1]<stdout>:      e.message += (\" name: \" + name if name is not None else \"\")\r\n\u00a0 | [0]<stdout>:<string>:357: in horovod_allgather\r\n\u00a0 | [1]<stdout>:>     raise core._status_to_exception(e) from None  # pylint: disable=protected-access\r\n\u00a0 | [0]<stdout>:    ???\r\n\u00a0 | [1]<stdout>:E     tensorflow.python.framework.errors_impl.UnknownError: {{function_node **__wrapped__HorovodAllgather_device_/job:localhost/replica:0/task:0/device:GPU:0}} ncclAllGather failed: invalid argument [Op:HorovodAllgather] name: test_start.sz**\r\n\u00a0 | [0]<stdout>:_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\u00a0 | [1]<stdout>:\r\n\u00a0 | [0]<stdout>:\r\n\u00a0 | [1]<stdout>:/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:7252: UnknownError\r\n\u00a0 | [0]<stdout>:e = _NotOkStatusException(), name = 'test_start.sz'\r\n\r\n\r\n\r\nThere are also other errors related to allreduce.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3779/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3779/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3757", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3757/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3757/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3757/events", "html_url": "https://github.com/horovod/horovod/issues/3757", "id": 1425089484, "node_id": "I_kwDOBfOI785U8SPM", "number": 3757, "title": "static tsl::Status tsl::Status::OK() is deprecated warning when build with Tensorflow 2.11.0rc1", "user": {"login": "pfierek-hb-ai", "id": 75849792, "node_id": "MDQ6VXNlcjc1ODQ5Nzky", "avatar_url": "https://avatars.githubusercontent.com/u/75849792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pfierek-hb-ai", "html_url": "https://github.com/pfierek-hb-ai", "followers_url": "https://api.github.com/users/pfierek-hb-ai/followers", "following_url": "https://api.github.com/users/pfierek-hb-ai/following{/other_user}", "gists_url": "https://api.github.com/users/pfierek-hb-ai/gists{/gist_id}", "starred_url": "https://api.github.com/users/pfierek-hb-ai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pfierek-hb-ai/subscriptions", "organizations_url": "https://api.github.com/users/pfierek-hb-ai/orgs", "repos_url": "https://api.github.com/users/pfierek-hb-ai/repos", "events_url": "https://api.github.com/users/pfierek-hb-ai/events{/privacy}", "received_events_url": "https://api.github.com/users/pfierek-hb-ai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 728479138, "node_id": "MDU6TGFiZWw3Mjg0NzkxMzg=", "url": "https://api.github.com/repos/horovod/horovod/labels/contribution%20welcome", "name": "contribution welcome", "color": "138e05", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-10-27T06:14:30Z", "updated_at": "2022-11-17T07:22:55Z", "closed_at": "2022-11-17T07:22:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow)\r\n2. Framework version: 2.11.0rc1\r\n3. Horovod version: 0.26.1\r\n4. MPI version: 4.1.2\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.8.10\r\n8. Spark / PySpark version: N/A\r\n9. Ray version: N/A\r\n10. OS and version: ubuntu 20.04\r\n11. GCC version: 9.4.0\r\n12. CMake version: 3.16.3\r\n\r\n**Bug report:**\r\nWhen i install (build) horovod with tensorflow-cpu==2.11.0rc1 i get a lot of warnings, like: \r\n```horovod/tensorflow/mpi_ops.cc:1771:25: warning: \u2018static tsl::Status tsl::Status::OK()\u2019 is deprecated: Use `OkStatus()` (preferred) or `Status()` (wh\r\nich is backward compatible with TF v2.9 and lower) instead. [-Wdeprecated-declarations]                                                                                                     \r\n 1771 |       return Status::OK();```\r\n\r\nThis problem did not appear in previous versions of Tensorflow.\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3757/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3757/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3754", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3754/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3754/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3754/events", "html_url": "https://github.com/horovod/horovod/issues/3754", "id": 1419471174, "node_id": "I_kwDOBfOI785Um2lG", "number": 3754, "title": "With \"tf-nightly-cpu==2.12.0.dev20221019\" and newer, \"import horovod.tensorflow as hvd\" throws \"undefined symbol\" error.", "user": {"login": "ashahba", "id": 12436063, "node_id": "MDQ6VXNlcjEyNDM2MDYz", "avatar_url": "https://avatars.githubusercontent.com/u/12436063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ashahba", "html_url": "https://github.com/ashahba", "followers_url": "https://api.github.com/users/ashahba/followers", "following_url": "https://api.github.com/users/ashahba/following{/other_user}", "gists_url": "https://api.github.com/users/ashahba/gists{/gist_id}", "starred_url": "https://api.github.com/users/ashahba/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ashahba/subscriptions", "organizations_url": "https://api.github.com/users/ashahba/orgs", "repos_url": "https://api.github.com/users/ashahba/repos", "events_url": "https://api.github.com/users/ashahba/events{/privacy}", "received_events_url": "https://api.github.com/users/ashahba/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2022-10-22T19:31:29Z", "updated_at": "2022-12-09T14:49:08Z", "closed_at": "2022-12-09T14:49:08Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: `TensorFlow`\r\n2. Framework version: `tf-nightly==2.12.0.dev20221019` or newer\r\n3. Horovod version: `All`\r\n4. MPI version: `4.0.3`\r\n5. CUDA version: `N/A`\r\n6. NCCL version: `N/A`\r\n7. Python version: `3.8.10`\r\n8. Spark / PySpark version: `N/A`\r\n9. Ray version: `N/A`\r\n10. OS and version: `Ubuntu 20.04.5 LTS`\r\n11. GCC version: `9.4.0`\r\n12. CMake version: `3.16.3`\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? `Yes`\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? `N/A`\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? `N/A`\r\n4. Did you check if you question is answered in the [troubleshooting guide] (https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? `Yes`\r\n\r\n**Bug report:**\r\nWith \"tf-nightly-cpu==2.12.0.dev20221019\" and newer, \"import horovod.tensorflow as hvd\" throws \"undefined symbol\" as below regardless which version Horovod release is used:\r\n\r\n```\r\n(tf-nightly-cpu) root@05635c676813:~# export HOROVOD_VERSION=v0.26.0\r\n(tf-nightly-cpu) root@05635c676813:~# python3 -m pip install --no-cache-dir git+https://github.com/horovod/horovod.git@${HOROVOD_VERSION}\r\nCollecting git+https://github.com/horovod/horovod.git@v0.26.0\r\n  Cloning https://github.com/horovod/horovod.git (to revision v0.26.0) to /tmp/pip-req-build-op6r8nuv\r\n  Running command git clone -q https://github.com/horovod/horovod.git /tmp/pip-req-build-op6r8nuv\r\n  Running command git checkout -q c638dcec972750d4a75b229bc208cff9dc76b00a\r\n  Running command git submodule update --init --recursive -q\r\nCollecting cloudpickle\r\n  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\r\nRequirement already satisfied: packaging in ./tf-nightly-cpu/lib/python3.8/site-packages (from horovod==0.26.0) (21.3)\r\nCollecting psutil\r\n  Downloading psutil-5.9.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 295 kB 88.3 MB/s \r\nCollecting pyyaml\r\n  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 701 kB 131.0 MB/s \r\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./tf-nightly-cpu/lib/python3.8/site-packages (from packaging->horovod==0.26.0) (3.0.9)\r\nBuilding wheels for collected packages: horovod\r\n  Building wheel for horovod (setup.py) ... done\r\n  Created wheel for horovod: filename=horovod-0.26.0-cp38-cp38-linux_x86_64.whl size=19817679 sha256=58bf0042b9c9d7068d69558ce479884c4dc64feef0618534b361fd9ee3572a88\r\n  Stored in directory: /tmp/pip-ephem-wheel-cache-dha_sfk9/wheels/4d/88/85/e2cf70be97879d9f6662a0e0a2b80d9abc7485bf6f4665af0f\r\nSuccessfully built horovod\r\nInstalling collected packages: cloudpickle, psutil, pyyaml, horovod\r\nSuccessfully installed cloudpickle-2.2.0 horovod-0.26.0 psutil-5.9.3 pyyaml-6.0\r\n(tf-nightly-cpu) root@05635c676813:~# python\r\nPython 3.8.10 (default, Jun 22 2022, 20:18:18) \r\n[GCC 9.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import horovod.tensorflow as hvd\r\n2022-10-22 18:55:02.445270: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/root/tf-nightly-cpu/lib/python3.8/site-packages/horovod/tensorflow/__init__.py\", line 27, in <module>\r\n    from horovod.tensorflow import elastic\r\n  File \"/root/tf-nightly-cpu/lib/python3.8/site-packages/horovod/tensorflow/elastic.py\", line 24, in <module>\r\n    from horovod.tensorflow.functions import broadcast_object, broadcast_object_fn, broadcast_variables\r\n  File \"/root/tf-nightly-cpu/lib/python3.8/site-packages/horovod/tensorflow/functions.py\", line 24, in <module>\r\n    from horovod.tensorflow.mpi_ops import allgather, broadcast, broadcast_\r\n  File \"/root/tf-nightly-cpu/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py\", line 53, in <module>\r\n    raise e\r\n  File \"/root/tf-nightly-cpu/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py\", line 50, in <module>\r\n    MPI_LIB = _load_library('mpi_lib' + get_ext_suffix())\r\n  File \"/root/tf-nightly-cpu/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py\", line 45, in _load_library\r\n    library = load_library.load_op_library(filename)\r\n  File \"/root/tf-nightly-cpu/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\", line 54, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /root/tf-nightly-cpu/lib/python3.8/site-packages/horovod/tensorflow/mpi_lib.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK3xla14HloComputation23CollectUnreachableRootsEv\r\n```\r\n\r\nI even tried with every single commit after `v0.26.0` that has gone into Horovod's `master` branch and the behavior is the same.\r\nHowever if `tf-nightly-cpu==2.12.0.dev20221018` is used, this is no loner an issue!\r\n`tf-nightly` also shows the same error if nightly versions above are used.\r\n\r\nChances are the changes that went into TensorFlow's `setup.py` here:\r\nhttps://github.com/tensorflow/tensorflow/commits/master/tensorflow/tools/pip_package/setup.py\r\nand starting from this commit: `6b7be928f9043c7199810109b1f4d0988c3f0a02`\r\n\r\nare contributing to the issue, but I'm not \ud83d\udcaf certain.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3754/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3754/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3753", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3753/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3753/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3753/events", "html_url": "https://github.com/horovod/horovod/issues/3753", "id": 1417408650, "node_id": "I_kwDOBfOI785Ue_CK", "number": 3753, "title": "cmake cannot find custom openmpi installation", "user": {"login": "slittle-twilio", "id": 102050829, "node_id": "U_kgDOBhUsDQ", "avatar_url": "https://avatars.githubusercontent.com/u/102050829?v=4", "gravatar_id": "", "url": "https://api.github.com/users/slittle-twilio", "html_url": "https://github.com/slittle-twilio", "followers_url": "https://api.github.com/users/slittle-twilio/followers", "following_url": "https://api.github.com/users/slittle-twilio/following{/other_user}", "gists_url": "https://api.github.com/users/slittle-twilio/gists{/gist_id}", "starred_url": "https://api.github.com/users/slittle-twilio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/slittle-twilio/subscriptions", "organizations_url": "https://api.github.com/users/slittle-twilio/orgs", "repos_url": "https://api.github.com/users/slittle-twilio/repos", "events_url": "https://api.github.com/users/slittle-twilio/events{/privacy}", "received_events_url": "https://api.github.com/users/slittle-twilio/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-10-20T22:38:59Z", "updated_at": "2023-02-05T16:51:29Z", "closed_at": "2023-02-05T16:51:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: Tensorflow 2.8.0\r\n3. Horovod version: 0.25.0\r\n4. MPI version: 4.0.1\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.8\r\n8. Spark / PySpark version: 3.2.2\r\n9. Ray version: N/A\r\n10. OS and version: Ubuntu 18.04\r\n11. GCC version: 7.5.0\r\n12. CMake version: 3.23.1\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nIt seems like cmake in the Horovod installation is not picking up my openmpi (v4.0.1) installation. I've added openmpi to `LD_LIBRARY_PATH` and `PATH` and a couple of other things to help cmake find it:\r\n```ENV LD_LIBRARY_PATH=/opt/openmpi/lib:/opt/openmpi/lib/pmix:/opt/openmpi/lib/openmpi:/opt/conda/lib:/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH\r\nENV PATH=/opt/openmpi/bin:/opt/conda/bin:/usr/bin:$PATH\r\nENV MPICC=/opt/openmpi/bin/mpicc\r\nENV MPI_HOME=/opt/openmpi\r\nRUN echo /opt/openmpi/lib | tee -a /etc/ld.so.conf\r\nRUN ldconfig\r\n```\r\nAs a note, pip has no problem finding openmpi when installing mpi4py.\r\n\r\nBut still cmake is not able to find openmpi:\r\n```\r\n...\r\nRunning CMake in build/temp.linux-x86_64-3.8/RelWithDebInfo:\r\n--\r\n\u00a0 | cmake /tmp/pip-install-uvv5lcic/horovod_218c269c263f47eeba0923e748e34010 -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/tmp/pip-install-uvv5lcic/horovod_218c269c263f47eeba0923e748e34010/build/lib.linux-x86_64-3.8 -DPYTHON_EXECUTABLE:FILEPATH=/opt/conda/bin/python\r\n\u00a0 | cmake --build . --config RelWithDebInfo -- -j8 VERBOSE=1\r\n\u00a0 | -- The CXX compiler identification is GNU 7.5.0\r\n\u00a0 | -- Detecting CXX compiler ABI info\r\n\u00a0 | -- Detecting CXX compiler ABI info - done\r\n\u00a0 | -- Check for working CXX compiler: /opt/conda/bin/c++ - skipped\r\n\u00a0 | -- Detecting CXX compile features\r\n\u00a0 | -- Detecting CXX compile features - done\r\n\u00a0 | -- Build architecture flags: -mf16c -mavx -mfma\r\n\u00a0 | -- Using command /opt/conda/bin/python\r\n\u00a0 | -- Could NOT find MPI_CXX (missing: MPI_CXX_WORKS)\r\n\u00a0 | CMake Error at /opt/conda/share/cmake-3.23/Modules/FindPackageHandleStandardArgs.cmake:230 (message):\r\n\u00a0 | Could NOT find MPI (missing: MPI_CXX_FOUND)\r\n\u00a0 | Call Stack (most recent call first):\r\n\u00a0 | /opt/conda/share/cmake-3.23/Modules/FindPackageHandleStandardArgs.cmake:594 (_FPHSA_FAILURE_MESSAGE)\r\n\u00a0 | /opt/conda/share/cmake-3.23/Modules/FindMPI.cmake:1830 (find_package_handle_standard_args)\r\n\u00a0 | CMakeLists.txt:138 (find_package)\r\n...\r\n```\r\n\r\nQuestion on how to specify the location using the `HOROVOD_BUILD_ARCH_FLAGS` variable to help cmake find my openmpi installation: does this look correct?\r\n```\r\n# Horovod installation\r\nRUN /opt/conda/bin/python -m pip install --no-deps --no-cache-dir \"petastorm>=0.12.0\" && \\\r\n    HOROVOD_WITH_MPI=1 HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITHOUT_MXNET=1 HOROVOD_WITHOUT_GLOO=1 \\\r\n    HOROVOD_BUILD_ARCH_FLAGS=\"-DMPI_C_COMPILER=/opt/openmpi/bin/mpicc -DMPI_CXX_COMPILER=/opt/openmpi/bin/mpicxx\" \\\r\n    /opt/conda/bin/python -m pip install --no-deps --no-cache-dir \"horovod==0.25.0\"\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3753/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3753/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3744", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3744/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3744/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3744/events", "html_url": "https://github.com/horovod/horovod/issues/3744", "id": 1408651184, "node_id": "I_kwDOBfOI785T9k-w", "number": 3744, "title": "No module named 'packaging' when install horovod", "user": {"login": "ice-tong", "id": 32220263, "node_id": "MDQ6VXNlcjMyMjIwMjYz", "avatar_url": "https://avatars.githubusercontent.com/u/32220263?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ice-tong", "html_url": "https://github.com/ice-tong", "followers_url": "https://api.github.com/users/ice-tong/followers", "following_url": "https://api.github.com/users/ice-tong/following{/other_user}", "gists_url": "https://api.github.com/users/ice-tong/gists{/gist_id}", "starred_url": "https://api.github.com/users/ice-tong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ice-tong/subscriptions", "organizations_url": "https://api.github.com/users/ice-tong/orgs", "repos_url": "https://api.github.com/users/ice-tong/repos", "events_url": "https://api.github.com/users/ice-tong/events{/privacy}", "received_events_url": "https://api.github.com/users/ice-tong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2022-10-14T02:13:47Z", "updated_at": "2022-10-27T10:31:27Z", "closed_at": "2022-10-14T05:28:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "It seems that the horovod v0.26.0 has some dependency problems.\r\n\r\nHow long does it take for a new patch version to be released or should I pin the horovod version? ^_^\r\n\r\n![image](https://user-images.githubusercontent.com/32220263/195746141-2a0050f5-1eaf-4f7b-9a62-50fd6b13f2ff.png)\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3744/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3744/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3728", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3728/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3728/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3728/events", "html_url": "https://github.com/horovod/horovod/issues/3728", "id": 1398775322, "node_id": "I_kwDOBfOI785TX54a", "number": 3728, "title": "Pytorch-MPIAllreduce-ROCM installation error: undefined horovod symbol in horovodrun [HOROVOD_GPU_ALLREDUCE=MPI]", "user": {"login": "R0n12", "id": 59843980, "node_id": "MDQ6VXNlcjU5ODQzOTgw", "avatar_url": "https://avatars.githubusercontent.com/u/59843980?v=4", "gravatar_id": "", "url": "https://api.github.com/users/R0n12", "html_url": "https://github.com/R0n12", "followers_url": "https://api.github.com/users/R0n12/followers", "following_url": "https://api.github.com/users/R0n12/following{/other_user}", "gists_url": "https://api.github.com/users/R0n12/gists{/gist_id}", "starred_url": "https://api.github.com/users/R0n12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/R0n12/subscriptions", "organizations_url": "https://api.github.com/users/R0n12/orgs", "repos_url": "https://api.github.com/users/R0n12/repos", "events_url": "https://api.github.com/users/R0n12/events{/privacy}", "received_events_url": "https://api.github.com/users/R0n12/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-10-06T04:44:05Z", "updated_at": "2022-10-17T08:33:17Z", "closed_at": "2022-10-17T08:33:17Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: **Pytorch**\r\n2. Framework version: **1.12.0a0+git664058f** (v1.12.1 release source)\r\n3. Horovod version: **commit 141f41ea93731b9e3d2d7ecbac70fc10e0a8ec7e** **PR** [**#3588**](https://github.com/horovod/horovod/pull/3588)\r\n4. MPI version: MVAPICH2-GDR 2.3.7\r\n5. CUDA version: **N/A**\r\n6. NCCL version: **N/A**\r\n7. ROCM version: **5.1.1**\r\n8. Python version: **3.8.13**\r\n9. Spark / PySpark version: **N/A**\r\n10. Ray version: **N/A**\r\n11. OS and version:\r\n```\r\nNAME=\"Rocky Linux\"\r\nVERSION=\"8.5 (Green Obsidian)\"\r\nID=\"rocky\"\r\nID_LIKE=\"rhel centos fedora\"\r\nVERSION_ID=\"8.5\"\r\nPLATFORM_ID=\"platform:el8\"\r\nPRETTY_NAME=\"Rocky Linux 8.5 (Green Obsidian)\"\r\nANSI_COLOR=\"0;32\"\r\nCPE_NAME=\"cpe:/o:rocky:rocky:8.5:GA\"\r\nHOME_URL=\"https://rockylinux.org/\"\r\nBUG_REPORT_URL=\"https://bugs.rockylinux.org/\"\r\nROCKY_SUPPORT_PRODUCT=\"Rocky Linux\"\r\nROCKY_SUPPORT_PRODUCT_VERSION=\"8\"\r\n```\r\n13. GCC version: **10.3.0**\r\n14. CMake version: **3.22.2**\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?  **Yes**\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nI was able to build horovod on top of pytorch with mpiallreduce rocm support, however when I ran `horovodrun --check-build --verbose`, it is not able to detect built pytorch because of the following error:\r\n\r\n`ImportError: /home/xu.3304/miniconda3/envs/hvd-torch-rocm/lib/python3.8/site-packages/horovod-0.25.0-py3.8-linux-x86_64.egg/horovod/torch/mpi_lib_v2.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN7horovod6common16MPI_GPUAllreduceC1EPNS0_10GPUContextEPNS0_18HorovodGlobalStateE`\r\n\r\nHorovod build command:  \r\n```\r\nHOROVOD_ROCM_HOME=/opt/rocm-5.1.1 CC=$(which mpicc) CXX=$(which mpicxx) HOROVOD_WITHOUT_GLOO=1 HOROVOD_WITH_MPI=1 HOROVOD_GPU=ROCM HOROVOD_GPU_ALLREDUCE=MPI HOROVOD_WITHOUT_TENSORFLOW=1 HOROVOD_WITH_PYTORCH=1 HOROVOD_WITHOUT_MXNET=1 /home/xu.3304/miniconda3/envs/hvd-torch-rocm/bin/python setup.py install > \"${outfile}\" 2>&1\r\n```\r\n\r\nthe horovod build log:  \r\n[hvd_build.log](https://github.com/horovod/horovod/files/9721281/hvd_build.log)\r\nthe horovodrun checkbuild verbose output:  \r\n[hvdrun_checkbuild_verbose.log](https://github.com/horovod/horovod/files/9721282/hvdrun_checkbuild_verbose.log)\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3728/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3728/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3704", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3704/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3704/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3704/events", "html_url": "https://github.com/horovod/horovod/issues/3704", "id": 1378321620, "node_id": "I_kwDOBfOI785SJ4TU", "number": 3704, "title": "I coundn't use all GPU with 2 machine", "user": {"login": "Passerby", "id": 1323588, "node_id": "MDQ6VXNlcjEzMjM1ODg=", "avatar_url": "https://avatars.githubusercontent.com/u/1323588?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Passerby", "html_url": "https://github.com/Passerby", "followers_url": "https://api.github.com/users/Passerby/followers", "following_url": "https://api.github.com/users/Passerby/following{/other_user}", "gists_url": "https://api.github.com/users/Passerby/gists{/gist_id}", "starred_url": "https://api.github.com/users/Passerby/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Passerby/subscriptions", "organizations_url": "https://api.github.com/users/Passerby/orgs", "repos_url": "https://api.github.com/users/Passerby/repos", "events_url": "https://api.github.com/users/Passerby/events{/privacy}", "received_events_url": "https://api.github.com/users/Passerby/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-09-19T17:56:21Z", "updated_at": "2022-09-21T09:52:24Z", "closed_at": "2022-09-21T09:52:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) tensorflow 2.8\r\n2. Framework version: tensorflow 2.8\r\n3. Horovod version:  v0.24.3\r\n4. MPI version: 4.0.0\r\n5. CUDA version: 11.2.1 (docker nvidia/cuda:11.2.1-cudnn8-devel-ubuntu18.04)\r\n6. NCCL version: 2.8  (docker nvidia/cuda:11.2.1-cudnn8-devel-ubuntu18.04)\r\n7. Python version: 3.9\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version: ubuntu18.04\r\n11. GCC version: 7.5\r\n12. CMake version: 3.22.4 \r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Y\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? Y\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? Y\r\n4. Did you check if you question is answered in the [troubleshooting guide] (https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Y\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\nHorovod v0.24.3:\r\n\r\nAvailable Frameworks:\r\n    [X] TensorFlow\r\n    [X] PyTorch\r\n    [ ] MXNet\r\n\r\nAvailable Controllers:\r\n    [X] MPI\r\n    [ ] Gloo\r\n\r\nAvailable Tensor Operations:\r\n    [X] NCCL\r\n    [ ] DDL\r\n    [ ] CCL\r\n    [X] MPI\r\n    [ ] Gloo\r\n\r\nI have 2 machine(4 x A100 GPU),\r\n\r\nwhen I run the command in 1 machine with 4 GPU, it's fine\r\n```\r\ndocker run --rm -it --net=host  xxximage horovodrun --verbose -np 4 -H xxxx1:4 -p 12345 python3 tensorflow2_keras_mnist.py\r\n```\r\n\r\nwhen I run the command in 2 machine with 2 GPU each machine, it's fine\r\n```\r\ndocker run --rm -it --net=host  xxximage  bash -c \"/usr/sbin/sshd -p 12345; sleep infinity\" \r\n\r\ndocker run --rm -it --net=host  xxximage horovodrun --verbose -np 4 -H xxxx1:2,xxxx2:2 -p 12345 python3 tensorflow2_keras_mnist.py\r\n```\r\n\r\nwhen I run the command in 2 machine with 4 GPU each machine, is's wrong, hang out in epoch 1\r\n```\r\ndocker run --rm -it --net=host  xxximage  bash -c \"/usr/sbin/sshd -p 12345; sleep infinity\" \r\ndocker run --rm -it --net=host  xxximage horovodrun --verbose -np 8 -H xxxx1:4,xxxx2:4 -p 12345 python3 tensorflow2_keras_mnist.py\r\n```\r\n\r\n```\r\nmpirun --allow-run-as-root --tag-output -np 8 -H xxxx:4,xxxxx:4 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca plm_rsh_args \"-p 12345\" -mca btl_tcp_if_include bond0 -x NCCL_SOCKET_IFNAME=bond0  -x CUDA_VERSION -x DEBIAN_FRONTEND -x HOME -x HOSTNAME -x LC_CTYPE -x[555/9786]\r\nY_PATH -x LIBRARY_PATH -x NCCL_VERSION -x NVARCH -x NVIDIA_DRIVER_CAPABILITIES -x NVIDIA_REQUIRE_CUDA -x NVIDIA_VISIBLE_DEVICES -x NV_CUDA_COMPAT_PACKAGE -x NV_CUDA_CUDART_DEV_VERSION -x NV_CUDA_CUDART_VERSION -x NV_CUDA_LIB_VERSION -x NV_LIBCUBLAS_DEV_PACKAGE -x NV_LIBCUBLAS_DEV_PACKAGE_NAME -x NV_LIBCUBLAS_DEV_VER\r\nSION -x NV_LIBCUBLAS_PACKAGE -x NV_LIBCUBLAS_PACKAGE_NAME -x NV_LIBCUBLAS_VERSION -x NV_LIBCUSPARSE_DEV_VERSION -x NV_LIBCUSPARSE_VERSION -x NV_LIBNCCL_DEV_PACKAGE -x NV_LIBNCCL_DEV_PACKAGE_NAME -x NV_LIBNCCL_DEV_PACKAGE_VERSION -x NV_LIBNCCL_PACKAGE -x NV_LIBNCCL_PACKAGE_NAME -x NV_LIBNCCL_PACKAGE_VERSION -x NV_LIB\r\nNPP_DEV_PACKAGE -x NV_LIBNPP_DEV_VERSION -x NV_LIBNPP_PACKAGE -x NV_LIBNPP_VERSION -x NV_NVML_DEV_VERSION -x NV_NVPROF_DEV_PACKAGE -x NV_NVPROF_VERSION -x NV_NVTX_VERSION -x PATH -x TERM  python3 /newton/tensorflow2_keras_mnist.py\r\n[1,2]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,3]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,1]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,0]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,4]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,5]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,6]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,7]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,1]<stdout>:11493376/11490434 [==============================] - 1s 0us/step]<stdout>:  892928/11490434 [=>............................] - ETA: 4s[1,5]<stdout>:\r\n[1,1]<stdout>:11501568/11490434 [==============================] - 1s 0us/step\r\n[1,4]<stdout>:11493376/11490434 [==============================] - 1s 0us/step]<stdout>:\r\n[1,4]<stdout>:11501568/11490434 [==============================] - 1s 0us/step\r\n[1,3]<stdout>:11493376/11490434 [==============================] - 1s 0us/step\r\n[1,3]<stdout>:11501568/11490434 [==============================] - 1s 0us/step\r\n[1,2]<stdout>:11493376/11490434 [==============================] - 1s 0us/step\r\n[1,2]<stdout>:11501568/11490434 [==============================] - 1s 0us/step\r\n[1,6]<stdout>:11493376/11490434 [==============================] - 1s 0us/step\r\n[1,6]<stdout>:11501568/11490434 [==============================] - 1s 0us/step\r\n[1,5]<stdout>:11493376/11490434 [==============================] - 1s 0us/step]<stdout>:\r\n[1,5]<stdout>:11501568/11490434 [==============================] - 1s 0us/step\r\n[1,7]<stdout>:11493376/11490434 [==============================] - 1s 0us/step]<stdout>:\r\n11501568/11490434 [==============================] - 1s 0us/step\r\n[1,0]<stdout>:11493376/11490434 [==============================] - 1s 0us/step]<stdout>:\r\n[1,0]<stdout>:11501568/11490434 [==============================] - 1s 0us/step\r\n[1,1]<stderr>:2022-09-19 17:29:30.832621: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n[1,1]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[1,3]<stderr>:2022-09-19 17:29:30.873262: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n[1,3]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[1,4]<stderr>:2022-09-19 17:29:30.873449: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n[1,4]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[1,2]<stderr>:2022-09-19 17:29:30.883842: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n[1,2]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[1,6]<stderr>:2022-09-19 17:29:30.883811: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n[1,6]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[1,5]<stderr>:2022-09-19 17:29:30.897496: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n[1,5]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[1,7]<stderr>:2022-09-19 17:29:30.917004: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n[1,7]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[1,0]<stderr>:2022-09-19 17:29:30.987564: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n[1,0]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[1,1]<stderr>:2022-09-19 17:29:31.902098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78856 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:65:00.0, compute capability: 8.0\r\n[1,3]<stderr>:2022-09-19 17:29:31.956171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78856 MB memory:  -> device: 3, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:e3:00.0, compute capability: 8.0\r\n[1,4]<stderr>:2022-09-19 17:29:31.951832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78856 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:4b:00.0, compute capability: 8.0\r\n[1,2]<stderr>:2022-09-19 17:29:31.963408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78856 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:ca:00.0, compute capability: 8.0\r\n[1,6]<stderr>:2022-09-19 17:29:31.970834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78856 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:ca:00.0, compute capability: 8.0\r\n[1,0]<stderr>:2022-09-19 17:29:31.989271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78856 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:4b:00.0, compute capability: 8.0\r\n[1,7]<stderr>:2022-09-19 17:29:32.010417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78856 MB memory:  -> device: 3, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:e3:00.0, compute capability: 8.0\r\n[1,5]<stderr>:2022-09-19 17:29:32.017663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78856 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:65:00.0, compute capability: 8.0\r\n[1,0]<stdout>:Epoch 1/24                                \r\n[1,4]<stderr>:2022-09-19 17:29:34.519693: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n[1,1]<stderr>:2022-09-19 17:29:34.570642: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n[1,2]<stderr>:2022-09-19 17:29:34.627058: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n[1,7]<stderr>:2022-09-19 17:29:34.650686: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n[1,3]<stderr>:2022-09-19 17:29:34.684422: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n[1,0]<stderr>:2022-09-19 17:29:34.694156: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n[1,6]<stderr>:2022-09-19 17:29:34.690960: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n[1,5]<stderr>:2022-09-19 17:29:34.701873: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n[1,4]<stderr>:2022-09-19 17:29:35.413411: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\r\n[1,1]<stderr>:2022-09-19 17:29:35.495313: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\r\n[1,7]<stderr>:2022-09-19 17:29:35.507309: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\r\n[1,2]<stderr>:2022-09-19 17:29:35.528658: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\r\n[1,6]<stderr>:2022-09-19 17:29:35.571000: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\r\n[1,5]<stderr>:2022-09-19 17:29:35.573581: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\r\n[1,0]<stderr>:2022-09-19 17:29:35.601275: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\r\n[1,3]<stderr>:2022-09-19 17:29:35.602406: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\r\n[1,4]<stderr>:2022-09-19 17:29:36.933650: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n[1,7]<stderr>:2022-09-19 17:29:36.982336: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n[1,1]<stderr>:2022-09-19 17:29:37.058221: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n[1,2]<stderr>:2022-09-19 17:29:37.091075: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n[1,5]<stderr>:2022-09-19 17:29:37.104232: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n[1,6]<stderr>:2022-09-19 17:29:37.136724: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n[1,0]<stderr>:2022-09-19 17:29:37.166737: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n[1,3]<stderr>:2022-09-19 17:29:37.173748: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n\r\n```\r\n\r\nI'm so confuse about it.  And how to debug it.\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3704/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3704/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3698", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3698/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3698/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3698/events", "html_url": "https://github.com/horovod/horovod/issues/3698", "id": 1370310355, "node_id": "I_kwDOBfOI785RrUbT", "number": 3698, "title": "reducescatter() and grouped_reducescatter() crash for scalar inputs", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/5", "html_url": "https://github.com/horovod/horovod/milestone/5", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/5/labels", "id": 8403712, "node_id": "MI_kwDOBfOI784AgDsA", "number": 5, "title": "v0.26.0", "description": "All issues and PRs that we want to see in the next release.", "creator": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 7, "state": "closed", "created_at": "2022-09-08T18:35:15Z", "updated_at": "2022-10-13T06:47:31Z", "due_on": null, "closed_at": "2022-10-13T06:47:31Z"}, "comments": 0, "created_at": "2022-09-12T18:00:01Z", "updated_at": "2022-09-20T06:30:14Z", "closed_at": "2022-09-20T06:30:14Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "`hvd.reducescatter(3.14)` currently leads to a C++ assertion failure in debug builds or a segmentation fault in release builds. \r\n\r\nThere should either be a clear error message or it should behave similarly to `hvd.reducescatter([3.14])`, which returns a one-element tensor on the root rank and an empty tensor on the other ranks.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3698/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3698/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3696", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3696/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3696/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3696/events", "html_url": "https://github.com/horovod/horovod/issues/3696", "id": 1368460831, "node_id": "I_kwDOBfOI785RkQ4f", "number": 3696, "title": "Specify MPI compiler, compiler flags, library flags", "user": {"login": "felker", "id": 1410981, "node_id": "MDQ6VXNlcjE0MTA5ODE=", "avatar_url": "https://avatars.githubusercontent.com/u/1410981?v=4", "gravatar_id": "", "url": "https://api.github.com/users/felker", "html_url": "https://github.com/felker", "followers_url": "https://api.github.com/users/felker/followers", "following_url": "https://api.github.com/users/felker/following{/other_user}", "gists_url": "https://api.github.com/users/felker/gists{/gist_id}", "starred_url": "https://api.github.com/users/felker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/felker/subscriptions", "organizations_url": "https://api.github.com/users/felker/orgs", "repos_url": "https://api.github.com/users/felker/repos", "events_url": "https://api.github.com/users/felker/events{/privacy}", "received_events_url": "https://api.github.com/users/felker/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-09-10T02:14:56Z", "updated_at": "2022-09-16T08:46:14Z", "closed_at": "2022-09-16T05:03:05Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow and PyTorch\r\n2. Framework version: TF 2.10.0, PyTorch 1.12.1\r\n3. Horovod version: 0.26\r\n4. MPI version: Cray MPICH 8.1.16\r\n5. CUDA version: 11.6.2\r\n6. NCCL version: 2.14.3\r\n7. Python version: 3.8\r\n8. Spark / PySpark version: N/A\r\n9. Ray version: N/A\r\n10. OS and version: SLES 15.3\r\n11. GCC version: 11.2\r\n12. CMake version: 3.22.1\r\n\r\n\r\n**Bug report:**\r\nI am currently trying to build Horovod from support with NCCL and MPI support. My build command is something along the lines of \r\n```\r\nMPI_ROOT=/opt/cray/pe/mpich/8.1.16/ofi/gnu/9.1 HOROVOD_WITH_MPI=1 HOROVOD_CUDA_HOME=/soft/compilers/cudatoolkit/cuda-11.6.2 HOROVOD_NCCL_HOME=/soft/libraries//nccl/nccl_2.14.3-1+cuda11.6_x86_64 HOROVOD_CMAKE=/soft/datascience/conda/2022-09-08/mconda3/bin/cmake HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITH_PYTORCH=1 HOROVOD_WITHOUT_MXNET=1 python setup.py bdist_wheel\r\n```\r\nFrom what I can decipher from the build process, Horovod never uses `mpicc` but instead uses the underlying wrapped `g++` compiler and adds the MPI library e.g. \r\n```\r\n-- Found MPI_CXX: /opt/cray/pe/mpich/8.1.16/ofi/gnu/9.1/lib/libmpi_gnu_91.so (found version \"3.1\")\r\n-- Found MPI: TRUE (found version \"3.1\")\r\n...\r\n```\r\nThus `/opt/cray/pe/mpich/8.1.16/ofi/gnu/9.1/lib/libmpi_gnu_91.so` added in the link steps. However, Cray MPICH uses wrapper compilers `cc` `CC` and often adds other essential compiler flags and libraries such as `-lmpi_gtl_cuda` for CUDA-Aware MPICH (which I know isnt necessary for Horovod operations, but to build Horovod with it regardless).\r\n\r\nI could not find a way to specify MPI-only compiler flags and/or link flags. What is the easiest way to add this?\r\n\r\nI tried `HOROVOD_BUILD_ARCH_FLAGS='-shared -target-accel=nvidia80'`, but this does not work likely since it is only accepts `gcc` flags: \r\n```\r\n-- Could NOT find MPI_CXX (missing: MPI_CXX_WORKS)\r\n-- Could NOT find MPI (missing: MPI_CXX_FOUND)\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3696/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3696/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3691", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3691/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3691/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3691/events", "html_url": "https://github.com/horovod/horovod/issues/3691", "id": 1367325939, "node_id": "I_kwDOBfOI785Rf7zz", "number": 3691, "title": "NVTabular Docker image does not build", "user": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-09-09T06:00:42Z", "updated_at": "2022-09-15T09:41:56Z", "closed_at": "2022-09-15T09:41:56Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "The `docker/horovod-nvtabular/Dockerfile` Docker image does not build in master any more:\r\nhttps://github.com/horovod/horovod/runs/8261962616?check_suite_focus=true#step:8:2828\r\n```\r\n#27 40.96 Traceback (most recent call last):\r\n#27 40.96   File \"<string>\", line 1, in <module>\r\n#27 40.96   File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/__init__.py\", line 37, in <module>\r\n#27 40.96     from tensorflow.python.tools import module_util as _module_util\r\n#27 40.96   File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py\", line 37, in <module>\r\n#27 40.96     from tensorflow.python.eager import context\r\n#27 40.96   File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\", line 29, in <module>\r\n#27 40.96     from tensorflow.core.framework import function_pb2\r\n#27 40.96   File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/core/framework/function_pb2.py\", line 7, in <module>\r\n#27 40.96     from google.protobuf import descriptor as _descriptor\r\n#27 40.96   File \"/root/miniconda3/lib/python3.8/site-packages/google/protobuf/descriptor.py\", line 40, in <module>\r\n#27 40.96     from google.protobuf.internal import api_implementation\r\n#27 40.96   File \"/root/miniconda3/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py\", line 104, in <module>\r\n#27 40.96     from google.protobuf.pyext import _message\r\n#27 40.96 TypeError: bases must be types\r\n```\r\n\r\nIt is likely that conflicting dependencies break tensorflow (e.g. #3684). Try to compare versions installed earlier when the image used to build with versions now being installed.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3691/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3691/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3672", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3672/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3672/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3672/events", "html_url": "https://github.com/horovod/horovod/issues/3672", "id": 1353019050, "node_id": "I_kwDOBfOI785QpW6q", "number": 3672, "title": "UnicodeDecodeError in horovod ", "user": {"login": "yinciki", "id": 10599627, "node_id": "MDQ6VXNlcjEwNTk5NjI3", "avatar_url": "https://avatars.githubusercontent.com/u/10599627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yinciki", "html_url": "https://github.com/yinciki", "followers_url": "https://api.github.com/users/yinciki/followers", "following_url": "https://api.github.com/users/yinciki/following{/other_user}", "gists_url": "https://api.github.com/users/yinciki/gists{/gist_id}", "starred_url": "https://api.github.com/users/yinciki/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yinciki/subscriptions", "organizations_url": "https://api.github.com/users/yinciki/orgs", "repos_url": "https://api.github.com/users/yinciki/repos", "events_url": "https://api.github.com/users/yinciki/events{/privacy}", "received_events_url": "https://api.github.com/users/yinciki/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-08-27T11:21:08Z", "updated_at": "2022-08-29T17:55:27Z", "closed_at": "2022-08-29T17:55:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.7\r\n3. Horovod version: 0.23\r\n4. MPI version: None\r\n5. CUDA version: 11.4\r\n6. NCCL version: 2.11.4\r\n7. Python version: 3.6.8\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version: \r\n11. GCC version: 8.3.1\r\n12. CMake version: 3.23.3\r\n\r\n\r\n**Bug report:**\r\nWhen I run my model with horovodrun command I found this error:\r\n\r\nException in thread Thread-5:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/local/lib/python3.8/threading.py\", line 870, in run \r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/horovod/runner/common/util/safe_shell_exec.py\", line 126, in prefix_connection\r\n    text = decoder.decode(buf or b'', final=not buf)\r\n  File \"/usr/local/lib/python3.8/codecs.py\", line 322, in decode\r\n    (result, consumed) = self._buffer_decode(data, self.errors, final)\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x8a in position 91: invalid start byte\r\n\r\nFile \"/usr/local/lib/python3.8/site-packages/horovod/runner/common/util/safe_shell_exec.py\", line 126 -- this is mentioned in https://github.com/horovod/horovod/issues/2367 and it is regarded as a solution. \r\n\r\nhow to solve this error?\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3672/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3672/timeline", "performed_via_github_app": null, "state_reason": "not_planned"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3671", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3671/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3671/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3671/events", "html_url": "https://github.com/horovod/horovod/issues/3671", "id": 1353019042, "node_id": "I_kwDOBfOI785QpW6i", "number": 3671, "title": "UnicodeDecodeError in horovod ", "user": {"login": "yinciki", "id": 10599627, "node_id": "MDQ6VXNlcjEwNTk5NjI3", "avatar_url": "https://avatars.githubusercontent.com/u/10599627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yinciki", "html_url": "https://github.com/yinciki", "followers_url": "https://api.github.com/users/yinciki/followers", "following_url": "https://api.github.com/users/yinciki/following{/other_user}", "gists_url": "https://api.github.com/users/yinciki/gists{/gist_id}", "starred_url": "https://api.github.com/users/yinciki/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yinciki/subscriptions", "organizations_url": "https://api.github.com/users/yinciki/orgs", "repos_url": "https://api.github.com/users/yinciki/repos", "events_url": "https://api.github.com/users/yinciki/events{/privacy}", "received_events_url": "https://api.github.com/users/yinciki/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-08-27T11:21:07Z", "updated_at": "2022-08-29T17:55:11Z", "closed_at": "2022-08-29T17:55:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.7\r\n3. Horovod version: 0.23\r\n4. MPI version: None\r\n5. CUDA version: 11.4\r\n6. NCCL version: 11.4\r\n7. Python version: 3.6.8\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version: \r\n11. GCC version: 8.3.1\r\n12. CMake version: 3.23.3\r\n\r\n\r\n**Bug report:**\r\nWhen I run my model with horovodrun command I found this error:\r\n\r\nException in thread Thread-5:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/local/lib/python3.8/threading.py\", line 870, in run \r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/horovod/runner/common/util/safe_shell_exec.py\", line 126, in prefix_connection\r\n    text = decoder.decode(buf or b'', final=not buf)\r\n  File \"/usr/local/lib/python3.8/codecs.py\", line 322, in decode\r\n    (result, consumed) = self._buffer_decode(data, self.errors, final)\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x8a in position 91: invalid start byte\r\n\r\nFile \"/usr/local/lib/python3.8/site-packages/horovod/runner/common/util/safe_shell_exec.py\", line 126 -- this is mentioned in https://github.com/horovod/horovod/issues/2367 and it is regarded as a solution. \r\n\r\nhow to solve this error?\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3671/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3671/timeline", "performed_via_github_app": null, "state_reason": "not_planned"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3670", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3670/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3670/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3670/events", "html_url": "https://github.com/horovod/horovod/issues/3670", "id": 1353019033, "node_id": "I_kwDOBfOI785QpW6Z", "number": 3670, "title": "UnicodeDecodeError in horovod ", "user": {"login": "yinciki", "id": 10599627, "node_id": "MDQ6VXNlcjEwNTk5NjI3", "avatar_url": "https://avatars.githubusercontent.com/u/10599627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yinciki", "html_url": "https://github.com/yinciki", "followers_url": "https://api.github.com/users/yinciki/followers", "following_url": "https://api.github.com/users/yinciki/following{/other_user}", "gists_url": "https://api.github.com/users/yinciki/gists{/gist_id}", "starred_url": "https://api.github.com/users/yinciki/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yinciki/subscriptions", "organizations_url": "https://api.github.com/users/yinciki/orgs", "repos_url": "https://api.github.com/users/yinciki/repos", "events_url": "https://api.github.com/users/yinciki/events{/privacy}", "received_events_url": "https://api.github.com/users/yinciki/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-08-27T11:21:05Z", "updated_at": "2022-08-29T17:54:53Z", "closed_at": "2022-08-29T17:54:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.7\r\n3. Horovod version: 0.23\r\n4. MPI version: None\r\n5. CUDA version: 11.4\r\n6. NCCL version: 11.4\r\n7. Python version: 3.6.8\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version: \r\n11. GCC version: 8.3.1\r\n12. CMake version: 3.23.3\r\n\r\n\r\n**Bug report:**\r\nWhen I run my model with horovodrun command I found this error:\r\n\r\nException in thread Thread-5:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/local/lib/python3.8/threading.py\", line 870, in run \r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/horovod/runner/common/util/safe_shell_exec.py\", line 126, in prefix_connection\r\n    text = decoder.decode(buf or b'', final=not buf)\r\n  File \"/usr/local/lib/python3.8/codecs.py\", line 322, in decode\r\n    (result, consumed) = self._buffer_decode(data, self.errors, final)\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x8a in position 91: invalid start byte\r\n\r\nFile \"/usr/local/lib/python3.8/site-packages/horovod/runner/common/util/safe_shell_exec.py\", line 126 -- this is mentioned in https://github.com/horovod/horovod/issues/2367 and it is regarded as a solution. \r\n\r\nhow to solve this error?\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3670/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3670/timeline", "performed_via_github_app": null, "state_reason": "not_planned"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3650", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3650/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3650/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3650/events", "html_url": "https://github.com/horovod/horovod/issues/3650", "id": 1338676492, "node_id": "I_kwDOBfOI785PypUM", "number": 3650, "title": "Can't pass-in edit_fields for TransformSpec in pytorch_lightning", "user": {"login": "serena-ruan", "id": 82044803, "node_id": "MDQ6VXNlcjgyMDQ0ODAz", "avatar_url": "https://avatars.githubusercontent.com/u/82044803?v=4", "gravatar_id": "", "url": "https://api.github.com/users/serena-ruan", "html_url": "https://github.com/serena-ruan", "followers_url": "https://api.github.com/users/serena-ruan/followers", "following_url": "https://api.github.com/users/serena-ruan/following{/other_user}", "gists_url": "https://api.github.com/users/serena-ruan/gists{/gist_id}", "starred_url": "https://api.github.com/users/serena-ruan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/serena-ruan/subscriptions", "organizations_url": "https://api.github.com/users/serena-ruan/orgs", "repos_url": "https://api.github.com/users/serena-ruan/repos", "events_url": "https://api.github.com/users/serena-ruan/events{/privacy}", "received_events_url": "https://api.github.com/users/serena-ruan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-08-15T08:10:36Z", "updated_at": "2022-08-17T22:09:45Z", "closed_at": "2022-08-17T22:09:45Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) pytorch_lightning\r\n2. Framework version: 1.5.0\r\n3. Horovod version: 0.25.0\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. Spark / PySpark version: 3.2.0\r\n9. Ray version:\r\n10. OS and version:\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nIn PetastormDataModule defined in horovod/spark/lightning/datamodule.py file:\r\n<img width=\"563\" alt=\"image\" src=\"https://user-images.githubusercontent.com/82044803/184599194-fe8b66e6-ca38-4d27-be06-b74235eb9f6c.png\">\r\n\r\nIt only accepts `self.transformation` as a func param into class `TransformSpec`, and this limit means that you could only modify a row and return it with the same key. The ideal design would be that you could pass in all fields that class `TransformSpec` could accept here:\r\n<img width=\"669\" alt=\"image\" src=\"https://user-images.githubusercontent.com/82044803/184599421-aacd91a2-6ff6-4de6-9684-ffd26e946641.png\">\r\nOr at least `edit_fields` because the later two `removed_fields` and `selected_fields` can all be done inside of a function or training steps. So I'm hoping we can expose a param named for example `transform_edit_fields` so that we can add more fields into the schema besides the existing ones.\r\n\r\nAnd I'm happy to contribute to this feature. Pls let me know if this proposal makes sense for you, thanks!\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3650/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3650/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3641", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3641/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3641/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3641/events", "html_url": "https://github.com/horovod/horovod/issues/3641", "id": 1334973239, "node_id": "I_kwDOBfOI785PkhM3", "number": 3641, "title": "CI: tfhead build is broken", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 963944291, "node_id": "MDU6TGFiZWw5NjM5NDQyOTE=", "url": "https://api.github.com/repos/horovod/horovod/labels/upstream%20bug", "name": "upstream bug", "color": "e228dc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-08-10T17:49:35Z", "updated_at": "2022-08-12T12:36:30Z", "closed_at": "2022-08-12T12:36:30Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Seen in https://github.com/horovod/horovod/runs/7771432718?check_suite_focus=true\r\n\r\nAppears to be caused by this TF commit: https://github.com/tensorflow/tensorflow/commit/399e4071c471f6dc47bf245f8aeb8ab0c0374fce\r\n```\r\n2022-08-10T16:38:11.6788601Z #44 157.3   [ 66%] Building CXX object horovod/tensorflow/CMakeFiles/tensorflow.dir/mpi_ops.cc.o\r\n2022-08-10T16:38:11.6792823Z #44 157.3   cd /tmp/pip-req-build-ggufvm1f/build/temp.linux-x86_64-3.8/RelWithDebInfo/horovod/tensorflow && /usr/bin/c++  -DEIGEN_MPL2_ONLY=1 -DHAVE_GLOO=1 -DHAVE_MPI=1 -DTENSORFLOW_VERSION=9999999999 -Dtensorflow_EXPORTS -I/tmp/pip-req-build-ggufvm1f/third_party/HTTPRequest/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/assert/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/config/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/core/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/detail/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/iterator/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/lockfree/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/mpl/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/parameter/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/predef/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/preprocessor/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/static_assert/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/type_traits/include -I/tmp/pip-req-build-ggufvm1f/third_party/boost/utility/include -I/tmp/pip-req-build-ggufvm1f/third_party/lbfgs/include -I/tmp/pip-req-build-ggufvm1f/third_party/gloo -I/tmp/pip-req-build-ggufvm1f/third_party/flatbuffers/include -isystem /usr/local/lib/python3.8/dist-packages/tensorflow/include  -I/usr/local/lib/python3.8/dist-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1 -DEIGEN_MAX_ALIGN_BYTES=64  -pthread -fPIC -Wall -ftree-vectorize -mf16c -mavx -mfma -O3 -g -DNDEBUG -fPIC   -std=c++17 -o CMakeFiles/tensorflow.dir/mpi_ops.cc.o -c /tmp/pip-req-build-ggufvm1f/horovod/tensorflow/mpi_ops.cc\r\n2022-08-10T16:38:11.6795960Z #44 157.4   In file included from /tmp/pip-req-build-ggufvm1f/horovod/common/gloo/../mpi/mpi_context.h:25,\r\n2022-08-10T16:38:11.8295689Z #44 157.4                    from /tmp/pip-req-build-ggufvm1f/horovod/common/gloo/gloo_context.h:25,\r\n2022-08-10T16:38:11.8296650Z #44 157.4                    from /tmp/pip-req-build-ggufvm1f/horovod/common/gloo/gloo_controller.h:19,\r\n2022-08-10T16:38:11.8297220Z #44 157.4                    from /tmp/pip-req-build-ggufvm1f/horovod/common/gloo/gloo_controller.cc:16:\r\n2022-08-10T16:38:11.8298063Z #44 157.4   /tmp/pip-req-build-ggufvm1f/horovod/common/gloo/../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(const short unsigned int*, float*)\u2019:\r\n2022-08-10T16:38:11.8298871Z #44 157.4   /tmp/pip-req-build-ggufvm1f/horovod/common/gloo/../mpi/../half.h:76:11: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n2022-08-10T16:38:11.8299357Z #44 157.4      76 |   *res = *reinterpret_cast<float const*>(&f);\r\n2022-08-10T16:38:11.8299655Z #44 157.4         |           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n2022-08-10T16:38:13.5852575Z #44 159.3   In file included from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/platform/status.h:32,\r\n2022-08-10T16:38:13.7360889Z #44 159.3                    from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/lib/core/status.h:19,\r\n2022-08-10T16:38:13.7361596Z #44 159.3                    from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/framework/resource_base.h:20,\r\n2022-08-10T16:38:13.7362253Z #44 159.3                    from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/framework/resource_handle.h:21,\r\n2022-08-10T16:38:13.7362956Z #44 159.3                    from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/framework/types.h:32,\r\n2022-08-10T16:38:13.7363571Z #44 159.3                    from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/framework/op_def_builder.h:28,\r\n2022-08-10T16:38:13.7364233Z #44 159.3                    from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/framework/full_type_inference_util.h:23,\r\n2022-08-10T16:38:13.7364870Z #44 159.3                    from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/framework/op.h:24,\r\n2022-08-10T16:38:13.7365433Z #44 159.3                    from /tmp/pip-req-build-ggufvm1f/horovod/tensorflow/mpi_ops.cc:34:\r\n2022-08-10T16:38:13.7366144Z #44 159.3   /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/platform/stack_frame.h:19:10: fatal error: tensorflow/tsl/platform/stack_frame.h: No such file or directory\r\n2022-08-10T16:38:13.7366631Z #44 159.3      19 | #include \"tensorflow/tsl/platform/stack_frame.h\"\r\n2022-08-10T16:38:13.7366941Z #44 159.3         |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n2022-08-10T16:38:13.7367206Z #44 159.3   compilation terminated.\r\n2022-08-10T16:38:13.7367601Z #44 159.3   make[2]: *** [horovod/tensorflow/CMakeFiles/tensorflow.dir/build.make:453: horovod/tensorflow/CMakeFiles/tensorflow.dir/mpi_ops.cc.o] Error 1\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3641/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3641/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3611", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3611/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3611/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3611/events", "html_url": "https://github.com/horovod/horovod/issues/3611", "id": 1312235143, "node_id": "I_kwDOBfOI785ONx6H", "number": 3611, "title": "Horovod hangs on nccl/gloo network connection failure", "user": {"login": "MrAta", "id": 3257322, "node_id": "MDQ6VXNlcjMyNTczMjI=", "avatar_url": "https://avatars.githubusercontent.com/u/3257322?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MrAta", "html_url": "https://github.com/MrAta", "followers_url": "https://api.github.com/users/MrAta/followers", "following_url": "https://api.github.com/users/MrAta/following{/other_user}", "gists_url": "https://api.github.com/users/MrAta/gists{/gist_id}", "starred_url": "https://api.github.com/users/MrAta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MrAta/subscriptions", "organizations_url": "https://api.github.com/users/MrAta/orgs", "repos_url": "https://api.github.com/users/MrAta/repos", "events_url": "https://api.github.com/users/MrAta/events{/privacy}", "received_events_url": "https://api.github.com/users/MrAta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-07-21T01:01:50Z", "updated_at": "2022-10-10T12:18:24Z", "closed_at": "2022-07-28T02:47:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.4\r\n3. Horovod version: 0.23\r\n4. MPI version: 4.1.1\r\n5. CUDA version:11.1\r\n6. NCCL version: 2.12.12\r\n7. Python version: 3.7\r\n10. OS and version: RHEL7\r\n11. GCC version: 8.3.1\r\n12. CMake version: 3.10.2\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes.\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? Yes.\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? Yes.\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes.\r\n\r\n**Bug report:**\r\nRunning horovod with nccl on a k8s cluster with 32 Pods each with 6 V100 GPUs, nccl threads halt in `persistentSocketThread` due to failure in performing `recv`:\r\n\r\n```bash\r\n[15]worker-23:83:2526 [0] misc/socket.cc:503 NCCL WARN Net : Call to recv from 100.96.188.199<41468> failed : Connection timed out\r\n[15]worker-23:83:2526 [0] NCCL INFO misc/socket.cc:520 -> 2\r\n[15]23:83:2526 [0] transport/net_socket.cc:219 NCCL WARN NET/Socket : socket progress error\r\n[15]worker-23:83:2520 [0] NCCL INFO include/net.h:32 -> 2\r\n[15]worker-23:83:2520 [0] NCCL INFO transport/net.cc:870 -> 2\r\n[15]worker-23:83:2520 [0] NCCL INFO proxy.cc:494 -> 2\r\n[15]worker-23:83:2520 [0] NCCL INFO proxy.cc:614 -> 2 [Proxy Thread]\r\n```\r\nAll of the ranks have this stack trace:\r\n```bash\r\n#0  0x00007f7a2620c965 in pthread_cond_wait@@GLIBC_2.3.2 () from /usr/lib64/libpthread.so.0\r\n#1  0x00007f795f0e179b in persistentSocketThread (args_=0x7f61ac040c10) at transport/net_socket.cc:231\r\n#2  0x00007f7a26208dd5 in start_thread () from /usr/lib64/libpthread.so.0\r\n#3  0x00007f7a25828ead in clone () from /usr/lib64/libc.so.6\r\n```\r\n\r\nSome horovod threads are also waiting for GPU events:\r\n```bash\r\n#0  0x00007f7a2580dd47 in sched_yield () from /usr/lib64/libc.so.6\r\n#1  0x00007f795f07b8a2 in __gthread_yield () at /opt/rh/devtoolset-8/root/usr/include/c++/8/x86_64-redhat-linux/bits/gthr-default.h:692\r\n#2  std::this_thread::yield () at /opt/rh/devtoolset-8/root/usr/include/c++/8/thread:357\r\n#3  horovod::common::GPUContext::impl::WaitForEvents(std::queue<std::pair<std::string, horovod::common::Event>, std::deque<std::pair<std::string, horovod::common::Event>, std::allocator<std::pair<std::string, horovod::common::Event> > > >&, std::vector<horovod::common::TensorTableEntry, std::allocator<horovod::common::TensorTableEntry> > const&, horovod::common::Timeline&, std::function<void ()> const&, bool) (this=0x54baeb0, event_queue=std::queue wrapping: std::deque with 0 elements, entries=std::vector of length 80, capacity 80 = {...}, timeline=..., error_check_callback=..., elastic=true) at /horovod/horovod/common/ops/cuda_operations.cc:131\r\n#4  0x00007f795f07a220 in horovod::common::GPUContext::WaitForEvents(std::queue<std::pair<std::string, horovod::common::Event>, std::deque<std::pair<std::string, horovod::common::Event>, std::allocator<std::pair<std::string, horovod::common::Event> > > >&, std::vector<horovod::common::TensorTableEntry, std::allocator<horovod::common::TensorTableEntry> > const&, horovod::common::Timeline&, std::function<void ()> const&, bool) (this=<optimized out>, event_queue=..., entries=std::vector of length 80, capacity 80 = {...}, timeline=..., error_check_callback=..., elastic=<optimized out>) at /horovod/horovod/common/ops/gpu_context_impl.cc:27\r\n#5  0x00007f795f07c3fc in horovod::common::GPUOpContext::<lambda()>::operator() (__closure=0x7f61a8000d00) at /horovod/horovod/common/ops/gpu_operations.cc:80\r\n#6  std::_Function_handler<void(), horovod::common::GPUOpContext::FinalizeGPUQueue(std::vector<horovod::common::TensorTableEntry>&, bool, const std::function<void()>&)::<lambda()> >::_M_invoke(const std::_Any_data &) (__functor=...) at /opt/rh/devtoolset-8/root/usr/include/c++/8/bits/std_function.h:297\r\n#7  0x00007f795f03b72f in std::function<void ()>::operator()() const (this=0x7f795d739ea0) at /opt/rh/devtoolset-8/root/usr/include/c++/8/bits/std_function.h:260\r\n#8  horovod::common::ThreadPool::loop (this=0x7f7961816258 <horovod::common::(anonymous namespace)::gpu_context+24>) at /horovod/horovod/common/thread_pool.cc:62\r\n#9  0x00007f79fc36278f in execute_native_thread_routine () from /opt/code-fetcher-system/tf-benchmark-azkaban_2d680d557648cbf50c785ee0639c5d54f5335585ecb5e8b7696a52c4db0d76b8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#10 0x00007f7a26208dd5 in start_thread () from /usr/lib64/libpthread.so.0\r\n#11 0x00007f7a25828ead in clone () from /usr/lib64/libc.so.6\r\n```\r\nBecause of the same connection issue, gloo threads are also facing a deadlock:\r\n```bash\r\n#0  0x00007f7a2620cd12 in pthread_cond_timedwait@@GLIBC_2.3.2 () from /usr/lib64/libpthread.so.0\r\n#1  0x00007f795f1682f9 in __gthread_cond_timedwait (__abs_timeout=0x7f795ef3bee0, __mutex=<optimized out>, __cond=0x7f79584f2460) at /opt/rh/devtoolset-8/root/usr/include/c++/8/x86_64-redhat-linux/bits/gthr-default.h:871\r\n#2  std::condition_variable::__wait_until_impl<std::chrono::duration<long, std::ratio<1l, 1000000000l> > > (__atime=..., __lock=..., this=0x7f79584f2460) at /opt/rh/devtoolset-8/root/usr/include/c++/8/condition_variable:178\r\n#3  std::condition_variable::wait_until<std::chrono::duration<long, std::ratio<1l, 1000000000l> > > (__atime=..., __lock=..., this=0x7f79584f2460) at /opt/rh/devtoolset-8/root/usr/include/c++/8/condition_variable:106\r\n#4  std::condition_variable::wait_until<std::chrono::_V2::system_clock, std::chrono::duration<long int, std::ratio<1, 1000000000> >, gloo::transport::tcp::UnboundBuffer::waitRecv(int*, std::chrono::milliseconds)::<lambda()> > (__p=..., __atime=..., __lock=..., this=0x7f79584f2460) at /opt/rh/devtoolset-8/root/usr/include/c++/8/condition_variable:129\r\n#5  std::condition_variable::wait_for<long int, std::ratio<1, 1000>, gloo::transport::tcp::UnboundBuffer::waitRecv(int*, std::chrono::milliseconds)::<lambda()> > (__p=..., __rtime=<synthetic pointer>..., __lock=..., this=0x7f79584f2460) at /opt/rh/devtoolset-8/root/usr/include/c++/8/condition_variable:156\r\n#6  gloo::transport::tcp::UnboundBuffer::waitRecv (this=0x7f79584f2410, rank=0x0, timeout=...) at /horovod/third_party/compatible_gloo/gloo/transport/tcp/unbound_buffer.cc:61\r\n#7  0x00007f795f1400ec in gloo::transport::UnboundBuffer::waitRecv (timeout=..., this=<optimized out>) at /horovod/third_party/gloo/gloo/transport/unbound_buffer.h:76\r\n#8  gloo::(anonymous namespace)::ring (opts=..., reduceInputs=..., broadcastOutputs=...) at /horovod/third_party/compatible_gloo/gloo/allreduce.cc:366\r\n#9  0x00007f795f141623 in gloo::(anonymous namespace)::allreduce (opts=...) at /opt/rh/devtoolset-8/root/usr/include/c++/8/bits/std_function.h:260\r\n#10 0x00007f795f09469f in horovod::common::GlooController::CrossRankBitwiseAnd (this=<optimized out>, bitvector=..., count=<optimized out>) at /horovod/horovod/common/gloo/gloo_controller.cc:122\r\n#11 0x00007f795f03594a in horovod::common::CacheCoordinator::sync (this=this@entry=0x7f795ef3c7f0, controller=std::shared_ptr<horovod::common::Controller> (use count 3, weak count 1) = {...}, timeline_enabled=<optimized out>) at /horovod/horovod/common/response_cache.cc:425\r\n#12 0x00007f795eff9f07 in horovod::common::Controller::CoordinateCacheAndState (this=0x5546b20, cache_coordinator=...) at /opt/rh/devtoolset-8/root/usr/include/c++/8/bits/shared_ptr_base.h:246\r\n#13 0x00007f795effe37d in horovod::common::Controller::ComputeResponseList (this=0x5546b20, this_process_requested_shutdown=this_process_requested_shutdown@entry=false, state=..., process_set=...) at /horovod/horovod/common/controller.cc:158\r\n#14 0x00007f795f01d55e in horovod::common::(anonymous namespace)::RunLoopOnce (state=...) at /horovod/horovod/common/operations.cc:778\r\n#15 horovod::common::(anonymous namespace)::BackgroundThreadLoop (state=...) at /horovod/horovod/common/operations.cc:660\r\n#16 0x00007f79fc36278f in execute_native_thread_routine () from /opt/code-fetcher-system/tf-benchmark-azkaban_2d680d557648cbf50c785ee0639c5d54f5335585ecb5e8b7696a52c4db0d76b8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#17 0x00007f7a26208dd5 in start_thread () from /usr/lib64/libpthread.so.0\r\n#18 0x00007f7a25828ead in clone () from /usr/lib64/libc.so.6\r\n```\r\nand\r\n```bash\r\n#0  0x00007f7a25829483 in epoll_wait () from /usr/lib64/libc.so.6\r\n#1  0x00007f795f152a3b in gloo::transport::tcp::Loop::run (this=0x7f7958000a00) at /horovod/third_party/compatible_gloo/gloo/transport/tcp/loop.cc:72\r\n#2  0x00007f79fc36278f in execute_native_thread_routine () from /opt/code-fetcher-system/tf-benchmark-azkaban_2d680d557648cbf50c785ee0639c5d54f5335585ecb5e8b7696a52c4db0d76b8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#3  0x00007f7a26208dd5 in start_thread () from /usr/lib64/libpthread.so.0\r\n#4  0x00007f7a25828ead in clone () from /usr/lib64/libc.so.6\r\n```\r\n\r\nThis is while the GPU utilization and GPU memory utilization stays nearly at 100% while no training is going on:\r\n```bash\r\n$ nvidia-smi\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-PCIE...  On   | 00000000:3B:00.0 Off |                    0 |\r\n| N/A   48C    P0    47W / 250W |  30765MiB / 32510MiB |    100%   E. Process |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla V100-PCIE...  On   | 00000000:60:00.0 Off |                    0 |\r\n| N/A   38C    P0    40W / 250W |  30789MiB / 32510MiB |    100%   E. Process |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla V100-PCIE...  On   | 00000000:61:00.0 Off |                    0 |\r\n| N/A   40C    P0    41W / 250W |  30789MiB / 32510MiB |    100%   E. Process |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla V100-PCIE...  On   | 00000000:86:00.0 Off |                    0 |\r\n| N/A   52C    P0    43W / 250W |  30765MiB / 32510MiB |    100%   E. Process |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  Tesla V100-PCIE...  On   | 00000000:DA:00.0 Off |                    0 |\r\n| N/A   42C    P0    43W / 250W |  30789MiB / 32510MiB |    100%   E. Process |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  Tesla V100-PCIE...  On   | 00000000:DB:00.0 Off |                    0 |\r\n| N/A   45C    P0    43W / 250W |  30789MiB / 32510MiB |    100%   E. Process |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n```\r\n\r\nThis is pretty much similar to [nccl #193](https://github.com/NVIDIA/nccl/issues/193) where the nccl authors believe that if NCCL returns an error, it's the job of the frameworks on top to abort the process.\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3611/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3611/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3606", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3606/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3606/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3606/events", "html_url": "https://github.com/horovod/horovod/issues/3606", "id": 1306731143, "node_id": "I_kwDOBfOI785N4yKH", "number": 3606, "title": "torch.utils.ffi was removed but is still used in horovod", "user": {"login": "adamjstewart", "id": 12021217, "node_id": "MDQ6VXNlcjEyMDIxMjE3", "avatar_url": "https://avatars.githubusercontent.com/u/12021217?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adamjstewart", "html_url": "https://github.com/adamjstewart", "followers_url": "https://api.github.com/users/adamjstewart/followers", "following_url": "https://api.github.com/users/adamjstewart/following{/other_user}", "gists_url": "https://api.github.com/users/adamjstewart/gists{/gist_id}", "starred_url": "https://api.github.com/users/adamjstewart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adamjstewart/subscriptions", "organizations_url": "https://api.github.com/users/adamjstewart/orgs", "repos_url": "https://api.github.com/users/adamjstewart/repos", "events_url": "https://api.github.com/users/adamjstewart/events{/privacy}", "received_events_url": "https://api.github.com/users/adamjstewart/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-07-16T07:08:51Z", "updated_at": "2022-08-11T07:09:57Z", "closed_at": "2022-08-11T07:09:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.12.0\r\n3. Horovod version: 0.25.0\r\n4. MPI version: OpenMPI 4.1.4\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.9.13\r\n8. Spark / PySpark version: N/A\r\n9. Ray version: N/A\r\n10. OS and version: macOS 12.4\r\n11. GCC version: Apple Clang 13.1.6\r\n12. CMake version: 3.23.1\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nIn `torch/mpi_lib/__init__.py` and `torch/mpi_lib_impl/__init__.py`, horovod imports `torch.utils.ffi`. But this module was deprecated in PyTorch 1.0 (https://github.com/pytorch/pytorch/pull/12122) almost 5 years ago and finally removed completely in PyTorch 1.12.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3606/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3606/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3605", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3605/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3605/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3605/events", "html_url": "https://github.com/horovod/horovod/issues/3605", "id": 1306726809, "node_id": "I_kwDOBfOI785N4xGZ", "number": 3605, "title": "aarch64 build requires newer eigen", "user": {"login": "adamjstewart", "id": 12021217, "node_id": "MDQ6VXNlcjEyMDIxMjE3", "avatar_url": "https://avatars.githubusercontent.com/u/12021217?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adamjstewart", "html_url": "https://github.com/adamjstewart", "followers_url": "https://api.github.com/users/adamjstewart/followers", "following_url": "https://api.github.com/users/adamjstewart/following{/other_user}", "gists_url": "https://api.github.com/users/adamjstewart/gists{/gist_id}", "starred_url": "https://api.github.com/users/adamjstewart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adamjstewart/subscriptions", "organizations_url": "https://api.github.com/users/adamjstewart/orgs", "repos_url": "https://api.github.com/users/adamjstewart/repos", "events_url": "https://api.github.com/users/adamjstewart/events{/privacy}", "received_events_url": "https://api.github.com/users/adamjstewart/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-07-16T06:44:26Z", "updated_at": "2022-07-26T08:10:59Z", "closed_at": "2022-07-26T08:10:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.12.0\r\n3. Horovod version: 0.25.0\r\n4. MPI version: OpenMPI 4.1.4\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.9.13\r\n8. Spark / PySpark version: N/A\r\n9. Ray version: N/A\r\n10. OS and version: macOS 12.4\r\n11. GCC version: Apple Clang 13.1.6\r\n12. CMake version: 3.23.1\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nCompiling horovod on aarch64 (e.g., Apple M1) fails with the current version of eigen, eigen needs the following patch to build properly: https://gitlab.com/libeigen/eigen/-/commit/fd1dcb6b45a2c797ad4c4d6cc7678ee70763b4ed\r\n\r\nThis raises two questions:\r\n\r\n1. Can we bump the vendored copy of eigen to a newer version?\r\n2. More importantly, would it be possible to build against external installations of eigen?\r\n\r\nPackage managers like [Spack](https://spack.io) include build recipes for many libraries, including eigen. These packages build fine on aarch64, and often receive bugfix patches like this. We try to avoid using vendored copies of dependencies because you can end up with different versions of eigen in a single build DAG. These vendored copies often quickly become out of date and you end up with issues like this.\r\n\r\nFixed in Spack by applying the needed patch: https://github.com/spack/spack/pull/29310", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3605/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3605/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3589", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3589/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3589/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3589/events", "html_url": "https://github.com/horovod/horovod/issues/3589", "id": 1287979639, "node_id": "I_kwDOBfOI785MxQJ3", "number": 3589, "title": "Can not run `RayExecutor`", "user": {"login": "JiahaoYao", "id": 20907377, "node_id": "MDQ6VXNlcjIwOTA3Mzc3", "avatar_url": "https://avatars.githubusercontent.com/u/20907377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JiahaoYao", "html_url": "https://github.com/JiahaoYao", "followers_url": "https://api.github.com/users/JiahaoYao/followers", "following_url": "https://api.github.com/users/JiahaoYao/following{/other_user}", "gists_url": "https://api.github.com/users/JiahaoYao/gists{/gist_id}", "starred_url": "https://api.github.com/users/JiahaoYao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JiahaoYao/subscriptions", "organizations_url": "https://api.github.com/users/JiahaoYao/orgs", "repos_url": "https://api.github.com/users/JiahaoYao/repos", "events_url": "https://api.github.com/users/JiahaoYao/events{/privacy}", "received_events_url": "https://api.github.com/users/JiahaoYao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-06-28T22:41:00Z", "updated_at": "2022-06-29T20:48:37Z", "closed_at": "2022-06-29T20:48:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "Code: \r\n\r\n```python\r\nimport ray\r\nfrom horovod.ray import RayExecutor\r\nimport horovod.torch as hvd\r\n\r\n# Start the Ray cluster or attach to an existing Ray cluster\r\nray.init()\r\nnum_workers = 1\r\n\r\n# Start num_workers actors on the cluster\r\nsettings = RayExecutor.create_settings(timeout_s=30)\r\nexecutor = RayExecutor(\r\n    settings, num_workers=num_workers,cpus_per_worker=1, use_gpu=True)\r\n\r\n# This will launch `num_workers` actors on the Ray Cluster.\r\nexecutor.start()\r\n\r\n# Using the stateless `run` method, a function can take in any args or kwargs\r\ndef simple_fn():\r\n    hvd.init()\r\n    print(\"hvd rank\", hvd.rank())\r\n    return hvd.rank()\r\n\r\n# Execute the function on all workers at once\r\nresult = executor.run(simple_fn)\r\nprint(result)\r\nexecutor.shutdown()\r\n```\r\n\r\nResult: \r\n```python\r\n2022-06-28 22:05:33,656 INFO services.py:1477 -- View the Ray dashboard at http://127.0.0.1:8266\r\n(BaseHorovodWorker pid=14896) *** SIGSEGV received at time=1656453935 on cpu 0 ***\r\n(BaseHorovodWorker pid=14896) PC: @     0x7f80eff99fcc  (unknown)  horovod::common::(anonymous namespace)::BackgroundThreadLoop()\r\n(BaseHorovodWorker pid=14896)     @     0x7f833f117980       4560  (unknown)\r\n(BaseHorovodWorker pid=14896)     @     0x7f833cbffaa3         24  execute_native_thread_routine\r\n(BaseHorovodWorker pid=14896)     @ ... and at least 4 more frames\r\n(BaseHorovodWorker pid=14896) [2022-06-28 22:05:35,709 E 14896 14934] logging.cc:325: *** SIGSEGV received at time=1656453935 on cpu 0 ***\r\n(BaseHorovodWorker pid=14896) [2022-06-28 22:05:35,709 E 14896 14934] logging.cc:325: PC: @     0x7f80eff99fcc  (unknown)  horovod::common::(anonymous namespace)::BackgroundThreadLoop()\r\n(BaseHorovodWorker pid=14896) [2022-06-28 22:05:35,710 E 14896 14934] logging.cc:325:     @     0x7f833f117980       4560  (unknown)\r\n(BaseHorovodWorker pid=14896) [2022-06-28 22:05:35,710 E 14896 14934] logging.cc:325:     @     0x7f833cbffaa3         24  execute_native_thread_routine\r\n(BaseHorovodWorker pid=14896) [2022-06-28 22:05:35,710 E 14896 14934] logging.cc:325:     @ ... and at least 4 more frames\r\n(BaseHorovodWorker pid=14896) Fatal Python error: Segmentation fault\r\n(BaseHorovodWorker pid=14896) \r\n2022-06-28 22:05:35,839 WARNING worker.py:1728 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff192c4de9ae2ac15aafc2ab1801000000 Worker ID: 64a4d8791c417ee4cc7d4ea3473dcb4fa6303705700c01ddc8bfd3fa Node ID: 78571af15b4fb6c918265637b8618542b59fd3c7f493a81a0b6b7569 Worker IP address: 10.0.2.180 Worker port: 33549 Worker PID: 14896 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\r\nTraceback (most recent call last):\r\n  File \"test_0628.py\", line 25, in <module>\r\n    result = executor.run(simple_fn)\r\n  File \"/home/ubuntu/anaconda3/envs/hd/lib/python3.8/site-packages/horovod/ray/runner.py\", line 376, in run\r\n    return self._maybe_call_ray(self.adapter.run, **kwargs_)\r\n  File \"/home/ubuntu/anaconda3/envs/hd/lib/python3.8/site-packages/horovod/ray/runner.py\", line 421, in _maybe_call_ray\r\n    return driver_func(**kwargs)\r\n  File \"/home/ubuntu/anaconda3/envs/hd/lib/python3.8/site-packages/horovod/ray/runner.py\", line 599, in run\r\n    return ray.get(self._run_remote(fn=f))\r\n  File \"/home/ubuntu/anaconda3/envs/hd/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/envs/hd/lib/python3.8/site-packages/ray/_private/worker.py\", line 2176, in get\r\n    raise value\r\nray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\r\n        class_name: BaseHorovodWorker\r\n        actor_id: 192c4de9ae2ac15aafc2ab1801000000\r\n        pid: 14896\r\n        namespace: acb48abc-7432-420d-923f-2d19a510800c\r\n        ip: 10.0.2.180\r\nThe actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\r\nNone\r\nException ignored in: <function ActorHandle.__del__ at 0x7f93cce2ef70>\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/anaconda3/envs/hd/lib/python3.8/site-packages/ray/actor.py\", line 1029, in __del__\r\nAttributeError: 'NoneType' object has no attribute 'worker'\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3589/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3589/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3587", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3587/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3587/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3587/events", "html_url": "https://github.com/horovod/horovod/issues/3587", "id": 1287198037, "node_id": "I_kwDOBfOI785MuRVV", "number": 3587, "title": "Installation fails with PyTorch on Mac M1", "user": {"login": "MatthiasLeimeisterSonos", "id": 105651002, "node_id": "U_kgDOBkwbOg", "avatar_url": "https://avatars.githubusercontent.com/u/105651002?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MatthiasLeimeisterSonos", "html_url": "https://github.com/MatthiasLeimeisterSonos", "followers_url": "https://api.github.com/users/MatthiasLeimeisterSonos/followers", "following_url": "https://api.github.com/users/MatthiasLeimeisterSonos/following{/other_user}", "gists_url": "https://api.github.com/users/MatthiasLeimeisterSonos/gists{/gist_id}", "starred_url": "https://api.github.com/users/MatthiasLeimeisterSonos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MatthiasLeimeisterSonos/subscriptions", "organizations_url": "https://api.github.com/users/MatthiasLeimeisterSonos/orgs", "repos_url": "https://api.github.com/users/MatthiasLeimeisterSonos/repos", "events_url": "https://api.github.com/users/MatthiasLeimeisterSonos/events{/privacy}", "received_events_url": "https://api.github.com/users/MatthiasLeimeisterSonos/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-06-28T11:26:22Z", "updated_at": "2022-07-28T15:25:05Z", "closed_at": "2022-07-26T08:11:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) PyTorch\r\n2. Framework version: 1.11.0\r\n3. Horovod version: 0.25.0\r\n4. MPI version: 4.1.4\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.9\r\n8. Spark / PySpark version: N/A\r\n9. Ray version: N/A\r\n10. OS and version: OS X 12.4, Mac M1 Pro\r\n11. GCC version: clang 13.1.6\r\n12. CMake version: 3.23.1\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\n\r\nHi, when trying to install Horovod via Pip using the command\r\n\r\n```\r\nHOROVOD_WITH_PYTORCH=1 HOROVOD_WITHOUT_TENSORFLOW=1 HOROVOD_WITHOUT_MXNET=1 pip install horovod --no-cache-dir\r\n```\r\n\r\nthe installation fails with a linker error due to duplicate symbols:\r\n\r\n```\r\nCollecting horovod\r\n  Downloading horovod-0.25.0.tar.gz (3.4 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.4 MB 3.1 MB/s \r\nRequirement already satisfied: cloudpickle in ./anaconda3/lib/python3.9/site-packages (from horovod) (2.0.0)\r\nRequirement already satisfied: psutil in ./anaconda3/lib/python3.9/site-packages (from horovod) (5.8.0)\r\nRequirement already satisfied: pyyaml in ./anaconda3/lib/python3.9/site-packages (from horovod) (6.0)\r\nRequirement already satisfied: cffi>=1.4.0 in ./anaconda3/lib/python3.9/site-packages (from horovod) (1.15.0)\r\nRequirement already satisfied: pycparser in ./anaconda3/lib/python3.9/site-packages (from cffi>=1.4.0->horovod) (2.21)\r\nBuilding wheels for collected packages: horovod\r\n  Building wheel for horovod (setup.py) ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: /Users/mleimeister/anaconda3/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/cg/8x25dwnn2xx6b7bbw8kw973w0000gq/T/pip-install-2qg__ipb/horovod_cd0910fb8cf942ebbc6c7e3e0a0a9b78/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/cg/8x25dwnn2xx6b7bbw8kw973w0000gq/T/pip-install-2qg__ipb/horovod_cd0910fb8cf942ebbc6c7e3e0a0a9b78/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/cg/8x25dwnn2xx6b7bbw8kw973w0000gq/T/pip-wheel-q1skcjy3\r\n       cwd: /private/var/folders/cg/8x25dwnn2xx6b7bbw8kw973w0000gq/T/pip-install-2qg__ipb/horovod_cd0910fb8cf942ebbc6c7e3e0a0a9b78/\r\n\r\n[...]\r\n\r\nRunning CMake in build/temp.macosx-11.1-arm64-3.9/RelWithDebInfo:\r\n  cmake /private/var/folders/cg/8x25dwnn2xx6b7bbw8kw973w0000gq/T/pip-install-2qg__ipb/horovod_cd0910fb8cf942ebbc6c7e3e0a0a9b78 -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/private/var/folders/cg/8x25dwnn2xx6b7bbw8kw973w0000gq/T/pip-install-2qg__ipb/horovod_cd0910fb8cf942ebbc6c7e3e0a0a9b78/build/lib.macosx-11.1-arm64-3.9 -DPYTHON_EXECUTABLE:FILEPATH=/Users/mleimeister/anaconda3/bin/python\r\n  cmake --build . --config RelWithDebInfo -- -j8 VERBOSE=1\r\n  -- Could not find CCache. Consider installing CCache to speed up compilation.\r\n  -- The CXX compiler identification is AppleClang 13.1.6.13160021\r\n  -- Detecting CXX compiler ABI info\r\n  -- Detecting CXX compiler ABI info - done\r\n  -- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++ - skipped\r\n  -- Detecting CXX compile features\r\n  -- Detecting CXX compile features - done\r\n  -- Build architecture flags:\r\n  -- Using command /Users/mleimeister/anaconda3/bin/python\r\n  -- Found MPI_CXX: /opt/homebrew/Cellar/open-mpi/4.1.4/lib/libmpi.dylib (found version \"3.1\")\r\n  -- Found MPI: TRUE (found version \"3.1\")\r\n  -- Looking for a CUDA compiler\r\n  -- Looking for a CUDA compiler - NOTFOUND\r\n  -- Looking for a CUDA host compiler - /Library/Developer/CommandLineTools/usr/bin/c++\r\n  -- Could not find nvcc, please set CUDAToolkit_ROOT.\r\n  -- Could NOT find NVTX (missing: NVTX_INCLUDE_DIR)\r\n  -- The C compiler identification is AppleClang 13.1.6.13160021\r\n  -- Detecting C compiler ABI info\r\n  -- Detecting C compiler ABI info - done\r\n  -- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc - skipped\r\n  -- Detecting C compile features\r\n  -- Detecting C compile features - done\r\n  -- Gloo build as STATIC library\r\n  -- Found PkgConfig: /opt/homebrew/bin/pkg-config (found version \"0.29.2\")\r\n  -- Checking for one of the modules 'libuv>=1.26'\r\n  -- Found MPI_C: /opt/homebrew/Cellar/open-mpi/4.1.4/lib/libmpi.dylib (found version \"3.1\")\r\n  -- Found MPI: TRUE (found version \"3.1\")\r\n  -- MPI include path: /opt/homebrew/Cellar/open-mpi/4.1.4/include\r\n  -- MPI libraries: /opt/homebrew/Cellar/open-mpi/4.1.4/lib/libmpi.dylib\r\n  -- Found Pytorch: 1.11.0 (found suitable version \"1.11.0\", minimum required is \"1.5.0\")\r\n  -- Gloo build as STATIC library\r\n  -- MPI include path: /opt/homebrew/Cellar/open-mpi/4.1.4/include\r\n  -- MPI libraries: /opt/homebrew/Cellar/open-mpi/4.1.4/lib/libmpi.dylib\r\n  -- Configuring done\r\n  -- Generating done\r\n\r\n[...]\r\n\r\n7 warnings generated.\r\n  [100%] Linking CXX shared library ../../../../lib.macosx-11.1-arm64-3.9/horovod/torch/mpi_lib_v2.cpython-39-darwin.so\r\n  cd /private/var/folders/cg/8x25dwnn2xx6b7bbw8kw973w0000gq/T/pip-install-2qg__ipb/horovod_cd0910fb8cf942ebbc6c7e3e0a0a9b78/build/temp.macosx-11.1-arm64-3.9/RelWithDebInfo/horovod/torch && /opt/homebrew/Cellar/cmake/3.23.1_1/bin/cmake -E cmake_link_script CMakeFiles/pytorch.dir/link.txt --verbose=1\r\n  /Library/Developer/CommandLineTools/usr/bin/c++  -D_GLIBCXX_USE_CXX11_ABI=0  -pthread -fPIC -Wall -ftree-vectorize  -O3 -g -DNDEBUG -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX12.3.sdk -dynamiclib -Wl,-headerpad_max_install_names  -undefined dynamic_lookup -Wl,-exported_symbols_list,/private/var/folders/cg/8x25dwnn2xx6b7bbw8kw973w0000gq/T/pip-install-2qg__ipb/horovod_cd0910fb8cf942ebbc6c7e3e0a0a9b78/horovod.exp -o ../../../../lib.macosx-11.1-arm64-3.9/horovod/torch/mpi_lib_v2.cpython-39-darwin.so -install_name @rpath/mpi_lib_v2.cpython-39-darwin.so CMakeFiles/pytorch.dir/__/common/common.cc.o CMakeFiles/pytorch.dir/__/common/controller.cc.o CMakeFiles/pytorch.dir/__/common/fusion_buffer_manager.cc.o CMakeFiles/pytorch.dir/__/common/group_table.cc.o CMakeFiles/pytorch.dir/__/common/half.cc.o CMakeFiles/pytorch.dir/__/common/logging.cc.o CMakeFiles/pytorch.dir/__/common/message.cc.o CMakeFiles/pytorch.dir/__/common/operations.cc.o CMakeFiles/pytorch.dir/__/common/parameter_manager.cc.o CMakeFiles/pytorch.dir/__/common/process_set.cc.o CMakeFiles/pytorch.dir/__/common/response_cache.cc.o CMakeFiles/pytorch.dir/__/common/stall_inspector.cc.o CMakeFiles/pytorch.dir/__/common/thread_pool.cc.o CMakeFiles/pytorch.dir/__/common/timeline.cc.o CMakeFiles/pytorch.dir/__/common/tensor_queue.cc.o CMakeFiles/pytorch.dir/__/common/ops/collective_operations.cc.o CMakeFiles/pytorch.dir/__/common/ops/operation_manager.cc.o CMakeFiles/pytorch.dir/__/common/optim/bayesian_optimization.cc.o CMakeFiles/pytorch.dir/__/common/optim/gaussian_process.cc.o CMakeFiles/pytorch.dir/__/common/utils/env_parser.cc.o CMakeFiles/pytorch.dir/__/common/mpi/mpi_context.cc.o CMakeFiles/pytorch.dir/__/common/mpi/mpi_controller.cc.o CMakeFiles/pytorch.dir/__/common/ops/mpi_operations.cc.o CMakeFiles/pytorch.dir/__/common/ops/adasum/adasum_mpi.cc.o CMakeFiles/pytorch.dir/__/common/ops/adasum_mpi_operations.cc.o CMakeFiles/pytorch.dir/__/common/gloo/gloo_context.cc.o CMakeFiles/pytorch.dir/__/common/gloo/gloo_controller.cc.o CMakeFiles/pytorch.dir/__/common/gloo/http_store.cc.o CMakeFiles/pytorch.dir/__/common/gloo/memory_store.cc.o CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o CMakeFiles/pytorch.dir/handle_manager.cc.o CMakeFiles/pytorch.dir/ready_event.cc.o CMakeFiles/pytorch.dir/cuda_util.cc.o CMakeFiles/pytorch.dir/mpi_ops_v2.cc.o CMakeFiles/pytorch.dir/adapter_v2.cc.o  -Wl,-rpath,/Users/mleimeister/anaconda3/lib/python3.9/site-packages/torch/lib /opt/homebrew/Cellar/open-mpi/4.1.4/lib/libmpi.dylib /Users/mleimeister/anaconda3/lib/python3.9/site-packages/torch/lib/libc10.dylib /Users/mleimeister/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch.dylib /Users/mleimeister/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib /Users/mleimeister/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_python.dylib ../../third_party/compatible_gloo/gloo/libcompatible_gloo.a /opt/homebrew/Cellar/open-mpi/4.1.4/lib/libmpi.dylib /opt/homebrew/Cellar/libuv/1.44.1_1/lib/libuv.a -lpthread\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::enable_shared_from_this<horovod::common::Controller> from CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::Controller from CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::Controller from CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::enable_shared_from_this<horovod::common::Controller> from CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n  ld: warning: cannot export hidden symbol std::__1::thread::thread<void (&)(horovod::common::HorovodGlobalState&), std::__1::reference_wrapper<horovod::common::HorovodGlobalState>, void>(void (&)(horovod::common::HorovodGlobalState&), std::__1::reference_wrapper<horovod::common::HorovodGlobalState>&&) from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::ParameterManager::TunableParameter<Eigen::Matrix<double, -1, 1, 0, -1, 1> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::ParameterManager::ITunableParameter from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::ParameterManager::CategoricalParameter<bool> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::ParameterManager::TunableParameter<bool> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::MPIController*, std::__1::shared_ptr<horovod::common::Controller>::__shared_ptr_default_delete<horovod::common::Controller, horovod::common::MPIController>, std::__1::allocator<horovod::common::MPIController> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::Controller>::__shared_ptr_default_delete<horovod::common::Controller, horovod::common::MPIController> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::Controller from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::enable_shared_from_this<horovod::common::Controller> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::GlooController*, std::__1::shared_ptr<horovod::common::Controller>::__shared_ptr_default_delete<horovod::common::Controller, horovod::common::GlooController>, std::__1::allocator<horovod::common::GlooController> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::Controller>::__shared_ptr_default_delete<horovod::common::Controller, horovod::common::GlooController> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::GlooAllreduce*, std::__1::shared_ptr<horovod::common::AllreduceOp>::__shared_ptr_default_delete<horovod::common::AllreduceOp, horovod::common::GlooAllreduce>, std::__1::allocator<horovod::common::GlooAllreduce> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::AllreduceOp>::__shared_ptr_default_delete<horovod::common::AllreduceOp, horovod::common::GlooAllreduce> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::GlooAllgather*, std::__1::shared_ptr<horovod::common::AllgatherOp>::__shared_ptr_default_delete<horovod::common::AllgatherOp, horovod::common::GlooAllgather>, std::__1::allocator<horovod::common::GlooAllgather> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::AllgatherOp>::__shared_ptr_default_delete<horovod::common::AllgatherOp, horovod::common::GlooAllgather> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::GlooBroadcast*, std::__1::shared_ptr<horovod::common::BroadcastOp>::__shared_ptr_default_delete<horovod::common::BroadcastOp, horovod::common::GlooBroadcast>, std::__1::allocator<horovod::common::GlooBroadcast> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::BroadcastOp>::__shared_ptr_default_delete<horovod::common::BroadcastOp, horovod::common::GlooBroadcast> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::GlooAlltoall*, std::__1::shared_ptr<horovod::common::AlltoallOp>::__shared_ptr_default_delete<horovod::common::AlltoallOp, horovod::common::GlooAlltoall>, std::__1::allocator<horovod::common::GlooAlltoall> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::AlltoallOp>::__shared_ptr_default_delete<horovod::common::AlltoallOp, horovod::common::GlooAlltoall> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::GlooReducescatter*, std::__1::shared_ptr<horovod::common::ReducescatterOp>::__shared_ptr_default_delete<horovod::common::ReducescatterOp, horovod::common::GlooReducescatter>, std::__1::allocator<horovod::common::GlooReducescatter> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::ReducescatterOp>::__shared_ptr_default_delete<horovod::common::ReducescatterOp, horovod::common::GlooReducescatter> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::AdasumMPIAllreduceOp*, std::__1::shared_ptr<horovod::common::AllreduceOp>::__shared_ptr_default_delete<horovod::common::AllreduceOp, horovod::common::AdasumMPIAllreduceOp>, std::__1::allocator<horovod::common::AdasumMPIAllreduceOp> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::AllreduceOp>::__shared_ptr_default_delete<horovod::common::AllreduceOp, horovod::common::AdasumMPIAllreduceOp> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::MPIAllreduce*, std::__1::shared_ptr<horovod::common::AllreduceOp>::__shared_ptr_default_delete<horovod::common::AllreduceOp, horovod::common::MPIAllreduce>, std::__1::allocator<horovod::common::MPIAllreduce> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::AllreduceOp>::__shared_ptr_default_delete<horovod::common::AllreduceOp, horovod::common::MPIAllreduce> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::MPIAllgather*, std::__1::shared_ptr<horovod::common::AllgatherOp>::__shared_ptr_default_delete<horovod::common::AllgatherOp, horovod::common::MPIAllgather>, std::__1::allocator<horovod::common::MPIAllgather> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::AllgatherOp>::__shared_ptr_default_delete<horovod::common::AllgatherOp, horovod::common::MPIAllgather> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::MPIBroadcast*, std::__1::shared_ptr<horovod::common::BroadcastOp>::__shared_ptr_default_delete<horovod::common::BroadcastOp, horovod::common::MPIBroadcast>, std::__1::allocator<horovod::common::MPIBroadcast> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::BroadcastOp>::__shared_ptr_default_delete<horovod::common::BroadcastOp, horovod::common::MPIBroadcast> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::MPIAlltoall*, std::__1::shared_ptr<horovod::common::AlltoallOp>::__shared_ptr_default_delete<horovod::common::AlltoallOp, horovod::common::MPIAlltoall>, std::__1::allocator<horovod::common::MPIAlltoall> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::AlltoallOp>::__shared_ptr_default_delete<horovod::common::AlltoallOp, horovod::common::MPIAlltoall> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::MPIReducescatter*, std::__1::shared_ptr<horovod::common::ReducescatterOp>::__shared_ptr_default_delete<horovod::common::ReducescatterOp, horovod::common::MPIReducescatter>, std::__1::allocator<horovod::common::MPIReducescatter> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::ReducescatterOp>::__shared_ptr_default_delete<horovod::common::ReducescatterOp, horovod::common::MPIReducescatter> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::JoinOp*, std::__1::shared_ptr<horovod::common::JoinOp>::__shared_ptr_default_delete<horovod::common::JoinOp, horovod::common::JoinOp>, std::__1::allocator<horovod::common::JoinOp> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::JoinOp>::__shared_ptr_default_delete<horovod::common::JoinOp, horovod::common::JoinOp> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::BarrierOp*, std::__1::shared_ptr<horovod::common::BarrierOp>::__shared_ptr_default_delete<horovod::common::BarrierOp, horovod::common::BarrierOp>, std::__1::allocator<horovod::common::BarrierOp> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::BarrierOp>::__shared_ptr_default_delete<horovod::common::BarrierOp, horovod::common::BarrierOp> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_pointer<horovod::common::ErrorOp*, std::__1::shared_ptr<horovod::common::ErrorOp>::__shared_ptr_default_delete<horovod::common::ErrorOp, horovod::common::ErrorOp>, std::__1::allocator<horovod::common::ErrorOp> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::shared_ptr<horovod::common::ErrorOp>::__shared_ptr_default_delete<horovod::common::ErrorOp, horovod::common::ErrorOp> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::ParameterManager::ITunableParameter from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::ParameterManager::TunableParameter<Eigen::Matrix<double, -1, 1, 0, -1, 1> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::ParameterManager::TunableParameter<bool> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::ParameterManager::CategoricalParameter<bool> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::MPIController*, std::__1::shared_ptr<horovod::common::Controller>::__shared_ptr_default_delete<horovod::common::Controller, horovod::common::MPIController>, std::__1::allocator<horovod::common::MPIController> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::enable_shared_from_this<horovod::common::Controller> from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::Controller from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::GlooController*, std::__1::shared_ptr<horovod::common::Controller>::__shared_ptr_default_delete<horovod::common::Controller, horovod::common::GlooController>, std::__1::allocator<horovod::common::GlooController> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::GlooAllreduce*, std::__1::shared_ptr<horovod::common::AllreduceOp>::__shared_ptr_default_delete<horovod::common::AllreduceOp, horovod::common::GlooAllreduce>, std::__1::allocator<horovod::common::GlooAllreduce> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::GlooAllgather*, std::__1::shared_ptr<horovod::common::AllgatherOp>::__shared_ptr_default_delete<horovod::common::AllgatherOp, horovod::common::GlooAllgather>, std::__1::allocator<horovod::common::GlooAllgather> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::GlooBroadcast*, std::__1::shared_ptr<horovod::common::BroadcastOp>::__shared_ptr_default_delete<horovod::common::BroadcastOp, horovod::common::GlooBroadcast>, std::__1::allocator<horovod::common::GlooBroadcast> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::GlooAlltoall*, std::__1::shared_ptr<horovod::common::AlltoallOp>::__shared_ptr_default_delete<horovod::common::AlltoallOp, horovod::common::GlooAlltoall>, std::__1::allocator<horovod::common::GlooAlltoall> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::GlooReducescatter*, std::__1::shared_ptr<horovod::common::ReducescatterOp>::__shared_ptr_default_delete<horovod::common::ReducescatterOp, horovod::common::GlooReducescatter>, std::__1::allocator<horovod::common::GlooReducescatter> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::AdasumMPIAllreduceOp*, std::__1::shared_ptr<horovod::common::AllreduceOp>::__shared_ptr_default_delete<horovod::common::AllreduceOp, horovod::common::AdasumMPIAllreduceOp>, std::__1::allocator<horovod::common::AdasumMPIAllreduceOp> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::MPIAllreduce*, std::__1::shared_ptr<horovod::common::AllreduceOp>::__shared_ptr_default_delete<horovod::common::AllreduceOp, horovod::common::MPIAllreduce>, std::__1::allocator<horovod::common::MPIAllreduce> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::MPIAllgather*, std::__1::shared_ptr<horovod::common::AllgatherOp>::__shared_ptr_default_delete<horovod::common::AllgatherOp, horovod::common::MPIAllgather>, std::__1::allocator<horovod::common::MPIAllgather> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::MPIBroadcast*, std::__1::shared_ptr<horovod::common::BroadcastOp>::__shared_ptr_default_delete<horovod::common::BroadcastOp, horovod::common::MPIBroadcast>, std::__1::allocator<horovod::common::MPIBroadcast> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::MPIAlltoall*, std::__1::shared_ptr<horovod::common::AlltoallOp>::__shared_ptr_default_delete<horovod::common::AlltoallOp, horovod::common::MPIAlltoall>, std::__1::allocator<horovod::common::MPIAlltoall> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::MPIReducescatter*, std::__1::shared_ptr<horovod::common::ReducescatterOp>::__shared_ptr_default_delete<horovod::common::ReducescatterOp, horovod::common::MPIReducescatter>, std::__1::allocator<horovod::common::MPIReducescatter> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::JoinOp*, std::__1::shared_ptr<horovod::common::JoinOp>::__shared_ptr_default_delete<horovod::common::JoinOp, horovod::common::JoinOp>, std::__1::allocator<horovod::common::JoinOp> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::BarrierOp*, std::__1::shared_ptr<horovod::common::BarrierOp>::__shared_ptr_default_delete<horovod::common::BarrierOp, horovod::common::BarrierOp>, std::__1::allocator<horovod::common::BarrierOp> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_pointer<horovod::common::ErrorOp*, std::__1::shared_ptr<horovod::common::ErrorOp>::__shared_ptr_default_delete<horovod::common::ErrorOp, horovod::common::ErrorOp>, std::__1::allocator<horovod::common::ErrorOp> > from CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::ParameterManager::ITunableParameter from CMakeFiles/pytorch.dir/__/common/parameter_manager.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::ParameterManager::TunableParameter<Eigen::Matrix<double, -1, 1, 0, -1, 1> > from CMakeFiles/pytorch.dir/__/common/parameter_manager.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::ParameterManager::TunableParameter<bool> from CMakeFiles/pytorch.dir/__/common/parameter_manager.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::ParameterManager::CategoricalParameter<bool> from CMakeFiles/pytorch.dir/__/common/parameter_manager.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::ParameterManager::TunableParameter<Eigen::Matrix<double, -1, 1, 0, -1, 1> > from CMakeFiles/pytorch.dir/__/common/parameter_manager.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::ParameterManager::ITunableParameter from CMakeFiles/pytorch.dir/__/common/parameter_manager.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::ParameterManager::CategoricalParameter<bool> from CMakeFiles/pytorch.dir/__/common/parameter_manager.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::ParameterManager::TunableParameter<bool> from CMakeFiles/pytorch.dir/__/common/parameter_manager.cc.o\r\n  ld: warning: cannot export hidden symbol std::__1::thread::thread<void (horovod::common::ThreadPool::*)(), horovod::common::ThreadPool*, void>(void (horovod::common::ThreadPool::*&&)(), horovod::common::ThreadPool*&&) from CMakeFiles/pytorch.dir/__/common/thread_pool.cc.o\r\n  ld: warning: cannot export hidden symbol std::__1::thread::thread<void (horovod::common::TimelineWriter::*)(), horovod::common::TimelineWriter*, void>(void (horovod::common::TimelineWriter::*&&)(), horovod::common::TimelineWriter*&&) from CMakeFiles/pytorch.dir/__/common/timeline.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::BroadcastOp from CMakeFiles/pytorch.dir/__/common/ops/collective_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::AlltoallOp from CMakeFiles/pytorch.dir/__/common/ops/collective_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::BroadcastOp from CMakeFiles/pytorch.dir/__/common/ops/collective_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::AlltoallOp from CMakeFiles/pytorch.dir/__/common/ops/collective_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::OperationManager from CMakeFiles/pytorch.dir/__/common/ops/operation_manager.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::OperationManager from CMakeFiles/pytorch.dir/__/common/ops/operation_manager.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::enable_shared_from_this<horovod::common::Controller> from CMakeFiles/pytorch.dir/__/common/mpi/mpi_controller.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::Controller from CMakeFiles/pytorch.dir/__/common/mpi/mpi_controller.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::Controller from CMakeFiles/pytorch.dir/__/common/mpi/mpi_controller.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::enable_shared_from_this<horovod::common::Controller> from CMakeFiles/pytorch.dir/__/common/mpi/mpi_controller.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::BroadcastOp from CMakeFiles/pytorch.dir/__/common/ops/mpi_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::AlltoallOp from CMakeFiles/pytorch.dir/__/common/ops/mpi_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::BroadcastOp from CMakeFiles/pytorch.dir/__/common/ops/mpi_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::AlltoallOp from CMakeFiles/pytorch.dir/__/common/ops/mpi_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::Adasum<ompi_communicator_t*> from CMakeFiles/pytorch.dir/__/common/ops/adasum/adasum_mpi.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::Adasum<ompi_communicator_t*> from CMakeFiles/pytorch.dir/__/common/ops/adasum/adasum_mpi.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::enable_shared_from_this<horovod::common::Controller> from CMakeFiles/pytorch.dir/__/common/gloo/gloo_controller.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::Controller from CMakeFiles/pytorch.dir/__/common/gloo/gloo_controller.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::Controller from CMakeFiles/pytorch.dir/__/common/gloo/gloo_controller.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::enable_shared_from_this<horovod::common::Controller> from CMakeFiles/pytorch.dir/__/common/gloo/gloo_controller.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::GlooStore from CMakeFiles/pytorch.dir/__/common/gloo/http_store.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::GlooStore from CMakeFiles/pytorch.dir/__/common/gloo/http_store.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::GlooStore from CMakeFiles/pytorch.dir/__/common/gloo/memory_store.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::GlooStore from CMakeFiles/pytorch.dir/__/common/gloo/memory_store.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::BroadcastOp from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::AlltoallOp from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::GlooAlgorithms<unsigned char> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::IGlooAlgorithms from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::GlooAlgorithms<signed char> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::GlooAlgorithms<unsigned short> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::GlooAlgorithms<short> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::GlooAlgorithms<int> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::GlooAlgorithms<long long> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::GlooAlgorithms<gloo::float16> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::GlooAlgorithms<float> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::GlooAlgorithms<double> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::GlooAlgorithms<bool> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::BroadcastOp from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::AlltoallOp from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::IGlooAlgorithms from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::GlooAlgorithms<unsigned char> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::GlooAlgorithms<signed char> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::GlooAlgorithms<unsigned short> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::GlooAlgorithms<short> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::GlooAlgorithms<int> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::GlooAlgorithms<long long> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::GlooAlgorithms<gloo::float16> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::GlooAlgorithms<float> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::GlooAlgorithms<double> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::GlooAlgorithms<bool> from CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_emplace<horovod::common::Status, std::__1::allocator<horovod::common::Status> > from CMakeFiles/pytorch.dir/handle_manager.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_emplace<horovod::common::Status, std::__1::allocator<horovod::common::Status> > from CMakeFiles/pytorch.dir/handle_manager.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_emplace<horovod::torch::TorchTensor, std::__1::allocator<horovod::torch::TorchTensor> > from CMakeFiles/pytorch.dir/mpi_ops_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_emplace<horovod::torch::TorchOpContext, std::__1::allocator<horovod::torch::TorchOpContext> > from CMakeFiles/pytorch.dir/mpi_ops_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__function::__base<void (horovod::common::Status const&)> from CMakeFiles/pytorch.dir/mpi_ops_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_emplace<horovod::torch::TorchTensor, std::__1::allocator<horovod::torch::TorchTensor> > from CMakeFiles/pytorch.dir/mpi_ops_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_emplace<horovod::torch::TorchOpContext, std::__1::allocator<horovod::torch::TorchOpContext> > from CMakeFiles/pytorch.dir/mpi_ops_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__function::__base<void (horovod::common::Status const&)> from CMakeFiles/pytorch.dir/mpi_ops_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::PersistentBuffer from CMakeFiles/pytorch.dir/adapter_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::Tensor from CMakeFiles/pytorch.dir/adapter_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for horovod::common::OpContext from CMakeFiles/pytorch.dir/adapter_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_emplace<horovod::torch::TorchPersistentBuffer, std::__1::allocator<horovod::torch::TorchPersistentBuffer> > from CMakeFiles/pytorch.dir/adapter_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo name for std::__1::__shared_ptr_emplace<horovod::torch::TorchTensor, std::__1::allocator<horovod::torch::TorchTensor> > from CMakeFiles/pytorch.dir/adapter_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::PersistentBuffer from CMakeFiles/pytorch.dir/adapter_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::Tensor from CMakeFiles/pytorch.dir/adapter_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for horovod::common::OpContext from CMakeFiles/pytorch.dir/adapter_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_emplace<horovod::torch::TorchPersistentBuffer, std::__1::allocator<horovod::torch::TorchPersistentBuffer> > from CMakeFiles/pytorch.dir/adapter_v2.cc.o\r\n  ld: warning: cannot export hidden symbol typeinfo for std::__1::__shared_ptr_emplace<horovod::torch::TorchTensor, std::__1::allocator<horovod::torch::TorchTensor> > from CMakeFiles/pytorch.dir/adapter_v2.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/operations.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/process_set.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/parameter_manager.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/response_cache.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/ops/collective_operations.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/ops/operation_manager.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/optim/bayesian_optimization.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/ops/mpi_operations.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/mpi/mpi_controller.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/ops/adasum/adasum_mpi.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/optim/gaussian_process.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/ops/adasum_mpi_operations.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/gloo/gloo_controller.cc.o\r\n  duplicate symbol 'Eigen::internal::conditional<((unpacket_traits<__simd128_float16_t>::size) % (8)) == (0), Eigen::internal::unpacket_traits<__simd128_float16_t>::half, __simd128_float16_t>::type Eigen::internal::predux_half_dowto4<__simd128_float16_t>(__simd128_float16_t const&)' in:\r\n      CMakeFiles/pytorch.dir/__/common/controller.cc.o\r\n      CMakeFiles/pytorch.dir/__/common/ops/gloo_operations.cc.o\r\n  ld: 14 duplicate symbols for architecture arm64\r\n  clang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n  make[2]: *** [../../lib.macosx-11.1-arm64-3.9/horovod/torch/mpi_lib_v2.cpython-39-darwin.so] Error 1\r\n  make[1]: *** [horovod/torch/CMakeFiles/pytorch.dir/all] Error 2\r\n  make: *** [all] Error 2\r\n  Traceback (most recent call last):\r\n    File \"<string>\", line 1, in <module>\r\n    File \"/private/var/folders/cg/8x25dwnn2xx6b7bbw8kw973w0000gq/T/pip-install-2qg__ipb/horovod_cd0910fb8cf942ebbc6c7e3e0a0a9b78/setup.py\", line 210, in <module>\r\n      setup(name='horovod',\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/__init__.py\", line 87, in setup\r\n      return distutils.core.setup(**attrs)\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 148, in setup\r\n      return run_commands(dist)\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 163, in run_commands\r\n      dist.run_commands()\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 967, in run_commands\r\n      self.run_command(cmd)\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/dist.py\", line 1214, in run_command\r\n      super().run_command(command)\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\r\n      cmd_obj.run()\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/wheel/bdist_wheel.py\", line 299, in run\r\n      self.run_command('build')\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/dist.py\", line 1214, in run_command\r\n      super().run_command(command)\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\r\n      cmd_obj.run()\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/command/build.py\", line 135, in run\r\n      self.run_command(cmd_name)\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/dist.py\", line 1214, in run_command\r\n      super().run_command(command)\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\r\n      cmd_obj.run()\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 79, in run\r\n      _build_ext.run(self)\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\r\n      _build_ext.build_ext.run(self)\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 339, in run\r\n      self.build_extensions()\r\n    File \"/private/var/folders/cg/8x25dwnn2xx6b7bbw8kw973w0000gq/T/pip-install-2qg__ipb/horovod_cd0910fb8cf942ebbc6c7e3e0a0a9b78/setup.py\", line 144, in build_extensions\r\n      subprocess.check_call(command, cwd=cmake_build_dir)\r\n    File \"/Users/mleimeister/anaconda3/lib/python3.9/subprocess.py\", line 373, in check_call\r\n      raise CalledProcessError(retcode, cmd)\r\n  subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--config', 'RelWithDebInfo', '--', '-j8', 'VERBOSE=1']' returned non-zero exit status 2.\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n  Running setup.py clean for horovod\r\nFailed to build horovod\r\n```\r\n\r\nFull output logs: \r\n[install_logs.txt](https://github.com/horovod/horovod/files/9000446/install_logs.txt)\r\n\r\nThe same error happens when trying to build from source. Is there any CMake setting or other configuration changes that could prevent this?\r\n\r\nThanks for any hints!\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3587/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3587/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3579", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3579/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3579/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3579/events", "html_url": "https://github.com/horovod/horovod/issues/3579", "id": 1271277189, "node_id": "I_kwDOBfOI785LxiaF", "number": 3579, "title": "Tensorflow Import Error with MacOS 13, M1 Ultra", "user": {"login": "abhimanyuchadha96", "id": 37940438, "node_id": "MDQ6VXNlcjM3OTQwNDM4", "avatar_url": "https://avatars.githubusercontent.com/u/37940438?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abhimanyuchadha96", "html_url": "https://github.com/abhimanyuchadha96", "followers_url": "https://api.github.com/users/abhimanyuchadha96/followers", "following_url": "https://api.github.com/users/abhimanyuchadha96/following{/other_user}", "gists_url": "https://api.github.com/users/abhimanyuchadha96/gists{/gist_id}", "starred_url": "https://api.github.com/users/abhimanyuchadha96/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abhimanyuchadha96/subscriptions", "organizations_url": "https://api.github.com/users/abhimanyuchadha96/orgs", "repos_url": "https://api.github.com/users/abhimanyuchadha96/repos", "events_url": "https://api.github.com/users/abhimanyuchadha96/events{/privacy}", "received_events_url": "https://api.github.com/users/abhimanyuchadha96/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2022-06-14T19:40:10Z", "updated_at": "2022-09-19T14:45:27Z", "closed_at": "2022-09-19T14:29:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow and Keras\r\n2. Framework version: 2.9.2\r\n3. Horovod version: 0.24\r\n4. MPI version: 4.1.4\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.9\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version: MacOS 13, M1 Ultra Chip\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\n\r\nReproduction steps:-\r\nEnvironment Setup:-\r\n`conda uninstall -c apple tensorflow-deps -y\r\nconda install -c apple tensorflow-deps -y\r\npython -m pip uninstall tensorflow-macos -y\r\npython -m pip uninstall tensorflow-metal -y\r\nconda install -c apple tensorflow-deps --force-reinstall -y\r\npython -m pip install tensorflow-macos\r\npython -m pip install tensorflow-metal\r\nsudo pip uninstall horovod -y\r\nHOROVOD_WITH_TENSORFLOW=1 sudo pip install horovod`\r\n\r\n\r\nCODE:-\r\n`import horovod.tensorflow as hvd`\r\n\r\nERROR OUTPUT:-\r\n![Screen Shot 2022-06-14 at 3 40 02 PM](https://user-images.githubusercontent.com/37940438/173674530-50b07ea9-4a81-46d0-b982-e2a7f08dae19.png)\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3579/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3579/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3570", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3570/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3570/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3570/events", "html_url": "https://github.com/horovod/horovod/issues/3570", "id": 1264465571, "node_id": "I_kwDOBfOI785LXjaj", "number": 3570, "title": "CI for torchhead hangs after `TorchTests::test_horovod_join_allgather`", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-06-08T09:33:39Z", "updated_at": "2022-07-24T09:30:58Z", "closed_at": "2022-07-24T09:30:58Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: Nightly\r\n3. Horovod version: master\r\n\r\n**Bug report:**\r\nAs observed in https://github.com/horovod/horovod/pull/3558#issuecomment-1148685657, having fixed the build for TF 2.10 nightly, tests for `torchhead` now seem to hang just after `TorchTests::test_horovod_join_allgather`.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3570/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3570/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3566", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3566/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3566/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3566/events", "html_url": "https://github.com/horovod/horovod/issues/3566", "id": 1260321273, "node_id": "I_kwDOBfOI785LHvn5", "number": 3566, "title": "Unit test \"test_spark_keras\" fails with TF head:", "user": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-06-03T20:02:56Z", "updated_at": "2022-06-08T09:57:45Z", "closed_at": "2022-06-08T09:57:45Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "```\r\nself = <test_spark_keras.SparkKerasTests testMethod=test_fit_model>\r\n\r\n    def test_fit_model(self):\r\n        model = create_xor_model()\r\n        optimizer = tf.keras.optimizers.SGD(lr=0.1)\r\n        loss = 'binary_crossentropy'\r\n    \r\n        with spark_session('test_fit_model') as spark:\r\n            df = create_xor_data(spark)\r\n    \r\n            with local_store() as store:\r\n                keras_estimator = hvd.KerasEstimator(\r\n                    num_proc=2,\r\n                    store=store,\r\n                    model=model,\r\n                    optimizer=optimizer,\r\n                    loss=loss,\r\n                    feature_cols=['features'],\r\n                    label_cols=['y'],\r\n                    batch_size=1,\r\n                    random_seed=1,\r\n                    epochs=3,\r\n                    verbose=2,\r\n                    use_gpu=False)\r\n    \r\n                assert not keras_estimator.getUseGpu()\r\n    \r\n>               keras_model = keras_estimator.fit(df)\r\n\r\ntest_spark_keras.py:106: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/local/lib/python3.8/dist-packages/horovod/spark/common/estimator.py:35: in fit\r\n    return super(HorovodEstimator, self).fit(df, params)\r\n/usr/local/lib/python3.8/dist-packages/pyspark/ml/base.py:161: in fit\r\n    return self._fit(dataset)\r\n/usr/local/lib/python3.8/dist-packages/horovod/spark/common/estimator.py:80: in _fit\r\n    return self._fit_on_prepared_data(\r\n/usr/local/lib/python3.8/dist-packages/horovod/spark/keras/estimator.py:270: in _fit_on_prepared_data\r\n    serialized_model = self._compile_model(keras_utils)\r\n/usr/local/lib/python3.8/dist-packages/horovod/spark/keras/estimator.py:318: in _compile_model\r\n    dist_optimizer = keras_utils.get_horovod().DistributedOptimizer(**dist_optimizer_args)\r\n/usr/local/lib/python3.8/dist-packages/horovod/spark/keras/util.py:99: in get_horovod\r\n    return TFKerasUtil.horovod_fn()()\r\n/usr/local/lib/python3.8/dist-packages/horovod/spark/keras/util.py:104: in fn\r\n    import horovod.tensorflow.keras as hvd\r\n/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/__init__.py:26: in <module>\r\n    from horovod.tensorflow import elastic\r\n/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/elastic.py:24: in <module>\r\n    from horovod.tensorflow.functions import broadcast_object, broadcast_object_fn, broadcast_variables\r\n/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/functions.py:24: in <module>\r\n    from horovod.tensorflow.mpi_ops import allgather, broadcast, broadcast_\r\n/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/mpi_ops.py:53: in <module>\r\n    raise e\r\n/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/mpi_ops.py:50: in <module>\r\n    MPI_LIB = _load_library('mpi_lib' + get_ext_suffix())\r\n/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/mpi_ops.py:45: in _load_library\r\n    library = load_library.load_op_library(filename)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nlibrary_filename = '/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/mpi_lib.cpython-38-x86_64-linux-gnu.so'\r\n\r\n    @tf_export('load_op_library')\r\n    def load_op_library(library_filename):\r\n      \"\"\"Loads a TensorFlow plugin, containing custom ops and kernels.\r\n    \r\n      Pass \"library_filename\" to a platform-specific mechanism for dynamically\r\n      loading a library. The rules for determining the exact location of the\r\n      library are platform-specific and are not documented here. When the\r\n      library is loaded, ops and kernels registered in the library via the\r\n      `REGISTER_*` macros are made available in the TensorFlow process. Note\r\n      that ops with the same name as an existing op are rejected and not\r\n      registered with the process.\r\n    \r\n      Args:\r\n        library_filename: Path to the plugin.\r\n          Relative or absolute filesystem path to a dynamic library file.\r\n    \r\n      Returns:\r\n        A python module containing the Python wrappers for Ops defined in\r\n        the plugin.\r\n    \r\n      Raises:\r\n        RuntimeError: when unable to load the library or get the python wrappers.\r\n      \"\"\"\r\n>     lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\nE     tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/horovod/tensorflow/mpi_lib.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021110211string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE\r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/load_library.py:54: NotFoundError\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3566/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3566/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3552", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3552/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3552/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3552/events", "html_url": "https://github.com/horovod/horovod/issues/3552", "id": 1247286156, "node_id": "I_kwDOBfOI785KWBOM", "number": 3552, "title": "\"import horovod.tensorflow as hvd\" fais with \"tensorflow.python.framework.errors_impl.NotFoundError\"", "user": {"login": "ashahba", "id": 12436063, "node_id": "MDQ6VXNlcjEyNDM2MDYz", "avatar_url": "https://avatars.githubusercontent.com/u/12436063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ashahba", "html_url": "https://github.com/ashahba", "followers_url": "https://api.github.com/users/ashahba/followers", "following_url": "https://api.github.com/users/ashahba/following{/other_user}", "gists_url": "https://api.github.com/users/ashahba/gists{/gist_id}", "starred_url": "https://api.github.com/users/ashahba/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ashahba/subscriptions", "organizations_url": "https://api.github.com/users/ashahba/orgs", "repos_url": "https://api.github.com/users/ashahba/repos", "events_url": "https://api.github.com/users/ashahba/events{/privacy}", "received_events_url": "https://api.github.com/users/ashahba/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-05-25T01:08:18Z", "updated_at": "2022-06-08T09:57:45Z", "closed_at": "2022-06-08T09:57:45Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. TensorFlow\r\n2. Framework version: `tf-nightly-cpu==2.10.0.dev20220524`\r\n3. Horovod version: `v0.24.3` installed from: `git+https://github.com/horovod/horovod.git@a0cd0af`\r\n4. MPI version: v4.0.3\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.8.10\r\n8. Spark / PySpark version: N/A\r\n9. Ray version: N/A\r\n10. OS and version: Ubuntu 20.04.4 LTS\r\n11. GCC version: 9.4.0\r\n12. CMake version: 3.16.3\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? N/A\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? N/A\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Bug report:**\r\nI'm trying to run some `nightly` tests with latest TF nightly (currently `tf-nightly-cpu==2.10.0.dev20220524` ) and I installed required openmpi-bin and openmpi-common libraries.\r\nThen installing `Horovod` from tip of the main branch works fine:\r\n\r\n```\r\nexport HOROVOD_WITHOUT_PYTORCH=1\r\nexport HOROVOD_WITHOUT_MXNET=1\r\nexport HOROVOD_WITH_TENSORFLOW=1\r\n\r\nexport HOROVOD_VERSION=a0cd0af\r\n\r\n# python3 -m pip install git+https://github.com/horovod/horovod.git@${HOROVOD_VERSION}\r\nCollecting git+https://github.com/horovod/horovod.git@a0cd0af\r\n  Cloning https://github.com/horovod/horovod.git (to revision a0cd0af) to /tmp/pip-req-build-sj1jyas6\r\n  WARNING: Did not find branch or tag 'a0cd0af', assuming revision or ref.\r\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from horovod==0.24.3) (2.1.0)\r\nRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from horovod==0.24.3) (5.9.1)\r\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from horovod==0.24.3) (6.0)\r\nBuilding wheels for collected packages: horovod\r\n  Building wheel for horovod (setup.py) ... done\r\n  Created wheel for horovod: filename=horovod-0.24.3-cp38-cp38-linux_x86_64.whl size=17992056 sha256=b48ce85c1068eaa6a013788b71715e21081f315ef9c6cf24daf4829887a35bf3\r\n  Stored in directory: /tmp/pip-ephem-wheel-cache-_z7jhj34/wheels/d8/b7/96/3fc3f9533ba4858038d8df4974b7744163753ab4799ae0b2ff\r\nSuccessfully built horovod\r\nInstalling collected packages: horovod\r\n  Attempting uninstall: horovod\r\n    Found existing installation: horovod 0.24.2\r\n    Uninstalling horovod-0.24.2:\r\n      Successfully uninstalled horovod-0.24.2\r\nSuccessfully installed horovod-0.24.3\r\n```\r\nBut after that when I attempt to import `horovod.tensorflow` I get the following error:\r\n\r\n```\r\n# python\r\nPython 3.8.10 (default, Mar 15 2022, 12:22:08) \r\n[GCC 9.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import horovod.tensorflow as hvd\r\n2022-05-25 01:07:21.098784: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nWARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\r\nWARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\r\nWARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\r\nWARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\nWARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\r\nWARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\r\nWARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\r\nWARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\r\nWARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/__init__.py\", line 26, in <module>\r\n    from horovod.tensorflow import elastic\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/elastic.py\", line 24, in <module>\r\n    from horovod.tensorflow.functions import broadcast_object, broadcast_object_fn, broadcast_variables\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/functions.py\", line 24, in <module>\r\n    from horovod.tensorflow.mpi_ops import allgather, broadcast, broadcast_\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/mpi_ops.py\", line 53, in <module>\r\n    raise e\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/mpi_ops.py\", line 50, in <module>\r\n    MPI_LIB = _load_library('mpi_lib' + get_ext_suffix())\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/mpi_ops.py\", line 45, in _load_library\r\n    library = load_library.load_op_library(filename)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/load_library.py\", line 54, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/horovod/tensorflow/mpi_lib.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021110211string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3552/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3552/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3545", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3545/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3545/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3545/events", "html_url": "https://github.com/horovod/horovod/issues/3545", "id": 1234037491, "node_id": "I_kwDOBfOI785Jjerz", "number": 3545, "title": "HOROVOD_WITH_PYTORCH=1 HOROVOD_WITHOUT_TENSORFLOW=1 pip3 install horovod[pytorch] install failed", "user": {"login": "you-old", "id": 16161846, "node_id": "MDQ6VXNlcjE2MTYxODQ2", "avatar_url": "https://avatars.githubusercontent.com/u/16161846?v=4", "gravatar_id": "", "url": "https://api.github.com/users/you-old", "html_url": "https://github.com/you-old", "followers_url": "https://api.github.com/users/you-old/followers", "following_url": "https://api.github.com/users/you-old/following{/other_user}", "gists_url": "https://api.github.com/users/you-old/gists{/gist_id}", "starred_url": "https://api.github.com/users/you-old/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/you-old/subscriptions", "organizations_url": "https://api.github.com/users/you-old/orgs", "repos_url": "https://api.github.com/users/you-old/repos", "events_url": "https://api.github.com/users/you-old/events{/privacy}", "received_events_url": "https://api.github.com/users/you-old/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2022-05-12T14:04:19Z", "updated_at": "2022-09-09T15:16:18Z", "closed_at": "2022-09-09T15:16:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "HOROVOD_WITH_PYTORCH=1 HOROVOD_WITHOUT_TENSORFLOW=1 pip3 install horovod[pytorch]\r\n\r\n**Environment:**\r\n1. Framework:pytorch\r\n2. Framework version:1.9.0\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:11.1\r\n6. NCCL version:\r\n7. Python version:3.8\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version:ubuntu20.04\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n```\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-o6yhlor8/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-o6yhlor8/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-zhlcztka/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/sczone/.local/include/python3.8/horovod\r\n         cwd: /tmp/pip-install-o6yhlor8/horovod/\r\n    Complete output (346 lines):\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.8\r\n    creating build/lib.linux-x86_64-3.8/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-3.8/horovod\r\n    creating build/lib.linux-x86_64-3.8/horovod/mxnet\r\n    copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.8/horovod/mxnet\r\n    copying horovod/mxnet/compression.py -> build/lib.linux-x86_64-3.8/horovod/mxnet\r\n    copying horovod/mxnet/functions.py -> build/lib.linux-x86_64-3.8/horovod/mxnet\r\n    copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.8/horovod/mxnet\r\n    creating build/lib.linux-x86_64-3.8/horovod/spark\r\n    copying horovod/spark/conf.py -> build/lib.linux-x86_64-3.8/horovod/spark\r\n    copying horovod/spark/mpi_run.py -> build/lib.linux-x86_64-3.8/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.8/horovod/spark\r\n    copying horovod/spark/gloo_run.py -> build/lib.linux-x86_64-3.8/horovod/spark\r\n    copying horovod/spark/runner.py -> build/lib.linux-x86_64-3.8/horovod/spark\r\n    creating build/lib.linux-x86_64-3.8/horovod/torch\r\n    copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.8/horovod/torch\r\n    copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.8/horovod/torch\r\n    copying horovod/torch/functions.py -> build/lib.linux-x86_64-3.8/horovod/torch\r\n    copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.8/horovod/torch\r\n    copying horovod/torch/sync_batch_norm.py -> build/lib.linux-x86_64-3.8/horovod/torch\r\n    copying horovod/torch/optimizer.py -> build/lib.linux-x86_64-3.8/horovod/torch\r\n    creating build/lib.linux-x86_64-3.8/horovod/_keras\r\n    copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.8/horovod/_keras\r\n    copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.8/horovod/_keras\r\n    copying horovod/_keras/elastic.py -> build/lib.linux-x86_64-3.8/horovod/_keras\r\n    creating build/lib.linux-x86_64-3.8/horovod/runner\r\n    copying horovod/runner/mpi_run.py -> build/lib.linux-x86_64-3.8/horovod/runner\r\n    copying horovod/runner/__init__.py -> build/lib.linux-x86_64-3.8/horovod/runner\r\n    copying horovod/runner/gloo_run.py -> build/lib.linux-x86_64-3.8/horovod/runner\r\n    copying horovod/runner/run_task.py -> build/lib.linux-x86_64-3.8/horovod/runner\r\n    copying horovod/runner/js_run.py -> build/lib.linux-x86_64-3.8/horovod/runner\r\n    copying horovod/runner/launch.py -> build/lib.linux-x86_64-3.8/horovod/runner\r\n    copying horovod/runner/task_fn.py -> build/lib.linux-x86_64-3.8/horovod/runner\r\n    creating build/lib.linux-x86_64-3.8/horovod/data\r\n    copying horovod/data/__init__.py -> build/lib.linux-x86_64-3.8/horovod/data\r\n    copying horovod/data/data_loader_base.py -> build/lib.linux-x86_64-3.8/horovod/data\r\n    creating build/lib.linux-x86_64-3.8/horovod/tensorflow\r\n    copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.8/horovod/tensorflow\r\n    copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.8/horovod/tensorflow\r\n    copying horovod/tensorflow/gradient_aggregation.py -> build/lib.linux-x86_64-3.8/horovod/tensorflow\r\n    copying horovod/tensorflow/functions.py -> build/lib.linux-x86_64-3.8/horovod/tensorflow\r\n    copying horovod/tensorflow/gradient_aggregation_eager.py -> build/lib.linux-x86_64-3.8/horovod/tensorflow\r\n    copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.8/horovod/tensorflow\r\n    copying horovod/tensorflow/sync_batch_norm.py -> build/lib.linux-x86_64-3.8/horovod/tensorflow\r\n    copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.8/horovod/tensorflow\r\n    copying horovod/tensorflow/elastic.py -> build/lib.linux-x86_64-3.8/horovod/tensorflow\r\n    creating build/lib.linux-x86_64-3.8/horovod/ray\r\n    copying horovod/ray/utils.py -> build/lib.linux-x86_64-3.8/horovod/ray\r\n    copying horovod/ray/ray_logger.py -> build/lib.linux-x86_64-3.8/horovod/ray\r\n    copying horovod/ray/driver_service.py -> build/lib.linux-x86_64-3.8/horovod/ray\r\n    copying horovod/ray/__init__.py -> build/lib.linux-x86_64-3.8/horovod/ray\r\n    copying horovod/ray/elastic_v2.py -> build/lib.linux-x86_64-3.8/horovod/ray\r\n    copying horovod/ray/worker.py -> build/lib.linux-x86_64-3.8/horovod/ray\r\n    copying horovod/ray/runner.py -> build/lib.linux-x86_64-3.8/horovod/ray\r\n    copying horovod/ray/strategy.py -> build/lib.linux-x86_64-3.8/horovod/ray\r\n    copying horovod/ray/adapter.py -> build/lib.linux-x86_64-3.8/horovod/ray\r\n    copying horovod/ray/elastic.py -> build/lib.linux-x86_64-3.8/horovod/ray\r\n    creating build/lib.linux-x86_64-3.8/horovod/keras\r\n    copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.8/horovod/keras\r\n    copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.8/horovod/keras\r\n    copying horovod/keras/elastic.py -> build/lib.linux-x86_64-3.8/horovod/keras\r\n    creating build/lib.linux-x86_64-3.8/horovod/common\r\n    copying horovod/common/exceptions.py -> build/lib.linux-x86_64-3.8/horovod/common\r\n    copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.8/horovod/common\r\n    copying horovod/common/basics.py -> build/lib.linux-x86_64-3.8/horovod/common\r\n    copying horovod/common/util.py -> build/lib.linux-x86_64-3.8/horovod/common\r\n    copying horovod/common/elastic.py -> build/lib.linux-x86_64-3.8/horovod/common\r\n    copying horovod/common/process_sets.py -> build/lib.linux-x86_64-3.8/horovod/common\r\n    creating build/lib.linux-x86_64-3.8/horovod/spark/driver\r\n    copying horovod/spark/driver/rsh.py -> build/lib.linux-x86_64-3.8/horovod/spark/driver\r\n    copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.8/horovod/spark/driver\r\n    copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.8/horovod/spark/driver\r\n    copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.8/horovod/spark/driver\r\n    copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.8/horovod/spark/driver\r\n    copying horovod/spark/driver/host_discovery.py -> build/lib.linux-x86_64-3.8/horovod/spark/driver\r\n    copying horovod/spark/driver/rendezvous.py -> build/lib.linux-x86_64-3.8/horovod/spark/driver\r\n    creating build/lib.linux-x86_64-3.8/horovod/spark/torch\r\n    copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.8/horovod/spark/torch\r\n    copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.8/horovod/spark/torch\r\n    copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.8/horovod/spark/torch\r\n    copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.8/horovod/spark/torch\r\n    creating build/lib.linux-x86_64-3.8/horovod/spark/data_loaders\r\n    copying horovod/spark/data_loaders/__init__.py -> build/lib.linux-x86_64-3.8/horovod/spark/data_loaders\r\n    copying horovod/spark/data_loaders/pytorch_data_loaders.py -> build/lib.linux-x86_64-3.8/horovod/spark/data_loaders\r\n    creating build/lib.linux-x86_64-3.8/horovod/spark/task\r\n    copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.8/horovod/spark/task\r\n    copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.8/horovod/spark/task\r\n    copying horovod/spark/task/gloo_exec_fn.py -> build/lib.linux-x86_64-3.8/horovod/spark/task\r\n    copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.8/horovod/spark/task\r\n    copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.8/horovod/spark/task\r\n    creating build/lib.linux-x86_64-3.8/horovod/spark/keras\r\n    copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.8/horovod/spark/keras\r\n    copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.8/horovod/spark/keras\r\n    copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.8/horovod/spark/keras\r\n    copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.8/horovod/spark/keras\r\n    copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.8/horovod/spark/keras\r\n    copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.8/horovod/spark/keras\r\n    copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.8/horovod/spark/keras\r\n    creating build/lib.linux-x86_64-3.8/horovod/spark/common\r\n    copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.8/horovod/spark/common\r\n    copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.8/horovod/spark/common\r\n    copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.8/horovod/spark/common\r\n    copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.8/horovod/spark/common\r\n    copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.8/horovod/spark/common\r\n    copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.8/horovod/spark/common\r\n    copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.8/horovod/spark/common\r\n    copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.8/horovod/spark/common\r\n    copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.8/horovod/spark/common\r\n    copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.8/horovod/spark/common\r\n    creating build/lib.linux-x86_64-3.8/horovod/spark/lightning\r\n    copying horovod/spark/lightning/remote.py -> build/lib.linux-x86_64-3.8/horovod/spark/lightning\r\n    copying horovod/spark/lightning/legacy.py -> build/lib.linux-x86_64-3.8/horovod/spark/lightning\r\n    copying horovod/spark/lightning/estimator.py -> build/lib.linux-x86_64-3.8/horovod/spark/lightning\r\n    copying horovod/spark/lightning/__init__.py -> build/lib.linux-x86_64-3.8/horovod/spark/lightning\r\n    copying horovod/spark/lightning/datamodule.py -> build/lib.linux-x86_64-3.8/horovod/spark/lightning\r\n    copying horovod/spark/lightning/util.py -> build/lib.linux-x86_64-3.8/horovod/spark/lightning\r\n    creating build/lib.linux-x86_64-3.8/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.8/horovod/torch/mpi_lib_impl\r\n    creating build/lib.linux-x86_64-3.8/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.8/horovod/torch/mpi_lib\r\n    creating build/lib.linux-x86_64-3.8/horovod/torch/elastic\r\n    copying horovod/torch/elastic/state.py -> build/lib.linux-x86_64-3.8/horovod/torch/elastic\r\n    copying horovod/torch/elastic/__init__.py -> build/lib.linux-x86_64-3.8/horovod/torch/elastic\r\n    copying horovod/torch/elastic/sampler.py -> build/lib.linux-x86_64-3.8/horovod/torch/elastic\r\n    creating build/lib.linux-x86_64-3.8/horovod/runner/driver\r\n    copying horovod/runner/driver/driver_service.py -> build/lib.linux-x86_64-3.8/horovod/runner/driver\r\n    copying horovod/runner/driver/__init__.py -> build/lib.linux-x86_64-3.8/horovod/runner/driver\r\n    creating build/lib.linux-x86_64-3.8/horovod/runner/elastic\r\n    copying horovod/runner/elastic/settings.py -> build/lib.linux-x86_64-3.8/horovod/runner/elastic\r\n    copying horovod/runner/elastic/driver.py -> build/lib.linux-x86_64-3.8/horovod/runner/elastic\r\n    copying horovod/runner/elastic/__init__.py -> build/lib.linux-x86_64-3.8/horovod/runner/elastic\r\n    copying horovod/runner/elastic/worker.py -> build/lib.linux-x86_64-3.8/horovod/runner/elastic\r\n    copying horovod/runner/elastic/discovery.py -> build/lib.linux-x86_64-3.8/horovod/runner/elastic\r\n    copying horovod/runner/elastic/constants.py -> build/lib.linux-x86_64-3.8/horovod/runner/elastic\r\n    copying horovod/runner/elastic/rendezvous.py -> build/lib.linux-x86_64-3.8/horovod/runner/elastic\r\n    copying horovod/runner/elastic/registration.py -> build/lib.linux-x86_64-3.8/horovod/runner/elastic\r\n    creating build/lib.linux-x86_64-3.8/horovod/runner/task\r\n    copying horovod/runner/task/__init__.py -> build/lib.linux-x86_64-3.8/horovod/runner/task\r\n    copying horovod/runner/task/task_service.py -> build/lib.linux-x86_64-3.8/horovod/runner/task\r\n    creating build/lib.linux-x86_64-3.8/horovod/runner/http\r\n    copying horovod/runner/http/http_server.py -> build/lib.linux-x86_64-3.8/horovod/runner/http\r\n    copying horovod/runner/http/http_client.py -> build/lib.linux-x86_64-3.8/horovod/runner/http\r\n    copying horovod/runner/http/__init__.py -> build/lib.linux-x86_64-3.8/horovod/runner/http\r\n    creating build/lib.linux-x86_64-3.8/horovod/runner/util\r\n    copying horovod/runner/util/remote.py -> build/lib.linux-x86_64-3.8/horovod/runner/util\r\n    copying horovod/runner/util/lsf.py -> build/lib.linux-x86_64-3.8/horovod/runner/util\r\n    copying horovod/runner/util/__init__.py -> build/lib.linux-x86_64-3.8/horovod/runner/util\r\n    copying horovod/runner/util/cache.py -> build/lib.linux-x86_64-3.8/horovod/runner/util\r\n    copying horovod/runner/util/streams.py -> build/lib.linux-x86_64-3.8/horovod/runner/util\r\n    copying horovod/runner/util/network.py -> build/lib.linux-x86_64-3.8/horovod/runner/util\r\n    copying horovod/runner/util/threads.py -> build/lib.linux-x86_64-3.8/horovod/runner/util\r\n    creating build/lib.linux-x86_64-3.8/horovod/runner/common\r\n    copying horovod/runner/common/__init__.py -> build/lib.linux-x86_64-3.8/horovod/runner/common\r\n    creating build/lib.linux-x86_64-3.8/horovod/runner/common/service\r\n    copying horovod/runner/common/service/driver_service.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/service\r\n    copying horovod/runner/common/service/__init__.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/service\r\n    copying horovod/runner/common/service/task_service.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/service\r\n    creating build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/codec.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/settings.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/secret.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/__init__.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/config_parser.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/timeout.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/env.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/host_hash.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/network.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/hosts.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/tiny_shell_exec.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    creating build/lib.linux-x86_64-3.8/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.8/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.8/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/elastic.py -> build/lib.linux-x86_64-3.8/horovod/tensorflow/keras\r\n    running build_ext\r\n    Running CMake in build/temp.linux-x86_64-3.8/RelWithDebInfo:\r\n    cmake /tmp/pip-install-o6yhlor8/horovod -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/tmp/pip-install-o6yhlor8/horovod/build/lib.linux-x86_64-3.8 -DPYTHON_EXECUTABLE:FILEPATH=/usr/bin/python3\r\n    cmake --build . --config RelWithDebInfo -- -j8 VERBOSE=1\r\n    -- Could not find CCache. Consider installing CCache to speed up compilation.\r\n    -- The CXX compiler identification is GNU 9.3.0\r\n    -- Check for working CXX compiler: /usr/bin/c++\r\n    -- Check for working CXX compiler: /usr/bin/c++ -- works\r\n    -- Detecting CXX compiler ABI info\r\n    -- Detecting CXX compiler ABI info - done\r\n    -- Detecting CXX compile features\r\n    -- Detecting CXX compile features - done\r\n    -- Build architecture flags: -mf16c -mavx -mfma\r\n    -- Using command /usr/bin/python3\r\n    -- Found MPI_CXX: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so (found version \"3.1\")\r\n    -- Found MPI: TRUE (found version \"3.1\")\r\n    -- Looking for a CUDA compiler\r\n    -- Looking for a CUDA compiler - NOTFOUND\r\n    -- Looking for a CUDA host compiler - /usr/bin/c++\r\n    -- Found CUDAToolkit: /usr/local/cuda/include (found version \"11.1.74\")\r\n    -- Looking for C++ include pthread.h\r\n    -- Looking for C++ include pthread.h - found\r\n    -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\r\n    -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\r\n    -- Found Threads: TRUE\r\n    CUDA compiler was not found in $PATH, but searching again in CUDA Toolkit binary directory\r\n    -- The CUDA compiler identification is NVIDIA 11.1.74\r\n    -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc\r\n    -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc -- works\r\n    -- Detecting CUDA compiler ABI info\r\n    -- Detecting CUDA compiler ABI info - done\r\n    -- Found NVTX: /usr/local/cuda/include\r\n    -- Found NVTX (include: /usr/local/cuda/include, library: dl)\r\n    -- The C compiler identification is GNU 9.3.0\r\n    -- Check for working C compiler: /usr/bin/cc\r\n    -- Check for working C compiler: /usr/bin/cc -- works\r\n    -- Detecting C compiler ABI info\r\n    -- Detecting C compiler ABI info - done\r\n    -- Detecting C compile features\r\n    -- Detecting C compile features - done\r\n    -- Gloo build as STATIC library\r\n    -- Found MPI_C: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so (found version \"3.1\")\r\n    -- Found MPI: TRUE (found version \"3.1\")\r\n    -- MPI include path: /usr/lib/x86_64-linux-gnu/openmpi/include/openmpi/usr/lib/x86_64-linux-gnu/openmpi/include\r\n    -- MPI libraries: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so/usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so\r\n    -- Found Pytorch: 1.9.1+cu111 (found suitable version \"1.9.1+cu111\", minimum required is \"1.2.0\")\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n    ModuleNotFoundError: No module named 'mxnet'\r\n    -- Could NOT find Mxnet (missing: Mxnet_LIBRARIES) (Required is at least version \"1.4.0\")\r\n    -- HVD_NVCC_COMPILE_FLAGS = -O3 -Xcompiler -fPIC -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_62,code=sm_62 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_72,code=sm_72 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_86,code=compute_86\r\n    -- Gloo build as STATIC library\r\n    -- MPI include path: /usr/lib/x86_64-linux-gnu/openmpi/include/openmpi/usr/lib/x86_64-linux-gnu/openmpi/include\r\n    -- MPI libraries: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so/usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so\r\n    -- Configuring done\r\n    You have changed variables that require your cache to be deleted.\r\n    Configure will be re-run and you may have to reset some variables.\r\n    The following variables have changed:\r\n    CMAKE_CUDA_COMPILER= NOTFOUND\r\n    \r\n    -- Could not find CCache. Consider installing CCache to speed up compilation.\r\n    -- The CXX compiler identification is GNU 9.3.0\r\n    -- Check for working CXX compiler: /usr/bin/c++\r\n    -- Check for working CXX compiler: /usr/bin/c++ -- works\r\n    -- Detecting CXX compiler ABI info\r\n    -- Detecting CXX compiler ABI info - done\r\n    -- Detecting CXX compile features\r\n    -- Detecting CXX compile features - done\r\n    -- Build architecture flags: -mf16c -mavx -mfma\r\n    -- Found Python: /usr/bin/python3.8 (found suitable version \"3.8.10\", minimum required is \"3.6\") found components: Interpreter\r\n    -- Using command /usr/bin/python3.8\r\n    -- Found MPI_CXX: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so (found version \"3.1\")\r\n    -- Found MPI: TRUE (found version \"3.1\")\r\n    -- Found CUDAToolkit: /usr/local/cuda/include (found version \"11.1.74\")\r\n    -- Looking for C++ include pthread.h\r\n    -- Looking for C++ include pthread.h - found\r\n    -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\r\n    -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\r\n    -- Found Threads: TRUE\r\n    CUDA compiler was not found in $PATH, but searching again in CUDA Toolkit binary directory\r\n    -- The CUDA compiler identification is NVIDIA 11.1.74\r\n    -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc\r\n    -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc -- works\r\n    -- Detecting CUDA compiler ABI info\r\n    -- Detecting CUDA compiler ABI info - done\r\n    -- Found NVTX: /usr/local/cuda/include\r\n    -- Found NVTX (include: /usr/local/cuda/include, library: dl)\r\n    -- The C compiler identification is GNU 9.3.0\r\n    -- Check for working C compiler: /usr/bin/cc\r\n    -- Check for working C compiler: /usr/bin/cc -- works\r\n    -- Detecting C compiler ABI info\r\n    -- Detecting C compiler ABI info - done\r\n    -- Detecting C compile features\r\n    -- Detecting C compile features - done\r\n    -- Build type not set -- defaulting to Release\r\n    -- Gloo build as STATIC library\r\n    -- Found MPI_C: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so (found version \"3.1\")\r\n    -- Found MPI: TRUE (found version \"3.1\")\r\n    -- MPI include path: /usr/lib/x86_64-linux-gnu/openmpi/include/openmpi/usr/lib/x86_64-linux-gnu/openmpi/include\r\n    -- MPI libraries: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so/usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so\r\n    -- Found Pytorch: 1.9.1+cu111 (found suitable version \"1.9.1+cu111\", minimum required is \"1.2.0\")\r\n    CMake Error at horovod/torch/CMakeLists.txt:18 (file):\r\n      file failed to open for writing (Permission denied):\r\n    \r\n        /metadata.json\r\n    \r\n    \r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n    ModuleNotFoundError: No module named 'mxnet'\r\n    -- Could NOT find Mxnet (missing: Mxnet_LIBRARIES) (Required is at least version \"1.4.0\")\r\n    CMake Error at CMakeLists.txt:345 (file):\r\n      file failed to open for writing (Permission denied):\r\n    \r\n        /metadata.json\r\n    \r\n    \r\n    -- HVD_NVCC_COMPILE_FLAGS = -O3 -Xcompiler -fPIC -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_62,code=sm_62 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_72,code=sm_72 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_86,code=compute_86\r\n    -- Build type not set -- defaulting to Release\r\n    -- Gloo build as STATIC library\r\n    -- MPI include path: /usr/lib/x86_64-linux-gnu/openmpi/include/openmpi/usr/lib/x86_64-linux-gnu/openmpi/include\r\n    -- MPI libraries: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so/usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so\r\n    -- Configuring incomplete, errors occurred!\r\n    See also \"/tmp/pip-install-o6yhlor8/horovod/build/temp.linux-x86_64-3.8/RelWithDebInfo/CMakeFiles/CMakeOutput.log\".\r\n    You have changed variables that require your cache to be deleted.\r\n    Configure will be re-run and you may have to reset some variables.\r\n    The following variables have changed:\r\n    CMAKE_CUDA_COMPILER= NOTFOUND\r\n    \r\n    -- Generating done\r\n    CMake Generate step failed.  Build files cannot be regenerated correctly.\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/tmp/pip-install-o6yhlor8/horovod/setup.py\", line 209, in <module>\r\n        setup(name='horovod',\r\n      File \"/usr/lib/python3/dist-packages/setuptools/__init__.py\", line 144, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/usr/lib/python3.8/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/usr/lib/python3.8/distutils/dist.py\", line 966, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/usr/lib/python3/dist-packages/setuptools/command/install.py\", line 61, in run\r\n        return orig.install.run(self)\r\n      File \"/usr/lib/python3.8/distutils/command/install.py\", line 589, in run\r\n        self.run_command('build')\r\n      File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/usr/lib/python3.8/distutils/command/build.py\", line 135, in run\r\n        self.run_command(cmd_name)\r\n      File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/usr/lib/python3/dist-packages/setuptools/command/build_ext.py\", line 87, in run\r\n        _build_ext.run(self)\r\n      File \"/home/sczone/.local/lib/python3.8/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\r\n        _build_ext.build_ext.run(self)\r\n      File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 340, in run\r\n        self.build_extensions()\r\n      File \"/tmp/pip-install-o6yhlor8/horovod/setup.py\", line 144, in build_extensions\r\n        subprocess.check_call(command, cwd=cmake_build_dir)\r\n      File \"/usr/lib/python3.8/subprocess.py\", line 364, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['cmake', '/tmp/pip-install-o6yhlor8/horovod', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/tmp/pip-install-o6yhlor8/horovod/build/lib.linux-x86_64-3.8', '-DPYTHON_EXECUTABLE:FILEPATH=/usr/bin/python3']' returned non-zero exit status 1.\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-o6yhlor8/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-o6yhlor8/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-zhlcztka/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/sczone/.local/include/python3.8/horovod Check the logs for full command output.\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3545/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3545/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3540", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3540/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3540/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3540/events", "html_url": "https://github.com/horovod/horovod/issues/3540", "id": 1229286773, "node_id": "I_kwDOBfOI785JRW11", "number": 3540, "title": "Pytorch_lightning's TorchEstimator doesn't pass transformation_fn correctly", "user": {"login": "serena-ruan", "id": 82044803, "node_id": "MDQ6VXNlcjgyMDQ0ODAz", "avatar_url": "https://avatars.githubusercontent.com/u/82044803?v=4", "gravatar_id": "", "url": "https://api.github.com/users/serena-ruan", "html_url": "https://github.com/serena-ruan", "followers_url": "https://api.github.com/users/serena-ruan/followers", "following_url": "https://api.github.com/users/serena-ruan/following{/other_user}", "gists_url": "https://api.github.com/users/serena-ruan/gists{/gist_id}", "starred_url": "https://api.github.com/users/serena-ruan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/serena-ruan/subscriptions", "organizations_url": "https://api.github.com/users/serena-ruan/orgs", "repos_url": "https://api.github.com/users/serena-ruan/repos", "events_url": "https://api.github.com/users/serena-ruan/events{/privacy}", "received_events_url": "https://api.github.com/users/serena-ruan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2022-05-09T07:16:11Z", "updated_at": "2022-05-26T08:28:42Z", "closed_at": "2022-05-10T18:39:04Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Pytorch Lightning\r\n2. Framework version: 1.5.0\r\n3. Horovod version: 0.23.0\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. Spark / PySpark version: 3.2.0\r\n9. Ray version:\r\n10. OS and version:\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nPytorch_lightning's TorchEstimator accepts `transformation_fn` as a parameter but it's not actually passing it through petaStormDataModule so that the transformation_fn used in the training/validation is always the default value of `torch.as_tensor`. From the source code I found here (https://github.com/horovod/horovod/blob/464c82ef5307986531909861e01ee1c5b235640a/horovod/spark/lightning/datamodule.py#:~:text=transform_spec%20%3D%20TransformSpec,%3DFalse)) it assigned a value to `transform_spec` but only used it to distinguish the reader type and didn't pass it as a parameter to the reader.\r\n\r\nA reproduce of the problem would be assigning a transformation_fn to horovod.spark.lightning.TorchEstimator and it doesn't use my transformation_fn to transform the row; the same transformation_fn works for horovod.spark.torch.TorchEstimator.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3540/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3540/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3537", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3537/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3537/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3537/events", "html_url": "https://github.com/horovod/horovod/issues/3537", "id": 1227292353, "node_id": "I_kwDOBfOI785JJv7B", "number": 3537, "title": "Can't pip install horovod for rocm 5.0+", "user": {"login": "xiaoyu-work", "id": 85524621, "node_id": "MDQ6VXNlcjg1NTI0NjIx", "avatar_url": "https://avatars.githubusercontent.com/u/85524621?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiaoyu-work", "html_url": "https://github.com/xiaoyu-work", "followers_url": "https://api.github.com/users/xiaoyu-work/followers", "following_url": "https://api.github.com/users/xiaoyu-work/following{/other_user}", "gists_url": "https://api.github.com/users/xiaoyu-work/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiaoyu-work/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiaoyu-work/subscriptions", "organizations_url": "https://api.github.com/users/xiaoyu-work/orgs", "repos_url": "https://api.github.com/users/xiaoyu-work/repos", "events_url": "https://api.github.com/users/xiaoyu-work/events{/privacy}", "received_events_url": "https://api.github.com/users/xiaoyu-work/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2022-05-06T00:10:33Z", "updated_at": "2022-06-30T20:56:48Z", "closed_at": "2022-06-30T20:56:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): PyTorch\r\n2. Framework version: 1.12.0.dev\r\n3. Horovod version: 0.24.2\r\n4. MPI version: 3.1\r\n5. Rocm version: ROCM 5.0+\r\n6. NCCL version:\r\n7. Python version: 3.8\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version: Ubuntu2004\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nWhen I \"pip install horovod\" for rocm 5.0.1 and rocm 5.1.1, got error:\r\n\r\nStacktrace:\r\n```\r\n[pip-requirements.txt]     Found existing installation: numpy 1.    ERROR: Command errored out with exit status 1:\r\n     command: /opt/conda/envs/ptca/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-vd9tp1oy/horovod_8df28208658e45d2bcf35f4cc2a6010c/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-vd9tp1oy/horovod_8df28208658e45d2bcf35f4cc2a6010c/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-h7ut125g/install-record.txt --single-version-externally-managed --compile --install-headers /opt/conda/envs/ptca/include/python3.8/horovod\r\n         cwd: /tmp/pip-install-vd9tp1oy/horovod_8df28208658e45d2bcf35f4cc2a6010c/\r\n    Complete output (280 lines):\r\n    running install\r\n    /opt/conda/envs/ptca/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n      warnings.warn(\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.8\r\n    creating build/lib.linux-x86_64-3.8/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-3.8/horovod\r\n    creating build/lib.linux-x86_64-3.8/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.8/horovod/spark\r\n    copying horovod/spark/mpi_run.py -> build/lib.linux-x86_64-3.8/horovod/spark\r\n    copying horovod/spark/runner.py -> build/lib.linux-x86_64-3.8/horovod/spark\r\n    copying horovod/spark/gloo_run.py -> build/lib.linux-x86_64-3.8/horovod/spark\r\n    copying horovod/spark/conf.py -> build/lib.linux-x86_64-3.8/horovod/spark\r\n........ (skip copying)\r\n    copying horovod/runner/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/settings.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    copying horovod/runner/common/util/secret.py -> build/lib.linux-x86_64-3.8/horovod/runner/common/util\r\n    creating build/lib.linux-x86_64-3.8/horovod/torch/elastic\r\n    copying horovod/torch/elastic/__init__.py -> build/lib.linux-x86_64-3.8/horovod/torch/elastic\r\n    copying horovod/torch/elastic/sampler.py -> build/lib.linux-x86_64-3.8/horovod/torch/elastic\r\n    copying horovod/torch/elastic/state.py -> build/lib.linux-x86_64-3.8/horovod/torch/elastic\r\n    creating build/lib.linux-x86_64-3.8/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.8/horovod/torch/mpi_lib\r\n    creating build/lib.linux-x86_64-3.8/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.8/horovod/torch/mpi_lib_impl\r\n    running build_ext\r\n    Running CMake in build/temp.linux-x86_64-3.8/RelWithDebInfo:\r\n    cmake /tmp/pip-install-vd9tp1oy/horovod_8df28208658e45d2bcf35f4cc2a6010c -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/tmp/pip-install-vd9tp1oy/horovod_8df28208658e45d2bcf35f4cc2a6010c/build/lib.linux-x86_64-3.8 -DPYTHON_EXECUTABLE:FILEPATH=/opt/conda/envs/ptca/bin/python\r\n    cmake --build . --config RelWithDebInfo -- -j8 VERBOSE=1\r\n\r\n    -- Could not find CCache. Consider installing CCache to speed up compilation.\r\n    -- The CXX compiler identification is GNU 9.4.0\r\n    -- Check for working CXX compiler: /usr/bin/c++\r\n    -- Check for working CXX compiler: /usr/bin/c++ -- works\r\n    -- Detecting CXX compiler ABI info\r\n    -- Detecting CXX compiler ABI info - done\r\n    -- Detecting CXX compile features\r\n    -- Detecting CXX compile features - done\r\n    -- Build architecture flags: -mf16c -mavx -mfma\r\n    -- Using command /opt/conda/envs/ptca/bin/python\r\n    -- Found MPI_CXX: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so (found version \"3.1\")\r\n    -- Found MPI: TRUE (found version \"3.1\")\r\n    -- Looking for a CUDA compiler\r\n    -- Looking for a CUDA compiler - NOTFOUND\r\n    -- Looking for a CUDA host compiler - /usr/bin/c++\r\n    -- Could not find nvcc, please set CUDAToolkit_ROOT.\r\n    -- Could NOT find NVTX (missing: NVTX_INCLUDE_DIR)\r\n    -- The C compiler identification is GNU 9.4.0\r\n    -- Check for working C compiler: /usr/bin/cc\r\n    -- Check for working C compiler: /usr/bin/cc -- works\r\n    -- Detecting C compiler ABI info\r\n    -- Detecting C compiler ABI info - done\r\n    -- Detecting C compile features\r\n    -- Detecting C compile features - done\r\n    -- Gloo build as STATIC library\r\n    -- Found MPI_C: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so (found version \"3.1\")\r\n    -- Found MPI: TRUE (found version \"3.1\")\r\n    -- MPI include path: /usr/lib/x86_64-linux-gnu/openmpi/include/openmpi/usr/lib/x86_64-linux-gnu/openmpi/include\r\n    -- MPI libraries: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so/usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n    ModuleNotFoundError: No module named 'tensorflow'\r\n    -- Could NOT find Tensorflow (missing: Tensorflow_LIBRARIES) (Required is at least version \"1.15.0\")\r\n    -- Found Pytorch: 1.12.0.dev20220505+rocm5.0 (found suitable version \"1.12.0.dev20220505+rocm5.0\", minimum required is \"1.2.0\")\r\n    Successfully preprocessed all matching files.\r\n    Total number of unsupported CUDA function calls: 0\r\n    \r\n    Total number of replaced kernel launches: 0\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n    ModuleNotFoundError: No module named 'mxnet'\r\n    -- Could NOT find Mxnet (missing: Mxnet_LIBRARIES) (Required is at least version \"1.4.0\")\r\n    -- Gloo build as STATIC library\r\n    -- MPI include path: /usr/lib/x86_64-linux-gnu/openmpi/include/openmpi/usr/lib/x86_64-linux-gnu/openmpi/include\r\n    -- MPI libraries: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so/usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so\r\n    -- Configuring done\r\n    CMake Error at horovod/torch/CMakeLists.txt:81 (add_library):\r\n      Cannot find source file:\r\n    \r\n        /tmp/pip-install-vd9tp1oy/horovod_8df28208658e45d2bcf35f4cc2a6010c/horovod/torch/ready_event_hip.cc\r\n    \r\n      Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm\r\n      .hpp .hxx .in .txx\r\n    \r\n    \r\n    CMake Error at horovod/torch/CMakeLists.txt:81 (add_library):\r\n      No SOURCES given to target: pytorch\r\n   \r\n    CMake Generate step failed.  Build files cannot be regenerated correctly.\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/tmp/pip-install-vd9tp1oy/horovod_8df28208658e45d2bcf35f4cc2a6010c/setup.py\", line 209, in <module>\r\n        setup(name='horovod',\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/site-packages/setuptools/__init__.py\", line 153, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/distutils/dist.py\", line 966, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/site-packages/setuptools/command/install.py\", line 68, in run\r\n        return orig.install.run(self)\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/distutils/command/install.py\", line 545, in run\r\n        self.run_command('build')\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/distutils/command/build.py\", line 135, in run\r\n        self.run_command(cmd_name)\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/site-packages/setuptools/command/build_ext.py\", line 79, in run\r\n        _build_ext.run(self)\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/distutils/command/build_ext.py\", line 340, in run\r\n        self.build_extensions()\r\n      File \"/tmp/pip-install-vd9tp1oy/horovod_8df28208658e45d2bcf35f4cc2a6010c/setup.py\", line 144, in build_extensions\r\n        subprocess.check_call(command, cwd=cmake_build_dir)\r\n      File \"/opt/conda/envs/ptca/lib/python3.8/subprocess.py\", line 364, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['cmake', '/tmp/pip-install-vd9tp1oy/horovod_8df28208658e45d2bcf35f4cc2a6010c', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/tmp/pip-install-vd9tp1oy/horovod_8df28208658e45d2bcf35f4cc2a6010c/build/lib.linux-x86_64-3.8', '-DPYTHON_EXECUTABLE:FILEPATH=/opt/conda/envs/ptca/bin/python']' returned non-zero exit status 1.\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /opt/conda/envs/ptca/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-vd9tp1oy/horovod_8df28208658e45d2bcf35f4cc2a6010c/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-vd9tp1oy/horovod_8df28208658e45d2bcf35f4cc2a6010c/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-h7ut125g/install-record.txt --single-version-externally-managed --compile --install-headers /opt/conda/envs/ptca/include/python3.8/horovod Check the logs for full command output.\r\n22.3\r\n```\r\n\r\nError as above. I tried ROCM 5.0.1 and ROCM 5.1.1, and both failed.\r\n\r\nCan you please take a look?\r\n\r\nThanks\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3537/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3537/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3511", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3511/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3511/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3511/events", "html_url": "https://github.com/horovod/horovod/issues/3511", "id": 1208647210, "node_id": "I_kwDOBfOI785ICn4q", "number": 3511, "title": "Horovod installation for TF CPU nightly fails with error: no member \"tensorflow_gpu_device_info\"!", "user": {"login": "ashahba", "id": 12436063, "node_id": "MDQ6VXNlcjEyNDM2MDYz", "avatar_url": "https://avatars.githubusercontent.com/u/12436063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ashahba", "html_url": "https://github.com/ashahba", "followers_url": "https://api.github.com/users/ashahba/followers", "following_url": "https://api.github.com/users/ashahba/following{/other_user}", "gists_url": "https://api.github.com/users/ashahba/gists{/gist_id}", "starred_url": "https://api.github.com/users/ashahba/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ashahba/subscriptions", "organizations_url": "https://api.github.com/users/ashahba/orgs", "repos_url": "https://api.github.com/users/ashahba/repos", "events_url": "https://api.github.com/users/ashahba/events{/privacy}", "received_events_url": "https://api.github.com/users/ashahba/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2022-04-19T17:24:41Z", "updated_at": "2022-04-21T01:08:25Z", "closed_at": "2022-04-21T01:08:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. TensorFlow\r\n2. Framework version: 2.10 nightly\r\n3. Horovod version: 0.24.2 all the way up to tip of master\r\n4. MPI version: 4.0.3\r\n5. CUDA version: N/A this is CPU install\r\n6. NCCL version: N/A\r\n7. Python version: 3.8.10\r\n8. Spark / PySpark version: N/A\r\n9. Ray version: N/A\r\n10. OS and version: Ubuntu 20.04.4 LTS\r\n11. GCC version: 9.4.0\r\n12. CMake version: 3.16.3\r\n\r\nWhile installing any version of Horovod from `0.24.2` all the way up to tip of `master` branch and with the following settings I get:\r\n\r\n```\r\n# Install Horovod\r\nexport HOROVOD_WITHOUT_PYTORCH=1\r\nexport HOROVOD_WITHOUT_MXNET=1\r\nexport HOROVOD_WITH_TENSORFLOW=1\r\nexport HOROVOD_VERSION=v0.24.2\r\n```\r\n\r\nand then:\r\n```\r\npython3 -m pip install git+https://github.com/horovod/horovod.git@${HOROVOD_VERSION}\r\n```\r\n\r\nand I'm getting this error during installation:\r\n```\r\n/tmp/pip-req-build-xs138tj2/horovod/common/ops/gloo_operations.h:51:8:   required from here\r\n  /tmp/pip-req-build-xs138tj2/third_party/gloo/gloo/math.h:20:22: warning: comparison of integer expressions of different signedness: \u00e2\u20ac\u02dcint\u00e2\u20ac\u2122 and \u00e2\u20ac\u02dcsize_t\u00e2\u20ac\u2122 {aka \u00e2\u20ac\u02dclong unsigned int\u00e2\u20ac\u2122} [-Wsign-compare]\r\n  [ 99%] Building CXX object horovod/tensorflow/CMakeFiles/tensorflow.dir/mpi_ops.cc.o\r\n  cd /tmp/pip-req-build-xs138tj2/build/temp.linux-x86_64-cpython-38/RelWithDebInfo/horovod/tensorflow && /usr/bin/c++  -DEIGEN_MPL2_ONLY=1 -DHAVE_GLOO=1 -DHAVE_MPI=1 -DTENSORFLOW_VERSION=2010000000 -Dtensorflow_EXPORTS -I/tmp/pip-req-build-xs138tj2/third_party/HTTPRequest/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/assert/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/config/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/core/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/detail/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/iterator/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/lockfree/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/mpl/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/parameter/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/predef/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/preprocessor/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/static_assert/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/type_traits/include -I/tmp/pip-req-build-xs138tj2/third_party/boost/utility/include -I/tmp/pip-req-build-xs138tj2/third_party/lbfgs/include -I/tmp/pip-req-build-xs138tj2/third_party/gloo -I/tmp/pip-req-build-xs138tj2/third_party/flatbuffers/include -isystem /usr/lib/x86_64-linux-gnu/openmpi/include/openmpi -isystem /usr/lib/x86_64-linux-gnu/openmpi/include -isystem /usr/local/lib/python3.8/dist-packages/tensorflow/include  -I/usr/local/lib/python3.8/dist-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0 -DEIGEN_MAX_ALIGN_BYTES=64  -pthread -fPIC -Wall -ftree-vectorize -mf16c -mavx -mfma -O3 -g -DNDEBUG -fPIC   -std=c++14 -o CMakeFiles/tensorflow.dir/mpi_ops.cc.o -c /tmp/pip-req-build-xs138tj2/horovod/tensorflow/mpi_ops.cc\r\n  /tmp/pip-req-build-xs138tj2/horovod/tensorflow/mpi_ops.cc: In function \u00e2\u20ac\u02dcint horovod::tensorflow::{anonymous}::GetDeviceID(tensorflow::OpKernelContext*)\u00e2\u20ac\u2122:\r\n  /tmp/pip-req-build-xs138tj2/horovod/tensorflow/mpi_ops.cc:389:26: error: \u00e2\u20ac\u02dcclass tensorflow::DeviceBase\u00e2\u20ac\u2122 has no member named \u00e2\u20ac\u02dctensorflow_gpu_device_info\u00e2\u20ac\u2122; did you mean \u00e2\u20ac\u02dctensorflow_accelerator_device_info\u00e2\u20ac\u2122?\r\n         context->device()->tensorflow_gpu_device_info() != nullptr) {\r\n                            ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\n                            tensorflow_accelerator_device_info\r\n  /tmp/pip-req-build-xs138tj2/horovod/tensorflow/mpi_ops.cc:390:33: error: \u00e2\u20ac\u02dcclass tensorflow::DeviceBase\u00e2\u20ac\u2122 has no member named \u00e2\u20ac\u02dctensorflow_gpu_device_info\u00e2\u20ac\u2122; did you mean \u00e2\u20ac\u02dctensorflow_accelerator_device_info\u00e2\u20ac\u2122?\r\n       device = context->device()->tensorflow_gpu_device_info()->gpu_id;\r\n                                   ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\n                                   tensorflow_accelerator_device_info\r\n  /tmp/pip-req-build-xs138tj2/horovod/tensorflow/mpi_ops.cc: At global scope:\r\n  /tmp/pip-req-build-xs138tj2/horovod/tensorflow/mpi_ops.cc:384:18: warning: \u00e2\u20ac\u02dctensorflow::OpKernelContext* horovod::tensorflow::{anonymous}::TFOpContext::GetKernelContext() const\u00e2\u20ac\u2122 defined but not used [-Wunused-function]\r\n   OpKernelContext* TFOpContext::GetKernelContext() const { return context_; }\r\n                    ^~~~~~~~~~~\r\n  /tmp/pip-req-build-xs138tj2/horovod/tensorflow/mpi_ops.cc:293:30: warning: \u00e2\u20ac\u02dcconst tensorflow::Tensor* horovod::tensorflow::{anonymous}::TFTensor::tensor() const\u00e2\u20ac\u2122 defined but not used [-Wunused-function]\r\n   const ::tensorflow::Tensor*  TFTensor::tensor() const { return &tensor_; }\r\n                                ^~~~~~~~\r\n  make[2]: *** [horovod/tensorflow/CMakeFiles/tensorflow.dir/build.make:453: horovod/tensorflow/CMakeFiles/tensorflow.dir/mpi_ops.cc.o] Error 1\r\n  make[2]: Leaving directory '/tmp/pip-req-build-xs138tj2/build/temp.linux-x86_64-cpython-38/RelWithDebInfo'\r\n  make[1]: *** [CMakeFiles/Makefile2:443: horovod/tensorflow/CMakeFiles/tensorflow.dir/all] Error 2\r\n  make[1]: Leaving directory '/tmp/pip-req-build-xs138tj2/build/temp.linux-x86_64-cpython-38/RelWithDebInfo'\r\n  make: *** [Makefile:130: all] Error 2\r\n  Traceback (most recent call last):\r\n    File \"<string>\", line 1, in <module>\r\n    File \"/tmp/pip-req-build-xs138tj2/setup.py\", line 166, in <module>\r\n      setup(name='horovod',\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/__init__.py\", line 87, in setup\r\n      return distutils.core.setup(**attrs)\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/core.py\", line 148, in setup\r\n      return run_commands(dist)\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/core.py\", line 163, in run_commands\r\n      dist.run_commands()\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/dist.py\", line 967, in run_commands\r\n      self.run_command(cmd)\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/dist.py\", line 1214, in run_command\r\n      super().run_command(command)\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/dist.py\", line 986, in run_command\r\n      cmd_obj.run()\r\n    File \"/usr/lib/python3/dist-packages/wheel/bdist_wheel.py\", line 223, in run\r\n      self.run_command('build')\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/dist.py\", line 1214, in run_command\r\n      super().run_command(command)\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/dist.py\", line 986, in run_command\r\n      cmd_obj.run()\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/command/build.py\", line 136, in run\r\n      self.run_command(cmd_name)\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/dist.py\", line 1214, in run_command\r\n      super().run_command(command)\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/dist.py\", line 986, in run_command\r\n      cmd_obj.run()\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/build_ext.py\", line 79, in run\r\n      _build_ext.run(self)\r\n    File \"/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/command/build_ext.py\", line 339, in run\r\n      self.build_extensions()\r\n    File \"/tmp/pip-req-build-xs138tj2/setup.py\", line 100, in build_extensions\r\n      subprocess.check_call([cmake_bin, '--build', '.'] + cmake_build_args,\r\n    File \"/usr/lib/python3.8/subprocess.py\", line 364, in check_call\r\n      raise CalledProcessError(retcode, cmd)\r\n  subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--config', 'RelWithDebInfo', '--', 'VERBOSE=1']' returned non-zero exit status 2.\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n  Running setup.py clean for horovod\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3511/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3511/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3504", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3504/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3504/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3504/events", "html_url": "https://github.com/horovod/horovod/issues/3504", "id": 1194043077, "node_id": "I_kwDOBfOI785HK6bF", "number": 3504, "title": "hvd.DistributedOptimizer gradient accumulation doesn't clean up infinite gradient correctly", "user": {"login": "yundai424", "id": 43726198, "node_id": "MDQ6VXNlcjQzNzI2MTk4", "avatar_url": "https://avatars.githubusercontent.com/u/43726198?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yundai424", "html_url": "https://github.com/yundai424", "followers_url": "https://api.github.com/users/yundai424/followers", "following_url": "https://api.github.com/users/yundai424/following{/other_user}", "gists_url": "https://api.github.com/users/yundai424/gists{/gist_id}", "starred_url": "https://api.github.com/users/yundai424/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yundai424/subscriptions", "organizations_url": "https://api.github.com/users/yundai424/orgs", "repos_url": "https://api.github.com/users/yundai424/repos", "events_url": "https://api.github.com/users/yundai424/events{/privacy}", "received_events_url": "https://api.github.com/users/yundai424/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-04-06T05:12:54Z", "updated_at": "2022-04-15T17:39:00Z", "closed_at": "2022-04-15T17:39:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Keras\r\n2. Framework version: 2.4\r\n3. Horovod version: 2.3\r\n4. MPI version: \r\n5. CUDA version: \r\n6. NCCL version:\r\n7. Python version:\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version:\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\n\r\nWe were training in TensorFlow [FP16 mixed precision](https://www.tensorflow.org/guide/mixed_precision) with keras `model.fit()` and with gradient accumulation/aggregation (`backward_pass_per_step` in `hvd.DistributedOptimizer`) and noticed that the [GradientAggregationHelperEager](https://github.com/horovod/horovod/blob/master/horovod/tensorflow/gradient_aggregation_eager.py#L8) doesn't work correctly with FP16 when the loss goes infinite. Details:\r\n\r\nIt is kind of expected that at the very first 2-15 steps of the training, the gradient out of TF [LossScaleOptimizer](https://github.com/keras-team/keras/blob/v2.8.0/keras/mixed_precision/loss_scale_optimizer.py#L258-L844) is infinite (because the default initial loss scale factor is as large as `2**15`). Dynamic LSO can handle this gracefully, it just skips applying gradient of that step and divides the scale factor by half. However horovod GradientAggregationHelper will anyway add the infinite gradient up locally, and the infinite gradient will never be correctly cleaned up in [this way](https://github.com/horovod/horovod/blob/133ef0725253db83cfb82a4ed4003df76d189829/horovod/tensorflow/gradient_aggregation_eager.py#L119-L123):\r\n```\r\n    def _clear_vars(self):\r\n        self.counter.assign(0)\r\n        for idx in self.locally_aggregated_grads.keys():\r\n            self.locally_aggregated_grads[idx].assign_add(\r\n                -1 * self.locally_aggregated_grads[idx])\r\n```\r\n\r\nas the result of adding inf value by its negative val will be NaN. \r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3504/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3504/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3501", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3501/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3501/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3501/events", "html_url": "https://github.com/horovod/horovod/issues/3501", "id": 1190555539, "node_id": "I_kwDOBfOI785G9m-T", "number": 3501, "title": "Is there a problem with ProcessSetTable Finalize when elastic?", "user": {"login": "Richie-yan", "id": 41471499, "node_id": "MDQ6VXNlcjQxNDcxNDk5", "avatar_url": "https://avatars.githubusercontent.com/u/41471499?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Richie-yan", "html_url": "https://github.com/Richie-yan", "followers_url": "https://api.github.com/users/Richie-yan/followers", "following_url": "https://api.github.com/users/Richie-yan/following{/other_user}", "gists_url": "https://api.github.com/users/Richie-yan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Richie-yan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Richie-yan/subscriptions", "organizations_url": "https://api.github.com/users/Richie-yan/orgs", "repos_url": "https://api.github.com/users/Richie-yan/repos", "events_url": "https://api.github.com/users/Richie-yan/events{/privacy}", "received_events_url": "https://api.github.com/users/Richie-yan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-04-02T08:23:35Z", "updated_at": "2022-05-12T03:16:01Z", "closed_at": "2022-05-12T03:16:01Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Background:\r\nSuppose there are currently 4 ranks on 4 machines\r\nDue to the failure of machine 1, rank1 exits directly, and the final shutdown: logic is not executed\r\nThen the remaining machines will perform the shutdown operation in the case of  elasticity, and will call process_set_table.Finalize function. this function uses allgather to determine whether the process set needs to be removed, but at this time rank1 has already exited, then allgather operation should theoretically cause the remaining processes to be abnormal, so that the shutdown cannot be normal and elastic cannot be normal.\r\n@maxhgerlach ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3501/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3501/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3481", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3481/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3481/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3481/events", "html_url": "https://github.com/horovod/horovod/issues/3481", "id": 1174524706, "node_id": "I_kwDOBfOI785GAdMi", "number": 3481, "title": "Multi-nodes recognized as one node", "user": {"login": "takahh", "id": 6489519, "node_id": "MDQ6VXNlcjY0ODk1MTk=", "avatar_url": "https://avatars.githubusercontent.com/u/6489519?v=4", "gravatar_id": "", "url": "https://api.github.com/users/takahh", "html_url": "https://github.com/takahh", "followers_url": "https://api.github.com/users/takahh/followers", "following_url": "https://api.github.com/users/takahh/following{/other_user}", "gists_url": "https://api.github.com/users/takahh/gists{/gist_id}", "starred_url": "https://api.github.com/users/takahh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/takahh/subscriptions", "organizations_url": "https://api.github.com/users/takahh/orgs", "repos_url": "https://api.github.com/users/takahh/repos", "events_url": "https://api.github.com/users/takahh/events{/privacy}", "received_events_url": "https://api.github.com/users/takahh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2022-03-20T12:02:14Z", "updated_at": "2022-03-21T19:54:17Z", "closed_at": "2022-03-21T19:54:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) TF\r\n2. Framework version: 2.4.0\r\n3. Horovod version: 0.24.2\r\n4. MPI version:3.1.4\r\n5. CUDA version:11.2.146\r\n6. NCCL version:2.8.4\r\n7. Python version:3.8.3\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version:Linux SUSE\r\n11. GCC version:8.3.0\r\n12. CMake version:3.22.2\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? \r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n[tape_aug_full.txt](https://github.com/horovod/horovod/files/8311164/tape_aug_full.txt)\r\n\r\nInstallation was ok but when I ran the horovodrun with two nodes (one GPU for each), 2GPUs in total.\r\nThe two GPU were recognized as two GPUs in the same node and I got OOM. The output is attached. Thank you.\r\n\r\n#######\r\nHorovod v0.24.2:\r\n\r\nAvailable Frameworks:\r\n    [X] TensorFlow\r\n    [X] PyTorch\r\n    [ ] MXNet\r\n\r\nAvailable Controllers:\r\n    [X] MPI\r\n    [ ] Gloo\r\n\r\nAvailable Tensor Operations:\r\n    [X] NCCL\r\n    [ ] DDL\r\n    [ ] CCL\r\n    [X] MPI\r\n    [ ] Gloo    ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3481/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3481/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3469", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3469/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3469/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3469/events", "html_url": "https://github.com/horovod/horovod/issues/3469", "id": 1170635695, "node_id": "I_kwDOBfOI785Fxnuv", "number": 3469, "title": "Rank() returns all zero on multi-GPU", "user": {"login": "takahh", "id": 6489519, "node_id": "MDQ6VXNlcjY0ODk1MTk=", "avatar_url": "https://avatars.githubusercontent.com/u/6489519?v=4", "gravatar_id": "", "url": "https://api.github.com/users/takahh", "html_url": "https://github.com/takahh", "followers_url": "https://api.github.com/users/takahh/followers", "following_url": "https://api.github.com/users/takahh/following{/other_user}", "gists_url": "https://api.github.com/users/takahh/gists{/gist_id}", "starred_url": "https://api.github.com/users/takahh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/takahh/subscriptions", "organizations_url": "https://api.github.com/users/takahh/orgs", "repos_url": "https://api.github.com/users/takahh/repos", "events_url": "https://api.github.com/users/takahh/events{/privacy}", "received_events_url": "https://api.github.com/users/takahh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2022-03-16T07:20:38Z", "updated_at": "2022-03-17T02:38:39Z", "closed_at": "2022-03-17T02:38:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.4.0\r\n3. Horovod version: 0.23.0\r\n4. MPI version: 3.1.4\r\n5. CUDA version: 11.0.194\r\n6. NCCL version: 2.8.4\r\n7. Python version: 3.6.5\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version: SuSE Linux ES12 SP2\r\n11. GCC version: 8.3 or 4.8??\r\n12. CMake version: 3.22.3\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? -\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? -\r\n4. Did you check if you question is answered in the [troubleshooting guide] Yes (https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nI am using the university's HPC. Multi nodes and GPUs. I got no error but noticed that the rank() always returns zero in any server in multi-nodes calculations. I cannot know server names in advance, so I did not use -H option. \r\n\r\nHere is the script for submitting a job to the HPC.\r\n<pre><code>\r\n#!/bin/bash\r\n#$ -cwd\r\n#$ -l q_node=2\r\n#$ -l h_rt=1:00:00\r\n#$ -p -4\r\n#$ -N ftest\r\n\r\n. /etc/profile.d/modules.sh\r\nsource /home/2/18D38035/.bashrc\r\nconda activate myenv\r\nmodule load python/3.8.3\r\nmodule load python/3.6.5\r\nmodule load cuda/11.0.194\r\n#module load cuda/11.2.146\r\nmodule load nccl/2.8.4\r\nmodule load intel openmpi\r\nmpirun --version\r\nmodule load cudnn/8.1\r\nmodule load tensorflow/2.4.1\r\nmodule load gcc/8.3\r\n\r\nexport PATH=$PATH:/home/2/18D38035/.local/bin\r\nexport PATH=\"/gs/hs0/tga-science/kimura/transformer_tape_dnabert/cmake-3.22.2/bin/:$PATH\"\r\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/home/2/18D38035/.local/\"\r\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/gs/hs0/tga-science/kimura/transformer_tape_dnabert:/gs/hs0/tga-science/kimura/transformer_tape_dnabert/anaconda/envs/myenv/x86_64-conda-linux-gnu/lib/\"\r\nexport PYTHONPATH=\"$PYTHONPATH:/gs/hs0/tga-science/kimura/transformer_tape_dnabert/horovod\"\r\n\r\npython -m pip install --user --upgrade pip\r\npython -m pip install --user --upgrade cmake\r\npython -m pip install --user numpy --upgrade\r\npip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl\r\nalias cmake='/gs/hs0/tga-science/kimura/transformer_tape_dnabert/bin/cmake'\r\n/gs/hs0/tga-science/kimura/transformer_tape_dnabert/anaconda/bin/conda install gcc_linux-64 gxx_linux-64\r\n\r\ncd /gs/hs0/tga-science/kimura/transformer_tape_dnabert/horovod\r\n\r\nHOROVOD_GPU_OPERATIONS=NCCL HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITHOUT_MXNET=1 NCCL_INCLUDE_DIR=/home/2/18D38035/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/nccl NCCL_LIBRARY=/home/2/18D38035/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/ncclpip install horovod -v -e .\r\n\r\nln -s /home/2/18D38035/.local/lib/libpython3.6m.so.1.0 /gs/hs0/tga-science/kimura/transformer_tape_dnabert/libpython3.6m.a\r\n\r\nmpirun -np 2 -npernode 1 -bind-to none -x LD_LIBRARY_PATH -x NCCL_DEBUG=INFO -mca pml ob1 -mca btl ^openib python /gs/hs0/tga-science/kimura/transformer_tape_dnabert/python/multi_nodes/multi_nodes.py</pre></code>\r\n\r\nThank you!", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3469/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3469/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3465", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3465/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3465/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3465/events", "html_url": "https://github.com/horovod/horovod/issues/3465", "id": 1164727382, "node_id": "I_kwDOBfOI785FbFRW", "number": 3465, "title": "On the clang-format check of the project", "user": {"login": "GHGmc2", "id": 6487326, "node_id": "MDQ6VXNlcjY0ODczMjY=", "avatar_url": "https://avatars.githubusercontent.com/u/6487326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GHGmc2", "html_url": "https://github.com/GHGmc2", "followers_url": "https://api.github.com/users/GHGmc2/followers", "following_url": "https://api.github.com/users/GHGmc2/following{/other_user}", "gists_url": "https://api.github.com/users/GHGmc2/gists{/gist_id}", "starred_url": "https://api.github.com/users/GHGmc2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GHGmc2/subscriptions", "organizations_url": "https://api.github.com/users/GHGmc2/orgs", "repos_url": "https://api.github.com/users/GHGmc2/repos", "events_url": "https://api.github.com/users/GHGmc2/events{/privacy}", "received_events_url": "https://api.github.com/users/GHGmc2/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-03-10T04:08:52Z", "updated_at": "2022-04-26T18:13:52Z", "closed_at": "2022-04-26T18:13:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "I noticed that horovod use [clang-format](https://clang.llvm.org/docs/ClangFormat.html) to format C++ code.\r\n\r\nBut when I check the project with clang-format-12, I still got many errors. The cmd I used as below:\r\n```bash\r\n#!/usr/bin/env bash\r\n\r\nfor src in $(find ./horovod -name \"*.h\" -or -name \"*.cc\")\r\ndo\r\n clang-format-12 -style=file ${src}\r\ndone\r\n```\r\n\r\nAnd the output as attached [hvd_cf12.txt](https://github.com/horovod/horovod/files/8220236/hvd_cf12.txt).\r\n\r\nMay I know did I use the wrong clang-format version, or the cmd is not right?\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3465/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3465/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3463", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3463/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3463/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3463/events", "html_url": "https://github.com/horovod/horovod/issues/3463", "id": 1164662484, "node_id": "I_kwDOBfOI785Fa1bU", "number": 3463, "title": "DeadBlock", "user": {"login": "ForawardStar", "id": 32625467, "node_id": "MDQ6VXNlcjMyNjI1NDY3", "avatar_url": "https://avatars.githubusercontent.com/u/32625467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ForawardStar", "html_url": "https://github.com/ForawardStar", "followers_url": "https://api.github.com/users/ForawardStar/followers", "following_url": "https://api.github.com/users/ForawardStar/following{/other_user}", "gists_url": "https://api.github.com/users/ForawardStar/gists{/gist_id}", "starred_url": "https://api.github.com/users/ForawardStar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ForawardStar/subscriptions", "organizations_url": "https://api.github.com/users/ForawardStar/orgs", "repos_url": "https://api.github.com/users/ForawardStar/repos", "events_url": "https://api.github.com/users/ForawardStar/events{/privacy}", "received_events_url": "https://api.github.com/users/ForawardStar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-03-10T02:27:08Z", "updated_at": "2022-04-26T18:07:25Z", "closed_at": "2022-04-26T18:07:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch + apex\r\n2. Framework version: PyTorch1.7\r\n3. Horovod version:  \r\n4. MPI version:  openmpi4.0.3\r\n5. CUDA version: CUDA 10.1\r\n6. NCCL version: NCCL 2.5.6\r\n7. Python version: Python 3.6\r\n8. OS and version: Linux\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? yes\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? yes\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? yes\r\n\r\n**Bug report:**\r\nI train a deep learning model using one machine four cards (the code is from https://github.com/ChenRocks/UNITER), but a deadblock error occurred when I launched the training process. The error information are as follows:\r\n\r\n```\r\n<stderr>:[2022-03-09 22:07:00. 25729: W /tmp/pip-install-va4zflcj/horovod_55d8c8a132ee4aa98a318e155c0a1689/horovod/common/stall_inspector.cc:105] One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock.\r\n\r\n2022-03-09 22:07:00.025 [1,0]<stderr>:Missing ranks:\r\n\r\n2022-03-09 22:07:00.025 [1,0]<stderr>:0: [broadcast.noname.1]\r\n\r\n2022-03-09 22:07:00.025 [1,0]<stderr>:1: [broadcast.noname.1]\r\n\r\n2022-03-09 22:07:00.025 [1,0]<stderr>:2: [broadcast.noname.1]\r\n\r\n\r\n```\r\nHow can I fix this error? Thanks.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3463/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3463/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3461", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3461/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3461/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3461/events", "html_url": "https://github.com/horovod/horovod/issues/3461", "id": 1164427526, "node_id": "I_kwDOBfOI785FZ8EG", "number": 3461, "title": "pytorch model weight updates aren't averaged when running on GKE", "user": {"login": "ioga", "id": 839187, "node_id": "MDQ6VXNlcjgzOTE4Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/839187?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ioga", "html_url": "https://github.com/ioga", "followers_url": "https://api.github.com/users/ioga/followers", "following_url": "https://api.github.com/users/ioga/following{/other_user}", "gists_url": "https://api.github.com/users/ioga/gists{/gist_id}", "starred_url": "https://api.github.com/users/ioga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ioga/subscriptions", "organizations_url": "https://api.github.com/users/ioga/orgs", "repos_url": "https://api.github.com/users/ioga/repos", "events_url": "https://api.github.com/users/ioga/events{/privacy}", "received_events_url": "https://api.github.com/users/ioga/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-03-09T20:51:57Z", "updated_at": "2022-03-11T17:19:34Z", "closed_at": "2022-03-11T17:19:34Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: torch 1.9 / torch 1.10.2\r\n3. Horovod version: 0.24.0, 0.24.1; worked okay in 0.23.0\r\n5. CUDA version: cuda 11.1 / cuda 11.3\r\n\r\nRunning on GKE \"Regular\" channel 1.21.6-gke.1503, nvidia drivers 450.119.04, 4 x Tesla K80\r\n\r\nExample docker image: `determinedai/environments-dev:cuda-11.3-pytorch-1.10-lightning-1.5-tf-2.8-gpu-3da66d1`, built on top of `nvidia/cuda:11.3.1-cudnn8-devel-ubuntu18.04`.\r\n\r\n**Bug report:**\r\nModel weights updates are seemingly not averaged between workers, but summed up instead: when running with 2 workers, updates are 2x what they are supposed to be, when running with 4 workers, it's 4x etc.\r\n\r\nThis is only reproducible when running on GKE. Same exact build runs okay on a plain instance running same version of nvidia drivers 450.119.04, and same GPU (Tesla K80).\r\n\r\nTest script is the same as in #3460 \r\n```\r\nfrom typing import Any, Dict, Tuple\r\n\r\nimport torch.utils.data\r\nimport horovod.torch as hvd\r\n\r\nhvd.init()\r\ntorch.cuda.set_device(hvd.local_rank())\r\n\r\nclass OnesDataset(torch.utils.data.Dataset):\r\n    def __len__(self) -> int:\r\n        return 64\r\n\r\n    def __getitem__(self, index: int) -> Tuple:\r\n        return torch.Tensor([float(1)])\r\n\r\ntrain_dataset = OnesDataset()\r\n\r\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16)\r\n\r\nmodel = torch.nn.Linear(1, 1, False)\r\nmodel.weight.data.fill_(0)\r\nmodel = model.cuda()\r\n\r\nloss_fn = torch.nn.MSELoss()\r\n\r\noptimizer = torch.optim.SGD(model.parameters(), 0.1)\r\noptimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters())\r\n\r\nhvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\n\r\nfor epoch in range(1):\r\n    for batch_idx, data in enumerate(train_loader):\r\n        data = data.cuda()\r\n        optimizer.zero_grad()\r\n        output = model(data)\r\n        loss = loss_fn(output, data)\r\n        loss.backward()\r\n        optimizer.step()\r\n        if hvd.rank() == 0:\r\n            weight = model.weight.data.item()\r\n            print('weight:', weight)\r\n```\r\n\r\n**Actual behavior:**\r\n\r\nRunning `horovodrun -np 2 python train.py` outputs: \r\n```[0]<stdout>:weight: 0.4000000059604645\r\n[0]<stdout>:weight: 0.64000004529953\r\n[0]<stdout>:weight: 0.784000039100647\r\n[0]<stdout>:weight: 0.8704000115394592\r\n```\r\n\r\n**Expected behavior:**\r\n\r\nRunning the same on a plain setup works okay: \r\n```\r\n[0]<stdout>:weight: 0.20000000298023224\r\n[0]<stdout>:weight: 0.36000001430511475\r\n[0]<stdout>:weight: 0.4880000054836273\r\n[0]<stdout>:weight: 0.590399980545044\r\n```\r\n\r\nNotice that the weight difference between steps is 2x when running `-np 2` between expected and actual behaviors.\r\n\r\n**Troubleshooting:**\r\n\r\n- I've bisected horovod from 0.23.0 to 0.24.1 and tracked it down to this specific PR which refactored cmake & CUDA configuration: #3261 . Somehow this affects the computation, but only at runtime on GKE. I couldn't repro it anywhere else.\r\n- Same nvidia-drivers version 450.119.04 on a plain instance worked okay.\r\n- Building with `MAKEFLAGS=-j1` didn't help.\r\n- I've tried out official `horovod/horovod:0.24.1` images and discovered #3460 in the process. But what's especially weird, when running `horovod/horovod:0.24.1` on GKE, the weight updates have both issues (this one and #3460 - not updating weights). So with two workers, the weights are double what they're supposed to be and also not updating:\r\n```\r\n[1,0]<stdout>:weight: 0.4000000059604645                                                                                 \r\n[1,0]<stdout>:weight: 0.4000000059604645                                                                                 \r\n[1,0]<stdout>:weight: 0.4000000059604645                                                                                 \r\n[1,0]<stdout>:weight: 0.4000000059604645\r\n```\r\n\r\nAny ideas what can be causing this? And how exactly changes from #3261 can be affecting this *at runtime*?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3461/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3461/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3460", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3460/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3460/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3460/events", "html_url": "https://github.com/horovod/horovod/issues/3460", "id": 1164314995, "node_id": "I_kwDOBfOI785FZglz", "number": 3460, "title": "pytorch model weights aren't updated properly in `horovod/horovod:0.24.1` docker image", "user": {"login": "ioga", "id": 839187, "node_id": "MDQ6VXNlcjgzOTE4Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/839187?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ioga", "html_url": "https://github.com/ioga", "followers_url": "https://api.github.com/users/ioga/followers", "following_url": "https://api.github.com/users/ioga/following{/other_user}", "gists_url": "https://api.github.com/users/ioga/gists{/gist_id}", "starred_url": "https://api.github.com/users/ioga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ioga/subscriptions", "organizations_url": "https://api.github.com/users/ioga/orgs", "repos_url": "https://api.github.com/users/ioga/repos", "events_url": "https://api.github.com/users/ioga/events{/privacy}", "received_events_url": "https://api.github.com/users/ioga/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-03-09T18:51:37Z", "updated_at": "2022-03-10T15:05:27Z", "closed_at": "2022-03-10T15:05:27Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n3. Horovod version: \"official\" docker images for 0.24.0 and 0.24.1\r\n13. Host: ubuntu 18.04, Docker 20.10.12, nvidia drivers 470.103.01, 8 x Tesla K80\r\n\r\n**Bug report:**\r\nIn the recent \"official\" `horovod/horovod:0.24.1` docker image, model weights doesn't seem to be updated properly between iterations. \r\n\r\nTest script:\r\n```\r\nfrom typing import Any, Dict, Tuple\r\n\r\nimport torch.utils.data\r\nimport horovod.torch as hvd\r\n\r\nhvd.init()\r\ntorch.cuda.set_device(hvd.local_rank())\r\n\r\nclass OnesDataset(torch.utils.data.Dataset):\r\n    def __len__(self) -> int:\r\n        return 64\r\n\r\n    def __getitem__(self, index: int) -> Tuple:\r\n        return torch.Tensor([float(1)])\r\n\r\ntrain_dataset = OnesDataset()\r\n\r\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16)\r\n\r\nmodel = torch.nn.Linear(1, 1, False)\r\nmodel.weight.data.fill_(0)\r\nmodel = model.cuda()\r\n\r\nloss_fn = torch.nn.MSELoss()\r\n\r\noptimizer = torch.optim.SGD(model.parameters(), 0.1)\r\noptimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters())\r\n\r\nhvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\n\r\nfor epoch in range(1):\r\n    for batch_idx, data in enumerate(train_loader):\r\n        data = data.cuda()\r\n        optimizer.zero_grad()\r\n        output = model(data)\r\n        loss = loss_fn(output, data)\r\n        loss.backward()\r\n        optimizer.step()\r\n        if hvd.rank() == 0:\r\n            weight = model.weight.data.item()\r\n            print('weight:', weight)\r\n```\r\n\r\nRunning `horovodrun -np 2 python train.py` in `horovod/horovod:0.24.1` or `horovod/horovod:0.24.0` outputs: \r\n```\r\n[1,0]<stdout>:weight: 0.20000000298023224                                                                                \r\n[1,0]<stdout>:weight: 0.20000000298023224                                                                                \r\n[1,0]<stdout>:weight: 0.20000000298023224                                                                                \r\n[1,0]<stdout>:weight: 0.20000000298023224      \r\n```\r\n\r\nNotice that the weights are the same \u2014 they aren't updated.\r\n\r\n**Expected behavior:**\r\nRunning the same in our own (Determined AI's) docker images with (pytorch 1.9 + cuda 11.1) or (pytorch 1.10.2 + cuda 11.3) and the same horovod versions (these are based on corresponding `nvidia/cuda` images, e.g. `determinedai/environments-dev:cuda-11.3-pytorch-1.10-lightning-1.5-tf-2.8-gpu-3da66d1`) works okay: \r\n```\r\n[0]<stdout>:weight: 0.20000000298023224\r\n[0]<stdout>:weight: 0.36000001430511475\r\n[0]<stdout>:weight: 0.4880000054836273\r\n[0]<stdout>:weight: 0.590399980545044\r\n```\r\n\r\n I suspect something is wrong with the official docker build.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3460/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3460/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3455", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3455/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3455/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3455/events", "html_url": "https://github.com/horovod/horovod/issues/3455", "id": 1160447661, "node_id": "I_kwDOBfOI785FKwat", "number": 3455, "title": "Build MXNet1.9 from source , install horovod will report cannot find mxnet ", "user": {"login": "Gao-HaoYuan", "id": 80264276, "node_id": "MDQ6VXNlcjgwMjY0Mjc2", "avatar_url": "https://avatars.githubusercontent.com/u/80264276?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gao-HaoYuan", "html_url": "https://github.com/Gao-HaoYuan", "followers_url": "https://api.github.com/users/Gao-HaoYuan/followers", "following_url": "https://api.github.com/users/Gao-HaoYuan/following{/other_user}", "gists_url": "https://api.github.com/users/Gao-HaoYuan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gao-HaoYuan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gao-HaoYuan/subscriptions", "organizations_url": "https://api.github.com/users/Gao-HaoYuan/orgs", "repos_url": "https://api.github.com/users/Gao-HaoYuan/repos", "events_url": "https://api.github.com/users/Gao-HaoYuan/events{/privacy}", "received_events_url": "https://api.github.com/users/Gao-HaoYuan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 23, "created_at": "2022-03-05T21:15:20Z", "updated_at": "2023-02-13T11:14:34Z", "closed_at": "2023-02-13T11:14:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nenvironment\uff1a\r\npython 3.8\r\nubuntu 18.04 \r\ngcc 7.5     g++7.5\r\nmxnet1.9(build from source)\r\nopenmpi 4.0\r\nhorovod 0.24\r\n\r\ninstructions\r\nHOROVOD_WITHOUT_TENSORFLOW=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITH_MXNET=1 pip install dist/horovod-0.24.1.tar.gz\r\n\r\nHOROVOD_WITH_MXNET=1 pip install --no-cache-dir horovod[MXNET]\r\n\r\nHorovod cannot be installed or compile\r\n\r\n### Error Message\r\n```\r\n Traceback (most recent call last):\r\n        File \"<string>\", line 1, in <module>\r\n        File \"/root/miniconda3/lib/python3.8/site-packages/mxnet-1.9.0-py3.8.egg/mxnet/libinfo.py\", line 108, in find_include_path\r\n          raise RuntimeError('Cannot find the MXNet include path in either ' + pip_incl_path +\r\n      RuntimeError: Cannot find the MXNet include path in either /root/miniconda3/lib/python3.8/site-packages/mxnet-1.9.0-py3.8.egg/mxnet/include/ or /root/miniconda3/lib/python3.8/site-packages/mxnet-1.9.0-py3.8.egg/mxnet/../../include/\r\n\r\n      CMake Error at /tmp/horovod-cmake-tmpaicqjfxp/cmake/data/share/cmake-3.13/Modules/FindPackageHandleStandardArgs.cmake:137 (message):\r\n        Could NOT find Mxnet (missing: Mxnet_LIBRARIES) (Required is at least\r\n        version \"1.4.0\")\r\n      Call Stack (most recent call first):\r\n        /tmp/horovod-cmake-tmpaicqjfxp/cmake/data/share/cmake-3.13/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE)\r\n        cmake/Modules/FindMxnet.cmake:65 (find_package_handle_standard_args)\r\n        horovod/mxnet/CMakeLists.txt:12 (find_package)\r\n\r\n\r\n      -- Configuring incomplete, errors occurred!\r\n      See also \"/tmp/pip-req-build-sz62zlyv/build/temp.linux-x86_64-3.8/RelWithDebInfo/CMakeFiles/CMakeOutput.log\".\r\n      Traceback (most recent call last):\r\n        File \"<string>\", line 2, in <module>\r\n        File \"<pip-setuptools-caller>\", line 34, in <module>\r\n        File \"/tmp/pip-req-build-sz62zlyv/setup.py\", line 209, in <module>\r\n          setup(name='horovod',\r\n        File \"/root/miniconda3/lib/python3.8/site-packages/setuptools/__init__.py\", line 153, in setup\r\n          return distutils.core.setup(**attrs)\r\n        File \"/root/miniconda3/lib/python3.8/distutils/core.py\", line 148, in setup\r\n          dist.run_commands()\r\n        File \"/root/miniconda3/lib/python3.8/distutils/dist.py\", line 966, in run_commands\r\n          self.run_command(cmd)\r\n        File \"/root/miniconda3/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n          cmd_obj.run()\r\n        File \"/root/miniconda3/lib/python3.8/site-packages/setuptools/command/install.py\", line 61, in run\r\n          return orig.install.run(self)\r\n        File \"/root/miniconda3/lib/python3.8/distutils/command/install.py\", line 545, in run\r\n          self.run_command('build')\r\n        File \"/root/miniconda3/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n          self.distribution.run_command(command)\r\n        File \"/root/miniconda3/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n          cmd_obj.run()\r\n        File \"/root/miniconda3/lib/python3.8/distutils/command/build.py\", line 135, in run\r\n          self.run_command(cmd_name)\r\n        File \"/root/miniconda3/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n          self.distribution.run_command(command)\r\n        File \"/root/miniconda3/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n          cmd_obj.run()\r\n        File \"/root/miniconda3/lib/python3.8/site-packages/setuptools/command/build_ext.py\", line 79, in run\r\n          _build_ext.run(self)\r\n        File \"/root/miniconda3/lib/python3.8/distutils/command/build_ext.py\", line 340, in run\r\n          self.build_extensions()\r\n        File \"/tmp/pip-req-build-sz62zlyv/setup.py\", line 144, in build_extensions\r\n          subprocess.check_call(command, cwd=cmake_build_dir)\r\n        File \"/root/miniconda3/lib/python3.8/subprocess.py\", line 364, in check_call\r\n          raise CalledProcessError(retcode, cmd)\r\n      subprocess.CalledProcessError: Command '['/tmp/horovod-cmake-tmpaicqjfxp/bin/run_cmake', '/tmp/pip-req-build-sz62zlyv', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/tmp/pip-req-build-sz62zlyv/build/lib.linux-x86_64-3.8', '-DPYTHON_EXECUTABLE:FILEPATH=/root/miniconda3/bin/python']' returned non-zero exit status 1.\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  Rolling back uninstall of horovod\r\n  Moving to /root/miniconda3/bin/horovodrun\r\n   from /tmp/pip-uninstall-ddcttzju/horovodrun\r\nerror: legacy-install-failure\r\n\r\n\u00d7 Encountered error while trying to install package.\r\n\u2570\u2500> horovod\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for output from the failure.\r\n```\r\n\r\n## To Reproduce\r\n\r\nHOROVOD_WITHOUT_TENSORFLOW=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITH_MXNET=1 pip install dist/horovod-0.24.1.tar.gz\r\n\r\nHOROVOD_WITH_MXNET=1 pip install --no-cache-dir horovod[MXNET]\r\n\r\n### Steps to reproduce\r\n(Paste the commands you ran that produced the error.)\r\n\r\n1. compile the mxnet 1.9 \r\n         apt-get update \r\n         sudo apt-get install -y build-essential libopenblas-dev libopencv-dev graphviz\r\n         make -j8\r\n         sudo python setup.py install\r\n         export PYTHONPATH=\"/root/mxnet/python:$PYTHONPATH\"   and source ~/.bashrc\r\n2. conda install openmpi (4.0.2) \r\n3. HOROVOD_WITH_MXNET=1 pip install --no-cache-dir horovod[MXNET] \r\n\r\n## What have you tried to solve it?\r\n\r\n1. compile the horovod \r\n2. compile the openmpi\r\n\r\n## Environment\r\n\r\npython 3.8\r\nubuntu 18.04 \r\ngcc 7.5     g++7.5\r\nmxnet1.9(build from source)\r\nopenmpi 4.0\r\nhorovod 0.24\r\n\r\n<details>\r\n<summary>Environment Information</summary>\r\n\r\n```\r\n# Paste the diagnose.py command output here\r\n```\r\n\r\n</details>\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3455/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3455/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3453", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3453/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3453/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3453/events", "html_url": "https://github.com/horovod/horovod/issues/3453", "id": 1160330552, "node_id": "I_kwDOBfOI785FKT04", "number": 3453, "title": "Horovod does not compile with old framework versions that setup.py accept", "user": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-03-05T12:10:30Z", "updated_at": "2022-03-11T22:49:16Z", "closed_at": "2022-03-11T22:49:16Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Building Horovod, the log says:\r\n\r\nBut actually building Horovod against PyTorch 1.2.0, it fails with:\r\n\r\n```\r\n    /tmp/pip-req-build-13fs79hx/horovod/torch/mpi_ops_v2.cc:61:12: error: \u2018class at::Tensor\u2019 has no member named \u2018floor_divide_\u2019\r\n         tensor.floor_divide_(divisor);\r\n                ^~~~~~~~~~~~~\r\n```\r\n\r\nLooks like the minimum PyTorch that Horovod compiles with is 1.5.0.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3453/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3453/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3450", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3450/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3450/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3450/events", "html_url": "https://github.com/horovod/horovod/issues/3450", "id": 1160124839, "node_id": "I_kwDOBfOI785FJhmn", "number": 3450, "title": "No module named 'fsspec.callbacks' thrown at horovod/spark/common/store.py ln 33", "user": {"login": "zyluo", "id": 1192841, "node_id": "MDQ6VXNlcjExOTI4NDE=", "avatar_url": "https://avatars.githubusercontent.com/u/1192841?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zyluo", "html_url": "https://github.com/zyluo", "followers_url": "https://api.github.com/users/zyluo/followers", "following_url": "https://api.github.com/users/zyluo/following{/other_user}", "gists_url": "https://api.github.com/users/zyluo/gists{/gist_id}", "starred_url": "https://api.github.com/users/zyluo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zyluo/subscriptions", "organizations_url": "https://api.github.com/users/zyluo/orgs", "repos_url": "https://api.github.com/users/zyluo/repos", "events_url": "https://api.github.com/users/zyluo/events{/privacy}", "received_events_url": "https://api.github.com/users/zyluo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2022-03-04T23:11:35Z", "updated_at": "2022-03-05T10:26:31Z", "closed_at": "2022-03-05T10:26:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.6.2\r\n3. Horovod version: 0.24.1\r\n4. MPI version: 4.1.0\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.7\r\n8. Spark / PySpark version: 3.2\r\n9. Ray version: N/A\r\n10. OS and version: Ubuntu 18.04\r\n11. GCC version: 9.3.1\r\n12. CMake version: 2.8\r\n\r\n**Checklist:** >>>>>>>>>>>>>>>>> all \"YES\"\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n1. Create a GCP Dataproc cluster with 2.0.27-ubuntu18 image\r\n2. install TF 2.6.2 and Horovod 0.24.1\r\n3. `>> from horovod.spark.common.store import HDFSStore`\r\noutput:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/default/lib/python3.8/site-packages/horovod/spark/common/store.py\", line 33, in <module>\r\n    from fsspec.callbacks import _DEFAULModuleNotFoundError: No module named 'fsspec.callbacks'\r\n\r\nThe fsspec.callback module was introduced in https://github.com/fsspec/filesystem_spec/releases/tag/2021.07.0\r\n\r\nThe line\r\nhttps://github.com/horovod/horovod/blob/ebd135098571722469bb6290a6d098a9e1c96574/setup.py#L169\r\nshould be\r\n`spark_require_list = ['numpy', 'petastorm>=0.11.0', 'pyarrow>=0.15.0', 'fsspec>=2021.07.0']`\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3450/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3450/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3445", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3445/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3445/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3445/events", "html_url": "https://github.com/horovod/horovod/issues/3445", "id": 1158539781, "node_id": "I_kwDOBfOI785FDeoF", "number": 3445, "title": "clang-format / autopep8 format", "user": {"login": "nrailgun", "id": 14273895, "node_id": "MDQ6VXNlcjE0MjczODk1", "avatar_url": "https://avatars.githubusercontent.com/u/14273895?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nrailgun", "html_url": "https://github.com/nrailgun", "followers_url": "https://api.github.com/users/nrailgun/followers", "following_url": "https://api.github.com/users/nrailgun/following{/other_user}", "gists_url": "https://api.github.com/users/nrailgun/gists{/gist_id}", "starred_url": "https://api.github.com/users/nrailgun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nrailgun/subscriptions", "organizations_url": "https://api.github.com/users/nrailgun/orgs", "repos_url": "https://api.github.com/users/nrailgun/repos", "events_url": "https://api.github.com/users/nrailgun/events{/privacy}", "received_events_url": "https://api.github.com/users/nrailgun/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-03-03T15:17:34Z", "updated_at": "2022-03-05T14:25:43Z", "closed_at": "2022-03-05T14:25:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "I tried\r\n```bash\r\ncd horovod\r\nclang-format -style=file -i horovod/common/common.cc\r\n```\r\n\r\nthen many lines were changed, I guess there should be no diff?\r\n```\r\ndiff --git a/horovod/common/common.cc b/horovod/common/common.cc\r\nindex 3c6d18b..0b5260a 100644\r\n--- a/horovod/common/common.cc\r\n+++ b/horovod/common/common.cc\r\n@@ -17,11 +17,11 @@\r\n #include \"common.h\"\r\n #include \"logging.h\"\r\n\r\n-#include <sstream>\r\n #include <cassert>\r\n #include <cstring>\r\n-#include <utility>\r\n #include <limits.h>\r\n+#include <sstream>\r\n+#include <utility>\r\n\r\n namespace horovod {\r\n namespace common {\r\n@@ -29,12 +29,9 @@ namespace common {\r\n Status::Status() = default;\r\n\r\n Status::Status(StatusType type, std::string reason)\r\n-    : type_(type), reason_(std::move(reason)) {\r\n-}\r\n+    : type_(type), reason_(std::move(reason)) {}\r\n\r\n-Status Status::OK() {\r\n-  return Status();\r\n-}\r\n+Status Status::OK() { return Status(); }\r\n\r\n Status Status::UnknownError(const std::string& message) {\r\n   return Status(StatusType::UNKNOWN_ERROR, message);\r\n@@ -52,29 +49,17 @@ Status Status::InvalidArgument(const std::string& message) {\r\n   return Status(StatusType::INVALID_ARGUMENT, message);\r\n }\r\n\r\n-Status Status::InProgress() {\r\n-  return Status(StatusType::IN_PROGRESS, \"\");\r\n-}\r\n+Status Status::InProgress() { return Status(StatusType::IN_PROGRESS, \"\"); }\r\n\r\n-bool Status::ok() const {\r\n-  return type_ == StatusType::OK;\r\n-}\r\n+bool Status::ok() const { return type_ == StatusType::OK; }\r\n```\r\n\r\nSimilar thing happened when I tried `autopep8 --in-place horovod/tensorflow/mpi_ops.py`\r\n```\r\ndiff --git a/horovod/tensorflow/mpi_ops.py b/horovod/tensorflow/mpi_ops.py\r\nindex 8865e58..355773f 100644\r\n--- a/horovod/tensorflow/mpi_ops.py\r\n+++ b/horovod/tensorflow/mpi_ops.py\r\n@@ -45,6 +45,7 @@ def _load_library(name):\r\n     library = load_library.load_op_library(filename)\r\n     return library\r\n\r\n+\r\n # Check possible symbol not found error from tensorflow version mismatch\r\n try:\r\n     MPI_LIB = _load_library('mpi_lib' + get_ext_suffix())\r\n@@ -83,14 +84,17 @@ Average = _basics.Average\r\n Sum = _basics.Sum\r\n Adasum = _basics.Adasum\r\n\r\n+\r\n def init(*args, **kwargs):\r\n     _basics.init(*args, **kwargs)\r\n     # Call set up again to make sure the basics is in sync\r\n     _setup_process_sets(_basics)\r\n\r\n+\r\n is_homogeneous = _basics.is_homogeneous\r\n\r\n-handle_average_backwards_compatibility = get_average_backwards_compatibility_fun(_basics)\r\n+handle_average_backwards_compatibility = get_average_backwards_compatibility_fun(\r\n+    _basics)\r\n```\r\n\r\n**Environment:**\r\n\r\nHorovod version 0.23\r\nPython version 3.6\r\nclang-format version 11.0.0\r\nautopep8 1.6.0 (pycodestyle: 2.8.0)", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3445/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3445/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3422", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3422/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3422/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3422/events", "html_url": "https://github.com/horovod/horovod/issues/3422", "id": 1150809436, "node_id": "I_kwDOBfOI785El_Vc", "number": 3422, "title": "TF Nightly breaks unit tests test_horovod_syncbn_gpu() and test_horovod_syncbn_cpu()", "user": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Tixxx", "id": 26332583, "node_id": "MDQ6VXNlcjI2MzMyNTgz", "avatar_url": "https://avatars.githubusercontent.com/u/26332583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tixxx", "html_url": "https://github.com/Tixxx", "followers_url": "https://api.github.com/users/Tixxx/followers", "following_url": "https://api.github.com/users/Tixxx/following{/other_user}", "gists_url": "https://api.github.com/users/Tixxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tixxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tixxx/subscriptions", "organizations_url": "https://api.github.com/users/Tixxx/orgs", "repos_url": "https://api.github.com/users/Tixxx/repos", "events_url": "https://api.github.com/users/Tixxx/events{/privacy}", "received_events_url": "https://api.github.com/users/Tixxx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Tixxx", "id": 26332583, "node_id": "MDQ6VXNlcjI2MzMyNTgz", "avatar_url": "https://avatars.githubusercontent.com/u/26332583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tixxx", "html_url": "https://github.com/Tixxx", "followers_url": "https://api.github.com/users/Tixxx/followers", "following_url": "https://api.github.com/users/Tixxx/following{/other_user}", "gists_url": "https://api.github.com/users/Tixxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tixxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tixxx/subscriptions", "organizations_url": "https://api.github.com/users/Tixxx/orgs", "repos_url": "https://api.github.com/users/Tixxx/repos", "events_url": "https://api.github.com/users/Tixxx/events{/privacy}", "received_events_url": "https://api.github.com/users/Tixxx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2022-02-25T19:50:28Z", "updated_at": "2022-02-28T19:52:30Z", "closed_at": "2022-02-28T19:52:30Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Bug report:**\r\n\r\nNightly config CI: \r\nhttps://github.com/horovod/horovod/runs/5327552707?check_suite_focus=true\r\n\r\nFailure stack:\r\n```\r\n[0]<stdout>:=================================== FAILURES ===================================\r\n[0]<stdout>:___________________ TensorFlowTests.test_horovod_syncbn_cpu ____________________\r\n[0]<stdout>:\r\n[0]<stdout>:self = <test_tensorflow.TensorFlowTests testMethod=test_horovod_syncbn_cpu>\r\n[0]<stdout>:\r\n[0]<stdout>:    def test_horovod_syncbn_cpu(self):\r\n[0]<stdout>:        \"\"\"Test that the SyncBatchNormalization implementation is correct on CPU.\"\"\"\r\n[0]<stdout>:    \r\n[0]<stdout>:        hvd.init()\r\n[0]<stdout>:        with tf.device(\"/cpu:0\"):\r\n[0]<stdout>:            x_list = [\r\n[0]<stdout>:                tf.convert_to_tensor(np.stack([\r\n[0]<stdout>:                    np.array([\r\n[0]<stdout>:                        [r, r + 1],\r\n[0]<stdout>:                        [r * 2, r * 2 + 1],\r\n[0]<stdout>:                        [r * 3, r * 3 + 1],\r\n[0]<stdout>:                        [r * 4, r * 4 + 1]\r\n[0]<stdout>:                    ], dtype=np.float32)\r\n[0]<stdout>:                    for r in range(hvd.size())\r\n[0]<stdout>:                ]), np.float32),\r\n[0]<stdout>:                tf.convert_to_tensor(np.stack([\r\n[0]<stdout>:                    np.array([\r\n[0]<stdout>:                        [r + 1],\r\n[0]<stdout>:                        [r * 2 + 1],\r\n[0]<stdout>:                        [r * 3 + 1],\r\n[0]<stdout>:                        [r * 4 + 1]\r\n[0]<stdout>:                    ], dtype=np.float32)\r\n[0]<stdout>:                    for r in range(hvd.size())\r\n[0]<stdout>:                ]), np.float32),\r\n[0]<stdout>:            ]\r\n[0]<stdout>:    \r\n[0]<stdout>:            for x in x_list:\r\n[0]<stdout>:                bn = tf.keras.layers.BatchNormalization(axis=1, fused=False)\r\n[0]<stdout>:                sync_bn = hvd.SyncBatchNormalization(axis=1)\r\n[0]<stdout>:>               bn_func = bn.apply(x, training=True)\r\n[0]<stdout>:E               AttributeError: 'BatchNormalization' object has no attribute 'apply'\r\n```\r\n\r\n\r\nTF nightly removed `apply()` function:\r\n\r\n```\r\n@deprecation.deprecated( date=None, instructions=\u2018Please use `layer.__call__` method instead.\u2019)\r\n@doc_controls.do_not_doc_inheritable\r\ndef apply(self, inputs, *args, **kwargs):\r\n\u201c\u201d\"Deprecated, do NOT use!\r\n```\r\nWe should switch to `layer.__call__` for TF>=2.9.0.\r\n\r\nFailed unit tests:\r\n`test_horovod_syncbn_gpu()`: https://github.com/horovod/horovod/blob/master/test/parallel/test_tensorflow.py#L4054\r\n`test_horovod_syncbn_cpu()`: https://github.com/horovod/horovod/blob/master/test/parallel/test_tensorflow.py#L4101\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3422/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3422/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3417", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3417/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3417/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3417/events", "html_url": "https://github.com/horovod/horovod/issues/3417", "id": 1147684934, "node_id": "I_kwDOBfOI785EaEhG", "number": 3417, "title": "test_spark_keras.py::SparkKerasTests fails in PySpark 2.4.8 and TF 2.7 in CI", "user": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2022-02-23T06:44:45Z", "updated_at": "2022-02-27T21:15:18Z", "closed_at": "2022-02-27T21:15:18Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Bug report:**\r\nFrom CI history https://github.com/horovod/horovod/runs/5298539738\r\nTwo spark Keras tests fail when using PySpark 2.4.8:\r\n\r\n test_fit_model (test.integration.test_spark_keras.SparkKerasTests)\r\n test_fit_model_multiclass (test.integration.test_spark_keras.SparkKerasTests)\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3417/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3417/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3414", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3414/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3414/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3414/events", "html_url": "https://github.com/horovod/horovod/issues/3414", "id": 1145658688, "node_id": "I_kwDOBfOI785ESV1A", "number": 3414, "title": "Horovod 0.21.0 with Pytorch and GPU support installation error", "user": {"login": "Snoeprol", "id": 29781662, "node_id": "MDQ6VXNlcjI5NzgxNjYy", "avatar_url": "https://avatars.githubusercontent.com/u/29781662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Snoeprol", "html_url": "https://github.com/Snoeprol", "followers_url": "https://api.github.com/users/Snoeprol/followers", "following_url": "https://api.github.com/users/Snoeprol/following{/other_user}", "gists_url": "https://api.github.com/users/Snoeprol/gists{/gist_id}", "starred_url": "https://api.github.com/users/Snoeprol/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Snoeprol/subscriptions", "organizations_url": "https://api.github.com/users/Snoeprol/orgs", "repos_url": "https://api.github.com/users/Snoeprol/repos", "events_url": "https://api.github.com/users/Snoeprol/events{/privacy}", "received_events_url": "https://api.github.com/users/Snoeprol/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-02-21T11:14:05Z", "updated_at": "2022-03-02T18:45:34Z", "closed_at": "2022-03-02T18:45:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.10.1+cu102\r\n3. Horovod version: 0.21.0\r\n4. MPI version: mpirun (Open MPI) 3.1.3\r\n5. CUDA version: CUDA/10.1.243\r\n6. NCCL version:  NCCL/2.5.6-CUDA-10.1.243\r\n7. Python version: Python 3.8.8\r\n8. Spark / PySpark version: 3.2.0\r\n9. Ray version: .\r\n10. OS and version:\r\n\r\nPRETTY_NAME=\"Debian GNU/Linux 10 (buster)\"\r\nNAME=\"Debian GNU/Linux\"\r\nVERSION_ID=\"10\"\r\nVERSION=\"10 (buster)\"\r\nVERSION_CODENAME=buster\r\nID=debian\r\nHOME_URL=\"https://www.debian.org/\"\r\nSUPPORT_URL=\"https://www.debian.org/support\"\r\nBUG_REPORT_URL=\"https://bugs.debian.org/\"\r\n\r\n11. GCC version: 8.3.0\r\n12. CMake version: 3.13.4\r\n\r\n**Bug report:**\r\nI am trying to install horvod 0.21.0. I used the following steps:\r\n\r\n```\r\nHOROVOD_WITH_PYTORCH=1\r\nHOROVOD_WITH_TENSORFLOW=0\r\nHOROVOD_WITH_MXNET=0\r\nHOROVOD_WITHOUT_TENSORFLOW=1\r\nHOROVOD_WITHOUT_MXNET=1\r\nHOROVOD_WITHOUT_PYTORCH=0\r\nHOROVOD_GPU_OPERATIONS=NCCL pip install --no-cache-dir horovod[pytorch]==0.21.0\r\n```\r\n\r\nThis produces the error:\r\n\r\n```\r\n  Another error similar to the one below -> \r\n\r\n      cd /scratch/pip-install-c158jwy5/horovod_2bb67489ec2e4bfebb17b533f73b6ca4/build/temp.linux-x86_64-3.8/third_party/compatible_gloo/gloo && /usr/bin/cmake -P CMakeFiles/compatible_gloo.dir/cmake_clean_target.cmake\r\n      cd /scratch/pip-install-c158jwy5/horovod_2bb67489ec2e4bfebb17b533f73b6ca4/build/temp.linux-x86_64-3.8/third_party/compatible_gloo/gloo && /usr/bin/cmake -E cmake_link_script CMakeFiles/compatible_gloo.dir/link.txt --verbose=1\r\n      /usr/bin/ar qc libcompatible_gloo.a  CMakeFiles/compatible_gloo.dir/algorithm.cc.o CMakeFiles/compatible_gloo.dir/allgather.cc.o CMakeFiles/compatible_gloo.dir/allgatherv.cc.o CMakeFiles/compatible_gloo.dir/allreduce.cc.o CMakeFiles/compatible_gloo.dir/allreduce_local.cc.o CMakeFiles/compatible_gloo.dir/alltoall.cc.o CMakeFiles/compatible_gloo.dir/alltoallv.cc.o CMakeFiles/compatible_gloo.dir/barrier.cc.o CMakeFiles/compatible_gloo.dir/broadcast.cc.o CMakeFiles/compatible_gloo.dir/context.cc.o CMakeFiles/compatible_gloo.dir/gather.cc.o CMakeFiles/compatible_gloo.dir/gatherv.cc.o CMakeFiles/compatible_gloo.dir/reduce.cc.o CMakeFiles/compatible_gloo.dir/scatter.cc.o CMakeFiles/compatible_gloo.dir/types.cc.o CMakeFiles/compatible_gloo.dir/common/logging.cc.o CMakeFiles/compatible_gloo.dir/common/linux.cc.o CMakeFiles/compatible_gloo.dir/mpi/context.cc.o CMakeFiles/compatible_gloo.dir/rendezvous/context.cc.o CMakeFiles/compatible_gloo.dir/rendezvous/file_store.cc.o CMakeFiles/compatible_gloo.dir/rendezvous/hash_store.cc.o CMakeFiles/compatible_gloo.dir/rendezvous/prefix_store.cc.o CMakeFiles/compatible_gloo.dir/rendezvous/store.cc.o CMakeFiles/compatible_gloo.dir/transport/address.cc.o CMakeFiles/compatible_gloo.dir/transport/buffer.cc.o CMakeFiles/compatible_gloo.dir/transport/context.cc.o CMakeFiles/compatible_gloo.dir/transport/device.cc.o CMakeFiles/compatible_gloo.dir/transport/pair.cc.o CMakeFiles/compatible_gloo.dir/transport/unbound_buffer.cc.o CMakeFiles/compatible_gloo.dir/transport/tcp/address.cc.o CMakeFiles/compatible_gloo.dir/transport/tcp/buffer.cc.o CMakeFiles/compatible_gloo.dir/transport/tcp/context.cc.o CMakeFiles/compatible_gloo.dir/transport/tcp/device.cc.o CMakeFiles/compatible_gloo.dir/transport/tcp/loop.cc.o CMakeFiles/compatible_gloo.dir/transport/tcp/pair.cc.o CMakeFiles/compatible_gloo.dir/transport/tcp/unbound_buffer.cc.o\r\n      /usr/bin/ranlib libcompatible_gloo.a\r\n      make[2]: Leaving directory '/scratch/pip-install-c158jwy5/horovod_2bb67489ec2e4bfebb17b533f73b6ca4/build/temp.linux-x86_64-3.8'\r\n      [ 50%] Linking CXX static library libgloo.a\r\n      cd /scratch/pip-install-c158jwy5/horovod_2bb67489ec2e4bfebb17b533f73b6ca4/build/temp.linux-x86_64-3.8/third_party/gloo/gloo && /usr/bin/cmake -P CMakeFiles/gloo.dir/cmake_clean_target.cmake\r\n      [ 50%] Built target compatible_gloo\r\n      cd /scratch/pip-install-c158jwy5/horovod_2bb67489ec2e4bfebb17b533f73b6ca4/build/temp.linux-x86_64-3.8/third_party/gloo/gloo && /usr/bin/cmake -E cmake_link_script CMakeFiles/gloo.dir/link.txt --verbose=1\r\n      /usr/bin/ar qc libgloo.a  CMakeFiles/gloo.dir/algorithm.cc.o CMakeFiles/gloo.dir/allgather.cc.o CMakeFiles/gloo.dir/allgatherv.cc.o CMakeFiles/gloo.dir/allreduce.cc.o CMakeFiles/gloo.dir/allreduce_local.cc.o CMakeFiles/gloo.dir/alltoall.cc.o CMakeFiles/gloo.dir/alltoallv.cc.o CMakeFiles/gloo.dir/barrier.cc.o CMakeFiles/gloo.dir/broadcast.cc.o CMakeFiles/gloo.dir/context.cc.o CMakeFiles/gloo.dir/gather.cc.o CMakeFiles/gloo.dir/gatherv.cc.o CMakeFiles/gloo.dir/reduce.cc.o CMakeFiles/gloo.dir/scatter.cc.o CMakeFiles/gloo.dir/types.cc.o CMakeFiles/gloo.dir/common/logging.cc.o CMakeFiles/gloo.dir/common/linux.cc.o CMakeFiles/gloo.dir/mpi/context.cc.o CMakeFiles/gloo.dir/rendezvous/context.cc.o CMakeFiles/gloo.dir/rendezvous/file_store.cc.o CMakeFiles/gloo.dir/rendezvous/hash_store.cc.o CMakeFiles/gloo.dir/rendezvous/prefix_store.cc.o CMakeFiles/gloo.dir/rendezvous/store.cc.o CMakeFiles/gloo.dir/transport/address.cc.o CMakeFiles/gloo.dir/transport/buffer.cc.o CMakeFiles/gloo.dir/transport/context.cc.o CMakeFiles/gloo.dir/transport/device.cc.o CMakeFiles/gloo.dir/transport/pair.cc.o CMakeFiles/gloo.dir/transport/unbound_buffer.cc.o CMakeFiles/gloo.dir/transport/tcp/address.cc.o CMakeFiles/gloo.dir/transport/tcp/buffer.cc.o CMakeFiles/gloo.dir/transport/tcp/context.cc.o CMakeFiles/gloo.dir/transport/tcp/device.cc.o CMakeFiles/gloo.dir/transport/tcp/loop.cc.o CMakeFiles/gloo.dir/transport/tcp/pair.cc.o CMakeFiles/gloo.dir/transport/tcp/unbound_buffer.cc.o\r\n      /usr/bin/ranlib libgloo.a\r\n      make[2]: Leaving directory '/scratch/pip-install-c158jwy5/horovod_2bb67489ec2e4bfebb17b533f73b6ca4/build/temp.linux-x86_64-3.8'\r\n      [ 50%] Built target gloo\r\n      make[1]: Leaving directory '/scratch/pip-install-c158jwy5/horovod_2bb67489ec2e4bfebb17b533f73b6ca4/build/temp.linux-x86_64-3.8'\r\n      make: *** [Makefile:130: all] Error 2\r\n      Traceback (most recent call last):\r\n        File \"<string>\", line 2, in <module>\r\n        File \"<pip-setuptools-caller>\", line 34, in <module>\r\n        File \"/scratch/pip-install-c158jwy5/horovod_2bb67489ec2e4bfebb17b533f73b6ca4/setup.py\", line 144, in <module>\r\n          setup(name='horovod',\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/__init__.py\", line 155, in setup\r\n          return distutils.core.setup(**attrs)\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/_distutils/core.py\", line 148, in setup\r\n          return run_commands(dist)\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/_distutils/core.py\", line 163, in run_commands\r\n          dist.run_commands()\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 967, in run_commands\r\n          self.run_command(cmd)\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\r\n          cmd_obj.run()\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/command/install.py\", line 68, in run\r\n          return orig.install.run(self)\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/_distutils/command/install.py\", line 670, in run\r\n          self.run_command('build')\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/_distutils/cmd.py\", line 313, in run_command\r\n          self.distribution.run_command(command)\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\r\n          cmd_obj.run()\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/_distutils/command/build.py\", line 135, in run\r\n          self.run_command(cmd_name)\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/_distutils/cmd.py\", line 313, in run_command\r\n          self.distribution.run_command(command)\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\r\n          cmd_obj.run()\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/command/build_ext.py\", line 79, in run\r\n          _build_ext.run(self)\r\n        File \"/sw/arch/Debian10/EB_production/2021/software/Anaconda3/2021.05/lib/python3.8/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\r\n          _build_ext.build_ext.run(self)\r\n        File \"/home/rooijm/.local/lib/python3.8/site-packages/setuptools/_distutils/command/build_ext.py\", line 339, in run\r\n          self.build_extensions()\r\n        File \"/scratch/pip-install-c158jwy5/horovod_2bb67489ec2e4bfebb17b533f73b6ca4/setup.py\", line 90, in build_extensions\r\n          subprocess.check_call([cmake_bin, '--build', '.'] + cmake_build_args,\r\n        File \"/sw/arch/Debian10/EB_production/2021/software/Anaconda3/2021.05/lib/python3.8/subprocess.py\", line 364, in check_call\r\n          raise CalledProcessError(retcode, cmd)\r\n      subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--config', 'RelWithDebInfo', '--', '-j8', 'VERBOSE=1']' returned non-zero exit status 2.\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: legacy-install-failure\r\n\r\n\u00d7 Encountered error while trying to install package.\r\n\u2570\u2500> horovod\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for output from the failure. \r\n```\r\n\r\nI can't seem to figure out what I'm doing wrong. The error does not tell me much.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3414/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3414/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3412", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3412/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3412/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3412/events", "html_url": "https://github.com/horovod/horovod/issues/3412", "id": 1144986975, "node_id": "I_kwDOBfOI785EPx1f", "number": 3412, "title": "tensorflow.python.framework.errors_impl.UnknownError:  Horovod has been shut down. ", "user": {"login": "whybeyoung", "id": 10629930, "node_id": "MDQ6VXNlcjEwNjI5OTMw", "avatar_url": "https://avatars.githubusercontent.com/u/10629930?v=4", "gravatar_id": "", "url": "https://api.github.com/users/whybeyoung", "html_url": "https://github.com/whybeyoung", "followers_url": "https://api.github.com/users/whybeyoung/followers", "following_url": "https://api.github.com/users/whybeyoung/following{/other_user}", "gists_url": "https://api.github.com/users/whybeyoung/gists{/gist_id}", "starred_url": "https://api.github.com/users/whybeyoung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/whybeyoung/subscriptions", "organizations_url": "https://api.github.com/users/whybeyoung/orgs", "repos_url": "https://api.github.com/users/whybeyoung/repos", "events_url": "https://api.github.com/users/whybeyoung/events{/privacy}", "received_events_url": "https://api.github.com/users/whybeyoung/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-02-20T11:02:39Z", "updated_at": "2022-05-13T16:07:01Z", "closed_at": "2022-05-13T16:07:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow2, Keras)\r\n2. Framework version: 2.5 \r\n3. Horovod version:  0.23.0\r\n4. MPI version:\r\n5. CUDA version:  CPU\r\n6. NCCL version:\r\n7. Python version: 3.8.10\r\n\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\n\r\ni am training deep ctr model using horvod.  and  the log is :\r\n\r\n```bash\r\n20220217\r\nhorovod-job-atp-mnist-worker-0.horovod-job-atp-mnist:1,horovod-job-atp-mnist-worker-1.horovod-job-atp-mnist:1,horovod-job-atp-mnist-worker-2.horovod-job-atp-mnist:1\r\nWarning: Permanently added 'horovod-job-atp-mnist-worker-0.horovod-job-atp-mnist,100.126.5.248' (ECDSA) to the list of known hosts.\r\nWarning: Permanently added 'horovod-job-atp-mnist-worker-2.horovod-job-atp-mnist,100.126.5.196' (ECDSA) to the list of known hosts.\r\nWarning: Permanently added 'horovod-job-atp-mnist-worker-1.horovod-job-atp-mnist,100.80.136.138' (ECDSA) to the list of known hosts.\r\n[1,2]<stdout>:['20220217', '20220216', '20220215']\r\n[1,0]<stdout>:['20220217', '20220216', '20220215']\r\n[1,1]<stdout>:['20220217', '20220216', '20220215']\r\n[1,2]<stderr>:2022-02-20 10:38:24.704281: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n[1,2]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[1,1]<stderr>:2022-02-20 10:38:24.755622: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n[1,1]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[1,2]<stdout>:Model: \"model\"\r\n[1,2]<stdout>:__________________________________________________________________________________________________\r\n[1,2]<stdout>:Layer (type)                    Output Shape         Param #     Connected to\r\n[1,2]<stdout>:==================================================================================================\r\n[1,2]<stdout>:input_1 (InputLayer)            [(None, 30)]         0\r\n[1,2]<stdout>:__________________________________________________________________________________________________\r\n[1,2]<stdout>:embedding (Embedding)           (None, 30, 8)        3596408     input_1[0][0]\r\n[1,2]<stdout>:__________________________________________________________________________________________________\r\n[1,2]<stdout>:tf.reshape (TFOpLambda)         (None, 240)          0           embedding[0][0]\r\n[1,2]<stdout>:__________________________________________________________________________________________________\r\n[1,2]<stdout>:dnn (DNN)                       (None, 64)           102848      tf.reshape[0][0]\r\n[1,2]<stdout>:__________________________________________________________________________________________________\r\n[1,2]<stdout>:fm (FM)                         (None, 1)            2641        tf.reshape[0][0]\r\n[1,2]<stdout>:__________________________________________________________________________________________________\r\n[1,2]<stdout>:dense_3 (Dense)                 (None, 1)            65          dnn[0][0]\r\n[1,2]<stdout>:__________________________________________________________________________________________________\r\n[1,2]<stdout>:tf.math.add (TFOpLambda)        (None, 1)            0           fm[0][0]\r\n[1,2]<stdout>:                                                                 dense_3[0][0]\r\n[1,2]<stdout>:__________________________________________________________________________________________________\r\n[1,2]<stdout>:input_2 (InputLayer)            [(None, 166)]        0\r\n[1,2]<stdout>:__________________________________________________________________________________________________\r\n[1,2]<stdout>:tf.math.sigmoid (TFOpLambda)    (None, 1)            0           tf.math.add[0][0]\r\n[1,2]<stdout>:==================================================================================================\r\n[1,2]<stdout>:Total params: 3,701,962\r\n[1,2]<stdout>:Trainable params: 3,701,962\r\n[1,2]<stdout>:Non-trainable params: 0\r\n[1,2]<stdout>:__________________________________________________________________________________________________\r\n[1,2]<stdout>:<PaddedBatchDataset shapes: (((None, 30), (None, 150), (None,), (None,)), (None,)), types: ((tf.int32, tf.float32, tf.string, tf.string), tf.int32)>\r\n[1,1]<stdout>:Model: \"model\"\r\n[1,1]<stdout>:__________________________________________________________________________________________________\r\n[1,1]<stdout>:Layer (type)                    Output Shape         Param #     Connected to\r\n[1,1]<stdout>:==================================================================================================\r\n[1,1]<stdout>:input_1 (InputLayer)            [(None, 30)]         0\r\n[1,1]<stdout>:__________________________________________________________________________________________________\r\n[1,1]<stdout>:embedding (Embedding)           (None, 30, 8)        3596408     input_1[0][0]\r\n[1,1]<stdout>:__________________________________________________________________________________________________\r\n[1,1]<stdout>:tf.reshape (TFOpLambda)         (None, 240)          0           embedding[0][0]\r\n[1,1]<stdout>:__________________________________________________________________________________________________\r\n[1,1]<stdout>:dnn (DNN)                       (None, 64)           102848      tf.reshape[0][0]\r\n[1,1]<stdout>:__________________________________________________________________________________________________\r\n[1,1]<stdout>:fm (FM)                         (None, 1)            2641        tf.reshape[0][0]\r\n[1,1]<stdout>:__________________________________________________________________________________________________\r\n[1,1]<stdout>:dense_3 (Dense)                 (None, 1)            65          dnn[0][0]\r\n[1,1]<stdout>:__________________________________________________________________________________________________\r\n[1,1]<stdout>:tf.math.add (TFOpLambda)        (None, 1)            0           fm[0][0]\r\n[1,1]<stdout>:                                                                 dense_3[0][0]\r\n[1,1]<stdout>:__________________________________________________________________________________________________\r\n[1,1]<stdout>:input_2 (InputLayer)            [(None, 166)]        0\r\n[1,1]<stdout>:__________________________________________________________________________________________________\r\n[1,1]<stdout>:tf.math.sigmoid (TFOpLambda)    (None, 1)            0           tf.math.add[0][0]\r\n[1,1]<stdout>:==================================================================================================\r\n[1,1]<stdout>:Total params: 3,701,962\r\n[1,1]<stdout>:Trainable params: 3,701,962\r\n[1,1]<stdout>:Non-trainable params: 0\r\n[1,1]<stdout>:__________________________________________________________________________________________________\r\n[1,1]<stdout>:<PaddedBatchDataset shapes: (((None, 30), (None, 150), (None,), (None,)), (None,)), types: ((tf.int32, tf.float32, tf.string, tf.string), tf.int32)>\r\n[1,0]<stderr>:2022-02-20 10:38:25.433845: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n[1,0]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n[1,0]<stdout>:Model: \"model\"\r\n[1,0]<stdout>:__________________________________________________________________________________________________\r\n[1,0]<stdout>:Layer (type)                    Output Shape         Param #     Connected to\r\n[1,0]<stdout>:==================================================================================================\r\n[1,0]<stdout>:input_1 (InputLayer)            [(None, 30)]         0\r\n[1,0]<stdout>:__________________________________________________________________________________________________\r\n[1,0]<stdout>:embedding (Embedding)           (None, 30, 8)        3596408     input_1[0][0]\r\n[1,0]<stdout>:__________________________________________________________________________________________________\r\n[1,0]<stdout>:tf.reshape (TFOpLambda)         (None, 240)          0           embedding[0][0]\r\n[1,0]<stdout>:__________________________________________________________________________________________________\r\n[1,0]<stdout>:dnn (DNN)                       (None, 64)           102848      tf.reshape[0][0]\r\n[1,0]<stdout>:__________________________________________________________________________________________________\r\n[1,0]<stdout>:fm (FM)                         (None, 1)            2641        tf.reshape[0][0]\r\n[1,0]<stdout>:__________________________________________________________________________________________________\r\n[1,0]<stdout>:dense_3 (Dense)                 (None, 1)            65          dnn[0][0]\r\n[1,0]<stdout>:__________________________________________________________________________________________________\r\n[1,0]<stdout>:tf.math.add (TFOpLambda)        (None, 1)            0           fm[0][0]\r\n[1,0]<stdout>:                                                                 dense_3[0][0]\r\n[1,0]<stdout>:__________________________________________________________________________________________________\r\n[1,0]<stdout>:input_2 (InputLayer)            [(None, 166)]        0\r\n[1,0]<stdout>:__________________________________________________________________________________________________\r\n[1,0]<stdout>:tf.math.sigmoid (TFOpLambda)    (None, 1)            0           tf.math.add[0][0]\r\n[1,0]<stdout>:==================================================================================================\r\n[1,0]<stdout>:Total params: 3,701,962\r\n[1,0]<stdout>:Trainable params: 3,701,962\r\n[1,0]<stdout>:Non-trainable params: 0\r\n[1,0]<stdout>:__________________________________________________________________________________________________\r\n[1,0]<stdout>:<PaddedBatchDataset shapes: (((None, 30), (None, 150), (None,), (None,)), (None,)), types: ((tf.int32, tf.float32, tf.string, tf.string), tf.int32)>\r\n[1,2]<stderr>:2022-02-20 10:38:26.928397: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\n[1,2]<stderr>:2022-02-20 10:38:26.962908: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2600000000 Hz\r\n[1,1]<stderr>:2022-02-20 10:38:27.086272: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\n[1,1]<stderr>:2022-02-20 10:38:27.097634: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2600000000 Hz\r\n[1,0]<stderr>:2022-02-20 10:38:27.742206: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\n[1,0]<stderr>:2022-02-20 10:38:27.753663: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2600000000 Hz\r\n[1,0]<stdout>:2022-02-20 10:38:29,028 [INFO] {'loss': 1.0014339685440063, 'auc': 0.4689686894416809, 'batch': 0}\r\n[1,1]<stdout>:2022-02-20 10:38:29,032 [INFO] {'loss': 0.9956496357917786, 'auc': 0.4890790581703186, 'batch': 0}\r\n[1,2]<stdout>:2022-02-20 10:38:29,033 [INFO] {'loss': 1.0065269470214844, 'auc': 0.5079171061515808, 'batch': 0}\r\n[1,0]<stdout>:925/925 - 522s - loss: 0.1655 - auc: 0.7404 - val_loss: 0.1336 - val_auc: 0.8013\r\n[1,2]<stderr>:Traceback (most recent call last):\r\n[1,2]<stderr>:  File \"/work/code/horovod_test/train_atp_day_cal_ad_horovod.py\", line 202, in <module>\r\n[1,2]<stderr>:    model.fit(\r\n[1,2]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\", line 1183, in fit\r\n[1,2]<stderr>:    tmp_logs = self.train_function(iterator)\r\n[1,2]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\r\n[1,2]<stderr>:    result = self._call(*args, **kwds)\r\n[1,2]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 917, in _call\r\n[1,2]<stderr>:    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n[1,2]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 3023, in __call__\r\n[1,2]<stderr>:    return graph_function._call_flat(\r\n[1,2]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 1960, in _call_flat\r\n[1,2]<stderr>:    return self._build_call_outputs(self._inference_function.call(\r\n[1,2]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 591, in call\r\n[1,2]<stderr>:    outputs = execute.execute(\r\n[1,2]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n[1,2]<stderr>:    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n[1,2]<stderr>:tensorflow.python.framework.errors_impl.UnknownError:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n[1,2]<stderr>:\t [[{{node PartitionedCall/DistributedAdam_Allreduce/cond/then/_65/DistributedAdam_Allreduce/cond/HorovodAllreduce_grads_0}}]] [Op:__inference_train_function_1988]\r\n[1,2]<stderr>:\r\n[1,2]<stderr>:Function call stack:\r\n[1,2]<stderr>:train_function\r\n[1,2]<stderr>:\r\n[1,1]<stderr>:Traceback (most recent call last):\r\n[1,1]<stderr>:  File \"/work/code/horovod_test/train_atp_day_cal_ad_horovod.py\", line 202, in <module>\r\n[1,1]<stderr>:    model.fit(\r\n[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\", line 1183, in fit\r\n[1,1]<stderr>:    tmp_logs = self.train_function(iterator)\r\n[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\r\n[1,1]<stderr>:    result = self._call(*args, **kwds)\r\n[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 917, in _call\r\n[1,1]<stderr>:    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 3023, in __call__\r\n[1,1]<stderr>:    return graph_function._call_flat(\r\n[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 1960, in _call_flat\r\n[1,1]<stderr>:    return self._build_call_outputs(self._inference_function.call(\r\n[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 591, in call\r\n[1,1]<stderr>:    outputs = execute.execute(\r\n[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n[1,1]<stderr>:    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n[1,1]<stderr>:tensorflow.python.framework.errors_impl.UnknownError:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n[1,1]<stderr>:\t [[{{node PartitionedCall/DistributedAdam_Allreduce/cond/then/_65/DistributedAdam_Allreduce/cond/HorovodAllreduce_grads_0}}]] [Op:__inference_train_function_1988]\r\n[1,1]<stderr>:\r\n[1,1]<stderr>:Function call stack:\r\n[1,1]<stderr>:train_function\r\n[1,1]<stderr>:\r\n-------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n-------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun detected that one or more processes exited with non-zero status, thus causing\r\nthe job to be terminated. The first process to do so was:\r\n\r\n  Process name: [[64271,1],2]\r\n  Exit code:    1\r\n-----------------------------------------\r\n```\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3412/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3412/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3383", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3383/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3383/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3383/events", "html_url": "https://github.com/horovod/horovod/issues/3383", "id": 1113540832, "node_id": "I_kwDOBfOI785CX0jg", "number": 3383, "title": "Cannot install horovod with tensorflow framework", "user": {"login": "Yikai-coder", "id": 54537903, "node_id": "MDQ6VXNlcjU0NTM3OTAz", "avatar_url": "https://avatars.githubusercontent.com/u/54537903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Yikai-coder", "html_url": "https://github.com/Yikai-coder", "followers_url": "https://api.github.com/users/Yikai-coder/followers", "following_url": "https://api.github.com/users/Yikai-coder/following{/other_user}", "gists_url": "https://api.github.com/users/Yikai-coder/gists{/gist_id}", "starred_url": "https://api.github.com/users/Yikai-coder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Yikai-coder/subscriptions", "organizations_url": "https://api.github.com/users/Yikai-coder/orgs", "repos_url": "https://api.github.com/users/Yikai-coder/repos", "events_url": "https://api.github.com/users/Yikai-coder/events{/privacy}", "received_events_url": "https://api.github.com/users/Yikai-coder/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2022-01-25T07:52:07Z", "updated_at": "2023-02-13T11:15:19Z", "closed_at": "2023-02-13T11:15:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "  I was trying to install horovod using the command below:\r\n``` HOROVOD_WITHOUT_GLOO=1 HOROVOD_WITHOUT_MXNET=1 HOROVOD_WITH_TENSORFLOW=1 HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_NCCL_HOME=/home/li/nccl/build pip install --no-cache-dir horovod[tensorflow] ```\r\n  After a while, I saw that the horovod was successfully installed, but when I run ```horovodrun --check-build``` to check the installation, I did not see the tensorflow framework was installed.\r\n```\r\nHorovod v0.23.0:\r\n\r\nAvailable Frameworks:\r\n    [ ] TensorFlow\r\n    [X] PyTorch\r\n    [ ] MXNet\r\n\r\nAvailable Controllers:\r\n    [X] MPI\r\n    [ ] Gloo\r\n\r\nAvailable Tensor Operations:\r\n    [X] NCCL\r\n    [ ] DDL\r\n    [ ] CCL\r\n    [X] MPI\r\n    [ ] Gloo \r\n```\r\nWhen I tried to import the module by ```import horovod.tensorflow```, I got such error:\r\n```\r\ntensorflow.python.framework.errors_impl.NotFoundError: /home/li/.local/lib/python3.8/site-packages/horovod/tensorflow/mpi_lib.cpython-38-x86_64-linux-gnu.so: undefined symbol: cudaGetDriverEntryPoint, version libcudart.so.11.0\r\n```\r\nThe environment I use now is below:\r\n```\r\nUbuntu 20.04\r\nCUDA: 11.6\r\npython: 3.8.10\r\nHorovod: 0.23.0\r\ntensorflow 2.7.0\r\n```\r\nI will be sincerely gratefully if someone can help me fix this problem.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3383/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3383/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3357", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3357/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3357/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3357/events", "html_url": "https://github.com/horovod/horovod/issues/3357", "id": 1099259946, "node_id": "I_kwDOBfOI785BhWAq", "number": 3357, "title": "test_ray.py::test_gpu_ids_num_workers sometimes fails on Buildkite", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "ashahab", "id": 690493, "node_id": "MDQ6VXNlcjY5MDQ5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/690493?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ashahab", "html_url": "https://github.com/ashahab", "followers_url": "https://api.github.com/users/ashahab/followers", "following_url": "https://api.github.com/users/ashahab/following{/other_user}", "gists_url": "https://api.github.com/users/ashahab/gists{/gist_id}", "starred_url": "https://api.github.com/users/ashahab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ashahab/subscriptions", "organizations_url": "https://api.github.com/users/ashahab/orgs", "repos_url": "https://api.github.com/users/ashahab/repos", "events_url": "https://api.github.com/users/ashahab/events{/privacy}", "received_events_url": "https://api.github.com/users/ashahab/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ashahab", "id": 690493, "node_id": "MDQ6VXNlcjY5MDQ5Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/690493?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ashahab", "html_url": "https://github.com/ashahab", "followers_url": "https://api.github.com/users/ashahab/followers", "following_url": "https://api.github.com/users/ashahab/following{/other_user}", "gists_url": "https://api.github.com/users/ashahab/gists{/gist_id}", "starred_url": "https://api.github.com/users/ashahab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ashahab/subscriptions", "organizations_url": "https://api.github.com/users/ashahab/orgs", "repos_url": "https://api.github.com/users/ashahab/repos", "events_url": "https://api.github.com/users/ashahab/events{/privacy}", "received_events_url": "https://api.github.com/users/ashahab/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2022-01-11T14:55:06Z", "updated_at": "2022-03-02T11:00:56Z", "closed_at": "2022-03-02T11:00:56Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "`CUDA_VISIBLE_DEVICES` seems to contain too many entries.\r\n\r\nExample from PR #3261: https://buildkite.com/horovod/horovod/builds/7041#9a807189-938e-491f-9f83-c6bc31420a67\r\n```\r\n        hjob = RayExecutor(setting, num_workers=4, use_gpu=True)\r\n        hjob.start()\r\n        all_envs = hjob.execute(lambda _: os.environ.copy())\r\n        all_cudas = {ev[\"CUDA_VISIBLE_DEVICES\"] for ev in all_envs}\r\n        assert len(all_cudas) == 1, all_cudas\r\n>       assert len(all_envs[0][\"CUDA_VISIBLE_DEVICES\"].split(\",\")) == 4\r\nE       assert 8 == 4\r\nE         +8\r\nE         -4\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3357/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3357/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3355", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3355/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3355/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3355/events", "html_url": "https://github.com/horovod/horovod/issues/3355", "id": 1097344649, "node_id": "I_kwDOBfOI785BaCaJ", "number": 3355, "title": "can horovod work only with Gloo\uff0cwithout MPI?", "user": {"login": "yongqiangz", "id": 4211003, "node_id": "MDQ6VXNlcjQyMTEwMDM=", "avatar_url": "https://avatars.githubusercontent.com/u/4211003?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongqiangz", "html_url": "https://github.com/yongqiangz", "followers_url": "https://api.github.com/users/yongqiangz/followers", "following_url": "https://api.github.com/users/yongqiangz/following{/other_user}", "gists_url": "https://api.github.com/users/yongqiangz/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongqiangz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongqiangz/subscriptions", "organizations_url": "https://api.github.com/users/yongqiangz/orgs", "repos_url": "https://api.github.com/users/yongqiangz/repos", "events_url": "https://api.github.com/users/yongqiangz/events{/privacy}", "received_events_url": "https://api.github.com/users/yongqiangz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2022-01-10T00:27:54Z", "updated_at": "2022-04-26T18:15:27Z", "closed_at": "2022-04-26T18:15:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying install horovod with tensorflow, I read the doc and found out that horovod controller has two options: MPI and Gloo, so i try to use Gloo only, my cmd is\r\n```\r\nHOROVOD_WITHOUT_MPI=1  HOROVOD_WITH_GLOO=1 HOROVOD_WITH_TENSORFLOW=1 pip install --no-cache-dir horovod[tensorflow]\r\n```\r\nbut when install success, check-build show like this:\r\n![image](https://user-images.githubusercontent.com/4211003/148707244-7070d04e-2a4b-41be-890b-30343926c865.png)\r\nwhen i run horovod demo, eror log:\r\n```\r\nValueError: Gloo support has not been built.  If this is not expected, ensure CMake is installed and reinstall Horovod with HOROVOD_WITH_GLOO=1 to debug the build error.\r\n``` \r\nmy question is\uff1a\r\n- can i use horovod without install MPI ?\r\n- i have set HOROVOD_WITH_TENSORFLOW=1 and install success, why check-build show no tensorflow?\r\n\r\n**Environment:**\r\n1. Framework: Tensorflow\r\n2. Framework version: 1.15\r\n3. Horovod version: 0.23.0\r\n4. MPI version: No MPI\r\n5. CUDA version:10.0\r\n6. NCCL version: 2.6.4\r\n7. Python version: 3.6\r\n8. Spark / PySpark version: No Spark\r\n9. Ray version: No Ray\r\n10. OS and version: Centos 7.6\r\n11. GCC version: 7.2.1\r\n12. CMake version: 3.20\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3355/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3355/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3352", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3352/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3352/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3352/events", "html_url": "https://github.com/horovod/horovod/issues/3352", "id": 1096693776, "node_id": "I_kwDOBfOI785BXjgQ", "number": 3352, "title": "GIL-related deadlock with PyTorch 1.10.1", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2022-01-07T21:48:12Z", "updated_at": "2022-01-10T19:38:23Z", "closed_at": "2022-01-10T19:38:23Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "# GIL-related deadlock with PyTorch 1.10.1\r\n\r\n**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.10.1\r\n3. Python version: 3.7.10\r\n\r\nI built Horovod like this:\r\n```\r\npip install -U torch==1.10.1+cpu pytorch-lightning==1.3.8 torchvision==0.11.2+cpu -f https://download.pytorch.org/whl/torch_stable.html\r\nHOROVOD_DEBUG=1 HOROVOD_WITHOUT_MPI=1 HOROVOD_WITH_GLOO=1 HOROVOD_WITH_PYTORCH=1 HOROVOD_WITH_MXNET=1 HOROVOD_WITH_TENSORFLOW=1 pip install -v -e .\r\n```\r\n\r\n**Bug report:**\r\nI've been looking at some test failures in PR #3261, that popped up after rebasing to master, with PyTorch 1.10.1 and Gloo. PR #3351 should fix some problems, I think, but when debugging locally I would occasionally run into hangs that I did not understand as easily. About 1 in 5 evocations of `horovodrun -np 2 -H localhost:2 --gloo pytest -v -x  test/parallel/test_torch.py` would encounter such a problem. I've seen this with various test cases: `test_async_sparse_allreduce`, `test_horovod_grouped_allreduce_grad_process_sets`, and maybe `test_broadcast_state` (not sure if that one really had the same cause).\r\n\r\nExample for `test_horovod_grouped_allreduce_grad` with `HOROVOD_LOG_LEVEL=TRACE`:\r\n\r\n```\r\n# ...\r\n[0]<stdout>:[T horovod/common/operations.cc:783] [0]: Performing grouped_allreduce.noname.13_1of5, grouped_allreduce.noname.13_2of5, grouped_allreduce.noname.13_3of5, grouped_allreduce.noname.13_4of5, grouped_allreduce.noname.13_5of5\r\n[1]<stdout>:[T horovod/common/operations.cc:783] [1]: Performing grouped_allreduce.noname.16_1of5, grouped_allreduce.noname.16_2of5, grouped_allreduce.noname.16_3of5, grouped_allreduce.noname.16_4of5, grouped_allreduce.noname.16_5of5\r\n[0]<stdout>:[T horovod/common/operations.cc:785] [0]: Processing 5 tensors\r\n[1]<stdout>:[T horovod/common/operations.cc:785] [1]: Processing 5 tensors\r\n[0]<stdout>:[T horovod/common/operations.cc:788] [0]: Finished performing grouped_allreduce.noname.13_1of5, grouped_allreduce.noname.13_2of5, grouped_allreduce.noname.13_3of5, grouped_allreduce.noname.13_4of5, grouped_allreduce.noname.13_5of5\r\n[1]<stdout>:[T horovod/common/operations.cc:788] [1]: Finished performing grouped_allreduce.noname.16_1of5, grouped_allreduce.noname.16_2of5, grouped_allreduce.noname.16_3of5, grouped_allreduce.noname.16_4of5, grouped_allreduce.noname.16_5of5\r\n[0]<stdout>:[T horovod/common/operations.cc:1496] [0]: Enqueued grouped_allreduce.noname.14_1of5; grouped_allreduce.noname.14_2of5; grouped_allreduce.noname.14_3of5; grouped_allreduce.noname.14_4of5; grouped_allreduce.noname.14_5of5;\r\n[1]<stdout>:[T horovod/common/operations.cc:1496] [1]: Enqueued grouped_allreduce.noname.17_1of5; grouped_allreduce.noname.17_2of5; grouped_allreduce.noname.17_3of5; grouped_allreduce.noname.17_4of5; grouped_allreduce.noname.17_5of5;\r\n[0]<stdout>:[T horovod/common/controller.cc:187] [0]: Sent 5 messages to coordinator.\r\n[1]<stdout>:[T horovod/common/controller.cc:187] [0]: Sent 5 messages to coordinator.\r\n[0]<stdout>:[T horovod/common/controller.cc:262] Adding messages from process-set rank 0\r\n[1]<stdout>:[T horovod/common/controller.cc:262] Adding messages from process-set rank 0\r\n[0]<stdout>:[T horovod/common/controller.cc:947] Created response of size 98260\r\n[1]<stdout>:[T horovod/common/controller.cc:947] Created response of size 98260\r\n[0]<stdout>:[T horovod/common/controller.cc:450] Sending ready responses as grouped_allreduce.noname.14_1of5, grouped_allreduce.noname.14_2of5, grouped_allreduce.noname.14_3of5, grouped_allreduce.noname.14_4of5, grouped_allreduce.noname.14_5of5;\r\n[1]<stdout>:[T horovod/common/controller.cc:450] Sending ready responses as grouped_allreduce.noname.17_1of5, grouped_allreduce.noname.17_2of5, grouped_allreduce.noname.17_3of5, grouped_allreduce.noname.17_4of5, grouped_allreduce.noname.17_5of5;\r\n[0]<stdout>:[T horovod/common/operations.cc:782] [0]: Process set id 1\r\n[1]<stdout>:[T horovod/common/operations.cc:782] [1]: Process set id 2\r\n[0]<stdout>:[T horovod/common/operations.cc:783] [0]: Performing grouped_allreduce.noname.14_1of5, grouped_allreduce.noname.14_2of5, grouped_allreduce.noname.14_3of5, grouped_allreduce.noname.14_4of5, grouped_allreduce.noname.14_5of5\r\n[1]<stdout>:[T horovod/common/operations.cc:783] [1]: Performing grouped_allreduce.noname.17_1of5, grouped_allreduce.noname.17_2of5, grouped_allreduce.noname.17_3of5, grouped_allreduce.noname.17_4of5, grouped_allreduce.noname.17_5of5\r\n[0]<stdout>:[T horovod/common/operations.cc:785] [0]: Processing 5 tensors\r\n[1]<stdout>:[T horovod/common/operations.cc:785] [1]: Processing 5 tensors\r\n[0]<stdout>:[T horovod/common/operations.cc:1496] [0]: Enqueued grouped_allreduce.noname.15_1of5; grouped_allreduce.noname.15_2of5; grouped_allreduce.noname.15_3of5; grouped_allreduce.noname.15_4of5; grouped_allreduce.noname.15_5of5;\r\n[1]<stdout>:[T horovod/common/operations.cc:788] [1]: Finished performing grouped_allreduce.noname.17_1of5, grouped_allreduce.noname.17_2of5, grouped_allreduce.noname.17_3of5, grouped_allreduce.noname.17_4of5, grouped_allreduce.noname.17_5of5\r\n# Hangs\r\n```\r\n\r\nInvestigating with GDB, I found that rank 0 was in a blocking collective operation (in this case `ProcessSetTable::InitializeRegisteredAndRemoveMarkedIfReady`, which is called at the beginning of each Horovod step), while rank 1 was stuck at the end of `PerformOperation` in the destructor of `std::vector<TensorTableEntry> entries`, which in Horovod code ultimately calls the destructor of a `::torch::Tensor`.\r\n\r\nBacktraces for rank 0:\r\n```\r\n(gdb) t 18\r\n[Switching to thread 18 (Thread 0x7fa34c3ee700 (LWP 291931))]\r\n#0  0x00007fa440cb3709 in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0\r\n(gdb) bt\r\n#0  0x00007fa440cb3709 in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0\r\n#1  0x00007fa317b97566 in gloo::transport::tcp::UnboundBuffer::waitSend(int*, std::chrono::duration<long, std::ratio<1l, 1000l> >) () from /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so\r\n#2  0x00007fa317b6ca3a in gloo::allgather(gloo::AllgatherOptions&) () from /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so\r\n#3  0x00007fa30ebe0d2d in horovod::common::GlooController::Allgather2Ints (this=0x592ad40, values=..., recv_values=std::vector of length 4, capacity 4 = {...}) at /mnt/data/max_temp/horovod/horovod/common/gloo/gloo_controller.cc:304\r\n#4  0x00007fa30eb2ea36 in horovod::common::ProcessSetTable::InitializeRegisteredAndRemoveMarkedIfReady_<horovod::common::GlooContext> (this=0x7fa312740cd0 <horovod::common::(anonymous namespace)::horovod_global+58722512>, global_context=..., removal_status=...) at /mnt/data/max_temp/horovod/horovod/common/process_set.cc:187\r\n#5  0x00007fa30eb2c505 in horovod::common::ProcessSetTable::InitializeRegisteredAndRemoveMarkedIfReady (this=0x7fa312740cd0 <horovod::common::(anonymous namespace)::horovod_global+58722512>, global_gloo_context=..., status=...) at /mnt/data/max_temp/horovod/horovod/common/process_set.cc:299\r\n#6  0x00007fa30eaff479 in horovod::common::(anonymous namespace)::RunLoopOnce (state=...) at /mnt/data/max_temp/horovod/horovod/common/operations.cc:737\r\n#7  0x00007fa30eafee5b in horovod::common::(anonymous namespace)::BackgroundThreadLoop (state=...) at /mnt/data/max_temp/horovod/horovod/common/operations.cc:651\r\n#8  0x00007fa30eb1ea9e in std::__invoke_impl<void, void (*)(horovod::common::HorovodGlobalState&), std::reference_wrapper<horovod::common::HorovodGlobalState> > (__f=@0x58f3fd0: 0x7fa30eafe19c <horovod::common::(anonymous namespace)::BackgroundThreadLoop(horovod::common::HorovodGlobalState&)>) at /usr/include/c++/9/bits/invoke.h:60\r\n#9  0x00007fa30eb1e9f9 in std::__invoke<void (*)(horovod::common::HorovodGlobalState&), std::reference_wrapper<horovod::common::HorovodGlobalState> > (__fn=@0x58f3fd0: 0x7fa30eafe19c <horovod::common::(anonymous namespace)::BackgroundThreadLoop(horovod::common::HorovodGlobalState&)>) at /usr/include/c++/9/bits/invoke.h:95\r\n#10 0x00007fa30eb1e959 in std::thread::_Invoker<std::tuple<void (*)(horovod::common::HorovodGlobalState&), std::reference_wrapper<horovod::common::HorovodGlobalState> > >::_M_invoke<0ul, 1ul> (this=0x58f3fc8) at /usr/include/c++/9/thread:244\r\n#11 0x00007fa30eb1e8ff in std::thread::_Invoker<std::tuple<void (*)(horovod::common::HorovodGlobalState&), std::reference_wrapper<horovod::common::HorovodGlobalState> > >::operator() (this=0x58f3fc8) at /usr/include/c++/9/thread:251\r\n#12 0x00007fa30eb1e888 in std::thread::_State_impl<std::thread::_Invoker<std::tuple<void (*)(horovod::common::HorovodGlobalState&), std::reference_wrapper<horovod::common::HorovodGlobalState> > > >::_M_run (this=0x58f3fc0) at /usr/include/c++/9/thread:195\r\n#13 0x00007fa432f1072f in execute_native_thread_routine () from /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/lib/libc10.so\r\n#14 0x00007fa440cad6ba in start_thread () from /lib/x86_64-linux-gnu/libpthread.so.0\r\n#15 0x00007fa43fe9051d in clone () from /lib/x86_64-linux-gnu/libc.so.6\r\n\r\n(gdb) t 1\r\n[Switching to thread 1 (Thread 0x7fa4410d3700 (LWP 287801))]\r\n#0  0x00007fa440cb626d in __lll_lock_wait () from /lib/x86_64-linux-gnu/libpthread.so.0\r\n(gdb) bt\r\n#0  0x00007fa440cb626d in __lll_lock_wait () from /lib/x86_64-linux-gnu/libpthread.so.0\r\n#1  0x00007fa440cafe42 in pthread_mutex_lock () from /lib/x86_64-linux-gnu/libpthread.so.0\r\n#2  0x00007fa30eb05082 in __gthread_mutex_lock (__mutex=0x7fa312740cd0 <horovod::common::(anonymous namespace)::horovod_global+58722512>) at /usr/include/x86_64-linux-gnu/c++/9/bits/gthr-default.h:749\r\n#3  0x00007fa30eb050d2 in __gthread_recursive_mutex_lock (__mutex=0x7fa312740cd0 <horovod::common::(anonymous namespace)::horovod_global+58722512>) at /usr/include/x86_64-linux-gnu/c++/9/bits/gthr-default.h:811\r\n#4  0x00007fa30eb052f2 in std::recursive_mutex::lock (this=0x7fa312740cd0 <horovod::common::(anonymous namespace)::horovod_global+58722512>) at /usr/include/c++/9/mutex:106\r\n#5  0x00007fa30eb08836 in std::lock_guard<std::recursive_mutex>::lock_guard (this=0x7fffcebaa080, __m=...) at /usr/include/c++/9/bits/std_mutex.h:159\r\n#6  0x00007fa30eb2cb70 in horovod::common::ProcessSetTable::Contains (this=0x7fa312740cd0 <horovod::common::(anonymous namespace)::horovod_global+58722512>, id=2) at /mnt/data/max_temp/horovod/horovod/common/process_set.cc:369\r\n#7  0x00007fa30eb0143e in horovod::common::EnqueueTensorAllreduces(std::vector<std::shared_ptr<horovod::common::OpContext>, std::allocator<std::shared_ptr<horovod::common::OpContext> > >&, std::vector<std::shared_ptr<horovod::common::Tensor>, std::allocator<std::shared_ptr<horovod::common::Tensor> > >&, std::vector<std::shared_ptr<horovod::common::Tensor>, std::allocator<std::shared_ptr<horovod::common::Tensor> > >&, std::vector<horovod::common::ReadyEventList, std::allocator<horovod::common::ReadyEventList> >&, std::vector<std::string, std::allocator<std::string> >&, int, std::vector<std::function<void (horovod::common::Status const&)>, std::allocator<std::function<void (horovod::common::Status const&)> > >&, horovod::common::ReduceOp, double, double, int) (contexts=std::vector of length 5, capacity 5 = {...}, tensors=std::vector of length 5, capacity 5 = {...}, outputs=std::vector of length 5, capacity 5 = {...}, ready_event_lists=std::vector of length 5, capacity 5 = {...}, names=std::vector of length 5, capacity 5 = {...}, device=-1, callbacks=std::vector of length 5, capacity 5 = {...}, reduce_op=horovod::common::SUM, prescale_factor=1, postscale_factor=1, process_set_id=2) at /mnt/data/max_temp/horovod/horovod/common/operations.cc:1398\r\n#8  0x00007fa30ebfeb04 in horovod::torch::DoGroupedAllreduce (tensors=std::vector of length 5, capacity 5 = {...}, outputs=std::vector of length 5, capacity 5 = {...}, divisor=1, name=\"\", reduce_op_int=1, prescale_factor=1, postscale_factor=1, process_set_id=2) at /mnt/data/max_temp/horovod/horovod/torch/mpi_ops_v2.cc:225\r\n#9  0x00007fa30ec34d32 in pybind11::detail::argument_loader<std::vector<at::Tensor, std::allocator<at::Tensor> > const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, int, std::string const&, int, double, double, int>::call_impl<int, int (*&)(std::vector<at::Tensor, std::allocator<at::Tensor> > const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, int, std::string const&, int, double, double, int), 0ul, 1ul, 2ul, 3ul, 4ul, 5ul, 6ul, 7ul, pybind11::detail::void_type>(int (*&)(std::vector<at::Tensor, std::allocator<at::Tensor> > const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, int, std::string const&, int, double, double, int), std::integer_sequence<unsigned long, 0ul, 1ul, 2ul, 3ul, 4ul, 5ul, 6ul, 7ul>, pybind11::detail::void_type&&) && (this=0x7fffcebaa6d0, f=@0x54da568: 0x7fa30ebfe4a9 <horovod::torch::DoGroupedAllreduce(std::vector<at::Tensor, std::allocator<at::Tensor> > const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, int, std::string const&, int, double, double, int)>) at /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/include/pybind11/cast.h:2042\r\n# ...\r\n```\r\n\r\nBacktraces for rank 1:\r\n```\r\n(gdb) t 18\r\n[Switching to thread 18 (Thread 0x7ff43bce1700 (LWP 291928))]\r\n#0  0x00007ff4585a6709 in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0\r\n(gdb) bt\r\n#0  0x00007ff4585a6709 in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0\r\n#1  0x000000000061a240 in ?? ()\r\n#2  0x000000000061a802 in PyEval_AcquireThread ()\r\n#3  0x00007ff4499457ae in pybind11::gil_scoped_acquire::gil_scoped_acquire() () from /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/lib/libtorch_python.so\r\n#4  0x00007ff44a188a6c in (anonymous namespace)::concrete_decref_fn(c10::impl::PyInterpreter const*, _object*, bool) () from /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/lib/libtorch_python.so\r\n#5  0x00007ff4495af9bb in c10::TensorImpl::release_resources() () from /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/lib/libc10.so\r\n#6  0x00007ff327734fd1 in c10::intrusive_ptr<c10::TensorImpl, c10::UndefinedTensorImpl>::reset_ (this=0x4b2d998) at /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/include/c10/util/intrusive_ptr.h:268\r\n#7  0x00007ff32772eb2a in c10::intrusive_ptr<c10::TensorImpl, c10::UndefinedTensorImpl>::~intrusive_ptr (this=0x4b2d998, __in_chrg=<optimized out>) at /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/include/c10/util/intrusive_ptr.h:349\r\n#8  0x00007ff327720434 in at::TensorBase::~TensorBase (this=0x4b2d998, __in_chrg=<optimized out>) at /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/include/ATen/core/TensorBase.h:76\r\n#9  0x00007ff32772065c in at::Tensor::~Tensor (this=0x4b2d998, __in_chrg=<optimized out>) at /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:75\r\n#10 0x00007ff3277588a8 in horovod::torch::TorchTensor::~TorchTensor (this=0x4b2d990, __in_chrg=<optimized out>) at /mnt/data/max_temp/horovod/horovod/torch/adapter_v2.h:42\r\n#11 0x00007ff327753b23 in __gnu_cxx::new_allocator<horovod::torch::TorchTensor>::destroy<horovod::torch::TorchTensor> (this=0x4b2d990, __p=0x4b2d990) at /usr/include/c++/9/ext/new_allocator.h:152\r\n#12 0x00007ff327753a65 in std::allocator_traits<std::allocator<horovod::torch::TorchTensor> >::destroy<horovod::torch::TorchTensor> (__a=..., __p=0x4b2d990) at /usr/include/c++/9/bits/alloc_traits.h:496\r\n#13 0x00007ff327753737 in std::_Sp_counted_ptr_inplace<horovod::torch::TorchTensor, std::allocator<horovod::torch::TorchTensor>, (__gnu_cxx::_Lock_policy)2>::_M_dispose (this=0x4b2d980) at /usr/include/c++/9/bits/shared_ptr_base.h:557\r\n#14 0x00007ff3275eff56 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release (this=0x4b2d980) at /usr/include/c++/9/bits/shared_ptr_base.h:155\r\n#15 0x00007ff3275ed83f in std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count (this=0x7ff320031430, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:730\r\n#16 0x00007ff32761d700 in std::__shared_ptr<horovod::common::Tensor, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr (this=0x7ff320031428, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:1169\r\n#17 0x00007ff32761d742 in std::shared_ptr<horovod::common::Tensor>::~shared_ptr (this=0x7ff320031428 = {...}, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr.h:103\r\n#18 0x00007ff32761d9a6 in horovod::common::TensorTableEntry::~TensorTableEntry (this=0x7ff320031410, __in_chrg=<optimized out>) at /mnt/data/max_temp/horovod/horovod/common/common.h:348\r\n#19 0x00007ff32762f9b2 in std::_Destroy<horovod::common::TensorTableEntry> (__pointer=0x7ff320031410) at /usr/include/c++/9/bits/stl_construct.h:98\r\n#20 0x00007ff32762cb27 in std::_Destroy_aux<false>::__destroy<horovod::common::TensorTableEntry*> (__first=0x7ff320031410, __last=0x7ff320031570) at /usr/include/c++/9/bits/stl_construct.h:108\r\n#21 0x00007ff327628322 in std::_Destroy<horovod::common::TensorTableEntry*> (__first=0x7ff320031200, __last=0x7ff320031570) at /usr/include/c++/9/bits/stl_construct.h:137\r\n#22 0x00007ff327623293 in std::_Destroy<horovod::common::TensorTableEntry*, horovod::common::TensorTableEntry> (__first=0x7ff320031200, __last=0x7ff320031570) at /usr/include/c++/9/bits/stl_construct.h:206\r\n#23 0x00007ff32761f39f in std::vector<horovod::common::TensorTableEntry, std::allocator<horovod::common::TensorTableEntry> >::~vector (this=0x7ff43bce0610 = {...}, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/stl_vector.h:677\r\n#24 0x00007ff327614c37 in horovod::common::(anonymous namespace)::PerformOperation (response=..., process_set=...) at /mnt/data/max_temp/horovod/horovod/common/operations.cc:292\r\n#25 0x00007ff3276169a8 in horovod::common::(anonymous namespace)::RunLoopOnce (state=...) at /mnt/data/max_temp/horovod/horovod/common/operations.cc:787\r\n#26 0x00007ff327615e5b in horovod::common::(anonymous namespace)::BackgroundThreadLoop (state=...) at /mnt/data/max_temp/horovod/horovod/common/operations.cc:651\r\n#27 0x00007ff327635a9e in std::__invoke_impl<void, void (*)(horovod::common::HorovodGlobalState&), std::reference_wrapper<horovod::common::HorovodGlobalState> > (__f=@0x4c862e0: 0x7ff32761519c <horovod::common::(anonymous namespace)::BackgroundThreadLoop(horovod::common::HorovodGlobalState&)>) at /usr/include/c++/9/bits/invoke.h:60\r\n#28 0x00007ff3276359f9 in std::__invoke<void (*)(horovod::common::HorovodGlobalState&), std::reference_wrapper<horovod::common::HorovodGlobalState> > (__fn=@0x4c862e0: 0x7ff32761519c <horovod::common::(anonymous namespace)::BackgroundThreadLoop(horovod::common::HorovodGlobalState&)>) at /usr/include/c++/9/bits/invoke.h:95\r\n#29 0x00007ff327635959 in std::thread::_Invoker<std::tuple<void (*)(horovod::common::HorovodGlobalState&), std::reference_wrapper<horovod::common::HorovodGlobalState> > >::_M_invoke<0ul, 1ul> (this=0x4c862d8) at /usr/include/c++/9/thread:244\r\n#30 0x00007ff3276358ff in std::thread::_Invoker<std::tuple<void (*)(horovod::common::HorovodGlobalState&), std::reference_wrapper<horovod::common::HorovodGlobalState> > >::operator() (this=0x4c862d8) at /usr/include/c++/9/thread:251\r\n#31 0x00007ff327635888 in std::thread::_State_impl<std::thread::_Invoker<std::tuple<void (*)(horovod::common::HorovodGlobalState&), std::reference_wrapper<horovod::common::HorovodGlobalState> > > >::_M_run (this=0x4c862d0) at /usr/include/c++/9/thread:195\r\n#32 0x00007ff4495df72f in execute_native_thread_routine () from /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/lib/libc10.so\r\n#33 0x00007ff4585a06ba in start_thread () from /lib/x86_64-linux-gnu/libpthread.so.0\r\n#34 0x00007ff45778351d in clone () from /lib/x86_64-linux-gnu/libc.so.6\r\n\r\n\r\nThread 1 (Thread 0x7ff4589c6700 (LWP 287804) \"pytest\"):\r\n#0  0x00007ff457766927 in sched_yield () from /lib/x86_64-linux-gnu/libc.so.6\r\n#1  0x00007ff327661937 in __gthread_yield () at /usr/include/x86_64-linux-gnu/c++/9/bits/gthr-default.h:693\r\n#2  0x00007ff327661977 in std::this_thread::yield () at /usr/include/c++/9/thread:356\r\n#3  0x00007ff3277196cf in horovod::torch::WaitAndClear (handle=15) at /mnt/data/max_temp/horovod/horovod/torch/mpi_ops_v2.cc:609\r\n#4  0x00007ff32774cda2 in pybind11::detail::argument_loader<int>::call_impl<void, void (*&)(int), 0ul, pybind11::detail::void_type>(void (*&)(int), std::integer_sequence<unsigned long, 0ul>, pybind11::detail::void_type&&) && (this=0x7fff2481f6ec, f=@0x4a679d8: 0x7ff32771969a <horovod::torch::WaitAndClear(int)>) at /learndata4/maxDev/horovod-dev-venv/lib/python3.7/site-packages/torch/include/pybind11/cast.h:2042\r\n#...\r\n```\r\n\r\n**Analysis:**\r\n\r\nRank 0: Thread 1 is blocked waiting for the TensorTable mutex. Thread 18 (Horovod background loop) holds that mutex and is blocked in an Allgather, waiting for rank 1 to join.\r\n\r\nRank 1: Thread 1 holds the Python GIL and is waiting (in `synchronize()` from mpi_ops.py). Thread 18 is waiting to\r\nacquire the GIL, which it apparently needs to relase a PyTorch tensor.\r\n\r\nIt's unclear if the behavior of PyTorch has changed here in a recent release. \r\n\r\n=> Releasing the GIL in thread 1 while it is yielding should help. Rank 1 would be unblocked then, which in turn would unblock rank 0.\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3352/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3352/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3330", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3330/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3330/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3330/events", "html_url": "https://github.com/horovod/horovod/issues/3330", "id": 1086399868, "node_id": "I_kwDOBfOI785AwSV8", "number": 3330, "title": "pip3 install -e . run errors", "user": {"login": "idiomaticrefactoring", "id": 29055749, "node_id": "MDQ6VXNlcjI5MDU1NzQ5", "avatar_url": "https://avatars.githubusercontent.com/u/29055749?v=4", "gravatar_id": "", "url": "https://api.github.com/users/idiomaticrefactoring", "html_url": "https://github.com/idiomaticrefactoring", "followers_url": "https://api.github.com/users/idiomaticrefactoring/followers", "following_url": "https://api.github.com/users/idiomaticrefactoring/following{/other_user}", "gists_url": "https://api.github.com/users/idiomaticrefactoring/gists{/gist_id}", "starred_url": "https://api.github.com/users/idiomaticrefactoring/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/idiomaticrefactoring/subscriptions", "organizations_url": "https://api.github.com/users/idiomaticrefactoring/orgs", "repos_url": "https://api.github.com/users/idiomaticrefactoring/repos", "events_url": "https://api.github.com/users/idiomaticrefactoring/events{/privacy}", "received_events_url": "https://api.github.com/users/idiomaticrefactoring/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-12-22T02:58:55Z", "updated_at": "2021-12-22T08:06:41Z", "closed_at": "2021-12-22T08:06:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Checklist:**\r\nyes\r\n\r\n**Bug report:**\r\n**Hello I want to run existing test suites, so I run command:**\r\n**pip3 install -e .**\r\n**python3 -m pytest -v test/single/test_run.py**\r\n\r\n**However, it occur errors, Actually, I am weird that why I run \"pip3 install -e .\", it does not install TensorFlow or other packages?**\r\n\r\nCollecting cloudpickle\r\n  Using cached cloudpickle-2.0.0-py3-none-any.whl (25 kB)\r\nCollecting psutil\r\n  Using cached psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\r\nCollecting pyyaml\r\n  Using cached PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\r\nCollecting cffi>=1.4.0\r\n  Using cached cffi-1.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (427 kB)\r\nCollecting pycparser\r\n  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\r\nInstalling collected packages: cloudpickle, psutil, pyyaml, pycparser, cffi, horovod\r\n  Running setup.py develop for horovod\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /mnt/zejun/smp/data/python_star_2000repo/horovod/venv_test_7/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/mnt/zejun/smp/data/python_star_2000repo/horovod/setup.py'\"'\"'; __file__='\"'\"'/mnt/zejun/smp/data/python_star_2000repo/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\r\n         cwd: /mnt/zejun/smp/data/python_star_2000repo/horovod/\r\n    Complete output (97 lines):\r\n    running develop\r\n    running egg_info\r\n    creating horovod.egg-info\r\n    writing horovod.egg-info/PKG-INFO\r\n    writing dependency_links to horovod.egg-info/dependency_links.txt\r\n    writing entry points to horovod.egg-info/entry_points.txt\r\n    writing requirements to horovod.egg-info/requires.txt\r\n    writing top-level names to horovod.egg-info/top_level.txt\r\n    writing manifest file 'horovod.egg-info/SOURCES.txt'\r\n    reading manifest file 'horovod.egg-info/SOURCES.txt'\r\n    reading manifest template 'MANIFEST.in'\r\n    warning: no files found matching '*.hpp' under directory '*'\r\n    no previously-included directories found matching '.eggs'\r\n    warning: no directories found matching 'third_party/eigen/Eigen'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/Eigen'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/IterativeLinearSolvers'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/MetisSupport'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/Sparse'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/SparseCholesky'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/SparseLU'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/src/IterativeSolvers/*'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/src/OrderingMethods/Amd.h'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/src/SparseCholesky/*'\r\n    warning: no previously-included files found matching 'third_party/eigen/unsupported/test/mpreal/mpreal.h'\r\n    warning: no previously-included files found matching 'third_party/eigen/unsupported/Eigen/FFT'\r\n    warning: no previously-included files found matching 'third_party/eigen/unsupported/Eigen/MPRealSupport'\r\n    warning: no previously-included files found matching 'third_party/eigen/doc/PreprocessorDirectives.dox'\r\n    warning: no previously-included files found matching 'third_party/eigen/doc/UsingIntelMKL.dox'\r\n    warning: no previously-included files found matching 'third_party/eigen/doc/SparseLinearSystems.dox'\r\n    warning: no previously-included files found matching 'third_party/eigen/COPYING.GPL'\r\n    warning: no previously-included files found matching 'third_party/eigen/COPYING.LGPL'\r\n    warning: no previously-included files found matching 'third_party/eigen/COPYING.README'\r\n    warning: no directories found matching 'third_party/gloo/cmake'\r\n    warning: no files found matching 'CMakeLists.txt' under directory 'third_party/gloo'\r\n    warning: no files found matching '*.in' under directory 'third_party/gloo'\r\n    writing manifest file 'horovod.egg-info/SOURCES.txt'\r\n    running build_ext\r\n    -- Could not find CCache. Consider installing CCache to speed up compilation.\r\n    -- The CXX compiler identification is GNU 7.5.0\r\n    -- Check for working CXX compiler: /usr/bin/c++\r\n    -- Check for working CXX compiler: /usr/bin/c++ -- works\r\n    -- Detecting CXX compiler ABI info\r\n    -- Detecting CXX compiler ABI info - done\r\n    -- Detecting CXX compile features\r\n    -- Detecting CXX compile features - done\r\n    -- Build architecture flags: -mf16c -mavx -mfma\r\n    -- Using command /mnt/zejun/smp/data/python_star_2000repo/horovod/venv_test_7/bin/python3.7\r\n    -- Could NOT find MPI_CXX (missing: MPI_CXX_LIB_NAMES MPI_CXX_HEADER_DIR MPI_CXX_WORKS)\r\n    -- Could NOT find MPI (missing: MPI_CXX_FOUND)\r\n    -- Could NOT find NVTX (missing: NVTX_INCLUDE_DIR)\r\n    CMake Error at CMakeLists.txt:265 (add_subdirectory):\r\n      The source directory\r\n    \r\n        /mnt/zejun/smp/data/python_star_2000repo/horovod/third_party/gloo\r\n    \r\n      does not contain a CMakeLists.txt file.\r\n    \r\n    \r\n    CMake Error at CMakeLists.txt:267 (target_compile_definitions):\r\n      Cannot specify compile definitions for target \"gloo\" which is not built by\r\n      this project.\r\n    \r\n    \r\n    -- Could NOT find Tensorflow (missing: Tensorflow_LIBRARIES) (Required is at least version \"1.15.0\")\r\n    -- Could NOT find Pytorch: Found unsuitable version \"\", but required is at least \"1.2.0\" (found )\r\n    -- Could NOT find Mxnet (missing: Mxnet_LIBRARIES) (Required is at least version \"1.4.0\")\r\n    -- Configuring incomplete, errors occurred!\r\n    See also \"/mnt/zejun/smp/data/python_star_2000repo/horovod/build/temp.linux-x86_64-3.7/RelWithDebInfo/CMakeFiles/CMakeOutput.log\".\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/mnt/zejun/smp/data/python_star_2000repo/horovod/setup.py\", line 213, in <module>\r\n        'horovodrun = horovod.runner.launch:run_commandline'\r\n      File \"/mnt/zejun/smp/data/python_star_2000repo/horovod/venv_test_7/lib/python3.7/site-packages/setuptools/__init__.py\", line 144, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/usr/lib/python3.7/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/usr/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/mnt/zejun/smp/data/python_star_2000repo/horovod/venv_test_7/lib/python3.7/site-packages/setuptools/command/develop.py\", line 38, in run\r\n        self.install_for_development()\r\n      File \"/mnt/zejun/smp/data/python_star_2000repo/horovod/venv_test_7/lib/python3.7/site-packages/setuptools/command/develop.py\", line 140, in install_for_development\r\n        self.run_command('build_ext')\r\n      File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/mnt/zejun/smp/data/python_star_2000repo/horovod/venv_test_7/lib/python3.7/site-packages/setuptools/command/build_ext.py\", line 87, in run\r\n        _build_ext.run(self)\r\n      File \"/usr/lib/python3.7/distutils/command/build_ext.py\", line 340, in run\r\n        self.build_extensions()\r\n      File \"/mnt/zejun/smp/data/python_star_2000repo/horovod/setup.py\", line 101, in build_extensions\r\n        cwd=cmake_build_dir)\r\n      File \"/usr/lib/python3.7/subprocess.py\", line 363, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['cmake', '/mnt/zejun/smp/data/python_star_2000repo/horovod', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/mnt/zejun/smp/data/python_star_2000repo/horovod/build/lib.linux-x86_64-3.7', '-DPYTHON_EXECUTABLE:FILEPATH=/mnt/zejun/smp/data/python_star_2000repo/horovod/venv_test_7/bin/python3.7']' returned non-zero exit status 1.\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /mnt/zejun/smp/data/python_star_2000repo/horovod/venv_test_7/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/mnt/zejun/smp/data/python_star_2000repo/horovod/setup.py'\"'\"'; __file__='\"'\"'/mnt/zejun/smp/data/python_star_2000repo/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps Check the logs for full command output.\r\nWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\r\nYou should consider upgrading via the '/mnt/zejun/smp/data/python_star_2000repo/horovod/venv_test_7/bin/python3.7 -m pip install --upgrade pip' command.\r\nCollecting pytest\r\n  Using cached pytest-6.2.5-py3-none-any.whl (280 kB)\r\nCollecting pytest-mock\r\n  Using cached pytest_mock-3.6.1-py3-none-any.whl (12 kB)\r\nCollecting pytest-cov\r\n  Using cached pytest_cov-3.0.0-py3-none-any.whl (20 kB)\r\nCollecting pluggy<2.0,>=0.12\r\n  Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\r\nCollecting iniconfig\r\n  Using cached iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\r\nCollecting importlib-metadata>=0.12; python_version < \"3.8\"\r\n  Using cached importlib_metadata-4.10.0-py3-none-any.whl (17 kB)\r\nCollecting toml\r\n  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\r\nCollecting packaging\r\n  Using cached packaging-21.3-py3-none-any.whl (40 kB)\r\nCollecting attrs>=19.2.0\r\n  Using cached attrs-21.2.0-py2.py3-none-any.whl (53 kB)\r\nCollecting py>=1.8.2\r\n  Using cached py-1.11.0-py2.py3-none-any.whl (98 kB)\r\nCollecting coverage[toml]>=5.2.1\r\n  Using cached coverage-6.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\r\nCollecting typing-extensions>=3.6.4; python_version < \"3.8\"\r\n  Using cached typing_extensions-4.0.1-py3-none-any.whl (22 kB)\r\nCollecting zipp>=0.5\r\n  Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\r\nCollecting pyparsing!=3.0.5,>=2.0.2\r\n  Using cached pyparsing-3.0.6-py3-none-any.whl (97 kB)\r\nCollecting tomli; extra == \"toml\"\r\n  Using cached tomli-2.0.0-py3-none-any.whl (12 kB)\r\nInstalling collected packages: typing-extensions, zipp, importlib-metadata, pluggy, iniconfig, toml, pyparsing, packaging, attrs, py, pytest, pytest-mock, tomli, coverage, pytest-cov\r\nSuccessfully installed attrs-21.2.0 coverage-6.2 importlib-metadata-4.10.0 iniconfig-1.1.1 packaging-21.3 pluggy-1.0.0 py-1.11.0 pyparsing-3.0.6 pytest-6.2.5 pytest-cov-3.0.0 pytest-mock-3.6.1 toml-0.10.2 tomli-2.0.0 typing-extensions-4.0.1 zipp-3.6.0\r\nWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\r\nYou should consider upgrading via the '/mnt/zejun/smp/data/python_star_2000repo/horovod/venv_test_7/bin/python3.7 -m pip install --upgrade pip' command.\r\n*************************install*************************\r\n*************************test*************************\r\n============================= test session starts ==============================\r\nplatform linux -- Python 3.7.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- /mnt/zejun/smp/data/python_star_2000repo/horovod/venv_test_7/bin/python3.7\r\ncachedir: .pytest_cache\r\nrootdir: /mnt/zejun/smp/data/python_star_2000repo/horovod, configfile: setup.cfg\r\nplugins: cov-3.0.0, mock-3.6.1\r\ncollecting ... collected 0 items / 1 error\r\n\r\n==================================== ERRORS ====================================\r\n___________________ ERROR collecting test/single/test_run.py ___________________\r\nImportError while importing test module '/mnt/zejun/smp/data/python_star_2000repo/horovod/test/single/test_run.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.7/importlib/__init__.py:127: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntest/single/test_run.py:29: in <module>\r\n    import mock\r\nE   ModuleNotFoundError: No module named 'mock'\r\n=========================== short test summary info ============================\r\nERROR test/single/test_run.py\r\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3330/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3330/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3314", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3314/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3314/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3314/events", "html_url": "https://github.com/horovod/horovod/issues/3314", "id": 1078393485, "node_id": "I_kwDOBfOI785ARvqN", "number": 3314, "title": "`TorchTests::test_delta_optimizer` causes deadlocks in later tests", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Tixxx", "id": 26332583, "node_id": "MDQ6VXNlcjI2MzMyNTgz", "avatar_url": "https://avatars.githubusercontent.com/u/26332583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tixxx", "html_url": "https://github.com/Tixxx", "followers_url": "https://api.github.com/users/Tixxx/followers", "following_url": "https://api.github.com/users/Tixxx/following{/other_user}", "gists_url": "https://api.github.com/users/Tixxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tixxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tixxx/subscriptions", "organizations_url": "https://api.github.com/users/Tixxx/orgs", "repos_url": "https://api.github.com/users/Tixxx/repos", "events_url": "https://api.github.com/users/Tixxx/events{/privacy}", "received_events_url": "https://api.github.com/users/Tixxx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Tixxx", "id": 26332583, "node_id": "MDQ6VXNlcjI2MzMyNTgz", "avatar_url": "https://avatars.githubusercontent.com/u/26332583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tixxx", "html_url": "https://github.com/Tixxx", "followers_url": "https://api.github.com/users/Tixxx/followers", "following_url": "https://api.github.com/users/Tixxx/following{/other_user}", "gists_url": "https://api.github.com/users/Tixxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tixxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tixxx/subscriptions", "organizations_url": "https://api.github.com/users/Tixxx/orgs", "repos_url": "https://api.github.com/users/Tixxx/repos", "events_url": "https://api.github.com/users/Tixxx/events{/privacy}", "received_events_url": "https://api.github.com/users/Tixxx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2021-12-13T11:09:06Z", "updated_at": "2022-01-24T18:47:20Z", "closed_at": "2022-01-24T18:47:20Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.10\r\n3. Horovod version: master\r\n4. MPI version: OpenMPI\r\n\r\n**Bug report:**\r\nWith PyTorch 1.10 we occasionally observed deadlocks in `TorchTests::test_dynamic_requires_grad`. These went away by skipping `test_delta_optimizer` (the test before the previous test in alphabetical order), see https://github.com/horovod/horovod/pull/3291#issuecomment-988021354. Since that test only applies with MPI and when run on GPUs, only a few CI configurations can encounter the problem.\r\n\r\nThe skip is a workaround for some more fundamental problem that is not understood. It should be fixed and `test_delta_optimizer` should be re-eneabled then.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3314/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3314/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3308", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3308/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3308/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3308/events", "html_url": "https://github.com/horovod/horovod/issues/3308", "id": 1075341452, "node_id": "I_kwDOBfOI785AGGiM", "number": 3308, "title": "Segmentation fault with `hvd.barrier`", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Tixxx", "id": 26332583, "node_id": "MDQ6VXNlcjI2MzMyNTgz", "avatar_url": "https://avatars.githubusercontent.com/u/26332583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tixxx", "html_url": "https://github.com/Tixxx", "followers_url": "https://api.github.com/users/Tixxx/followers", "following_url": "https://api.github.com/users/Tixxx/following{/other_user}", "gists_url": "https://api.github.com/users/Tixxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tixxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tixxx/subscriptions", "organizations_url": "https://api.github.com/users/Tixxx/orgs", "repos_url": "https://api.github.com/users/Tixxx/repos", "events_url": "https://api.github.com/users/Tixxx/events{/privacy}", "received_events_url": "https://api.github.com/users/Tixxx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Tixxx", "id": 26332583, "node_id": "MDQ6VXNlcjI2MzMyNTgz", "avatar_url": "https://avatars.githubusercontent.com/u/26332583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tixxx", "html_url": "https://github.com/Tixxx", "followers_url": "https://api.github.com/users/Tixxx/followers", "following_url": "https://api.github.com/users/Tixxx/following{/other_user}", "gists_url": "https://api.github.com/users/Tixxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tixxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tixxx/subscriptions", "organizations_url": "https://api.github.com/users/Tixxx/orgs", "repos_url": "https://api.github.com/users/Tixxx/repos", "events_url": "https://api.github.com/users/Tixxx/events{/privacy}", "received_events_url": "https://api.github.com/users/Tixxx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2021-12-09T09:21:17Z", "updated_at": "2021-12-14T10:44:50Z", "closed_at": "2021-12-14T10:44:50Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.10\r\n3. Horovod version: master\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nThe following variation of `TorchTests::test_horovod_broadcast_duplicate_name_error` has been observed to trigger segmentation faults with PyTorch 1.10 and OpenMPI (see this comment https://github.com/horovod/horovod/pull/3300#issuecomment-986264420)\r\n``` Python\r\n    def test_horovod_broadcast_duplicate_name_error(self):\r\n        \"\"\"Test that the broadcast raises an error if there are\r\n        two concurrent operations with the same name.\"\"\"\r\n        hvd.init()\r\n        size = hvd.size()\r\n        rank = hvd.rank()\r\n\r\n        # This test does not apply if there is only one worker.\r\n        if size == 1:\r\n            self.skipTest(\"Only one worker available\")\r\n\r\n        dims = [17] * 3\r\n        tensor = torch.FloatTensor(*dims)\r\n\r\n        if rank == 0:\r\n            hvd.broadcast_async(tensor, name='duplicate_name', root_rank=0)\r\n            try:\r\n                hvd.broadcast_async(tensor, name='duplicate_name', root_rank=0)\r\n                assert False, 'hvd.broadcast_async did not throw error'\r\n            except (torch.FatalError, ValueError):\r\n                pass\r\n        hvd.barrier()\r\n        ## Workaround:\r\n        # hvd.allreduce(torch.FloatTensor([1]), name=\"synch1\")\r\n        if rank > 0:\r\n            hvd.broadcast_async(tensor, name='duplicate_name', root_rank=0)\r\n            try:\r\n                hvd.broadcast_async(tensor, name='duplicate_name', root_rank=0)\r\n                assert False, 'hvd.broadcast_async did not throw error'\r\n            except (torch.FatalError, ValueError):\r\n                pass\r\n        hvd.barrier()\r\n        ## Workaround:\r\n        # hvd.allreduce(torch.FloatTensor([2]), name=\"synch2\")\r\n```\r\nThe same applies to equivalent tests for the other collective ops. As a workaround we use `allreduce` instead of `barrier` for now.\r\n\r\nWhen just the second `barrier` was replaced by an `allreduce`, but the first was kept, we still observed some test failures. Maybe those were caused by undefinded behavior?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3308/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3308/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3297", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3297/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3297/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3297/events", "html_url": "https://github.com/horovod/horovod/issues/3297", "id": 1068154410, "node_id": "I_kwDOBfOI784_qr4q", "number": 3297, "title": "Fail to install horovod 0.19.0", "user": {"login": "coolnut12138", "id": 43488547, "node_id": "MDQ6VXNlcjQzNDg4NTQ3", "avatar_url": "https://avatars.githubusercontent.com/u/43488547?v=4", "gravatar_id": "", "url": "https://api.github.com/users/coolnut12138", "html_url": "https://github.com/coolnut12138", "followers_url": "https://api.github.com/users/coolnut12138/followers", "following_url": "https://api.github.com/users/coolnut12138/following{/other_user}", "gists_url": "https://api.github.com/users/coolnut12138/gists{/gist_id}", "starred_url": "https://api.github.com/users/coolnut12138/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/coolnut12138/subscriptions", "organizations_url": "https://api.github.com/users/coolnut12138/orgs", "repos_url": "https://api.github.com/users/coolnut12138/repos", "events_url": "https://api.github.com/users/coolnut12138/events{/privacy}", "received_events_url": "https://api.github.com/users/coolnut12138/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-12-01T09:15:54Z", "updated_at": "2022-07-01T20:35:01Z", "closed_at": "2021-12-02T10:48:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:0.19.0\r\n4. MPI version:4.0.3\r\n5. CUDA version:10.0\r\n6. NCCL version:2.5.6\r\n7. Python version:3.6.8\r\n8. Spark / PySpark version:\r\n9. Ray version: None\r\n10. OS and version: centos7\r\n11. GCC version:7.3.1\r\n12. CMake version:2.8.12.2\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nHi! I'm unable to install horovod 0.19.0 successfully by running \"HOROVOD_WITHOUT_GLOO=1 HOROVOD_WITH_TENSORFLOW=1 HOROVOD_NCCL_INCLUDE=/usr/include HOROVOD_NCCL_LIB=/usr/lib64 HOROVOD_GPU_OPERATIONS=NCCL pip install --no-cache-dir horovod==0.19.0\"\r\n\r\nError log shows:\r\n\r\n[root@VM-29-31-centos ~]# HOROVOD_WITHOUT_GLOO=1 HOROVOD_WITH_TENSORFLOW=1 HOROVOD_NCCL_INCLUDE=/usr/include HOROVOD_NCCL_LIB=/usr/lib64 HOROVOD_GPU_OPERATIONS=NCCL pip install --no-cache-dir horovod==0.19.0\r\nCollecting horovod==0.19.0\r\n  Downloading horovod-0.19.0.tar.gz (2.9 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.9 MB 52.6 MB/s            \r\n  Preparing metadata (setup.py) ... done\r\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.6/site-packages (from horovod==0.19.0) (2.0.0)\r\nRequirement already satisfied: psutil in /usr/local/lib64/python3.6/site-packages (from horovod==0.19.0) (5.8.0)\r\nRequirement already satisfied: pyyaml in /usr/lib64/python3.6/site-packages (from horovod==0.19.0) (3.13)\r\nRequirement already satisfied: six in ./.local/lib/python3.6/site-packages (from horovod==0.19.0) (1.16.0)\r\nRequirement already satisfied: cffi>=1.4.0 in /usr/local/lib64/python3.6/site-packages (from horovod==0.19.0) (1.15.0)\r\nRequirement already satisfied: pycparser in /usr/local/lib/python3.6/site-packages (from cffi>=1.4.0->horovod==0.19.0) (2.21)\r\nBuilding wheels for collected packages: horovod\r\n  Building wheel for horovod (setup.py) ... /\r\nerror\r\n  ERROR: Command errored out with exit status 1:\r\n   command: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-rw1my8vd/horovod_c985d6fc46794d40a1fbe4f795ac2673/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-rw1my8vd/horovod_c985d6fc46794d40a1fbe4f795ac2673/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-6xu84ilg\r\n       cwd: /tmp/pip-install-rw1my8vd/horovod_c985d6fc46794d40a1fbe4f795ac2673/\r\n  Complete output (209 lines):\r\n  /usr/lib64/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'test_requires'\r\n    warnings.warn(msg)\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib.linux-x86_64-3.6\r\n  creating build/lib.linux-x86_64-3.6/horovod\r\n  copying horovod/__init__.py -> build/lib.linux-x86_64-3.6/horovod\r\n  creating build/lib.linux-x86_64-3.6/horovod/common\r\n  copying horovod/common/basics.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n  copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n  copying horovod/common/util.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n  creating build/lib.linux-x86_64-3.6/horovod/spark\r\n  copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark\r\n  creating build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  creating build/lib.linux-x86_64-3.6/horovod/mxnet\r\n  copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/mxnet\r\n  copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.6/horovod/mxnet\r\n  creating build/lib.linux-x86_64-3.6/horovod/_keras\r\n  copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/_keras\r\n  copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/_keras\r\n  creating build/lib.linux-x86_64-3.6/horovod/run\r\n  copying horovod/run/run_task.py -> build/lib.linux-x86_64-3.6/horovod/run\r\n  copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.6/horovod/run\r\n  copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run\r\n  copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.6/horovod/run\r\n  copying horovod/run/run.py -> build/lib.linux-x86_64-3.6/horovod/run\r\n  copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.6/horovod/run\r\n  creating build/lib.linux-x86_64-3.6/horovod/torch\r\n  copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n  copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n  copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n  creating build/lib.linux-x86_64-3.6/horovod/keras\r\n  copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/keras\r\n  copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/keras\r\n  creating build/lib.linux-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n  creating build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  creating build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  creating build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n  copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n  copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n  copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n  copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n  creating build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  creating build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n  creating build/lib.linux-x86_64-3.6/horovod/run/task\r\n  copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.6/horovod/run/task\r\n  copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/task\r\n  creating build/lib.linux-x86_64-3.6/horovod/run/common\r\n  copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/common\r\n  creating build/lib.linux-x86_64-3.6/horovod/run/http\r\n  copying horovod/run/http/http_client.py -> build/lib.linux-x86_64-3.6/horovod/run/http\r\n  copying horovod/run/http/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/http\r\n  copying horovod/run/http/http_server.py -> build/lib.linux-x86_64-3.6/horovod/run/http\r\n  creating build/lib.linux-x86_64-3.6/horovod/run/driver\r\n  copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/run/driver\r\n  copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/driver\r\n  creating build/lib.linux-x86_64-3.6/horovod/run/util\r\n  copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.6/horovod/run/util\r\n  copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.6/horovod/run/util\r\n  copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/util\r\n  copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.6/horovod/run/util\r\n  creating build/lib.linux-x86_64-3.6/horovod/run/common/service\r\n  copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.6/horovod/run/common/service\r\n  copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/run/common/service\r\n  copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/common/service\r\n  creating build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n  copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n  copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n  copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n  copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n  copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n  copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n  copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n  copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n  copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n  copying horovod/run/common/util/config_parser.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n  creating build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib\r\n  copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib\r\n  creating build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib_impl\r\n  copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib_impl\r\n  running build_ext\r\n  gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/include/python3.6m -c build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.o\r\n  gcc -pthread -shared -Wl,-z,relro -g build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.o -L/usr/lib64 -o build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.so\r\n  gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -I/usr/include/python3.6m -c build/temp.linux-x86_64-3.6/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.6/test_compile/test_link_flags.o\r\n  gcc -pthread -shared -Wl,-z,relro -g -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.6/test_compile/test_link_flags.o -L/usr/lib64 -o build/temp.linux-x86_64-3.6/test_compile/test_link_flags.so\r\n  INFO: HOROVOD_WITHOUT_GLOO detected, skip compiling Horovod with Gloo.\r\n  INFO: Compiler /opt/rh/devtoolset-7/root/usr/bin/g++ (version 7.3.1 20180303 (Red Hat 7.3.1-5)) is not usable for this TensorFlow installation. Require g++ (version >=4.8.5, <5).\r\n  INFO: Compiler /opt/rh/devtoolset-8/root/usr/bin/g++ (version 8.3.1 20190311 (Red Hat 8.3.1-3)) is not usable for this TensorFlow installation. Require g++ (version >=4.8.5, <5).\r\n  INFO: Compilers /usr/bin/gcc and /usr/bin/g++ (version 4.8.5 20150623 (Red Hat 4.8.5-39)) selected for TensorFlow plugin build.\r\n  building 'horovod.tensorflow.mpi_lib' extension\r\n  creating build/temp.linux-x86_64-3.6/horovod\r\n  creating build/temp.linux-x86_64-3.6/horovod/common\r\n  creating build/temp.linux-x86_64-3.6/horovod/common/ops\r\n  creating build/temp.linux-x86_64-3.6/horovod/common/optim\r\n  creating build/temp.linux-x86_64-3.6/horovod/common/utils\r\n  creating build/temp.linux-x86_64-3.6/horovod/common/mpi\r\n  creating build/temp.linux-x86_64-3.6/horovod/common/ops/adasum\r\n  creating build/temp.linux-x86_64-3.6/horovod/tensorflow\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/common.cc -o build/temp.linux-x86_64-3.6/horovod/common/common.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/controller.cc -o build/temp.linux-x86_64-3.6/horovod/common/controller.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/fusion_buffer_manager.cc -o build/temp.linux-x86_64-3.6/horovod/common/fusion_buffer_manager.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/logging.cc -o build/temp.linux-x86_64-3.6/horovod/common/logging.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/message.cc -o build/temp.linux-x86_64-3.6/horovod/common/message.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/operations.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  In file included from horovod/common/mpi/mpi_context.h:25:0,\r\n                   from horovod/common/operations.cc:47:\r\n  horovod/common/mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n  horovod/common/mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     *res = *reinterpret_cast<float const*>(&f);\r\n                                              ^\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/parameter_manager.cc -o build/temp.linux-x86_64-3.6/horovod/common/parameter_manager.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  horovod/common/parameter_manager.cc: In member function \u2018virtual bool horovod::common::ParameterManager::BayesianParameter::IsDoneTuning() const\u2019:\r\n  horovod/common/parameter_manager.cc:466:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     return iteration_ > max_samples_;\r\n                         ^\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/response_cache.cc -o build/temp.linux-x86_64-3.6/horovod/common/response_cache.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/stall_inspector.cc -o build/temp.linux-x86_64-3.6/horovod/common/stall_inspector.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/thread_pool.cc -o build/temp.linux-x86_64-3.6/horovod/common/thread_pool.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/timeline.cc -o build/temp.linux-x86_64-3.6/horovod/common/timeline.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/tensor_queue.cc -o build/temp.linux-x86_64-3.6/horovod/common/tensor_queue.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/ops/collective_operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/collective_operations.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/ops/operation_manager.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/operation_manager.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/optim/bayesian_optimization.cc -o build/temp.linux-x86_64-3.6/horovod/common/optim/bayesian_optimization.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/optim/gaussian_process.cc -o build/temp.linux-x86_64-3.6/horovod/common/optim/gaussian_process.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/utils/env_parser.cc -o build/temp.linux-x86_64-3.6/horovod/common/utils/env_parser.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/half.cc -o build/temp.linux-x86_64-3.6/horovod/common/half.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  In file included from horovod/common/half.cc:16:0:\r\n  horovod/common/half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n  horovod/common/half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     *res = *reinterpret_cast<float const*>(&f);\r\n                                              ^\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/mpi/mpi_context.cc -o build/temp.linux-x86_64-3.6/horovod/common/mpi/mpi_context.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  In file included from horovod/common/mpi/mpi_context.h:25:0,\r\n                   from horovod/common/mpi/mpi_context.cc:17:\r\n  horovod/common/mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n  horovod/common/mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     *res = *reinterpret_cast<float const*>(&f);\r\n                                              ^\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/mpi/mpi_controller.cc -o build/temp.linux-x86_64-3.6/horovod/common/mpi/mpi_controller.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  In file included from horovod/common/mpi/mpi_context.h:25:0,\r\n                   from horovod/common/mpi/mpi_controller.h:19,\r\n                   from horovod/common/mpi/mpi_controller.cc:16:\r\n  horovod/common/mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n  horovod/common/mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     *res = *reinterpret_cast<float const*>(&f);\r\n                                              ^\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/ops/mpi_operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/mpi_operations.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  In file included from horovod/common/ops/../mpi/mpi_context.h:25:0,\r\n                   from horovod/common/ops/mpi_operations.h:27,\r\n                   from horovod/common/ops/mpi_operations.cc:17:\r\n  horovod/common/ops/../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n  horovod/common/ops/../mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     *res = *reinterpret_cast<float const*>(&f);\r\n                                              ^\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/ops/adasum/adasum_mpi.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/adasum/adasum_mpi.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  In file included from horovod/common/ops/adasum/../../mpi/mpi_context.h:25:0,\r\n                   from horovod/common/ops/adasum/adasum_mpi.h:21,\r\n                   from horovod/common/ops/adasum/adasum_mpi.cc:16:\r\n  horovod/common/ops/adasum/../../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n  horovod/common/ops/adasum/../../mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     *res = *reinterpret_cast<float const*>(&f);\r\n                                              ^\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/ops/adasum_mpi_operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/adasum_mpi_operations.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  In file included from horovod/common/ops/adasum/../../mpi/mpi_context.h:25:0,\r\n                   from horovod/common/ops/adasum/adasum_mpi.h:21,\r\n                   from horovod/common/ops/adasum_mpi_operations.h:22,\r\n                   from horovod/common/ops/adasum_mpi_operations.cc:16:\r\n  horovod/common/ops/adasum/../../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n  horovod/common/ops/adasum/../../mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     *res = *reinterpret_cast<float const*>(&f);\r\n                                              ^\r\n  /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/tensorflow/mpi_ops.cc -o build/temp.linux-x86_64-3.6/horovod/tensorflow/mpi_ops.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  /usr/bin/g++ -pthread -shared -Wl,-z,relro -g -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv build/temp.linux-x86_64-3.6/horovod/common/common.o build/temp.linux-x86_64-3.6/horovod/common/controller.o build/temp.linux-x86_64-3.6/horovod/common/fusion_buffer_manager.o build/temp.linux-x86_64-3.6/horovod/common/logging.o build/temp.linux-x86_64-3.6/horovod/common/message.o build/temp.linux-x86_64-3.6/horovod/common/operations.o build/temp.linux-x86_64-3.6/horovod/common/parameter_manager.o build/temp.linux-x86_64-3.6/horovod/common/response_cache.o build/temp.linux-x86_64-3.6/horovod/common/stall_inspector.o build/temp.linux-x86_64-3.6/horovod/common/thread_pool.o build/temp.linux-x86_64-3.6/horovod/common/timeline.o build/temp.linux-x86_64-3.6/horovod/common/tensor_queue.o build/temp.linux-x86_64-3.6/horovod/common/ops/collective_operations.o build/temp.linux-x86_64-3.6/horovod/common/ops/operation_manager.o build/temp.linux-x86_64-3.6/horovod/common/optim/bayesian_optimization.o build/temp.linux-x86_64-3.6/horovod/common/optim/gaussian_process.o build/temp.linux-x86_64-3.6/horovod/common/utils/env_parser.o build/temp.linux-x86_64-3.6/horovod/common/half.o build/temp.linux-x86_64-3.6/horovod/common/mpi/mpi_context.o build/temp.linux-x86_64-3.6/horovod/common/mpi/mpi_controller.o build/temp.linux-x86_64-3.6/horovod/common/ops/mpi_operations.o build/temp.linux-x86_64-3.6/horovod/common/ops/adasum/adasum_mpi.o build/temp.linux-x86_64-3.6/horovod/common/ops/adasum_mpi_operations.o build/temp.linux-x86_64-3.6/horovod/tensorflow/mpi_ops.o -L/usr/lib64 -lpython3.6m -o build/lib.linux-x86_64-3.6/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so -Wl,--version-script=horovod.lds -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -L/root/.local/lib/python3.6/site-packages/tensorflow -l:libtensorflow_framework.so.1\r\n  /opt/rh/devtoolset-7/root/usr/bin/ld: cannot find -lpython3.6m\r\n  collect2: error: ld returned 1 exit status\r\n  error: command '/usr/bin/g++' failed with exit status 1\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n  Running setup.py clean for horovod\r\nFailed to build horovod\r\nInstalling collected packages: horovod\r\n    Running setup.py install for horovod ... /\r\nERROR: Command errored out with exit status 1:\r\n     command: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-rw1my8vd/horovod_c985d6fc46794d40a1fbe4f795ac2673/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-rw1my8vd/horovod_c985d6fc46794d40a1fbe4f795ac2673/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-vlu2jf8f/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.6m/horovod\r\n         cwd: /tmp/pip-install-rw1my8vd/horovod_c985d6fc46794d40a1fbe4f795ac2673/\r\n    Complete output (211 lines):\r\n    /usr/lib64/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'test_requires'\r\n      warnings.warn(msg)\r\n    running install\r\n    /root/.local/lib/python3.6/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n      setuptools.SetuptoolsDeprecationWarning,\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.6\r\n    creating build/lib.linux-x86_64-3.6/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-3.6/horovod\r\n    creating build/lib.linux-x86_64-3.6/horovod/common\r\n    copying horovod/common/basics.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n    copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n    copying horovod/common/util.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n    creating build/lib.linux-x86_64-3.6/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark\r\n    creating build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    creating build/lib.linux-x86_64-3.6/horovod/mxnet\r\n    copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/mxnet\r\n    copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.6/horovod/mxnet\r\n    creating build/lib.linux-x86_64-3.6/horovod/_keras\r\n    copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/_keras\r\n    copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/_keras\r\n    creating build/lib.linux-x86_64-3.6/horovod/run\r\n    copying horovod/run/run_task.py -> build/lib.linux-x86_64-3.6/horovod/run\r\n    copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.6/horovod/run\r\n    copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run\r\n    copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.6/horovod/run\r\n    copying horovod/run/run.py -> build/lib.linux-x86_64-3.6/horovod/run\r\n    copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.6/horovod/run\r\n    creating build/lib.linux-x86_64-3.6/horovod/torch\r\n    copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n    copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n    copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n    creating build/lib.linux-x86_64-3.6/horovod/keras\r\n    copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/keras\r\n    copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/keras\r\n    creating build/lib.linux-x86_64-3.6/horovod/spark/task\r\n    copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n    copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n    copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n    copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n    creating build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    creating build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    creating build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n    copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n    copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n    copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n    copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n    creating build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    creating build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n    creating build/lib.linux-x86_64-3.6/horovod/run/task\r\n    copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.6/horovod/run/task\r\n    copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/task\r\n    creating build/lib.linux-x86_64-3.6/horovod/run/common\r\n    copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/common\r\n    creating build/lib.linux-x86_64-3.6/horovod/run/http\r\n    copying horovod/run/http/http_client.py -> build/lib.linux-x86_64-3.6/horovod/run/http\r\n    copying horovod/run/http/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/http\r\n    copying horovod/run/http/http_server.py -> build/lib.linux-x86_64-3.6/horovod/run/http\r\n    creating build/lib.linux-x86_64-3.6/horovod/run/driver\r\n    copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/run/driver\r\n    copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/driver\r\n    creating build/lib.linux-x86_64-3.6/horovod/run/util\r\n    copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.6/horovod/run/util\r\n    copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.6/horovod/run/util\r\n    copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/util\r\n    copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.6/horovod/run/util\r\n    creating build/lib.linux-x86_64-3.6/horovod/run/common/service\r\n    copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.6/horovod/run/common/service\r\n    copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/run/common/service\r\n    copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/common/service\r\n    creating build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n    copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n    copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n    copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n    copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n    copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n    copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n    copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n    copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n    copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n    copying horovod/run/common/util/config_parser.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\r\n    creating build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib\r\n    creating build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib_impl\r\n    running build_ext\r\n    gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/include/python3.6m -c build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.o\r\n    gcc -pthread -shared -Wl,-z,relro -g build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.o -L/usr/lib64 -o build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.so\r\n    gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -I/usr/include/python3.6m -c build/temp.linux-x86_64-3.6/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.6/test_compile/test_link_flags.o\r\n    gcc -pthread -shared -Wl,-z,relro -g -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.6/test_compile/test_link_flags.o -L/usr/lib64 -o build/temp.linux-x86_64-3.6/test_compile/test_link_flags.so\r\n    INFO: HOROVOD_WITHOUT_GLOO detected, skip compiling Horovod with Gloo.\r\n    INFO: Compiler /opt/rh/devtoolset-7/root/usr/bin/g++ (version 7.3.1 20180303 (Red Hat 7.3.1-5)) is not usable for this TensorFlow installation. Require g++ (version >=4.8.5, <5).\r\n    INFO: Compiler /opt/rh/devtoolset-8/root/usr/bin/g++ (version 8.3.1 20190311 (Red Hat 8.3.1-3)) is not usable for this TensorFlow installation. Require g++ (version >=4.8.5, <5).\r\n    INFO: Compilers /usr/bin/gcc and /usr/bin/g++ (version 4.8.5 20150623 (Red Hat 4.8.5-39)) selected for TensorFlow plugin build.\r\n    building 'horovod.tensorflow.mpi_lib' extension\r\n    creating build/temp.linux-x86_64-3.6/horovod\r\n    creating build/temp.linux-x86_64-3.6/horovod/common\r\n    creating build/temp.linux-x86_64-3.6/horovod/common/ops\r\n    creating build/temp.linux-x86_64-3.6/horovod/common/optim\r\n    creating build/temp.linux-x86_64-3.6/horovod/common/utils\r\n    creating build/temp.linux-x86_64-3.6/horovod/common/mpi\r\n    creating build/temp.linux-x86_64-3.6/horovod/common/ops/adasum\r\n    creating build/temp.linux-x86_64-3.6/horovod/tensorflow\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/common.cc -o build/temp.linux-x86_64-3.6/horovod/common/common.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/controller.cc -o build/temp.linux-x86_64-3.6/horovod/common/controller.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/fusion_buffer_manager.cc -o build/temp.linux-x86_64-3.6/horovod/common/fusion_buffer_manager.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/logging.cc -o build/temp.linux-x86_64-3.6/horovod/common/logging.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/message.cc -o build/temp.linux-x86_64-3.6/horovod/common/message.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/operations.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    In file included from horovod/common/mpi/mpi_context.h:25:0,\r\n                     from horovod/common/operations.cc:47:\r\n    horovod/common/mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/parameter_manager.cc -o build/temp.linux-x86_64-3.6/horovod/common/parameter_manager.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    horovod/common/parameter_manager.cc: In member function \u2018virtual bool horovod::common::ParameterManager::BayesianParameter::IsDoneTuning() const\u2019:\r\n    horovod/common/parameter_manager.cc:466:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       return iteration_ > max_samples_;\r\n                           ^\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/response_cache.cc -o build/temp.linux-x86_64-3.6/horovod/common/response_cache.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/stall_inspector.cc -o build/temp.linux-x86_64-3.6/horovod/common/stall_inspector.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/thread_pool.cc -o build/temp.linux-x86_64-3.6/horovod/common/thread_pool.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/timeline.cc -o build/temp.linux-x86_64-3.6/horovod/common/timeline.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/tensor_queue.cc -o build/temp.linux-x86_64-3.6/horovod/common/tensor_queue.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/ops/collective_operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/collective_operations.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/ops/operation_manager.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/operation_manager.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/optim/bayesian_optimization.cc -o build/temp.linux-x86_64-3.6/horovod/common/optim/bayesian_optimization.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/optim/gaussian_process.cc -o build/temp.linux-x86_64-3.6/horovod/common/optim/gaussian_process.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/utils/env_parser.cc -o build/temp.linux-x86_64-3.6/horovod/common/utils/env_parser.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/half.cc -o build/temp.linux-x86_64-3.6/horovod/common/half.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    In file included from horovod/common/half.cc:16:0:\r\n    horovod/common/half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/mpi/mpi_context.cc -o build/temp.linux-x86_64-3.6/horovod/common/mpi/mpi_context.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    In file included from horovod/common/mpi/mpi_context.h:25:0,\r\n                     from horovod/common/mpi/mpi_context.cc:17:\r\n    horovod/common/mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/mpi/mpi_controller.cc -o build/temp.linux-x86_64-3.6/horovod/common/mpi/mpi_controller.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    In file included from horovod/common/mpi/mpi_context.h:25:0,\r\n                     from horovod/common/mpi/mpi_controller.h:19,\r\n                     from horovod/common/mpi/mpi_controller.cc:16:\r\n    horovod/common/mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/ops/mpi_operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/mpi_operations.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    In file included from horovod/common/ops/../mpi/mpi_context.h:25:0,\r\n                     from horovod/common/ops/mpi_operations.h:27,\r\n                     from horovod/common/ops/mpi_operations.cc:17:\r\n    horovod/common/ops/../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/ops/../mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/ops/adasum/adasum_mpi.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/adasum/adasum_mpi.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    In file included from horovod/common/ops/adasum/../../mpi/mpi_context.h:25:0,\r\n                     from horovod/common/ops/adasum/adasum_mpi.h:21,\r\n                     from horovod/common/ops/adasum/adasum_mpi.cc:16:\r\n    horovod/common/ops/adasum/../../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/ops/adasum/../../mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/common/ops/adasum_mpi_operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/adasum_mpi_operations.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    In file included from horovod/common/ops/adasum/../../mpi/mpi_context.h:25:0,\r\n                     from horovod/common/ops/adasum/adasum_mpi.h:21,\r\n                     from horovod/common/ops/adasum_mpi_operations.h:22,\r\n                     from horovod/common/ops/adasum_mpi_operations.cc:16:\r\n    horovod/common/ops/adasum/../../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/ops/adasum/../../mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -I/usr/include/python3.6m -c horovod/tensorflow/mpi_ops.cc -o build/temp.linux-x86_64-3.6/horovod/tensorflow/mpi_ops.o -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/root/.local/lib/python3.6/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n    /usr/bin/g++ -pthread -shared -Wl,-z,relro -g -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv build/temp.linux-x86_64-3.6/horovod/common/common.o build/temp.linux-x86_64-3.6/horovod/common/controller.o build/temp.linux-x86_64-3.6/horovod/common/fusion_buffer_manager.o build/temp.linux-x86_64-3.6/horovod/common/logging.o build/temp.linux-x86_64-3.6/horovod/common/message.o build/temp.linux-x86_64-3.6/horovod/common/operations.o build/temp.linux-x86_64-3.6/horovod/common/parameter_manager.o build/temp.linux-x86_64-3.6/horovod/common/response_cache.o build/temp.linux-x86_64-3.6/horovod/common/stall_inspector.o build/temp.linux-x86_64-3.6/horovod/common/thread_pool.o build/temp.linux-x86_64-3.6/horovod/common/timeline.o build/temp.linux-x86_64-3.6/horovod/common/tensor_queue.o build/temp.linux-x86_64-3.6/horovod/common/ops/collective_operations.o build/temp.linux-x86_64-3.6/horovod/common/ops/operation_manager.o build/temp.linux-x86_64-3.6/horovod/common/optim/bayesian_optimization.o build/temp.linux-x86_64-3.6/horovod/common/optim/gaussian_process.o build/temp.linux-x86_64-3.6/horovod/common/utils/env_parser.o build/temp.linux-x86_64-3.6/horovod/common/half.o build/temp.linux-x86_64-3.6/horovod/common/mpi/mpi_context.o build/temp.linux-x86_64-3.6/horovod/common/mpi/mpi_controller.o build/temp.linux-x86_64-3.6/horovod/common/ops/mpi_operations.o build/temp.linux-x86_64-3.6/horovod/common/ops/adasum/adasum_mpi.o build/temp.linux-x86_64-3.6/horovod/common/ops/adasum_mpi_operations.o build/temp.linux-x86_64-3.6/horovod/tensorflow/mpi_ops.o -L/usr/lib64 -lpython3.6m -o build/lib.linux-x86_64-3.6/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so -Wl,--version-script=horovod.lds -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -L/root/.local/lib/python3.6/site-packages/tensorflow -l:libtensorflow_framework.so.1\r\n    /opt/rh/devtoolset-7/root/usr/bin/ld: cannot find -lpython3.6m\r\n    collect2: error: ld returned 1 exit status\r\n    error: command '/usr/bin/g++' failed with exit status 1\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-rw1my8vd/horovod_c985d6fc46794d40a1fbe4f795ac2673/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-rw1my8vd/horovod_c985d6fc46794d40a1fbe4f795ac2673/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-vlu2jf8f/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.6m/horovod Check the logs for full command output.\r\n\r\n\r\n\r\n\r\n**Could anyone help which step I did is wrong? Thanks a lot! **\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3297/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3297/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3278", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3278/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3278/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3278/events", "html_url": "https://github.com/horovod/horovod/issues/3278", "id": 1055181124, "node_id": "I_kwDOBfOI784-5MlE", "number": 3278, "title": "[Ray] hvd.size() incorrect in 2GPU x 1Instance case for lightning + ray", "user": {"login": "irasit", "id": 12163435, "node_id": "MDQ6VXNlcjEyMTYzNDM1", "avatar_url": "https://avatars.githubusercontent.com/u/12163435?v=4", "gravatar_id": "", "url": "https://api.github.com/users/irasit", "html_url": "https://github.com/irasit", "followers_url": "https://api.github.com/users/irasit/followers", "following_url": "https://api.github.com/users/irasit/following{/other_user}", "gists_url": "https://api.github.com/users/irasit/gists{/gist_id}", "starred_url": "https://api.github.com/users/irasit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/irasit/subscriptions", "organizations_url": "https://api.github.com/users/irasit/orgs", "repos_url": "https://api.github.com/users/irasit/repos", "events_url": "https://api.github.com/users/irasit/events{/privacy}", "received_events_url": "https://api.github.com/users/irasit/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "richardliaw", "id": 4529381, "node_id": "MDQ6VXNlcjQ1MjkzODE=", "avatar_url": "https://avatars.githubusercontent.com/u/4529381?v=4", "gravatar_id": "", "url": "https://api.github.com/users/richardliaw", "html_url": "https://github.com/richardliaw", "followers_url": "https://api.github.com/users/richardliaw/followers", "following_url": "https://api.github.com/users/richardliaw/following{/other_user}", "gists_url": "https://api.github.com/users/richardliaw/gists{/gist_id}", "starred_url": "https://api.github.com/users/richardliaw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/richardliaw/subscriptions", "organizations_url": "https://api.github.com/users/richardliaw/orgs", "repos_url": "https://api.github.com/users/richardliaw/repos", "events_url": "https://api.github.com/users/richardliaw/events{/privacy}", "received_events_url": "https://api.github.com/users/richardliaw/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "richardliaw", "id": 4529381, "node_id": "MDQ6VXNlcjQ1MjkzODE=", "avatar_url": "https://avatars.githubusercontent.com/u/4529381?v=4", "gravatar_id": "", "url": "https://api.github.com/users/richardliaw", "html_url": "https://github.com/richardliaw", "followers_url": "https://api.github.com/users/richardliaw/followers", "following_url": "https://api.github.com/users/richardliaw/following{/other_user}", "gists_url": "https://api.github.com/users/richardliaw/gists{/gist_id}", "starred_url": "https://api.github.com/users/richardliaw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/richardliaw/subscriptions", "organizations_url": "https://api.github.com/users/richardliaw/orgs", "repos_url": "https://api.github.com/users/richardliaw/repos", "events_url": "https://api.github.com/users/richardliaw/events{/privacy}", "received_events_url": "https://api.github.com/users/richardliaw/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2021-11-16T18:16:03Z", "updated_at": "2021-11-18T00:35:37Z", "closed_at": "2021-11-18T00:35:37Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework:  PyTorch + lightningSparkEstimator\r\n2. Framework version: 1.5\r\n3. Horovod version: current\r\n4. MPI version: \r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version: 3.6.9\r\n8. Spark / PySpark version: 2.4\r\n9. Ray version: 2.0\r\n10. OS and version:\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nFind a problem in 2GPU x 1Instance case for lightning+ray. Seems the hvd.size() is only 1 even it specified 2 GPU x 1 instance in ray.\r\n```\r\nRayClientDLContext num_workers:1 gpus_per_worker:2 job_config.max_workers:1 cpus_per_horovod_worker:40\r\nand we got 35735 steps,\r\n```\r\nTrain rows: 1786757465, Train batch size: 50000, Train_steps_per_epoch: 35735\r\nwhich should be 17867 steps. hvd.size() should be 2, but instead, ray only start 1 horovod process.\r\n```\r\n_train_steps_per_epoch = int(math.floor(float(train_rows) / batch_size / hvd.size()))\r\n```\r\nlog is here: https://code.uberinternal.com/P296321\r\n\r\nIt is unlikely related to lighning. because lightning trainer is not started yet. Also lightning trainer should not affect hvd.size() , aka, how many horovod instance are created. The problem is most likely at the place where Ray started horovod process.\r\n\r\nI do not think the issue is in the place to creating the context, but more likely in the ray.remote to create horovod workers.\r\nIf 2GPU x 1 instance is configured, it is correct for ray to start 1 ray worker, but that worker need to start 2 horovod process in [here](https://github.com/horovod/horovod/blob/0715c2210647a515a8c49b1f72f575880e522269/horovod/spark/lightning/estimator.py#L415) and each will call the remote [train function](https://github.com/horovod/horovod/blob/0715c2210647a515a8c49b1f72f575880e522269/horovod/spark/lightning/remote.py#L97)\r\n\r\nSuspecting the error in [here](https://github.com/horovod/horovod/blob/0715c2210647a515a8c49b1f72f575880e522269/horovod/ray/strategy.py#L182), we should create a separate worker for each GPU ?\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3278/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3278/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3275", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3275/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3275/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3275/events", "html_url": "https://github.com/horovod/horovod/issues/3275", "id": 1054328309, "node_id": "I_kwDOBfOI784-18X1", "number": 3275, "title": "Cannot install horovod[spark] for Tensorflow 2.6", "user": {"login": "LifengWang", "id": 5210110, "node_id": "MDQ6VXNlcjUyMTAxMTA=", "avatar_url": "https://avatars.githubusercontent.com/u/5210110?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LifengWang", "html_url": "https://github.com/LifengWang", "followers_url": "https://api.github.com/users/LifengWang/followers", "following_url": "https://api.github.com/users/LifengWang/following{/other_user}", "gists_url": "https://api.github.com/users/LifengWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/LifengWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LifengWang/subscriptions", "organizations_url": "https://api.github.com/users/LifengWang/orgs", "repos_url": "https://api.github.com/users/LifengWang/repos", "events_url": "https://api.github.com/users/LifengWang/events{/privacy}", "received_events_url": "https://api.github.com/users/LifengWang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2021-11-16T01:15:17Z", "updated_at": "2022-03-02T21:40:46Z", "closed_at": "2021-12-16T07:31:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version:2.6.2\r\n3. Horovod version: 0.23\r\n4. MPI version:4.1.1\r\n5. CUDA version:N/A\r\n6. NCCL version:N/A\r\n7. Python version: 3.7\r\n8. Spark / PySpark version: 2.4.5\r\n9. Ray version:N/A\r\n10. OS and version: RHEL 8.4\r\n11. GCC version: 9.3.0\r\n12. CMake version: 3.5.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?  Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? N/A\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? N/A\r\n4. Did you check if you question is answered in the [troubleshooting guide] (https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\n```\r\nInstalling collected packages: pyparsing, pycparser, pyzmq, pyyaml, pyarrow, psutil, packaging, future, fsspec, diskcache, dill, cloudpickle, cffi, petastorm, horovod, h5py\r\n  Attempting uninstall: h5py\r\n    Found existing installation: h5py 3.1.0\r\n    Uninstalling h5py-3.1.0:\r\n      Successfully uninstalled h5py-3.1.0\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\ntensorflow 2.6.2 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\r\n```\r\n\r\n**Reproduce Steps:**\r\n\r\n1. `conda create -n horovod python=3.7`\r\n2. `conda activate horovod`\r\n3. `conda install pyspark=2.4.5 openmpi-mpicc cmake -c conda-forge`\r\n4. `pip install tensorflow==2.6.2`\r\n5. `HOROVOD_WITH_MPI=1 HOROVOD_WITH_TENSORFLOW=1 pip install horovod[spark]`\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3275/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3275/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3268", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3268/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3268/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3268/events", "html_url": "https://github.com/horovod/horovod/issues/3268", "id": 1049713726, "node_id": "I_kwDOBfOI784-kVw-", "number": 3268, "title": "Unable to load most recent checkpoint for Pytorch and Pytorch lightning Estimator", "user": {"login": "kamalsharma2", "id": 88836971, "node_id": "MDQ6VXNlcjg4ODM2OTcx", "avatar_url": "https://avatars.githubusercontent.com/u/88836971?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kamalsharma2", "html_url": "https://github.com/kamalsharma2", "followers_url": "https://api.github.com/users/kamalsharma2/followers", "following_url": "https://api.github.com/users/kamalsharma2/following{/other_user}", "gists_url": "https://api.github.com/users/kamalsharma2/gists{/gist_id}", "starred_url": "https://api.github.com/users/kamalsharma2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kamalsharma2/subscriptions", "organizations_url": "https://api.github.com/users/kamalsharma2/orgs", "repos_url": "https://api.github.com/users/kamalsharma2/repos", "events_url": "https://api.github.com/users/kamalsharma2/events{/privacy}", "received_events_url": "https://api.github.com/users/kamalsharma2/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-11-10T11:34:06Z", "updated_at": "2021-11-23T07:12:35Z", "closed_at": "2021-11-23T07:11:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.8.1\r\n3. Horovod version: 0.23.0\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version: 3.8\r\n8. Spark / PySpark version: 3.1.2\r\n9. Ray version:\r\n10. OS and version:\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Bug report:**\r\nIn case of pytorch lightning estimator, the _read_checkpoint() API does not return the latest checkpoint stored in the run path. \r\nReason: Pytorch lightning estimator calls store.get_checkpoints() which looks for a folder named 'checkpoint' in run path while there is no folder named checkpoint, instead there is a temp folder generated via tempfile.TemporaryDirectory()\r\n\r\nIn case of pytorch estimator, the checkpoint stored in run path is not overwritten if multiple iterations are done using the same run path, which leads to _load_checkpoint() API returning the stale checkpoint.\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3268/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3268/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3264", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3264/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3264/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3264/events", "html_url": "https://github.com/horovod/horovod/issues/3264", "id": 1047231395, "node_id": "I_kwDOBfOI784-a3uj", "number": 3264, "title": "All workers failed on failure with Elastic Horovod", "user": {"login": "jasperzhong", "id": 25879526, "node_id": "MDQ6VXNlcjI1ODc5NTI2", "avatar_url": "https://avatars.githubusercontent.com/u/25879526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasperzhong", "html_url": "https://github.com/jasperzhong", "followers_url": "https://api.github.com/users/jasperzhong/followers", "following_url": "https://api.github.com/users/jasperzhong/following{/other_user}", "gists_url": "https://api.github.com/users/jasperzhong/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasperzhong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasperzhong/subscriptions", "organizations_url": "https://api.github.com/users/jasperzhong/orgs", "repos_url": "https://api.github.com/users/jasperzhong/repos", "events_url": "https://api.github.com/users/jasperzhong/events{/privacy}", "received_events_url": "https://api.github.com/users/jasperzhong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2021-11-08T09:48:12Z", "updated_at": "2021-11-10T10:12:26Z", "closed_at": "2021-11-10T10:12:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): PyTorch\r\n2. Framework version: 1.10\r\n3. Horovod version: latest master (3efc229a8d12c250ea4a3493dc01aa8241a10899)\r\n4. MPI version: \r\n5. CUDA version: 10.2\r\n6. NCCL version: 2.7.6\r\n7. Python version: 3.6\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version: ubuntu 18.04lts\r\n11. GCC version: 7.5\r\n12. CMake version: 3.21.3\r\n\r\n**Bug report:**\r\n\r\nWe found that this PR https://github.com/horovod/horovod/pull/3112 solved the some problems of NCCL. So we tested it with the latest code. However, we found sometimes all workers failed on failure. \r\n\r\nWe have two machines, each equipped with 2 P100 GPUs. We run the program in the master node (10.28.1.16) with the following command:\r\n```sh\r\nhorovodrun -np 4 --min-np 2 -H 10.28.1.16:2,10.28.1.17:2 --start-timeout 600 python pytorch_synthetic_benchmark_elastic.py\r\n```\r\n\r\nDuring the execution, we **intentionally killed** the workers on the host (10.28.1.17) with `pkill python`. The workers on that host died immediatelly. \r\n\r\nHowever, sometimes the workers in the master host also failed and exited with the status code 134. From the log, it seems that the workers did not re-initialize since the `initialization_done` is `false`. This is weird because the alive workers should re-init (https://github.com/horovod/horovod/blob/master/horovod/torch/elastic/__init__.py#L48). \r\n```sh\r\n(d2l) \u279c  pytorch git:(master) \u2717 horovodrun -np 4 --min-np 2 --host-discovery-script ./discover_hosts.sh --start-timeout 600 --network-interface eth2 python pytorch_synthetic_benchmark_elastic.py\r\n[0]<stdout>:Model: resnet50\r\n[0]<stdout>:Batch size: 32\r\n[0]<stdout>:Number of GPUs: 4\r\n[0]<stdout>:Running warmup...\r\n[0]<stdout>:Running benchmark...\r\n[0]<stdout>:Iter #0: 48.1 img/sec per GPU\r\n[0]<stderr>:[2021-11-08 15:08:30.430065: E /home/gmsheng/horovod/horovod/common/operations.cc:654] [0]: Horovod background loop uncaught exception: [/opt/conda/conda-bld/pytorch_1634272115665/work/third_party/glo\r\no/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.28.1.17]:52145\r\n[1]<stderr>:[2021-11-08 15:08:30.430133: E /home/gmsheng/horovod/horovod/common/operations.cc:654] [1]: Horovod background loop uncaught exception: [/opt/conda/conda-bld/pytorch_1634272115665/work/third_party/glo\r\no/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.28.1.17]:49285\r\nProcess 2 exit with status code 255.\r\nProcess 3 exit with status code 255.\r\n[0]<stderr>:python: /home/gmsheng/horovod/horovod/common/process_set.cc:20: bool horovod::common::ProcessSet::IsCurrentProcessIncluded() const: Assertion `initialization_done' failed.\r\n[1]<stderr>:python: /home/gmsheng/horovod/horovod/common/process_set.cc:20: bool horovod::common::ProcessSet::IsCurrentProcessIncluded() const: Assertion `initialization_done' failed.\r\n[1]<stderr>:Aborted (core dumped)\r\nProcess 1 exit with status code 134.\r\n[0]<stderr>:Aborted (core dumped)\r\nProcess 0 exit with status code 134.\r\nERROR:root:failure count == 4 -> stop running\r\nTraceback (most recent call last):\r\n  File \"/home/gmsheng/.conda/envs/d2l/bin/horovodrun\", line 33, in <module>\r\n    sys.exit(load_entry_point('horovod', 'console_scripts', 'horovodrun')())\r\n  File \"/home/gmsheng/horovod/horovod/runner/launch.py\", line 770, in run_commandline\r\n    _run(args)\r\n  File \"/home/gmsheng/horovod/horovod/runner/launch.py\", line 758, in _run\r\n    return _run_elastic(args)\r\n  File \"/home/gmsheng/horovod/horovod/runner/launch.py\", line 668, in _run_elastic\r\n    gloo_run_elastic(settings, env, args.command)\r\n  File \"/home/gmsheng/horovod/horovod/runner/gloo_run.py\", line 350, in gloo_run_elastic\r\n    launch_gloo_elastic(command, exec_command, settings, env, get_common_interfaces, rendezvous)\r\n  File \"/home/gmsheng/horovod/horovod/runner/gloo_run.py\", line 337, in launch_gloo_elastic\r\n    .format(name=name, code=exit_code))\r\nRuntimeError: Horovod detected that one or more processes exited with non-zero status, thus causing the job to be terminated. The first process to do so was:\r\nProcess name: 10.28.1.17[0]\r\nExit code: 255\r\n```\r\n\r\n**Expected behaviour**:\r\n\r\nThe program continues to execute normally in the master host. Sometimes we found it succeed as shown in the log below. \r\n```sh\r\n(d2l) \u279c  pytorch git:(master) \u2717 horovodrun -np 4 --min-np 2 --host-discovery-script ./discover_hosts.sh --start-timeout 600 --network-interface eth2 python pytorch_synthetic_benchmark_elastic.py                 [\r\n0]<stdout>:Model: resnet50\r\n[0]<stdout>:Batch size: 32\r\n[0]<stdout>:Number of GPUs: 4\r\n[0]<stdout>:Running warmup...\r\n[0]<stdout>:Running benchmark...\r\n[0]<stdout>:Iter #0: 52.9 img/sec per GPU\r\n[0]<stdout>:Iter #1: 30.3 img/sec per GPU\r\n[0]<stderr>:[2021-11-08 13:56:12. 47430: E /home/gmsheng/horovod/horovod/common/operations.cc:654] [0]: Horovod background loop uncaught exception: [/opt/conda/conda-bld/pytorch_1634272115665/work/third_party/glo\r\no/gloo/transport/tcp/pair.cc:589] Read error [10.28.1.17]:58789: Connection reset by peer\r\n[1]<stderr>:[2021-11-08 13:56:12.115609: E /home/gmsheng/horovod/horovod/common/operations.cc:654] [1]: Horovod background loop uncaught exception: [/opt/conda/conda-bld/pytorch_1634272115665/work/third_party/glo\r\no/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.28.1.17]:26242\r\nProcess 3 exit with status code 255.\r\nProcess 2 exit with status code 255.\r\nWARNING:root:blacklist failing host: 10.28.1.17\r\n[0]<stdout>:Iter #1: 140.5 img/sec per GPU\r\n[0]<stdout>:Iter #2: 142.1 img/sec per GPU\r\n[0]<stdout>:Iter #3: 141.8 img/sec per GPU\r\n[0]<stdout>:Iter #4: 139.9 img/sec per GPU\r\n[0]<stdout>:Iter #5: 138.3 img/sec per GPU\r\n[0]<stdout>:Iter #6: 135.8 img/sec per GPU\r\n[0]<stdout>:Iter #7: 139.1 img/sec per GPU\r\n[0]<stdout>:Iter #8: 139.2 img/sec per GPU\r\n[0]<stdout>:Iter #9: 138.0 img/sec per GPU\r\n[0]<stdout>:Img/sec per GPU: 121.6 +-74.6\r\n[0]<stdout>:Total img/sec on 2 GPU(s): 243.3 +-149.2\r\n```\r\n\r\n\r\n**Other information:**\r\n\r\nWe build horovod from source. Here is our installation command. \r\n```sh\r\nHOROVOD_DEBUG=1 CXX=/usr/bin/g++ CC=/usr/bin/gcc HOROVOD_WITHOUT_MPI=1 HOROVOD_WITH_GLOO=1  HOROVOD_NCCL_HOME=/usr/local/cuda HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_WITHOUT_MXNET=1 pip install --no-cache-dir -v -e .\r\n```\r\n\r\n```sh\r\n~ horovodrun --check-build\r\nHorovod v0.23.0:\r\n\r\nAvailable Frameworks:\r\n    [ ] TensorFlow\r\n    [X] PyTorch\r\n    [ ] MXNet\r\n\r\nAvailable Controllers:\r\n    [ ] MPI\r\n    [X] Gloo\r\n\r\nAvailable Tensor Operations:\r\n    [X] NCCL\r\n    [ ] DDL\r\n    [ ] CCL\r\n    [ ] MPI\r\n    [X] Gloo\r\n```\r\n\r\n___\r\n\r\ncc: @woodlgz @tgaddair", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3264/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3262", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3262/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3262/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3262/events", "html_url": "https://github.com/horovod/horovod/issues/3262", "id": 1046886036, "node_id": "I_kwDOBfOI784-ZjaU", "number": 3262, "title": "Fix flaky spark integration tests", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2021-11-08T00:00:24Z", "updated_at": "2021-11-23T10:43:55Z", "closed_at": "2021-11-23T10:43:55Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Several Spark tests have been disabled in https://github.com/horovod/horovod/pull/3259, we should address the underlying flakiness and re-enable.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3262/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3262/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3251", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3251/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3251/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3251/events", "html_url": "https://github.com/horovod/horovod/issues/3251", "id": 1040828455, "node_id": "I_kwDOBfOI784-Ccgn", "number": 3251, "title": "How to load a pre-trained model using horovod", "user": {"login": "ForawardStar", "id": 32625467, "node_id": "MDQ6VXNlcjMyNjI1NDY3", "avatar_url": "https://avatars.githubusercontent.com/u/32625467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ForawardStar", "html_url": "https://github.com/ForawardStar", "followers_url": "https://api.github.com/users/ForawardStar/followers", "following_url": "https://api.github.com/users/ForawardStar/following{/other_user}", "gists_url": "https://api.github.com/users/ForawardStar/gists{/gist_id}", "starred_url": "https://api.github.com/users/ForawardStar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ForawardStar/subscriptions", "organizations_url": "https://api.github.com/users/ForawardStar/orgs", "repos_url": "https://api.github.com/users/ForawardStar/repos", "events_url": "https://api.github.com/users/ForawardStar/events{/privacy}", "received_events_url": "https://api.github.com/users/ForawardStar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-11-01T06:52:27Z", "updated_at": "2021-11-02T12:34:25Z", "closed_at": "2021-11-02T12:34:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch 1.4\r\n2. python version: horovod with ppytorch\r\n3. Horovod version: latest version\r\n4. MPI version: 4.0.3\r\n5. CUDA version: cuda10.1\r\n6. NCCL version: 2.5.6\r\n7. Python version:  python3.6\r\n\r\n**Question**\r\nI can successfully train my model using horovod in a multi-machine-multi-card fashion, and save the checkpoint models only on worker 0 to prevent other workers from corrupting them. My question is how to load such pre-trained models using horovod  in a multi-machine-multi-card fashion, Do I need to load the pre-trained models only on worker 0 ?\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3251/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3251/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3244", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3244/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3244/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3244/events", "html_url": "https://github.com/horovod/horovod/issues/3244", "id": 1037905846, "node_id": "I_kwDOBfOI78493S-2", "number": 3244, "title": "pytorch_lightning_mnist.py example is not working with GPU", "user": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2021-10-27T22:14:39Z", "updated_at": "2021-10-28T15:26:04Z", "closed_at": "2021-10-28T15:26:04Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\ntorch==1.7.1\r\npytorch-lightning==1.3.8\r\nhorovod==master branch\r\n\r\n**Bug report:**\r\nReproduce with `horovodrun -np 1 -H agent11240-phx4:1 python pytorch_lightning_mnist.py --epochs 1`\r\nIt fails in test step since model weights are on cpu:\r\n```\r\nEpoch 0: 100% 946/948 [00:10<00:00, 86.76it/s, loss=0.438, v[[1,0]<stdout>:A epoch ended.\r\nEpoch 0: 100% 948/948 [00:11<00:00, 84.24it/s, loss=0.438, v_[1,0]<stdout>:Training ends\r\nEpoch 0: 100% 948/948 [00:11<00:00, 84.18it/s, loss=0.438, v_num=0][1,0]<stdout>:\r\n[1,0]<stderr>:Traceback (most recent call last):\r\n[1,0]<stderr>:  File \"pytorch_lightning_mnist.py\", line 218, in <module>\r\n[1,0]<stderr>:    test()\r\n[1,0]<stderr>:  File \"pytorch_lightning_mnist.py\", line 101, in test\r\n[1,0]<stderr>:    output = model(data)\r\n[1,0]<stderr>:  File \"/usr/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\r\n[1,0]<stderr>:    result = self.forward(*input, **kwargs)\r\n[1,0]<stderr>:  File \"pytorch_lightning_mnist.py\", line 59, in forward\r\n[1,0]<stderr>:    x = F.relu(F.max_pool2d(self.conv1(x), 2))\r\n[1,0]<stderr>:  File \"/usr/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\r\n[1,0]<stderr>:    result = self.forward(*input, **kwargs)\r\n[1,0]<stderr>:  File \"/usr/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 423, in forward\r\n[1,0]<stderr>:    return self._conv_forward(input, self.weight)\r\n[1,0]<stderr>:  File \"/usr/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 420, in _conv_forward\r\n[1,0]<stderr>:    self.padding, self.dilation, self.groups)\r\n[1,0]<stderr>:RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\r\n```\r\n\r\nCPU version `horovodrun -np 1 -H agent11240-phx4:1 python pytorch_lightning_mnist.py --epochs 1 --no-cuda` is working.\r\n\r\nAlso, the example seems has wrong configuration for using GPUs:\r\nThe `gpus` for `trainer` should depend on `args.cuda`, instead of system default setting.\r\nhttps://github.com/horovod/horovod/blob/master/examples/pytorch/pytorch_lightning_mnist.py#L208", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3244/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3244/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3231", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3231/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3231/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3231/events", "html_url": "https://github.com/horovod/horovod/issues/3231", "id": 1029953355, "node_id": "I_kwDOBfOI7849Y9dL", "number": 3231, "title": "Rebuild horovod with customer nccl library", "user": {"login": "JoeyYoung", "id": 28895626, "node_id": "MDQ6VXNlcjI4ODk1NjI2", "avatar_url": "https://avatars.githubusercontent.com/u/28895626?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JoeyYoung", "html_url": "https://github.com/JoeyYoung", "followers_url": "https://api.github.com/users/JoeyYoung/followers", "following_url": "https://api.github.com/users/JoeyYoung/following{/other_user}", "gists_url": "https://api.github.com/users/JoeyYoung/gists{/gist_id}", "starred_url": "https://api.github.com/users/JoeyYoung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JoeyYoung/subscriptions", "organizations_url": "https://api.github.com/users/JoeyYoung/orgs", "repos_url": "https://api.github.com/users/JoeyYoung/repos", "events_url": "https://api.github.com/users/JoeyYoung/events{/privacy}", "received_events_url": "https://api.github.com/users/JoeyYoung/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-10-19T07:25:40Z", "updated_at": "2021-10-19T10:01:05Z", "closed_at": "2021-10-19T10:01:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.9.1\r\n3. Horovod version: v0.23.0\r\n5. CUDA version: 11.2\r\n6. NCCL version: 2.11.4\r\n7. Python version: 3.9\r\n\r\nHello, \r\nI have installed Horovod with a customer nccl library. But everytime I modify the nccl library, I need to rebuild horovod with following steps to make sure it uses modified nccl:\r\n\r\n```\r\ncd ~/horovod\r\npython setup.py sdict\r\nHOROVOD_NCCL_HOME=/path/to/nccl HOROVOD_GPU_OPERATIONS=NCCL pip install --no-cache-dir dist/horovod-0.23.0.tar.gz\r\n```\r\n\r\nIs this a must? Any suggestion to simplify the rebuild process?\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3231/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3231/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3226", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3226/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3226/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3226/events", "html_url": "https://github.com/horovod/horovod/issues/3226", "id": 1027928108, "node_id": "I_kwDOBfOI7849RPAs", "number": 3226, "title": "horovod.torch.allreduce_() is not working", "user": {"login": "Alam45", "id": 10148055, "node_id": "MDQ6VXNlcjEwMTQ4MDU1", "avatar_url": "https://avatars.githubusercontent.com/u/10148055?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Alam45", "html_url": "https://github.com/Alam45", "followers_url": "https://api.github.com/users/Alam45/followers", "following_url": "https://api.github.com/users/Alam45/following{/other_user}", "gists_url": "https://api.github.com/users/Alam45/gists{/gist_id}", "starred_url": "https://api.github.com/users/Alam45/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Alam45/subscriptions", "organizations_url": "https://api.github.com/users/Alam45/orgs", "repos_url": "https://api.github.com/users/Alam45/repos", "events_url": "https://api.github.com/users/Alam45/events{/privacy}", "received_events_url": "https://api.github.com/users/Alam45/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-10-16T02:28:49Z", "updated_at": "2021-10-16T16:40:53Z", "closed_at": "2021-10-16T16:40:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version:1.9.0\r\n3. Horovod version: 0.22.0\r\n4. MPI version: 4.1.0\r\n5. CUDA version: 11.2.2\r\n6. NCCL version: 2.8.4\r\n7. Python version: 3.9.2\r\n8. Spark / PySpark version: n/a\r\n9. Ray version: n/a\r\n10. OS and version: CentOS\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\n                                                  **Error Message**\r\n...\r\nhvd.allreduce_(tensor, name='summed_tensor', op=hvd.Sum)\r\n  File \"/.../site-packages/horovod/torch/mpi_ops.py\", line 284, in allreduce_\r\n    return synchronize(handle)\r\n  File \"/../site-packages/horovod/torch/mpi_ops.py\", line 628, in synchronize\r\n    raise HorovodInternalError(e)\r\nhorovod.common.exceptions.HorovodInternalError: ncclCommInitRank failed: internal error\r\nTraceback (most recent call last):\r\n  File \"/.../site-packages/horovod/torch/mpi_ops.py\", line 624, in synchronize\r\n    mpi_lib.horovod_torch_wait_and_clear(handle)\r\nRuntimeError: ncclCommInitRank failed: internal error\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3226/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3226/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3224", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3224/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3224/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3224/events", "html_url": "https://github.com/horovod/horovod/issues/3224", "id": 1027163062, "node_id": "I_kwDOBfOI7849OUO2", "number": 3224, "title": "Segmentation fault in horovod_shutdown when running a job along several nodes", "user": {"login": "msdlr", "id": 27902289, "node_id": "MDQ6VXNlcjI3OTAyMjg5", "avatar_url": "https://avatars.githubusercontent.com/u/27902289?v=4", "gravatar_id": "", "url": "https://api.github.com/users/msdlr", "html_url": "https://github.com/msdlr", "followers_url": "https://api.github.com/users/msdlr/followers", "following_url": "https://api.github.com/users/msdlr/following{/other_user}", "gists_url": "https://api.github.com/users/msdlr/gists{/gist_id}", "starred_url": "https://api.github.com/users/msdlr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/msdlr/subscriptions", "organizations_url": "https://api.github.com/users/msdlr/orgs", "repos_url": "https://api.github.com/users/msdlr/repos", "events_url": "https://api.github.com/users/msdlr/events{/privacy}", "received_events_url": "https://api.github.com/users/msdlr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-10-15T07:33:28Z", "updated_at": "2022-11-10T11:38:35Z", "closed_at": "2022-11-10T11:38:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: tensorflow-**cpu**\r\n2. Framework version: 2.6.0\r\n3. Horovod version: v0.23.0\r\n4. MPI version: 4.1.2 (locally built)\r\n5. CUDA version: None - I want to use CPU training to get information about the MPI communications.\r\n6. NCCL version: None - Same as above.\r\n7. Python version: 3.9.6 (Installed via pyenv, **I don't have root access** on this cluster I try to run Horovod on) \r\n8. Spark / PySpark version: None\r\n9. Ray version: None\r\n10. OS and version: Ubuntu 16.04.3 LTS\r\n11. GCC version: 5.4.0\r\n12. CMake version: 3.18.4\r\n\r\nHello, I'm trying to execute the benchmark `tf_cnn_benchmarks.py` as follows:\r\n\r\n```\r\nmpirun --display-map \\\r\n  $TRANSP \\\r\n -bind-to none -map-by node \\\r\n -x LD_LIBRARY_PATH -x PATH -x HOROVOD_MPI_THREADS_DISABLE=1 \\\r\n  python $benchmark --variable_update horovod --batch_size 64 --horovod_device cpu --device=CPU\r\n```\r\n\r\nI don't specify `-N` or `-np` parameters to `mpirun` because they are passed by Slurm (I configured ompi with the `--with-slurm` option, although the issue persisted before and after that). When running other toy MPI programs everything works out of the box this way. I need to use the `mpirun`-type command because I use a wrapper to it which uses PMPI and folllows the same syntax; so using `horovodrun` is out of question.\r\n\r\nThe program executes correctly when running on a single cluster node, however, when I run it over several nodes I get a segmentation fault before finishing:\r\n\r\n```\r\nThread 0x00007fd1c07f9700 (most recent call first):\r\n  File \"/home/msanchez/.pyenv/versions/3.9.6/lib/python3.9/site-packages/horovod/common/basics.py\", line 149 in shutdown\r\nFatal Python error: Segmentation fault\r\n```\r\nI only get the trace this deep in calls, so I guess the library it references is somehow not being appropriately dyn-linked?\r\n\r\nI have the setup automated because some other colleages may need to run horovod too, and asure we have the same environment: \r\n\r\n```\r\n$ pip3 install --no-cache-dir --upgrade tensorflow-cpu\r\n\r\nexport HOROVOD_WITH_MPI=1\r\nexport HOROVOD_WITHOUT_GLOO=1\r\n\t\r\nexport HOROVOD_WITH_TENSORFLOW=1\r\nexport HOROVOD_WITHOUT_PYTORCH=1\r\nexport HOROVOD_WITHOUT_MXNET=1\r\n\r\nexport HOROVOD_CPU_OPERATIONS=MPI\r\n```\r\n\r\nI've tried insalling both via pip3 and building the source material:\r\n\r\n```\r\n$ git clone --recursive https://github.com/horovod/horovod.git /tmp/horovod_$USER\r\n$ cd /tmp/horovod_$USER\r\n$ python3 setup.py clean build sdist\r\n$ pip3 install dist/horovod*tar.gz\r\n```\r\n\r\n```\r\npip3 install --no-cache-dir horovod[tensorflow]\r\n```\r\n\r\nWhen I clone the repo I do have the C++ code to build the library:\r\n\r\n```\r\n$ git clone https://github.com/horovod/horovod.git--recursive /tmp/horovod_$USER\r\n$ cd /tmp/horovod_$USER\r\n$ grep -iRI \"horovod_shutdown\"\r\nhorovod/common/basics.py:        self.MPI_LIB_CTYPES.horovod_shutdown()\r\nhorovod/common/operations.cc:void horovod_shutdown() {\r\nhorovod/common/operations.h:void horovod_shutdown();\r\n```\r\n\r\nMy `PATH` variable does contain Python, Python3, pip, pip3 (the ones installed via pyenv), ompi on `~/.local/bin`\r\nMy `LD_LIBRARY_PATH` includes `~/.local/lib` for ompi. Maybe there's a directory I'm missing? I'm checking standard and error output from compilation and I don't see any `.so` files being generated.\r\n\r\nWhen I check the Horovod build everything seems okay.\r\n```\r\n$ horovodrun --check-build\r\nHorovod v0.23.0:\r\n\r\nAvailable Frameworks:\r\n    [X] TensorFlow\r\n    [X] PyTorch\r\n    [ ] MXNet\r\n\r\nAvailable Controllers:\r\n    [X] MPI\r\n    [ ] Gloo\r\n\r\nAvailable Tensor Operations:\r\n    [ ] NCCL\r\n    [ ] DDL\r\n    [ ] CCL\r\n    [X] MPI\r\n    [ ] Gloo\r\n```\r\nThis is the location horovodrun is installed at: \r\n```\r\n$ which horovodrun \r\n/home/msanchez/.pyenv/shims/horovodrun\r\n```\r\nAny help would be appreciated.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3224/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3224/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3223", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3223/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3223/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3223/events", "html_url": "https://github.com/horovod/horovod/issues/3223", "id": 1026181718, "node_id": "I_kwDOBfOI7849KkpW", "number": 3223, "title": "docker build error", "user": {"login": "behome", "id": 19470810, "node_id": "MDQ6VXNlcjE5NDcwODEw", "avatar_url": "https://avatars.githubusercontent.com/u/19470810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/behome", "html_url": "https://github.com/behome", "followers_url": "https://api.github.com/users/behome/followers", "following_url": "https://api.github.com/users/behome/following{/other_user}", "gists_url": "https://api.github.com/users/behome/gists{/gist_id}", "starred_url": "https://api.github.com/users/behome/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/behome/subscriptions", "organizations_url": "https://api.github.com/users/behome/orgs", "repos_url": "https://api.github.com/users/behome/repos", "events_url": "https://api.github.com/users/behome/events{/privacy}", "received_events_url": "https://api.github.com/users/behome/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-10-14T09:37:24Z", "updated_at": "2021-10-15T14:19:39Z", "closed_at": "2021-10-15T14:19:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version: Ubuntu 18.04.3 LTS\r\n11. GCC version:\r\n12. CMake version:\r\n13. Docker version: 19.03.13, build 4484c46d9d\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n\r\n**Bug report:**\r\nI want to build my own docker image through the Dockerfile provided in the project. But error happend. I changed nothing.\r\n\r\n```\r\nRunning setup.py install for horovod: started\r\n    Running command /usr/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-4j_mtnr3/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-4j_mtnr3/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-hn4z8609/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/horovod\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.7\r\n    creating build/lib.linux-x86_64-3.7/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/sync_batch_norm.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/functions.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/optimizer.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/sync_batch_norm.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/functions.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/gradient_aggregation.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/elastic.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/gradient_aggregation_eager.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    creating build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/exceptions.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/process_sets.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/elastic.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/ray\r\n    copying horovod/ray/utils.py -> build/lib.linux-x86_64-3.7/horovod/ray\r\n    copying horovod/ray/runner.py -> build/lib.linux-x86_64-3.7/horovod/ray\r\n    copying horovod/ray/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/ray\r\n    copying horovod/ray/strategy.py -> build/lib.linux-x86_64-3.7/horovod/ray\r\n    copying horovod/ray/__init__.py -> build/lib.linux-x86_64-3.7/horovod/ray\r\n    copying horovod/ray/ray_logger.py -> build/lib.linux-x86_64-3.7/horovod/ray\r\n    copying horovod/ray/elastic.py -> build/lib.linux-x86_64-3.7/horovod/ray\r\n    copying horovod/ray/worker.py -> build/lib.linux-x86_64-3.7/horovod/ray\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/conf.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/runner.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/compression.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/functions.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    creating build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/elastic.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/elastic.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/runner\r\n    copying horovod/runner/run_task.py -> build/lib.linux-x86_64-3.7/horovod/runner\r\n    copying horovod/runner/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/runner\r\n    copying horovod/runner/js_run.py -> build/lib.linux-x86_64-3.7/horovod/runner\r\n    copying horovod/runner/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/runner\r\n    copying horovod/runner/__init__.py -> build/lib.linux-x86_64-3.7/horovod/runner\r\n    copying horovod/runner/launch.py -> build/lib.linux-x86_64-3.7/horovod/runner\r\n    copying horovod/runner/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/runner\r\n    creating build/lib.linux-x86_64-3.7/horovod/data\r\n    copying horovod/data/data_loader_base.py -> build/lib.linux-x86_64-3.7/horovod/data\r\n    copying horovod/data/__init__.py -> build/lib.linux-x86_64-3.7/horovod/data\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/elastic\r\n    copying horovod/torch/elastic/state.py -> build/lib.linux-x86_64-3.7/horovod/torch/elastic\r\n    copying horovod/torch/elastic/sampler.py -> build/lib.linux-x86_64-3.7/horovod/torch/elastic\r\n    copying horovod/torch/elastic/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/elastic\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/elastic.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/rendezvous.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/host_discovery.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/data_loaders\r\n    copying horovod/spark/data_loaders/pytorch_data_loaders.py -> build/lib.linux-x86_64-3.7/horovod/spark/data_loaders\r\n    copying horovod/spark/data_loaders/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/data_loaders\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/lightning\r\n    copying horovod/spark/lightning/legacy.py -> build/lib.linux-x86_64-3.7/horovod/spark/lightning\r\n    copying horovod/spark/lightning/datamodule.py -> build/lib.linux-x86_64-3.7/horovod/spark/lightning\r\n    copying horovod/spark/lightning/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/lightning\r\n    copying horovod/spark/lightning/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/lightning\r\n    copying horovod/spark/lightning/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/lightning\r\n    copying horovod/spark/lightning/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/lightning\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/gloo_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/runner/driver\r\n    copying horovod/runner/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/runner/driver\r\n    copying horovod/runner/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/runner/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/runner/http\r\n    copying horovod/runner/http/http_server.py -> build/lib.linux-x86_64-3.7/horovod/runner/http\r\n    copying horovod/runner/http/__init__.py -> build/lib.linux-x86_64-3.7/horovod/runner/http\r\n    copying horovod/runner/http/http_client.py -> build/lib.linux-x86_64-3.7/horovod/runner/http\r\n    creating build/lib.linux-x86_64-3.7/horovod/runner/common\r\n    copying horovod/runner/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/runner/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/runner/util\r\n    copying horovod/runner/util/network.py -> build/lib.linux-x86_64-3.7/horovod/runner/util\r\n    copying horovod/runner/util/lsf.py -> build/lib.linux-x86_64-3.7/horovod/runner/util\r\n    copying horovod/runner/util/streams.py -> build/lib.linux-x86_64-3.7/horovod/runner/util\r\n    copying horovod/runner/util/remote.py -> build/lib.linux-x86_64-3.7/horovod/runner/util\r\n    copying horovod/runner/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/runner/util\r\n    copying horovod/runner/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/runner/util\r\n    copying horovod/runner/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/runner/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/runner/task\r\n    copying horovod/runner/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/runner/task\r\n    copying horovod/runner/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/runner/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/runner/elastic\r\n    copying horovod/runner/elastic/registration.py -> build/lib.linux-x86_64-3.7/horovod/runner/elastic\r\n    copying horovod/runner/elastic/rendezvous.py -> build/lib.linux-x86_64-3.7/horovod/runner/elastic\r\n    copying horovod/runner/elastic/settings.py -> build/lib.linux-x86_64-3.7/horovod/runner/elastic\r\n    copying horovod/runner/elastic/discovery.py -> build/lib.linux-x86_64-3.7/horovod/runner/elastic\r\n    copying horovod/runner/elastic/constants.py -> build/lib.linux-x86_64-3.7/horovod/runner/elastic\r\n    copying horovod/runner/elastic/__init__.py -> build/lib.linux-x86_64-3.7/horovod/runner/elastic\r\n    copying horovod/runner/elastic/driver.py -> build/lib.linux-x86_64-3.7/horovod/runner/elastic\r\n    copying horovod/runner/elastic/worker.py -> build/lib.linux-x86_64-3.7/horovod/runner/elastic\r\n    creating build/lib.linux-x86_64-3.7/horovod/runner/common/service\r\n    copying horovod/runner/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/service\r\n    copying horovod/runner/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/service\r\n    copying horovod/runner/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/service\r\n    creating build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    copying horovod/runner/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    copying horovod/runner/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    copying horovod/runner/common/util/tiny_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    copying horovod/runner/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    copying horovod/runner/common/util/hosts.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    copying horovod/runner/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    copying horovod/runner/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    copying horovod/runner/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    copying horovod/runner/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    copying horovod/runner/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    copying horovod/runner/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    copying horovod/runner/common/util/config_parser.py -> build/lib.linux-x86_64-3.7/horovod/runner/common/util\r\n    running build_ext\r\n    -- Could not find CCache. Consider installing CCache to speed up compilation.\r\n    -- The CXX compiler identification is GNU 7.5.0\r\n    -- Check for working CXX compiler: /usr/bin/c++\r\n    -- Check for working CXX compiler: /usr/bin/c++ -- works\r\n    -- Detecting CXX compiler ABI info\r\n    -- Detecting CXX compiler ABI info - done\r\n    -- Detecting CXX compile features\r\n    -- Detecting CXX compile features - done\r\n    -- Build architecture flags: -mf16c -mavx -mfma\r\n    -- Using command /usr/bin/python\r\n    -- Found MPI_CXX: /usr/local/lib/libmpi.so (found version \"3.1\")\r\n    -- Found MPI: TRUE (found version \"3.1\")\r\n    -- Could NOT find NVTX (missing: NVTX_INCLUDE_DIR)\r\n    CMake Error at CMakeLists.txt:265 (add_subdirectory):\r\n      add_subdirectory given source \"third_party/gloo\" which is not an existing\r\n      directory.\r\n\r\n\r\n    CMake Error at CMakeLists.txt:267 (target_compile_definitions):\r\n      Cannot specify compile definitions for target \"gloo\" which is not built by\r\n      this project.\r\n\r\n\r\n    Tensorflow_LIBRARIES := -L/usr/local/lib/python3.7/dist-packages/tensorflow -l:libtensorflow_framework.so.2\r\n    -- Found Tensorflow: -L/usr/local/lib/python3.7/dist-packages/tensorflow -l:libtensorflow_framework.so.2 (found suitable version \"2.5.0\", minimum required is \"1.15.0\")\r\n    -- Found Pytorch: 1.8.1+cu102 (found suitable version \"1.8.1+cu102\", minimum required is \"1.2.0\")\r\n    -- Found Mxnet: /usr/local/lib/python3.7/dist-packages/mxnet/libmxnet.so (found suitable version \"1.8.0\", minimum required is \"1.4.0\")\r\n    CMake Error at CMakeLists.txt:327 (file):\r\n      file COPY cannot find \"/tmp/pip-req-build-4j_mtnr3/third_party/gloo\".\r\n\r\n\r\n    CMake Error at CMakeLists.txt:331 (add_subdirectory):\r\n      The source directory\r\n\r\n        /tmp/pip-req-build-4j_mtnr3/third_party/compatible_gloo\r\n\r\n      does not contain a CMakeLists.txt file.\r\n\r\n\r\n    CMake Error at CMakeLists.txt:332 (target_compile_definitions):\r\n      Cannot specify compile definitions for target \"compatible_gloo\" which is\r\n      not built by this project.\r\n\r\n\r\n    CMake Error: The following variables are used in this project, but they are set to NOTFOUND.\r\n    Please set them or make sure they are set and tested correctly in the CMake files:\r\n    /tmp/pip-req-build-4j_mtnr3/horovod/mxnet/TF_FLATBUFFERS_INCLUDE_PATH\r\n       used as include directory in directory /tmp/pip-req-build-4j_mtnr3/horovod/mxnet\r\n    /tmp/pip-req-build-4j_mtnr3/horovod/tensorflow/TF_FLATBUFFERS_INCLUDE_PATH\r\n       used as include directory in directory /tmp/pip-req-build-4j_mtnr3/horovod/tensorflow\r\n    /tmp/pip-req-build-4j_mtnr3/horovod/torch/TF_FLATBUFFERS_INCLUDE_PATH\r\n       used as include directory in directory /tmp/pip-req-build-4j_mtnr3/horovod/torch\r\n\r\n    -- Configuring incomplete, errors occurred!\r\n    See also \"/tmp/pip-req-build-4j_mtnr3/build/temp.linux-x86_64-3.7/RelWithDebInfo/CMakeFiles/CMakeOutput.log\".\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/tmp/pip-req-build-4j_mtnr3/setup.py\", line 211, in <module>\r\n        'horovodrun = horovod.runner.launch:run_commandline'\r\n      File \"/usr/local/lib/python3.7/dist-packages/setuptools/__init__.py\", line 153, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/usr/lib/python3.7/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/usr/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/install.py\", line 61, in run\r\n        return orig.install.run(self)\r\n      File \"/usr/lib/python3.7/distutils/command/install.py\", line 589, in run\r\n        self.run_command('build')\r\n      File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/usr/lib/python3.7/distutils/command/build.py\", line 135, in run\r\n        self.run_command(cmd_name)\r\n      File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/build_ext.py\", line 79, in run\r\n        _build_ext.run(self)\r\n      File \"/usr/lib/python3.7/distutils/command/build_ext.py\", line 340, in run\r\n        self.build_extensions()\r\n      File \"/tmp/pip-req-build-4j_mtnr3/setup.py\", line 99, in build_extensions\r\n        cwd=cmake_build_dir)\r\n      File \"/usr/lib/python3.7/subprocess.py\", line 363, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['cmake', '/tmp/pip-req-build-4j_mtnr3', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/tmp/pip-req-build-4j_mtnr3/build/lib.linux-x86_64-3.7', '-DPYTHON_EXECUTABLE:FILEPATH=/usr/bin/python']' returned non-zero exit status 1.\r\n    Running setup.py install for horovod: finished with status 'error'\r\nERROR: Command errored out with exit status 1: /usr/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-4j_mtnr3/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-4j_mtnr3/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-hn4z8609/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/horovod Check the logs for full command output.\r\nThe command '/bin/bash -cu python setup.py sdist &&     bash -c \"HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITH_PYTORCH=1 HOROVOD_WITH_MXNET=1 pip install --no-cache-dir -v $(ls /horovod/dist/horovod-*.tar.gz)[spark,ray]\" &&     horovodrun --check-build' returned a non-zero code: 1\r\n\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3223/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3223/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3197", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3197/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3197/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3197/events", "html_url": "https://github.com/horovod/horovod/issues/3197", "id": 1016424724, "node_id": "I_kwDOBfOI7848lWkU", "number": 3197, "title": "RayElastic scale-up test fails", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-10-05T14:49:16Z", "updated_at": "2021-10-18T18:23:42Z", "closed_at": "2021-10-18T18:23:42Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Followup from #2813, the ray elastic scale-up test is failing in Buildkite as well. We should investigate thus as part of #3190.\r\n\r\n```\r\n/usr/local/lib/python3.8/dist-packages/horovod/ray/elastic.py:454: RuntimeError\r\n--\r\n\u00a0 | ------------------------------ Captured log call -------------------------------\r\n\u00a0 | ERROR    root:registration.py:179 failed to activate new hosts -> stop running\r\n\u00a0 | Traceback (most recent call last):\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/runner/elastic/registration.py\", line 177, in _on_workers_recorded\r\n\u00a0 | self._driver.resume()\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/runner/elastic/driver.py\", line 99, in resume\r\n\u00a0 | self._activate_workers(self._min_np)\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/runner/elastic/driver.py\", line 177, in _activate_workers\r\n\u00a0 | pending_slots = self._update_host_assignments(current_hosts)\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/runner/elastic/driver.py\", line 248, in _update_host_assignments\r\n\u00a0 | raise RuntimeError('No hosts from previous set remaining, unable to broadcast state.')\r\n\u00a0 | RuntimeError: No hosts from previous set remaining, unable to broadcast state.\r\n\r\n\r\n```\r\n\r\nhttps://buildkite.com/horovod/horovod/builds/6525#f16bee64-0b80-4cf8-9ba7-89b2d6aebde7/6-9500", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3197/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3197/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3158", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3158/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3158/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3158/events", "html_url": "https://github.com/horovod/horovod/issues/3158", "id": 990738820, "node_id": "MDU6SXNzdWU5OTA3Mzg4MjA=", "number": 3158, "title": "Can't install horovod", "user": {"login": "wjpang", "id": 48470521, "node_id": "MDQ6VXNlcjQ4NDcwNTIx", "avatar_url": "https://avatars.githubusercontent.com/u/48470521?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjpang", "html_url": "https://github.com/wjpang", "followers_url": "https://api.github.com/users/wjpang/followers", "following_url": "https://api.github.com/users/wjpang/following{/other_user}", "gists_url": "https://api.github.com/users/wjpang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjpang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjpang/subscriptions", "organizations_url": "https://api.github.com/users/wjpang/orgs", "repos_url": "https://api.github.com/users/wjpang/repos", "events_url": "https://api.github.com/users/wjpang/events{/privacy}", "received_events_url": "https://api.github.com/users/wjpang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-09-08T05:48:10Z", "updated_at": "2021-09-15T13:10:18Z", "closed_at": "2021-09-15T13:10:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch)\r\n2. Framework version: (2.6.0, 2.6.0, 1.9.0)\r\n3. Horovod version: 0.22.1 (I think)\r\n4. MPI version: NA\r\n5. CUDA version: NA\r\n6. NCCL version: NA\r\n7. Python version: 3.9.7\r\n8. Spark / PySpark version: NA\r\n9. Ray version: NA\r\n10. OS and version: Windows 10\r\n11. GCC version: 9.2.0-2\r\n12. CMake version: 3.21.2\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\n I cant install horovod. After running \"pip install horovod[tensorflow,keras,pytorch] -v\", the full output I get:\r\n\r\nUsing pip 21.2.4 from C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\site-packages\\pip (python 3.9)\r\nCollecting horovod[keras,pytorch,tensorflow]\r\n  Using cached horovod-0.22.1.tar.gz (3.3 MB)\r\n    Running command python setup.py egg_info\r\n    running egg_info\r\n    creating C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-pip-egg-info-drn1iqif\\horovod.egg-info\r\n    writing C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-pip-egg-info-drn1iqif\\horovod.egg-info\\PKG-INFO\r\n    writing dependency_links to C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-pip-egg-info-drn1iqif\\horovod.egg-info\\dependency_links.txt\r\n    writing entry points to C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-pip-egg-info-drn1iqif\\horovod.egg-info\\entry_points.txt\r\n    writing requirements to C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-pip-egg-info-drn1iqif\\horovod.egg-info\\requires.txt\r\n    writing top-level names to C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-pip-egg-info-drn1iqif\\horovod.egg-info\\top_level.txt\r\n    writing manifest file 'C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-pip-egg-info-drn1iqif\\horovod.egg-info\\SOURCES.txt'\r\n    reading manifest file 'C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-pip-egg-info-drn1iqif\\horovod.egg-info\\SOURCES.txt'\r\n    reading manifest template 'MANIFEST.in'\r\n    no previously-included directories found matching '.eggs'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\Eigen\\Eigen'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\Eigen\\IterativeLinearSolvers'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\Eigen\\MetisSupport'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\Eigen\\Sparse'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\Eigen\\SparseCholesky'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\Eigen\\SparseLU'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\Eigen\\src\\IterativeSolvers\\*'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\Eigen\\src\\OrderingMethods\\Amd.h'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\Eigen\\src\\SparseCholesky\\*'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\unsupported\\test\\mpreal\\mpreal.h'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\unsupported\\Eigen\\FFT'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\unsupported\\Eigen\\MPRealSupport'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\doc\\PreprocessorDirectives.dox'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\doc\\UsingIntelMKL.dox'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\doc\\SparseLinearSystems.dox'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\COPYING.GPL'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\COPYING.LGPL'\r\n    warning: no previously-included files found matching 'third_party\\eigen\\COPYING.README'\r\n    adding license file 'LICENSE'\r\n    writing manifest file 'C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-pip-egg-info-drn1iqif\\horovod.egg-info\\SOURCES.txt'\r\nRequirement already satisfied: cloudpickle in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from horovod[keras,pytorch,tensorflow]) (1.6.0)\r\nRequirement already satisfied: psutil in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from horovod[keras,pytorch,tensorflow]) (5.8.0)\r\nRequirement already satisfied: pyyaml in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from horovod[keras,pytorch,tensorflow]) (5.4.1)\r\nRequirement already satisfied: cffi>=1.4.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from horovod[keras,pytorch,tensorflow]) (1.14.6)\r\nRequirement already satisfied: keras!=2.0.9,!=2.1.0,!=2.1.1,>=2.0.8 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from horovod[keras,pytorch,tensorflow]) (2.6.0)\r\nRequirement already satisfied: torch in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from horovod[keras,pytorch,tensorflow]) (1.9.0)\r\nRequirement already satisfied: pytorch_lightning in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from horovod[keras,pytorch,tensorflow]) (1.4.5)\r\nRequirement already satisfied: tensorflow in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from horovod[keras,pytorch,tensorflow]) (2.6.0)\r\nRequirement already satisfied: pycparser in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from cffi>=1.4.0->horovod[keras,pytorch,tensorflow]) (2.20)\r\nRequirement already satisfied: tqdm>=4.41.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from pytorch_lightning->horovod[keras,pytorch,tensorflow]) (4.62.2)\r\nRequirement already satisfied: pyDeprecate==0.3.1 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from pytorch_lightning->horovod[keras,pytorch,tensorflow]) (0.3.1)\r\nRequirement already satisfied: numpy>=1.17.2 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from pytorch_lightning->horovod[keras,pytorch,tensorflow]) (1.19.5)\r\nRequirement already satisfied: future>=0.17.1 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from pytorch_lightning->horovod[keras,pytorch,tensorflow]) (0.18.2)\r\nRequirement already satisfied: typing-extensions in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from pytorch_lightning->horovod[keras,pytorch,tensorflow]) (3.7.4.3)\r\nRequirement already satisfied: torchmetrics>=0.4.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from pytorch_lightning->horovod[keras,pytorch,tensorflow]) (0.5.1)\r\nRequirement already satisfied: packaging>=17.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from pytorch_lightning->horovod[keras,pytorch,tensorflow]) (21.0)\r\nRequirement already satisfied: tensorboard>=2.2.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from pytorch_lightning->horovod[keras,pytorch,tensorflow]) (2.6.0)\r\nRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from pytorch_lightning->horovod[keras,pytorch,tensorflow]) (2021.8.1)\r\nRequirement already satisfied: aiohttp in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (3.7.4.post0)\r\nRequirement already satisfied: requests in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (2.26.0)\r\nRequirement already satisfied: pyparsing>=2.0.2 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from packaging>=17.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (2.4.7)\r\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (0.6.1)\r\nRequirement already satisfied: wheel>=0.26 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (0.37.0)\r\nRequirement already satisfied: absl-py>=0.4 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (0.13.0)\r\nRequirement already satisfied: werkzeug>=0.11.15 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (2.0.1)\r\nRequirement already satisfied: setuptools>=41.0.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (58.0.2)\r\nRequirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (1.35.0)\r\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (0.4.6)\r\nRequirement already satisfied: grpcio>=1.24.3 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (1.40.0)\r\nRequirement already satisfied: markdown>=2.6.8 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (3.3.4)\r\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (1.8.0)\r\nRequirement already satisfied: protobuf>=3.6.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (3.17.3)\r\nRequirement already satisfied: six in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (1.15.0)\r\nRequirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (4.7.2)\r\nRequirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (0.2.7)\r\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (4.2.2)\r\nRequirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (1.3.0)\r\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (0.4.8)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (1.26.6)\r\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (2021.5.30)\r\nRequirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\wjuin\\appdata\\roaming\\python\\python39\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (2.0.4)\r\nRequirement already satisfied: idna<4,>=2.5 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (3.1)\r\nRequirement already satisfied: oauthlib>=3.0.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (3.1.1)\r\nRequirement already satisfied: colorama in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tqdm>=4.41.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (0.4.4)\r\nRequirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (1.6.3)\r\nRequirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (3.0.1)\r\nRequirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (5.1.0)\r\nRequirement already satisfied: chardet<5.0,>=2.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (4.0.0)\r\nRequirement already satisfied: attrs>=17.3.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->horovod[keras,pytorch,tensorflow]) (21.2.0)\r\nRequirement already satisfied: astunparse~=1.6.3 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorflow->horovod[keras,pytorch,tensorflow]) (1.6.3)\r\nRequirement already satisfied: clang~=5.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorflow->horovod[keras,pytorch,tensorflow]) (5.0)\r\nRequirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorflow->horovod[keras,pytorch,tensorflow]) (2.6.0)\r\nRequirement already satisfied: h5py~=3.1.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorflow->horovod[keras,pytorch,tensorflow]) (3.1.0)\r\nRequirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorflow->horovod[keras,pytorch,tensorflow]) (3.3.0)\r\nRequirement already satisfied: wrapt~=1.12.1 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorflow->horovod[keras,pytorch,tensorflow]) (1.12.1)\r\nRequirement already satisfied: google-pasta~=0.2 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorflow->horovod[keras,pytorch,tensorflow]) (0.2.0)\r\nRequirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorflow->horovod[keras,pytorch,tensorflow]) (1.12)\r\nRequirement already satisfied: gast==0.4.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorflow->horovod[keras,pytorch,tensorflow]) (0.4.0)\r\nRequirement already satisfied: termcolor~=1.1.0 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorflow->horovod[keras,pytorch,tensorflow]) (1.1.0)\r\nRequirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\wjuin\\miniconda3\\envs\\bodo\\lib\\site-packages (from tensorflow->horovod[keras,pytorch,tensorflow]) (1.1.2)\r\nBuilding wheels for collected packages: horovod\r\n  Running command 'C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\WJuin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dvcyd0yk\\\\horovod_8fc62df0973b46ebb6fd2305139123a1\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\WJuin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dvcyd0yk\\\\horovod_8fc62df0973b46ebb6fd2305139123a1\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-wheel-4yzrtdes'\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build\\lib.win-amd64-3.9\r\n  creating build\\lib.win-amd64-3.9\\horovod\r\n  copying horovod\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\r\n  creating build\\lib.win-amd64-3.9\\horovod\\common\r\n  copying horovod\\common\\basics.py -> build\\lib.win-amd64-3.9\\horovod\\common\r\n  copying horovod\\common\\elastic.py -> build\\lib.win-amd64-3.9\\horovod\\common\r\n  copying horovod\\common\\exceptions.py -> build\\lib.win-amd64-3.9\\horovod\\common\r\n  copying horovod\\common\\util.py -> build\\lib.win-amd64-3.9\\horovod\\common\r\n  copying horovod\\common\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\common\r\n  creating build\\lib.win-amd64-3.9\\horovod\\data\r\n  copying horovod\\data\\data_loader_base.py -> build\\lib.win-amd64-3.9\\horovod\\data\r\n  copying horovod\\data\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\data\r\n  creating build\\lib.win-amd64-3.9\\horovod\\keras\r\n  copying horovod\\keras\\callbacks.py -> build\\lib.win-amd64-3.9\\horovod\\keras\r\n  copying horovod\\keras\\elastic.py -> build\\lib.win-amd64-3.9\\horovod\\keras\r\n  copying horovod\\keras\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\keras\r\n  creating build\\lib.win-amd64-3.9\\horovod\\mxnet\r\n  copying horovod\\mxnet\\functions.py -> build\\lib.win-amd64-3.9\\horovod\\mxnet\r\n  copying horovod\\mxnet\\mpi_ops.py -> build\\lib.win-amd64-3.9\\horovod\\mxnet\r\n  copying horovod\\mxnet\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\mxnet\r\n  creating build\\lib.win-amd64-3.9\\horovod\\ray\r\n  copying horovod\\ray\\driver_service.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n  copying horovod\\ray\\elastic.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n  copying horovod\\ray\\ray_logger.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n  copying horovod\\ray\\runner.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n  copying horovod\\ray\\strategy.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n  copying horovod\\ray\\utils.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n  copying horovod\\ray\\worker.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n  copying horovod\\ray\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n  creating build\\lib.win-amd64-3.9\\horovod\\runner\r\n  copying horovod\\runner\\gloo_run.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n  copying horovod\\runner\\js_run.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n  copying horovod\\runner\\launch.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n  copying horovod\\runner\\mpi_run.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n  copying horovod\\runner\\run_task.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n  copying horovod\\runner\\task_fn.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n  copying horovod\\runner\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n  creating build\\lib.win-amd64-3.9\\horovod\\spark\r\n  copying horovod\\spark\\conf.py -> build\\lib.win-amd64-3.9\\horovod\\spark\r\n  copying horovod\\spark\\gloo_run.py -> build\\lib.win-amd64-3.9\\horovod\\spark\r\n  copying horovod\\spark\\mpi_run.py -> build\\lib.win-amd64-3.9\\horovod\\spark\r\n  copying horovod\\spark\\runner.py -> build\\lib.win-amd64-3.9\\horovod\\spark\r\n  copying horovod\\spark\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\r\n  creating build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n  copying horovod\\tensorflow\\compression.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n  copying horovod\\tensorflow\\elastic.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n  copying horovod\\tensorflow\\functions.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n  copying horovod\\tensorflow\\gradient_aggregation.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n  copying horovod\\tensorflow\\gradient_aggregation_eager.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n  copying horovod\\tensorflow\\mpi_ops.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n  copying horovod\\tensorflow\\sync_batch_norm.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n  copying horovod\\tensorflow\\util.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n  copying horovod\\tensorflow\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n  creating build\\lib.win-amd64-3.9\\horovod\\torch\r\n  copying horovod\\torch\\compression.py -> build\\lib.win-amd64-3.9\\horovod\\torch\r\n  copying horovod\\torch\\functions.py -> build\\lib.win-amd64-3.9\\horovod\\torch\r\n  copying horovod\\torch\\mpi_ops.py -> build\\lib.win-amd64-3.9\\horovod\\torch\r\n  copying horovod\\torch\\optimizer.py -> build\\lib.win-amd64-3.9\\horovod\\torch\r\n  copying horovod\\torch\\sync_batch_norm.py -> build\\lib.win-amd64-3.9\\horovod\\torch\r\n  copying horovod\\torch\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\torch\r\n  creating build\\lib.win-amd64-3.9\\horovod\\_keras\r\n  copying horovod\\_keras\\callbacks.py -> build\\lib.win-amd64-3.9\\horovod\\_keras\r\n  copying horovod\\_keras\\elastic.py -> build\\lib.win-amd64-3.9\\horovod\\_keras\r\n  copying horovod\\_keras\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\_keras\r\n  creating build\\lib.win-amd64-3.9\\horovod\\runner\\common\r\n  copying horovod\\runner\\common\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\r\n  creating build\\lib.win-amd64-3.9\\horovod\\runner\\driver\r\n  copying horovod\\runner\\driver\\driver_service.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\driver\r\n  copying horovod\\runner\\driver\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\driver\r\n  creating build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n  copying horovod\\runner\\elastic\\constants.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n  copying horovod\\runner\\elastic\\discovery.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n  copying horovod\\runner\\elastic\\driver.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n  copying horovod\\runner\\elastic\\registration.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n  copying horovod\\runner\\elastic\\rendezvous.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n  copying horovod\\runner\\elastic\\settings.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n  copying horovod\\runner\\elastic\\worker.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n  copying horovod\\runner\\elastic\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n  creating build\\lib.win-amd64-3.9\\horovod\\runner\\http\r\n  copying horovod\\runner\\http\\http_client.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\http\r\n  copying horovod\\runner\\http\\http_server.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\http\r\n  copying horovod\\runner\\http\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\http\r\n  creating build\\lib.win-amd64-3.9\\horovod\\runner\\task\r\n  copying horovod\\runner\\task\\task_service.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\task\r\n  copying horovod\\runner\\task\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\task\r\n  creating build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n  copying horovod\\runner\\util\\cache.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n  copying horovod\\runner\\util\\lsf.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n  copying horovod\\runner\\util\\network.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n  copying horovod\\runner\\util\\remote.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n  copying horovod\\runner\\util\\streams.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n  copying horovod\\runner\\util\\threads.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n  copying horovod\\runner\\util\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n  creating build\\lib.win-amd64-3.9\\horovod\\runner\\common\\service\r\n  copying horovod\\runner\\common\\service\\driver_service.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\service\r\n  copying horovod\\runner\\common\\service\\task_service.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\service\r\n  copying horovod\\runner\\common\\service\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\service\r\n  creating build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  copying horovod\\runner\\common\\util\\codec.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  copying horovod\\runner\\common\\util\\config_parser.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  copying horovod\\runner\\common\\util\\env.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  copying horovod\\runner\\common\\util\\hosts.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  copying horovod\\runner\\common\\util\\host_hash.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  copying horovod\\runner\\common\\util\\network.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  copying horovod\\runner\\common\\util\\safe_shell_exec.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  copying horovod\\runner\\common\\util\\secret.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  copying horovod\\runner\\common\\util\\settings.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  copying horovod\\runner\\common\\util\\timeout.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  copying horovod\\runner\\common\\util\\tiny_shell_exec.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  copying horovod\\runner\\common\\util\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n  creating build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n  copying horovod\\spark\\common\\backend.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n  copying horovod\\spark\\common\\cache.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n  copying horovod\\spark\\common\\constants.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n  copying horovod\\spark\\common\\estimator.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n  copying horovod\\spark\\common\\params.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n  copying horovod\\spark\\common\\serialization.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n  copying horovod\\spark\\common\\store.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n  copying horovod\\spark\\common\\util.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n  copying horovod\\spark\\common\\_namedtuple_fix.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n  copying horovod\\spark\\common\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n  creating build\\lib.win-amd64-3.9\\horovod\\spark\\data_loaders\r\n  copying horovod\\spark\\data_loaders\\pytorch_data_loaders.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\data_loaders\r\n  copying horovod\\spark\\data_loaders\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\data_loaders\r\n  creating build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n  copying horovod\\spark\\driver\\driver_service.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n  copying horovod\\spark\\driver\\host_discovery.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n  copying horovod\\spark\\driver\\job_id.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n  copying horovod\\spark\\driver\\mpirun_rsh.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n  copying horovod\\spark\\driver\\rendezvous.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n  copying horovod\\spark\\driver\\rsh.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n  copying horovod\\spark\\driver\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n  creating build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n  copying horovod\\spark\\keras\\bare.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n  copying horovod\\spark\\keras\\estimator.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n  copying horovod\\spark\\keras\\optimizer.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n  copying horovod\\spark\\keras\\remote.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n  copying horovod\\spark\\keras\\tensorflow.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n  copying horovod\\spark\\keras\\util.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n  copying horovod\\spark\\keras\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n  creating build\\lib.win-amd64-3.9\\horovod\\spark\\lightning\r\n  copying horovod\\spark\\lightning\\estimator.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\lightning\r\n  copying horovod\\spark\\lightning\\legacy.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\lightning\r\n  copying horovod\\spark\\lightning\\remote.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\lightning\r\n  copying horovod\\spark\\lightning\\util.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\lightning\r\n  copying horovod\\spark\\lightning\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\lightning\r\n  creating build\\lib.win-amd64-3.9\\horovod\\spark\\task\r\n  copying horovod\\spark\\task\\gloo_exec_fn.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\task\r\n  copying horovod\\spark\\task\\mpirun_exec_fn.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\task\r\n  copying horovod\\spark\\task\\task_info.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\task\r\n  copying horovod\\spark\\task\\task_service.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\task\r\n  copying horovod\\spark\\task\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\task\r\n  creating build\\lib.win-amd64-3.9\\horovod\\spark\\torch\r\n  copying horovod\\spark\\torch\\estimator.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\torch\r\n  copying horovod\\spark\\torch\\remote.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\torch\r\n  copying horovod\\spark\\torch\\util.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\torch\r\n  copying horovod\\spark\\torch\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\torch\r\n  creating build\\lib.win-amd64-3.9\\horovod\\tensorflow\\keras\r\n  copying horovod\\tensorflow\\keras\\callbacks.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\\keras\r\n  copying horovod\\tensorflow\\keras\\elastic.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\\keras\r\n  copying horovod\\tensorflow\\keras\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\\keras\r\n  creating build\\lib.win-amd64-3.9\\horovod\\torch\\elastic\r\n  copying horovod\\torch\\elastic\\sampler.py -> build\\lib.win-amd64-3.9\\horovod\\torch\\elastic\r\n  copying horovod\\torch\\elastic\\state.py -> build\\lib.win-amd64-3.9\\horovod\\torch\\elastic\r\n  copying horovod\\torch\\elastic\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\torch\\elastic\r\n  creating build\\lib.win-amd64-3.9\\horovod\\torch\\mpi_lib\r\n  copying horovod\\torch\\mpi_lib\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\torch\\mpi_lib\r\n  creating build\\lib.win-amd64-3.9\\horovod\\torch\\mpi_lib_impl\r\n  copying horovod\\torch\\mpi_lib_impl\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\torch\\mpi_lib_impl\r\n  running build_ext\r\n  -- Building for: Visual Studio 14 2015 Win64\r\n  -- Selecting Windows SDK version  to target Windows 10.0.19043.\r\n  CMake Error at CMakeLists.txt:19 (project):\r\n    Failed to run MSBuild command:\r\n\r\n      MSBuild.exe\r\n\r\n    to get the value of VCTargetsPath:\r\n\r\n      Microsoft (R) Build Engine version 4.8.4084.0\r\n      [Microsoft .NET Framework, version 4.0.30319.42000]\r\n      Copyright (C) Microsoft Corporation. All rights reserved.\r\n\r\n      Build started 8/09/2021 1:44:42 PM.\r\n      Project \"C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\build\\temp.win-amd64-3.9\\Release\\RelWithDebInfo\\CMakeFiles\\3.21.2\\VCTargetsPath.vcxproj\" on node 1 (default targets).\r\n      C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\build\\temp.win-amd64-3.9\\Release\\RelWithDebInfo\\CMakeFiles\\3.21.2\\VCTargetsPath.vcxproj(14,2): error MSB4019: The imported project \"C:\\Microsoft.Cpp.Default.props\" was not found. Confirm that the path in the <Import> declaration is correct, and that the file exists on disk.\r\n      Done Building Project \"C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\build\\temp.win-amd64-3.9\\Release\\RelWithDebInfo\\CMakeFiles\\3.21.2\\VCTargetsPath.vcxproj\" (default targets) -- FAILED.\r\n\r\n      Build FAILED.\r\n\r\n      \"C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\build\\temp.win-amd64-3.9\\Release\\RelWithDebInfo\\CMakeFiles\\3.21.2\\VCTargetsPath.vcxproj\" (default target) (1) ->\r\n        C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\build\\temp.win-amd64-3.9\\Release\\RelWithDebInfo\\CMakeFiles\\3.21.2\\VCTargetsPath.vcxproj(14,2): error MSB4019: The imported project \"C:\\Microsoft.Cpp.Default.props\" was not found. Confirm that the path in the <Import> declaration is correct, and that the file exists on disk.\r\n\r\n          0 Warning(s)\r\n          1 Error(s)\r\n\r\n      Time Elapsed 00:00:00.26\r\n\r\n\r\n    Exit code: 1\r\n\r\n\r\n\r\n  -- Configuring incomplete, errors occurred!\r\n  See also \"C:/Users/WJuin/AppData/Local/Temp/pip-install-dvcyd0yk/horovod_8fc62df0973b46ebb6fd2305139123a1/build/temp.win-amd64-3.9/Release/RelWithDebInfo/CMakeFiles/CMakeOutput.log\".\r\n  Traceback (most recent call last):\r\n    File \"<string>\", line 1, in <module>\r\n    File \"C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\setup.py\", line 155, in <module>\r\n      setup(name='horovod',\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\site-packages\\setuptools\\__init__.py\", line 153, in setup\r\n      return distutils.core.setup(**attrs)\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\core.py\", line 148, in setup\r\n      dist.run_commands()\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\dist.py\", line 966, in run_commands\r\n      self.run_command(cmd)\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\site-packages\\wheel\\bdist_wheel.py\", line 299, in run\r\n      self.run_command('build')\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\command\\build.py\", line 135, in run\r\n      self.run_command(cmd_name)\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\site-packages\\setuptools\\command\\build_ext.py\", line 79, in run\r\n      _build_ext.run(self)\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\command\\build_ext.py\", line 340, in run\r\n      self.build_extensions()\r\n    File \"C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\setup.py\", line 94, in build_extensions\r\n      subprocess.check_call([cmake_bin, self.extensions[0].cmake_lists_dir] + cmake_args,\r\n    File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\subprocess.py\", line 373, in check_call\r\n      raise CalledProcessError(retcode, cmd)\r\n  subprocess.CalledProcessError: Command '['cmake', 'C:\\\\Users\\\\WJuin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dvcyd0yk\\\\horovod_8fc62df0973b46ebb6fd2305139123a1', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=C:\\\\Users\\\\WJuin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dvcyd0yk\\\\horovod_8fc62df0973b46ebb6fd2305139123a1\\\\build\\\\lib.win-amd64-3.9', '-DPYTHON_EXECUTABLE:FILEPATH=C:\\\\Users\\\\WJuin\\\\miniconda3\\\\envs\\\\Bodo\\\\python.exe']' returned non-zero exit status 1.\r\n  Building wheel for horovod (setup.py) ... error\r\n  ERROR: Failed building wheel for horovod\r\n  Running setup.py clean for horovod\r\n  Running command 'C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\WJuin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dvcyd0yk\\\\horovod_8fc62df0973b46ebb6fd2305139123a1\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\WJuin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dvcyd0yk\\\\horovod_8fc62df0973b46ebb6fd2305139123a1\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' clean --all\r\n  running clean\r\n  removing 'build\\temp.win-amd64-3.9' (and everything under it)\r\n  removing 'build\\lib.win-amd64-3.9' (and everything under it)\r\n  'build\\bdist.win-amd64' does not exist -- can't clean it\r\n  'build\\scripts-3.9' does not exist -- can't clean it\r\n  removing 'build'\r\nFailed to build horovod\r\nInstalling collected packages: horovod\r\n    Running command 'C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\WJuin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dvcyd0yk\\\\horovod_8fc62df0973b46ebb6fd2305139123a1\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\WJuin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dvcyd0yk\\\\horovod_8fc62df0973b46ebb6fd2305139123a1\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-record-w56ukd2a\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\Include\\horovod'\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build\\lib.win-amd64-3.9\r\n    creating build\\lib.win-amd64-3.9\\horovod\r\n    copying horovod\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\r\n    creating build\\lib.win-amd64-3.9\\horovod\\common\r\n    copying horovod\\common\\basics.py -> build\\lib.win-amd64-3.9\\horovod\\common\r\n    copying horovod\\common\\elastic.py -> build\\lib.win-amd64-3.9\\horovod\\common\r\n    copying horovod\\common\\exceptions.py -> build\\lib.win-amd64-3.9\\horovod\\common\r\n    copying horovod\\common\\util.py -> build\\lib.win-amd64-3.9\\horovod\\common\r\n    copying horovod\\common\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\common\r\n    creating build\\lib.win-amd64-3.9\\horovod\\data\r\n    copying horovod\\data\\data_loader_base.py -> build\\lib.win-amd64-3.9\\horovod\\data\r\n    copying horovod\\data\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\data\r\n    creating build\\lib.win-amd64-3.9\\horovod\\keras\r\n    copying horovod\\keras\\callbacks.py -> build\\lib.win-amd64-3.9\\horovod\\keras\r\n    copying horovod\\keras\\elastic.py -> build\\lib.win-amd64-3.9\\horovod\\keras\r\n    copying horovod\\keras\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\keras\r\n    creating build\\lib.win-amd64-3.9\\horovod\\mxnet\r\n    copying horovod\\mxnet\\functions.py -> build\\lib.win-amd64-3.9\\horovod\\mxnet\r\n    copying horovod\\mxnet\\mpi_ops.py -> build\\lib.win-amd64-3.9\\horovod\\mxnet\r\n    copying horovod\\mxnet\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\mxnet\r\n    creating build\\lib.win-amd64-3.9\\horovod\\ray\r\n    copying horovod\\ray\\driver_service.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n    copying horovod\\ray\\elastic.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n    copying horovod\\ray\\ray_logger.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n    copying horovod\\ray\\runner.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n    copying horovod\\ray\\strategy.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n    copying horovod\\ray\\utils.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n    copying horovod\\ray\\worker.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n    copying horovod\\ray\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\ray\r\n    creating build\\lib.win-amd64-3.9\\horovod\\runner\r\n    copying horovod\\runner\\gloo_run.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n    copying horovod\\runner\\js_run.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n    copying horovod\\runner\\launch.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n    copying horovod\\runner\\mpi_run.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n    copying horovod\\runner\\run_task.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n    copying horovod\\runner\\task_fn.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n    copying horovod\\runner\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\r\n    creating build\\lib.win-amd64-3.9\\horovod\\spark\r\n    copying horovod\\spark\\conf.py -> build\\lib.win-amd64-3.9\\horovod\\spark\r\n    copying horovod\\spark\\gloo_run.py -> build\\lib.win-amd64-3.9\\horovod\\spark\r\n    copying horovod\\spark\\mpi_run.py -> build\\lib.win-amd64-3.9\\horovod\\spark\r\n    copying horovod\\spark\\runner.py -> build\\lib.win-amd64-3.9\\horovod\\spark\r\n    copying horovod\\spark\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\r\n    creating build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n    copying horovod\\tensorflow\\compression.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n    copying horovod\\tensorflow\\elastic.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n    copying horovod\\tensorflow\\functions.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n    copying horovod\\tensorflow\\gradient_aggregation.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n    copying horovod\\tensorflow\\gradient_aggregation_eager.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n    copying horovod\\tensorflow\\mpi_ops.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n    copying horovod\\tensorflow\\sync_batch_norm.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n    copying horovod\\tensorflow\\util.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n    copying horovod\\tensorflow\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\r\n    creating build\\lib.win-amd64-3.9\\horovod\\torch\r\n    copying horovod\\torch\\compression.py -> build\\lib.win-amd64-3.9\\horovod\\torch\r\n    copying horovod\\torch\\functions.py -> build\\lib.win-amd64-3.9\\horovod\\torch\r\n    copying horovod\\torch\\mpi_ops.py -> build\\lib.win-amd64-3.9\\horovod\\torch\r\n    copying horovod\\torch\\optimizer.py -> build\\lib.win-amd64-3.9\\horovod\\torch\r\n    copying horovod\\torch\\sync_batch_norm.py -> build\\lib.win-amd64-3.9\\horovod\\torch\r\n    copying horovod\\torch\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\torch\r\n    creating build\\lib.win-amd64-3.9\\horovod\\_keras\r\n    copying horovod\\_keras\\callbacks.py -> build\\lib.win-amd64-3.9\\horovod\\_keras\r\n    copying horovod\\_keras\\elastic.py -> build\\lib.win-amd64-3.9\\horovod\\_keras\r\n    copying horovod\\_keras\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\_keras\r\n    creating build\\lib.win-amd64-3.9\\horovod\\runner\\common\r\n    copying horovod\\runner\\common\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\r\n    creating build\\lib.win-amd64-3.9\\horovod\\runner\\driver\r\n    copying horovod\\runner\\driver\\driver_service.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\driver\r\n    copying horovod\\runner\\driver\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\driver\r\n    creating build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n    copying horovod\\runner\\elastic\\constants.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n    copying horovod\\runner\\elastic\\discovery.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n    copying horovod\\runner\\elastic\\driver.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n    copying horovod\\runner\\elastic\\registration.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n    copying horovod\\runner\\elastic\\rendezvous.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n    copying horovod\\runner\\elastic\\settings.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n    copying horovod\\runner\\elastic\\worker.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n    copying horovod\\runner\\elastic\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\elastic\r\n    creating build\\lib.win-amd64-3.9\\horovod\\runner\\http\r\n    copying horovod\\runner\\http\\http_client.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\http\r\n    copying horovod\\runner\\http\\http_server.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\http\r\n    copying horovod\\runner\\http\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\http\r\n    creating build\\lib.win-amd64-3.9\\horovod\\runner\\task\r\n    copying horovod\\runner\\task\\task_service.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\task\r\n    copying horovod\\runner\\task\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\task\r\n    creating build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n    copying horovod\\runner\\util\\cache.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n    copying horovod\\runner\\util\\lsf.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n    copying horovod\\runner\\util\\network.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n    copying horovod\\runner\\util\\remote.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n    copying horovod\\runner\\util\\streams.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n    copying horovod\\runner\\util\\threads.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n    copying horovod\\runner\\util\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\util\r\n    creating build\\lib.win-amd64-3.9\\horovod\\runner\\common\\service\r\n    copying horovod\\runner\\common\\service\\driver_service.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\service\r\n    copying horovod\\runner\\common\\service\\task_service.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\service\r\n    copying horovod\\runner\\common\\service\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\service\r\n    creating build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    copying horovod\\runner\\common\\util\\codec.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    copying horovod\\runner\\common\\util\\config_parser.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    copying horovod\\runner\\common\\util\\env.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    copying horovod\\runner\\common\\util\\hosts.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    copying horovod\\runner\\common\\util\\host_hash.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    copying horovod\\runner\\common\\util\\network.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    copying horovod\\runner\\common\\util\\safe_shell_exec.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    copying horovod\\runner\\common\\util\\secret.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    copying horovod\\runner\\common\\util\\settings.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    copying horovod\\runner\\common\\util\\timeout.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    copying horovod\\runner\\common\\util\\tiny_shell_exec.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    copying horovod\\runner\\common\\util\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\runner\\common\\util\r\n    creating build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n    copying horovod\\spark\\common\\backend.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n    copying horovod\\spark\\common\\cache.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n    copying horovod\\spark\\common\\constants.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n    copying horovod\\spark\\common\\estimator.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n    copying horovod\\spark\\common\\params.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n    copying horovod\\spark\\common\\serialization.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n    copying horovod\\spark\\common\\store.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n    copying horovod\\spark\\common\\util.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n    copying horovod\\spark\\common\\_namedtuple_fix.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n    copying horovod\\spark\\common\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\common\r\n    creating build\\lib.win-amd64-3.9\\horovod\\spark\\data_loaders\r\n    copying horovod\\spark\\data_loaders\\pytorch_data_loaders.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\data_loaders\r\n    copying horovod\\spark\\data_loaders\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\data_loaders\r\n    creating build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n    copying horovod\\spark\\driver\\driver_service.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n    copying horovod\\spark\\driver\\host_discovery.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n    copying horovod\\spark\\driver\\job_id.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n    copying horovod\\spark\\driver\\mpirun_rsh.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n    copying horovod\\spark\\driver\\rendezvous.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n    copying horovod\\spark\\driver\\rsh.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n    copying horovod\\spark\\driver\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\driver\r\n    creating build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n    copying horovod\\spark\\keras\\bare.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n    copying horovod\\spark\\keras\\estimator.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n    copying horovod\\spark\\keras\\optimizer.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n    copying horovod\\spark\\keras\\remote.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n    copying horovod\\spark\\keras\\tensorflow.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n    copying horovod\\spark\\keras\\util.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n    copying horovod\\spark\\keras\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\keras\r\n    creating build\\lib.win-amd64-3.9\\horovod\\spark\\lightning\r\n    copying horovod\\spark\\lightning\\estimator.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\lightning\r\n    copying horovod\\spark\\lightning\\legacy.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\lightning\r\n    copying horovod\\spark\\lightning\\remote.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\lightning\r\n    copying horovod\\spark\\lightning\\util.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\lightning\r\n    copying horovod\\spark\\lightning\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\lightning\r\n    creating build\\lib.win-amd64-3.9\\horovod\\spark\\task\r\n    copying horovod\\spark\\task\\gloo_exec_fn.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\task\r\n    copying horovod\\spark\\task\\mpirun_exec_fn.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\task\r\n    copying horovod\\spark\\task\\task_info.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\task\r\n    copying horovod\\spark\\task\\task_service.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\task\r\n    copying horovod\\spark\\task\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\task\r\n    creating build\\lib.win-amd64-3.9\\horovod\\spark\\torch\r\n    copying horovod\\spark\\torch\\estimator.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\torch\r\n    copying horovod\\spark\\torch\\remote.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\torch\r\n    copying horovod\\spark\\torch\\util.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\torch\r\n    copying horovod\\spark\\torch\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\spark\\torch\r\n    creating build\\lib.win-amd64-3.9\\horovod\\tensorflow\\keras\r\n    copying horovod\\tensorflow\\keras\\callbacks.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\\keras\r\n    copying horovod\\tensorflow\\keras\\elastic.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\\keras\r\n    copying horovod\\tensorflow\\keras\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\tensorflow\\keras\r\n    creating build\\lib.win-amd64-3.9\\horovod\\torch\\elastic\r\n    copying horovod\\torch\\elastic\\sampler.py -> build\\lib.win-amd64-3.9\\horovod\\torch\\elastic\r\n    copying horovod\\torch\\elastic\\state.py -> build\\lib.win-amd64-3.9\\horovod\\torch\\elastic\r\n    copying horovod\\torch\\elastic\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\torch\\elastic\r\n    creating build\\lib.win-amd64-3.9\\horovod\\torch\\mpi_lib\r\n    copying horovod\\torch\\mpi_lib\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\torch\\mpi_lib\r\n    creating build\\lib.win-amd64-3.9\\horovod\\torch\\mpi_lib_impl\r\n    copying horovod\\torch\\mpi_lib_impl\\__init__.py -> build\\lib.win-amd64-3.9\\horovod\\torch\\mpi_lib_impl\r\n    running build_ext\r\n    -- Building for: Visual Studio 14 2015 Win64\r\n    -- Selecting Windows SDK version  to target Windows 10.0.19043.\r\n    CMake Error at CMakeLists.txt:19 (project):\r\n      Failed to run MSBuild command:\r\n\r\n        MSBuild.exe\r\n\r\n      to get the value of VCTargetsPath:\r\n\r\n        Microsoft (R) Build Engine version 4.8.4084.0\r\n        [Microsoft .NET Framework, version 4.0.30319.42000]\r\n        Copyright (C) Microsoft Corporation. All rights reserved.\r\n\r\n        Build started 8/09/2021 1:44:45 PM.\r\n        Project \"C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\build\\temp.win-amd64-3.9\\Release\\RelWithDebInfo\\CMakeFiles\\3.21.2\\VCTargetsPath.vcxproj\" on node 1 (default targets).\r\n        C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\build\\temp.win-amd64-3.9\\Release\\RelWithDebInfo\\CMakeFiles\\3.21.2\\VCTargetsPath.vcxproj(14,2): error MSB4019: The imported project \"C:\\Microsoft.Cpp.Default.props\" was not found. Confirm that the path in the <Import> declaration is correct, and that the file exists on disk.\r\n        Done Building Project \"C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\build\\temp.win-amd64-3.9\\Release\\RelWithDebInfo\\CMakeFiles\\3.21.2\\VCTargetsPath.vcxproj\" (default targets) -- FAILED.\r\n\r\n        Build FAILED.\r\n\r\n        \"C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\build\\temp.win-amd64-3.9\\Release\\RelWithDebInfo\\CMakeFiles\\3.21.2\\VCTargetsPath.vcxproj\" (default target) (1) ->\r\n          C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\build\\temp.win-amd64-3.9\\Release\\RelWithDebInfo\\CMakeFiles\\3.21.2\\VCTargetsPath.vcxproj(14,2): error MSB4019: The imported project \"C:\\Microsoft.Cpp.Default.props\" was not found. Confirm that the path in the <Import> declaration is correct, and that the file exists on disk.\r\n\r\n            0 Warning(s)\r\n            1 Error(s)\r\n\r\n        Time Elapsed 00:00:00.28\r\n\r\n\r\n      Exit code: 1\r\n\r\n\r\n\r\n    -- Configuring incomplete, errors occurred!\r\n    See also \"C:/Users/WJuin/AppData/Local/Temp/pip-install-dvcyd0yk/horovod_8fc62df0973b46ebb6fd2305139123a1/build/temp.win-amd64-3.9/Release/RelWithDebInfo/CMakeFiles/CMakeOutput.log\".\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\setup.py\", line 155, in <module>\r\n        setup(name='horovod',\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\site-packages\\setuptools\\__init__.py\", line 153, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\dist.py\", line 966, in run_commands\r\n        self.run_command(cmd)\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\site-packages\\setuptools\\command\\install.py\", line 61, in run\r\n        return orig.install.run(self)\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\command\\install.py\", line 546, in run\r\n        self.run_command('build')\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\command\\build.py\", line 135, in run\r\n        self.run_command(cmd_name)\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\site-packages\\setuptools\\command\\build_ext.py\", line 79, in run\r\n        _build_ext.run(self)\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\distutils\\command\\build_ext.py\", line 340, in run\r\n        self.build_extensions()\r\n      File \"C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-install-dvcyd0yk\\horovod_8fc62df0973b46ebb6fd2305139123a1\\setup.py\", line 94, in build_extensions\r\n        subprocess.check_call([cmake_bin, self.extensions[0].cmake_lists_dir] + cmake_args,\r\n      File \"C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\lib\\subprocess.py\", line 373, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['cmake', 'C:\\\\Users\\\\WJuin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dvcyd0yk\\\\horovod_8fc62df0973b46ebb6fd2305139123a1', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=C:\\\\Users\\\\WJuin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dvcyd0yk\\\\horovod_8fc62df0973b46ebb6fd2305139123a1\\\\build\\\\lib.win-amd64-3.9', '-DPYTHON_EXECUTABLE:FILEPATH=C:\\\\Users\\\\WJuin\\\\miniconda3\\\\envs\\\\Bodo\\\\python.exe']' returned non-zero exit status 1.\r\n    Running setup.py install for horovod ... error\r\nERROR: Command errored out with exit status 1: 'C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\WJuin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dvcyd0yk\\\\horovod_8fc62df0973b46ebb6fd2305139123a1\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\WJuin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dvcyd0yk\\\\horovod_8fc62df0973b46ebb6fd2305139123a1\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\WJuin\\AppData\\Local\\Temp\\pip-record-w56ukd2a\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\WJuin\\miniconda3\\envs\\Bodo\\Include\\horovod' Check the logs for full command output.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3158/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3158/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3156", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3156/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3156/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3156/events", "html_url": "https://github.com/horovod/horovod/issues/3156", "id": 990398819, "node_id": "MDU6SXNzdWU5OTAzOTg4MTk=", "number": 3156, "title": "Spark/Keras: checkpoint is only relying on local val loss on GPU 0", "user": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2021-09-07T22:23:34Z", "updated_at": "2021-09-07T23:53:02Z", "closed_at": "2021-09-07T23:53:02Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Bug report:**\r\nWhen multi-GPUs training is enabled:\r\n\r\n- Only GPU 0 is doing checkpoint: https://github.com/horovod/horovod/blob/master/horovod/spark/keras/remote.py#L158\r\n- GPU 0 can only access local validation data:https://github.com/horovod/horovod/blob/master/horovod/spark/keras/remote.py#L231\r\n- Checkpoint is biased by GPU 0's local val data and will be used to overwrite model weights in the end of training: https://github.com/horovod/horovod/blob/master/horovod/spark/keras/remote.py#L263\r\n \r\n\r\nAn allreduce scheme should be added to fix local validation issue.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3156/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3156/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3149", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3149/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3149/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3149/events", "html_url": "https://github.com/horovod/horovod/issues/3149", "id": 988203585, "node_id": "MDU6SXNzdWU5ODgyMDM1ODU=", "number": 3149, "title": "Unit test fails on test-cpu-gloo-py3_8-tfhead-keras_none-torchhead-mxnethead-pyspark3_1_2", "user": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-09-04T04:03:07Z", "updated_at": "2021-10-05T21:28:51Z", "closed_at": "2021-10-05T21:28:51Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Recently lots of torch collectives related unit tests are failing under this config.\r\nFor example: https://github.com/horovod/horovod/runs/3510886664\r\n\r\n```\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allgather_grad FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allgather_grad_process_sets FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allgather_process_sets FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allgather_type_error PASSED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allgather_variable_size FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_async_fused FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_average FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_cpu_gpu_error SKIPPED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_duplicate_name_error FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_error PASSED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_grad FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_grad_average FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_grad_process_sets FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_inplace FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_multi_gpu SKIPPED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_postscale FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_prescale FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_process_sets FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_allreduce_type_error PASSED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_alltoall FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_alltoall_equal_split FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_alltoall_equal_split_grad FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_alltoall_equal_split_length_error PASSED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_alltoall_grad FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_alltoall_grad_process_sets FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_alltoall_process_sets FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_alltoall_rank_error PASSED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_alltoall_splits_error PASSED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_alltoall_splits_on_gpu SKIPPED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_alltoall_splits_type_error PASSED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_alltoall_type_error PASSED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_broadcast FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_broadcast_duplicate_name_error FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_broadcast_error PASSED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_broadcast_grad FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_broadcast_grad_process_sets FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_broadcast_inplace FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_broadcast_process_sets FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_broadcast_rank_error PASSED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_broadcast_type_error PASSED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_grouped_allreduce FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_grouped_allreduce_average FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_grouped_allreduce_cpu_gpu_error SKIPPED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_grouped_allreduce_grad FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_grouped_allreduce_grad_average FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_grouped_allreduce_grad_process_sets FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_grouped_allreduce_inplace FAILED\r\n[1]<stdout>:test_torch.py::TorchTests::test_horovod_grouped_allreduce_process_sets FAILED\r\n```\r\n\r\nCC @tgaddair @EnricoMi \r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3149/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3149/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3143", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3143/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3143/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3143/events", "html_url": "https://github.com/horovod/horovod/issues/3143", "id": 985095969, "node_id": "MDU6SXNzdWU5ODUwOTU5Njk=", "number": 3143, "title": "[Elastic Horovod]  It will loss some indices of processed samples in hvd.elastic.state when some nodes dropped", "user": {"login": "hgx1991", "id": 9511326, "node_id": "MDQ6VXNlcjk1MTEzMjY=", "avatar_url": "https://avatars.githubusercontent.com/u/9511326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hgx1991", "html_url": "https://github.com/hgx1991", "followers_url": "https://api.github.com/users/hgx1991/followers", "following_url": "https://api.github.com/users/hgx1991/following{/other_user}", "gists_url": "https://api.github.com/users/hgx1991/gists{/gist_id}", "starred_url": "https://api.github.com/users/hgx1991/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hgx1991/subscriptions", "organizations_url": "https://api.github.com/users/hgx1991/orgs", "repos_url": "https://api.github.com/users/hgx1991/repos", "events_url": "https://api.github.com/users/hgx1991/events{/privacy}", "received_events_url": "https://api.github.com/users/hgx1991/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-09-01T12:33:21Z", "updated_at": "2021-10-21T20:44:14Z", "closed_at": "2021-10-21T20:44:14Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.7.0+cu101\r\n3. Horovod version: 0.22.1\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?  \r\n    yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n    yes\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? \r\n    yes\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n    yes\r\n\r\n**Bug report:**\r\nhorovod/torch/elastic/state.py\r\n```python\r\nclass SamplerStateHandler(StateHandler):\r\n    def __init__(self, sampler):\r\n        super().__init__(sampler)\r\n        self._saved_sampler_state = copy.deepcopy(self.value.state_dict())\r\n\r\n    def save(self):\r\n        self._saved_sampler_state = copy.deepcopy(self.value.state_dict())\r\n\r\n    def restore(self):\r\n        self.value.load_state_dict(self._saved_sampler_state)\r\n\r\n    def sync(self):\r\n        # Get the set of processed indices from all workers\r\n        world_processed_indices = _union(allgather_object(self.value.processed_indices))\r\n\r\n        # Replace local processed indices with global indices\r\n        state_dict = self.value.state_dict()\r\n        state_dict['processed_indices'] = world_processed_indices\r\n\r\n        # Broadcast and load the state to make sure we're all in sync\r\n        self.value.load_state_dict(broadcast_object(state_dict))\r\n```\r\nwhen `state.commit()` is called, function `save()` above only save the local state of `ElasticSampler` locally. If one node is dropped by some reason, the indices of processed samples on this node is lost. So after restart and sync, those samples whill be processed again, which is not what we want.\r\n\r\n**Steps to reproduce**\r\n1. Add some log to `SamplerStateHandler.sync()`\r\n```python\r\nclass SamplerStateHandler(StateHandler):\r\n    ......\r\n    def sync(self):\r\n        # Get the set of processed indices from all workers\r\n        world_processed_indices = _union(allgather_object(self.value.processed_indices))\r\n        print(f\"world_processed_indices: {world_processed_indices }\")\r\n        ......\r\n```\r\n2. Use the code below to reproduce. Note not do shuffle for the convenience of observation.\r\n```python\r\n#! /usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n\r\n\r\nimport time\r\nimport torch\r\nimport horovod.torch as hvd\r\n\r\n\r\nBATCH_SIZE_PER_GPU = 2\r\n\r\n\r\nclass MyDataset(torch.utils.data.Dataset):\r\n    def __init__(self, n):\r\n        self.n = n\r\n    \r\n    def __getitem__(self, index):\r\n        index = index % self.n\r\n        return index\r\n\r\n    def __len__(self):\r\n        return self.n\r\n\r\n\r\n@hvd.elastic.run\r\ndef train(state, data_loader, a):\r\n    rank = hvd.rank()\r\n    print(f\"train rank={rank}\")\r\n    total_epoch = 100\r\n    for epoch in range(state.epoch, total_epoch):\r\n        print(f\"epoch={epoch}\")\r\n\r\n        print(\"Epoch {} / {}, Start training\".format(epoch, total_epoch))\r\n        print(f\"train... rank={rank}\")\r\n        print(f\"start enumerate train_loader... rank={rank}\")\r\n        batch_offset = state.batch\r\n        for i, d in enumerate(data_loader):\r\n            state.batch = batch_idx = batch_offset + i\r\n            if state.batch % 5 == 0:\r\n                t1 = time.time()\r\n                state.commit()\r\n                print(f\"time: {time.time() - t1}\")\r\n            state.check_host_updates()\r\n            b = hvd.allreduce(a)\r\n            print(f\"b: {b}\")\r\n            state.train_sampler.record_batch(i, BATCH_SIZE_PER_GPU)\r\n    \r\n            # if rank == 0:\r\n            msg = 'Epoch: [{0}][{1}/{2}]\\t'.format(\r\n                state.epoch, state.batch, len(data_loader))\r\n\r\n            print(msg)\r\n            time.sleep(0.5)\r\n        state.epoch += 1\r\n        state.batch = 0\r\n        data_loader.sampler.set_epoch(epoch)\r\n        state.commit()\r\n\r\n\r\ndef main():\r\n    hvd.init()\r\n    torch.manual_seed(219)\r\n    torch.cuda.set_device(hvd.local_rank())\r\n\r\n    dataset = MyDataset(2000)\r\n    sampler = hvd.elastic.ElasticSampler(dataset, shuffle=False)\r\n    data_loader = torch.utils.data.DataLoader(\r\n        dataset,\r\n        batch_size=BATCH_SIZE_PER_GPU,\r\n        shuffle=False,\r\n        num_workers=2,\r\n        sampler=sampler,\r\n        worker_init_fn=None,\r\n        drop_last=True,\r\n    )\r\n    a = torch.Tensor([1,2,3,4])\r\n    state = hvd.elastic.TorchState(epoch=0,\r\n                                   train_sampler=sampler,\r\n                                   batch=0)\r\n\r\n    train(state, data_loader, a)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n\r\n```\r\n3. Use elastic horovod to run the above code on some nodes, for example, on 3 nodes.\r\n4. Kill the processes on one node after a while.\r\n5. Observe the log we added to `SamplerStateHandler.sync()`.\r\n\r\n**Sloutions**\r\n1. sloution 1\r\nSave the global state. To get the global state of ElasticSampler on every node, function `save` should call function `sync` first.\r\n```python\r\nclass SamplerStateHandler(StateHandler):\r\n    ......\r\n    def save(self):\r\n        self.sync()\r\n        self._saved_sampler_state = copy.deepcopy(self.value.state_dict())\r\n    ......\r\n```\r\nBut this will  cause `state.commit()` to take a long time.\r\n2. sloution 2\r\nMaybe we can save the number of processed samples instead of save all the processed indices. The number of processed samples can be calculated locally by `batch_size` and `num_replicas`.\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3143/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3143/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3132", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3132/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3132/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3132/events", "html_url": "https://github.com/horovod/horovod/issues/3132", "id": 980743422, "node_id": "MDU6SXNzdWU5ODA3NDM0MjI=", "number": 3132, "title": "[OSX] Horovod build fails on Tensorflow 2.6.0 on master branch", "user": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-08-27T00:09:10Z", "updated_at": "2021-09-13T17:04:50Z", "closed_at": "2021-09-13T17:04:50Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\nTensorflow 2.6.0\r\nKeras 2.6.0\r\nOSX: 11.5.1\r\n\r\n**Bug report:**\r\nBuild command:\r\n```\r\nHOROVOD_WITHOUT_MPI=1 HOROVOD_WITHOUT_MXNET=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITH_TENSORFLOW=1 python setup.py install\r\n```\r\n\r\nError:\r\n\r\n```\r\n[ 71%] Linking CXX shared library ../../../../lib.macosx-11-x86_64-3.7/horovod/tensorflow/mpi_lib.cpython-37m-darwin.so\r\ncd /Users/chongxiaoc/git/horovod/build/temp.macosx-11-x86_64-3.7/RelWithDebInfo/horovod/tensorflow && /usr/local/Cellar/cmake/3.19.0/bin/cmake -E cmake_link_script CMakeFiles/tensorflow.dir/link.txt --verbose=1\r\n/Library/Developer/CommandLineTools/usr/bin/c++ -I/Users/chongxiaoc/build/hvd-py3.7/lib/python3.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0 -DEIGEN_MAX_ALIGN_BYTES=64  -pthread -fPIC -Wall -ftree-vectorize  -O3 -g -DNDEBUG -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.1.sdk -dynamiclib -Wl,-headerpad_max_install_names  -undefined dynamic_lookup -Wl,-exported_symbols_list,/Users/chongxiaoc/git/horovod/horovod.exp -o ../../../../lib.macosx-11-x86_64-3.7/horovod/tensorflow/mpi_lib.cpython-37m-darwin.so -install_name @rpath/mpi_lib.cpython-37m-darwin.so CMakeFiles/tensorflow.dir/__/common/common.cc.o CMakeFiles/tensorflow.dir/__/common/controller.cc.o CMakeFiles/tensorflow.dir/__/common/fusion_buffer_manager.cc.o CMakeFiles/tensorflow.dir/__/common/group_table.cc.o CMakeFiles/tensorflow.dir/__/common/half.cc.o CMakeFiles/tensorflow.dir/__/common/logging.cc.o CMakeFiles/tensorflow.dir/__/common/message.cc.o CMakeFiles/tensorflow.dir/__/common/operations.cc.o CMakeFiles/tensorflow.dir/__/common/parameter_manager.cc.o CMakeFiles/tensorflow.dir/__/common/process_set.cc.o CMakeFiles/tensorflow.dir/__/common/response_cache.cc.o CMakeFiles/tensorflow.dir/__/common/stall_inspector.cc.o CMakeFiles/tensorflow.dir/__/common/thread_pool.cc.o CMakeFiles/tensorflow.dir/__/common/timeline.cc.o CMakeFiles/tensorflow.dir/__/common/tensor_queue.cc.o CMakeFiles/tensorflow.dir/__/common/ops/collective_operations.cc.o CMakeFiles/tensorflow.dir/__/common/ops/operation_manager.cc.o CMakeFiles/tensorflow.dir/__/common/optim/bayesian_optimization.cc.o CMakeFiles/tensorflow.dir/__/common/optim/gaussian_process.cc.o CMakeFiles/tensorflow.dir/__/common/utils/env_parser.cc.o CMakeFiles/tensorflow.dir/__/common/gloo/gloo_context.cc.o CMakeFiles/tensorflow.dir/__/common/gloo/gloo_controller.cc.o CMakeFiles/tensorflow.dir/__/common/gloo/http_store.cc.o CMakeFiles/tensorflow.dir/__/common/gloo/memory_store.cc.o CMakeFiles/tensorflow.dir/__/common/ops/gloo_operations.cc.o CMakeFiles/tensorflow.dir/mpi_ops.cc.o CMakeFiles/tensorflow.dir/xla_mpi_ops.cc.o  -L/Users/chongxiaoc/build/hvd-py3.7/lib/python3.7/site-packages/tensorflow -ltensorflow_framework.2 -L/Users/chongxiaoc/build/hvd-py3.7/lib/python3.7/site-packages/tensorflow/python/ -l:_pywrap_tensorflow_internal.so ../../third_party/compatible_gloo/gloo/libcompatible_gloo.a /usr/local/Cellar/libuv/1.41.0/lib/libuv.a -lpthread\r\nld: library not found for -l:_pywrap_tensorflow_internal.so\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nmake[2]: *** [../../lib.macosx-11-x86_64-3.7/horovod/tensorflow/mpi_lib.cpython-37m-darwin.so] Error 1\r\nmake[1]: *** [horovod/tensorflow/CMakeFiles/tensorflow.dir/all] Error 2\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3132/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3132/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3121", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3121/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3121/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3121/events", "html_url": "https://github.com/horovod/horovod/issues/3121", "id": 975010785, "node_id": "MDU6SXNzdWU5NzUwMTA3ODU=", "number": 3121, "title": "horovod.common.exceptions.HorovodInternalError: Broadcast is not supported with Join at this time.", "user": {"login": "b-hahn", "id": 23552045, "node_id": "MDQ6VXNlcjIzNTUyMDQ1", "avatar_url": "https://avatars.githubusercontent.com/u/23552045?v=4", "gravatar_id": "", "url": "https://api.github.com/users/b-hahn", "html_url": "https://github.com/b-hahn", "followers_url": "https://api.github.com/users/b-hahn/followers", "following_url": "https://api.github.com/users/b-hahn/following{/other_user}", "gists_url": "https://api.github.com/users/b-hahn/gists{/gist_id}", "starred_url": "https://api.github.com/users/b-hahn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/b-hahn/subscriptions", "organizations_url": "https://api.github.com/users/b-hahn/orgs", "repos_url": "https://api.github.com/users/b-hahn/repos", "events_url": "https://api.github.com/users/b-hahn/events{/privacy}", "received_events_url": "https://api.github.com/users/b-hahn/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Tixxx", "id": 26332583, "node_id": "MDQ6VXNlcjI2MzMyNTgz", "avatar_url": "https://avatars.githubusercontent.com/u/26332583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tixxx", "html_url": "https://github.com/Tixxx", "followers_url": "https://api.github.com/users/Tixxx/followers", "following_url": "https://api.github.com/users/Tixxx/following{/other_user}", "gists_url": "https://api.github.com/users/Tixxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tixxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tixxx/subscriptions", "organizations_url": "https://api.github.com/users/Tixxx/orgs", "repos_url": "https://api.github.com/users/Tixxx/repos", "events_url": "https://api.github.com/users/Tixxx/events{/privacy}", "received_events_url": "https://api.github.com/users/Tixxx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Tixxx", "id": 26332583, "node_id": "MDQ6VXNlcjI2MzMyNTgz", "avatar_url": "https://avatars.githubusercontent.com/u/26332583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tixxx", "html_url": "https://github.com/Tixxx", "followers_url": "https://api.github.com/users/Tixxx/followers", "following_url": "https://api.github.com/users/Tixxx/following{/other_user}", "gists_url": "https://api.github.com/users/Tixxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tixxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tixxx/subscriptions", "organizations_url": "https://api.github.com/users/Tixxx/orgs", "repos_url": "https://api.github.com/users/Tixxx/repos", "events_url": "https://api.github.com/users/Tixxx/events{/privacy}", "received_events_url": "https://api.github.com/users/Tixxx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2021-08-19T20:13:24Z", "updated_at": "2021-10-06T05:53:45Z", "closed_at": "2021-10-06T04:00:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Pytorch (Lightning)\r\n2. Framework version: 1.9.0+cu102 (and 1.4.2 for pytorch lightning)\r\n3. Horovod version: 0.22.1\r\n4. MPI version: 2.1.1\r\n5. CUDA version: 10.2\r\n6. NCCL version: 2708\r\n7. Python version: 3.9.6\r\n8. Spark / PySpark version: -\r\n9. Ray version: -\r\n10. OS and version: Ubuntu 18.04\r\n11. GCC version:  gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\n12. CMake version: cmake version 3.10.2\r\n\r\n\r\n**Bug report:**\r\nWhen running my training loop using horovod as an accelerator in pytorch lightning I encounter the following error after the 2nd epoch in all of my 8 workers:\r\n```\r\n[0]<stderr>:  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 816, in file_exists\r\n[0]<stderr>:    return trainer.training_type_plugin.broadcast(exists)\r\n[0]<stderr>:           \u2502       \u2502                              \u2514 False\r\n[0]<stderr>:           \u2502       \u2514 <property object at 0x7fa7182721d0>\r\n[0]<stderr>:           \u2514 <pytorch_lightning.trainer.trainer.Trainer object at 0x7fa708526fa0>\r\n[0]<stderr>:\r\n[0]<stderr>:  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/plugins/training_type/horovod.py\", line 129, in broadcast\r\n[0]<stderr>:    obj = hvd.broadcast_object(obj, src)\r\n[0]<stderr>:          \u2502   \u2502                \u2502    \u2514 0\r\n[0]<stderr>:          \u2502   \u2502                \u2514 False\r\n[0]<stderr>:          \u2502   \u2514 <function broadcast_object at 0x7fa72eb0c4c0>\r\n[0]<stderr>:          \u2514 <module 'horovod.torch' from '/usr/local/lib/python3.9/dist-packages/horovod/torch/__init__.py'>\r\n[0]<stderr>:\r\n[0]<stderr>:  File \"/usr/local/lib/python3.9/dist-packages/horovod/torch/functions.py\", line 218, in broadcast_object\r\n[0]<stderr>:    broadcast_(sz, root_rank, name + '.sz')\r\n[0]<stderr>:    \u2502          \u2502   \u2502          \u2514 'bool'\r\n[0]<stderr>:    \u2502          \u2502   \u2514 0\r\n[0]<stderr>:    \u2502          \u2514 tensor([4], dtype=torch.int32)\r\n[0]<stderr>:    \u2514 <function broadcast_ at 0x7fa72eb0a040>\r\n[0]<stderr>:\r\n[0]<stderr>:  File \"/usr/local/lib/python3.9/dist-packages/horovod/torch/mpi_ops.py\", line 741, in broadcast_\r\n[0]<stderr>:    return synchronize(handle)\r\n[0]<stderr>:           \u2502           \u2514 69713\r\n[0]<stderr>:           \u2514 <function synchronize at 0x7fa72eb0a4c0>\r\n[0]<stderr>:\r\n[0]<stderr>:  File \"/usr/local/lib/python3.9/dist-packages/horovod/torch/mpi_ops.py\", line 882, in synchronize\r\n[0]<stderr>:    raise HorovodInternalError(e)\r\n[0]<stderr>:          \u2514 <class 'horovod.common.exceptions.HorovodInternalError'>\r\n\r\n[0]<stderr>:horovod.common.exceptions.HorovodInternalError: Broadcast is not supported with Join at this time.\r\n```\r\n\r\nI'm not quite sure how to avoid the broadcast in the Join since this is all code internal to pytorch lightning. Do you have any idea what might be causing this? If you think this is an issue with pytorch lightning I'm happy to open an issue there. \r\nThanks a lot!\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3121/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3121/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3119", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3119/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3119/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3119/events", "html_url": "https://github.com/horovod/horovod/issues/3119", "id": 973923598, "node_id": "MDU6SXNzdWU5NzM5MjM1OTg=", "number": 3119, "title": "Spark Lightning MNIST fails on GPU", "user": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2021-08-18T18:00:13Z", "updated_at": "2021-08-19T17:10:12Z", "closed_at": "2021-08-19T17:10:12Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "From buildkite.\r\n\r\n```\r\n/horovod/examples/spark/pytorch/pytorch_lightning_spark_mnist.py --num-proc 2 --work-dir /work --data-dir /data --epochs 3\"' in service test-gpu-gloo-py3_8-tf2_4_3-keras2_3_1-torch1_7_1-mxnet1_6_0_p0-pyspark3_1_2 | 2m 46s\r\n-- | --\r\n\u00a0 | $ docker-compose -f docker-compose.test.yml -p buildkite27b20b242900470484e62a9743c390b7 -f docker-compose.buildkite-6387-override.yml run --name buildkite27b20b242900470484e62a9743c390b7_test-gpu-gloo-py3_8-tf2_4_3-keras2_3_1-torch1_7_1-mxnet1_6_0_p0-pyspark3_1_2_build_6387 -v /var/lib/buildkite-agent/builds/buildkite-2x-gpu-v510-i-0c5beeec60df27818-2/horovod/horovod/artifacts:/artifacts --rm test-gpu-gloo-py3_8-tf2_4_3-keras2_3_1-torch1_7_1-mxnet1_6_0_p0-pyspark3_1_2 /bin/sh -e -c 'bash -c \"OMP_NUM_THREADS=1 /spark_env.sh python /horovod/examples/spark/pytorch/pytorch_lightning_spark_mnist.py --num-proc 2 --work-dir /work --data-dir /data --epochs 3\"'\r\n\u00a0 | Creating buildkite27b20b242900470484e62a9743c390b7_test-gpu-gloo-py3_8-tf2_4_3-keras2_3_1-torch1_7_1-mxnet1_6_0_p0-pyspark3_1_2_run ... done\r\n\u00a0 | 21/08/18 15:13:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n\u00a0 | Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\r\n\u00a0 | Setting default log level to \"WARN\".\r\n\u00a0 | To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\r\n\u00a0 | num_partitions=20\r\n\u00a0 | writing dataframes\r\n\u00a0 | train_data_path=file:///work/intermediate_train_data.0\r\n\u00a0 | val_data_path=file:///work/intermediate_val_data.0\r\n\u00a0 | train_partitions=18\r\n\u00a0 | val_partitions=2\r\n\u00a0 | /usr/local/lib/python3.8/dist-packages/horovod/spark/common/util.py:509: FutureWarning: The 'field_by_name' method is deprecated, use 'field' instead\r\n\u00a0 | metadata, avg_row_size = make_metadata_dictionary(train_data_schema)\r\n\u00a0 | train_rows=48721\r\n\u00a0 | val_rows=5384\r\n\u00a0 | 2021-08-18 15:14:26.091848: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n\u00a0 | 2021-08-18 15:14:26.091875: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n\u00a0 | 2021-08-18 15:14:27.292047: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n\u00a0 | 2021-08-18 15:14:27.292079: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n\u00a0 | 2021-08-18 15:14:28.372275: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n\u00a0 | 2021-08-18 15:14:28.372304: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n\u00a0 | Wed Aug 18 15:14:31 2021[1]<stdout>:Training data of rank[1]: train_rows:48721, batch_size:64, _train_steps_per_epoch:380.\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:Creating trainer with:\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:  {'accelerator': 'horovod', 'gpus': 1, 'callbacks': [<__main__.MyDummyCallback object at 0x7f62c12d1fd0>, <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f6261f33490>, <pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f6261b9a1f0>], 'max_epochs': 3, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f62c12d1790>, 'log_every_n_steps': 50, 'resume_from_checkpoint': None, 'checkpoint_callback': True, 'num_sanity_val_steps': 0, 'reload_dataloaders_every_epoch': False, 'progress_bar_refresh_rate': 38, 'terminate_on_nan': False}\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:Starting to init trainer!\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:Trainer is initialized.\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:pytorch_lightning version=1.3.8\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO Bootstrap : Using [0]lo:127.0.0.1<0> [1]eth0:192.168.48.2<0>\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO NET/Socket : Using [0]lo:127.0.0.1<0> [1]eth0:192.168.48.2<0>\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO Using network Socket\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO threadThresholds 8/8/64 \\| 16/8/64 \\| 8/8/64\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO Trees [0] -1/-1/-1->1->0\\|0->1->-1/-1/-1 [1] -1/-1/-1->1->0\\|0->1->-1/-1/-1\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO Could not enable P2P between dev 1(=1e0) and dev 0(=1d0)\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO Could not enable P2P between dev 1(=1e0) and dev 0(=1d0)\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO Channel 00 : 1[1e0] -> 0[1d0] via direct shared memory\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO Could not enable P2P between dev 1(=1e0) and dev 0(=1d0)\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO Could not enable P2P between dev 1(=1e0) and dev 0(=1d0)\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO Channel 01 : 1[1e0] -> 0[1d0] via direct shared memory\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stdout>:b436722175a2:337:369 [1] NCCL INFO comm 0x7f62ac01c6c0 rank 1 nranks 2 cudaDev 1 busId 1e0 - Init COMPLETE\r\n\u00a0 | Wed Aug 18 15:14:35 2021[1]<stdout>:Setup train dataloader\r\n\u00a0 | Wed Aug 18 15:14:35 2021[1]<stdout>:[train dataloader]: Initializing petastorm dataloader with batch_size=64shuffling_queue_capacity=24360, limit_step_per_epoch=380\r\n\u00a0 | Wed Aug 18 15:14:35 2021[1]<stdout>:Apply the AsyncDataLoaderMixin on top of the data loader, async_loader_queue_size=64.\r\n\u00a0 | Wed Aug 18 15:14:35 2021[1]<stdout>:setup val dataloader\r\n\u00a0 | Wed Aug 18 15:14:35 2021[1]<stdout>:[val dataloader]: Initializing petastorm dataloader with batch_size=64shuffling_queue_capacity=0, limit_step_per_epoch=42\r\n\u00a0 | Wed Aug 18 15:14:35 2021[1]<stdout>:Apply the AsyncDataLoaderMixin on top of the data loader, async_loader_queue_size=64.\r\n\u00a0 | Wed Aug 18 15:14:35 2021[1]<stdout>:Start generating batches from async data loader.\r\n\u00a0 | Wed Aug 18 15:14:35 2021[1]<stdout>:[train dataloader]: Start to generate batch data. limit_step_per_epoch=380\r\n\u00a0 | Wed Aug 18 15:14:36 2021[1]<stdout>:training data batch size: torch.Size([64])\r\n\u00a0 | Wed Aug 18 15:14:38 2021[1]<stdout>:[train dataloader]: Reach limit_step_per_epoch. Stop at step 380.\r\n\u00a0 | Wed Aug 18 15:14:38 2021[1]<stdout>:[train dataloader]: Start to generate batch data. limit_step_per_epoch=380\r\n\u00a0 | Wed Aug 18 15:14:38 2021[1]<stdout>:A train epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:38 2021[1]<stdout>:A train or eval epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:38 2021[1]<stdout>:Start generating batches from async data loader.\r\n\u00a0 | Wed Aug 18 15:14:38 2021[1]<stdout>:[val dataloader]: Start to generate batch data. limit_step_per_epoch=42\r\n\u00a0 | Wed Aug 18 15:14:39 2021[1]<stdout>:validation data batch size: torch.Size([64])\r\n\u00a0 | Wed Aug 18 15:14:39 2021[1]<stdout>:[val dataloader]: Reach limit_step_per_epoch. Stop at step 42.\r\n\u00a0 | Wed Aug 18 15:14:39 2021[1]<stdout>:[val dataloader]: Start to generate batch data. limit_step_per_epoch=42\r\n\u00a0 | Wed Aug 18 15:14:39 2021[1]<stdout>:A val epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:39 2021[1]<stdout>:A train or eval epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:40 2021[1]<stdout>:Start generating batches from async data loader.\r\n\u00a0 | Wed Aug 18 15:14:40 2021[1]<stdout>:training data batch size: torch.Size([64])\r\n\u00a0 | Wed Aug 18 15:14:40 2021[1]<stdout>:[val dataloader]: Reach limit_step_per_epoch. Stop at step 42.\r\n\u00a0 | Wed Aug 18 15:14:40 2021[1]<stdout>:[val dataloader]: Start to generate batch data. limit_step_per_epoch=42\r\n\u00a0 | Wed Aug 18 15:14:42 2021[1]<stdout>:[train dataloader]: Reach limit_step_per_epoch. Stop at step 380.\r\n\u00a0 | Wed Aug 18 15:14:42 2021[1]<stdout>:[train dataloader]: Start to generate batch data. limit_step_per_epoch=380\r\n\u00a0 | Wed Aug 18 15:14:43 2021[1]<stdout>:A train epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[1]<stdout>:A train or eval epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[1]<stdout>:Start generating batches from async data loader.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[1]<stdout>:validation data batch size: torch.Size([64])\r\n\u00a0 | Wed Aug 18 15:14:43 2021[1]<stdout>:A val epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[1]<stdout>:A train or eval epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[1]<stdout>:Start generating batches from async data loader.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[1]<stdout>:training data batch size: torch.Size([64])\r\n\u00a0 | Wed Aug 18 15:14:43 2021[1]<stdout>:[val dataloader]: Reach limit_step_per_epoch. Stop at step 42.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[1]<stdout>:[val dataloader]: Start to generate batch data. limit_step_per_epoch=42\r\n\u00a0 | Wed Aug 18 15:14:45 2021[1]<stdout>:[train dataloader]: Reach limit_step_per_epoch. Stop at step 380.\r\n\u00a0 | Wed Aug 18 15:14:45 2021[1]<stdout>:[train dataloader]: Start to generate batch data. limit_step_per_epoch=380\r\n\u00a0 | Wed Aug 18 15:14:46 2021[1]<stdout>:A train epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:46 2021[1]<stdout>:A train or eval epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:46 2021[1]<stdout>:Start generating batches from async data loader.\r\n\u00a0 | Wed Aug 18 15:14:46 2021[1]<stdout>:validation data batch size: torch.Size([64])\r\n\u00a0 | Wed Aug 18 15:14:46 2021[1]<stdout>:[val dataloader]: Reach limit_step_per_epoch. Stop at step 42.\r\n\u00a0 | Wed Aug 18 15:14:46 2021[1]<stdout>:[val dataloader]: Start to generate batch data. limit_step_per_epoch=42\r\n\u00a0 | Wed Aug 18 15:14:46 2021[1]<stdout>:A val epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:46 2021[1]<stdout>:A train or eval epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:46 2021[1]<stdout>:Training ends:epcoh_end_counter=6, train_epcoh_end_counter=3, validation_epoch_end_counter=3\r\n\u00a0 | Wed Aug 18 15:14:46 2021[1]<stdout>:\r\n\u00a0 | Wed Aug 18 15:14:46 2021[1]<stdout>:Tear down petastorm readers\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stderr>:GPU available: True, used: True\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stderr>:TPU available: False, using: 0 TPU cores\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stderr>:/usr/local/lib/python3.8/dist-packages/petastorm/fs_utils.py:88: FutureWarning: pyarrow.localfs is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stderr>:  self._filesystem = pyarrow.localfs\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stderr>:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,3]\r\n\u00a0 | Wed Aug 18 15:14:34 2021[1]<stderr>:Missing logger folder: /tmp/tmpwmgicp1r/logs/default\r\n\u00a0 | Wed Aug 18 15:14:36 2021[1]<stderr>:/usr/local/lib/python3.8/dist-packages/petastorm/pytorch.py:339: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\r\n\u00a0 | Wed Aug 18 15:14:36 2021[1]<stderr>:  row_as_dict[k] = self.transform_fn(v)\r\n\u00a0 | Wed Aug 18 15:14:40 2021[1]<stderr>:[rank: 1] Metric val_loss improved. New best score: 0.500\r\n\u00a0 | Wed Aug 18 15:14:46 2021[1]<stderr>:terminate called without an active exception\r\n\u00a0 | Wed Aug 18 15:14:50 2021[1]<stderr>:Aborted (core dumped)\r\n\u00a0 | Wed Aug 18 15:14:31 2021[0]<stdout>:Training data of rank[0]: train_rows:48721, batch_size:64, _train_steps_per_epoch:380.\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:Creating trainer with:\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:  {'accelerator': 'horovod', 'gpus': 1, 'callbacks': [<__main__.MyDummyCallback object at 0x7f00ac791fd0>, <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f004d418490>, <pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f004d07f1f0>], 'max_epochs': 3, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f00ac791790>, 'log_every_n_steps': 50, 'resume_from_checkpoint': None, 'checkpoint_callback': True, 'num_sanity_val_steps': 0, 'reload_dataloaders_every_epoch': False, 'progress_bar_refresh_rate': 38, 'terminate_on_nan': False}\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:Starting to init trainer!\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:Trainer is initialized.\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:pytorch_lightning version=1.3.8\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO Bootstrap : Using [0]lo:127.0.0.1<0> [1]eth0:192.168.48.2<0>\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO NET/Socket : Using [0]lo:127.0.0.1<0> [1]eth0:192.168.48.2<0>\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO Using network Socket\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:NCCL version 2.7.8+cuda10.1\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO Channel 00/02 :    0   1\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO Channel 01/02 :    0   1\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO threadThresholds 8/8/64 \\| 16/8/64 \\| 8/8/64\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1\\|-1->0->1/-1/-1 [1] 1/-1/-1->0->-1\\|-1->0->1/-1/-1\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO Could not enable P2P between dev 0(=1d0) and dev 1(=1e0)\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO Could not enable P2P between dev 0(=1d0) and dev 1(=1e0)\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO Channel 00 : 0[1d0] -> 1[1e0] via direct shared memory\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO Could not enable P2P between dev 0(=1d0) and dev 1(=1e0)\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO Could not enable P2P between dev 0(=1d0) and dev 1(=1e0)\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO Channel 01 : 0[1d0] -> 1[1e0] via direct shared memory\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO comm 0x7f009801d090 rank 0 nranks 2 cudaDev 0 busId 1d0 - Init COMPLETE\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stdout>:b436722175a2:333:379 [0] NCCL INFO Launch mode Parallel\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stdout>:Setup train dataloader\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stdout>:[train dataloader]: Initializing petastorm dataloader with batch_size=64shuffling_queue_capacity=24360, limit_step_per_epoch=380\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stdout>:Apply the AsyncDataLoaderMixin on top of the data loader, async_loader_queue_size=64.\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stdout>:setup val dataloader\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stdout>:[val dataloader]: Initializing petastorm dataloader with batch_size=64shuffling_queue_capacity=0, limit_step_per_epoch=42\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stdout>:Apply the AsyncDataLoaderMixin on top of the data loader, async_loader_queue_size=64.\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stdout>:Epoch 0:   0%\\|          \\| 0/422 [00:00<?, ?it/s] Start generating batches from async data loader.\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stdout>:[train dataloader]: Start to generate batch data. limit_step_per_epoch=380\r\n\u00a0 | Wed Aug 18 15:14:36 2021[0]<stdout>:training data batch size: torch.Size([64])\r\n\u00a0 | Wed Aug 18 15:14:38 2021[0]<stdout>:Epoch 0:  72%\\|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  \\| 304/422 [00:02<00:00, 118.47it/s, loss=1.2, v_num=0] [train dataloader]: Reach limit_step_per_epoch. Stop at step 380.\r\n\u00a0 | Wed Aug 18 15:14:38 2021[0]<stdout>:[train dataloader]: Start to generate batch data. limit_step_per_epoch=380\r\n\u00a0 | Wed Aug 18 15:14:38 2021[0]<stdout>:Epoch 0:  90%\\|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \\| 380/422 [00:03<00:00, 125.42it/s, loss=1.05, v_num=0]A train epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:38 2021[0]<stdout>:A train or eval epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:38 2021[0]<stdout>:                                                  Start generating batches from async data loader.\r\n\u00a0 | Wed Aug 18 15:14:38 2021[0]<stdout>:[val dataloader]: Start to generate batch data. limit_step_per_epoch=42\r\n\u00a0 | Wed Aug 18 15:14:40 2021[0]<stdout>:[val dataloader]: Reach limit_step_per_epoch. Stop at step 42.\r\n\u00a0 | Wed Aug 18 15:14:40 2021[0]<stdout>:[val dataloader]: Start to generate batch data. limit_step_per_epoch=42\r\n\u00a0 | Wed Aug 18 15:14:40 2021[0]<stdout>:validation data batch size: torch.Size([64])\r\n\u00a0 | Wed Aug 18 15:14:40 2021[0]<stdout>:Epoch 0: 100%\\|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\| 422/422 [00:04<00:00, 91.34it/s, loss=1.05, v_num=0] A val epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:40 2021[0]<stdout>:A train or eval epoch ended. 38/42 [00:01<00:00, 24.30it/s]\r\n\u00a0 | Wed Aug 18 15:14:40 2021[0]<stdout>:Epoch 1:   0%\\|          \\| 0/422 [00:00<?, ?it/s, loss=1.05, v_num=0]Start generating batches from async data loader.\r\n\u00a0 | Wed Aug 18 15:14:40 2021[0]<stdout>:training data batch size: torch.Size([64])\r\n\u00a0 | Wed Aug 18 15:14:40 2021[0]<stdout>:[val dataloader]: Reach limit_step_per_epoch. Stop at step 42.\r\n\u00a0 | Wed Aug 18 15:14:40 2021[0]<stdout>:[val dataloader]: Start to generate batch data. limit_step_per_epoch=42\r\n\u00a0 | Wed Aug 18 15:14:42 2021[0]<stdout>:Epoch 1:  72%\\|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  \\| 304/422 [00:02<00:00, 138.95it/s, loss=0.939, v_num=0][train dataloader]: Reach limit_step_per_epoch. Stop at step 380.\r\n\u00a0 | Wed Aug 18 15:14:42 2021[0]<stdout>:[train dataloader]: Start to generate batch data. limit_step_per_epoch=380\r\n\u00a0 | Wed Aug 18 15:14:43 2021[0]<stdout>:Epoch 1:  90%\\|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \\| 380/422 [00:02<00:00, 138.97it/s, loss=0.774, v_num=0]A train epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[0]<stdout>:A train or eval epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[0]<stdout>:                                                  Start generating batches from async data loader.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[0]<stdout>:validation data batch size: torch.Size([64])?it/s]\r\n\u00a0 | Wed Aug 18 15:14:43 2021[0]<stdout>:A val epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[0]<stdout>:A train or eval epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[0]<stdout>:Epoch 2:   0%\\|          \\| 0/422 [00:00<?, ?it/s, loss=0.774, v_num=0]Start generating batches from async data loader.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[0]<stdout>:training data batch size: torch.Size([64])\r\n\u00a0 | Wed Aug 18 15:14:43 2021[0]<stdout>:[val dataloader]: Reach limit_step_per_epoch. Stop at step 42.\r\n\u00a0 | Wed Aug 18 15:14:43 2021[0]<stdout>:[val dataloader]: Start to generate batch data. limit_step_per_epoch=42\r\n\u00a0 | Wed Aug 18 15:14:45 2021[0]<stdout>:Epoch 2:  72%\\|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  \\| 304/422 [00:02<00:00, 135.23it/s, loss=0.639, v_num=0][train dataloader]: Reach limit_step_per_epoch. Stop at step 380.\r\n\u00a0 | Wed Aug 18 15:14:45 2021[0]<stdout>:[train dataloader]: Start to generate batch data. limit_step_per_epoch=380\r\n\u00a0 | Wed Aug 18 15:14:46 2021[0]<stdout>:Epoch 2:  90%\\|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \\| 380/422 [00:02<00:00, 134.50it/s, loss=0.656, v_num=0]A train epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:46 2021[0]<stdout>:A train or eval epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:46 2021[0]<stdout>:                                                  Start generating batches from async data loader.\r\n\u00a0 | Wed Aug 18 15:14:46 2021[0]<stdout>:validation data batch size: torch.Size([64])?it/s]\r\n\u00a0 | Wed Aug 18 15:14:46 2021[0]<stdout>:A val epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:46 2021[0]<stdout>:A train or eval epoch ended.\r\n\u00a0 | Wed Aug 18 15:14:46 2021[0]<stdout>:Epoch 2: 100%\\|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\| 422/422 [00:02<00:00, 14Training ends:epcoh_end_counter=6, train_epcoh_end_counter=3, validation_epoch_end_counter=3\r\n\u00a0 | Wed Aug 18 15:14:46 2021[0]<stdout>:\r\n\u00a0 | Wed Aug 18 15:14:46 2021[0]<stdout>:Epoch 2: 100%\\|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\| 422/422 [00:02<00:00, 143.65it/s, loss=0.656, v_num=0]\r\n\u00a0 | Wed Aug 18 15:14:46 2021[0]<stdout>:Tear down petastorm readers\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stderr>:GPU available: True, used: True\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stderr>:TPU available: False, using: 0 TPU cores\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stderr>:/usr/local/lib/python3.8/dist-packages/petastorm/fs_utils.py:88: FutureWarning: pyarrow.localfs is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stderr>:  self._filesystem = pyarrow.localfs\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stderr>:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,3]\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stderr>:2021-08-18 15:14:34.868268: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n\u00a0 | Wed Aug 18 15:14:34 2021[0]<stderr>:2021-08-18 15:14:34.868287: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:  \\| Name       \\| Type      \\| Params\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:-----------------------------------------\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:0 \\| conv1      \\| Conv2d    \\| 260\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:1 \\| conv2      \\| Conv2d    \\| 5.0 K\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:2 \\| conv2_drop \\| Dropout2d \\| 0\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:3 \\| fc1        \\| Linear    \\| 16.1 K\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:4 \\| fc2        \\| Linear    \\| 510\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:-----------------------------------------\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:21.8 K    Trainable params\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:0         Non-trainable params\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:21.8 K    Total params\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:0.087     Total estimated model params size (MB)\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:/usr/local/lib/python3.8/dist-packages/petastorm/pytorch.py:339: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\r\n\u00a0 | Wed Aug 18 15:14:35 2021[0]<stderr>:  row_as_dict[k] = self.transform_fn(v)\r\n\u00a0 | Wed Aug 18 15:14:40 2021[0]<stderr>:[rank: 0] Metric val_loss improved. New best score: 0.479\r\n\u00a0 | Wed Aug 18 15:14:40 2021[0]<stderr>:/usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:610: LightningDeprecationWarning: Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2 and will be removed in v1.4. Please, create your own `mc = ModelCheckpoint(monitor='your_monitor')` and use it as `Trainer(callbacks=[mc])`.\r\n\u00a0 | Wed Aug 18 15:14:40 2021[0]<stderr>:  warning_cache.deprecation(\r\n\u00a0 | Wed Aug 18 15:14:46 2021[0]<stderr>:terminate called without an active exception\r\n\u00a0 | Wed Aug 18 15:14:51 2021[0]<stderr>:Aborted (core dumped)\r\n\u00a0 | Exception in thread Thread-3:\r\n\u00a0 | Traceback (most recent call last):\r\n\u00a0 | File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n\u00a0 | self.run()\r\n\u00a0 | File \"/usr/lib/python3.8/threading.py\", line 870, in run\r\n\u00a0 | self._target(*self._args, **self._kwargs)\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/runner.py\", line 141, in run_spark\r\n\u00a0 | result = procs.mapPartitionsWithIndex(mapper).collect()\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/pyspark/rdd.py\", line 949, in collect\r\n\u00a0 | sock_info = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/py4j/java_gateway.py\", line 1304, in __call__\r\n\u00a0 | return_value = get_return_value(\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/pyspark/sql/utils.py\", line 111, in deco\r\n\u00a0 | return f(*a, **kw)\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/py4j/protocol.py\", line 326, in get_return_value\r\n\u00a0 | raise Py4JJavaError(\r\n\u00a0 | py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\r\n\u00a0 | : org.apache.spark.SparkException: Job 4 cancelled part of cancelled job group horovod.spark.run.0\r\n\u00a0 | at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\r\n\u00a0 | at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:2154)\r\n\u00a0 | at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleJobGroupCancelled$4(DAGScheduler.scala:1048)\r\n\u00a0 | at scala.runtime.java8.JFunction1$mcVI$sp.apply(JFunction1$mcVI$sp.java:23)\r\n\u00a0 | at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\r\n\u00a0 | at org.apache.spark.scheduler.DAGScheduler.handleJobGroupCancelled(DAGScheduler.scala:1047)\r\n\u00a0 | at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2407)\r\n\u00a0 | at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\r\n\u00a0 | at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\r\n\u00a0 | at org.apache.spark.util.EventLoop$anon$1.run(EventLoop.scala:49)\r\n\u00a0 | at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\u00a0 | at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\r\n\u00a0 | at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)\r\n\u00a0 | at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)\r\n\u00a0 | at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)\r\n\u00a0 | at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\r\n\u00a0 | at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\u00a0 | at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\u00a0 | at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\u00a0 | at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\r\n\u00a0 | at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\r\n\u00a0 | at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\u00a0 | at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\u00a0 | at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\u00a0 | at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\u00a0 | at java.lang.reflect.Method.invoke(Method.java:498)\r\n\u00a0 | at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\u00a0 | at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\u00a0 | at py4j.Gateway.invoke(Gateway.java:282)\r\n\u00a0 | at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\u00a0 | at py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\u00a0 | at py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\u00a0 | at java.lang.Thread.run(Thread.java:748)\r\n\u00a0 | \u00a0\r\n\u00a0 | Traceback (most recent call last):\r\n\u00a0 | File \"/horovod/examples/spark/pytorch/pytorch_lightning_spark_mnist.py\", line 214, in <module>\r\n\u00a0 | train_model(args)\r\n\u00a0 | File \"/horovod/examples/spark/pytorch/pytorch_lightning_spark_mnist.py\", line 199, in train_model\r\n\u00a0 | torch_model = torch_estimator.fit(train_df).setOutputCols(['label_prob'])\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/estimator.py\", line 35, in fit\r\n\u00a0 | return super(HorovodEstimator, self).fit(df, params)\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/pyspark/ml/base.py\", line 161, in fit\r\n\u00a0 | return self._fit(dataset)\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/estimator.py\", line 80, in _fit\r\n\u00a0 | return self._fit_on_prepared_data(\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/lightning/estimator.py\", line 406, in _fit_on_prepared_data\r\n\u00a0 | handle = backend.run(trainer, args=(serialized_model,), env={})\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/backend.py\", line 83, in run\r\n\u00a0 | return horovod.spark.run(fn, args=args, kwargs=kwargs,\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/runner.py\", line 287, in run\r\n\u00a0 | _launch_job(use_mpi, use_gloo, settings, driver, env, stdout, stderr, executable)\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/runner.py\", line 154, in _launch_job\r\n\u00a0 | run_controller(use_gloo, lambda: gloo_run(executable, settings, nics, driver, env, stdout, stderr),\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/runner/launch.py\", line 706, in run_controller\r\n\u00a0 | gloo_run()\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/runner.py\", line 154, in <lambda>\r\n\u00a0 | run_controller(use_gloo, lambda: gloo_run(executable, settings, nics, driver, env, stdout, stderr),\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/gloo_run.py\", line 68, in gloo_run\r\n\u00a0 | launch_gloo(command, exec_command, settings, nics, {}, server_ip)\r\n\u00a0 | File \"/usr/local/lib/python3.8/dist-packages/horovod/runner/gloo_run.py\", line 282, in launch_gloo\r\n\u00a0 | raise RuntimeError('Horovod detected that one or more processes exited with non-zero '\r\n\u00a0 | RuntimeError: Horovod detected that one or more processes exited with non-zero status, thus causing the job to be terminated. The first process to do so was:\r\n\u00a0 | Process name: 1\r\n\u00a0 | Exit code: 134\r\n\r\n\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3119/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3119/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3118", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3118/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3118/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3118/events", "html_url": "https://github.com/horovod/horovod/issues/3118", "id": 973497340, "node_id": "MDU6SXNzdWU5NzM0OTczNDA=", "number": 3118, "title": "Distributed Training Failed with Horovod built from source", "user": {"login": "jasperzhong", "id": 25879526, "node_id": "MDQ6VXNlcjI1ODc5NTI2", "avatar_url": "https://avatars.githubusercontent.com/u/25879526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasperzhong", "html_url": "https://github.com/jasperzhong", "followers_url": "https://api.github.com/users/jasperzhong/followers", "following_url": "https://api.github.com/users/jasperzhong/following{/other_user}", "gists_url": "https://api.github.com/users/jasperzhong/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasperzhong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasperzhong/subscriptions", "organizations_url": "https://api.github.com/users/jasperzhong/orgs", "repos_url": "https://api.github.com/users/jasperzhong/repos", "events_url": "https://api.github.com/users/jasperzhong/events{/privacy}", "received_events_url": "https://api.github.com/users/jasperzhong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-08-18T10:06:23Z", "updated_at": "2021-11-05T10:02:54Z", "closed_at": "2021-11-05T10:02:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.9.0+cu102\r\n3. Horovod version: 0.22.1\r\n4. MPI version: none\r\n5. CUDA version: 10.2\r\n6. NCCL version: 2.9.6\r\n7. Python version: 3.6.13\r\n8. Spark / PySpark version: \r\n9. Ray version:\r\n10. OS and version: ubuntu 18.04 lts\r\n11. GCC version: 7.5\r\n12. CMake version: 3.19.6\r\n\r\n**Bug report:**\r\n\r\nI have two machines, each equipped with 4 V100 GPUs. \r\n\r\n```sh\r\nenp94s0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\r\n        inet 10.28.1.27  netmask 255.255.255.0  broadcast 10.28.1.255\r\n        inet6 fe80::e42:a1ff:fe0c:5714  prefixlen 64  scopeid 0x20<link>\r\n        ether 0c:42:a1:0c:57:14  txqueuelen 1000  (Ethernet)\r\n        RX packets 1418319890  bytes 155530617173 (155.5 GB)\r\n        RX errors 0  dropped 0  overruns 0  frame 0\r\n        TX packets 1402926022  bytes 221353554872 (221.3 GB)\r\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\r\n```\r\n\r\n```sh\r\nenp94s0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\r\n        inet 10.28.1.28  netmask 255.255.255.0  broadcast 10.28.1.255\r\n        inet6 fe80::ba59:9fff:feab:83b0  prefixlen 64  scopeid 0x20<link>\r\n        ether b8:59:9f:ab:83:b0  txqueuelen 1000  (Ethernet)\r\n        RX packets 1403090728  bytes 221304591692 (221.3 GB)\r\n        RX errors 0  dropped 68864  overruns 0  frame 0\r\n        TX packets 1418041340  bytes 155464862915 (155.4 GB)\r\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\r\n```\r\n\r\nI cloned the latest repo and built Horovod with the following command\r\n```sh\r\ngit clone --recursive https://github.com/horovod/horovod.git\r\ncd horovod\r\nHOROVOD_WITHOUT_MPI=1 HOROVOD_WITH_GLOO=1  HOROVOD_NCCL_HOME=/usr/local/nccl HOROVOD_GPU_OPERATIONS=NCCL pip install --no-cache-dir -v -e .\r\n```\r\n\r\n\r\n```sh\r\n$ horovodrun --check-buildHorovod v0.22.1:\r\n\r\nAvailable Frameworks:\r\n    [ ] TensorFlow\r\n    [X] PyTorch\r\n    [ ] MXNet\r\n\r\nAvailable Controllers:\r\n    [ ] MPI\r\n    [X] Gloo\r\n\r\nAvailable Tensor Operations:\r\n    [X] NCCL\r\n    [ ] DDL\r\n    [ ] CCL\r\n    [ ] MPI\r\n    [X] Gloo\r\n```\r\n\r\nThen I run the following command in one of the machines, \r\n```sh\r\nhorovodrun -np 8 -H 10.28.1.27:4,10.28.1.28:4 --start-timeout 600 --network-interface enp94s0 --verbose python pytorch_mnist.py\r\n```\r\n\r\nbut I got this error\r\n```sh\r\nFiltering local host names.\r\nRemote host found: 10.28.1.28\r\nChecking ssh on all remote hosts.\r\nSSH was successful into all the remote hosts.\r\nHOROVOD_HOSTNAME=10.28.1.27 HOROVOD_RANK=0 HOROVOD_SIZE=8 HOROVOD_LOCAL_RANK=0 HOROVOD_LOCAL_SIZE=4 HOROVOD_CROSS_RANK=0 HOROVOD_CROSS_SIZE=2 LANG=en_US.UTF-8 USER=yczhong LOGNAME=yczhong HOME=/home/yczhong PATH=/opt/anaconda3/envs/ft_hvd/bin:/opt/anaconda3/condabin:/usr/local/cuda/bin:/opt/anaconda3/bin:/home/yczhong/.local/bin:/home/yczhong/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games MAIL=/var/mail/yczhong SHELL=/usr/bin/zsh SSH_CLIENT='147.8.179.11 56294 22' SSH_CONNECTION='147.8.179.11 56294 202.45.128.232 22' SSH_TTY=/dev/pts/17 TERM=screen-256color XDG_SESSION_ID=445 XDG_RUNTIME_DIR=/run/user/1019 DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1019/bus LC_NUMERIC=zh_CN.UTF-8 LC_TIME=zh_CN.UTF-8 LC_MONETARY=zh_CN.UTF-8 LC_PAPER=zh_CN.UTF-8 LC_NAME=zh_CN.UTF-8 LC_ADDRESS=zh_CN.UTF-8 LC_TELEPHONE=zh_CN.UTF-8 LC_MEASUREMENT=zh_CN.UTF-8 LC_IDENTIFICATION=zh_CN.UTF-8 SHLVL=1 PWD=/home/yczhong/repos/horovod/examples/pytorch ZSH=/home/yczhong/.oh-my-zsh PAGER=less LESS=-R LSCOLORS=Gxfxcxdxbxegedabagacad LS_COLORS='rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:' LD_LIBRARY_PATH=/usr/local/cuda/lib64: CONDA_EXE=/opt/anaconda3/bin/conda _CE_M='' _CE_CONDA='' CONDA_PYTHON_EXE=/opt/anaconda3/bin/python CONDA_SHLVL=2 CONDA_PREFIX=/opt/anaconda3/envs/ft_hvd CONDA_DEFAULT_ENV=ft_hvd CONDA_PROMPT_MODIFIER='(ft_hvd) ' CONDA_PREFIX_1=/opt/anaconda3 _=/opt/anaconda3/envs/ft_hvd/bin/horovodrun PYTHONUNBUFFERED=1 HOROVOD_GLOO_RENDEZVOUS_ADDR=10.28.1.27 HOROVOD_GLOO_RENDEZVOUS_PORT=7738 HOROVOD_CONTROLLER=gloo HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=enp94s0 NCCL_SOCKET_IFNAME=enp94s0 python pytorch_mnist.py\r\nHOROVOD_HOSTNAME=10.28.1.27 HOROVOD_RANK=1 HOROVOD_SIZE=8 HOROVOD_LOCAL_RANK=1 HOROVOD_LOCAL_SIZE=4 HOROVOD_CROSS_RANK=0 HOROVOD_CROSS_SIZE=2 LANG=en_US.UTF-8 USER=yczhong LOGNAME=yczhong HOME=/home/yczhong PATH=/opt/anaconda3/envs/ft_hvd/bin:/opt/anaconda3/condabin:/usr/local/cuda/bin:/opt/anaconda3/bin:/home/yczhong/.local/bin:/home/yczhong/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games MAIL=/var/mail/yczhong SHELL=/usr/bin/zsh SSH_CLIENT='147.8.179.11 56294 22' SSH_CONNECTION='147.8.179.11 56294 202.45.128.232 22' SSH_TTY=/dev/pts/17 TERM=screen-256color XDG_SESSION_ID=445 XDG_RUNTIME_DIR=/run/user/1019 DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1019/bus LC_NUMERIC=zh_CN.UTF-8 LC_TIME=zh_CN.UTF-8 LC_MONETARY=zh_CN.UTF-8 LC_PAPER=zh_CN.UTF-8 LC_NAME=zh_CN.UTF-8 LC_ADDRESS=zh_CN.UTF-8 LC_TELEPHONE=zh_CN.UTF-8 LC_MEASUREMENT=zh_CN.UTF-8 LC_IDENTIFICATION=zh_CN.UTF-8 SHLVL=1 PWD=/home/yczhong/repos/horovod/examples/pytorch ZSH=/home/yczhong/.oh-my-zsh PAGER=less LESS=-R LSCOLORS=Gxfxcxdxbxegedabagacad LS_COLORS='rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:' LD_LIBRARY_PATH=/usr/local/cuda/lib64: CONDA_EXE=/opt/anaconda3/bin/conda _CE_M='' _CE_CONDA='' CONDA_PYTHON_EXE=/opt/anaconda3/bin/python CONDA_SHLVL=2 CONDA_PREFIX=/opt/anaconda3/envs/ft_hvd CONDA_DEFAULT_ENV=ft_hvd CONDA_PROMPT_MODIFIER='(ft_hvd) ' CONDA_PREFIX_1=/opt/anaconda3 _=/opt/anaconda3/envs/ft_hvd/bin/horovodrun PYTHONUNBUFFERED=1 HOROVOD_GLOO_RENDEZVOUS_ADDR=10.28.1.27 HOROVOD_GLOO_RENDEZVOUS_PORT=7738 HOROVOD_CONTROLLER=gloo HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=enp94s0 NCCL_SOCKET_IFNAME=enp94s0 python pytorch_mnist.py\r\nHOROVOD_HOSTNAME=10.28.1.27 HOROVOD_RANK=2 HOROVOD_SIZE=8 HOROVOD_LOCAL_RANK=2 HOROVOD_LOCAL_SIZE=4 HOROVOD_CROSS_RANK=0 HOROVOD_CROSS_SIZE=2 LANG=en_US.UTF-8 USER=yczhong LOGNAME=yczhong HOME=/home/yczhong PATH=/opt/anaconda3/envs/ft_hvd/bin:/opt/anaconda3/condabin:/usr/local/cuda/bin:/opt/anaconda3/bin:/home/yczhong/.local/bin:/home/yczhong/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games MAIL=/var/mail/yczhong SHELL=/usr/bin/zsh SSH_CLIENT='147.8.179.11 56294 22' SSH_CONNECTION='147.8.179.11 56294 202.45.128.232 22' SSH_TTY=/dev/pts/17 TERM=screen-256color XDG_SESSION_ID=445 XDG_RUNTIME_DIR=/run/user/1019 DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1019/bus LC_NUMERIC=zh_CN.UTF-8 LC_TIME=zh_CN.UTF-8 LC_MONETARY=zh_CN.UTF-8 LC_PAPER=zh_CN.UTF-8 LC_NAME=zh_CN.UTF-8 LC_ADDRESS=zh_CN.UTF-8 LC_TELEPHONE=zh_CN.UTF-8 LC_MEASUREMENT=zh_CN.UTF-8 LC_IDENTIFICATION=zh_CN.UTF-8 SHLVL=1 PWD=/home/yczhong/repos/horovod/examples/pytorch ZSH=/home/yczhong/.oh-my-zsh PAGER=less LESS=-R LSCOLORS=Gxfxcxdxbxegedabagacad LS_COLORS='rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:' LD_LIBRARY_PATH=/usr/local/cuda/lib64: CONDA_EXE=/opt/anaconda3/bin/conda _CE_M='' _CE_CONDA='' CONDA_PYTHON_EXE=/opt/anaconda3/bin/python CONDA_SHLVL=2 CONDA_PREFIX=/opt/anaconda3/envs/ft_hvd CONDA_DEFAULT_ENV=ft_hvd CONDA_PROMPT_MODIFIER='(ft_hvd) ' CONDA_PREFIX_1=/opt/anaconda3 _=/opt/anaconda3/envs/ft_hvd/bin/horovodrun PYTHONUNBUFFERED=1 HOROVOD_GLOO_RENDEZVOUS_ADDR=10.28.1.27 HOROVOD_GLOO_RENDEZVOUS_PORT=7738 HOROVOD_CONTROLLER=gloo HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=enp94s0 NCCL_SOCKET_IFNAME=enp94s0 python pytorch_mnist.py\r\nHOROVOD_HOSTNAME=10.28.1.27 HOROVOD_RANK=3 HOROVOD_SIZE=8 HOROVOD_LOCAL_RANK=3 HOROVOD_LOCAL_SIZE=4 HOROVOD_CROSS_RANK=0 HOROVOD_CROSS_SIZE=2 LANG=en_US.UTF-8 USER=yczhong LOGNAME=yczhong HOME=/home/yczhong PATH=/opt/anaconda3/envs/ft_hvd/bin:/opt/anaconda3/condabin:/usr/local/cuda/bin:/opt/anaconda3/bin:/home/yczhong/.local/bin:/home/yczhong/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games MAIL=/var/mail/yczhong SHELL=/usr/bin/zsh SSH_CLIENT='147.8.179.11 56294 22' SSH_CONNECTION='147.8.179.11 56294 202.45.128.232 22' SSH_TTY=/dev/pts/17 TERM=screen-256color XDG_SESSION_ID=445 XDG_RUNTIME_DIR=/run/user/1019 DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1019/bus LC_NUMERIC=zh_CN.UTF-8 LC_TIME=zh_CN.UTF-8 LC_MONETARY=zh_CN.UTF-8 LC_PAPER=zh_CN.UTF-8 LC_NAME=zh_CN.UTF-8 LC_ADDRESS=zh_CN.UTF-8 LC_TELEPHONE=zh_CN.UTF-8 LC_MEASUREMENT=zh_CN.UTF-8 LC_IDENTIFICATION=zh_CN.UTF-8 SHLVL=1 PWD=/home/yczhong/repos/horovod/examples/pytorch ZSH=/home/yczhong/.oh-my-zsh PAGER=less LESS=-R LSCOLORS=Gxfxcxdxbxegedabagacad LS_COLORS='rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:' LD_LIBRARY_PATH=/usr/local/cuda/lib64: CONDA_EXE=/opt/anaconda3/bin/conda _CE_M='' _CE_CONDA='' CONDA_PYTHON_EXE=/opt/anaconda3/bin/python CONDA_SHLVL=2 CONDA_PREFIX=/opt/anaconda3/envs/ft_hvd CONDA_DEFAULT_ENV=ft_hvd CONDA_PROMPT_MODIFIER='(ft_hvd) ' CONDA_PREFIX_1=/opt/anaconda3 _=/opt/anaconda3/envs/ft_hvd/bin/horovodrun PYTHONUNBUFFERED=1 HOROVOD_GLOO_RENDEZVOUS_ADDR=10.28.1.27 HOROVOD_GLOO_RENDEZVOUS_PORT=7738 HOROVOD_CONTROLLER=gloo HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=enp94s0 NCCL_SOCKET_IFNAME=enp94s0 python pytorch_mnist.py\r\nssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no 10.28.1.28    'cd /home/yczhong/repos/horovod/examples/pytorch > /dev/null 2>&1 ; HOROVOD_HOSTNAME=10.28.1.28 HOROVOD_RANK=4 HOROVOD_SIZE=8 HOROVOD_LOCAL_RANK=0 HOROVOD_LOCAL_SIZE=4 HOROVOD_CROSS_RANK=1 HOROVOD_CROSS_SIZE=2 LANG=en_US.UTF-8 USER=yczhong LOGNAME=yczhong HOME=/home/yczhong PATH=/opt/anaconda3/envs/ft_hvd/bin:/opt/anaconda3/condabin:/usr/local/cuda/bin:/opt/anaconda3/bin:/home/yczhong/.local/bin:/home/yczhong/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games MAIL=/var/mail/yczhong SHELL=/usr/bin/zsh SSH_CLIENT='\"'\"'147.8.179.11 56294 22'\"'\"' SSH_CONNECTION='\"'\"'147.8.179.11 56294 202.45.128.232 22'\"'\"' SSH_TTY=/dev/pts/17 TERM=screen-256color XDG_SESSION_ID=445 XDG_RUNTIME_DIR=/run/user/1019 DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1019/bus LC_NUMERIC=zh_CN.UTF-8 LC_TIME=zh_CN.UTF-8 LC_MONETARY=zh_CN.UTF-8 LC_PAPER=zh_CN.UTF-8 LC_NAME=zh_CN.UTF-8 LC_ADDRESS=zh_CN.UTF-8 LC_TELEPHONE=zh_CN.UTF-8 LC_MEASUREMENT=zh_CN.UTF-8 LC_IDENTIFICATION=zh_CN.UTF-8 SHLVL=1 PWD=/home/yczhong/repos/horovod/examples/pytorch ZSH=/home/yczhong/.oh-my-zsh PAGER=less LESS=-R LSCOLORS=Gxfxcxdxbxegedabagacad LS_COLORS='\"'\"'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:'\"'\"' LD_LIBRARY_PATH=/usr/local/cuda/lib64: CONDA_EXE=/opt/anaconda3/bin/conda _CE_M='\"'\"''\"'\"' _CE_CONDA='\"'\"''\"'\"' CONDA_PYTHON_EXE=/opt/anaconda3/bin/python CONDA_SHLVL=2 CONDA_PREFIX=/opt/anaconda3/envs/ft_hvd CONDA_DEFAULT_ENV=ft_hvd CONDA_PROMPT_MODIFIER='\"'\"'(ft_hvd) '\"'\"' CONDA_PREFIX_1=/opt/anaconda3 _=/opt/anaconda3/envs/ft_hvd/bin/horovodrun PYTHONUNBUFFERED=1 HOROVOD_GLOO_RENDEZVOUS_ADDR=10.28.1.27 HOROVOD_GLOO_RENDEZVOUS_PORT=7738 HOROVOD_CONTROLLER=gloo HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=enp94s0 NCCL_SOCKET_IFNAME=enp94s0 python pytorch_mnist.py'\r\nssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no 10.28.1.28    'cd /home/yczhong/repos/horovod/examples/pytorch > /dev/null 2>&1 ; HOROVOD_HOSTNAME=10.28.1.28 HOROVOD_RANK=5 HOROVOD_SIZE=8 HOROVOD_LOCAL_RANK=1 HOROVOD_LOCAL_SIZE=4 HOROVOD_CROSS_RANK=1 HOROVOD_CROSS_SIZE=2 LANG=en_US.UTF-8 USER=yczhong LOGNAME=yczhong HOME=/home/yczhong PATH=/opt/anaconda3/envs/ft_hvd/bin:/opt/anaconda3/condabin:/usr/local/cuda/bin:/opt/anaconda3/bin:/home/yczhong/.local/bin:/home/yczhong/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games MAIL=/var/mail/yczhong SHELL=/usr/bin/zsh SSH_CLIENT='\"'\"'147.8.179.11 56294 22'\"'\"' SSH_CONNECTION='\"'\"'147.8.179.11 56294 202.45.128.232 22'\"'\"' SSH_TTY=/dev/pts/17 TERM=screen-256color XDG_SESSION_ID=445 XDG_RUNTIME_DIR=/run/user/1019 DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1019/bus LC_NUMERIC=zh_CN.UTF-8 LC_TIME=zh_CN.UTF-8 LC_MONETARY=zh_CN.UTF-8 LC_PAPER=zh_CN.UTF-8 LC_NAME=zh_CN.UTF-8 LC_ADDRESS=zh_CN.UTF-8 LC_TELEPHONE=zh_CN.UTF-8 LC_MEASUREMENT=zh_CN.UTF-8 LC_IDENTIFICATION=zh_CN.UTF-8 SHLVL=1 PWD=/home/yczhong/repos/horovod/examples/pytorch ZSH=/home/yczhong/.oh-my-zsh PAGER=less LESS=-R LSCOLORS=Gxfxcxdxbxegedabagacad LS_COLORS='\"'\"'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:'\"'\"' LD_LIBRARY_PATH=/usr/local/cuda/lib64: CONDA_EXE=/opt/anaconda3/bin/conda _CE_M='\"'\"''\"'\"' _CE_CONDA='\"'\"''\"'\"' CONDA_PYTHON_EXE=/opt/anaconda3/bin/python CONDA_SHLVL=2 CONDA_PREFIX=/opt/anaconda3/envs/ft_hvd CONDA_DEFAULT_ENV=ft_hvd CONDA_PROMPT_MODIFIER='\"'\"'(ft_hvd) '\"'\"' CONDA_PREFIX_1=/opt/anaconda3 _=/opt/anaconda3/envs/ft_hvd/bin/horovodrun PYTHONUNBUFFERED=1 HOROVOD_GLOO_RENDEZVOUS_ADDR=10.28.1.27 HOROVOD_GLOO_RENDEZVOUS_PORT=7738 HOROVOD_CONTROLLER=gloo HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=enp94s0 NCCL_SOCKET_IFNAME=enp94s0 python pytorch_mnist.py'\r\nssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no 10.28.1.28    'cd /home/yczhong/repos/horovod/examples/pytorch > /dev/null 2>&1 ; HOROVOD_HOSTNAME=10.28.1.28 HOROVOD_RANK=6 HOROVOD_SIZE=8 HOROVOD_LOCAL_RANK=2 HOROVOD_LOCAL_SIZE=4 HOROVOD_CROSS_RANK=1 HOROVOD_CROSS_SIZE=2 LANG=en_US.UTF-8 USER=yczhong LOGNAME=yczhong HOME=/home/yczhong PATH=/opt/anaconda3/envs/ft_hvd/bin:/opt/anaconda3/condabin:/usr/local/cuda/bin:/opt/anaconda3/bin:/home/yczhong/.local/bin:/home/yczhong/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games MAIL=/var/mail/yczhong SHELL=/usr/bin/zsh SSH_CLIENT='\"'\"'147.8.179.11 56294 22'\"'\"' SSH_CONNECTION='\"'\"'147.8.179.11 56294 202.45.128.232 22'\"'\"' SSH_TTY=/dev/pts/17 TERM=screen-256color XDG_SESSION_ID=445 XDG_RUNTIME_DIR=/run/user/1019 DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1019/bus LC_NUMERIC=zh_CN.UTF-8 LC_TIME=zh_CN.UTF-8 LC_MONETARY=zh_CN.UTF-8 LC_PAPER=zh_CN.UTF-8 LC_NAME=zh_CN.UTF-8 LC_ADDRESS=zh_CN.UTF-8 LC_TELEPHONE=zh_CN.UTF-8 LC_MEASUREMENT=zh_CN.UTF-8 LC_IDENTIFICATION=zh_CN.UTF-8 SHLVL=1 PWD=/home/yczhong/repos/horovod/examples/pytorch ZSH=/home/yczhong/.oh-my-zsh PAGER=less LESS=-R LSCOLORS=Gxfxcxdxbxegedabagacad LS_COLORS='\"'\"'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:'\"'\"' LD_LIBRARY_PATH=/usr/local/cuda/lib64: CONDA_EXE=/opt/anaconda3/bin/conda _CE_M='\"'\"''\"'\"' _CE_CONDA='\"'\"''\"'\"' CONDA_PYTHON_EXE=/opt/anaconda3/bin/python CONDA_SHLVL=2 CONDA_PREFIX=/opt/anaconda3/envs/ft_hvd CONDA_DEFAULT_ENV=ft_hvd CONDA_PROMPT_MODIFIER='\"'\"'(ft_hvd) '\"'\"' CONDA_PREFIX_1=/opt/anaconda3 _=/opt/anaconda3/envs/ft_hvd/bin/horovodrun PYTHONUNBUFFERED=1 HOROVOD_GLOO_RENDEZVOUS_ADDR=10.28.1.27 HOROVOD_GLOO_RENDEZVOUS_PORT=7738 HOROVOD_CONTROLLER=gloo HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=enp94s0 NCCL_SOCKET_IFNAME=enp94s0 python pytorch_mnist.py'\r\nssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no 10.28.1.28    'cd /home/yczhong/repos/horovod/examples/pytorch > /dev/null 2>&1 ; HOROVOD_HOSTNAME=10.28.1.28 HOROVOD_RANK=7 HOROVOD_SIZE=8 HOROVOD_LOCAL_RANK=3 HOROVOD_LOCAL_SIZE=4 HOROVOD_CROSS_RANK=1 HOROVOD_CROSS_SIZE=2 LANG=en_US.UTF-8 USER=yczhong LOGNAME=yczhong HOME=/home/yczhong PATH=/opt/anaconda3/envs/ft_hvd/bin:/opt/anaconda3/condabin:/usr/local/cuda/bin:/opt/anaconda3/bin:/home/yczhong/.local/bin:/home/yczhong/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games MAIL=/var/mail/yczhong SHELL=/usr/bin/zsh SSH_CLIENT='\"'\"'147.8.179.11 56294 22'\"'\"' SSH_CONNECTION='\"'\"'147.8.179.11 56294 202.45.128.232 22'\"'\"' SSH_TTY=/dev/pts/17 TERM=screen-256color XDG_SESSION_ID=445 XDG_RUNTIME_DIR=/run/user/1019 DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1019/bus LC_NUMERIC=zh_CN.UTF-8 LC_TIME=zh_CN.UTF-8 LC_MONETARY=zh_CN.UTF-8 LC_PAPER=zh_CN.UTF-8 LC_NAME=zh_CN.UTF-8 LC_ADDRESS=zh_CN.UTF-8 LC_TELEPHONE=zh_CN.UTF-8 LC_MEASUREMENT=zh_CN.UTF-8 LC_IDENTIFICATION=zh_CN.UTF-8 SHLVL=1 PWD=/home/yczhong/repos/horovod/examples/pytorch ZSH=/home/yczhong/.oh-my-zsh PAGER=less LESS=-R LSCOLORS=Gxfxcxdxbxegedabagacad LS_COLORS='\"'\"'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:'\"'\"' LD_LIBRARY_PATH=/usr/local/cuda/lib64: CONDA_EXE=/opt/anaconda3/bin/conda _CE_M='\"'\"''\"'\"' _CE_CONDA='\"'\"''\"'\"' CONDA_PYTHON_EXE=/opt/anaconda3/bin/python CONDA_SHLVL=2 CONDA_PREFIX=/opt/anaconda3/envs/ft_hvd CONDA_DEFAULT_ENV=ft_hvd CONDA_PROMPT_MODIFIER='\"'\"'(ft_hvd) '\"'\"' CONDA_PREFIX_1=/opt/anaconda3 _=/opt/anaconda3/envs/ft_hvd/bin/horovodrun PYTHONUNBUFFERED=1 HOROVOD_GLOO_RENDEZVOUS_ADDR=10.28.1.27 HOROVOD_GLOO_RENDEZVOUS_PORT=7738 HOROVOD_CONTROLLER=gloo HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=enp94s0 NCCL_SOCKET_IFNAME=enp94s0 python pytorch_mnist.py'\r\n[5]<stderr>:terminate called after throwing an instance of 'gloo::IoException'\r\n[5]<stderr>:  what():  [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:799] connect [127.0.1.1]:37794: Connection refused\r\n[0]<stderr>:terminate called after throwing an instance of 'gloo::IoException'\r\n[1]<stderr>:terminate called after throwing an instance of 'gloo::IoException'\r\n[1]<stderr>:  what():  [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:799] connect [127.0.1.1]:19354: Connection refused\r\n[0]<stderr>:  what():  [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:799] connect [127.0.1.1]:31660: Connection refused\r\n[3]<stderr>:terminate called after throwing an instance of 'gloo::IoException'\r\n[3]<stderr>:  what():  [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:799] connect [127.0.1.1]:29072: Connection refused\r\nProcess 5 exit with status code 255.\r\nTerminating remaining workers after failure of Process 5.\r\n[0]<stderr>:Aborted (core dumped)\r\nProcess 0 exit with status code 134.\r\n[2]<stderr>:Terminated\r\n[1]<stderr>:Aborted (core dumped)\r\nProcess 1 exit with status code 134.\r\nProcess 2 exit with status code 143.\r\n[3]<stderr>:Aborted (core dumped)\r\nProcess 3 exit with status code 134.\r\nTraceback (most recent call last):\r\n  File \"/opt/anaconda3/envs/ft_hvd/bin/horovodrun\", line 33, in <module>\r\n    sys.exit(load_entry_point('horovod', 'console_scripts', 'horovodrun')())\r\n  File \"/home/yczhong/repos/horovod/horovod/runner/launch.py\", line 770, in run_commandline\r\n    _run(args)\r\n  File \"/home/yczhong/repos/horovod/horovod/runner/launch.py\", line 760, in _run\r\n    return _run_static(args)\r\n  File \"/home/yczhong/repos/horovod/horovod/runner/launch.py\", line 617, in _run_static\r\n    _launch_job(args, settings, nics, command)\r\n  File \"/home/yczhong/repos/horovod/horovod/runner/launch.py\", line 733, in _launch_job\r\n    args.verbose)\r\n  File \"/home/yczhong/repos/horovod/horovod/runner/launch.py\", line 706, in run_controller\r\n    gloo_run()\r\n  File \"/home/yczhong/repos/horovod/horovod/runner/launch.py\", line 722, in gloo_run_fn\r\n    gloo_run(settings, nics, env, driver_ip, command)\r\n  File \"/home/yczhong/repos/horovod/horovod/runner/gloo_run.py\", line 298, in gloo_run\r\n    launch_gloo(command, exec_command, settings, nics, env, server_ip)\r\n  File \"/home/yczhong/repos/horovod/horovod/runner/gloo_run.py\", line 285, in launch_gloo\r\n    .format(name=name, code=exit_code))\r\nRuntimeError: Horovod detected that one or more processes exited with non-zero status, thus causing the job to be terminated. The first process to do so was:\r\nProcess name: 5\r\nExit code: 255\r\n```\r\n\r\nHowever, with Horovod from the official pypi, I did not encounter the problem. \r\n```sh\r\nHOROVOD_WITHOUT_MPI=1 HOROVOD_WITH_GLOO=1  HOROVOD_NCCL_HOME=/usr/local/nccl HOROVOD_GPU_OPERATIONS=NCCL pip install --no-cache-dir horovod\r\n```\r\n\r\nIt seems that it is because of `core dumped`. But training locally works. ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3118/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3118/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3111", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3111/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3111/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3111/events", "html_url": "https://github.com/horovod/horovod/issues/3111", "id": 971749228, "node_id": "MDU6SXNzdWU5NzE3NDkyMjg=", "number": 3111, "title": "nccl error handling in elastic scenario is buggy", "user": {"login": "woodlgz", "id": 4121240, "node_id": "MDQ6VXNlcjQxMjEyNDA=", "avatar_url": "https://avatars.githubusercontent.com/u/4121240?v=4", "gravatar_id": "", "url": "https://api.github.com/users/woodlgz", "html_url": "https://github.com/woodlgz", "followers_url": "https://api.github.com/users/woodlgz/followers", "following_url": "https://api.github.com/users/woodlgz/following{/other_user}", "gists_url": "https://api.github.com/users/woodlgz/gists{/gist_id}", "starred_url": "https://api.github.com/users/woodlgz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/woodlgz/subscriptions", "organizations_url": "https://api.github.com/users/woodlgz/orgs", "repos_url": "https://api.github.com/users/woodlgz/repos", "events_url": "https://api.github.com/users/woodlgz/events{/privacy}", "received_events_url": "https://api.github.com/users/woodlgz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-08-16T13:37:53Z", "updated_at": "2021-10-23T18:27:49Z", "closed_at": "2021-10-23T18:27:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): Pytorch\r\n2. Framework version: 1.7.0\r\n3. Horovod version: 0.22.1\r\n4. MPI version: 4.0.3\r\n5. CUDA version: 10.2\r\n6. NCCL version: 2.9.6\r\n7. Python version: 3.6\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nwhen nccl communication is enabled in horovod, in elastic scenario, evicting a worker instance may cause nccl communicator abort from other workers.\r\n\r\nspecifically, there existed 3 problems in this scenario:\r\n1. gpu operations event error check (from a thread-pool thread) just throws away exceptions that will never be handled in which case the program aborts. this behaviour simply goes against elastic horovod's will.\r\n2. in the shadow of problem 1, background loop shutting-down and cleaning nccl resources by calling ncclCommDestroy (when controller detects a shutdown condition, for instance, peers exit) may get into race condition with thread pool error check in which ncclCommAbort will be called, potentially causing a double-free corruption.\r\n3. in elastic eviction scenario, a program of a particular rank somehow failed to detect its nccl communicator broken, is prone to hang reporting 100% gpu utilization.\r\n\r\none can reproduce this issue by using elastic example pytorch_synthetic_benchmark_elastic.py.\r\nIn my setup, I launched 2 workers each with 2 gpu thus yielding 4 slots in total and killed one rank in the middle of the training. For a lot of time, doing so will cause some of the rest 3 ranks to corrupt and others hang with gpu 100% utilization.\r\nlog similar to following can be retrieved. \r\n```\r\nINFO:root:record state: ts-a2e9e55167624c36a999c60507804f01-worker-0.titan-test.svc.cluster.local[1] = FAILURE\r\nProcess 1 exit with status code 137.\r\nWed Aug 18 10:51:34 2021[2]<stderr>:[2021-08-18 10:51:34.286842: E /data/guozelin/test-horovod/old/horovod-0.22.1/horovod/common/operations.cc:634] [2]: Horovod background loop uncaught exception: [/pytorch/third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:84] Timed out waiting 30000ms for recv operation to complete\r\nWed Aug 18 10:51:34 2021[2]<stderr>:*** Error in `python3': double free or corruption (out): 0x00007fce170a1100 ***\r\nWed Aug 18 10:51:34 2021[2]<stderr>:======= Backtrace: =========\r\nWed Aug 18 10:51:34 2021[2]<stderr>:/usr/lib64/libc.so.6(+0x7c619)[0x7fcf8e509619]\r\nWed Aug 18 10:51:34 2021[2]<stderr>:/usr/local/nccl_2.9.6-1+cuda11.0_x86_64/lib/libnccl.so.2(+0x31b6c)[0x7fce21b28b6c]\r\nWed Aug 18 10:51:34 2021[2]<stderr>:/usr/local/nccl_2.9.6-1+cuda11.0_x86_64/lib/libnccl.so.2(ncclCommDestroy+0x82)[0x7fce21b2ef42]\r\nWed Aug 18 10:51:34 2021[3]<stderr>:[2021-08-18 10:51:34.287533: E /apdcephfs/private_guozelin/test-horovod/old/horovod-0.22.1/horovod/common/operations.cc:634] [3]: Horovod background loop uncaught exception: [/pytorch/third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:84] Timed out waiting 30000ms for recv operation to complete\r\nWed Aug 18 10:51:34 2021[2]<stderr>:/usr/local/lib64/python3.6/site-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common11NCCLContext8ShutDownEv+0x41)[0x7fcedf450e51]\r\nWed Aug 18 10:51:34 2021[2]<stderr>:/usr/local/lib64/python3.6/site-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so(+0x94d93)[0x7fcedf3ddd93]\r\nWed Aug 18 10:51:34 2021[2]<stderr>:/usr/lib64/libstdc++.so.6(+0xba1bf)[0x7fcf82c4f1bf]\r\nWed Aug 18 10:51:34 2021[2]<stderr>:/usr/lib64/libpthread.so.0(+0x7e25)[0x7fcf8ef61e25]\r\nWed Aug 18 10:51:34 2021[2]<stderr>:/usr/lib64/libc.so.6(clone+0x6d)[0x7fcf8e58535d]\r\n```\r\nIn some cases where a coredump does not happen, a NCCL async error may instead be reported from some of the rest 3 ranks and others reporting 100% gpu utilization.\r\n```\r\nINFO:root:record state: ts-a2e9e55167624c36a999c60507804f01-worker-0.titan-test.svc.cluster.local[1] = FAILURE\r\nProcess 3 exit with status code 137.\r\nWed Aug 18 11:35:36 2021[0]<stderr>:terminate called after throwing an instance of 'std::logic_error'\r\nWed Aug 18 11:35:36 2021[0]<stderr>:  what():  NCCL async error: unhandled system error\r\nWed Aug 18 11:35:38 2021[1]<stderr>:[2021-08-18 11:35:38.692416: E /apdcephfs/private_guozelin/test-horovod/old/horovod-0.22.1/horovod/common/operations.cc:634] [1]: Horovod background loop uncaught exception: [/pytorch/third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:84] Timed out waiting 30000ms for recv operation to complete\r\nINFO:root:record state: ts-a2e9e55167624c36a999c60507804f01-launcher.titan-test.svc.cluster.local[0] = FAILURE\r\nProcess 0 exit with status code 134.\r\n```\r\nto reproduce the NCCL async error and abort with error code 134, one can manually add some latency in background thread loop before nccl_context.Shutdown()\r\n```c++\r\n#if HAVE_NCCL\r\n  using namespace std::chrono_literals;\r\n  std::this_thread::sleep_for(60s);\r\n  nccl_context.ShutDown();\r\n#endif\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3111/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3111/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3109", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3109/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3109/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3109/events", "html_url": "https://github.com/horovod/horovod/issues/3109", "id": 971729603, "node_id": "MDU6SXNzdWU5NzE3Mjk2MDM=", "number": 3109, "title": "\u3010Elastic Horovod\u3011torch op handles is not recollect right away as new elastic loop begins", "user": {"login": "woodlgz", "id": 4121240, "node_id": "MDQ6VXNlcjQxMjEyNDA=", "avatar_url": "https://avatars.githubusercontent.com/u/4121240?v=4", "gravatar_id": "", "url": "https://api.github.com/users/woodlgz", "html_url": "https://github.com/woodlgz", "followers_url": "https://api.github.com/users/woodlgz/followers", "following_url": "https://api.github.com/users/woodlgz/following{/other_user}", "gists_url": "https://api.github.com/users/woodlgz/gists{/gist_id}", "starred_url": "https://api.github.com/users/woodlgz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/woodlgz/subscriptions", "organizations_url": "https://api.github.com/users/woodlgz/orgs", "repos_url": "https://api.github.com/users/woodlgz/repos", "events_url": "https://api.github.com/users/woodlgz/events{/privacy}", "received_events_url": "https://api.github.com/users/woodlgz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-08-16T13:17:26Z", "updated_at": "2021-09-02T16:18:32Z", "closed_at": "2021-09-02T16:18:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Environment:\r\n\r\nFramework: (TensorFlow, Keras, PyTorch, MXNet): Pytorch\r\nFramework version: 1.6.0\r\nHorovod version: 0.21.3\r\nMPI version: 4.0.3\r\nCUDA version: 10.2\r\nNCCL version: 2.7.6\r\nPython version: 3.6\r\nChecklist:\r\n\r\nDid you search issues to find if somebody asked this question before? Yes.\r\nIf your question is about hang, did you read this doc?\r\nIf your question is about docker, did you read this doc?\r\nDid you check if you question is answered in the [troubleshooting guide] (https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Bug report:**\r\nhorovod torch currently use a dict to hold references to horovod operation results and release such reference in synchronize function.\r\n\r\n```python\r\ndef synchronize(handle):\r\n    if handle not in _handle_map:\r\n        return\r\n    try:\r\n        mpi_lib.horovod_torch_wait_and_clear(handle)\r\n        output = _handle_map.pop(handle)[-1]\r\n        return output\r\n    except RuntimeError as e:\r\n        raise HorovodInternalError(e)\r\n```\r\nthis code, however, does not releases the handle when exception occurs.as a result, in elastic scenario, handle references may still be retained in the dict for some time in new training loop, and will not be released until the handle counter reaches the same point again. this may be a problem when memory/gpumem is heavily used, prone to oom.\r\n\r\nI am going to submit a pr to fix this.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3109/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3109/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3082", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3082/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3082/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3082/events", "html_url": "https://github.com/horovod/horovod/issues/3082", "id": 962219819, "node_id": "MDU6SXNzdWU5NjIyMTk4MTk=", "number": 3082, "title": "Lightning Estimator: Runtime error from petastorm", "user": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2021-08-05T21:45:38Z", "updated_at": "2021-08-17T18:49:22Z", "closed_at": "2021-08-17T18:49:22Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: pytorch lighting 1.2.9; pytorch 1.8.1\r\n3. Horovod version: master branch\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version: 3.7.10\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version:OSX Big Sur\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Bug report:**\r\nReprdocer:\r\n```\r\npython pytorch_lightning_spark_mnist.py --num-proc 2 --epochs 1 --batch-size 1024\r\n```\r\n\r\nError:\r\n```\r\nThu Aug  5 14:38:47 2021[0]<stderr>:  row_as_dict[k] = self.transform_fn(v)\r\nThu Aug  5 14:38:54 2021[0]<stderr>:Iteration on Petastorm DataLoader raise error: RuntimeError('Trying to read a sample after a reader created by make_reader/make_batch_reader has stopped. This may happen if the make_reader/make_batch_reader context manager has exited but you try to fetch a sample from it anyway')\r\n```\r\n\r\nPossible reason: async dataloader kills/deletes petastorm reader before joining worker thread, which is still loading data from reader.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3082/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3082/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3077", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3077/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3077/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3077/events", "html_url": "https://github.com/horovod/horovod/issues/3077", "id": 960197214, "node_id": "MDU6SXNzdWU5NjAxOTcyMTQ=", "number": 3077, "title": "Multi optimizers with overlapping parameters", "user": {"login": "ProHuper", "id": 21972658, "node_id": "MDQ6VXNlcjIxOTcyNjU4", "avatar_url": "https://avatars.githubusercontent.com/u/21972658?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ProHuper", "html_url": "https://github.com/ProHuper", "followers_url": "https://api.github.com/users/ProHuper/followers", "following_url": "https://api.github.com/users/ProHuper/following{/other_user}", "gists_url": "https://api.github.com/users/ProHuper/gists{/gist_id}", "starred_url": "https://api.github.com/users/ProHuper/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ProHuper/subscriptions", "organizations_url": "https://api.github.com/users/ProHuper/orgs", "repos_url": "https://api.github.com/users/ProHuper/repos", "events_url": "https://api.github.com/users/ProHuper/events{/privacy}", "received_events_url": "https://api.github.com/users/ProHuper/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-08-04T10:12:38Z", "updated_at": "2021-08-06T02:42:38Z", "closed_at": "2021-08-06T02:42:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, here's the problem:\r\n\r\nI created 3 optimizers, in which opt has all parameters of the model, opt_s1 and opt_s2 only have partial parameters of the model\r\n```python\r\nopt = optim.Adam(net.parameters(), lr=args.lr)\r\nopt_s1 = optim.Adam(net.stage1_params(), lr=args.lr)\r\nopt_s2 = optim.Adam(net.stage2_params(), lr=args.lr)\r\n```\r\n\r\nI will use different optimizers in different epochs like this:\r\n```python\r\nif epoch == 1:\r\n    opt_s1.step()\r\nelif epoch == 2:\r\n    opt_s2.step()\r\nelse:\r\n    opt.step()\r\n```\r\n\r\nbut this will trigger duplicated parameter names Errors when broadcasting the optimizers since they have overlapping parameters:\r\n\r\n```python\r\nopt = hvd.DistributedOptimizer(opt, named_parameters=net.named_parameters())\r\nopt_s1 = hvd.DistributedOptimizer(opt_s1, named_parameters=net.stage1_named_params())\r\nopt_s2 = hvd.DistributedOptimizer(opt_s2, named_parameters=net.stage2_named_params())\r\n\r\nhvd.broadcast_parameters(opt, root_rank=0)\r\nhvd.broadcast_parameters(opt_s1, root_rank=0)\r\nhvd.broadcast_parameters(opt_s2, root_rank=0)\r\n```\r\n\r\nI solved this problem by adding prefix option when constructing named_parameters:\r\n```python\r\nopt = hvd.DistributedOptimizer(opt, named_parameters=net.named_parameters(prefix='all'))\r\nopt_s1 = hvd.DistributedOptimizer(opt_s1, named_parameters=net.stage1_named_params(prefix='s1'))\r\nopt_s2 = hvd.DistributedOptimizer(opt_s2, named_parameters=net.stage2_named_params(prefix='s2'))\r\n```\r\nBut this caused another Error:\r\n```\r\nGradients were computed more than backward_passes_per_step times before call to step().\r\n```\r\nSeems that horovod is monitoring those optimizers who didn't call step() after backward(), but I don't want to increase the backward_passes_per_step option. \r\nI tried this trick on the optimizer, which doesn't need to step() in the current iteration :\r\n\r\n```python\r\nopt_s2.zero_grad()\r\nopt_s2.step()\r\n```\r\n\r\nAgain, this caused:\r\n```\r\nAssertionError: optimizer.zero_grad() was called after loss.backward() but before optimizer.step() or optimizer.synchronize(). This is prohibited as it can cause a race condition.\r\n```\r\n\r\nIs there any method to solve this? Or overlapping optimizers is just forbidden in horovod?\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3077/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3077/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3058", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3058/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3058/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3058/events", "html_url": "https://github.com/horovod/horovod/issues/3058", "id": 954769994, "node_id": "MDU6SXNzdWU5NTQ3Njk5OTQ=", "number": 3058, "title": "examples/tensorflow2/tensorflow2_keras_synthetic_benchmark.py run error", "user": {"login": "gongjingcs", "id": 15030497, "node_id": "MDQ6VXNlcjE1MDMwNDk3", "avatar_url": "https://avatars.githubusercontent.com/u/15030497?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gongjingcs", "html_url": "https://github.com/gongjingcs", "followers_url": "https://api.github.com/users/gongjingcs/followers", "following_url": "https://api.github.com/users/gongjingcs/following{/other_user}", "gists_url": "https://api.github.com/users/gongjingcs/gists{/gist_id}", "starred_url": "https://api.github.com/users/gongjingcs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gongjingcs/subscriptions", "organizations_url": "https://api.github.com/users/gongjingcs/orgs", "repos_url": "https://api.github.com/users/gongjingcs/repos", "events_url": "https://api.github.com/users/gongjingcs/events{/privacy}", "received_events_url": "https://api.github.com/users/gongjingcs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-07-28T11:44:40Z", "updated_at": "2021-09-16T05:11:44Z", "closed_at": "2021-09-16T05:11:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "tf:2.4\r\n /usr/local/lib/python3.8/dist-packages/horovod/_keras/__init__.py:73 apply_gradients\r\n        raise Exception('`apply_gradients()` was called without a call to '\r\n\r\n    Exception: `apply_gradients()` was called without a call to `get_gradients()` or `_aggregate_gradients`. If you're using TensorFlow 2.0, please specify `experimental_run_tf_function=False` in `compile()`.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3058/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3058/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3027", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3027/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3027/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3027/events", "html_url": "https://github.com/horovod/horovod/issues/3027", "id": 939587178, "node_id": "MDU6SXNzdWU5Mzk1ODcxNzg=", "number": 3027, "title": "CMake Error in horovod/torch/CMakeLists.txt:     Target \"pytorch\" requires the language dialect \"CXX14\" , but CMake does not     know the compile flags to use to enable it.", "user": {"login": "Junzh821", "id": 31005549, "node_id": "MDQ6VXNlcjMxMDA1NTQ5", "avatar_url": "https://avatars.githubusercontent.com/u/31005549?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Junzh821", "html_url": "https://github.com/Junzh821", "followers_url": "https://api.github.com/users/Junzh821/followers", "following_url": "https://api.github.com/users/Junzh821/following{/other_user}", "gists_url": "https://api.github.com/users/Junzh821/gists{/gist_id}", "starred_url": "https://api.github.com/users/Junzh821/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Junzh821/subscriptions", "organizations_url": "https://api.github.com/users/Junzh821/orgs", "repos_url": "https://api.github.com/users/Junzh821/repos", "events_url": "https://api.github.com/users/Junzh821/events{/privacy}", "received_events_url": "https://api.github.com/users/Junzh821/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-07-08T08:03:34Z", "updated_at": "2021-08-03T10:13:52Z", "closed_at": "2021-08-03T10:13:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (PyTorch,)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version:\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n\r\n\r\n-- Configuring done\r\n  CMake Error in horovod/torch/CMakeLists.txt:\r\n    Target \"pytorch\" requires the language dialect \"CXX14\" , but CMake does not\r\n    know the compile flags to use to enable it.\r\n  \r\n  \r\n  -- Generating done\r\n  CMake Generate step failed.  Build files cannot be regenerated correctly.\r\n  Traceback (most recent call last):\r\n    File \"<string>\", line 1, in <module>\r\n    File \"/tmp/pip-install-3j8y4qov/horovod_155b0d6aeac74d1899be1b6ff9cb8742/setup.py\", line 199, in <module>\r\n      'horovodrun = horovod.runner.launch:run_commandline'\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/site-packages/setuptools/__init__.py\", line 163, in setup\r\n      return distutils.core.setup(**attrs)\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/distutils/core.py\", line 148, in setup\r\n      dist.run_commands()\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n      self.run_command(cmd)\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/site-packages/wheel/bdist_wheel.py\", line 299, in run\r\n      self.run_command('build')\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/distutils/command/build.py\", line 135, in run\r\n      self.run_command(cmd_name)\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/site-packages/setuptools/command/build_ext.py\", line 87, in run\r\n      _build_ext.run(self)\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/distutils/command/build_ext.py\", line 340, in run\r\n      self.build_extensions()\r\n    File \"/tmp/pip-install-3j8y4qov/horovod_155b0d6aeac74d1899be1b6ff9cb8742/setup.py\", line 95, in build_extensions\r\n      cwd=cmake_build_dir)\r\n    File \"/home/xx/.conda/envs/dalle_test/lib/python3.7/subprocess.py\", line 363, in check_call\r\n      raise CalledProcessError(retcode, cmd)\r\n  subprocess.CalledProcessError: Command '['cmake', '/tmp/pip-install-3j8y4qov/horovod_155b0d6aeac74d1899be1b6ff9cb8742', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/tmp/pip-install-3j8y4qov/horovod_155b0d6aeac74d1899be1b6ff9cb8742/build/lib.linux-x86_64-3.7', '-DPYTHON_EXECUTABLE:FILEPATH=/home/xx/.conda/envs/dalle_test/bin/python3.7']' returned non-zero exit status 1.\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3027/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3027/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3014", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3014/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3014/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3014/events", "html_url": "https://github.com/horovod/horovod/issues/3014", "id": 936427672, "node_id": "MDU6SXNzdWU5MzY0Mjc2NzI=", "number": 3014, "title": "\u3010ELASTIC HOROVOD\u3011It perhaps some  deadlock when all workers are recorded.", "user": {"login": "ezioliao", "id": 49278241, "node_id": "MDQ6VXNlcjQ5Mjc4MjQx", "avatar_url": "https://avatars.githubusercontent.com/u/49278241?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezioliao", "html_url": "https://github.com/ezioliao", "followers_url": "https://api.github.com/users/ezioliao/followers", "following_url": "https://api.github.com/users/ezioliao/following{/other_user}", "gists_url": "https://api.github.com/users/ezioliao/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezioliao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezioliao/subscriptions", "organizations_url": "https://api.github.com/users/ezioliao/orgs", "repos_url": "https://api.github.com/users/ezioliao/repos", "events_url": "https://api.github.com/users/ezioliao/events{/privacy}", "received_events_url": "https://api.github.com/users/ezioliao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-07-04T10:38:57Z", "updated_at": "2021-08-06T14:42:50Z", "closed_at": "2021-08-06T14:42:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): Pytorch\r\n2. Framework version: 1.6.0\r\n3. Horovod version: 0.21.3\r\n4. MPI version: 4.0.3\r\n5. CUDA version: 10.2\r\n6. NCCL version: 2.7.6\r\n7. Python version: 3.6\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes.\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide]  (https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Bug report:**\r\nAfter all workers have report their status, the driver will execute the `_on_workers_recorded` function which get and update host slot info and activate workers if necessary. The workers wait until the `_on_workers_recorded` function is completed.  When executing `_on_workers_recorded` function, if one READY worker becomes FAILED\uff0cthe deadlock will caused.(e.g. `_on_workers_recorded` call host discovery script that maybe consume seconds and one ready worker failed during this time). \r\n\r\nThe deadlock details as follows:\r\n1. If one ready worker(we call it `worker-A`) become failed during `_on_workers_recorded`, it will result in `_barrier.reset()` and holds  the `self._lock`, relevant code at [here](https://github.com/horovod/horovod/blob/1a0a6f2c5ec536c44fd5292875064b65545de6e0/horovod/runner/elastic/registration.py#L98). So it hang in `_barrier.reset()` until `_on_workers_recorded` function finish.\r\n\r\n2. But `_on_workers_recorded` function also try to acquire `self._lock` which already held by `worker-A` at [self.reset](https://github.com/horovod/horovod/blob/1a0a6f2c5ec536c44fd5292875064b65545de6e0/horovod/runner/elastic/registration.py#L52).  Deadlock occurs!\r\n\r\n**Steps to reproduce.**\r\n1. In order to easily reproduce the problem, we sleep 15s  at `wait_for_available_slots` in `horovod/runner/elastic/driver.py` file (It simulates the case that host discovery script consume a few seconds):\r\n```\r\n...\r\n    def wait_for_available_slots(self, min_np, min_hosts=1):\r\n        print(f\"wait_for_available_slots sleep 15s\")\r\n        time.sleep(15)\r\n\r\n        extra_message = ' An elastic job also requires that at least two hosts ' \\\r\n                        'are available to resolve compatible network interfaces. If you know which interfaces ' \\\r\n                        'are compatible in your network, set `--network-interface` to skip this check.' \\\r\n            if min_hosts > 1 else ''\r\n...\r\n```\r\n\r\n2. Run elastic horovod:\r\n```\r\nhorovodrun -np 1 --host-discovery-script ./discovery_hosts.sh --network-interface eth1 --min-np 1 --log-level DEBUG --verbose  python3 pytorch_synthetic_benchmark_elastic.py --num-iters=1000\r\n```\r\n\r\n3. After some iteration passed, we add a new worker in host-discovery-script to raise `HostsUpdatedInterrupt`. The driver will record all workers as ready and call  `_activate_workers` to new a worker and go to `wait_for_available_slots`, finally sleeping 15s in `wait_for_available_slots`.\r\n\r\n4. We immediately  kill one worker and the driver updates this worker as failed. Driver blocks in `_barrier.reset()`, holding the `self._lock`.\r\n\r\n5. After 15s, `_activate_workers` call `_worker_registry.reset()` to  acquire `_lock` which already is held. Deadlock! \r\n\r\n**Solution.**\r\nI think this issue is completely caused by worker updates during `_on_workers_recorded`.  Maybe should we prohibit any worker updates in `_on_workers_recorded` function? If any worker updated during this time,  we delay this to next rendezvous.  ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3014/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3014/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/3012", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/3012/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/3012/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/3012/events", "html_url": "https://github.com/horovod/horovod/issues/3012", "id": 933476670, "node_id": "MDU6SXNzdWU5MzM0NzY2NzA=", "number": 3012, "title": "Different Time Recorded for Allreduce Operation", "user": {"login": "dexhunter", "id": 6930518, "node_id": "MDQ6VXNlcjY5MzA1MTg=", "avatar_url": "https://avatars.githubusercontent.com/u/6930518?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dexhunter", "html_url": "https://github.com/dexhunter", "followers_url": "https://api.github.com/users/dexhunter/followers", "following_url": "https://api.github.com/users/dexhunter/following{/other_user}", "gists_url": "https://api.github.com/users/dexhunter/gists{/gist_id}", "starred_url": "https://api.github.com/users/dexhunter/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dexhunter/subscriptions", "organizations_url": "https://api.github.com/users/dexhunter/orgs", "repos_url": "https://api.github.com/users/dexhunter/repos", "events_url": "https://api.github.com/users/dexhunter/events{/privacy}", "received_events_url": "https://api.github.com/users/dexhunter/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2021-06-30T09:12:25Z", "updated_at": "2021-08-02T12:03:45Z", "closed_at": "2021-08-02T12:03:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Pytorch\r\n2. Framework version:  1.7.1\r\n3. Horovod version:  0.22.0\r\n4. MPI version: 4.0.1\r\n5. CUDA version: 10.1\r\n6. NCCL version: 2.6.4\r\n7. Python version: 3.7.10\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version: ubuntu \r\n11. GCC version: 5.4.0\r\n12. CMake version: \r\n\r\n\r\n**Bug report:**\r\n\r\nI use a simple script to record the elapsed time for allreduce op but I am getting different elapsed time from `torch.cuda.Event(enable_timing=True)` and the built-in timeline of horovod. \r\n\r\nMy script\r\n```python\r\nimport torch\r\nimport horovod.torch as hvd\r\nimport numpy as np\r\n\r\nhvd.init()\r\ntorch.cuda.set_device(hvd.local_rank())\r\n\r\nstart = torch.cuda.Event(enable_timing=True)\r\nend = torch.cuda.Event(enable_timing=True)\r\ntensor_size = 2**28\r\nx = torch.randn(tensor_size, dtype=torch.float).cuda()\r\n\r\n# allreduce op\r\nstart.record()\r\nreduced = hvd.allreduce(x, average=False)\r\nend.record()\r\n\r\ntorch.cuda.synchronize()\r\n\r\nelapsed_time=start.elapsed_time(end)\r\n```\r\n\r\nHowever, when I print out the result, there is always a gap between what torch records and the time on the timeline. I am just wondering which one will be more accurate? Thanks!\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/3012/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/3012/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2998", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2998/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2998/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2998/events", "html_url": "https://github.com/horovod/horovod/issues/2998", "id": 930523784, "node_id": "MDU6SXNzdWU5MzA1MjM3ODQ=", "number": 2998, "title": "  Imported target \"MPI::MPI_CXX\" includes non-existent path", "user": {"login": "Yiltan", "id": 9093579, "node_id": "MDQ6VXNlcjkwOTM1Nzk=", "avatar_url": "https://avatars.githubusercontent.com/u/9093579?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Yiltan", "html_url": "https://github.com/Yiltan", "followers_url": "https://api.github.com/users/Yiltan/followers", "following_url": "https://api.github.com/users/Yiltan/following{/other_user}", "gists_url": "https://api.github.com/users/Yiltan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Yiltan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Yiltan/subscriptions", "organizations_url": "https://api.github.com/users/Yiltan/orgs", "repos_url": "https://api.github.com/users/Yiltan/repos", "events_url": "https://api.github.com/users/Yiltan/events{/privacy}", "received_events_url": "https://api.github.com/users/Yiltan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-06-25T21:50:13Z", "updated_at": "2021-07-02T22:39:50Z", "closed_at": "2021-07-02T22:39:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nI am having some issues installing horovod with MPI, would anybody be able to give any suggestions? I have attached my setup below.\r\n\r\nThanks,\r\nYiltan\r\n\r\n**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.15.2\r\n3. Horovod version: v0.20.3\r\n4. MPI version: MVAPICH2-GDR\r\n5. CUDA version: 10.1.2436. NCCL version: n/a\r\n7. Python version: 3.7\r\n8. Spark / PySpark version: n/a\r\n9. Ray version: n/a\r\n10. OS and version: Red Hat \r\n11. GCC version: 8.4.0\r\n12. CMake version: 3.16.3\r\n\r\n**Install Script**\r\n\r\n```\r\nIBM_REPO=\"https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/\"\r\n\r\n# Create the enviroment\r\nconda create -y python=3.7 --prefix=$(pwd)/.conda/envs/horovod_tf/\r\neval \"$(conda shell.bash hook)\"\r\nconda activate .conda/envs/horovod_tf/\r\nconda install -y -c $IBM_REPO tensorflow-gpu==1.15.2 keras Pillow\r\n\r\n\r\n# Horovod variables\r\nexport HOROVOD_WITH_TENSORFLOW=1\r\nexport HOROVOD_WITHOUT_PYTORCH=1\r\nexport HOROVOD_WITHOUT_MXNET=1\r\nexport HOROVOD_WITHOUT_GLOO=1\r\nexport HOROVOD_CUDA_HOME=$CUDA_HOME\r\nexport HOROVOD_GPU_OPERATIONS=MPI\r\nexport HOROVOD_WITH_MPI=1\r\n\r\ncd packages/horovod\r\npython setup.py install\r\n```\r\n\r\n**Output**\r\n\r\n```running clean\r\nremoving 'build/temp.linux-ppc64le-3.7' (and everything under it)\r\nrunning install\r\nrunning bdist_egg\r\nrunning egg_info\r\nwriting horovod.egg-info/PKG-INFO\r\nwriting dependency_links to horovod.egg-info/dependency_links.txt\r\nwriting entry points to horovod.egg-info/entry_points.txt\r\nwriting requirements to horovod.egg-info/requires.txt\r\nwriting top-level names to horovod.egg-info/top_level.txt\r\nreading manifest file 'horovod.egg-info/SOURCES.txt'\r\nreading manifest template 'MANIFEST.in'\r\nno previously-included directories found matching '.eggs'\r\nwarning: no previously-included files found matching 'third_party/eigen/Eigen/src/IterativeSolvers/*'\r\nwarning: no previously-included files found matching 'third_party/eigen/unsupported/Eigen/FFT'\r\nwarning: no previously-included files found matching 'third_party/eigen/unsupported/Eigen/MPRealSupport'\r\nwarning: no previously-included files found matching 'third_party/eigen/doc/PreprocessorDirectives.dox'\r\nwarning: no previously-included files found matching 'third_party/eigen/doc/UsingIntelMKL.dox'\r\nwarning: no previously-included files found matching 'third_party/eigen/doc/SparseLinearSystems.dox'\r\nwarning: no previously-included files found matching 'third_party/eigen/COPYING.GPL'\r\nwarning: no previously-included files found matching 'third_party/eigen/COPYING.LGPL'\r\nwarning: no previously-included files found matching 'third_party/eigen/COPYING.README'\r\nwriting manifest file 'horovod.egg-info/SOURCES.txt'\r\ninstalling library code to build/bdist.linux-ppc64le/egg\r\nrunning install_lib\r\nrunning build_py\r\nrunning build_ext\r\n-- Could not find CCache. Consider installing CCache to speed up compilation.\r\n-- The CXX compiler identification is GNU 9.3.0\r\n-- Check for working CXX compiler: /opt/base/gcc/9.3.0/bin/g++\r\n-- Check for working CXX compiler: /opt/base/gcc/9.3.0/bin/g++ -- works\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\n-- Build architecture flags: \r\n-- Using command /project/.conda/envs/horovod_tf/bin/python\r\nCMake Error in /project/packages/horovod/build/temp.linux-ppc64le-3.7/CMakeFiles/CMakeTmp/CMakeLists.txt:\r\n  Imported target \"MPI::MPI_CXX\" includes non-existent path\r\n\r\n    \"/usr/tce/packages/cuda/cuda-10.1.243/include\"\r\n\r\n  in its INTERFACE_INCLUDE_DIRECTORIES.  Possible reasons include:\r\n\r\n  * The path was deleted, renamed, or moved to another location.\r\n\r\n  * An install or uninstall procedure did not complete successfully.\r\n\r\n  * The installation package was faulty and references files it does not\r\n  provide.\r\n\r\n\r\n\r\nCMake Error in /project/packages/horovod/build/temp.linux-ppc64le-3.7/CMakeFiles/CMakeTmp/CMakeLists.txt:\r\n  Imported target \"MPI::MPI_CXX\" includes non-existent path\r\n\r\n    \"/usr/tce/packages/cuda/cuda-10.1.243/include\"\r\n\r\n  in its INTERFACE_INCLUDE_DIRECTORIES.  Possible reasons include:\r\n\r\n  * The path was deleted, renamed, or moved to another location.\r\n\r\n  * An install or uninstall procedure did not complete successfully.\r\n\r\n  * The installation package was faulty and references files it does not\r\n  provide.\r\n\r\n\r\n\r\nCMake Error at /opt/base/cmake/3.16.3/share/cmake-3.16/Modules/FindMPI.cmake:1194 (try_compile):\r\n  Failed to generate test project build system.\r\nCall Stack (most recent call first):\r\n  /opt/base/cmake/3.16.3/share/cmake-3.16/Modules/FindMPI.cmake:1245 (_MPI_try_staged_settings)\r\n  /opt/base/cmake/3.16.3/share/cmake-3.16/Modules/FindMPI.cmake:1505 (_MPI_check_lang_works)\r\n  CMakeLists.txt:131 (find_package)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/project/packages/horovod/build/temp.linux-ppc64le-3.7/CMakeFiles/CMakeOutput.log\".\r\nTraceback (most recent call last):\r\n  File \"setup.py\", line 193, in <module>\r\n    'horovodrun = horovod.runner.launch:run_commandline'\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/site-packages/setuptools/__init__.py\", line 153, in setup\r\n    return distutils.core.setup(**attrs)\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/distutils/core.py\", line 148, in setup\r\n    dist.run_commands()\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n    self.run_command(cmd)\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/site-packages/setuptools/command/install.py\", line 67, in run\r\n    self.do_egg_install()\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/site-packages/setuptools/command/install.py\", line 109, in do_egg_install\r\n    self.run_command('bdist_egg')\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/site-packages/setuptools/command/bdist_egg.py\", line 164, in run\r\n    cmd = self.call_command('install_lib', warn_dir=0)\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/site-packages/setuptools/command/bdist_egg.py\", line 150, in call_command\r\n    self.run_command(cmdname)\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/site-packages/setuptools/command/install_lib.py\", line 11, in run\r\n    self.build()\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/distutils/command/install_lib.py\", line 107, in build\r\n    self.run_command('build_ext')\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/site-packages/setuptools/command/build_ext.py\", line 79, in run\r\n    _build_ext.run(self)\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/distutils/command/build_ext.py\", line 340, in run\r\n    self.build_extensions()\r\n  File \"setup.py\", line 89, in build_extensions\r\n    cwd=self.build_temp)\r\n  File \"/project/.conda/envs/horovod_tf/lib/python3.7/subprocess.py\", line 363, in check_call\r\n    raise CalledProcessError(retcode, cmd)\r\nsubprocess.CalledProcessError: Command '['cmake', '/project/packages/horovod', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/project/packages/horovod/build/lib.linux-ppc64le-3.7', '-DPYTHON_EXECUTABLE:FILEPATH=/project/mvapich-gdr/.conda/envs/horovod_tf/bin/python']' returned non-zero exit status 1.\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2998/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2998/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2995", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2995/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2995/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2995/events", "html_url": "https://github.com/horovod/horovod/issues/2995", "id": 927953852, "node_id": "MDU6SXNzdWU5Mjc5NTM4NTI=", "number": 2995, "title": "\u3010Elastic Horovod\u3011Should we catch exceptions for state.sync()\uff1f", "user": {"login": "ezioliao", "id": 49278241, "node_id": "MDQ6VXNlcjQ5Mjc4MjQx", "avatar_url": "https://avatars.githubusercontent.com/u/49278241?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezioliao", "html_url": "https://github.com/ezioliao", "followers_url": "https://api.github.com/users/ezioliao/followers", "following_url": "https://api.github.com/users/ezioliao/following{/other_user}", "gists_url": "https://api.github.com/users/ezioliao/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezioliao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezioliao/subscriptions", "organizations_url": "https://api.github.com/users/ezioliao/orgs", "repos_url": "https://api.github.com/users/ezioliao/repos", "events_url": "https://api.github.com/users/ezioliao/events{/privacy}", "received_events_url": "https://api.github.com/users/ezioliao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-06-23T07:37:25Z", "updated_at": "2021-06-27T22:54:26Z", "closed_at": "2021-06-27T22:54:26Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): Pytorch\r\n2. Framework version: 1.6.0\r\n3. Horovod version: 0.21.3\r\n4. MPI version: 4.0.3\r\n5. CUDA version: 10.2\r\n6. NCCL version: 2.7.6\r\n7. Python version: 3.6\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes.\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide]  (https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Bug report:**\r\nWhen a new worker was added in host discovery script, old workers will sync their state to new one. But if any worker failed during state synchronization,  unfortunately, the elastic horovod task will fail and  it seems not play a role for elastic:\r\n```\r\n[0]<stderr>:[2021-06-21 21:35:05.743047: E /tmp/pip-req-build-4rhufbvy/horovod/common/operations.cc:640] Horovod background loop uncaught exception: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:575] Connection closed by peer [11.198.63.123]:50349\r\n[0]<stdout>:[2021-06-21 21:35:05.773132: D /tmp/pip-req-build-4rhufbvy/horovod/common/operations.cc:652] [0]: Shutting down background thread\r\n[0]<stderr>:Traceback (most recent call last):\r\n[0]<stderr>:  File \"/usr/local/lib64/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 960, in synchronize\r\n[0]<stderr>:    mpi_lib.horovod_torch_wait_and_clear(handle)[0]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n[0]<stderr>:\r\n[0]<stderr>:During handling of the above exception, another exception occurred:[0]<stderr>: \r\n[0]<stderr>:Traceback (most recent call last):[0]<stderr>:  File \"pytorch_synthetic_benchmark_elastic.py\", line 140, in <module>\r\n[0]<stderr>:    run_benchmark(state)[0]<stderr>:  File \"/usr/local/lib64/python3.6/site-packages/horovod/common/elastic.py\", line 162, in wrapper\r\n[0]<stderr>:    state.sync()\r\n[0]<stderr>:  File \"/usr/local/lib64/python3.6/site-packages/horovod/torch/elastic/state.py\", line 62, in sync\r\n[0]<stderr>:    handler.sync()[0]<stderr>:  File \"/usr/local/lib64/python3.6/site-packages/horovod/torch/elastic/state.py\", line 101, in sync\r\n[0]<stderr>:    broadcast_parameters(self.value.state_dict(), root_rank=0)[0]<stderr>:  File \"/usr/local/lib64/python3.6/site-packages/horovod/torch/functions.py\", line 58, in broadcast_parameters\r\n[0]<stderr>:    synchronize(handle)[0]<stderr>:  File \"/usr/local/lib64/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 964, in synchronize\r\n[0]<stderr>:    raise HorovodInternalError(e)\r\n[0]<stderr>:horovod.common.exceptions.HorovodInternalError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n``` \r\n\r\nI think that was caused by this [code segment:](https://github.com/horovod/horovod/blob/139416965ab9aa5850baf96ec54ce35c58b05119/horovod/common/elastic.py#L161)\r\nIt works well for me when I fix code as follows\r\n```\r\ndef run_fn(func, reset):\r\n       ....\r\n        try:\r\n            while True:\r\n                try:\r\n                    # Here we also catch exceptions for state.sync().\r\n                    if not skip_sync:\r\n                         state.sync()\r\n                    return func(state, *args, **kwargs)\r\n                except HorovodInternalError:\r\n                    state.restore()\r\n                    skip_sync = False\r\n                except HostsUpdatedInterrupt as e:\r\n                    skip_sync = e.skip_sync\r\n\r\n                reset()\r\n                state.on_reset()\r\n        finally:\r\n            notification_manager.remove_listener(state)\r\n    return wrapper\r\n```\r\n\r\n\r\n**Steps to reproduce.**\r\n1. In order to easily reproduce the problem, we add one line  in `horovod/examples/elastic/pytorch/pytorch_synthetic_benchmark_elastic.py` as follows:\r\n```\r\n...\r\nstate.register_reset_callbacks([on_state_reset])\r\n# Here we sleep 30s to keep old workers stay in state.sync() when a new worker\r\n# was add in host-discovery-script.\r\ntime.sleep(30)\r\nrun_benchmark(state)\r\n...\r\n```\r\n2. Run elastic horovod:\r\n```\r\nhorovodrun -np 1 --host-discovery-script ./discovery_hosts.sh --network-interface eth1 --min-np 1 --log-level DEBUG --verbose  python3 pytorch_synthetic_benchmark_elastic.py --num-iters=1000\r\n```\r\n3. After some iteration passed, we add a new worker in host-discovery-script to raise `HostsUpdatedInterrupt`. The old workers will call `state.sync()` and hang in `state.sync()` for 30s as new worker will sleep 30s before `hvd.elastic.run`\r\n4. When old worker was hang in `state.sync`,  we kill one old worker to raise `HorovodInternalError` . At this time the elastic horovod will fail. The content of stderr as follows:\r\n```\r\n[0]<stderr>:[2021-06-21 21:35:05.743047: E /tmp/pip-req-build-4rhufbvy/horovod/common/operations.cc:640] Horovod background loop uncaught exception: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:575] Connection closed by peer [11.198.63.123]:50349\r\n[0]<stdout>:[2021-06-21 21:35:05.773132: D /tmp/pip-req-build-4rhufbvy/horovod/common/operations.cc:652] [0]: Shutting down background thread\r\n[0]<stderr>:Traceback (most recent call last):\r\n[0]<stderr>:  File \"/usr/local/lib64/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 960, in synchronize\r\n[0]<stderr>:    mpi_lib.horovod_torch_wait_and_clear(handle)[0]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n[0]<stderr>:\r\n[0]<stderr>:During handling of the above exception, another exception occurred:[0]<stderr>: \r\n[0]<stderr>:Traceback (most recent call last):[0]<stderr>:  File \"pytorch_synthetic_benchmark_elastic.py\", line 140, in <module>\r\n[0]<stderr>:    run_benchmark(state)[0]<stderr>:  File \"/usr/local/lib64/python3.6/site-packages/horovod/common/elastic.py\", line 162, in wrapper\r\n[0]<stderr>:    state.sync()\r\n[0]<stderr>:  File \"/usr/local/lib64/python3.6/site-packages/horovod/torch/elastic/state.py\", line 62, in sync\r\n[0]<stderr>:    handler.sync()[0]<stderr>:  File \"/usr/local/lib64/python3.6/site-packages/horovod/torch/elastic/state.py\", line 101, in sync\r\n[0]<stderr>:    broadcast_parameters(self.value.state_dict(), root_rank=0)[0]<stderr>:  File \"/usr/local/lib64/python3.6/site-packages/horovod/torch/functions.py\", line 58, in broadcast_parameters\r\n[0]<stderr>:    synchronize(handle)[0]<stderr>:  File \"/usr/local/lib64/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 964, in synchronize\r\n[0]<stderr>:    raise HorovodInternalError(e)\r\n[0]<stderr>:horovod.common.exceptions.HorovodInternalError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n``` \r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2995/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2995/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2989", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2989/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2989/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2989/events", "html_url": "https://github.com/horovod/horovod/issues/2989", "id": 923714025, "node_id": "MDU6SXNzdWU5MjM3MTQwMjU=", "number": 2989, "title": "Failed to use LossScaleOptimizer with DistributedOptimizer.", "user": {"login": "lazykyama", "id": 1679090, "node_id": "MDQ6VXNlcjE2NzkwOTA=", "avatar_url": "https://avatars.githubusercontent.com/u/1679090?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lazykyama", "html_url": "https://github.com/lazykyama", "followers_url": "https://api.github.com/users/lazykyama/followers", "following_url": "https://api.github.com/users/lazykyama/following{/other_user}", "gists_url": "https://api.github.com/users/lazykyama/gists{/gist_id}", "starred_url": "https://api.github.com/users/lazykyama/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lazykyama/subscriptions", "organizations_url": "https://api.github.com/users/lazykyama/orgs", "repos_url": "https://api.github.com/users/lazykyama/repos", "events_url": "https://api.github.com/users/lazykyama/events{/privacy}", "received_events_url": "https://api.github.com/users/lazykyama/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-06-17T09:42:30Z", "updated_at": "2021-06-21T20:51:48Z", "closed_at": "2021-06-21T20:51:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\nNote that I checked this issue on NVIDIA's NGC TF2 container image, `nvcr.io/nvidia/tensorflow:21.05-tf2-py3`. (Release notes: https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/rel_21-05.html#rel_21-05)\r\n\r\n1. Framework: TensorFlow (and its keras API)\r\n2. Framework version: 2.4.0+nv\r\n3. Horovod version: 0.21.3\r\n4. MPI version: 4.1.1rc1\r\n5. CUDA version: V11.3.58\r\n6. NCCL version: 2.9.8\r\n7. Python version: 3.8.5\r\n8. Spark / PySpark version: N/A\r\n9. Ray version: N/A\r\n10. OS and version: Ubuntu 20.04.2 LTS\r\n11. GCC version: 9.3.0\r\n12. CMake version: 3.16.3\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?: Y\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?: N/A\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?: Y\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?: Y\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nWhen I tried to use newer mixed precision API, `tf.keras.mixed_precision.LossScaleOptimizer`, with Horovod, the error, `AttributeError: 'LossScaleOptimizer' object has no attribute '_optimizer'`, happened.\r\n\r\nMinimal reproduction code is below, and if a line of `LossScaleOptimizer` is commented out, no error happens.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport horovod.tensorflow.keras as hvd\r\n\r\ndef main():\r\n    hvd.init()\r\n\r\n    gpus = tf.config.experimental.list_physical_devices('GPU')\r\n    for gpu in gpus:\r\n        tf.config.experimental.set_memory_growth(gpu, True)\r\n    if gpus:\r\n        tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\r\n\r\n    policy = tf.keras.mixed_precision.Policy('mixed_float16')\r\n    tf.keras.mixed_precision.set_global_policy(policy)\r\n    opt = tf.keras.optimizers.RMSprop(learning_rate=0.001 * (hvd.size()**0.5))\r\n    opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\r\n    opt = hvd.DistributedOptimizer(opt)\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nFull stacktrace message is below.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"minimal_repro.py\", line 21, in <module>\r\n    main()\r\n  File \"minimal_repro.py\", line 17, in main\r\n    opt = hvd.DistributedOptimizer(opt)\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/keras/__init__.py\", line 97, in DistributedOptimizer\r\n    return _impl.create_distributed_optimizer(\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/_keras/__init__.py\", line 167, in create_distributed_optimizer\r\n    return cls.from_config(config)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py\", line 794, in from_config\r\n    return cls(**config)\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/_keras/__init__.py\", line 37, in __init__\r\n    self._name = name or \"Distributed%s\" % self.__class__.__base__.__name__\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py\", line 918, in __setattr__\r\n    if (name != '_optimizer' and name in self._optimizer._hyper\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py\", line 888, in __getattribute__\r\n    raise e\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py\", line 884, in __getattribute__\r\n    return object.__getattribute__(self, name)\r\nAttributeError: 'LossScaleOptimizer' object has no attribute '_optimizer'\r\n```\r\n\r\nAs far as I checked, at [`keras/mixed_precision/loss_scale_optimizer.py`#L534](https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py#L534), `_optimizer` is initialized, and Horovod's automatically generated wrapper class, `_DistributedOptimizer`, tries to access `_name` attribute before this initialization ([`horovod/_keras/__init__.py`#L37](https://github.com/horovod/horovod/blob/master/horovod/_keras/__init__.py#L37)). Then, `LossScaleOptimizer` checks if an attribute exists or not when accessing to any attribute, and raise an error for a few attributes like `_optimizer` at ([`keras/mixed_precision/loss_scale_optimizer.py`#L882-L888](https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py#L882-L888))\r\nHowever, it looks like `_DistributedOptimizer` makes the initialization (= `_optimizer` initialization) delayed to the last of `__init__()` ([`horovod/_keras/__init__.py`#L69](https://github.com/horovod/horovod/blob/master/horovod/_keras/__init__.py#L69)). As a result, this error looks like caused.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2989/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2989/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2988", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2988/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2988/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2988/events", "html_url": "https://github.com/horovod/horovod/issues/2988", "id": 922398449, "node_id": "MDU6SXNzdWU5MjIzOTg0NDk=", "number": 2988, "title": "\"work-dir\" parameter doesn't work in Spark_Keras_mnist example", "user": {"login": "wjxiz1992", "id": 20476954, "node_id": "MDQ6VXNlcjIwNDc2OTU0", "avatar_url": "https://avatars.githubusercontent.com/u/20476954?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjxiz1992", "html_url": "https://github.com/wjxiz1992", "followers_url": "https://api.github.com/users/wjxiz1992/followers", "following_url": "https://api.github.com/users/wjxiz1992/following{/other_user}", "gists_url": "https://api.github.com/users/wjxiz1992/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjxiz1992/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjxiz1992/subscriptions", "organizations_url": "https://api.github.com/users/wjxiz1992/orgs", "repos_url": "https://api.github.com/users/wjxiz1992/repos", "events_url": "https://api.github.com/users/wjxiz1992/events{/privacy}", "received_events_url": "https://api.github.com/users/wjxiz1992/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2021-06-16T09:56:00Z", "updated_at": "2021-09-16T05:15:10Z", "closed_at": "2021-09-16T05:15:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version:  2.5.0\r\n3. Horovod version: 0.22.1\r\n4. MPI version: 4.0.2\r\n5. CUDA version: 11.2\r\n6. NCCL version: 2.9.9\r\n7. Python version: 3.8.8\r\n8. Spark / PySpark version: 3.1.2\r\n9. Ray version: /\r\n10. OS and version: Ubuntu 20.04\r\n11. GCC version: 9.3\r\n12. CMake version: 3.18.5\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? No\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? No\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nwhen installing Horovod+TensorFlow and set up Spark, run\r\n\r\n``` bash\r\npython keras_spark_mnist.py --master spark://10.19.183.124:7077 --num-proc 1 --work-dir /home/allxu/Desktop/gitlab/hvd-spark/work-dir --num-epoch 1\r\n```\r\nThe python file is the [one in the example folder](https://github.com/horovod/horovod/blob/master/examples/spark/keras/keras_spark_mnist.py)\r\n\r\nError message:\r\n```\r\nWed Jun 16 17:42:16 2021[1,0]<stderr>:2021-06-16 17:42:16.262808: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /tmp/tmpn_eenlao/logs/train/plugins/profile/2021_06_16_17_42_16Dumped tool data for xplane.pb to /tmp/tmpn_eenlao/logs/train/plugins/profile/2021_06_16_17_42_16/allxu-pc.xplane.pb\r\nWed Jun 16 17:42:16 2021[1,0]<stderr>:Dumped tool data for overview_page.pb to /tmp/tmpn_eenlao/logs/train/plugins/profile/2021_06_16_17_42_16/allxu-pc.overview_page.pb\r\nWed Jun 16 17:42:16 2021[1,0]<stderr>:Dumped tool data for input_pipeline.pb to /tmp/tmpn_eenlao/logs/train/plugins/profile/2021_06_16_17_42_16/allxu-pc.input_pipeline.pb\r\nWed Jun 16 17:42:16 2021[1,0]<stderr>:Dumped tool data for tensorflow_stats.pb to /tmp/tmpn_eenlao/logs/train/plugins/profile/2021_06_16_17_42_16/allxu-pc.tensorflow_stats.pb\r\nWed Jun 16 17:42:16 2021[1,0]<stderr>:Dumped tool data for kernel_stats.pb to /tmp/tmpn_eenlao/logs/train/plugins/profile/2021_06_16_17_42_16/allxu-pc.kernel_stats.pb\r\nWed Jun 16 17:42:16 2021[1,0]<stderr>:\r\nWed Jun 16 17:42:16 2021[1,0]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_begin` time: 0.0534s). Check your callbacks.\r\nWed Jun 16 17:42:16 2021[1,0]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0309s). Check your callbacks.\r\n423/423 [==============================]Wed Jun 16 17:42:17 2021[1,0]<stdout>: - 5s 5ms/step - loss: 1.0698 - accuracy: 0.8546Jun 16 17:42:17 2021[1,0]<stdout>:Wed Jun 16 17:42:17 2021[1,0]<stdout>:>:\r\nWed Jun 16 17:42:17 2021[1,0]<stderr>:2021-06-16 17:42:17.921864: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:Traceback (most recent call last):\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:  File \"/home/allxu/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:    return _run_code(code, main_globals, None,\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:  File \"/home/allxu/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:    exec(code, run_globals)\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:  File \"/home/allxu/miniconda3/lib/python3.8/site-packages/horovod/spark/task/mpirun_exec_fn.py\", line 52, in <module>\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:    main(codec.loads_base64(sys.argv[1]), codec.loads_base64(sys.argv[2]))\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:  File \"/home/allxu/miniconda3/lib/python3.8/site-packages/horovod/spark/task/mpirun_exec_fn.py\", line 45, in main\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:    task_exec(driver_addresses, settings, 'OMPI_COMM_WORLD_RANK', 'OMPI_COMM_WORLD_LOCAL_RANK')\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:  File \"/home/allxu/miniconda3/lib/python3.8/site-packages/horovod/spark/task/__init__.py\", line 61, in task_exec\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:    result = fn(*args, **kwargs)\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:  File \"/home/allxu/miniconda3/lib/python3.8/site-packages/horovod/spark/keras/remote.py\", line 262, in train\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:    with open(ckpt_file, 'rb') as f:\r\nWed Jun 16 17:42:18 2021[1,0]<stderr>:IsADirectoryError: [Errno 21] Is a directory: '/tmp/tmpn_eenlao/checkpoint'\r\n\r\n```\r\n\r\nWhen I check my work-dir, I can see files like `intermediate_train_data.0` and `intermediate_train_data.0_cached_metadata.pkl`.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2988/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2988/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2967", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2967/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2967/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2967/events", "html_url": "https://github.com/horovod/horovod/issues/2967", "id": 917090470, "node_id": "MDU6SXNzdWU5MTcwOTA0NzA=", "number": 2967, "title": "Error when broadcasting tensors", "user": {"login": "hgzjy25", "id": 27129520, "node_id": "MDQ6VXNlcjI3MTI5NTIw", "avatar_url": "https://avatars.githubusercontent.com/u/27129520?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hgzjy25", "html_url": "https://github.com/hgzjy25", "followers_url": "https://api.github.com/users/hgzjy25/followers", "following_url": "https://api.github.com/users/hgzjy25/following{/other_user}", "gists_url": "https://api.github.com/users/hgzjy25/gists{/gist_id}", "starred_url": "https://api.github.com/users/hgzjy25/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hgzjy25/subscriptions", "organizations_url": "https://api.github.com/users/hgzjy25/orgs", "repos_url": "https://api.github.com/users/hgzjy25/repos", "events_url": "https://api.github.com/users/hgzjy25/events{/privacy}", "received_events_url": "https://api.github.com/users/hgzjy25/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-06-10T08:54:32Z", "updated_at": "2021-06-11T02:46:37Z", "closed_at": "2021-06-11T02:46:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.2.0\r\n3. Horovod version: 0.19.5\r\n4. MPI version:\r\n5. CUDA version: 9.2\r\n6. NCCL version:\r\n7. Python version:\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version:\r\n11. GCC version: 5.2.0\r\n12. CMake version:\r\n\r\n**Bug report:**\r\n```\r\nThu Jun 10 16:02:20 2021[3]<stderr>:Traceback (most recent call last):\r\nThu Jun 10 16:02:21 2021[2]<stderr>:Traceback (most recent call last):\r\nThu Jun 10 16:02:21 2021[1]<stderr>:Traceback (most recent call last):\r\nThu Jun 10 16:02:21 2021[3]<stderr>:  File \"pretrain.py\", line 634, in <module>\r\nThu Jun 10 16:02:21 2021[2]<stderr>:  File \"pretrain.py\", line 634, in <module>\r\nThu Jun 10 16:02:21 2021[3]<stderr>:    main(args)\r\nThu Jun 10 16:02:21 2021[2]<stderr>:    main(args)\r\nThu Jun 10 16:02:21 2021[3]<stderr>:  File \"pretrain.py\", line 244, in main\r\nThu Jun 10 16:02:21 2021[1]<stderr>:  File \"pretrain.py\", line 634, in <module>\r\nThu Jun 10 16:02:21 2021[3]<stderr>:    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\nThu Jun 10 16:02:21 2021[1]<stderr>:    main(args)\r\nThu Jun 10 16:02:21 2021[3]<stderr>:  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/torch/__init__.py\", line 476, in broadcast_parameters\r\nThu Jun 10 16:02:21 2021[1]<stderr>:  File \"pretrain.py\", line 244, in main\r\nThu Jun 10 16:02:21 2021[2]<stderr>:  File \"pretrain.py\", line 244, in main\r\nThu Jun 10 16:02:21 2021[1]<stderr>:    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\nThu Jun 10 16:02:21 2021[2]<stderr>:    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\nThu Jun 10 16:02:21 2021[1]<stderr>:  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/torch/__init__.py\", line 476, in broadcast_parameters\r\nThu Jun 10 16:02:21 2021[2]<stderr>:  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/torch/__init__.py\", line 476, in broadcast_parameters\r\nThu Jun 10 16:02:21 2021[1]<stderr>:    handle = broadcast_async_(p, root_rank, name)\r\nThu Jun 10 16:02:21 2021[2]<stderr>:    handle = broadcast_async_(p, root_rank, name)\r\nThu Jun 10 16:02:21 2021[1]<stderr>:  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 449, in broadcast_async_\r\nThu Jun 10 16:02:21 2021[2]<stderr>:  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 449, in broadcast_async_\r\nThu Jun 10 16:02:21 2021[1]<stderr>:    return _broadcast_async(tensor, tensor, root_rank, name)\r\nThu Jun 10 16:02:21 2021[2]<stderr>:    return _broadcast_async(tensor, tensor, root_rank, name)\r\nThu Jun 10 16:02:21 2021[1]<stderr>:  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 359, in _broadcast_async\r\nThu Jun 10 16:02:21 2021[2]<stderr>:  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 359, in _broadcast_async\r\nThu Jun 10 16:02:21 2021[1]<stderr>:    tensor, output, root_rank, name.encode() if name is not None else _NULL)\r\nThu Jun 10 16:02:21 2021[2]<stderr>:    tensor, output, root_rank, name.encode() if name is not None else _NULL)\r\nThu Jun 10 16:02:21 2021[3]<stderr>:    handle = broadcast_async_(p, root_rank, name)\r\nThu Jun 10 16:02:21 2021[2]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\nThu Jun 10 16:02:21 2021[1]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\nThu Jun 10 16:02:21 2021[3]<stderr>:  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 449, in broadcast_async_\r\nThu Jun 10 16:02:21 2021[3]<stderr>:    return _broadcast_async(tensor, tensor, root_rank, name)\r\nThu Jun 10 16:02:21 2021[3]<stderr>:  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 359, in _broadcast_async\r\nThu Jun 10 16:02:21 2021[3]<stderr>:    tensor, output, root_rank, name.encode() if name is not None else _NULL)\r\nThu Jun 10 16:02:21 2021[3]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\nTraceback (most recent call last):\r\n  File \"/anacond3/envs/LightningDOT/bin/horovodrun\", line 21, in <module>\r\n    run_commandline()\r\n  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/run/runner.py\", line 723, in run_commandline\r\n    _run(args)\r\n  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/run/runner.py\", line 656, in _run\r\n    _launch_job(args, remote_host_names, settings, nics, command)\r\n  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/run/runner.py\", line 717, in _launch_job\r\n    args.verbose)\r\n  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/run/runner.py\", line 694, in run_controller\r\n    gloo_run()\r\n  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/run/runner.py\", line 706, in gloo_run_fn\r\n    gloo_run(settings, remote_host_names, nics, env, driver_ip, command)\r\n  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/run/gloo_run.py\", line 312, in gloo_run\r\n    launch_gloo(command, exec_command, settings, nics, env, server_ip)\r\n  File \"/anacond3/envs/LightningDOT/lib/python3.6/site-packages/horovod/run/gloo_run.py\", line 304, in launch_gloo\r\n    .format(name=name, code=exit_code))\r\nRuntimeError: Gloo job detected that one or more processes exited with non-zero status, thus causing the job to be terminated. The first process to do so was:\r\nProcess name: 7\r\nExit code: 1\r\n```\r\n\r\nHow do I solve this problems? I use 4 GPUs to run my task. I can't find any concrete exception. \r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2967/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2967/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2961", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2961/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2961/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2961/events", "html_url": "https://github.com/horovod/horovod/issues/2961", "id": 915394820, "node_id": "MDU6SXNzdWU5MTUzOTQ4MjA=", "number": 2961, "title": "PyTorch sparse allreduce fails with torch nightly", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2021-06-08T19:31:19Z", "updated_at": "2021-06-10T03:11:05Z", "closed_at": "2021-06-10T03:11:05Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Repro:\r\n\r\n```\r\npip install --no-cache-dir --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\r\n# install horovod\r\nhorovodrun -np 2 pytest -vs \"test/parallel/test_torch.py::TorchTests::test_async_sparse_allreduce\"\r\n```\r\n\r\nThe test hangs, which has been causing test failures.\r\n\r\ncc @chongxiaoc @romerojosh \r\n\r\n@chongxiaoc can you or @irasit take a look?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2961/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2961/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2936", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2936/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2936/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2936/events", "html_url": "https://github.com/horovod/horovod/issues/2936", "id": 900039304, "node_id": "MDU6SXNzdWU5MDAwMzkzMDQ=", "number": 2936, "title": "`struct.error: unpack requires a buffer of 4 bytes` and pickel erros in spark mnist example", "user": {"login": "darkjh", "id": 802343, "node_id": "MDQ6VXNlcjgwMjM0Mw==", "avatar_url": "https://avatars.githubusercontent.com/u/802343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/darkjh", "html_url": "https://github.com/darkjh", "followers_url": "https://api.github.com/users/darkjh/followers", "following_url": "https://api.github.com/users/darkjh/following{/other_user}", "gists_url": "https://api.github.com/users/darkjh/gists{/gist_id}", "starred_url": "https://api.github.com/users/darkjh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/darkjh/subscriptions", "organizations_url": "https://api.github.com/users/darkjh/orgs", "repos_url": "https://api.github.com/users/darkjh/repos", "events_url": "https://api.github.com/users/darkjh/events{/privacy}", "received_events_url": "https://api.github.com/users/darkjh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-05-24T21:45:47Z", "updated_at": "2021-05-25T19:24:42Z", "closed_at": "2021-05-25T19:24:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow and Spark\r\n2. Framework version: Tensorflow 2.4.1 mkl\r\n3. Horovod version: 0.22.0 and 0.21.3\r\n4. MPI version: 4.0.2\r\n7. Python version: 3.7.10\r\n8. Spark / PySpark version: 3.1.1\r\n11. GCC version: 7.3.0\r\n12. CMake version: 3.20.2\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\n\r\nRun horovod spark mnist example locally with CPU, both on local spark `local[4]` and a standalone local cluster. \r\nAlways gives error of this kind https://gist.github.com/darkjh/e7392a96c1f719a45067d3b031f6640b\r\n\r\nI tried both MPI and GLOO and same errors.\r\n\r\nOn the same machine, basic tensorflow2 example (with `horovodrun`) runs without any problem.\r\n\r\nSame error when trying the rossman example too.\r\n\r\nAny ideas? Thanks!", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2936/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2936/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2924", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2924/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2924/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2924/events", "html_url": "https://github.com/horovod/horovod/issues/2924", "id": 898105210, "node_id": "MDU6SXNzdWU4OTgxMDUyMTA=", "number": 2924, "title": "Horovod incompatible with TensorFlow nightly", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 963944291, "node_id": "MDU6TGFiZWw5NjM5NDQyOTE=", "url": "https://api.github.com/repos/horovod/horovod/labels/upstream%20bug", "name": "upstream bug", "color": "e228dc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-05-21T14:34:47Z", "updated_at": "2021-05-23T21:56:18Z", "closed_at": "2021-05-23T21:56:18Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "TensorFlow removed `PersistentTensor` from their API in https://github.com/tensorflow/tensorflow/commit/f8153ae87a88586ac1c364116208cfb144c9b64a#diff-b35354f62819de66aaa049a9498cccc261c108a7c488d39e04882110bdee65b5. We rely on this functionality for creating the fusion buffer, which needs to span across multiple ops. We need to find a workaround or work with the TF team to revert this change.\r\n\r\ncc @romerojosh @DEKHTIARJonathan ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2924/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2924/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2922", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2922/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2922/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2922/events", "html_url": "https://github.com/horovod/horovod/issues/2922", "id": 897294061, "node_id": "MDU6SXNzdWU4OTcyOTQwNjE=", "number": 2922, "title": "backward_passes_per_step >1, error: IndexError: tuple index out of range", "user": {"login": "roshni-kamath", "id": 19430592, "node_id": "MDQ6VXNlcjE5NDMwNTky", "avatar_url": "https://avatars.githubusercontent.com/u/19430592?v=4", "gravatar_id": "", "url": "https://api.github.com/users/roshni-kamath", "html_url": "https://github.com/roshni-kamath", "followers_url": "https://api.github.com/users/roshni-kamath/followers", "following_url": "https://api.github.com/users/roshni-kamath/following{/other_user}", "gists_url": "https://api.github.com/users/roshni-kamath/gists{/gist_id}", "starred_url": "https://api.github.com/users/roshni-kamath/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/roshni-kamath/subscriptions", "organizations_url": "https://api.github.com/users/roshni-kamath/orgs", "repos_url": "https://api.github.com/users/roshni-kamath/repos", "events_url": "https://api.github.com/users/roshni-kamath/events{/privacy}", "received_events_url": "https://api.github.com/users/roshni-kamath/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-05-20T18:58:12Z", "updated_at": "2021-05-24T16:19:48Z", "closed_at": "2021-05-24T16:19:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.13\r\n3. Horovod version: 0.21\r\n4. Python version: 3.8\r\n5. OS and version: Linux\r\n\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nI am trying to implement gradient accumulation using:\r\n\r\nstep = tf.contrib.framework.get_or_create_global_step()\r\nopt = hvd.DistributedOptimizer(opt,backward_passes_per_step=4,average_aggregated_gradients=True)\r\ngrads=opt.compute_gradients(total_loss,var_list=tf.trainable_variables())\r\ntrain_op = opt.apply_gradients(grads_and_vars=grads, global_step=step)\r\n\r\nBut I get the following error:\r\n\r\nFile \u201c/usr/local/lib/python3.8/dist-packages/horovod/tensorflow/gradient_aggregation.py\u201d, line 233, in apply_gradients\r\n  flattended_args0 = [item for tup in args[0] for item in tup]\r\nIndexError: tuple index out of range\r\n\r\n\r\nIs the implementation correct?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2922/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2922/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2907", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2907/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2907/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2907/events", "html_url": "https://github.com/horovod/horovod/issues/2907", "id": 892717206, "node_id": "MDU6SXNzdWU4OTI3MTcyMDY=", "number": 2907, "title": "Uncaught gloo::ioException in Elastic PyTorch", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-05-16T17:23:43Z", "updated_at": "2021-05-16T17:31:01Z", "closed_at": "2021-05-16T17:31:01Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "The elastic torch test makes the training script fail with SIGKILL on process with rank one, which should make elastic Horovod downscale the cluster to 3 training Horovod processes.\r\n\r\nFrom the log and exist codes we can see the other three training processes also fail, due to an uncaught Gloo IO Exception:\r\n\r\n```\r\n[0]<stderr>:RuntimeError: check_rank and exit epoch=1 batch=0 start_rank=0 rank=0\r\n[0]<stderr>:Killed\r\n\r\n[1]<stderr>:Terminated\r\n[1]<stderr>:terminate called after throwing an instance of 'gloo::IoException'\r\n[1]<stderr>:  what():  [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:589] Read error [127.0.0.1]:3977: Connection reset by peer\r\n[1]<stderr>:Aborted (core dumped)\r\n\r\n[2]<stderr>:terminate called after throwing an instance of 'gloo::IoException'\r\n[2]<stderr>:  what():  [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [127.0.0.1]:54168\r\n[2]<stderr>:Aborted (core dumped)\r\n\r\n[3]<stderr>:terminate called after throwing an instance of 'gloo::IoException'\r\n[3]<stderr>:  what():  [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:589] Read error [127.0.0.1]:52398: Connection reset by peer\r\n[3]<stderr>:Aborted (core dumped)\r\n```\r\n\r\nHere are the exit codes of the four Horovod processes:\r\n\r\n```\r\nProcess 0 exit with status code 137.\r\nProcess 3 exit with status code 134.\r\nProcess 2 exit with status code 134.\r\nProcess 1 exit with status code 134.\r\n```\r\n\r\nExit code 137 indicates a SIGKILL, exit code 134 indicates a SIGABRT.\r\n\r\nThis only occurs with torch head on GPU (torch-1.9.0.dev20210514+cu111), not torch head on CPU (torch-1.9.0.dev20210514+cpu).\r\n\r\nhttps://buildkite.com/horovod/horovod/builds/5681#8605273c-90ed-4476-be43-0f1c59b80a58", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2907/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2907/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2898", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2898/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2898/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2898/events", "html_url": "https://github.com/horovod/horovod/issues/2898", "id": 877352958, "node_id": "MDU6SXNzdWU4NzczNTI5NTg=", "number": 2898, "title": "Crashing PyTorch loaders with multiple workers and nodes", "user": {"login": "henrique", "id": 128897, "node_id": "MDQ6VXNlcjEyODg5Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/128897?v=4", "gravatar_id": "", "url": "https://api.github.com/users/henrique", "html_url": "https://github.com/henrique", "followers_url": "https://api.github.com/users/henrique/followers", "following_url": "https://api.github.com/users/henrique/following{/other_user}", "gists_url": "https://api.github.com/users/henrique/gists{/gist_id}", "starred_url": "https://api.github.com/users/henrique/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/henrique/subscriptions", "organizations_url": "https://api.github.com/users/henrique/orgs", "repos_url": "https://api.github.com/users/henrique/repos", "events_url": "https://api.github.com/users/henrique/events{/privacy}", "received_events_url": "https://api.github.com/users/henrique/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2021-05-06T10:34:07Z", "updated_at": "2021-05-12T12:28:26Z", "closed_at": "2021-05-12T12:28:26Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (PyTorch)\r\n2. Framework version: 1.6.0 / 1.7.1 / 1.8.1\r\n3. Horovod version: 0.20.0 / 0.21.1 / 0.21.3 (respectively)\r\n4. MPI version: OpenMPI 4.0.1 / cray-mpich-7.7.16 / =\r\n5. CUDA version: 10.1 (docker) / 11.0 (native)\r\n6. NCCL version: 2.8.3\r\n7. Python version: 3.8.5\r\n11. GCC version: 9.3.0\r\n12. CMake version: 3.10.2\r\n\r\n**Bug report:**\r\nWe have been supporting Horovod for a while (thanks for the great work!) but a user found an issue with the imagenet dataset when using many workers (required to scale the training). It also seems to happen with the default num_workers=4 as in the example, but less often.\r\n\r\nThe dataloader workers may crash when running pytorch_imagenet_resnet50.py on multiple nodes and multiple forked workers with MPI. The chances of this happen seems to increase when using more nodes and more workers (e.g. 12 workers on 32x 1-gpu nodes).\r\nmultiprocessing_context=fork gives our well known segfault.\r\nmultiprocessing_context=forkserver (as in the example) sometimes works, but might end up with Bus error/Broken pipe and leaked semaphores:\r\n```\r\npython3.8/multiprocessing/resource_tracker.py:96: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\r\n  File \"pytorch_imagenet_resnet50.py\", line 68, in train\r\n    for batch_idx, (data, target) in enumerate(train_loader):\r\n  File \".../torch/utils/data/dataloader.py\", line 352, in __iter__\r\n    return self._get_iterator()\r\n  File \".../torch/utils/data/dataloader.py\", line 294, in _get_iterator\r\n    return _MultiProcessingDataLoaderIter(self)\r\n  File \".../torch/utils/data/dataloader.py\", line 801, in __init__\r\n    w.start()\r\n  File \".../python3.8/multiprocessing/process.py\", line 121, in start\r\n    self._popen = self._Popen(self)\r\n  File \".../python3.8/multiprocessing/context.py\", line 291, in _Popen\r\n    return Popen(process_obj)\r\n  File \".../python3.8/multiprocessing/popen_forkserver.py\", line 35, in __init__\r\n    super().__init__(process_obj)\r\n  File \".../python3.8/multiprocessing/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \".../python3.8/multiprocessing/popen_forkserver.py\", line 58, in _launch\r\n    f.write(buf.getbuffer())\r\nBrokenPipeError: [Errno 32] Broken pipe\r\npython3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 14 leaked semaphore objects to clean up at shutdown\r\n```\r\nmultiprocessing_context=spawn gets extremely slow, and also crashes.\r\n\r\nnum_workers=0 solves the issue, but results in a massive IO bottleneck even when setting PyTorch to use lot of threads (e.g. torch.set_num_threads(24)). Therefore, making it unusable.\r\nThe native PyTorch DDP doesn't seem to have the same issue, not even with multiprocessing_context=fork, which seems intriguing... \r\n\r\nI've been struggling to understand this for a while, so I wonder if anyone here could give us some idea of what could be causing this?\r\nThe idea of forking the workers after the MPI initialisation seems already odd. Btw, we also get these warnings when running without a container:\r\n```\r\n[PE_29]:inet_listen_socket_setup:inet_setup_listen_socket: bind failed port 24389 listen_sock = 6 Address already in use\r\n[PE_29]:_pmi_inet_listen_socket_setup:socket setup failed\r\n```\r\nwhich disappear when setting PMI_NO_FORK=1  PMI_NO_PREINITIALIZE=1 but that doesn't seem to solve the problem with the dying workers\r\n\r\nWe are mainly using the pip installation with cray-mpich on SLURM (srun instead of horovodrun), but I was also able to reproduce the errors using horovod/horovod:0.20.0-tf2.3.0-torch1.6.0-mxnet1.6.0.post0-py3.7-cuda10.1 and OpenMPI 4.0.1 (I have to use sarus as we don't have docker in our env but I believe that shouldn't make a difference)\r\nWe have 64 GB of RAM on the nodes and 32 GB of /dev/shm so it shouldn't be a memory issue from my calculation (batch size 64/128).\r\nUsing the validation dataset for training is enough to reproduce it.\r\n\r\nI also was trying to test with Gloo only, but I am not sure how to force Horovod to use it without horovodrun. Setting HOROVOD_GLOO=1 doesn't seem to do the trick (hvd.gloo_built() == True, hvd.gloo_enabled() == False).\r\n\r\nThanks already for any input you can give us!\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2898/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2898/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2895", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2895/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2895/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2895/events", "html_url": "https://github.com/horovod/horovod/issues/2895", "id": 876413135, "node_id": "MDU6SXNzdWU4NzY0MTMxMzU=", "number": 2895, "title": "torchhead tests fail on Buildkite due to missing module torchvision", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2021-05-05T12:46:44Z", "updated_at": "2021-05-17T11:20:04Z", "closed_at": "2021-05-17T10:59:08Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Example: https://buildkite.com/horovod/horovod/builds/5615#30c863b2-5c39-49da-ace2-a33a95cf0259\r\n```\r\n$ docker-compose -f docker-compose.test.yml -p buildkite30c863b25c3949daace2a33a95cf0259 -f docker-compose.buildkite-5615-override.yml run --name buildkite30c863b25c3949daace2a33a95cf0259_test-cpu-gloo-py3_8-tfhead-keras_none-torchhead-mxnethead-pyspark_3_1_1_build_5615 -v /var/lib/buildkite-agent/builds/buildkite-cpu-i-073be3461ab55a438-1/horovod/horovod/artifacts:/artifacts --rm test-cpu-gloo-py3_8-tfhead-keras_none-torchhead-mxnethead-pyspark_3_1_1 /bin/sh -e -c 'bash -c \" python /horovod/examples/pytorch/pytorch_mnist.py --epochs 3 --data-dir /data/pytorch_datasets\"'\r\nTraceback (most recent call last):\r\n  File \"/horovod/examples/pytorch/pytorch_mnist.py\", line 9, in <module>\r\n    from torchvision import datasets, transforms\r\nModuleNotFoundError: No module named 'torchvision'\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2895/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2895/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2887", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2887/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2887/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2887/events", "html_url": "https://github.com/horovod/horovod/issues/2887", "id": 874562526, "node_id": "MDU6SXNzdWU4NzQ1NjI1MjY=", "number": 2887, "title": "Hangs during training", "user": {"login": "kevinghst", "id": 18520313, "node_id": "MDQ6VXNlcjE4NTIwMzEz", "avatar_url": "https://avatars.githubusercontent.com/u/18520313?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kevinghst", "html_url": "https://github.com/kevinghst", "followers_url": "https://api.github.com/users/kevinghst/followers", "following_url": "https://api.github.com/users/kevinghst/following{/other_user}", "gists_url": "https://api.github.com/users/kevinghst/gists{/gist_id}", "starred_url": "https://api.github.com/users/kevinghst/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kevinghst/subscriptions", "organizations_url": "https://api.github.com/users/kevinghst/orgs", "repos_url": "https://api.github.com/users/kevinghst/repos", "events_url": "https://api.github.com/users/kevinghst/events{/privacy}", "received_events_url": "https://api.github.com/users/kevinghst/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-05-03T13:11:30Z", "updated_at": "2021-05-03T15:13:17Z", "closed_at": "2021-05-03T15:13:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI have an error where from time to time, horovod hangs. Here is how to reproduce the error:\r\n\r\nMy horovod script:\r\n`mpirun --verbose -np 32 -H localhost:8,172.18.4.19:8,172.18.4.103:8,172.18.4.17:8 -mca plm_rsh_args \"-p 12345\" --allow-run-as-root -mca btl_tcp_if_exclude docker0,lo,bond0.1000 -x NCCL_SOCKET_IFNAME=bond0.2022 -bind-to none -map-by slot -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -mca pml ob1 -mca btl ^openib python /Hulk/Hulk/hvd_train_rnnt.py --project_name prod-master -g 8 -n 4 -w 10 --config config_prod.yaml --resume_from /media/10TBSATA/models/v8_1/checkpoint-28000.tar`\r\n\r\nTraining and evaluation code:\r\n```\r\ndef evaluate(args, gpu, model, test_loader, tokenizer=None, calc_wer=False):\r\n    print(\"STARTING VALIDATION\")\r\n    model.eval()\r\n    valid_loss = []\r\n    wers = []\r\n    cers = []\r\n    total_step = len(test_loader)\r\n\r\n    with torch.no_grad():\r\n        for i, _data in enumerate(test_loader):\r\n            start = time.time()\r\n            spectrograms, labels, input_lengths, label_lengths = _data\r\n\r\n            # calculate wer and cer\r\n            if calc_wer:\r\n                for j, xs in enumerate(spectrograms):\r\n                    sample_input_length = int(input_lengths[j])\r\n                    sample_label_length = int(label_lengths[j])\r\n                    sample_spec = torch.unsqueeze(xs[:sample_input_length, :], 0)\r\n                    sample_label = torch.unsqueeze(labels[j][:sample_label_length], 0)\r\n\r\n                    y, nll = model.greedy_decode1(sample_spec.cuda(), [sample_input_length])\r\n\r\n                    yt = tokenizer.decode(y)\r\n\r\n                    ref = sample_label[0].tolist()\r\n                    ref = [int(x) for x in ref]\r\n\r\n                    rt = tokenizer.decode(ref)\r\n\r\n                    er, _, _ = wer(rt, yt)\r\n                    wers.append(er)\r\n                    cers.append(cer(rt, yt))\r\n\r\n            # calculate loss\r\n\r\n            input_lengths = torch.tensor(input_lengths, dtype=torch.int32)\r\n            label_lengths = torch.tensor(label_lengths, dtype=torch.int32)\r\n            labels = torch.tensor(labels, dtype=torch.int64)\r\n\r\n            spectrograms, input_lengths = spectrograms.cuda(), input_lengths.cuda()\r\n            labels, label_lengths = labels.cuda(), label_lengths.cuda()\r\n\r\n            loss = model(spectrograms, labels, input_lengths, label_lengths)\r\n\r\n            loss_val = hvd.allreduce(torch.Tensor([loss.item()])).item()\r\n            valid_loss.append(loss_val)\r\n\r\n    avg_valid_loss = sum(valid_loss) / len(valid_loss)\r\n    avg_wer = sum(wers) / len(wers) if calc_wer else None\r\n    avg_cer = sum(cers) / len(cers) if calc_wer else None\r\n\r\n    return avg_valid_loss, avg_wer, avg_cer\r\n\r\ndef train():\r\n    for epoch in range(args.start_epoch, (config.dist_train.epochs + 1)):\r\n        model.zero_grad()\r\n        train_sampler.set_epoch(epoch - 1)\r\n        losses = []\r\n        for i, _data in enumerate(train_loader, start=args.start_step):\r\n            start = time.time()\r\n            spectrograms, labels, input_lengths, label_lengths = _data\r\n    \r\n            input_lengths = torch.tensor(input_lengths, dtype=torch.int32)\r\n            label_lengths = torch.tensor(label_lengths, dtype=torch.int32)\r\n            labels = torch.tensor(labels, dtype=torch.int64)\r\n    \r\n            spectrograms, input_lengths = spectrograms.cuda(), input_lengths.cuda()\r\n            labels, label_lengths = labels.cuda(), label_lengths.cuda()  # print(spectrograms.shape)\r\n    \r\n            loss = model(spectrograms, labels, input_lengths, label_lengths)\r\n            loss_val = hvd.allreduce(torch.Tensor([loss.item()]).cuda()).item()\r\n    \r\n            losses.append(loss_val)\r\n            loss = loss / config.dist_train.grad_acc_steps\r\n            loss.backward()\r\n    \r\n            if i % config.dist_train.grad_acc_steps == 0 or i == total_step:\r\n                optimizer.synchronize() \r\n                nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\r\n                with optimizer.skip_synchronize():\r\n                    optimizer.step()\r\n                scheduler.step()\r\n                model.zero_grad()\r\n                total_iter += 1\r\n    \r\n                if total_iter != 0:\r\n                    # validate\r\n                    if (total_iter % config.dist_train.valid_every) == 0 or (\r\n                            total_iter % config.dist_train.error_rate_every) == 0:\r\n                        avg_valid_loss, avg_wer, avg_cer = evaluate(\r\n                            args, gpu, model, test_loader,\r\n                            tokenizer=test_loader.dataset.tokenizer,\r\n                            calc_wer=True\r\n                        )\r\n\r\n                        model.train()\r\n                        losses = []  # empty losses\r\n\r\n```\r\n\r\nStacktrace:\r\n![Screen Shot 2021-05-03 at 9 10 46 AM](https://user-images.githubusercontent.com/18520313/116880013-74cc1f80-abef-11eb-88de-8c02df4f1a9d.png)\r\n\r\nBehavior:\r\nTraining hangs, the message above is repeated.\r\n\r\nCan anyone yield any insight?\r\n\r\nThanks for your help!\r\nKevin", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2887/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2887/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2834", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2834/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2834/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2834/events", "html_url": "https://github.com/horovod/horovod/issues/2834", "id": 854706232, "node_id": "MDU6SXNzdWU4NTQ3MDYyMzI=", "number": 2834, "title": "ray status seems to require redis password", "user": {"login": "cupdike", "id": 133214, "node_id": "MDQ6VXNlcjEzMzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/133214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cupdike", "html_url": "https://github.com/cupdike", "followers_url": "https://api.github.com/users/cupdike/followers", "following_url": "https://api.github.com/users/cupdike/following{/other_user}", "gists_url": "https://api.github.com/users/cupdike/gists{/gist_id}", "starred_url": "https://api.github.com/users/cupdike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cupdike/subscriptions", "organizations_url": "https://api.github.com/users/cupdike/orgs", "repos_url": "https://api.github.com/users/cupdike/repos", "events_url": "https://api.github.com/users/cupdike/events{/privacy}", "received_events_url": "https://api.github.com/users/cupdike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-04-09T17:11:04Z", "updated_at": "2021-04-10T14:35:05Z", "closed_at": "2021-04-09T22:32:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "Ray 1.2.0 running ray status gets an exception suggesting redis authentication is failing:\r\n`redis.exceptions.ResponseError: WRONGPASS invalid username-password pair`\r\nThere is no way to provide the redis password running this command AFAICT.  \r\n\r\n```\r\n$ srun singularity run ~/horovodDocker/native_horray.sif ray --version\r\nray, version 1.2.0\r\n\r\n$ srun singularity run ~/horovodDocker/native_horray.sif ray status\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/ray\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.7/dist-packages/ray/scripts/scripts.py\", line 1519, in main\r\n    return cli()\r\n  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/ray/scripts/scripts.py\", line 1405, in status\r\n    status = redis_client.hget(DEBUG_AUTOSCALING_STATUS, \"value\")\r\n  File \"/usr/local/lib/python3.7/dist-packages/redis/client.py\", line 3010, in hget\r\n    return self.execute_command('HGET', name, key)\r\n  File \"/usr/local/lib/python3.7/dist-packages/redis/client.py\", line 898, in execute_command\r\n    conn = self.connection or pool.get_connection(command_name, **options)\r\n  File \"/usr/local/lib/python3.7/dist-packages/redis/connection.py\", line 1192, in get_connection\r\n    connection.connect()\r\n  File \"/usr/local/lib/python3.7/dist-packages/redis/connection.py\", line 567, in connect\r\n    self.on_connect()\r\n  File \"/usr/local/lib/python3.7/dist-packages/redis/connection.py\", line 643, in on_connect\r\n    auth_response = self.read_response()\r\n  File \"/usr/local/lib/python3.7/dist-packages/redis/connection.py\", line 756, in read_response\r\n    raise response\r\nredis.exceptions.ResponseError: WRONGPASS invalid username-password pair\r\nsrun: error: node1: task 0: Exited with exit code 1\r\n```\r\nAs requested, @richardliaw ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2834/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2834/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2831", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2831/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2831/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2831/events", "html_url": "https://github.com/horovod/horovod/issues/2831", "id": 854089303, "node_id": "MDU6SXNzdWU4NTQwODkzMDM=", "number": 2831, "title": "RuntimeError: CUDA error: invalid device ordinal", "user": {"login": "alfredyewang", "id": 10357779, "node_id": "MDQ6VXNlcjEwMzU3Nzc5", "avatar_url": "https://avatars.githubusercontent.com/u/10357779?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alfredyewang", "html_url": "https://github.com/alfredyewang", "followers_url": "https://api.github.com/users/alfredyewang/followers", "following_url": "https://api.github.com/users/alfredyewang/following{/other_user}", "gists_url": "https://api.github.com/users/alfredyewang/gists{/gist_id}", "starred_url": "https://api.github.com/users/alfredyewang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alfredyewang/subscriptions", "organizations_url": "https://api.github.com/users/alfredyewang/orgs", "repos_url": "https://api.github.com/users/alfredyewang/repos", "events_url": "https://api.github.com/users/alfredyewang/events{/privacy}", "received_events_url": "https://api.github.com/users/alfredyewang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2021-04-09T02:11:48Z", "updated_at": "2021-04-23T15:19:37Z", "closed_at": "2021-04-23T15:17:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework:  PyTorch\r\n2. Framework version:  1.7.1\r\n3. Horovod version: 0.21.3\r\n4. MPI version: openmpi/4.0.1\r\n5. CUDA version: 11.2\r\n6. NCCL version: 2.7.08\r\n7. Python version: 3.7.19\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version:  CentOS 7\r\n11. GCC version: gcc 4.8.5\r\n12. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\nYes.  https://github.com/horovod/horovod/issues/1586\r\n\r\n**Bug report:**\r\nSystem: 4 nodes each with 4 P100 GPUs. \r\n\r\nI am able to run my script on any 2 nodes each with 2 GPUs,  any 1 node each with 4 GPUs or 4 nodes each with 1 GPUs. But when I'm trying to run the script on 4 nodes each with 2/3/4 GPUs or 2 nodes each with 3/4 GPUs , it shows the following error:\r\n\r\n```\r\n[ywang17@yarrow06 fast_molvae]$ horovodrun --verbose --network-interface enp24s0f0  -np 8 -H localhost:4,yarrow07:4 --start-timeout 300  python hovord_test.py\r\nFiltering local host names.\r\nRemote host found: yarrow07\r\nChecking ssh on all remote hosts.\r\nSSH was successful into all the remote hosts.\r\nmpirun --allow-run-as-root --tag-output -np 8 -H localhost:4,yarrow07:4 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib  -mca btl_tcp_if_include enp24s0f0 -x NCCL_SOCKET_IFNAME=enp24s0f0  -x ARC -x CONDA_DEFAULT_ENV -x CONDA_EXE -x CONDA_PREFIX -x CONDA_PREFIX_1 -x CONDA_PROMPT_MODIFIER -x CONDA_PYTHON_EXE -x CONDA_SHLVL -x ENVIRONMENT -x HISTCONTROL -x HISTSIZE -x HOME -x HOSTNAME -x JOB_ID -x JOB_NAME -x JOB_SCRIPT -x LANG -x LD_LIBRARY_PATH -x LD_RUN_PATH -x LESSOPEN -x LOADEDMODULES -x LOGNAME -x LS_COLORS -x MAIL -x MANPATH -x MODULEPATH -x MODULESHOME -x MODULE_VERSION -x MODULE_VERSION_STACK -x NHOSTS -x NQUEUES -x NSLOTS -x OMPIDIR -x PATH -x PE -x PE_HOSTFILE -x PWD -x QRSH_COMMAND -x QUEUE -x REQNAME -x REQUEST -x RESTARTED -x SGE_ACCOUNT -x SGE_ARCH -x SGE_BINARY_PATH -x SGE_CELL -x SGE_CLUSTER_NAME -x SGE_CWD_PATH -x SGE_HGR_TASK_ngpus -x SGE_HGR_ngpus -x SGE_JOB_SPOOL_DIR -x SGE_O_HOME -x SGE_O_HOST -x SGE_O_LOGNAME -x SGE_O_MAIL -x SGE_O_PATH -x SGE_O_SHELL -x SGE_O_WORKDIR -x SGE_RERUN_JOB -x SGE_RERUN_REQUESTED -x SGE_ROOT -x SGE_RSH_COMMAND -x SGE_STDERR_PATH -x SGE_STDIN_PATH -x SGE_STDOUT_PATH -x SGE_TASK_FIRST -x SGE_TASK_ID -x SGE_TASK_LAST -x SGE_TASK_STEPSIZE -x SHELL -x SHLVL -x TERM -x TMPDIR -x USER -x USE_SYSTEMD -x XDG_DATA_DIRS -x _ -x _CE_CONDA -x _CE_M -x _LMFILES_  python hovord_test.py\r\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\n[1,6]<stderr>:Traceback (most recent call last):\r\n[1,6]<stderr>:  File \"hovord_test.py\", line 126, in <module>\r\n[1,6]<stderr>:    torch.cuda.set_device(hvd.local_rank())\r\n[1,6]<stderr>:  File \"/home/ywang17/.conda/envs/chem3/lib/python3.7/site-packages/torch/cuda/__init__.py\", line 263, in set_device\r\n[1,6]<stderr>:    torch._C._cuda_setDevice(device)\r\n[1,6]<stderr>:RuntimeError: CUDA error: invalid device ordinal\r\n[1,5]<stderr>:Traceback (most recent call last):\r\n[1,5]<stderr>:  File \"hovord_test.py\", line 126, in <module>\r\n[1,5]<stderr>:    torch.cuda.set_device(hvd.local_rank())\r\n[1,5]<stderr>:  File \"/home/ywang17/.conda/envs/chem3/lib/python3.7/site-packages/torch/cuda/__init__.py\", line 263, in set_device\r\n[1,5]<stderr>:    torch._C._cuda_setDevice(device)\r\n[1,5]<stderr>:RuntimeError: CUDA error: invalid device ordinal\r\n[1,4]<stderr>:Traceback (most recent call last):\r\n[1,4]<stderr>:  File \"hovord_test.py\", line 126, in <module>\r\n[1,4]<stderr>:    torch.cuda.set_device(hvd.local_rank())\r\n[1,4]<stderr>:  File \"/home/ywang17/.conda/envs/chem3/lib/python3.7/site-packages/torch/cuda/__init__.py\", line 263, in set_device\r\n[1,4]<stderr>:    torch._C._cuda_setDevice(device)\r\n[1,4]<stderr>:RuntimeError: CUDA error: invalid device ordinal\r\n[1,7]<stderr>:Traceback (most recent call last):\r\n[1,7]<stderr>:  File \"hovord_test.py\", line 126, in <module>\r\n[1,7]<stderr>:    torch.cuda.set_device(hvd.local_rank())\r\n[1,7]<stderr>:  File \"/home/ywang17/.conda/envs/chem3/lib/python3.7/site-packages/torch/cuda/__init__.py\", line 263, in set_device\r\n[1,7]<stderr>:    torch._C._cuda_setDevice(device)\r\n[1,7]<stderr>:RuntimeError: CUDA error: invalid device ordinal\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun detected that one or more processes exited with non-zero status, thus causing\r\nthe job to be terminated. The first process to do so was:\r\n\r\n  Process name: [[18705,1],6]\r\n  Exit code:    1\r\n--------------------------------------------------------------------------\r\n```\r\n\r\nAny suggestion? Thank you in advance.\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2831/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2831/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2827", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2827/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2827/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2827/events", "html_url": "https://github.com/horovod/horovod/issues/2827", "id": 852653482, "node_id": "MDU6SXNzdWU4NTI2NTM0ODI=", "number": 2827, "title": "Task/Actor cannot be scheduled even though resources are available", "user": {"login": "cupdike", "id": 133214, "node_id": "MDQ6VXNlcjEzMzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/133214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cupdike", "html_url": "https://github.com/cupdike", "followers_url": "https://api.github.com/users/cupdike/followers", "following_url": "https://api.github.com/users/cupdike/following{/other_user}", "gists_url": "https://api.github.com/users/cupdike/gists{/gist_id}", "starred_url": "https://api.github.com/users/cupdike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cupdike/subscriptions", "organizations_url": "https://api.github.com/users/cupdike/orgs", "repos_url": "https://api.github.com/users/cupdike/repos", "events_url": "https://api.github.com/users/cupdike/events{/privacy}", "received_events_url": "https://api.github.com/users/cupdike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2021-04-07T17:52:06Z", "updated_at": "2021-04-08T18:37:23Z", "closed_at": "2021-04-08T18:37:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "On Horovod 0.21.3 (Ray 1.2.0), a WARNING is incorrectly reporting lack of resources trying to run the Horovod/Ray Mnist example (tensorflow2_mnist_ray.py) on SLURM.  It's a warning but it prevents training from running.  It's running on a single node with 40 CPU and 3 GPU.  I launch it like this:\r\n\r\n```\r\n# HEAD\r\nsrun  --nodes=1  --ntasks=1 -w apl-redd-ai02.datalake.jhuapl.edu --cpus-per-task=5 singularity run ~/horovodDocker/native_horray.sif  ray start  --head  --node-ip-address=30.30.30.30  --port=6379  --redis-password=supersecret  --num-cpus 5 --num-gpus 0  --include-dashboard False  --block &\r\n\r\n# WORKER\r\nsrun  --nodes=1  --ntasks=1  --cpus-per-task=5 --gres=gpu:1 -w apl-redd-ai02.datalake.jhuapl.edu singularity run ~/horovodDocker/native_horray.sif ray start --address 30.30.30.30:6379  --redis-password=supersecret --num-cpus 5 --num-gpus 0  --block &\r\n\r\n# Training script\r\nsrun --nodes=1 --ntasks=1 singularity run ~/horovodDocker/native_horray.sif python horray_mnist.py --address 30.30.30.30:6379 --redis_password supersecret\r\n```\r\n\r\nI stripped down the RayExecutor to use barely any resources:\r\n\r\n```\r\nexecutor = RayExecutor(settings, num_hosts=1, num_slots=3, use_gpu=False, cpus_per_slot=4)`\r\n```\r\n\r\nI'm getting this:\r\n\r\n```2021-04-07 14:10:01,526\tWARNING worker.py:1107 -- The actor or task with ID ffffffffffffffffa01c95bc3d119e36e40b31b204000000 cannot be scheduled right now. It requires {CPU: 12.000000} for placement, however the cluster currently cannot provide the requested resources. The required resources may be added as autoscaling takes place or placement groups are scheduled. Otherwise, consider reducing the resource requirements of the task.```\r\n\r\nEven though there are plenty of resources available:\r\n\r\n```\r\nscontrol show node\r\nNodeName=************* Arch=x86_64 CoresPerSocket=12 \r\n   CPUAlloc=12 CPUTot=48 CPULoad=0.16\r\n   AvailableFeatures=(null)\r\n   ActiveFeatures=(null)\r\n   Gres=gpu:3(S:0-1)\r\n   RealMemory=90185 AllocMem=0 FreeMem=6034 Sockets=2 Boards=1\r\n   State=MIXED ThreadsPerCore=2 TmpDisk=0 Weight=1 Owner=N/A MCS_label=N/A\r\n   Partitions=batch \r\n   BootTime=2020-12-07T20:50:20 SlurmdStartTime=2021-01-15T14:47:14\r\n   CfgTRES=cpu=48,mem=90185M,billing=48,gres/gpu=3\r\n   AllocTRES=cpu=12,gres/gpu=1\r\n   CapWatts=n/a\r\n   CurrentWatts=0 AveWatts=0\r\n   ExtSensorsJoules=n/s ExtSensorsWatts=0 ExtSensorsTemp=n/s\r\n```\r\n\r\nAny ideas what is causing this?\r\n\r\nTIA @richardliaw", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2827/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2827/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2823", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2823/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2823/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2823/events", "html_url": "https://github.com/horovod/horovod/issues/2823", "id": 851163626, "node_id": "MDU6SXNzdWU4NTExNjM2MjY=", "number": 2823, "title": "Segment fault when running the rossman dataset in distribution mode", "user": {"login": "JkSelf", "id": 11972570, "node_id": "MDQ6VXNlcjExOTcyNTcw", "avatar_url": "https://avatars.githubusercontent.com/u/11972570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JkSelf", "html_url": "https://github.com/JkSelf", "followers_url": "https://api.github.com/users/JkSelf/followers", "following_url": "https://api.github.com/users/JkSelf/following{/other_user}", "gists_url": "https://api.github.com/users/JkSelf/gists{/gist_id}", "starred_url": "https://api.github.com/users/JkSelf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JkSelf/subscriptions", "organizations_url": "https://api.github.com/users/JkSelf/orgs", "repos_url": "https://api.github.com/users/JkSelf/repos", "events_url": "https://api.github.com/users/JkSelf/events{/privacy}", "received_events_url": "https://api.github.com/users/JkSelf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-04-06T08:18:50Z", "updated_at": "2021-05-27T07:53:43Z", "closed_at": "2021-05-27T07:53:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\nFramework: (TensorFlow, PyTorch)\r\nFramework version:\r\nHorovod version: v0.21.3\r\nMPI version:\r\nCUDA version:\r\nNCCL version:\r\nPython version: 3.6\r\nOS and version: centos 7\r\nGCC version: 9.3\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nWhen I run the rossman dateset using distribution mode, I get the following error when connect the hdfs file system.\r\n![image](https://user-images.githubusercontent.com/11972570/113679926-e6997200-96f2-11eb-866f-6053b00b6ce3.png)\r\n\r\nThe start command is :\r\n![image](https://user-images.githubusercontent.com/11972570/113680438-6a535e80-96f3-11eb-9feb-4509c51db7f0.png)\r\n\r\nSpark Version: 2.4\r\nHadoop Version: 2.7.3\r\nPyarrow Version: 3.0\r\n\r\n@tgaddair Can you help me with this issue? Thanks for your help !", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2823/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2823/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2821", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2821/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2821/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2821/events", "html_url": "https://github.com/horovod/horovod/issues/2821", "id": 850469978, "node_id": "MDU6SXNzdWU4NTA0Njk5Nzg=", "number": 2821, "title": "hvd-pytorch: Multi Optimizer Issue observed in FutureGAN", "user": {"login": "jcsmik", "id": 81972226, "node_id": "MDQ6VXNlcjgxOTcyMjI2", "avatar_url": "https://avatars.githubusercontent.com/u/81972226?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jcsmik", "html_url": "https://github.com/jcsmik", "followers_url": "https://api.github.com/users/jcsmik/followers", "following_url": "https://api.github.com/users/jcsmik/following{/other_user}", "gists_url": "https://api.github.com/users/jcsmik/gists{/gist_id}", "starred_url": "https://api.github.com/users/jcsmik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jcsmik/subscriptions", "organizations_url": "https://api.github.com/users/jcsmik/orgs", "repos_url": "https://api.github.com/users/jcsmik/repos", "events_url": "https://api.github.com/users/jcsmik/events{/privacy}", "received_events_url": "https://api.github.com/users/jcsmik/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-04-05T16:01:35Z", "updated_at": "2021-04-19T14:20:05Z", "closed_at": "2021-04-19T14:20:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: pytorch\r\n2. Framework version: 1.6\r\n3. Horovod version: 0.19.5\r\n4. CUDA version: 11.0.167\r\n5. NCCL version: 2.7.5\r\n6. Python version: 3.6\r\n7. OS and version: Ubuntu 18.04\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? No\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? No\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Bug report:**\r\nHi @tgaddair would you please help in resolving the following error, i tried to resolve by referring to your suggestions in #2559   , #2154 .\r\n\r\nRuntimeError: Gradients were computed more than backward_passes_per_step times before call to step(). Increase backward_passes_per_step to accumulate gradients locally\r\n\r\nThe FutureGAN model implementation can be found in https://github.com/TUM-LMF/FutureGAN. \r\nAttaching the training script which is modified for Horovod based distributed training.\r\n[train_trial.py.txt](https://github.com/horovod/horovod/files/6259043/train_trial.py.txt)\r\n\r\nThank you.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2821/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2821/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2811", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2811/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2811/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2811/events", "html_url": "https://github.com/horovod/horovod/issues/2811", "id": 848300352, "node_id": "MDU6SXNzdWU4NDgzMDAzNTI=", "number": 2811, "title": "Issues while using Horovod (spark,keras) for distributed training", "user": {"login": "Aishwarya2703", "id": 81746913, "node_id": "MDQ6VXNlcjgxNzQ2OTEz", "avatar_url": "https://avatars.githubusercontent.com/u/81746913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aishwarya2703", "html_url": "https://github.com/Aishwarya2703", "followers_url": "https://api.github.com/users/Aishwarya2703/followers", "following_url": "https://api.github.com/users/Aishwarya2703/following{/other_user}", "gists_url": "https://api.github.com/users/Aishwarya2703/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aishwarya2703/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aishwarya2703/subscriptions", "organizations_url": "https://api.github.com/users/Aishwarya2703/orgs", "repos_url": "https://api.github.com/users/Aishwarya2703/repos", "events_url": "https://api.github.com/users/Aishwarya2703/events{/privacy}", "received_events_url": "https://api.github.com/users/Aishwarya2703/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2021-04-01T09:33:20Z", "updated_at": "2021-04-12T15:24:47Z", "closed_at": "2021-04-12T15:24:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version:\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nI was trying to implement distributed training framework with Horovod (spark , keras ) on MNIST dataset. But facing an issue while fitting the model on training data.\r\n\r\nThe code is failing at this point of the code -\r\nkeras_model = keras_estimator.fit(train_df).setOutputCols(['label_prob'])\r\n\r\nAnd giving following error -\r\nIndexError: list index out of range\r\n\r\nRuntimeError: Horovod detected that one or more processes exited with non-zero status, thus causing the job to be terminated. The first process to do so was:\r\nProcess name: 0\r\nExit code: 127\r\n\r\nI have also set following flags:\r\nos.environ.pop('TF_CONFIG', None)\r\nos.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n\r\nRefering this code : https://github.com/horovod/horovod/blob/master/examples/spark/keras/keras_spark_mnist.py\r\n\r\nCould you help on this ?\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2811/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2811/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2806", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2806/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2806/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2806/events", "html_url": "https://github.com/horovod/horovod/issues/2806", "id": 846074143, "node_id": "MDU6SXNzdWU4NDYwNzQxNDM=", "number": 2806, "title": "error when set backward_passes_per_step > 1 in tensorflow keras", "user": {"login": "tiandongtao", "id": 29449381, "node_id": "MDQ6VXNlcjI5NDQ5Mzgx", "avatar_url": "https://avatars.githubusercontent.com/u/29449381?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tiandongtao", "html_url": "https://github.com/tiandongtao", "followers_url": "https://api.github.com/users/tiandongtao/followers", "following_url": "https://api.github.com/users/tiandongtao/following{/other_user}", "gists_url": "https://api.github.com/users/tiandongtao/gists{/gist_id}", "starred_url": "https://api.github.com/users/tiandongtao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tiandongtao/subscriptions", "organizations_url": "https://api.github.com/users/tiandongtao/orgs", "repos_url": "https://api.github.com/users/tiandongtao/repos", "events_url": "https://api.github.com/users/tiandongtao/events{/privacy}", "received_events_url": "https://api.github.com/users/tiandongtao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2021-03-31T07:23:07Z", "updated_at": "2021-05-06T23:08:44Z", "closed_at": "2021-05-06T23:08:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) \r\n2. Framework version: (1.15, 2.3.1, 1.6.0, 1.6.0)\r\n3. Horovod version: 0.21.3\r\n4. MPI version:\r\n5. CUDA version:10.0\r\n6. NCCL version:\r\n7. Python version:3.7\r\n8. Spark / PySpark version:\r\n9. Ray version:\r\n10. OS and version:\r\n11. GCC version:\r\n12. CMake version:\r\n\r\n**Bug report:**\r\nwhen set backward_passes_per_step > 1 and sparse_as_dense True , execute mpirun -np 2 --allow-run-as-root python test.py   it output error\r\nhere is code \r\n ```python\r\nfrom __future__ import print_function\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nfrom bert4keras.backend import keras, K\r\nfrom bert4keras.layers import Loss\r\nfrom bert4keras.models import build_transformer_model\r\nfrom bert4keras.tokenizers import Tokenizer, load_vocab\r\nfrom bert4keras.optimizers import Adam\r\nfrom bert4keras.snippets import sequence_padding, open\r\nfrom bert4keras.snippets import DataGenerator, AutoRegressiveDecoder\r\nfrom keras.models import Model\r\nfrom rouge import Rouge  # pip install rouge\r\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\r\nimport pdb\r\nimport os\r\nimport tensorflow as tf\r\nimport keras\r\nimport horovod.tensorflow.keras as hvd\r\n\r\nhvd.init()\r\n\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nconfig.gpu_options.visible_device_list = str(hvd.local_rank())\r\nK.set_session(tf.Session(config=config))\r\n\r\nopt = Adam(1e-5 * hvd.size())\r\nopt = hvd.DistributedOptimizer(opt, backward_passes_per_step=2, sparse_as_dense=True)\r\n```\r\n\r\n\r\noutput error log :\r\n\r\n```bash\r\nMore specifically: Substructure \"type=IndexedSlices str=IndexedSlices(indices=Tensor(\"training/Adam/gradients/Embedding-Segment/embedding_lookup_grad/Reshape_1:0\", shape=(?,), dtype=int32), values=Tensor(\"training/Adam/gradients/Embedding-Segment/embedding_lookup_grad/Reshape:0\", shape=(?, 768), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/Embedding-Segment/embedding_lookup_grad/Const:0\", shape=(2,), dtype=int32))\" is a sequence, while substructure \"type=Tensor str=Tensor(\"training/Adam/cond_1/truediv_1:0\", shape=(2, 768), dtype=float32)\" is not\r\nEntire first structure:\r\n[., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., .]\r\nEntire second structure:\r\n[., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., .]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 223, in <module>\r\n    verbose=1 if hvd.rank() == 0 else 0\r\n  File \"/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1732, in fit_generator\r\n    initial_epoch=initial_epoch)\r\n  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator.py\", line 42, in fit_generator\r\n    model._make_train_function()\r\n  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 316, in _make_train_function\r\n    loss=self.total_loss)\r\n  File \"/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/keras/optimizers.py\", line 504, in get_updates\r\n    grads = self.get_gradients(loss, params)\r\n  File \"/usr/local/lib/python3.7/dist-packages/horovod/_keras/__init__.py\", line 106, in get_gradients\r\n    return self._allreduce(gradients, params)\r\n  File \"/usr/local/lib/python3.7/dist-packages/horovod/_keras/__init__.py\", line 121, in _allreduce\r\n    return self._agg_helper.compute_gradients(tuple(grads), tuple(vars))\r\n  File \"/usr/local/lib/python3.7/dist-packages/horovod/tensorflow/gradient_aggregation.py\", line 208, in compute_gradients\r\n    lambda: grads,\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 1260, in cond\r\n    \"Incompatible return values of true_fn and false_fn: {}\".format(e))\r\nValueError: Incompatible return values of true_fn and false_fn: The two structures don't have the same nested structure.\r\n```\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2806/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2806/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2804", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2804/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2804/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2804/events", "html_url": "https://github.com/horovod/horovod/issues/2804", "id": 844923334, "node_id": "MDU6SXNzdWU4NDQ5MjMzMzQ=", "number": 2804, "title": "Unexpected performance decrease after hvd.init on CPU nodes", "user": {"login": "casparvl", "id": 33718780, "node_id": "MDQ6VXNlcjMzNzE4Nzgw", "avatar_url": "https://avatars.githubusercontent.com/u/33718780?v=4", "gravatar_id": "", "url": "https://api.github.com/users/casparvl", "html_url": "https://github.com/casparvl", "followers_url": "https://api.github.com/users/casparvl/followers", "following_url": "https://api.github.com/users/casparvl/following{/other_user}", "gists_url": "https://api.github.com/users/casparvl/gists{/gist_id}", "starred_url": "https://api.github.com/users/casparvl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/casparvl/subscriptions", "organizations_url": "https://api.github.com/users/casparvl/orgs", "repos_url": "https://api.github.com/users/casparvl/repos", "events_url": "https://api.github.com/users/casparvl/events{/privacy}", "received_events_url": "https://api.github.com/users/casparvl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 23, "created_at": "2021-03-30T17:22:27Z", "updated_at": "2021-05-10T13:49:35Z", "closed_at": "2021-04-28T17:16:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.3.1\r\n3. Horovod version: 0.21.0\r\n4. MPI version: OpenMPI-4.0.3\r\n5. CUDA version: 11.0.2\r\n6. NCCL version: 2.7.8\r\n7. Python version: 3.8.2\r\n8. Spark / PySpark version: N/A\r\n9. Ray version: N/A\r\n10. OS and version: Red Hat Enterprise Linux Server release 7.9 (Maipo) \r\n11. GCC version: 9.3.0\r\n12. CMake version: 3.16.4\r\n\r\n**Bug report:**\r\n\r\nI see an unexpected performance decrease when running Horovod (using a single MPI rank) compared to just native TensorFlow. Essentially, I have a slightly altered version of the `tensorflow2_synthetic_benchmark.py` (see [here](https://github.com/casparvl/software-layer/blob/tensorflow/tests/reframe/eessi-checks/applications/src/tensorflow2_synthetic_benchmark.py)) to which I've added an extra argument `--use-horovod`. With that argument, it runs the exact same example, but with native tensorflow (i.e. it skips the hvd.init(), skips the wrapping in the Horovod distributed gradient tape, etc).\r\n\r\nNow, I performed 4 different runs all using a single rank. Run 1 & 2 were performed on a GPU node, run 3 & 4 on a CPU node.\r\n\r\n1. `srun -n 1 python tensorflow2_synthetic_benchmark.py --model ResNet50 --batch-size 32 --num-iters 5 --num-batches-per-iter 5 --num-warmup-batches 5`\r\n2. `srun -n 1 python tensorflow2_synthetic_benchmark.py --model ResNet50 --batch-size 32 --num-iters 5 --num-batches-per-iter 5 --num-warmup-batches 5 --use-horovod`\r\n3. `srun -n 1 python tensorflow2_synthetic_benchmark.py --model ResNet50 --batch-size 32 --num-iters 5 --num-batches-per-iter 5 --num-warmup-batches 5 --no-cuda`\r\n4. `srun -n 1 python tensorflow2_synthetic_benchmark.py --model ResNet50 --batch-size 32 --num-iters 5 --num-batches-per-iter 5 --num-warmup-batches 5 --no-cuda --use-horovod`\r\n\r\nAnd the the respective performance numbers are:\r\n\r\n1.  51.7 img/s\r\n2. 50.0 img/s\r\n3. 28.7 img/s\r\n4. 6.9 img/s\r\n\r\nClearly, I'm wondering about that last result. \r\n\r\nI've checked a horovod timeline, there's virtually nothing there (I see the broadcast operations, but as expected a broadcast with one worker only takes a few microseconds).\r\n\r\nFinally, I nailed it down to the hvd.init(): if I repeat run 3, but only add the lines\r\n```\r\nimport horovod.tensorflow as hvd\r\nhvd.init()\r\n```\r\nThat's when my performance drops (note: only importing the horovod.tensorflow module doesn't change the performance, it's really the `hvd.init()` that causes the performance drop).\r\n\r\nWould you have any idea what is causing the performance difference between run 3 and 4, as defined above? I saw that `horovodrun` has an option to disable mpi-thread support and mentions this sometimes 'can slow down other components'. Is there an equivalent way of disabling mpi-thread support when launching with other mpi wrappers such as `mpirun` or `srun`? (I thought I remember an environment variable that could be set, but can't seem to find it... )", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2804/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2804/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2800", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2800/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2800/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2800/events", "html_url": "https://github.com/horovod/horovod/issues/2800", "id": 843393900, "node_id": "MDU6SXNzdWU4NDMzOTM5MDA=", "number": 2800, "title": "Segmentation fault when running the keras_spark_rossmann_estimator.py with MLflow model serving", "user": {"login": "JkSelf", "id": 11972570, "node_id": "MDQ6VXNlcjExOTcyNTcw", "avatar_url": "https://avatars.githubusercontent.com/u/11972570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JkSelf", "html_url": "https://github.com/JkSelf", "followers_url": "https://api.github.com/users/JkSelf/followers", "following_url": "https://api.github.com/users/JkSelf/following{/other_user}", "gists_url": "https://api.github.com/users/JkSelf/gists{/gist_id}", "starred_url": "https://api.github.com/users/JkSelf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JkSelf/subscriptions", "organizations_url": "https://api.github.com/users/JkSelf/orgs", "repos_url": "https://api.github.com/users/JkSelf/repos", "events_url": "https://api.github.com/users/JkSelf/events{/privacy}", "received_events_url": "https://api.github.com/users/JkSelf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-03-29T13:53:34Z", "updated_at": "2021-05-27T07:53:54Z", "closed_at": "2021-05-27T07:53:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\nFramework: (TensorFlow, PyTorch)\r\nFramework version:\r\nHorovod version: v0.21.3\r\nMPI version:\r\nCUDA version:\r\nNCCL version:\r\nPython version: 3.6\r\nOS and version: centos 7\r\nGCC version: 9.3\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nHi all,\r\n\r\nI can run the keras_spark_rossmann_estimator.py in standalone mode with 1 node. But when I integrated with the MLflow model serving by adding the following code, I encountered the segmentation fault issue and cannot find any stack info.\r\n`with mlflow.start_run() as run:   \r\n      keras_model = keras_estimator.fit(train_df).setOutputCols(['Sales_output'])\r\n      mlflow.keras.log_model(keras_model , \"horovod keras models\")\r\n    mlflow.end_run()`\r\n\r\n@tgaddair  Can you help me with this issue? Thanks for your help very much!", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2800/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2800/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2727", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2727/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2727/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2727/events", "html_url": "https://github.com/horovod/horovod/issues/2727", "id": 836182594, "node_id": "MDU6SXNzdWU4MzYxODI1OTQ=", "number": 2727, "title": "Installation via `pip install -e .` doesn't work on OSX", "user": {"login": "amogkam", "id": 8068268, "node_id": "MDQ6VXNlcjgwNjgyNjg=", "avatar_url": "https://avatars.githubusercontent.com/u/8068268?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amogkam", "html_url": "https://github.com/amogkam", "followers_url": "https://api.github.com/users/amogkam/followers", "following_url": "https://api.github.com/users/amogkam/following{/other_user}", "gists_url": "https://api.github.com/users/amogkam/gists{/gist_id}", "starred_url": "https://api.github.com/users/amogkam/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amogkam/subscriptions", "organizations_url": "https://api.github.com/users/amogkam/orgs", "repos_url": "https://api.github.com/users/amogkam/repos", "events_url": "https://api.github.com/users/amogkam/events{/privacy}", "received_events_url": "https://api.github.com/users/amogkam/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2021-03-19T16:39:53Z", "updated_at": "2021-04-06T19:30:53Z", "closed_at": "2021-04-06T19:30:52Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): Torch\r\n2. Framework version: torch v1.8.0\r\n3. Horovod version: Master\r\n4. MPI version: N/A\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.8.6\r\n8. Spark / PySpark version: N/A\r\n9. OS and version: macOS Catalina 10.15.7\r\n10. GCC version: 11.0.3\r\n11. CMake version: 3.17.3\r\n\r\n**Bug report:**\r\nI've cloned the repo and am trying to install horovod master on my Mac like so `HOROVOD_WITH_GLOO=1 HOROVOD_WITHOUT_MPI=1 HOROVOD_WITHOUT_MXNET=1 HOROVOD_WITHOUT_TENSORFLOW=1 pip install --no-cache-dir -U -e .`\r\n\r\nBut it is failing with the following error\r\n```\r\nObtaining file:///Users/amog/dev/horovod\r\nRequirement already satisfied: cloudpickle in /Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages (from horovod==0.21.3) (1.6.0)\r\nRequirement already satisfied: psutil in /Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages (from horovod==0.21.3) (5.8.0)\r\nRequirement already satisfied: pyyaml in /Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages (from horovod==0.21.3) (5.3.1)\r\nRequirement already satisfied: cffi>=1.4.0 in /Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages (from horovod==0.21.3) (1.14.5)\r\nRequirement already satisfied: pycparser in /Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages (from cffi>=1.4.0->horovod==0.21.3) (2.20)\r\nInstalling collected packages: horovod\r\n  Attempting uninstall: horovod\r\n    Found existing installation: horovod 0.21.3\r\n    Uninstalling horovod-0.21.3:\r\n      Successfully uninstalled horovod-0.21.3\r\n  Running setup.py develop for horovod\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /Users/amog/dev/ray_lightning_accelerators/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/Users/amog/dev/horovod/setup.py'\"'\"'; __file__='\"'\"'/Users/amog/dev/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\r\n         cwd: /Users/amog/dev/horovod/\r\n    Complete output (95 lines):\r\n    running develop\r\n    running egg_info\r\n    writing horovod.egg-info/PKG-INFO\r\n    writing dependency_links to horovod.egg-info/dependency_links.txt\r\n    writing entry points to horovod.egg-info/entry_points.txt\r\n    writing requirements to horovod.egg-info/requires.txt\r\n    writing top-level names to horovod.egg-info/top_level.txt\r\n    reading manifest file 'horovod.egg-info/SOURCES.txt'\r\n    reading manifest template 'MANIFEST.in'\r\n    warning: no files found matching '*.hpp' under directory '*'\r\n    no previously-included directories found matching '.eggs'\r\n    warning: no directories found matching 'third_party/eigen/Eigen'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/Eigen'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/IterativeLinearSolvers'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/MetisSupport'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/Sparse'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/SparseCholesky'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/SparseLU'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/src/IterativeSolvers/*'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/src/OrderingMethods/Amd.h'\r\n    warning: no previously-included files found matching 'third_party/eigen/Eigen/src/SparseCholesky/*'\r\n    warning: no previously-included files found matching 'third_party/eigen/unsupported/test/mpreal/mpreal.h'\r\n    warning: no previously-included files found matching 'third_party/eigen/unsupported/Eigen/FFT'\r\n    warning: no previously-included files found matching 'third_party/eigen/unsupported/Eigen/MPRealSupport'\r\n    warning: no previously-included files found matching 'third_party/eigen/doc/PreprocessorDirectives.dox'\r\n    warning: no previously-included files found matching 'third_party/eigen/doc/UsingIntelMKL.dox'\r\n    warning: no previously-included files found matching 'third_party/eigen/doc/SparseLinearSystems.dox'\r\n    warning: no previously-included files found matching 'third_party/eigen/COPYING.GPL'\r\n    warning: no previously-included files found matching 'third_party/eigen/COPYING.LGPL'\r\n    warning: no previously-included files found matching 'third_party/eigen/COPYING.README'\r\n    warning: no directories found matching 'third_party/gloo/cmake'\r\n    warning: no files found matching 'CMakeLists.txt' under directory 'third_party/gloo'\r\n    warning: no files found matching '*.in' under directory 'third_party/gloo'\r\n    writing manifest file 'horovod.egg-info/SOURCES.txt'\r\n    running build_ext\r\n    -- Could not find CCache. Consider installing CCache to speed up compilation.\r\n    -- Build architecture flags:\r\n    -- Using command /Users/amog/dev/ray_lightning_accelerators/bin/python3\r\n    CMake Error at CMakeLists.txt:248 (add_subdirectory):\r\n      The source directory\r\n\r\n        /Users/amog/dev/horovod/third_party/gloo\r\n\r\n      does not contain a CMakeLists.txt file.\r\n\r\n\r\n    CMake Error at CMakeLists.txt:250 (target_compile_definitions):\r\n      Cannot specify compile definitions for target \"gloo\" which is not built by\r\n      this project.\r\n\r\n\r\n    CMake Error at CMakeLists.txt:314 (add_subdirectory):\r\n      The source directory\r\n\r\n        /Users/amog/dev/horovod/third_party/compatible_gloo\r\n\r\n      does not contain a CMakeLists.txt file.\r\n\r\n\r\n    CMake Error at CMakeLists.txt:315 (target_compile_definitions):\r\n      Cannot specify compile definitions for target \"compatible_gloo\" which is\r\n      not built by this project.\r\n\r\n\r\n    -- Configuring incomplete, errors occurred!\r\n    See also \"/Users/amog/dev/horovod/build/temp.macosx-10.15-x86_64-3.8/CMakeFiles/CMakeOutput.log\".\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/Users/amog/dev/horovod/setup.py\", line 151, in <module>\r\n        setup(name='horovod',\r\n      File \"/Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages/setuptools/__init__.py\", line 165, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/distutils/dist.py\", line 966, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages/setuptools/command/develop.py\", line 38, in run\r\n        self.install_for_development()\r\n      File \"/Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages/setuptools/command/develop.py\", line 140, in install_for_development\r\n        self.run_command('build_ext')\r\n      File \"/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages/setuptools/command/build_ext.py\", line 87, in run\r\n        _build_ext.run(self)\r\n      File \"/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/distutils/command/build_ext.py\", line 340, in run\r\n        self.build_extensions()\r\n      File \"/Users/amog/dev/horovod/setup.py\", line 93, in build_extensions\r\n        subprocess.check_call([cmake_bin, self.extensions[0].cmake_lists_dir] + cmake_args,\r\n      File \"/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/subprocess.py\", line 364, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['cmake', '/Users/amog/dev/horovod', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/Users/amog/dev/horovod/build/lib.macosx-10.15-x86_64-3.8', '-DPYTHON_EXECUTABLE:FILEPATH=/Users/amog/dev/ray_lightning_accelerators/bin/python3']' returned non-zero exit status 1.\r\n    ----------------------------------------\r\n  Rolling back uninstall of horovod\r\n  Moving to /Users/amog/dev/ray_lightning_accelerators/bin/horovodrun\r\n   from /private/var/folders/qt/f7ftj_xs6fn_swc4vn7kx0y80000gn/T/pip-uninstall-nvbmuvkt/horovodrun\r\n  Moving to /Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages/horovod-0.21.3.dist-info/\r\n   from /Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages/~orovod-0.21.3.dist-info\r\n  Moving to /Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages/horovod/\r\n   from /Users/amog/dev/ray_lightning_accelerators/lib/python3.8/site-packages/~orovod\r\nERROR: Command errored out with exit status 1: /Users/amog/dev/ray_lightning_accelerators/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/Users/amog/dev/horovod/setup.py'\"'\"'; __file__='\"'\"'/Users/amog/dev/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps Check the logs for full command output.\r\n```\r\n\r\nSame error also happens with just a normal `pip install --no-cache-dir -U -e .`.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2727/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2727/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2715", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2715/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2715/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2715/events", "html_url": "https://github.com/horovod/horovod/issues/2715", "id": 828307981, "node_id": "MDU6SXNzdWU4MjgzMDc5ODE=", "number": 2715, "title": "Bug in global_step update when local gradient aggregation is used", "user": {"login": "mnabian", "id": 20804484, "node_id": "MDQ6VXNlcjIwODA0NDg0", "avatar_url": "https://avatars.githubusercontent.com/u/20804484?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mnabian", "html_url": "https://github.com/mnabian", "followers_url": "https://api.github.com/users/mnabian/followers", "following_url": "https://api.github.com/users/mnabian/following{/other_user}", "gists_url": "https://api.github.com/users/mnabian/gists{/gist_id}", "starred_url": "https://api.github.com/users/mnabian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mnabian/subscriptions", "organizations_url": "https://api.github.com/users/mnabian/orgs", "repos_url": "https://api.github.com/users/mnabian/repos", "events_url": "https://api.github.com/users/mnabian/events{/privacy}", "received_events_url": "https://api.github.com/users/mnabian/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-03-10T20:40:31Z", "updated_at": "2021-04-28T22:15:37Z", "closed_at": "2021-04-28T22:15:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.15.3\r\n3. Horovod version: 0.21.3\r\n4. MPI version: 3.1.6\r\n5. CUDA version: 11.0.194\r\n6. NCCL version: 2.7.6\r\n7. Python version: 3.6.9\r\n8. Spark / PySpark version:\r\n9. OS and version: \r\n10. GCC version:\r\n11. CMake version:\r\n\r\n**Bug report:**\r\nThere seems to be a bug in how the `global_step` variable is updated when using local gradient aggregation with `backward_passes_per_step>1`. \r\n\r\nHere is a simple example to reproduce the issue:\r\n```\r\nimport tensorflow as tf\r\nimport horovod.tensorflow as hvd\r\n\r\ntf.disable_eager_execution()\r\nLR=0.01\r\n# data/label is always just 1\r\ndata = tf.constant([[1]], dtype=tf.float32)\r\n# one-variable linear model, no bias (y = w*x)\r\n#\r\n# gradient update is hand-calculatable if needed for testing:\r\n#\r\n# model:            yhat = w*x\r\n# mse loss:         L = (ytrue - w*x)**2\r\n# gradient:         dL/dw = -2*x*(ytrue - `w*x)`\r\n# let ytrue = x:    dL/dw = -2*x*x*(1-w)\r\ndef predict(x):\r\n    dense = tf.layers.Dense(1, use_bias=False, kernel_initializer=tf.zeros_initializer())\r\n    return dense(x)\r\npred = predict(data)\r\nloss = tf.losses.mean_squared_error(data, pred)\r\nstep = tf.contrib.framework.get_or_create_global_step()\r\noptimizer = tf.train.GradientDescentOptimizer(LR)\r\nhvd.init()\r\noptimizer = hvd.DistributedOptimizer(optimizer, backward_passes_per_step=2, average_aggregated_gradients=True)\r\n\r\nwith tf.control_dependencies([tf.print(\"step:\", step, \"loss:\", loss)]):\r\n    train_op = optimizer.minimize(loss, global_step=step)\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    sess.run(tf.local_variables_initializer())\r\n    # training loop\r\n    for i in range(10):\r\n        sess.run([train_op])\r\n```\r\n\r\nWhich gives this output:\r\n```\r\nstep: 0 loss: 1\r\nstep: 0 loss: 1\r\nstep: 0 loss: 1\r\nstep: 2 loss: 0.960400045\r\nstep: 2 loss: 0.960400045\r\nstep: 4 loss: 0.922368109\r\nstep: 4 loss: 0.922368109\r\nstep: 6 loss: 0.885842443\r\nstep: 6 loss: 0.885842443\r\nstep: 8 loss: 0.850763\r\nstep: 8 loss: 0.850763\r\n```\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2715/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2715/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2701", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2701/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2701/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2701/events", "html_url": "https://github.com/horovod/horovod/issues/2701", "id": 819753569, "node_id": "MDU6SXNzdWU4MTk3NTM1Njk=", "number": 2701, "title": "horovod ingore pytorch optimizer l2 regularization function", "user": {"login": "jasstionzyf", "id": 5241459, "node_id": "MDQ6VXNlcjUyNDE0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/5241459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasstionzyf", "html_url": "https://github.com/jasstionzyf", "followers_url": "https://api.github.com/users/jasstionzyf/followers", "following_url": "https://api.github.com/users/jasstionzyf/following{/other_user}", "gists_url": "https://api.github.com/users/jasstionzyf/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasstionzyf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasstionzyf/subscriptions", "organizations_url": "https://api.github.com/users/jasstionzyf/orgs", "repos_url": "https://api.github.com/users/jasstionzyf/repos", "events_url": "https://api.github.com/users/jasstionzyf/events{/privacy}", "received_events_url": "https://api.github.com/users/jasstionzyf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2021-03-02T08:02:54Z", "updated_at": "2021-06-29T07:00:45Z", "closed_at": "2021-06-29T07:00:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.7.1\r\n3. Horovod version:  0.21.3\r\n4. MPI version:\r\n5. CUDA version: 10.1\r\n6. NCCL version:\r\n7. Python version: 3.7\r\n8. Spark / PySpark version:\r\n9. OS and version:\r\n10. GCC version:\r\n11. CMake version:\r\n\r\n\r\n**Bug report:**\r\n ```\r\n\r\noptim.SGD(modelParams, lr=lr, momentum=0.9,weight_decay=weight_decay)\r\noptimizer = DistributedOptimizer(optimizer, named_parameters=model.named_parameters(),\r\n                                                    compression=compression)  \r\n\r\n\r\nlossValue.backward()\r\n\r\noptimizer.step()\r\n\r\n\r\n\r\n```\r\n\r\n\r\nabove code will not apply l2 regularization  within SGD,\r\nas a result, l2 loss will keep growing\r\nexcept you add l2 loss to lossValue\r\n`(lossValue+regLossValue).backward()`\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2701/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2701/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2695", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2695/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2695/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2695/events", "html_url": "https://github.com/horovod/horovod/issues/2695", "id": 816513821, "node_id": "MDU6SXNzdWU4MTY1MTM4MjE=", "number": 2695, "title": "no horovod.torch.init in latest docs", "user": {"login": "ydcjeff", "id": 32727188, "node_id": "MDQ6VXNlcjMyNzI3MTg4", "avatar_url": "https://avatars.githubusercontent.com/u/32727188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ydcjeff", "html_url": "https://github.com/ydcjeff", "followers_url": "https://api.github.com/users/ydcjeff/followers", "following_url": "https://api.github.com/users/ydcjeff/following{/other_user}", "gists_url": "https://api.github.com/users/ydcjeff/gists{/gist_id}", "starred_url": "https://api.github.com/users/ydcjeff/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ydcjeff/subscriptions", "organizations_url": "https://api.github.com/users/ydcjeff/orgs", "repos_url": "https://api.github.com/users/ydcjeff/repos", "events_url": "https://api.github.com/users/ydcjeff/events{/privacy}", "received_events_url": "https://api.github.com/users/ydcjeff/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2021-02-25T14:56:38Z", "updated_at": "2021-03-05T17:03:43Z", "closed_at": "2021-03-05T15:00:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "I can go directly to `horovod.torch.init` in v0.21.0 docs : https://horovod.readthedocs.io/en/v0.20.0/api.html#horovod.torch.init\r\nBut, can't anymore in https://horovod.readthedocs.io/en/latest/api.html#horovod.torch.init\r\nTraced down and found at it didn't start existing at https://horovod.readthedocs.io/en/v0.21.1/api.html#horovod.torch.init\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2695/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2695/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2693", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2693/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2693/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2693/events", "html_url": "https://github.com/horovod/horovod/issues/2693", "id": 816185820, "node_id": "MDU6SXNzdWU4MTYxODU4MjA=", "number": 2693, "title": "Ray + Horovod : hvd.init() fails on MacOS", "user": {"login": "Deathn0t", "id": 5201978, "node_id": "MDQ6VXNlcjUyMDE5Nzg=", "avatar_url": "https://avatars.githubusercontent.com/u/5201978?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Deathn0t", "html_url": "https://github.com/Deathn0t", "followers_url": "https://api.github.com/users/Deathn0t/followers", "following_url": "https://api.github.com/users/Deathn0t/following{/other_user}", "gists_url": "https://api.github.com/users/Deathn0t/gists{/gist_id}", "starred_url": "https://api.github.com/users/Deathn0t/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Deathn0t/subscriptions", "organizations_url": "https://api.github.com/users/Deathn0t/orgs", "repos_url": "https://api.github.com/users/Deathn0t/repos", "events_url": "https://api.github.com/users/Deathn0t/events{/privacy}", "received_events_url": "https://api.github.com/users/Deathn0t/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2021-02-25T07:56:00Z", "updated_at": "2021-08-13T22:51:47Z", "closed_at": "2021-08-13T22:51:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.2.0\r\n3. Horovod version: 0.21.3\r\n4. MPI version: mpirun (Open MPI) 4.0.5\r\n5. CUDA version: None\r\n6. NCCL version: None\r\n7. Python version: 3.7.9\r\n8. Spark / PySpark version: None\r\n9. OS and version: macOS Big Sur 11.2\r\n10. GCC version: Apple clang version 12.0.0 (clang-1200.0.32.29)\r\n11. CMake version: 3.19.3\r\n12. Ray version: 1.2.0\r\n\r\n**Bug report:**\r\n\r\nWhile trying to run the [examples/ray/tensorflow2_mnist_ray.py](https://github.com/horovod/horovod/blob/master/examples/ray/tensorflow2_mnist_ray.py) with `python tensorflow2_mnist_ray.py` the following errors appears:\r\n\r\n```\r\n2021-02-25 08:46:26,142\tINFO services.py:1174 -- View the Ray dashboard at http://127.0.0.1:8265\r\n(pid=8582) [/private/var/folders/20/45pr4b1n2vj8rpt6vys5wk5h0000gn/T/pip-install-bbp3loh7/horovod_e32d73fa0308444b8a908c32a4c684f7/third_party/gloo/gloo/transport/uv/libuv.h:602] uv_read_start: connection already in progress\r\n2021-02-25 08:46:29,995\tWARNING worker.py:1107 -- A worker died or was killed while executing task ffffffffffffffff19549ad93c7787cd0ef95f6801000000.\r\nTraceback (most recent call last):\r\n  File \"tensorflow2_example.py\", line 104, in <module>\r\n    executor.run(train, kwargs=dict(num_epochs=1))\r\n  File \"/Users/romainegele/opt/anaconda3/envs/dhtest/lib/python3.7/site-packages/horovod/ray/runner.py\", line 433, in run\r\n    return ray.get(self.run_remote(fn, args, kwargs))\r\n  File \"/Users/romainegele/opt/anaconda3/envs/dhtest/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/Users/romainegele/opt/anaconda3/envs/dhtest/lib/python3.7/site-packages/ray/worker.py\", line 1458, in get\r\n    raise value\r\nray.exceptions.RayActorError: The actor died unexpectedly before finishing this task. Check python-core-worker-*.log files for more information.\r\n```\r\n\r\nThe following example also fails:\r\n```\r\nimport ray\r\n\r\n# import horovod.tensorflow.keras as hvd\r\nimport tensorflow as tf\r\nimport horovod.tensorflow as hvd\r\nfrom horovod.ray import RayExecutor\r\n\r\n# Start the Ray cluster or attach to an existing Ray cluster\r\nray.init(num_cpus=2)\r\n\r\n# Ray executor settings\r\nsetting = RayExecutor.create_settings(timeout_s=100)\r\nnum_hosts = 1  # number of machine to use\r\nnum_slots = 2  # number of workers to use on each machine\r\ncpus_per_slot = 1  # number of cores to allocate to each worker\r\ngpus_per_slot = None  # number of GPUs to allocate to each worker\r\n\r\n# Start num_hosts * num_slots actors on the cluster\r\n# https://horovod.readthedocs.io/en/stable/api.html#horovod-ray-api\r\nexecutor = RayExecutor(\r\n    setting,\r\n    num_hosts=num_hosts,\r\n    num_slots=num_slots,\r\n    # cpus_per_slot=cpus_per_slot,\r\n    # gpus_per_slot=gpus_per_slot,\r\n)\r\n\r\n# Launch the Ray actors on each machine\r\n# This will launch `num_slots` actors on each machine\r\nexecutor.start()\r\n\r\n\r\n#! Note that there is an implicit assumption on the cluster being\r\n#! homogenous in shape (i.e., all machines have the same number of\r\n#! slots available). This is simply an implementation detail and is\r\n#! not a fundamental limitation.\r\n\r\n# Using the stateless `run` method, a function can take in any args or kwargs\r\ndef simple_fn():\r\n\r\n\r\n    hvd.init()\r\n\r\n    print(\"here\")\r\n    # print(\"hvd rank\", hvd.rank())\r\n    # return hvd.rank()\r\n    return 0\r\n\r\n\r\n# Execute the function on all workers at once\r\nresult = executor.run(simple_fn)\r\nprint(result)\r\n\r\n# Check that the rank of all workers is unique\r\nassert len(set(result)) == num_hosts * num_slots\r\n\r\nexecutor.shutdown()\r\n```\r\n\r\nHowever if the `hvd.init()` is commented out then it works fine.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2693/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2693/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2680", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2680/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2680/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2680/events", "html_url": "https://github.com/horovod/horovod/issues/2680", "id": 812485117, "node_id": "MDU6SXNzdWU4MTI0ODUxMTc=", "number": 2680, "title": "bug in checking sample_weights", "user": {"login": "irasit", "id": 12163435, "node_id": "MDQ6VXNlcjEyMTYzNDM1", "avatar_url": "https://avatars.githubusercontent.com/u/12163435?v=4", "gravatar_id": "", "url": "https://api.github.com/users/irasit", "html_url": "https://github.com/irasit", "followers_url": "https://api.github.com/users/irasit/followers", "following_url": "https://api.github.com/users/irasit/following{/other_user}", "gists_url": "https://api.github.com/users/irasit/gists{/gist_id}", "starred_url": "https://api.github.com/users/irasit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/irasit/subscriptions", "organizations_url": "https://api.github.com/users/irasit/orgs", "repos_url": "https://api.github.com/users/irasit/repos", "events_url": "https://api.github.com/users/irasit/events{/privacy}", "received_events_url": "https://api.github.com/users/irasit/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "irasit", "id": 12163435, "node_id": "MDQ6VXNlcjEyMTYzNDM1", "avatar_url": "https://avatars.githubusercontent.com/u/12163435?v=4", "gravatar_id": "", "url": "https://api.github.com/users/irasit", "html_url": "https://github.com/irasit", "followers_url": "https://api.github.com/users/irasit/followers", "following_url": "https://api.github.com/users/irasit/following{/other_user}", "gists_url": "https://api.github.com/users/irasit/gists{/gist_id}", "starred_url": "https://api.github.com/users/irasit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/irasit/subscriptions", "organizations_url": "https://api.github.com/users/irasit/orgs", "repos_url": "https://api.github.com/users/irasit/repos", "events_url": "https://api.github.com/users/irasit/events{/privacy}", "received_events_url": "https://api.github.com/users/irasit/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "irasit", "id": 12163435, "node_id": "MDQ6VXNlcjEyMTYzNDM1", "avatar_url": "https://avatars.githubusercontent.com/u/12163435?v=4", "gravatar_id": "", "url": "https://api.github.com/users/irasit", "html_url": "https://github.com/irasit", "followers_url": "https://api.github.com/users/irasit/followers", "following_url": "https://api.github.com/users/irasit/following{/other_user}", "gists_url": "https://api.github.com/users/irasit/gists{/gist_id}", "starred_url": "https://api.github.com/users/irasit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/irasit/subscriptions", "organizations_url": "https://api.github.com/users/irasit/orgs", "repos_url": "https://api.github.com/users/irasit/repos", "events_url": "https://api.github.com/users/irasit/events{/privacy}", "received_events_url": "https://api.github.com/users/irasit/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2021-02-20T02:21:49Z", "updated_at": "2021-02-22T21:57:47Z", "closed_at": "2021-02-22T21:57:47Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "this line \r\n```if sample_weights: ```\r\nin [here](https://github.com/horovod/horovod/blob/994913a2abc5812042a5c3540ced5b3316d23b72/horovod/spark/torch/remote.py#L268) should change to \r\n```if sample_weights is not None: ```\r\n\r\notherwise it complains about \r\n```RuntimeError: bool value of Tensor with more than one value is ambiguous.```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2680/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2680/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2674", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2674/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2674/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2674/events", "html_url": "https://github.com/horovod/horovod/issues/2674", "id": 810817903, "node_id": "MDU6SXNzdWU4MTA4MTc5MDM=", "number": 2674, "title": "Estimator failed to save model larger than 2G", "user": {"login": "irasit", "id": 12163435, "node_id": "MDQ6VXNlcjEyMTYzNDM1", "avatar_url": "https://avatars.githubusercontent.com/u/12163435?v=4", "gravatar_id": "", "url": "https://api.github.com/users/irasit", "html_url": "https://github.com/irasit", "followers_url": "https://api.github.com/users/irasit/followers", "following_url": "https://api.github.com/users/irasit/following{/other_user}", "gists_url": "https://api.github.com/users/irasit/gists{/gist_id}", "starred_url": "https://api.github.com/users/irasit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/irasit/subscriptions", "organizations_url": "https://api.github.com/users/irasit/orgs", "repos_url": "https://api.github.com/users/irasit/repos", "events_url": "https://api.github.com/users/irasit/events{/privacy}", "received_events_url": "https://api.github.com/users/irasit/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "irasit", "id": 12163435, "node_id": "MDQ6VXNlcjEyMTYzNDM1", "avatar_url": "https://avatars.githubusercontent.com/u/12163435?v=4", "gravatar_id": "", "url": "https://api.github.com/users/irasit", "html_url": "https://github.com/irasit", "followers_url": "https://api.github.com/users/irasit/followers", "following_url": "https://api.github.com/users/irasit/following{/other_user}", "gists_url": "https://api.github.com/users/irasit/gists{/gist_id}", "starred_url": "https://api.github.com/users/irasit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/irasit/subscriptions", "organizations_url": "https://api.github.com/users/irasit/orgs", "repos_url": "https://api.github.com/users/irasit/repos", "events_url": "https://api.github.com/users/irasit/events{/privacy}", "received_events_url": "https://api.github.com/users/irasit/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "irasit", "id": 12163435, "node_id": "MDQ6VXNlcjEyMTYzNDM1", "avatar_url": "https://avatars.githubusercontent.com/u/12163435?v=4", "gravatar_id": "", "url": "https://api.github.com/users/irasit", "html_url": "https://github.com/irasit", "followers_url": "https://api.github.com/users/irasit/followers", "following_url": "https://api.github.com/users/irasit/following{/other_user}", "gists_url": "https://api.github.com/users/irasit/gists{/gist_id}", "starred_url": "https://api.github.com/users/irasit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/irasit/subscriptions", "organizations_url": "https://api.github.com/users/irasit/orgs", "repos_url": "https://api.github.com/users/irasit/repos", "events_url": "https://api.github.com/users/irasit/events{/privacy}", "received_events_url": "https://api.github.com/users/irasit/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2021-02-18T06:54:45Z", "updated_at": "2021-03-01T15:48:08Z", "closed_at": "2021-03-01T15:48:08Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nGot error when save large models in metadata file.\r\n```\r\nFile \"/usr/lib/python3.6/site-packages/horovod/spark/torch/estimator.py\", line 62, in saveImpl\r\nparam_serializer_fn=_torch_param_serialize)\r\nFile \"/usr/lib/python3.6/site-packages/horovod/spark/common/serialization.py\", line 34, in saveMetadata\r\nsc.parallelize([metadata_json], 1).saveAsTextFile(metadata_path)\r\nFile \"/ml-code/bazel-bin/platforms/uber_eats/homefeed_conversion_model/path_gen.runfiles/pypi_deps_data_michelangelo/pypi_deps_data_michelangelo_pypi__pyspark_2_4_3/pyspark/context.py\", line 527, in parallelize\r\njrdd = self._serialize_to_jvm(c, serializer, reader_func, createRDDServer)\r\nFile \"/ml-code/bazel-bin/platforms/uber_eats/homefeed_conversion_model/path_gen.runfiles/pypi_deps_data_michelangelo/pypi_deps_data_michelangelo_pypi__pyspark_2_4_3/pyspark/context.py\", line 559, in _serialize_to_jvm\r\nserializer.dump_stream(data, tempFile)\r\nFile \"/ml-code/bazel-bin/platforms/uber_eats/homefeed_conversion_model/path_gen.runfiles/pypi_deps_data_michelangelo/pypi_deps_data_michelangelo_pypi__pyspark_2_4_3/pyspark/serializers.py\", line 345, in dump_stream\r\nself.serializer.dump_stream(self._batched(iterator), stream)\r\nFile \"/ml-code/bazel-bin/platforms/uber_eats/homefeed_conversion_model/path_gen.runfiles/pypi_deps_data_michelangelo/pypi_deps_data_michelangelo_pypi__pyspark_2_4_3/pyspark/serializers.py\", line 142, in dump_stream\r\nself._write_with_length(obj, stream)\r\nFile \"/ml-code/bazel-bin/platforms/uber_eats/homefeed_conversion_model/path_gen.runfiles/pypi_deps_data_michelangelo/pypi_deps_data_michelangelo_pypi__pyspark_2_4_3/pyspark/serializers.py\", line 156, in _write_with_length\r\nraise ValueError(\"can not serialize object larger than 2G\")\r\nValueError: can not serialize object larger than 2G\r\n```\r\n\r\nThe culprit is likely to be:\r\n\r\nFile \"/usr/lib/python3.6/site-packages/horovod/spark/common/serialization.py\", line 34, in saveMetadata\r\nsc.parallelize([metadata_json], 1).saveAsTextFile(metadata_path)\r\n\r\nIf metadata_json is >2G, it will hit the Spark limit for serialization. We can use Hadoop API to write it directly.\r\n\r\nHere is a Java example for using Hadoop FileSystem API https://stackoverflow.com/questions/27023766/spark-iterate-hdfs-directory\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2674/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2674/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2670", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2670/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2670/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2670/events", "html_url": "https://github.com/horovod/horovod/issues/2670", "id": 809754064, "node_id": "MDU6SXNzdWU4MDk3NTQwNjQ=", "number": 2670, "title": "Bug in _DistributedOptimizer: named_parameters is None and multiple param groups", "user": {"login": "vfdev-5", "id": 2459423, "node_id": "MDQ6VXNlcjI0NTk0MjM=", "avatar_url": "https://avatars.githubusercontent.com/u/2459423?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vfdev-5", "html_url": "https://github.com/vfdev-5", "followers_url": "https://api.github.com/users/vfdev-5/followers", "following_url": "https://api.github.com/users/vfdev-5/following{/other_user}", "gists_url": "https://api.github.com/users/vfdev-5/gists{/gist_id}", "starred_url": "https://api.github.com/users/vfdev-5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vfdev-5/subscriptions", "organizations_url": "https://api.github.com/users/vfdev-5/orgs", "repos_url": "https://api.github.com/users/vfdev-5/repos", "events_url": "https://api.github.com/users/vfdev-5/events{/privacy}", "received_events_url": "https://api.github.com/users/vfdev-5/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2021-02-17T00:39:57Z", "updated_at": "2021-03-05T18:16:26Z", "closed_at": "2021-03-05T18:16:26Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.7.1\r\n3. Horovod version: master\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. Spark / PySpark version:\r\n9. OS and version:\r\n10. GCC version:\r\n11. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\n\r\nI have an impression that this part of code is a bit wrong if multiple param_groups are used:\r\nhttps://github.com/horovod/horovod/blob/6916985c9df111f36864724e2611827f64de8e11/horovod/torch/optimizer.py#L46-L48\r\nand if checked then for duplicates:\r\nhttps://github.com/horovod/horovod/blob/6916985c9df111f36864724e2611827f64de8e11/horovod/torch/optimizer.py#L55\r\n\r\nFor example:\r\n```python\r\nparam_groups = [\r\n    {\"params\": [\"a\", \"b\", \"c\"]},\r\n    {\"params\": [\"e\", \"f\", \"g\"]},    \r\n]\r\n\r\nnamed_parameters = [('allreduce.noname.%s' % i, v)\r\n                    for param_group in param_groups\r\n                    for i, v in enumerate(param_group['params'])]\r\n\r\nprint(\"named_parameters:\", named_parameters)\r\n\r\ndef find_duplicates(lst):\r\n    seen = set()\r\n    dups = set()\r\n    for el in lst:\r\n        if el in seen:\r\n            dups.add(el)\r\n        seen.add(el)\r\n    return dups\r\n\r\ndups = find_duplicates([k for k, _ in named_parameters])\r\nprint(\"duplicates:\", dups)\r\n```\r\nOutput:\r\n```\r\nnamed_parameters: [('allreduce.noname.0', 'a'), ('allreduce.noname.1', 'b'), ('allreduce.noname.2', 'c'), ('allreduce.noname.0', 'e'), ('allreduce.noname.1', 'f'), ('allreduce.noname.2', 'g')]\r\n\r\nduplicates: {'allreduce.noname.0', 'allreduce.noname.1', 'allreduce.noname.2'}\r\n```\r\n\r\nHere is a complete code snippet to repro the issue:\r\n```python\r\n    hvd.init()\r\n    torch.cuda.set_device(hvd.local_rank())\r\n\r\n    model = nn.Sequential(nn.Linear(10, 10), nn.Linear(10, 10)).cuda()\r\n\r\n    optimizer = optim.SGD(\r\n        [{\"params\": model[0].parameters()}, {\"params\": model[1].parameters()},],\r\n        lr=0.001,\r\n    )\r\n\r\n    optimizer = hvd.DistributedOptimizer(\r\n        optimizer,\r\n        # named_parameters=model.named_parameters()\r\n    )\r\n\r\n> ValueError: Parameter names in named_parameters must be unique. Found duplicates: allreduce.noname.0, allreduce.noname.1\r\n```\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2670/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2670/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2664", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2664/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2664/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2664/events", "html_url": "https://github.com/horovod/horovod/issues/2664", "id": 805989787, "node_id": "MDU6SXNzdWU4MDU5ODk3ODc=", "number": 2664, "title": "Fix test_gradient_aggregation for TF 2.4.0", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-02-11T00:34:38Z", "updated_at": "2021-10-30T03:52:50Z", "closed_at": "2021-10-30T03:52:50Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Following #2647, local gradient aggregation will not work on a tf.constant.  We should change this test to use an actual gradient.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2664/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2664/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2662", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2662/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2662/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2662/events", "html_url": "https://github.com/horovod/horovod/issues/2662", "id": 805746336, "node_id": "MDU6SXNzdWU4MDU3NDYzMzY=", "number": 2662, "title": "Unit test TorchTests.test_horovod_join_broadcast stalls when running four MPI processes", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2021-02-10T18:05:04Z", "updated_at": "2021-02-11T16:43:48Z", "closed_at": "2021-02-11T16:43:48Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "```\r\n$ mpirun --tag-output -np 4 pytest -sv test/parallel/test_torch.py\r\n# ...\r\n[1,3]<stdout>:test/parallel/test_torch.py::TorchTests::test_horovod_join_broadcast \r\n[1,0]<stderr>:[2021-02-10 17:39:53.403710: W horovod/common/stall_inspector.cc:105] One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock.\r\n[1,0]<stderr>:Missing ranks:\r\n[1,0]<stderr>:0: [broadcast.noname.3765, broadcast.noname.3873]\r\n[1,0]<stderr>:1: [broadcast.noname.3873]\r\n[1,0]<stderr>:2: [broadcast.noname.3765]\r\n[1,0]<stderr>:3: [broadcast.noname.3765]\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2662/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2662/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2652", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2652/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2652/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2652/events", "html_url": "https://github.com/horovod/horovod/issues/2652", "id": 803496722, "node_id": "MDU6SXNzdWU4MDM0OTY3MjI=", "number": 2652, "title": "Elastic Horovod - Tensorflow/Keras - New worker hangs on start up", "user": {"login": "czmrand", "id": 78731618, "node_id": "MDQ6VXNlcjc4NzMxNjE4", "avatar_url": "https://avatars.githubusercontent.com/u/78731618?v=4", "gravatar_id": "", "url": "https://api.github.com/users/czmrand", "html_url": "https://github.com/czmrand", "followers_url": "https://api.github.com/users/czmrand/followers", "following_url": "https://api.github.com/users/czmrand/following{/other_user}", "gists_url": "https://api.github.com/users/czmrand/gists{/gist_id}", "starred_url": "https://api.github.com/users/czmrand/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/czmrand/subscriptions", "organizations_url": "https://api.github.com/users/czmrand/orgs", "repos_url": "https://api.github.com/users/czmrand/repos", "events_url": "https://api.github.com/users/czmrand/events{/privacy}", "received_events_url": "https://api.github.com/users/czmrand/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "chongxiaoc", "id": 74630762, "node_id": "MDQ6VXNlcjc0NjMwNzYy", "avatar_url": "https://avatars.githubusercontent.com/u/74630762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chongxiaoc", "html_url": "https://github.com/chongxiaoc", "followers_url": "https://api.github.com/users/chongxiaoc/followers", "following_url": "https://api.github.com/users/chongxiaoc/following{/other_user}", "gists_url": "https://api.github.com/users/chongxiaoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chongxiaoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chongxiaoc/subscriptions", "organizations_url": "https://api.github.com/users/chongxiaoc/orgs", "repos_url": "https://api.github.com/users/chongxiaoc/repos", "events_url": "https://api.github.com/users/chongxiaoc/events{/privacy}", "received_events_url": "https://api.github.com/users/chongxiaoc/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2021-02-08T11:59:41Z", "updated_at": "2021-03-03T23:34:27Z", "closed_at": "2021-03-03T23:34:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.3.1\r\n3. Horovod version: 0.21.1 (installed with HOROVOD_WITH_GLOO=1)\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version: 3\r\n8. Spark / PySpark version:\r\n9. OS and version:\r\n10. GCC version:\r\n11. CMake version:\r\n\r\nI am attempting to run the attached script on 3 systems.\r\n1. When I remove one of the workers (either by stopping the machine or killing the process), the training continues on the two remaining workers (as advertised) but I get the following error message:\r\n[0]<stderr>:[2021-02-08 09:24:59.555830: E /tmp/pip-install-7tlcippf/horovod_015e4deaf97a4b33908ab119077a4f9c/horovod/common/operations.cc:548] Horovod background loop uncaught exception: [/tmp/pip-install-7tlcippf/horovod_015e4deaf97a4b33908ab119077a4f9c/third_party/compatible_gloo/gloo/transport/tcp/pair.cc:566] Read error [10.0.1.246]:63386: Connection reset by peer\r\nIs this expected?\r\n\r\n2. The addition of a worker is also identified successfully, however the new worker stalls just before starting the train loop. As a result, the training on the other workers stalls as well with:\r\n[0]<stderr>:0: [HorovodBroadcast]\r\n[0]<stderr>:1: [HorovodBroadcast]\r\n[0]<stderr>:2: [HorovodBroadcast_Adam_conv1_bn_beta_m_0, HorovodBroadcast_Adam_conv1_bn_beta_v_0, HorovodBroadcast_Adam_conv1_bn_gamma_m_0, HorovodBroadcast_Adam_conv1_bn_gamma_v_0, HorovodBroadcast_Adam_conv1_conv_bias_m_0, HorovodBroadcast_Adam_conv1_conv_bias_v_0 ...]\r\n[0]<stderr>:[2021-02-08 10:54:33.732016: W /tmp/pip-install-7tlcippf/horovod_015e4deaf97a4b33908ab119077a4f9c/horovod/common/stall_inspector.cc:105] One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. \r\n[0]<stderr>:Missing ranks:\r\n\r\n\r\n[code.tar.gz](https://github.com/horovod/horovod/files/5943484/code.tar.gz)\r\n\r\n[data.tar.gz](https://github.com/horovod/horovod/files/5943469/data.tar.gz)\r\n\r\nimport argparse\r\nimport tensorflow as tf\r\nimport horovod.tensorflow.keras as hvd\r\n\r\nhvd.init()\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nfor gpu in gpus:\r\n    tf.config.experimental.set_memory_growth(gpu, True)\r\nif gpus:\r\n    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\r\n\r\ndef get_dataset(batch_size):\r\n    def parse_image_function(example_proto):\r\n        image_feature_description = {\r\n            'image': tf.io.FixedLenFeature([], tf.string),\r\n            'label': tf.io.FixedLenFeature([], tf.int64)\r\n        }\r\n        features = tf.io.parse_single_example(example_proto, image_feature_description)\r\n        image = tf.io.decode_raw(features['image'], tf.uint8)\r\n        image.set_shape([3 * 32 * 32])\r\n        image = tf.reshape(image, [32, 32, 3])\r\n        label = tf.cast(features['label'], tf.int32)\r\n        return image, label\r\n\r\n    from tensorflow.keras.layers.experimental import preprocessing\r\n\r\n    def rescale(image, label):\r\n        image = preprocessing.Rescaling(1.0 / 255)(image)\r\n        return image, label\r\n\r\n    autotune = tf.data.experimental.AUTOTUNE\r\n    options = tf.data.Options()\r\n    options.experimental_deterministic = False\r\n    records = tf.data.Dataset.list_files('data/*', shuffle=True).with_options(options)\r\n    ds = tf.data.TFRecordDataset(records, num_parallel_reads=autotune).repeat()\r\n    ds = ds.map(parse_image_function, num_parallel_calls=autotune)\r\n    ds = ds.batch(batch_size)\r\n    ds = ds.map(rescale,num_parallel_calls=autotune)\r\n    ds = ds.prefetch(autotune)\r\n    return ds\r\n\r\nif __name__ == \"__main__\":\r\n    parser = argparse.ArgumentParser(description=\"Train resnet50 cifar10\")\r\n    parser.add_argument(\"--lr\", type=float, default=0.001)\r\n    parser.add_argument(\"--model_dir\", type=str, default=\"./model_keras_resnet\")\r\n\r\n    args = parser.parse_args()\r\n\r\n    ds = get_dataset(batch_size=2)\r\n\r\n    model = tf.keras.applications.resnet.ResNet50(weights=None, input_shape=(32, 32, 3), classes=10)\r\n    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\r\n                  optimizer=tf.keras.optimizers.Adam())\r\n\r\n    def on_state_reset():\r\n        print('-----------------------------------')\r\n        print('resetting learning rate')\r\n        tf.keras.backend.set_value(model.optimizer.lr, 0.001)\r\n        print('-----------------------------------')\r\n\r\n    state = hvd.elastic.KerasState(model, batch=100, epoch=0)\r\n    state.register_reset_callbacks([on_state_reset])\r\n\r\n    callbacks = [\r\n        hvd.elastic.CommitStateCallback(state),\r\n        hvd.elastic.UpdateBatchStateCallback(state),\r\n        hvd.elastic.UpdateEpochStateCallback(state),\r\n    ]\r\n\r\n\r\n    @hvd.elastic.run\r\n    def train(state):\r\n        model.fit(ds, steps_per_epoch=100, epochs=100, callbacks=callbacks)\r\n    train(state)\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2652/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2652/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2627", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2627/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2627/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2627/events", "html_url": "https://github.com/horovod/horovod/issues/2627", "id": 794317254, "node_id": "MDU6SXNzdWU3OTQzMTcyNTQ=", "number": 2627, "title": "Wrong default for horovod.tensorflow.keras.allreduce(average...", "user": {"login": "Flamefire", "id": 309017, "node_id": "MDQ6VXNlcjMwOTAxNw==", "avatar_url": "https://avatars.githubusercontent.com/u/309017?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Flamefire", "html_url": "https://github.com/Flamefire", "followers_url": "https://api.github.com/users/Flamefire/followers", "following_url": "https://api.github.com/users/Flamefire/following{/other_user}", "gists_url": "https://api.github.com/users/Flamefire/gists{/gist_id}", "starred_url": "https://api.github.com/users/Flamefire/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Flamefire/subscriptions", "organizations_url": "https://api.github.com/users/Flamefire/orgs", "repos_url": "https://api.github.com/users/Flamefire/repos", "events_url": "https://api.github.com/users/Flamefire/events{/privacy}", "received_events_url": "https://api.github.com/users/Flamefire/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2021-01-26T15:19:12Z", "updated_at": "2021-02-08T16:17:55Z", "closed_at": "2021-02-08T16:17:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "In Horovod 0.21.1 the default for `average` in `allreduce` is still `True` leading to \r\n\r\n> ValueError: The op parameter supersedes average. Please provide only one of them.\r\n\r\nwhen using `op=...` (only).\r\n\r\nThis is only in in `horovod.tensorflow.keras`, not in `horovod.tensorflow`\r\n\r\nBTW: In TF2, is there any benefit of using `horovod.tensorflow.keras` over `horovod.tensorflow` when not disabling eager execution (which in my tests is pretty much unfeasible)", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2627/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2627/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2592", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2592/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2592/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2592/events", "html_url": "https://github.com/horovod/horovod/issues/2592", "id": 784666086, "node_id": "MDU6SXNzdWU3ODQ2NjYwODY=", "number": 2592, "title": "Dependency links in setup.py causing issues with private registry ", "user": {"login": "samj1912", "id": 16130816, "node_id": "MDQ6VXNlcjE2MTMwODE2", "avatar_url": "https://avatars.githubusercontent.com/u/16130816?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samj1912", "html_url": "https://github.com/samj1912", "followers_url": "https://api.github.com/users/samj1912/followers", "following_url": "https://api.github.com/users/samj1912/following{/other_user}", "gists_url": "https://api.github.com/users/samj1912/gists{/gist_id}", "starred_url": "https://api.github.com/users/samj1912/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samj1912/subscriptions", "organizations_url": "https://api.github.com/users/samj1912/orgs", "repos_url": "https://api.github.com/users/samj1912/repos", "events_url": "https://api.github.com/users/samj1912/events{/privacy}", "received_events_url": "https://api.github.com/users/samj1912/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2021-01-12T23:22:21Z", "updated_at": "2021-01-22T07:30:21Z", "closed_at": "2021-01-22T07:30:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) all\r\n2. Framework version: n/a\r\n3. Horovod version: 0.20.1+\r\n4. MPI version: n/a\r\n5. CUDA version: n/a\r\n6. NCCL version:\r\n7. Python version:\r\n8. Spark / PySpark version:\r\n9. OS and version:\r\n10. GCC version:\r\n11. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nIn horovod 0.20.x the setup.py was updated to add dependency links. Although it says it is removed from pip, it still causes issues in enterprise settings when a private registry is used as pip for some reason tries to connect to download.pytorch.org. This causes horovod versions 0.20.x to be uninstallable as pip just waits for a timeout on these for a long long time. Can we please remove these from the setup.py? ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2592/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2592/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2584", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2584/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2584/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2584/events", "html_url": "https://github.com/horovod/horovod/issues/2584", "id": 782286225, "node_id": "MDU6SXNzdWU3ODIyODYyMjU=", "number": 2584, "title": "Installing horovod (pip) - installed libuv cannot be found, osx", "user": {"login": "gtuzi", "id": 3085599, "node_id": "MDQ6VXNlcjMwODU1OTk=", "avatar_url": "https://avatars.githubusercontent.com/u/3085599?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gtuzi", "html_url": "https://github.com/gtuzi", "followers_url": "https://api.github.com/users/gtuzi/followers", "following_url": "https://api.github.com/users/gtuzi/following{/other_user}", "gists_url": "https://api.github.com/users/gtuzi/gists{/gist_id}", "starred_url": "https://api.github.com/users/gtuzi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gtuzi/subscriptions", "organizations_url": "https://api.github.com/users/gtuzi/orgs", "repos_url": "https://api.github.com/users/gtuzi/repos", "events_url": "https://api.github.com/users/gtuzi/events{/privacy}", "received_events_url": "https://api.github.com/users/gtuzi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2021-01-08T17:35:32Z", "updated_at": "2022-03-09T23:33:54Z", "closed_at": "2021-01-09T21:46:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.1.0\r\n3. Horovod version: 0.21.1\r\n4. MPI version: (OpenRTE) 4.0.5\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.6\r\n8. Spark / PySpark version: N/A\r\n9. OS and version: OSX 10.15.7 \r\n10. GCC version: 4.2.1\r\n11. CMake version: 3.18.4\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? N/A\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? N/A\r\n4. Did you check if you question is answered in the [troubleshooting guide] (https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nInstalled g++-4.9 from brew.\r\n```\r\ngcc-4.9 --version\r\ngcc-4.9 (Homebrew GCC 4.9.4_2) 4.9.4\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\n```\r\n```\r\ng++-4.9 --version\r\ng++-4.9 (Homebrew GCC 4.9.4_2) 4.9.4\r\n\r\n```\r\nAlso:\r\n\r\n```\r\n g++ --version\r\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/4.2.1\r\nApple clang version 12.0.0 (clang-1200.0.32.27)\r\nTarget: x86_64-apple-darwin19.6.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n```\r\n\r\nRan:\r\n`brew install libuv`. Installed version 1.40.0\r\n\r\nRan:\r\n`HOROVOD_WITH_TENSORFLOW=1 pip install horovod[tensorflow,keras]`\r\n\r\nIt seems CMake cannot find `libuv`. \r\n\r\nAny idea ?\r\n\r\n\r\n ```\r\nBuilding wheel for horovod (setup.py) ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: /Users/user_name/miniconda3/envs/bbmbb/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/1x/9fb41qyx5knf189hlblycxc00000gp/T/pip-install-p_hmijj5/horovod_d9fed83013d94ba6814b5b851e769fc6/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/1x/9fb41qyx5knf189hlblycxc00000gp/T/pip-install-p_hmijj5/horovod_d9fed83013d94ba6814b5b851e769fc6/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/1x/9fb41qyx5knf189hlblycxc00000gp/T/pip-wheel-7huqj2x9\r\n       cwd: /private/var/folders/1x/9fb41qyx5knf189hlblycxc00000gp/T/pip-install-p_hmijj5/horovod_d9fed83013d94ba6814b5b851e769fc6/\r\n  Complete output (252 lines):\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib.macosx-10.9-x86_64-3.6\r\n  creating build/lib.macosx-10.9-x86_64-3.6/horovod\r\n  copying horovod/__init__.py -> build/lib.macosx-10.9-x86_64-3.6/horovod\r\n  creating build/lib.macosx-10.9-x86_64-3.6/horovod/keras\r\n  copying horovod/keras/__init__.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/keras\r\n  copying horovod/keras/callbacks.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/keras\r\n  copying horovod/keras/elastic.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/keras\r\n  creating build/lib.macosx-10.9-x86_64-3.6/horovod/mxnet\r\n  copying horovod/mxnet/functions.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/mxnet\r\n  copying horovod/mxnet/mpi_ops.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/mxnet\r\n  copying horovod/mxnet/__init__.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/mxnet\r\n  creating build/lib.macosx-10.9-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/task_fn.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/gloo_run.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/__init__.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/launch.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/mpi_run.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/run_task.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/js_run.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/runner\r\n  creating build/lib.macosx-10.9-x86_64-3.6/horovod/torch\r\n....\r\n\r\ncopying horovod/spark/common/estimator.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/serialization.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/spark/common\r\n  creating build/lib.macosx-10.9-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/task_info.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/task_service.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/__init__.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/gloo_exec_fn.py -> build/lib.macosx-10.9-x86_64-3.6/horovod/spark/task\r\n  running build_ext\r\n  -- The CXX compiler identification is AppleClang 12.0.0.12000032\r\n  -- Detecting CXX compiler ABI info\r\n  -- Detecting CXX compiler ABI info - done\r\n  -- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ - skipped\r\n  -- Detecting CXX compile features\r\n  -- Detecting CXX compile features - done\r\n  -- Build architecture flags:\r\n  -- Using command /Users/user_name/miniconda3/envs/bbmbb/bin/python\r\n  -- Found MPI_CXX: /usr/local/lib/libmpi.dylib (found version \"3.1\")\r\n  -- Found MPI: TRUE (found version \"3.1\")\r\n  -- The C compiler identification is AppleClang 12.0.0.12000032\r\n  -- Detecting C compiler ABI info\r\n  -- Detecting C compiler ABI info - done\r\n  -- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc - skipped\r\n  -- Detecting C compile features\r\n  -- Detecting C compile features - done\r\n  -- Could NOT find PkgConfig (missing: PKG_CONFIG_EXECUTABLE)\r\n  -- Checking for one of the modules 'libuv>=1.26'\r\n  CMake Error at /Users/user_name/miniconda3/envs/bbmbb/lib/python3.6/site-packages/cmake/data/CMake.app/Contents/share/cmake-3.18/Modules/FindPkgConfig.cmake:797 (message):\r\n    None of the required 'libuv>=1.26' found\r\n  Call Stack (most recent call first):\r\n    third_party/gloo/cmake/Dependencies.cmake:46 (pkg_search_module)\r\n    third_party/gloo/CMakeLists.txt:75 (include)\r\n  \r\n  \r\n  FATALUnable to find static libuv library in\r\n  CMake Error at third_party/gloo/cmake/Dependencies.cmake:56 (set_target_properties):\r\n    set_target_properties called with incorrect number of arguments.\r\n  Call Stack (most recent call first):\r\n    third_party/gloo/CMakeLists.txt:75 (include)\r\n  \r\n  \r\n  -- Found MPI_C: /usr/local/lib/libmpi.dylib (found version \"3.1\")\r\n  -- Found MPI: TRUE (found version \"3.1\")\r\n  -- MPI include path: /usr/local/include\r\n  -- MPI libraries: /usr/local/lib/libmpi.dylib\r\n  -- Found Tensorflow: -L/Users/user_name/miniconda3/envs/bbmbb/lib/python3.6/site-packages/tensorflow_core;-ltensorflow_framework.2 (found suitable version \"2.1.0\", minimum required is \"1.15.0\")\r\n  -- Could NOT find Pytorch: Found unsuitable version \"\", but required is at least \"1.2.0\" (found )\r\n  -- Could NOT find Mxnet (missing: Mxnet_LIBRARIES) (Required is at least version \"1.4.0\")\r\n  -- Could NOT find PkgConfig (missing: PKG_CONFIG_EXECUTABLE)\r\n  -- Checking for one of the modules 'libuv>=1.26'\r\n  CMake Error at /Users/user_name/miniconda3/envs/bbmbb/lib/python3.6/site-packages/cmake/data/CMake.app/Contents/share/cmake-3.18/Modules/FindPkgConfig.cmake:797 (message):\r\n    None of the required 'libuv>=1.26' found\r\n  Call Stack (most recent call first):\r\n    third_party/compatible_gloo/cmake/Dependencies.cmake:46 (pkg_search_module)\r\n    third_party/compatible_gloo/CMakeLists.txt:75 (include)\r\n  \r\n  \r\n  FATALUnable to find static libuv library in\r\n  CMake Error at third_party/compatible_gloo/cmake/Dependencies.cmake:56 (set_target_properties):\r\n    set_target_properties called with incorrect number of arguments.\r\n  Call Stack (most recent call first):\r\n    third_party/compatible_gloo/CMakeLists.txt:75 (include)\r\n\r\n...\r\n\r\nFile \"/Users/user_name/miniconda3/envs/bmb/lib/python3.6/subprocess.py\", line 311, in check_call\r\n      raise CalledProcessError(retcode, cmd)\r\n  subprocess.CalledProcessError: Command '['cmake', '/private/var/folders/1x/9fb41qyx5knf189hlblycxc00000gp/T/pip-install-p_hmijj5/horovod_d9fed83013d94ba6814b5b851e769fc6', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/private/var/folders/1x/9fb41qyx5knf189hlblycxc00000gp/T/pip-install-p_hmijj5/horovod_d9fed83013d94ba6814b5b851e769fc6/build/lib.macosx-10.9-x86_64-3.6', '-DPYTHON_EXECUTABLE:FILEPATH=/Users/user_name/miniconda3/envs/bmb/bin/python']' returned non-zero exit status 1.\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n\r\n\r\n....\r\n\r\nERROR: Command errored out with exit status 1: /Users/user_name/miniconda3/envs/bbmbb/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/1x/9fb41qyx5knf189hlblycxc00000gp/T/pip-install-p_hmijj5/horovod_d9fed83013d94ba6814b5b851e769fc6/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/1x/9fb41qyx5knf189hlblycxc00000gp/T/pip-install-p_hmijj5/horovod_d9fed83013d94ba6814b5b851e769fc6/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/1x/9fb41qyx5knf189hlblycxc00000gp/T/pip-record-4yz193ik/install-record.txt --single-version-externally-managed --compile --install-headers /Users/user_name/miniconda3/envs/bbmbb/include/python3.6m/horovod Check the logs for full command output.\r\n\r\n```\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2584/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2584/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2579", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2579/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2579/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2579/events", "html_url": "https://github.com/horovod/horovod/issues/2579", "id": 781480068, "node_id": "MDU6SXNzdWU3ODE0ODAwNjg=", "number": 2579, "title": "Weird behavior of the DistributedOptimizer. ", "user": {"login": "ysyyork", "id": 6693605, "node_id": "MDQ6VXNlcjY2OTM2MDU=", "avatar_url": "https://avatars.githubusercontent.com/u/6693605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ysyyork", "html_url": "https://github.com/ysyyork", "followers_url": "https://api.github.com/users/ysyyork/followers", "following_url": "https://api.github.com/users/ysyyork/following{/other_user}", "gists_url": "https://api.github.com/users/ysyyork/gists{/gist_id}", "starred_url": "https://api.github.com/users/ysyyork/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ysyyork/subscriptions", "organizations_url": "https://api.github.com/users/ysyyork/orgs", "repos_url": "https://api.github.com/users/ysyyork/repos", "events_url": "https://api.github.com/users/ysyyork/events{/privacy}", "received_events_url": "https://api.github.com/users/ysyyork/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-01-07T17:25:06Z", "updated_at": "2021-01-08T09:39:47Z", "closed_at": "2021-01-08T09:39:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Tensorflow \r\n2. Framework version: 2.3\r\n3. Horovod version: 0.19.5\r\n4. MPI version: 4.0.0\r\n5. CUDA version: 11.1\r\n6. NCCL version: \r\n7. Python version: 3.6\r\n8. Spark / PySpark version:\r\n9. OS and version: Ubuntu\r\n10. GCC version:\r\n11. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nI'm training a keras mobilenet classification model. When I train it with single GPU, it can converge to very high (near 99%) accuracy. However when I use multiple workers, the accuracy dropped to only 50% ish with 2 workers and 40% ish with 3 workers. The more workers I used the lower the accuracy I got. This is really weird. \r\n\r\nHere is the training code:\r\n```\r\ndef main(cmd_args):\r\n    if cmd_args.gpus != 'all':\r\n        os.environ['CUDA_VISIBLE_DEVICES'] = cmd_args.gpus\r\n    hvd.init()\r\n    root_rank = cmd_args.root_rank\r\n\r\n    gpus = tf.config.experimental.list_physical_devices('GPU')\r\n    for gpu in gpus:\r\n        # tf.config.experimental.set_memory_growth(gpu, cmd_args.enable_gpu_memory_auto_growth)\r\n        tf.config.experimental.set_memory_growth(gpu, True)\r\n    if gpus:\r\n        tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\r\n\r\n    weights = None\r\n    if cmd_args.weights is not None:\r\n        weights = normpath(pathlib.Path(cmd_args.weights).expanduser().absolute())\r\n    data_path = normpath(pathlib.Path(cmd_args.data_path).expanduser().absolute())\r\n\r\n    verbose = 1 if hvd.rank() == root_rank else 0\r\n    session_id = time.time()\r\n    prefix = './checkpoints/{timestamp}_{session_id}_l2_{l2_rate}_lr_{lr}_batch_{batch_size}_folder_{folder}_{backbone}'.format(\r\n        timestamp=datetime.now().strftime(\"%Y-%M-%d-%H-%m-%S-%f\"),\r\n        session_id=session_id,\r\n        l2_rate=cmd_args.l2_rate,\r\n        batch_size=cmd_args.batch_size,\r\n        folder=data_path.split('/')[-1],\r\n        lr=cmd_args.lr,\r\n        backbone=cmd_args.backbone,\r\n    )\r\n    if cmd_args.weights_only:\r\n        checkpoint_path = '{prefix}/cp.ckpt'.format(\r\n            prefix=prefix\r\n        )\r\n    else:\r\n        checkpoint_path = '{prefix}/model'.format(\r\n            prefix=prefix\r\n        )\r\n\r\n\r\n\r\n    data_loader = DataLoader(\r\n        path=data_path,\r\n        batch_size=cmd_args.batch_size,\r\n        workers=cmd_args.workers,\r\n        max_queue_size=cmd_args.max_queue_size,\r\n        val_split=cmd_args.val_split,\r\n        shuffle=True,\r\n        verbose=verbose\r\n    )\r\n\r\n    model = ModelWrapper(\r\n        num_of_classes=data_loader.num_of_cls,\r\n        l2_rate=cmd_args.l2_rate,\r\n        weights=weights,\r\n        backbone=cmd_args.backbone,\r\n        verbose=verbose\r\n    ).model # this is just a mobilenet model. \r\n\r\n    lr = cmd_args.lr * hvd.size() * 1\r\n    if cmd_args.optimizer == 'adam':\r\n        opt = Adam(lr)\r\n    elif cmd_args.optimizer == 'sgd':\r\n        opt = SGD(lr, momentum=0.9)\r\n    opt = hvd.DistributedOptimizer(opt)\r\n\r\n    from tensorflow.keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\r\n    from tensorflow.keras.metrics import binary_accuracy, categorical_accuracy, sparse_categorical_accuracy\r\n\r\n    def custom_accuracy(y_true, y_pred):\r\n        pred_index = tf.argmax(y_pred, axis=-1)\r\n        gt_index = tf.argmax(y_true, axis=-1)\r\n        matches = tf.cast(tf.math.count_nonzero(tf.cast(pred_index == gt_index, dtype=tf.float32)), tf.float32)\r\n        total = tf.cast(tf.shape(y_true)[0], tf.float32)\r\n        res = matches / total\r\n        # tf.print(pred_index, summarize=30)\r\n        # tf.print(gt_index, summarize=30)\r\n        # tf.print(matches)\r\n        # tf.print(total)\r\n        # tf.print(res)\r\n        # tf.print(\"----------------\", summarize=30)\r\n\r\n\r\n        return res\r\n\r\n    model.compile(\r\n        optimizer=opt,\r\n        loss=categorical_crossentropy,\r\n        metrics=[\r\n            custom_accuracy, # was using the categorical_accuracy from keras but same result. \r\n            categorical_crossentropy,\r\n        ],\r\n    )\r\n\r\n\r\n    prefetch_num = 32\r\n    train_seq = data_loader.get_data_seq(mode='train')\r\n    val_seq = data_loader.get_data_seq(mode='val')\r\n\r\n    train_dataset = tf.data.Dataset.from_generator(\r\n        train_seq.get_gen,\r\n        output_types=(tf.float32, tf.float32)\r\n    ).prefetch(prefetch_num)\r\n    val_dataset = tf.data.Dataset.from_generator(\r\n        val_seq.get_gen,\r\n        output_types=(tf.float32, tf.float32)\r\n    ).prefetch(prefetch_num)\r\n    train_steps = len(train_seq) // hvd.size()\r\n    val_steps = len(val_seq) // hvd.size()\r\n\r\n\r\n    early_stop = EarlyStopping(patience=cmd_args.early_stop_patience)\r\n    reduce_lr = ReduceLROnPlateau(factor=0.5, patience=cmd_args.reduce_lr_patience)\r\n\r\n\r\n\r\n\r\n\r\n    def logging_on_epoch_begin(epoch, logs):\r\n        if verbose:\r\n            print(\"Session: {session_id}, Learning rate: {lr:e}\".format(lr=model.optimizer.lr.numpy(),\r\n                                                                        session_id=session_id))\r\n\r\n    logging_callback = LambdaCallback(\r\n        on_epoch_begin=logging_on_epoch_begin\r\n    )\r\n    final_lr = tf.convert_to_tensor(lr, dtype=tf.float32)\r\n    warmup_steps = cmd_args.warmup_steps\r\n\r\n\r\n    callbacks = [\r\n        hvd.callbacks.BroadcastGlobalVariablesCallback(root_rank),\r\n        hvd.callbacks.MetricAverageCallback(),\r\n        hvd.callbacks.LearningRateWarmupCallback(\r\n            warmup_epochs=warmup_steps,\r\n            initial_lr=lr,\r\n            verbose=verbose,\r\n            steps_per_epoch=train_steps\r\n        ),\r\n        reduce_lr,\r\n        early_stop,\r\n        logging_callback,\r\n    ]\r\n\r\n    if not cmd_args.disable_checkpoint and hvd.rank() == root_rank:\r\n        checkpoint = CustomKerasModelCheckpoint(\r\n            checkpoint_path,\r\n            monitor='val_loss',\r\n            # monitor='loss',\r\n            save_best_only=(not cmd_args.disable_save_best),\r\n            save_weights_only=cmd_args.weights_only,\r\n            mode='min',\r\n        )\r\n        callbacks.append(checkpoint)\r\n\r\n    model.fit(\r\n        train_dataset,\r\n        steps_per_epoch=train_steps,\r\n        validation_data=val_dataset,\r\n        validation_steps=val_steps,\r\n        epochs=cmd_args.epochs,\r\n        initial_epoch=cmd_args.initial_epoch,\r\n        callbacks=callbacks,\r\n        verbose=verbose,\r\n    )\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\r\n        '--data-path',\r\n        required=True\r\n    )\r\n    parser.add_argument(\r\n        '--lr',\r\n        type=float,\r\n        default=1e-4,\r\n        help=\"\"\"\r\n        Learning rate, default 1e-4\r\n        \"\"\"\r\n    )\r\n    parser.add_argument(\r\n        '--batch-size',\r\n        type=int,\r\n        default=32,\r\n        help=\"\"\"\r\n        Batch size, default 32\r\n        \"\"\"\r\n    )\r\n    parser.add_argument(\r\n        '--disable-checkpoint',\r\n        action='store_true',\r\n        help=\"\"\"\r\n        If checkpoint should be enabled.\r\n        \"\"\"\r\n    )\r\n    parser.add_argument(\r\n        '--disable-save-best',\r\n        action='store_true',\r\n        help=\"\"\"\r\n        Should the save best be disabled\r\n        \"\"\"\r\n    )\r\n    parser.add_argument(\r\n        '--weights',\r\n        type=str,\r\n        default=None,\r\n        help=\"\"\"\r\n        The weights location to load \r\n        \"\"\",\r\n    )\r\n    parser.add_argument(\r\n        '--weights-only',\r\n        action='store_true',\r\n        help=\"\"\"\r\n        If set, will only save weights otherwise save as a folder \r\n        \"\"\",\r\n    )\r\n    parser.add_argument(\r\n        '--val-split',\r\n        type=float,\r\n        default=0.15,\r\n        help=\"\"\"\r\n        Validation set split for simple data loader \r\n        \"\"\",\r\n    )\r\n    parser.add_argument(\r\n        '--workers',\r\n        type=int,\r\n        default=10,\r\n        help=\"\"\"\r\n        workers number of the data loader\r\n        \"\"\",\r\n    )\r\n    parser.add_argument(\r\n        '--max-queue-size',\r\n        type=int,\r\n        default=30,\r\n        help=\"\"\"\r\n        max queue size of the data loader\r\n        \"\"\",\r\n    )\r\n    parser.add_argument(\r\n        '--initial-epoch',\r\n        type=int,\r\n        default=0,\r\n        help=\"\"\"\r\n        Initial epoch to start with\r\n        \"\"\",\r\n    )\r\n    parser.add_argument(\r\n        '--epochs',\r\n        type=int,\r\n        default=300,\r\n        help=\"\"\"\r\n            Total epochs to run\r\n            \"\"\",\r\n    )\r\n    parser.add_argument(\r\n        '--early-stop-patience',\r\n        type=int,\r\n        default=40,\r\n        help=\"\"\"\r\n        Early stop patience\r\n        \"\"\"\r\n    )\r\n    parser.add_argument(\r\n        '--reduce-lr-patience',\r\n        type=int,\r\n        default=15,\r\n        help=\"\"\"\r\n        Reduce lr patience\r\n        \"\"\"\r\n    )\r\n    parser.add_argument(\r\n        '--l2-rate',\r\n        type=float,\r\n        default=0.0001,\r\n        help=\"\"\"\r\n        When training triplet model, you can sepecify the weight of triplet loss. \r\n        \"\"\"\r\n    )\r\n    parser.add_argument(\r\n        '--root-rank',\r\n        default=0,\r\n        type=int,\r\n        help=\"\"\"\r\n            The root rank for horovod\r\n            \"\"\"\r\n    )\r\n    parser.add_argument(\r\n        '-egmag', '--enable-gpu-memory-auto-growth',\r\n        action='store_true',\r\n        help='''\r\n            Should gpu be in auto growth mode\r\n            '''\r\n    )\r\n    parser.add_argument(\r\n        '--optimizer',\r\n        default='adam',\r\n        choices=['adam', 'sgd']\r\n    )\r\n    parser.add_argument(\r\n        '--warmup-steps',\r\n        type=float,\r\n        default=5\r\n    )\r\n    parser.add_argument(\r\n        '--backbone',\r\n        choices=['mobilenet_v2', 'mobilenet'],\r\n        default='mobilenet_v2'\r\n    )\r\n    parser.add_argument(\r\n        '--gpus',\r\n        type=str,\r\n        default='all'\r\n    )\r\n    cmd_args, unparsed = parser.parse_known_args()\r\n    print(cmd_args)\r\n\r\n    main(cmd_args)\r\n```\r\nHowever, if you comment out the line of `opt = hvd.DistributedOptimizer(opt)` and run with multiple workers, it turned normal. So I guess the issue is with this `DistributedOptimizer`. I also upgraded the horovod version to the latest 0.21.1 and change it to `opt = hvd.DistributedOptimizer(opt,  backward_passes_per_step=1, average_aggregated_gradients=True)` Problem still persist. Not sure what's happening here. \r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2579/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2579/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2574", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2574/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2574/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2574/events", "html_url": "https://github.com/horovod/horovod/issues/2574", "id": 779464776, "node_id": "MDU6SXNzdWU3Nzk0NjQ3NzY=", "number": 2574, "title": "Ray colocator test failure with nightly tests", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2021-01-05T19:28:40Z", "updated_at": "2021-01-06T18:28:34Z", "closed_at": "2021-01-06T18:28:33Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "```\r\n\r\n______________________________ test_colocator_gpu ______________________________\r\n--\r\n\u00a0 | \u00a0\r\n\u00a0 | tmpdir = local('/tmp/pytest-of-root/pytest-0/test_colocator_gpu0')\r\n\u00a0 | ray_start_4_cpus_4_gpus = {'metrics_export_port': 45147, 'node_id': 'd8e6f25f505063efe553607a1a5706ad33345eb9', 'node_ip_address': '172.18.0.2', 'object_store_address': '/tmp/ray/session_2021-01-05_19-14-35_284083_496/sockets/plasma_store', ...}\r\n\u00a0 | \u00a0\r\n\u00a0 | @pytest.mark.skipif(\r\n\u00a0 | torch.cuda.device_count() < 4, reason='GPU colocator test requires 4 GPUs')\r\n\u00a0 | @pytest.mark.skipif(\r\n\u00a0 | not torch.cuda.is_available(), reason='GPU colocator test requires CUDA')\r\n\u00a0 | def test_colocator_gpu(tmpdir, ray_start_4_cpus_4_gpus):\r\n\u00a0 | SetColocator = NodeColocator.options(num_cpus=4, num_gpus=4)\r\n\u00a0 | colocator = SetColocator.remote(\r\n\u00a0 | node_rank=0, num_slots=4, world_size=4, use_gpu=True)\r\n\u00a0 | colocator.create_workers.remote()\r\n\u00a0 | worker_handles = ray.get(colocator.get_workers.remote())\r\n\u00a0 | assert len(set(ray.get(\r\n\u00a0 | [h.hostname.remote() for h in worker_handles]))) == 1\r\n\u00a0 | resources = ray.available_resources()\r\n\u00a0 | ip_address = services.get_node_ip_address()\r\n\u00a0 | assert resources.get(\"CPU\", 0) == 0, resources\r\n\u00a0 | assert resources.get(\"GPU\", 0) == 0, resources\r\n\u00a0 | \u00a0\r\n\u00a0 | # TODO: https://github.com/horovod/horovod/issues/2438\r\n\u00a0 | # assert resources.get(f\"node:{ip_address}\", 0) == 1 - 4 * 0.01\r\n\u00a0 | \u00a0\r\n\u00a0 | all_envs = ray.get([h.env_vars.remote() for h in worker_handles])\r\n\u00a0 | >       assert len({ev[\"CUDA_VISIBLE_DEVICES\"] for ev in all_envs}) == 1\r\n\u00a0 | E       assert 2 == 1\r\n\u00a0 | E         +2\r\n\u00a0 | E         -1\r\n\u00a0 | \u00a0\r\n\u00a0 | test_ray.py:126: AssertionError\r\n\r\n\r\n```\r\n\r\nhttps://buildkite.com/horovod/horovod/builds/4633#b1bc3903-7817-461a-a806-077f454d0d57/312-397\r\n\r\ncc @richardliaw ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2574/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2574/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2568", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2568/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2568/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2568/events", "html_url": "https://github.com/horovod/horovod/issues/2568", "id": 777880231, "node_id": "MDU6SXNzdWU3Nzc4ODAyMzE=", "number": 2568, "title": "multi-node distributed training", "user": {"login": "zhao1157", "id": 12959339, "node_id": "MDQ6VXNlcjEyOTU5MzM5", "avatar_url": "https://avatars.githubusercontent.com/u/12959339?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhao1157", "html_url": "https://github.com/zhao1157", "followers_url": "https://api.github.com/users/zhao1157/followers", "following_url": "https://api.github.com/users/zhao1157/following{/other_user}", "gists_url": "https://api.github.com/users/zhao1157/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhao1157/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhao1157/subscriptions", "organizations_url": "https://api.github.com/users/zhao1157/orgs", "repos_url": "https://api.github.com/users/zhao1157/repos", "events_url": "https://api.github.com/users/zhao1157/events{/privacy}", "received_events_url": "https://api.github.com/users/zhao1157/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 23, "created_at": "2021-01-04T07:19:12Z", "updated_at": "2021-01-07T00:31:32Z", "closed_at": "2021-01-07T00:31:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "horovod version: 0.20.2\r\n\r\nI tried on two nodes and renamed the network interfaces of the two nodes so that they were the same. Before starting the docker container on the primary node, I launched a container on the secondary node with `/usr/sbin/sshd -p 22345; sleep infinity`. On the primary node if I ran ` horovodrun -np 2 -H localhost:1,secondary_node:1 -p 22345`, it hung for a while and exited with a warning \r\n\r\n> /usr/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 5 leaked semaphores to clean up at shutdown len(cache))\r\n\r\nI also tried to increase `--start-timeout`, but with no avail.\r\n\r\nAfter digging into the horovod source code and manually set `--network-interface=enx00e04c36024f`, and it worked. I wonder what causes the hang without explicitly specifying the network interface. \r\n\r\nAnother issue is the processing speed of utilizing two nodes is absurdly slower, 0.1 vs 25 images/second. Any idea on how to fix this performance degradation?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2568/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2568/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2543", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2543/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2543/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2543/events", "html_url": "https://github.com/horovod/horovod/issues/2543", "id": 772529986, "node_id": "MDU6SXNzdWU3NzI1Mjk5ODY=", "number": 2543, "title": "Race condition in CMake", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-12-21T23:33:42Z", "updated_at": "2022-01-17T17:07:31Z", "closed_at": "2022-01-17T17:07:31Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "It's been reported that Horovod can fail to build non-deterministically due to what appears to be a race condition during the CMake build process.\r\n\r\nSee https://github.com/horovod/horovod/issues/2358#issuecomment-749051099.\r\n\r\nTemporary workaround is to set `MAKEFLAGS=\"-j1\"`.\r\n\r\ncc @nvcastet @leezu @romerojosh ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2543/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2543/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2536", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2536/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2536/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2536/events", "html_url": "https://github.com/horovod/horovod/issues/2536", "id": 771083266, "node_id": "MDU6SXNzdWU3NzEwODMyNjY=", "number": 2536, "title": "Performance degredation with Spark Estimator during schema inference", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "irasit", "id": 12163435, "node_id": "MDQ6VXNlcjEyMTYzNDM1", "avatar_url": "https://avatars.githubusercontent.com/u/12163435?v=4", "gravatar_id": "", "url": "https://api.github.com/users/irasit", "html_url": "https://github.com/irasit", "followers_url": "https://api.github.com/users/irasit/followers", "following_url": "https://api.github.com/users/irasit/following{/other_user}", "gists_url": "https://api.github.com/users/irasit/gists{/gist_id}", "starred_url": "https://api.github.com/users/irasit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/irasit/subscriptions", "organizations_url": "https://api.github.com/users/irasit/orgs", "repos_url": "https://api.github.com/users/irasit/repos", "events_url": "https://api.github.com/users/irasit/events{/privacy}", "received_events_url": "https://api.github.com/users/irasit/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "irasit", "id": 12163435, "node_id": "MDQ6VXNlcjEyMTYzNDM1", "avatar_url": "https://avatars.githubusercontent.com/u/12163435?v=4", "gravatar_id": "", "url": "https://api.github.com/users/irasit", "html_url": "https://github.com/irasit", "followers_url": "https://api.github.com/users/irasit/followers", "following_url": "https://api.github.com/users/irasit/following{/other_user}", "gists_url": "https://api.github.com/users/irasit/gists{/gist_id}", "starred_url": "https://api.github.com/users/irasit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/irasit/subscriptions", "organizations_url": "https://api.github.com/users/irasit/orgs", "repos_url": "https://api.github.com/users/irasit/repos", "events_url": "https://api.github.com/users/irasit/events{/privacy}", "received_events_url": "https://api.github.com/users/irasit/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2020-12-18T18:24:21Z", "updated_at": "2021-02-04T23:00:47Z", "closed_at": "2021-02-04T23:00:47Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "#2373 solves the problem of Spark being unable to infer the schema following an operation on the underlying RDD.  However, the new schema inference process is expensive, as it requires sampling directly from the data.\r\n\r\nInstead, we should preserve the original schema when we reconstruct the DataFrame.\r\n\r\ncc @OscarDPan @thuningxu ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2536/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2536/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2493", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2493/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2493/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2493/events", "html_url": "https://github.com/horovod/horovod/issues/2493", "id": 754682065, "node_id": "MDU6SXNzdWU3NTQ2ODIwNjU=", "number": 2493, "title": "CMake error in conda env: CMake Error: The following variables are used in this project, but they are set to NOTFOUND.", "user": {"login": "jtchilders", "id": 10742392, "node_id": "MDQ6VXNlcjEwNzQyMzky", "avatar_url": "https://avatars.githubusercontent.com/u/10742392?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jtchilders", "html_url": "https://github.com/jtchilders", "followers_url": "https://api.github.com/users/jtchilders/followers", "following_url": "https://api.github.com/users/jtchilders/following{/other_user}", "gists_url": "https://api.github.com/users/jtchilders/gists{/gist_id}", "starred_url": "https://api.github.com/users/jtchilders/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jtchilders/subscriptions", "organizations_url": "https://api.github.com/users/jtchilders/orgs", "repos_url": "https://api.github.com/users/jtchilders/repos", "events_url": "https://api.github.com/users/jtchilders/events{/privacy}", "received_events_url": "https://api.github.com/users/jtchilders/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-12-01T19:58:23Z", "updated_at": "2021-01-12T13:45:47Z", "closed_at": "2021-01-12T13:45:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow, PyTorch\r\n2. Framework version: 2.3.0 and 1.7.0\r\n3. Horovod version: 0.21.0\r\n4. MPI version: 3.1\r\n5. CUDA version: none\r\n6. NCCL version: none\r\n7. Python version: 3.7.9\r\n8. Spark / PySpark version: none\r\n9. OS and version: SUSE 15\r\n10. GCC version: 8.3.0\r\n11. CMake version: 3.18.2\r\n\r\nI installed the latest Miniconda via the Shell script:\r\nhttps://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\r\n\r\nThen did\r\n`conda install tensorflow=2.3.0 pytorch=1.7.0 -c pytorch`\r\n\r\nThen I tried \r\n`pip install --no-cache-dir horovod[tensorflow,pytorch]`\r\n\r\nIt seems to find everything OK (see below) but the pytorch CMake seems to get confused about some library locations or environment variables.\r\n\r\n```bash\r\n running build_ext\r\n  -- Could not find CCache. Consider installing CCache to speed up compilation.\r\n  -- The CXX compiler identification is GNU 8.3.0\r\n  -- Cray Programming Environment 2.6.5 CXX\r\n  -- Detecting CXX compiler ABI info\r\n  -- Detecting CXX compiler ABI info - done\r\n  -- Check for working CXX compiler: /opt/cray/pe/craype/2.6.5/bin/CC - skipped\r\n  -- Detecting CXX compile features\r\n  -- Detecting CXX compile features - done\r\n  -- Build architecture flags: -mf16c -mavx -mfma\r\n  -- Using command /lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/bin/python\r\n  -- Found MPI_CXX: /opt/cray/pe/craype/2.6.5/bin/CC (found version \"3.1\")\r\n  -- Found MPI: TRUE (found version \"3.1\")\r\n  -- The C compiler identification is GNU 8.3.0\r\n  -- Cray Programming Environment 2.6.5 C\r\n  -- Detecting C compiler ABI info\r\n  -- Detecting C compiler ABI info - done\r\n  -- Check for working C compiler: /opt/cray/pe/craype/2.6.5/bin/cc - skipped\r\n  -- Detecting C compile features\r\n  -- Detecting C compile features - done\r\n  -- Found MPI_C: /opt/cray/pe/craype/2.6.5/bin/cc (found version \"3.1\")\r\n  -- Found MPI: TRUE (found version \"3.1\")\r\n  -- MPI include path:\r\n  -- MPI libraries:\r\n  -- Found Tensorflow: -L/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/site-packages/tensorflow;-l:libtensorflow_framework.so.2 (found suitable version \"2.3.0\", minimum required is \"1.15.0\")\r\n  CMake Warning (dev) at horovod/tensorflow/CMakeLists.txt:43 (add_library):\r\n    ADD_LIBRARY called with SHARED option but the target platform does not\r\n    support dynamic linking.  Building a STATIC library instead.  This may lead\r\n    to problems.\r\n  This warning is for project developers.  Use -Wno-dev to suppress it.\r\n\r\n  -- Found Pytorch: 1.7.0 (found suitable version \"1.7.0\", minimum required is \"1.2.0\")\r\n  CMake Warning (dev) at horovod/torch/CMakeLists.txt:68 (add_library):\r\n    ADD_LIBRARY called with SHARED option but the target platform does not\r\n    support dynamic linking.  Building a STATIC library instead.  This may lead\r\n    to problems.\r\n  This warning is for project developers.  Use -Wno-dev to suppress it.\r\n\r\n  -- Could NOT find Mxnet (missing: Mxnet_LIBRARIES) (Required is at least version \"1.4.0\")\r\n  -- Cray Programming Environment 2.6.5 C\r\n  -- MPI include path:\r\n  -- MPI libraries:\r\n  -- Configuring done\r\n  CMake Error: The following variables are used in this project, but they are set to NOTFOUND.\r\n  Please set them or make sure they are set and tested correctly in the CMake files:\r\n  FOUND_LIB_c10\r\n      linked by target \"pytorch\" in directory /tmp/pip-install-zzurxfof/horovod/horovod/torch\r\n  FOUND_LIB_torch\r\n      linked by target \"pytorch\" in directory /tmp/pip-install-zzurxfof/horovod/horovod/torch\r\n  FOUND_LIB_torch_cpu\r\n      linked by target \"pytorch\" in directory /tmp/pip-install-zzurxfof/horovod/horovod/torch\r\n  FOUND_LIB_torch_python\r\n      linked by target \"pytorch\" in directory /tmp/pip-install-zzurxfof/horovod/horovod/torch\r\n\r\n  -- Generating done\r\n  CMake Generate step failed.  Build files cannot be regenerated correctly.\r\n  Traceback (most recent call last):\r\n    File \"<string>\", line 1, in <module>\r\n    File \"/tmp/pip-install-zzurxfof/horovod/setup.py\", line 193, in <module>\r\n      'horovodrun = horovod.runner.launch:run_commandline'\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/site-packages/setuptools/__init__.py\", line 153, in setup\r\n      return distutils.core.setup(**attrs)\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/distutils/core.py\", line 148, in setup\r\n      dist.run_commands()\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n      self.run_command(cmd)\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/site-packages/wheel/bdist_wheel.py\", line 290, in run\r\n      self.run_command('build')\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/distutils/command/build.py\", line 135, in run\r\n      self.run_command(cmd_name)\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/site-packages/setuptools/command/build_ext.py\", line 79, in run\r\n      _build_ext.run(self)\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/distutils/command/build_ext.py\", line 340, in run\r\n      self.build_extensions()\r\n    File \"/tmp/pip-install-zzurxfof/horovod/setup.py\", line 89, in build_extensions\r\n      cwd=self.build_temp)\r\n    File \"/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/lib/python3.7/subprocess.py\", line 363, in check_call\r\n      raise CalledProcessError(retcode, cmd)\r\n  subprocess.CalledProcessError: Command '['cmake', '/tmp/pip-install-zzurxfof/horovod', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/tmp/pip-install-zzurxfof/horovod/build/lib.linux-x86_64-3.7', '-DPYTHON_EXECUTABLE:FILEPATH=/lus/theta-fs0/software/datascience/conda/miniconda3/2020-12/bin/python']' returned non-zero exit status 1.\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n  Running setup.py clean for horovod\r\nFailed to build horovod\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2493/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2493/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2474", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2474/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2474/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2474/events", "html_url": "https://github.com/horovod/horovod/issues/2474", "id": 748503833, "node_id": "MDU6SXNzdWU3NDg1MDM4MzM=", "number": 2474, "title": "0.20.3 FOUND_LIB_cudart is not set while using pip to install horovod", "user": {"login": "jihuacao", "id": 22140223, "node_id": "MDQ6VXNlcjIyMTQwMjIz", "avatar_url": "https://avatars.githubusercontent.com/u/22140223?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jihuacao", "html_url": "https://github.com/jihuacao", "followers_url": "https://api.github.com/users/jihuacao/followers", "following_url": "https://api.github.com/users/jihuacao/following{/other_user}", "gists_url": "https://api.github.com/users/jihuacao/gists{/gist_id}", "starred_url": "https://api.github.com/users/jihuacao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jihuacao/subscriptions", "organizations_url": "https://api.github.com/users/jihuacao/orgs", "repos_url": "https://api.github.com/users/jihuacao/repos", "events_url": "https://api.github.com/users/jihuacao/events{/privacy}", "received_events_url": "https://api.github.com/users/jihuacao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-11-23T06:17:10Z", "updated_at": "2020-11-25T13:43:10Z", "closed_at": "2020-11-25T13:43:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework:  PyTorch\r\n2. Framework version:1.7\r\n3. Horovod version:0.20.3\r\n4. MPI version:4.0.4\r\n5. CUDA version:11.1\r\n6. NCCL version:2.8.3\r\n7. Python version:3.6.2\r\n8. Spark / PySpark version:None\r\n9. OS and version:ubuntu 16.4\r\n10. GCC version:5.4.0\r\n11. CMake version:3.18.4\r\n\r\ncommand\uff1a \r\n HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_WITHOUT_GLOO=1 HOROVOD_WITHOUT_MXNET=1 HOROVOD_WITHOUT_TENSORFLOW=1 HOROVOD_CUDA_HOME=/usr/local/cuda proxychains pip install horovod\r\ngot\uff1a    \r\n    -- Configuring done\r\n    CMake Error: The following variables are used in this project, but they are set to NOTFOUND.\r\n    Please set them or make sure they are set and tested correctly in the CMake files:\r\n    FOUND_LIB_cudart\r\n        linked by target \"pytorch\" in directory /tmp/pip-install-a7n3i33r/horovod/horovod/torch\r\n\r\nuse  command\uff08install 0.19.5\uff09\uff1a\r\nHOROVOD_GPU_OPERATIONS=NCCL HOROVOD_WITHOUT_GLOO=1 HOROVOD_WITHOUT_MXNET=1 HOROVOD_WITHOUT_TENSORFLOW=1 HOROVOD_CUDA_HOME=/usr/local/cuda FOUND_LIB_cudart=/usr/local/cuda/lib64/libcudart.so proxychains pip install horovod==0.19.5\r\ngot\uff1a\r\n\r\nInstalling collected packages: horovod\r\nSuccessfully installed horovod-0.19.5\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2474/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2474/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2444", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2444/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2444/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2444/events", "html_url": "https://github.com/horovod/horovod/issues/2444", "id": 741822937, "node_id": "MDU6SXNzdWU3NDE4MjI5Mzc=", "number": 2444, "title": "ERROR: Command errored out with exit status 1", "user": {"login": "ashiqimranintel", "id": 65728957, "node_id": "MDQ6VXNlcjY1NzI4OTU3", "avatar_url": "https://avatars.githubusercontent.com/u/65728957?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ashiqimranintel", "html_url": "https://github.com/ashiqimranintel", "followers_url": "https://api.github.com/users/ashiqimranintel/followers", "following_url": "https://api.github.com/users/ashiqimranintel/following{/other_user}", "gists_url": "https://api.github.com/users/ashiqimranintel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ashiqimranintel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ashiqimranintel/subscriptions", "organizations_url": "https://api.github.com/users/ashiqimranintel/orgs", "repos_url": "https://api.github.com/users/ashiqimranintel/repos", "events_url": "https://api.github.com/users/ashiqimranintel/events{/privacy}", "received_events_url": "https://api.github.com/users/ashiqimranintel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-11-12T18:20:20Z", "updated_at": "2020-11-12T18:36:32Z", "closed_at": "2020-11-12T18:36:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.4\r\n3. Horovod version: 0.20.0 and 0.20.3\r\n4. MPI version: IntelMPI 2019\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version: 3.7\r\n8. Spark / PySpark version:\r\n9. OS and version: Ubuntu 18.04 OS\r\n10. GCC version: 8.1\r\n11. CMake version: 3.11.4\r\n\r\n\r\n**Bug report:**\r\nERROR: Command errored out with exit status 1: /../../../bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-rp03q5ua/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-rp03q5ua/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-9rme1nn8/install-record.txt --single-version-externally-managed --compile --install-headers /../.../.../anaconda3/include/python3.7m/horovod Check the logs for full command output\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2444/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2444/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2438", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2438/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2438/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2438/events", "html_url": "https://github.com/horovod/horovod/issues/2438", "id": 740878006, "node_id": "MDU6SXNzdWU3NDA4NzgwMDY=", "number": 2438, "title": "Unit Test: Ray Colocator test gives flaky resource availability results", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-11-11T15:58:38Z", "updated_at": "2021-01-29T08:41:28Z", "closed_at": "2021-01-29T08:41:28Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Starting from nightly build 2020/11/10, the `test_ray.py::test_colocator` has been failing sporadically with the following error:\r\n\r\n```\r\nassert resources.get(f\"node:{ip_address}\", 0) == 1 - 4 * 0.01\r\nassert 1.0 == 0.96\r\n  +1.0\r\n  -0.96\r\n```\r\n\r\nSee: https://buildkite.com/horovod/horovod/builds/4274#3f5eddde-efbd-4078-861a-8d79205d8478\r\n\r\ncc @richardliaw ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2438/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2438/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2414", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2414/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2414/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2414/events", "html_url": "https://github.com/horovod/horovod/issues/2414", "id": 734070405, "node_id": "MDU6SXNzdWU3MzQwNzA0MDU=", "number": 2414, "title": "Flaky tests", "user": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-11-01T21:51:06Z", "updated_at": "2020-12-15T17:27:48Z", "closed_at": "2020-12-15T17:27:48Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Issue to collect flaky unit tests.\r\n\r\nThe Unit Test Results comment reports failed tests:\r\n![grafik](https://user-images.githubusercontent.com/44700269/97816236-2bc4fe00-1c94-11eb-914e-31459a1c8e5d.png)\r\n\r\n... but Buildkite succeeds:\r\n![grafik](https://user-images.githubusercontent.com/44700269/97816269-6d55a900-1c94-11eb-9688-a1f7b52fc676.png)\r\n\r\nThis is because failed test job reran and eventually succeeds, hence a flaky test.\r\n\r\n- https://buildkite.com/horovod/horovod/builds/4239#4bc39604-926e-4120-9937-35220da79547\r\n  https://github.com/horovod/horovod/runs/1339365236\r\n1 out of 6 runs failed: test_hosts_added_and_removed (test.integration.test_elastic_torch.ElasticTorchTests)\r\ntest-results/factory-Elastic-Tests-test-cpu-gloo-py3_6-tf1_15_0-keras2_2_4-torch1_2_0/artifacts/junit.gloo.elastic.xml\r\n```\r\nself = <test_elastic_torch.ElasticTorchTests testMethod=test_hosts_added_and_removed>\r\nmock_get_min_start_hosts = <MagicMock name='_get_min_start_hosts' id='140507299633528'>\r\n\r\n    @mock.patch('horovod.runner.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS', 0.01)\r\n    @mock.patch('horovod.runner.gloo_run._get_min_start_hosts', return_value=1)\r\n    def test_hosts_added_and_removed(self, mock_get_min_start_hosts):\r\n        for slots, np, min_np, max_np in [(2, 2, 2, 4), (1, 1, 1, 2)]:\r\n            discovery_schedule = [\r\n                (0, ['localhost:{}'.format(slots)]),\r\n                (1, ['localhost:{}'.format(slots), '127.0.0.1:{}'.format(slots)]),\r\n                (None, ['127.0.0.1:{}'.format(slots)]),\r\n            ]\r\n    \r\n            results = self._run(discovery_schedule, np=np, min_np=min_np, max_np=max_np)\r\n    \r\n            assert len(results) == 3\r\n    \r\n            assert results[0]['start_rank'] == 0\r\n            assert results[0]['size'] == slots\r\n            assert results[0]['hostname'] == 'localhost'\r\n    \r\n            assert results[1]['start_rank'] == 0\r\n            assert results[1]['size'] == slots * 2\r\n            assert results[1]['hostname'] == 'localhost'\r\n    \r\n>           assert results[2]['start_rank'] == slots\r\nE           AssertionError\r\n\r\nelastic_common.py:138: AssertionError\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2414/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2414/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2399", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2399/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2399/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2399/events", "html_url": "https://github.com/horovod/horovod/issues/2399", "id": 729778102, "node_id": "MDU6SXNzdWU3Mjk3NzgxMDI=", "number": 2399, "title": "fail to install horovod via pip: tensorflow/core/framework/op.h: No such file or directory", "user": {"login": "b1ueshad0w", "id": 2503540, "node_id": "MDQ6VXNlcjI1MDM1NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/2503540?v=4", "gravatar_id": "", "url": "https://api.github.com/users/b1ueshad0w", "html_url": "https://github.com/b1ueshad0w", "followers_url": "https://api.github.com/users/b1ueshad0w/followers", "following_url": "https://api.github.com/users/b1ueshad0w/following{/other_user}", "gists_url": "https://api.github.com/users/b1ueshad0w/gists{/gist_id}", "starred_url": "https://api.github.com/users/b1ueshad0w/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/b1ueshad0w/subscriptions", "organizations_url": "https://api.github.com/users/b1ueshad0w/orgs", "repos_url": "https://api.github.com/users/b1ueshad0w/repos", "events_url": "https://api.github.com/users/b1ueshad0w/events{/privacy}", "received_events_url": "https://api.github.com/users/b1ueshad0w/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-10-26T17:49:26Z", "updated_at": "2021-09-09T08:55:45Z", "closed_at": "2020-10-30T17:47:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Environment:\r\n\r\nFramework: (TensorFlow, Keras, PyTorch, MXNet) TensorFLow\r\nFramework version: 1.15.0\r\nHorovod version: 0.20.3\r\nMPI version: Open MPI 4.0.0\r\nCUDA version: 10.1\r\nNCCL version: 2.7.8 (nccl-repo-rhel7-2.7.8-ga-cuda10.1-1-1.x86_64)\r\nPython version: 3.6.8\r\nSpark / PySpark version: N/A\r\nOS and version: CentOS Linux release 7.8.2003 (Core)\r\nGCC version: 4.9.2\r\nCMake version: 3.18.4\r\n\r\n## Checklist:\r\n* Did you search issues to find if somebody asked this question before? Y\r\n* If your question is about hang, did you read [this doc] (https://github.com/horovod/horovod/blob/master/docs/running.rst)? Y\r\n* If your question is about docker, did you read this doc? Y\r\n* Did you check if you question is answered in the troubleshooting guide? Y\r\n\r\n## Bug report:\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nInstalling horovo with command:\r\n```\r\nHOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITHOUT_MXNET=1 HOROVOD_NCCL_INCLUDE=/usr/include HOROVOD_NCCL_LIB=/usr/lib64 HOROVOD_CUDA_HOME=/usr/local/cuda-10.1 HOROVOD_CUDA_INCLUDE=/usr/local/cuda-10.1/include  HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_CPU_OPERATIONS=MPI HOROVOD_WITH_MPI=1 HOROVOD_WITHOUT_GLOO=1 pip3 install --no-cache-dir horovod\r\n```\r\nOutput:\r\n```\r\n... <too much>\r\n/tmp/pip-install-9hq74cjb/horovod/horovod/tensorflow/mpi_ops.cc:24:42: fatal error: tensorflow/core/framework/op.h: No such file or directory\r\n   #include \"tensorflow/core/framework/op.h\"\r\n                                            ^\r\n  compilation terminated.\r\n...\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2399/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2399/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2397", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2397/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2397/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2397/events", "html_url": "https://github.com/horovod/horovod/issues/2397", "id": 729371707, "node_id": "MDU6SXNzdWU3MjkzNzE3MDc=", "number": 2397, "title": "fail to install horovod (cmake error,  Could NOT find CUDA)", "user": {"login": "b1ueshad0w", "id": 2503540, "node_id": "MDQ6VXNlcjI1MDM1NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/2503540?v=4", "gravatar_id": "", "url": "https://api.github.com/users/b1ueshad0w", "html_url": "https://github.com/b1ueshad0w", "followers_url": "https://api.github.com/users/b1ueshad0w/followers", "following_url": "https://api.github.com/users/b1ueshad0w/following{/other_user}", "gists_url": "https://api.github.com/users/b1ueshad0w/gists{/gist_id}", "starred_url": "https://api.github.com/users/b1ueshad0w/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/b1ueshad0w/subscriptions", "organizations_url": "https://api.github.com/users/b1ueshad0w/orgs", "repos_url": "https://api.github.com/users/b1ueshad0w/repos", "events_url": "https://api.github.com/users/b1ueshad0w/events{/privacy}", "received_events_url": "https://api.github.com/users/b1ueshad0w/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-10-26T08:45:23Z", "updated_at": "2020-10-26T17:42:49Z", "closed_at": "2020-10-26T17:42:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) TensorFLow\r\n2. Framework version: 1.15.0\r\n3. Horovod version: 0.20.3\r\n4. MPI version: Open MPI 4.0.0\r\n5. CUDA version: 10.1\r\n6. NCCL version: 2.7.8 (nccl-repo-rhel7-2.7.8-ga-cuda10.1-1-1.x86_64)\r\n7. Python version: 3.6.8\r\n8. Spark / PySpark version: N/A\r\n9. OS and version: CentOS Linux release 7.8.2003 (Core)\r\n10. GCC version: 4.9.2\r\n11. CMake version: 3.18.4\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Y\r\n2. If your question is about hang, did you read [this doc] (https://github.com/horovod/horovod/blob/master/docs/running.rst)? Y\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? Y\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Y\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\nInstalling horovo with command:\r\n```\r\nCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-10.1/ HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITHOUT_MXNET=1 HOROVOD_NCCL_INCLUDE=/usr/include HOROVOD_NCCL_LIB=/usr/lib64 HOROVOD_CUDA_HOME=/usr/local/cuda-10.0 HOROVOD_CUDA_INCLUDE=/usr/local/cuda-10.0/include  HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_CPU_OPERATIONS=MPI HOROVOD_WITH_MPI=1 HOROVOD_WITHOUT_GLOO=1 pip install --no-cache-dir horovod\r\n```\r\nOutput:\r\n```\r\nLooking in indexes: http://mirrors.xxxx.com/pypi/simple\r\nCollecting horovod\r\n  Downloading http://mirrors.xxx.com/pypi/packages/6f/bd/b979db25c1337967472630714d0f98ec596ad9f199a3d1777dc36453d713/horovod-0.20.3.tar.gz (3.2 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.2 MB 640 kB/s\r\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.6/site-packages (from horovod) (1.6.0)\r\nRequirement already satisfied: psutil in /usr/local/lib64/python3.6/site-packages (from horovod) (5.7.2)\r\nRequirement already satisfied: pyyaml in /usr/local/lib64/python3.6/site-packages (from horovod) (5.1.2)\r\nRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/site-packages (from horovod) (0.7)\r\nBuilding wheels for collected packages: horovod\r\n  Building wheel for horovod (setup.py) ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-k9qpng1t/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-k9qpng1t/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-yc5ey6ps\r\n       cwd: /tmp/pip-install-k9qpng1t/horovod/\r\n  Complete output (209 lines):\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib.linux-x86_64-3.6\r\n  creating build/lib.linux-x86_64-3.6/horovod\r\n  copying horovod/__init__.py -> build/lib.linux-x86_64-3.6/horovod\r\n  creating build/lib.linux-x86_64-3.6/horovod/spark\r\n  copying horovod/spark/conf.py -> build/lib.linux-x86_64-3.6/horovod/spark\r\n  copying horovod/spark/mpi_run.py -> build/lib.linux-x86_64-3.6/horovod/spark\r\n  copying horovod/spark/runner.py -> build/lib.linux-x86_64-3.6/horovod/spark\r\n  copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark\r\n  copying horovod/spark/gloo_run.py -> build/lib.linux-x86_64-3.6/horovod/spark\r\n  creating build/lib.linux-x86_64-3.6/horovod/_keras\r\n  copying horovod/_keras/elastic.py -> build/lib.linux-x86_64-3.6/horovod/_keras\r\n  copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/_keras\r\n  copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/_keras\r\n  creating build/lib.linux-x86_64-3.6/horovod/ray\r\n  copying horovod/ray/elastic.py -> build/lib.linux-x86_64-3.6/horovod/ray\r\n  copying horovod/ray/runner.py -> build/lib.linux-x86_64-3.6/horovod/ray\r\n  copying horovod/ray/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/ray\r\n  copying horovod/ray/__init__.py -> build/lib.linux-x86_64-3.6/horovod/ray\r\n  creating build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  copying horovod/tensorflow/functions.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  copying horovod/tensorflow/sync_batch_norm.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  copying horovod/tensorflow/elastic.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n  creating build/lib.linux-x86_64-3.6/horovod/keras\r\n  copying horovod/keras/elastic.py -> build/lib.linux-x86_64-3.6/horovod/keras\r\n  copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/keras\r\n  copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/keras\r\n  creating build/lib.linux-x86_64-3.6/horovod/torch\r\n  copying horovod/torch/functions.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n  copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n  copying horovod/torch/sync_batch_norm.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n  copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n  copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n  copying horovod/torch/optimizer.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n  creating build/lib.linux-x86_64-3.6/horovod/mxnet\r\n  copying horovod/mxnet/functions.py -> build/lib.linux-x86_64-3.6/horovod/mxnet\r\n  copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/mxnet\r\n  copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.6/horovod/mxnet\r\n  creating build/lib.linux-x86_64-3.6/horovod/common\r\n  copying horovod/common/basics.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n  copying horovod/common/elastic.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n  copying horovod/common/exceptions.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n  copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n  copying horovod/common/util.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n  creating build/lib.linux-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/run_task.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/task_fn.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/launch.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/mpi_run.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/js_run.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n  copying horovod/runner/gloo_run.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n  creating build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n  creating build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n  copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n  copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n  copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n  copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n  creating build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  copying horovod/spark/driver/host_discovery.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  copying horovod/spark/driver/rsh.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  copying horovod/spark/driver/rendezvous.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n  creating build/lib.linux-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/gloo_exec_fn.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n  copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n  creating build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n  creating build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/elastic.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n  creating build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib_impl\r\n  copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib_impl\r\n  creating build/lib.linux-x86_64-3.6/horovod/torch/elastic\r\n  copying horovod/torch/elastic/sampler.py -> build/lib.linux-x86_64-3.6/horovod/torch/elastic\r\n  copying horovod/torch/elastic/state.py -> build/lib.linux-x86_64-3.6/horovod/torch/elastic\r\n  copying horovod/torch/elastic/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/elastic\r\n  creating build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib\r\n  copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib\r\n  creating build/lib.linux-x86_64-3.6/horovod/runner/util\r\n  copying horovod/runner/util/threads.py -> build/lib.linux-x86_64-3.6/horovod/runner/util\r\n  copying horovod/runner/util/cache.py -> build/lib.linux-x86_64-3.6/horovod/runner/util\r\n  copying horovod/runner/util/network.py -> build/lib.linux-x86_64-3.6/horovod/runner/util\r\n  copying horovod/runner/util/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/util\r\n  copying horovod/runner/util/lsf.py -> build/lib.linux-x86_64-3.6/horovod/runner/util\r\n  copying horovod/runner/util/remote.py -> build/lib.linux-x86_64-3.6/horovod/runner/util\r\n  creating build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n  copying horovod/runner/elastic/discovery.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n  copying horovod/runner/elastic/driver.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n  copying horovod/runner/elastic/settings.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n  copying horovod/runner/elastic/registration.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n  copying horovod/runner/elastic/worker.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n  copying horovod/runner/elastic/constants.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n  copying horovod/runner/elastic/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n  copying horovod/runner/elastic/rendezvous.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n  creating build/lib.linux-x86_64-3.6/horovod/runner/driver\r\n  copying horovod/runner/driver/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/runner/driver\r\n  copying horovod/runner/driver/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/driver\r\n  creating build/lib.linux-x86_64-3.6/horovod/runner/task\r\n  copying horovod/runner/task/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/task\r\n  copying horovod/runner/task/task_service.py -> build/lib.linux-x86_64-3.6/horovod/runner/task\r\n  creating build/lib.linux-x86_64-3.6/horovod/runner/common\r\n  copying horovod/runner/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/common\r\n  creating build/lib.linux-x86_64-3.6/horovod/runner/http\r\n  copying horovod/runner/http/http_server.py -> build/lib.linux-x86_64-3.6/horovod/runner/http\r\n  copying horovod/runner/http/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/http\r\n  copying horovod/runner/http/http_client.py -> build/lib.linux-x86_64-3.6/horovod/runner/http\r\n  creating build/lib.linux-x86_64-3.6/horovod/runner/common/service\r\n  copying horovod/runner/common/service/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/service\r\n  copying horovod/runner/common/service/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/service\r\n  copying horovod/runner/common/service/task_service.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/service\r\n  creating build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  copying horovod/runner/common/util/codec.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  copying horovod/runner/common/util/tiny_shell_exec.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  copying horovod/runner/common/util/config_parser.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  copying horovod/runner/common/util/timeout.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  copying horovod/runner/common/util/network.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  copying horovod/runner/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  copying horovod/runner/common/util/settings.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  copying horovod/runner/common/util/hosts.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  copying horovod/runner/common/util/secret.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  copying horovod/runner/common/util/env.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  copying horovod/runner/common/util/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  copying horovod/runner/common/util/host_hash.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n  running build_ext\r\n  -- The CXX compiler identification is GNU 4.9.2\r\n  -- Detecting CXX compiler ABI info\r\n  -- Detecting CXX compiler ABI info - done\r\n  -- Check for working CXX compiler: /usr/local/bin/c++ - skipped\r\n  -- Detecting CXX compile features\r\n  -- Detecting CXX compile features - done\r\n  -- Build architecture flags: -mf16c -mavx -mfma\r\n  -- Using command /usr/bin/python3\r\n  -- Found MPI_CXX: /usr/local/lib/libmpi.so (found version \"3.1\")\r\n  -- Found MPI: TRUE (found version \"3.1\")\r\n  CMake Error at /usr/local/share/cmake-3.18/Modules/FindPackageHandleStandardArgs.cmake:165 (message):\r\n    Could NOT find CUDA (missing: CUDA_INCLUDE_DIRS) (found version \"10.1\")\r\n  Call Stack (most recent call first):\r\n    /usr/local/share/cmake-3.18/Modules/FindPackageHandleStandardArgs.cmake:458 (_FPHSA_FAILURE_MESSAGE)\r\n    /usr/local/share/cmake-3.18/Modules/FindCUDA.cmake:1119 (find_package_handle_standard_args)\r\n    CMakeLists.txt:139 (find_package)\r\n    CMakeLists.txt:157 (add_cuda)\r\n\r\n\r\n  -- Configuring incomplete, errors occurred!\r\n  See also \"/tmp/pip-install-k9qpng1t/horovod/build/temp.linux-x86_64-3.6/CMakeFiles/CMakeOutput.log\".\r\n  Traceback (most recent call last):\r\n    File \"<string>\", line 1, in <module>\r\n    File \"/tmp/pip-install-k9qpng1t/horovod/setup.py\", line 191, in <module>\r\n      'horovodrun = horovod.runner.launch:run_commandline'\r\n    File \"/usr/local/lib/python3.6/site-packages/setuptools/__init__.py\", line 153, in setup\r\n      return distutils.core.setup(**attrs)\r\n    File \"/usr/lib64/python3.6/distutils/core.py\", line 148, in setup\r\n      dist.run_commands()\r\n    File \"/usr/lib64/python3.6/distutils/dist.py\", line 955, in run_commands\r\n      self.run_command(cmd)\r\n    File \"/usr/lib64/python3.6/distutils/dist.py\", line 974, in run_command\r\n      cmd_obj.run()\r\n    File \"/usr/local/lib/python3.6/site-packages/wheel/bdist_wheel.py\", line 290, in run\r\n      self.run_command('build')\r\n    File \"/usr/lib64/python3.6/distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"/usr/lib64/python3.6/distutils/dist.py\", line 974, in run_command\r\n      cmd_obj.run()\r\n    File \"/usr/lib64/python3.6/distutils/command/build.py\", line 135, in run\r\n      self.run_command(cmd_name)\r\n    File \"/usr/lib64/python3.6/distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"/usr/lib64/python3.6/distutils/dist.py\", line 974, in run_command\r\n      cmd_obj.run()\r\n    File \"/usr/local/lib/python3.6/site-packages/setuptools/command/build_ext.py\", line 79, in run\r\n      _build_ext.run(self)\r\n    File \"/usr/lib64/python3.6/distutils/command/build_ext.py\", line 339, in run\r\n      self.build_extensions()\r\n    File \"/tmp/pip-install-k9qpng1t/horovod/setup.py\", line 89, in build_extensions\r\n      cwd=self.build_temp)\r\n    File \"/usr/lib64/python3.6/subprocess.py\", line 311, in check_call\r\n      raise CalledProcessError(retcode, cmd)\r\n  subprocess.CalledProcessError: Command '['cmake', '/tmp/pip-install-k9qpng1t/horovod', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/tmp/pip-install-k9qpng1t/horovod/build/lib.linux-x86_64-3.6', '-DPYTHON_EXECUTABLE:FILEPATH=/usr/bin/python3']' returned non-zero exit status 1.\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n  Running setup.py clean for horovod\r\nFailed to build horovod\r\nInstalling collected packages: horovod\r\n    Running setup.py install for horovod ... error\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-k9qpng1t/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-k9qpng1t/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-g1xtpica/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.6m/horovod\r\n         cwd: /tmp/pip-install-k9qpng1t/horovod/\r\n    Complete output (211 lines):\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.6\r\n    creating build/lib.linux-x86_64-3.6/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-3.6/horovod\r\n    creating build/lib.linux-x86_64-3.6/horovod/spark\r\n    copying horovod/spark/conf.py -> build/lib.linux-x86_64-3.6/horovod/spark\r\n    copying horovod/spark/mpi_run.py -> build/lib.linux-x86_64-3.6/horovod/spark\r\n    copying horovod/spark/runner.py -> build/lib.linux-x86_64-3.6/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark\r\n    copying horovod/spark/gloo_run.py -> build/lib.linux-x86_64-3.6/horovod/spark\r\n    creating build/lib.linux-x86_64-3.6/horovod/_keras\r\n    copying horovod/_keras/elastic.py -> build/lib.linux-x86_64-3.6/horovod/_keras\r\n    copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/_keras\r\n    copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/_keras\r\n    creating build/lib.linux-x86_64-3.6/horovod/ray\r\n    copying horovod/ray/elastic.py -> build/lib.linux-x86_64-3.6/horovod/ray\r\n    copying horovod/ray/runner.py -> build/lib.linux-x86_64-3.6/horovod/ray\r\n    copying horovod/ray/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/ray\r\n    copying horovod/ray/__init__.py -> build/lib.linux-x86_64-3.6/horovod/ray\r\n    creating build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    copying horovod/tensorflow/functions.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    copying horovod/tensorflow/sync_batch_norm.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    copying horovod/tensorflow/elastic.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\r\n    creating build/lib.linux-x86_64-3.6/horovod/keras\r\n    copying horovod/keras/elastic.py -> build/lib.linux-x86_64-3.6/horovod/keras\r\n    copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/keras\r\n    copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/keras\r\n    creating build/lib.linux-x86_64-3.6/horovod/torch\r\n    copying horovod/torch/functions.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n    copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n    copying horovod/torch/sync_batch_norm.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n    copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n    copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n    copying horovod/torch/optimizer.py -> build/lib.linux-x86_64-3.6/horovod/torch\r\n    creating build/lib.linux-x86_64-3.6/horovod/mxnet\r\n    copying horovod/mxnet/functions.py -> build/lib.linux-x86_64-3.6/horovod/mxnet\r\n    copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/mxnet\r\n    copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.6/horovod/mxnet\r\n    creating build/lib.linux-x86_64-3.6/horovod/common\r\n    copying horovod/common/basics.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n    copying horovod/common/elastic.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n    copying horovod/common/exceptions.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n    copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n    copying horovod/common/util.py -> build/lib.linux-x86_64-3.6/horovod/common\r\n    creating build/lib.linux-x86_64-3.6/horovod/runner\r\n    copying horovod/runner/run_task.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n    copying horovod/runner/task_fn.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n    copying horovod/runner/launch.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n    copying horovod/runner/mpi_run.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n    copying horovod/runner/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n    copying horovod/runner/js_run.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n    copying horovod/runner/gloo_run.py -> build/lib.linux-x86_64-3.6/horovod/runner\r\n    creating build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.6/horovod/spark/keras\r\n    creating build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n    copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n    copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n    copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n    copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.6/horovod/spark/torch\r\n    creating build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    copying horovod/spark/driver/host_discovery.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    copying horovod/spark/driver/rsh.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    copying horovod/spark/driver/rendezvous.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\r\n    creating build/lib.linux-x86_64-3.6/horovod/spark/task\r\n    copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n    copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n    copying horovod/spark/task/gloo_exec_fn.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n    copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n    copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\r\n    creating build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.6/horovod/spark/common\r\n    creating build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/elastic.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\r\n    creating build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib_impl\r\n    creating build/lib.linux-x86_64-3.6/horovod/torch/elastic\r\n    copying horovod/torch/elastic/sampler.py -> build/lib.linux-x86_64-3.6/horovod/torch/elastic\r\n    copying horovod/torch/elastic/state.py -> build/lib.linux-x86_64-3.6/horovod/torch/elastic\r\n    copying horovod/torch/elastic/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/elastic\r\n    creating build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib\r\n    creating build/lib.linux-x86_64-3.6/horovod/runner/util\r\n    copying horovod/runner/util/threads.py -> build/lib.linux-x86_64-3.6/horovod/runner/util\r\n    copying horovod/runner/util/cache.py -> build/lib.linux-x86_64-3.6/horovod/runner/util\r\n    copying horovod/runner/util/network.py -> build/lib.linux-x86_64-3.6/horovod/runner/util\r\n    copying horovod/runner/util/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/util\r\n    copying horovod/runner/util/lsf.py -> build/lib.linux-x86_64-3.6/horovod/runner/util\r\n    copying horovod/runner/util/remote.py -> build/lib.linux-x86_64-3.6/horovod/runner/util\r\n    creating build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n    copying horovod/runner/elastic/discovery.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n    copying horovod/runner/elastic/driver.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n    copying horovod/runner/elastic/settings.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n    copying horovod/runner/elastic/registration.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n    copying horovod/runner/elastic/worker.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n    copying horovod/runner/elastic/constants.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n    copying horovod/runner/elastic/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n    copying horovod/runner/elastic/rendezvous.py -> build/lib.linux-x86_64-3.6/horovod/runner/elastic\r\n    creating build/lib.linux-x86_64-3.6/horovod/runner/driver\r\n    copying horovod/runner/driver/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/runner/driver\r\n    copying horovod/runner/driver/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/driver\r\n    creating build/lib.linux-x86_64-3.6/horovod/runner/task\r\n    copying horovod/runner/task/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/task\r\n    copying horovod/runner/task/task_service.py -> build/lib.linux-x86_64-3.6/horovod/runner/task\r\n    creating build/lib.linux-x86_64-3.6/horovod/runner/common\r\n    copying horovod/runner/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/common\r\n    creating build/lib.linux-x86_64-3.6/horovod/runner/http\r\n    copying horovod/runner/http/http_server.py -> build/lib.linux-x86_64-3.6/horovod/runner/http\r\n    copying horovod/runner/http/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/http\r\n    copying horovod/runner/http/http_client.py -> build/lib.linux-x86_64-3.6/horovod/runner/http\r\n    creating build/lib.linux-x86_64-3.6/horovod/runner/common/service\r\n    copying horovod/runner/common/service/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/service\r\n    copying horovod/runner/common/service/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/service\r\n    copying horovod/runner/common/service/task_service.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/service\r\n    creating build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    copying horovod/runner/common/util/codec.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    copying horovod/runner/common/util/tiny_shell_exec.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    copying horovod/runner/common/util/config_parser.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    copying horovod/runner/common/util/timeout.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    copying horovod/runner/common/util/network.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    copying horovod/runner/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    copying horovod/runner/common/util/settings.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    copying horovod/runner/common/util/hosts.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    copying horovod/runner/common/util/secret.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    copying horovod/runner/common/util/env.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    copying horovod/runner/common/util/__init__.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    copying horovod/runner/common/util/host_hash.py -> build/lib.linux-x86_64-3.6/horovod/runner/common/util\r\n    running build_ext\r\n    -- The CXX compiler identification is GNU 4.9.2\r\n    -- Detecting CXX compiler ABI info\r\n    -- Detecting CXX compiler ABI info - done\r\n    -- Check for working CXX compiler: /usr/local/bin/c++ - skipped\r\n    -- Detecting CXX compile features\r\n    -- Detecting CXX compile features - done\r\n    -- Build architecture flags: -mf16c -mavx -mfma\r\n    -- Using command /usr/bin/python3\r\n    -- Found MPI_CXX: /usr/local/lib/libmpi.so (found version \"3.1\")\r\n    -- Found MPI: TRUE (found version \"3.1\")\r\n    CMake Error at /usr/local/share/cmake-3.18/Modules/FindPackageHandleStandardArgs.cmake:165 (message):\r\n      Could NOT find CUDA (missing: CUDA_INCLUDE_DIRS) (found version \"10.1\")\r\n    Call Stack (most recent call first):\r\n      /usr/local/share/cmake-3.18/Modules/FindPackageHandleStandardArgs.cmake:458 (_FPHSA_FAILURE_MESSAGE)\r\n      /usr/local/share/cmake-3.18/Modules/FindCUDA.cmake:1119 (find_package_handle_standard_args)\r\n      CMakeLists.txt:139 (find_package)\r\n      CMakeLists.txt:157 (add_cuda)\r\n\r\n\r\n    -- Configuring incomplete, errors occurred!\r\n    See also \"/tmp/pip-install-k9qpng1t/horovod/build/temp.linux-x86_64-3.6/CMakeFiles/CMakeOutput.log\".\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/tmp/pip-install-k9qpng1t/horovod/setup.py\", line 191, in <module>\r\n        'horovodrun = horovod.runner.launch:run_commandline'\r\n      File \"/usr/local/lib/python3.6/site-packages/setuptools/__init__.py\", line 153, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/usr/lib64/python3.6/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/usr/lib64/python3.6/distutils/dist.py\", line 955, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/usr/lib64/python3.6/distutils/dist.py\", line 974, in run_command\r\n        cmd_obj.run()\r\n      File \"/usr/local/lib/python3.6/site-packages/setuptools/command/install.py\", line 61, in run\r\n        return orig.install.run(self)\r\n      File \"/usr/lib64/python3.6/distutils/command/install.py\", line 556, in run\r\n        self.run_command('build')\r\n      File \"/usr/lib64/python3.6/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/usr/lib64/python3.6/distutils/dist.py\", line 974, in run_command\r\n        cmd_obj.run()\r\n      File \"/usr/lib64/python3.6/distutils/command/build.py\", line 135, in run\r\n        self.run_command(cmd_name)\r\n      File \"/usr/lib64/python3.6/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/usr/lib64/python3.6/distutils/dist.py\", line 974, in run_command\r\n        cmd_obj.run()\r\n      File \"/usr/local/lib/python3.6/site-packages/setuptools/command/build_ext.py\", line 79, in run\r\n        _build_ext.run(self)\r\n      File \"/usr/lib64/python3.6/distutils/command/build_ext.py\", line 339, in run\r\n        self.build_extensions()\r\n      File \"/tmp/pip-install-k9qpng1t/horovod/setup.py\", line 89, in build_extensions\r\n        cwd=self.build_temp)\r\n      File \"/usr/lib64/python3.6/subprocess.py\", line 311, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['cmake', '/tmp/pip-install-k9qpng1t/horovod', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=/tmp/pip-install-k9qpng1t/horovod/build/lib.linux-x86_64-3.6', '-DPYTHON_EXECUTABLE:FILEPATH=/usr/bin/python3']' returned non-zero exit status 1.\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-k9qpng1t/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-k9qpng1t/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-g1xtpica/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.6m/horovod Check the logs for full command output.\r\n```\r\nEnvironment variables:\r\n```\r\n# echo $PATH\r\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/usr/local/cuda/lib64:/usr/local/cuda/bin:/usr/local/cuda-10.1/bin:/usr/local/cuda-10.1/bin:/usr/local/cuda-10.1/bin:/usr/local/cuda-10.1/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/usr/local/cuda/lib64:/usr/local/cuda/bin:/root/bin\r\n# echo $LD_LIBRARY_PATH\r\n/usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/lib64::/usr/local/cuda/lib64\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2397/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2397/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2378", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2378/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2378/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2378/events", "html_url": "https://github.com/horovod/horovod/issues/2378", "id": 722574041, "node_id": "MDU6SXNzdWU3MjI1NzQwNDE=", "number": 2378, "title": "Collectives performance ", "user": {"login": "bureddy", "id": 4983664, "node_id": "MDQ6VXNlcjQ5ODM2NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/4983664?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bureddy", "html_url": "https://github.com/bureddy", "followers_url": "https://api.github.com/users/bureddy/followers", "following_url": "https://api.github.com/users/bureddy/following{/other_user}", "gists_url": "https://api.github.com/users/bureddy/gists{/gist_id}", "starred_url": "https://api.github.com/users/bureddy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bureddy/subscriptions", "organizations_url": "https://api.github.com/users/bureddy/orgs", "repos_url": "https://api.github.com/users/bureddy/repos", "events_url": "https://api.github.com/users/bureddy/events{/privacy}", "received_events_url": "https://api.github.com/users/bureddy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-10-15T18:36:38Z", "updated_at": "2020-10-15T18:42:52Z", "closed_at": "2020-10-15T18:42:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow-CPU\r\n2. Framework version: 2.3.1\r\n3. Horovod version: 0.20.3\r\n4. MPI version: OpenMPI 4.0.4rc3\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.6.9\r\n8. Spark / PySpark version:\r\n9. OS and version: Ubuntu 18.04\r\n10. GCC version:\r\n11. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\n\r\nI'm seeing Collective performance is significantly lower with TF-CPU/HOROVOD compared to native MPI performance with OSU microbenchmarks. In this specific case, it is a simple 5MB all to all .\r\n\r\nthe below results are with 1 process per node, process bind to CPU socket, 8 nodes, message size:5MB.\r\nMPI                      : ~ 3000 us\r\nTF/HOROVOD      : ~30000 us\r\n\r\nI have put the timers inside MPI library around the  MPI_Alltoallv to get accurate timings in both cases.\r\nIt seems the Issue looks like related to the noise coming from existing of many threads in TF.\r\nis this expected behavior? is there any tining will improve the collective performance. \r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2378/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2378/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2367", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2367/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2367/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2367/events", "html_url": "https://github.com/horovod/horovod/issues/2367", "id": 719834798, "node_id": "MDU6SXNzdWU3MTk4MzQ3OTg=", "number": 2367, "title": "Horovod throws UnicodeDecodeError when using tqdm", "user": {"login": "hhaoyan", "id": 3487815, "node_id": "MDQ6VXNlcjM0ODc4MTU=", "avatar_url": "https://avatars.githubusercontent.com/u/3487815?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hhaoyan", "html_url": "https://github.com/hhaoyan", "followers_url": "https://api.github.com/users/hhaoyan/followers", "following_url": "https://api.github.com/users/hhaoyan/following{/other_user}", "gists_url": "https://api.github.com/users/hhaoyan/gists{/gist_id}", "starred_url": "https://api.github.com/users/hhaoyan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hhaoyan/subscriptions", "organizations_url": "https://api.github.com/users/hhaoyan/orgs", "repos_url": "https://api.github.com/users/hhaoyan/repos", "events_url": "https://api.github.com/users/hhaoyan/events{/privacy}", "received_events_url": "https://api.github.com/users/hhaoyan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 20, "created_at": "2020-10-13T03:48:21Z", "updated_at": "2020-11-02T00:54:34Z", "closed_at": "2020-11-02T00:54:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.2.0\r\n3. Horovod version: 0.19.5\r\n4. MPI version: None\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.7.8.1\r\n7. Python version: 3.6.12\r\n8. Spark / PySpark version: None\r\n9. OS and version: Linux 4.14.105-1-tlinux3-0010\r\n10. GCC version: 5.2.0\r\n11. CMake version: 2.8.12.2\r\n\r\n**What happened?**\r\nWhen using `horovod` together with `tqdm`, `horovod` throws `UnicodeDecodeError` when `tqdm` is progressing the bar display:\r\n\r\n```\r\nTue Oct 13 10:54:25 2020[0]<stderr>:[10/13/2020 10:54:25 - INFO - __main__ -   start running validation...\r\nTue Oct 13 10:54:25 2020[0]<stderr>:  0%|          | 0/1327 [00:00<?, ?it/s]\r\nTue Oct 13 10:55:56 2020[0]<stderr>:\r\nException in thread Thread-17:derr>: 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 866/1327 [01:17<00:47,  9.80it/s]\r\nTraceback (most recent call last):\r\n  File \"/data/anaconda3/envs/vcr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/data/anaconda3/envs/vcr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/runner/common/util/safe_shell_exec.py\", line 104, in forward_stream\r\n    text = text.decode('utf-8')\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xe2 in position 999: unexpected end of data\r\n\r\nTue Oct 13 10:58:56 2020[3]<stderr>:[2020-10-13 10:58:56.365049: E /dockerdata/app/tmp/pip-install-998q9kn4/horovod/horovod/common/operations.cc:525] Horovod background loop uncaught exception: [/dockerdata/app/tmp/pip-install-998q9kn4/horovod/third_party/compatible_gloo/gloo/transport/tcp/unbound_buffer.cc:84] Timed out waiting 30000ms for recv operation to complete\r\nTue Oct 13 10:58:56 2020[2]<stderr>:[2020-10-13 10:58:56.366492: E /dockerdata/app/tmp/pip-install-998q9kn4/horovod/horovod/common/operations.cc:525] Horovod background loop uncaught exception: [/dockerdata/app/tmp/pip-install-998q9kn4/horovod/third_party/compatible_gloo/gloo/transport/tcp/unbound_buffer.cc:84] Timed out waiting 30000ms for recv operation to complete\r\nTue Oct 13 10:58:56 2020[1]<stderr>:[2020-10-13 10:58:56.366674: E /dockerdata/app/tmp/pip-install-998q9kn4/horovod/horovod/common/operations.cc:525] Horovod background loop uncaught exception: [/dockerdata/app/tmp/pip-install-998q9kn4/horovod/third_party/compatible_gloo/gloo/transport/tcp/unbound_buffer.cc:136] Timed out waiting 30000ms for send operation to complete\r\nTue Oct 13 10:58:56 2020[3]<stderr>:Traceback (most recent call last):\r\nTue Oct 13 10:58:56 2020[1]<stderr>:Traceback (most recent call last):\r\nTue Oct 13 10:58:56 2020[3]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 622, in synchronize\r\nTue Oct 13 10:58:56 2020[2]<stderr>:Traceback (most recent call last):\r\nTue Oct 13 10:58:56 2020[3]<stderr>:    mpi_lib.horovod_torch_wait_and_clear(handle)\r\nTue Oct 13 10:58:56 2020[2]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 622, in synchronize\r\nTue Oct 13 10:58:56 2020[3]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\nTue Oct 13 10:58:56 2020[1]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 622, in synchronize\r\nTue Oct 13 10:58:56 2020[3]<stderr>:\r\nTue Oct 13 10:58:56 2020[1]<stderr>:    mpi_lib.horovod_torch_wait_and_clear(handle)\r\nTue Oct 13 10:58:56 2020[2]<stderr>:    mpi_lib.horovod_torch_wait_and_clear(handle)\r\nTue Oct 13 10:58:57 2020[3]<stderr>:During handling of the above exception, another exception occurred:\r\nTue Oct 13 10:58:57 2020[2]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\nTue Oct 13 10:58:57 2020[1]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\nTue Oct 13 10:58:57 2020[3]<stderr>:\r\nTue Oct 13 10:58:57 2020[1]<stderr>:\r\nTue Oct 13 10:58:57 2020[2]<stderr>:\r\nTue Oct 13 10:58:57 2020[3]<stderr>:Traceback (most recent call last):\r\nTue Oct 13 10:58:57 2020[2]<stderr>:During handling of the above exception, another exception occurred:\r\nTue Oct 13 10:58:57 2020[1]<stderr>:During handling of the above exception, another exception occurred:\r\nTue Oct 13 10:58:57 2020[3]<stderr>:  File \"train_vcr.py\", line 332, in <module>\r\nTue Oct 13 10:58:57 2020[1]<stderr>:\r\nTue Oct 13 10:58:57 2020[3]<stderr>:    main(parse_cmd_args(TrainingOpts))\r\nTue Oct 13 10:58:57 2020[1]<stderr>:Traceback (most recent call last):\r\nTue Oct 13 10:58:57 2020[3]<stderr>:  File \"train_vcr.py\", line 260, in main\r\nTue Oct 13 10:58:57 2020[1]<stderr>:  File \"train_vcr.py\", line 332, in <module>\r\nTue Oct 13 10:58:57 2020[3]<stderr>:    val_log = validate(model, val_dataloader)\r\nTue Oct 13 10:58:57 2020[1]<stderr>:    main(parse_cmd_args(TrainingOpts))\r\nTue Oct 13 10:58:57 2020[3]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 49, in decorate_no_grad\r\nTue Oct 13 10:58:57 2020[1]<stderr>:  File \"train_vcr.py\", line 260, in main\r\nTue Oct 13 10:58:57 2020[3]<stderr>:    return func(*args, **kwargs)\r\nTue Oct 13 10:58:57 2020[1]<stderr>:    val_log = validate(model, val_dataloader)\r\nTue Oct 13 10:58:58 2020[3]<stderr>:  File \"train_vcr.py\", line 310, in validate\r\nTue Oct 13 10:58:58 2020[1]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 49, in decorate_no_grad\r\nTue Oct 13 10:58:57 2020[2]<stderr>:\r\nTue Oct 13 10:58:58 2020[3]<stderr>:    qa_loss = sum(all_gather_list(qa_loss))\r\nTue Oct 13 10:58:58 2020[1]<stderr>:    return func(*args, **kwargs)\r\nTue Oct 13 10:58:58 2020[2]<stderr>:Traceback (most recent call last):\r\nTue Oct 13 10:58:58 2020[1]<stderr>:  File \"train_vcr.py\", line 310, in validate\r\nTue Oct 13 10:58:58 2020[2]<stderr>:  File \"train_vcr.py\", line 332, in <module>\r\nTue Oct 13 10:58:58 2020[3]<stderr>:  File \"/data/cdp_algo_ceph_ssd/users/haoyanhuo/vcr/utils/distributed.py\", line 233, in all_gather_list\r\nTue Oct 13 10:58:58 2020[2]<stderr>:    main(parse_cmd_args(TrainingOpts))\r\nTue Oct 13 10:58:58 2020[3]<stderr>:    max_size = hvd.allgather(torch.tensor([enc_size]).cuda()).max().item()\r\nTue Oct 13 10:58:58 2020[1]<stderr>:    qa_loss = sum(all_gather_list(qa_loss))\r\nTue Oct 13 10:58:58 2020[2]<stderr>:  File \"train_vcr.py\", line 260, in main\r\nTue Oct 13 10:58:58 2020[3]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 365, in allgather\r\nTue Oct 13 10:58:58 2020[2]<stderr>:    val_log = validate(model, val_dataloader)\r\nTue Oct 13 10:58:58 2020[3]<stderr>:    return HorovodAllgather.apply(tensor, name)\r\nTue Oct 13 10:58:58 2020[1]<stderr>:  File \"/data/cdp_algo_ceph_ssd/users/haoyanhuo/vcr/utils/distributed.py\", line 233, in all_gather_list\r\nTue Oct 13 10:58:58 2020[2]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 49, in decorate_no_grad\r\nTue Oct 13 10:58:58 2020[1]<stderr>:    max_size = hvd.allgather(torch.tensor([enc_size]).cuda()).max().item()\r\nTue Oct 13 10:58:58 2020[3]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 328, in forward\r\nTue Oct 13 10:58:59 2020[2]<stderr>:    return func(*args, **kwargs)\r\nTue Oct 13 10:58:59 2020[3]<stderr>:    return synchronize(handle)\r\nTue Oct 13 10:58:59 2020[2]<stderr>:  File \"train_vcr.py\", line 310, in validate\r\nTue Oct 13 10:58:59 2020[3]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 626, in synchronize\r\nTue Oct 13 10:58:59 2020[2]<stderr>:    qa_loss = sum(all_gather_list(qa_loss))\r\nTue Oct 13 10:58:59 2020[3]<stderr>:    raise HorovodInternalError(e)\r\nTue Oct 13 10:58:59 2020[2]<stderr>:  File \"/data/cdp_algo_ceph_ssd/users/haoyanhuo/vcr/utils/distributed.py\", line 233, in all_gather_list\r\nTue Oct 13 10:58:59 2020[3]<stderr>:horovod.common.exceptions.HorovodInternalError: Horovod has been shut down. This was causedby an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finishedexecution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\nTue Oct 13 10:58:59 2020[1]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 365, in allgather\r\nTue Oct 13 10:58:59 2020[2]<stderr>:    max_size = hvd.allgather(torch.tensor([enc_size]).cuda()).max().item()\r\nTue Oct 13 10:58:59 2020[2]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 365, in allgather\r\nTue Oct 13 10:58:59 2020[1]<stderr>:    return HorovodAllgather.apply(tensor, name)\r\nTue Oct 13 10:58:59 2020[1]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 328, in forward\r\nTue Oct 13 10:58:59 2020[2]<stderr>:    return HorovodAllgather.apply(tensor, name)\r\nTue Oct 13 10:58:59 2020[2]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 328, in forward\r\nTue Oct 13 10:58:59 2020[1]<stderr>:    return synchronize(handle)\r\nTue Oct 13 10:58:59 2020[1]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 626, in synchronize\r\nTue Oct 13 10:58:59 2020[2]<stderr>:    return synchronize(handle)\r\nTue Oct 13 10:58:59 2020[1]<stderr>:    raise HorovodInternalError(e)\r\nTue Oct 13 10:59:00 2020[2]<stderr>:  File \"/data/anaconda3/envs/vcr/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 626, in synchronize\r\nTue Oct 13 10:59:00 2020[1]<stderr>:horovod.common.exceptions.HorovodInternalError: Horovod has been shut down. This was causedby an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finishedexecution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\nTue Oct 13 10:59:00 2020[2]<stderr>:    raise HorovodInternalError(e)\r\nTue Oct 13 10:59:00 2020[2]<stderr>:horovod.common.exceptions.HorovodInternalError: Horovod has been shut down. This was causedby an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finishedexecution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n```\r\n\r\n**Reasons for this issue**\r\nThis is due to a truncated (since `horovod` only captures 1000 bytes) UTF8 code. For example, the above error was due to a truncated black box character `0xe2 0x96 0x88` used by `tqdm` to indicate progress. The following is an example of the bytes produced by `tqdm`. Pay attention to bytes `0x00059960-0x00059970`:\r\n```\r\n...\r\n00059930  30 5d 3c 73 74 64 65 72  72 3e 3a 0d 54 75 65 20  |0]<stderr>:.Tue |\r\n00059940  4f 63 74 20 31 33 20 31  30 3a 35 35 3a 35 35 20  |Oct 13 10:55:55 |\r\n00059950  32 30 32 30 5b 30 5d 3c  73 74 64 65 72 72 3e 3a  |2020[0]<stderr>:|\r\n00059960  20 36 35 25 7c e2 96 88  e2 96 88 e2 96 88 e2 96  | 65%|...........|\r\n00059970  88 e2 96 88 e2 96 88 e2  96 8d 20 20 20 7c 20 38  |..........   | 8|\r\n00059980  35 38 2f 31 33 32 37 20  5b 30 31 3a 31 37 3c 30  |58/1327 [01:17<0|\r\n00059990  30 3a 34 34 2c 20 31 30  2e 34 33 69 74 2f 73 5d  |0:44, 10.43it/s]|\r\n000599a0  1b 5b 41 1b 5b 41 0a 54  75 65 20 4f 63 74 20 31  |.[A.[A.Tue Oct 1|\r\n000599b0  33 20 31 30 3a 35 35 3a  35 35 20 32 30 32 30 5b  |3 10:55:55 2020[|\r\n000599c0  30 5d 3c 73 74 64 65 72  72 3e 3a 0a 54 75 65 20  |0]<stderr>:.Tue |\r\n...\r\n```\r\n\r\nI think `horovod` needs a better way of handling program outputs, either pipe them in binary or delay the decoding of partially captured UTF8 codes.\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2367/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2367/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2355", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2355/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2355/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2355/events", "html_url": "https://github.com/horovod/horovod/issues/2355", "id": 716064534, "node_id": "MDU6SXNzdWU3MTYwNjQ1MzQ=", "number": 2355, "title": "Horovod Build Failed with Tensorflow master ", "user": {"login": "ashiqimranintel", "id": 65728957, "node_id": "MDQ6VXNlcjY1NzI4OTU3", "avatar_url": "https://avatars.githubusercontent.com/u/65728957?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ashiqimranintel", "html_url": "https://github.com/ashiqimranintel", "followers_url": "https://api.github.com/users/ashiqimranintel/followers", "following_url": "https://api.github.com/users/ashiqimranintel/following{/other_user}", "gists_url": "https://api.github.com/users/ashiqimranintel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ashiqimranintel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ashiqimranintel/subscriptions", "organizations_url": "https://api.github.com/users/ashiqimranintel/orgs", "repos_url": "https://api.github.com/users/ashiqimranintel/repos", "events_url": "https://api.github.com/users/ashiqimranintel/events{/privacy}", "received_events_url": "https://api.github.com/users/ashiqimranintel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-10-06T22:31:15Z", "updated_at": "2020-11-09T15:56:31Z", "closed_at": "2020-10-07T01:05:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.4\r\n3. Horovod version: 0.20.3\r\n4. MPI version: 3.0.0\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.7\r\n8. Spark / PySpark version: N/A\r\n9. OS and version: Ubuntu 18.04\r\n10. GCC version: 7.5\r\n11. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? Yes\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? Yes\r\n4. Did you check if you question is answered in the [troubleshooting guide(https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? No\r\n\r\n**Bug report:**\r\n  horovod/tensorflow/CMakeFiles/tensorflow.dir/build.make:734: recipe for target 'horovod/tensorflow/CMakeFiles/tensorflow.dir/mpi_ops.cc.o' failed\r\n  make[2]: *** [horovod/tensorflow/CMakeFiles/tensorflow.dir/mpi_ops.cc.o] Error 1\r\n  make[2]: *** Waiting for unfinished jobs....\r\n  make[2]: Leaving directory '/tmp/pip-install-tnsdnjow/horovod/build/temp.linux-x86_64-3.7'\r\n  CMakeFiles/Makefile2:259: recipe for target 'horovod/tensorflow/CMakeFiles/tensorflow.dir/all' failed\r\n  make[1]: *** [horovod/tensorflow/CMakeFiles/tensorflow.dir/all] Error 2\r\n  make[1]: Leaving directory '/tmp/pip-install-tnsdnjow/horovod/build/temp.linux-x86_64-3.7'\r\n  Makefile:129: recipe for target 'all' failed\r\n  make: *** [all] Error 2\r\n  Traceback (most recent call last):\r\n    File \"<string>\", line 1, in <module>\r\n    File \"/tmp/pip-install-tnsdnjow/horovod/setup.py\", line 191, in <module>\r\n      'horovodrun = horovod.runner.launch:run_commandline'\r\n    File \"/localdisk/aimran/private-tensorflow2.4bin/setuptools/__init__.py\", line 153, in setup\r\n      return distutils.core.setup(**attrs)\r\n    File \"/anaconda3/lib/python3.7/distutils/core.py\", line 148, in setup\r\n      dist.run_commands()\r\n    File \"/anaconda3/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n      self.run_command(cmd)\r\n    File \"/anaconda3/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"/localdisk/aimran/private-tensorflow2.4bin/wheel/bdist_wheel.py\", line 290, in run\r\n      self.run_command('build')\r\n    File \"/anaconda3/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"/anaconda3/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"/anaconda3/lib/python3.7/distutils/command/build.py\", line 135, in run\r\n      self.run_command(cmd_name)\r\n    File \"/anaconda3/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"anaconda3/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"/localdisk/aimran/private-tensorflow2.4bin/setuptools/command/build_ext.py\", line 79, in run\r\n      _build_ext.run(self)\r\n    File \"anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\r\n      _build_ext.build_ext.run(self)\r\n    File \"anaconda3/lib/python3.7/distutils/command/build_ext.py\", line 340, in run\r\n      self.build_extensions()\r\n    File \"/tmp/pip-install-tnsdnjow/horovod/setup.py\", line 91, in build_extensions\r\n      cwd=self.build_temp)\r\n    File \"anaconda3/lib/python3.7/subprocess.py\", line 363, in check_call\r\n      raise CalledProcessError(retcode, cmd)\r\n  subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--config', 'RelWithDebInfo', '--', '-j8', 'VERBOSE=1']' returned non-zero exit status 2.\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2355/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2355/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2354", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2354/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2354/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2354/events", "html_url": "https://github.com/horovod/horovod/issues/2354", "id": 715704666, "node_id": "MDU6SXNzdWU3MTU3MDQ2NjY=", "number": 2354, "title": "Examples fail: munmap_chunk(): invalid pointer", "user": {"login": "PaulKarlshoeferBULL", "id": 42809608, "node_id": "MDQ6VXNlcjQyODA5NjA4", "avatar_url": "https://avatars.githubusercontent.com/u/42809608?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PaulKarlshoeferBULL", "html_url": "https://github.com/PaulKarlshoeferBULL", "followers_url": "https://api.github.com/users/PaulKarlshoeferBULL/followers", "following_url": "https://api.github.com/users/PaulKarlshoeferBULL/following{/other_user}", "gists_url": "https://api.github.com/users/PaulKarlshoeferBULL/gists{/gist_id}", "starred_url": "https://api.github.com/users/PaulKarlshoeferBULL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PaulKarlshoeferBULL/subscriptions", "organizations_url": "https://api.github.com/users/PaulKarlshoeferBULL/orgs", "repos_url": "https://api.github.com/users/PaulKarlshoeferBULL/repos", "events_url": "https://api.github.com/users/PaulKarlshoeferBULL/events{/privacy}", "received_events_url": "https://api.github.com/users/PaulKarlshoeferBULL/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2020-10-06T13:57:39Z", "updated_at": "2020-11-10T08:25:26Z", "closed_at": "2020-11-10T08:25:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow2\r\n2. Framework version: 2.2\r\n3. Horovod version: latest 20.3\r\n4. MPI version: 4.0.1\r\n5. CUDA version: 10.1.105\r\n6. NCCL version: 2\r\n7. Python version: 3.6.8\r\n8. Spark / PySpark version:\r\n9. OS and version: RHEL 7.4\r\n10. GCC version: 7.3\r\n11. CMake version: 3.13\r\n\r\nHello,\r\nI installed horovod on a fresh python3.6 with TF2.\r\nI installed using the following flags:\r\n`HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITHOUT_GLOO=1 HOROVOD_CUDA_INCLUDE=/usr/local/cuda/10.1.105/include/ HOROVOD_NCCL_INCLUDE=/users/bull/bullacc/Miniprojects/Horovod/resources/nccl-master/build/include/ HOROVOD_NCCL_LIB=/users/bull/bullacc/Miniprojects/Horovod/resources/nccl-master/build/lib/ HOROVOD_GPU_OPERATIONS=NCCL pip3.6 install --no-index --find-links file:///... --prefix=... .`\r\n\r\nI run the TF2 examples like so:\r\n`$PYTHONPATH/horovodrun -np 4 -H localhost:4 $PYTHONPATH/python3.6 $HOROVOD_EXAMPLES/tensorflow2_synthetic_benchmark.py`\r\n\r\nWith any example, I run into this error:\r\n```\r\n[1,2]<stderr>:*** Error in `/users/bull/bullacc/Miniprojects/Horovod_2/install/bin/python3.6': munmap_chunk(): invalid pointer: 0x0000000059ea0770 ***\r\n[1,2]<stderr>:======= Backtrace: =========\r\n[1,2]<stderr>:/usr/lib64/libc.so.6(+0x7ab54)[0x2aef7877cb54]\r\n[1,2]<stderr>:/usr/local/openmpi/gnu/3.1.5/lib/libmpi.so.40(ompi_coll_base_allreduce_intra_recursivedoubling+0x40a)[0x2af06d9d08ea]\r\n[1,2]<stderr>:/usr/local/openmpi/gnu/3.1.5/lib/libmpi.so.40(PMPI_Allreduce+0x14f)[0x2af06d990d7f]\r\n[1,2]<stderr>:/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common13MPIController19CrossRankBitwiseAndERSt6vectorIxSaIxEEi+0x2c)[0x2af0654b655c]\r\n[1,2]<stderr>:/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common16CacheCoordinator4syncESt10shared_ptrINS0_10ControllerEEb+0x19a)[0x2af06547f99a]\r\n[1,2]<stderr>:/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common10Controller23CoordinateCacheAndStateERNS0_16CacheCoordinatorE+0x5f)[0x2af06544ab2f]\r\n[1,2]<stderr>:/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common10Controller19ComputeResponseListERSt6atomicIbERNS0_18HorovodGlobalStateE+0x23c7)[0x2af0654523f7]\r\n[1,2]<stderr>:/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0x74b29)[0x2af06546db29]\r\n[1,2]<stderr>:/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so.2(+0x173375f)[0x2af05758275f]\r\n[1,2]<stderr>:/usr/lib64/libpthread.so.0(+0x7e25)[0x2aef77de4e25]\r\n[1,2]<stderr>:/usr/lib64/libc.so.6(clone+0x6d)[0x2aef787fa34d]\r\n```\r\nWhat is wrong? Thanks for your help!\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2354/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2336", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2336/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2336/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2336/events", "html_url": "https://github.com/horovod/horovod/issues/2336", "id": 709516178, "node_id": "MDU6SXNzdWU3MDk1MTYxNzg=", "number": 2336, "title": "Error ready_event.cc", "user": {"login": "joequant", "id": 2908185, "node_id": "MDQ6VXNlcjI5MDgxODU=", "avatar_url": "https://avatars.githubusercontent.com/u/2908185?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joequant", "html_url": "https://github.com/joequant", "followers_url": "https://api.github.com/users/joequant/followers", "following_url": "https://api.github.com/users/joequant/following{/other_user}", "gists_url": "https://api.github.com/users/joequant/gists{/gist_id}", "starred_url": "https://api.github.com/users/joequant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joequant/subscriptions", "organizations_url": "https://api.github.com/users/joequant/orgs", "repos_url": "https://api.github.com/users/joequant/repos", "events_url": "https://api.github.com/users/joequant/events{/privacy}", "received_events_url": "https://api.github.com/users/joequant/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-09-26T10:56:01Z", "updated_at": "2020-10-02T17:55:19Z", "closed_at": "2020-10-02T17:55:19Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. Spark / PySpark version:\r\n9. OS and version:\r\n10. GCC version:\r\n11. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nBuild error in 0.20.1\r\n\r\n01-install-python.sh    horovod>=v0.20.1          /tmp/pip-install-y4hzs7wm/horovod/horovod/torch/ready_event.cc: In function \u2018std::shared_ptr<horovod::common::ReadyEvent> horovod::torch::RecordR\r\neadyEvent(int)\u2019:                                                                                                                                                                                   \r\n01-install-python.sh    horovod>=v0.20.1          /tmp/pip-install-y4hzs7wm/horovod/horovod/torch/ready_event.cc:109:16: error: \u2018logic_error\u2019 is not a member of \u2018std\u2019                             \r\n01-install-python.sh    horovod>=v0.20.1            109 |     throw std::logic_error(\"Internal error. Requested ReadyEvent \"                                                                       \r\n01-install-python.sh    horovod>=v0.20.1                |                ^~~~~~~~~~~                                                                                                               \r\n01-install-python.sh    horovod>=v0.20.1          /tmp/pip-install-y4hzs7wm/horovod/horovod/torch/ready_event.cc:113:1: warning: control reaches end of non-void function [-Wreturn-type]          \r\n01-install-python.sh    horovod>=v0.20.1            113 | }                                                                                                                                        \r\n01-install-python.sh    horovod>=v0.20.1                | ^     \r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2336/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2336/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2318", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2318/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2318/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2318/events", "html_url": "https://github.com/horovod/horovod/issues/2318", "id": 707769741, "node_id": "MDU6SXNzdWU3MDc3Njk3NDE=", "number": 2318, "title": "cmake handling of GLIBCXX_USE_CXX11_ABI broken", "user": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-09-24T00:44:40Z", "updated_at": "2020-09-24T00:47:46Z", "closed_at": "2020-09-24T00:47:46Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Current CMakeLists.txt declares a special compatible gloo based on variables to be set by the `Find$FRAMEWORK.cmake` files:\r\n\r\nhttps://github.com/horovod/horovod/blob/543c4be18a5f2e32d7023e9d5e20c7dfe8cf9899/CMakeLists.txt#L290-L299\r\n\r\nThe `Find$FRAMEWORK.cmake` are invoked via\r\n\r\nhttps://github.com/horovod/horovod/blob/543c4be18a5f2e32d7023e9d5e20c7dfe8cf9899/CMakeLists.txt#L278-L283\r\n\r\nHowever, `add_subdirectory` creates a new scope and thus the variables set by `Find$FRAMEWORK.cmake` are all undefined in the main CMakeLists.txt and the compatible gloo will never be built.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2318/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2318/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2312", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2312/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2312/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2312/events", "html_url": "https://github.com/horovod/horovod/issues/2312", "id": 706284875, "node_id": "MDU6SXNzdWU3MDYyODQ4NzU=", "number": 2312, "title": "Multiple independent model instances with GradientTape and tf.function", "user": {"login": "P-Schumacher", "id": 24903880, "node_id": "MDQ6VXNlcjI0OTAzODgw", "avatar_url": "https://avatars.githubusercontent.com/u/24903880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/P-Schumacher", "html_url": "https://github.com/P-Schumacher", "followers_url": "https://api.github.com/users/P-Schumacher/followers", "following_url": "https://api.github.com/users/P-Schumacher/following{/other_user}", "gists_url": "https://api.github.com/users/P-Schumacher/gists{/gist_id}", "starred_url": "https://api.github.com/users/P-Schumacher/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/P-Schumacher/subscriptions", "organizations_url": "https://api.github.com/users/P-Schumacher/orgs", "repos_url": "https://api.github.com/users/P-Schumacher/repos", "events_url": "https://api.github.com/users/P-Schumacher/events{/privacy}", "received_events_url": "https://api.github.com/users/P-Schumacher/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-09-22T11:07:00Z", "updated_at": "2020-09-23T13:17:44Z", "closed_at": "2020-09-23T13:03:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.3.0.\r\n3. Horovod version: 0.20.0\r\n4. MPI version: 4.0.3\r\n5. CUDA version: N.A.\r\n6. NCCL version: N.A.\r\n7. Python version: 3.7.4.\r\n8. Spark / PySpark version: N.A.\r\n9. OS and version: Pop!_OS 20.04 LTS\r\n10. GCC version: 9.3.0.\r\n11. CMake version: 3.17.12.\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nAt the moment, I am using TensorFlow 2 custom training loops, i.e. GradientTape, and then use \r\n`tape = hvd.DistributedGradientTape(tape) `\r\n(and all other necessary horovod functions) to distribute training. I only use a local CPU at the moment. My run command is \r\n`mpirun -n 4 python3 main.py`\r\nThis works fine.\r\nIf I want to parallelize multiple different models in one program, I use this line every time I want to parallelize the gradient computation.\r\nThis also works fine.\r\n\r\nIf, however, I use DistributedGradientTape with multiple models in one program and I wrap the tape computation with tf.function to increase performance, I get the following error:\r\n\r\n`One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. \r\n`\r\n\r\nI guess horovod cannot distinguish the different tape instances inside the static computation graph induced by tf.function and tries to apply gradients of one model to the other, which is not possible.\r\n\r\nSo my question is, how can I use horovod to parallelize multiple independent models in one script, using DistributedGradientTape and tf.function?\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2312/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2312/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2311", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2311/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2311/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2311/events", "html_url": "https://github.com/horovod/horovod/issues/2311", "id": 706267286, "node_id": "MDU6SXNzdWU3MDYyNjcyODY=", "number": 2311, "title": "Performance is worse after rebuilding C++ code", "user": {"login": "zhao1157", "id": 12959339, "node_id": "MDQ6VXNlcjEyOTU5MzM5", "avatar_url": "https://avatars.githubusercontent.com/u/12959339?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhao1157", "html_url": "https://github.com/zhao1157", "followers_url": "https://api.github.com/users/zhao1157/followers", "following_url": "https://api.github.com/users/zhao1157/following{/other_user}", "gists_url": "https://api.github.com/users/zhao1157/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhao1157/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhao1157/subscriptions", "organizations_url": "https://api.github.com/users/zhao1157/orgs", "repos_url": "https://api.github.com/users/zhao1157/repos", "events_url": "https://api.github.com/users/zhao1157/events{/privacy}", "received_events_url": "https://api.github.com/users/zhao1157/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2020-09-22T10:41:28Z", "updated_at": "2020-09-23T18:26:12Z", "closed_at": "2020-09-23T09:33:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "I built a horovod image using the official `Dockerfile.gpu` file. In its container, I rebuilt horovod using the latest master branch of horovod source code, and compared the performance of the horovod I built from source (hereafter `horovod-rebuilt`)and the one in the original horovod docker image (hereafter `horovod-docker`). The result was quite a surprise. \r\n\r\n1. MNIST with 8 V100 GPUs: I did some tests with the script `tensorflow2_keras_mnist.py` in the docker container `/example` directory, and found `horovod-docker` got a performance of `~20 ms/step` while `horovod-rebuilt` got `~40 ms/step`. I thought this might be due to the `c++` code, so I exchanged the `.so` files in `horovod-docker` and `horovod-rebuilt` and redid the tests. It showed that the `.so` file in the original `horovod-docker` got `~20 ms/step` while the one in the original `horovod-rebuitl` got `~40 ms/step`.\r\n\r\n2. Resnet50 with 8/1 V100 GPUs: I also did some tests on `Resnet50`. All my tests showed that the `.so` file from the original `horovod-docker` always performed better than the one I built myself did. For 8 GPUs, the former reached `~2200 images/s` and the latter `~1400 images/s`. For 1 GPU, the former `~366 images/s` and the latter `~ 355 images/s`.\r\n\r\nSo I think there must be something I missed when building horovod from the current master branch. The command I used is just `python setup.py install`. I am not sure what I missed that is included in the `.so` file in `horovod-docker`. ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2311/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2311/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2310", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2310/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2310/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2310/events", "html_url": "https://github.com/horovod/horovod/issues/2310", "id": 706208428, "node_id": "MDU6SXNzdWU3MDYyMDg0Mjg=", "number": 2310, "title": "Library not loaded: @rpath/libtensorflow_framework.1.dylib", "user": {"login": "WangHeguan", "id": 35328798, "node_id": "MDQ6VXNlcjM1MzI4Nzk4", "avatar_url": "https://avatars.githubusercontent.com/u/35328798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WangHeguan", "html_url": "https://github.com/WangHeguan", "followers_url": "https://api.github.com/users/WangHeguan/followers", "following_url": "https://api.github.com/users/WangHeguan/following{/other_user}", "gists_url": "https://api.github.com/users/WangHeguan/gists{/gist_id}", "starred_url": "https://api.github.com/users/WangHeguan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WangHeguan/subscriptions", "organizations_url": "https://api.github.com/users/WangHeguan/orgs", "repos_url": "https://api.github.com/users/WangHeguan/repos", "events_url": "https://api.github.com/users/WangHeguan/events{/privacy}", "received_events_url": "https://api.github.com/users/WangHeguan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-09-22T09:13:10Z", "updated_at": "2020-09-22T14:30:59Z", "closed_at": "2020-09-22T14:30:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)TensorFlow==2.3.0\r\n2. Framework version:\r\n3. Horovod version:0.19.5\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:3.7\r\n8. Spark / PySpark version:2.4\r\n9. OS and version:mac os\r\n10. GCC version:4.9\r\n11. CMake version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nTraceback (most recent call last):\r\n  File \"/Users/heguanwang/Documents/code/spark-keras/lstm_horovod.py\", line 94, in <module>\r\n    keras_model = keras_estimator.fit(sdf).setOutputCols(['predict'])\r\n  File \"/usr/local/lib/python3.7/site-packages/horovod/spark/common/estimator.py\", line 37, in fit\r\n    return super(HorovodEstimator, self).fit(df, params)\r\n  File \"/usr/local/lib/python3.7/site-packages/pyspark/ml/base.py\", line 132, in fit\r\n    return self._fit(dataset)\r\n  File \"/usr/local/lib/python3.7/site-packages/horovod/spark/common/estimator.py\", line 82, in _fit\r\n    backend, train_rows, val_rows, metadata, avg_row_size, dataset_idx)\r\n  File \"/usr/local/lib/python3.7/site-packages/horovod/spark/keras/estimator.py\", line 278, in _fit_on_prepared_data\r\n    serialized_model = self._compile_model(keras_utils)\r\n  File \"/usr/local/lib/python3.7/site-packages/horovod/spark/keras/estimator.py\", line 327, in _compile_model\r\n    dist_optimizer = keras_utils.get_horovod().DistributedOptimizer(**dist_optimizer_args)\r\n  File \"/usr/local/lib/python3.7/site-packages/horovod/spark/keras/util.py\", line 83, in get_horovod\r\n    return TFKerasUtil.horovod_fn()()\r\n  File \"/usr/local/lib/python3.7/site-packages/horovod/spark/keras/util.py\", line 88, in fn\r\n    import horovod.tensorflow.keras as hvd\r\n  File \"/usr/local/lib/python3.7/site-packages/horovod/tensorflow/__init__.py\", line 28, in <module>\r\n    from horovod.tensorflow.mpi_ops import allgather, broadcast, _allreduce\r\n  File \"/usr/local/lib/python3.7/site-packages/horovod/tensorflow/mpi_ops.py\", line 49, in <module>\r\n    MPI_LIB = _load_library('mpi_lib' + get_ext_suffix())\r\n  File \"/usr/local/lib/python3.7/site-packages/horovod/tensorflow/mpi_ops.py\", line 45, in _load_library\r\n    library = load_library.load_op_library(filename)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/load_library.py\", line 58, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: dlopen(/usr/local/lib/python3.7/site-packages/horovod/tensorflow/mpi_lib.cpython-37m-darwin.so, 6): Library not loaded: @rpath/libtensorflow_framework.1.dylib\r\n  Referenced from: /usr/local/lib/python3.7/site-packages/horovod/tensorflow/mpi_lib.cpython-37m-darwin.so\r\n  Reason: image not found\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2310/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2310/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2309", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2309/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2309/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2309/events", "html_url": "https://github.com/horovod/horovod/issues/2309", "id": 706082171, "node_id": "MDU6SXNzdWU3MDYwODIxNzE=", "number": 2309, "title": "run horovod with cpu", "user": {"login": "WangHeguan", "id": 35328798, "node_id": "MDQ6VXNlcjM1MzI4Nzk4", "avatar_url": "https://avatars.githubusercontent.com/u/35328798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WangHeguan", "html_url": "https://github.com/WangHeguan", "followers_url": "https://api.github.com/users/WangHeguan/followers", "following_url": "https://api.github.com/users/WangHeguan/following{/other_user}", "gists_url": "https://api.github.com/users/WangHeguan/gists{/gist_id}", "starred_url": "https://api.github.com/users/WangHeguan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WangHeguan/subscriptions", "organizations_url": "https://api.github.com/users/WangHeguan/orgs", "repos_url": "https://api.github.com/users/WangHeguan/repos", "events_url": "https://api.github.com/users/WangHeguan/events{/privacy}", "received_events_url": "https://api.github.com/users/WangHeguan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-09-22T05:11:22Z", "updated_at": "2020-09-22T14:30:28Z", "closed_at": "2020-09-22T14:30:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow==2.3.0\r\n2. Framework version:\r\n3. Horovod version:0.19.5\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:3.7\r\n8. Spark / PySpark version:2.4\r\n9. OS and version:mac\r\n10. GCC version:\r\n11. CMake version:3.18.2\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nTraceback (most recent call last):\r\n  File \"/Users/heguanwang/Documents/code/spark-keras/lstm_horovod.py\", line 94, in <module>\r\n    keras_model = keras_estimator.fit(sdf).setOutputCols(['predict'])\r\n  File \"/Users/heguanwang/Library/Python/3.7/lib/python/site-packages/horovod/spark/common/estimator.py\", line 37, in fit\r\n    return super(HorovodEstimator, self).fit(df, params)\r\n  File \"/usr/local/lib/python3.7/site-packages/pyspark/ml/base.py\", line 132, in fit\r\n    return self._fit(dataset)\r\n  File \"/Users/heguanwang/Library/Python/3.7/lib/python/site-packages/horovod/spark/common/estimator.py\", line 82, in _fit\r\n    backend, train_rows, val_rows, metadata, avg_row_size, dataset_idx)\r\n  File \"/Users/heguanwang/Library/Python/3.7/lib/python/site-packages/horovod/spark/keras/estimator.py\", line 278, in _fit_on_prepared_data\r\n    serialized_model = self._compile_model(keras_utils)\r\n  File \"/Users/heguanwang/Library/Python/3.7/lib/python/site-packages/horovod/spark/keras/estimator.py\", line 327, in _compile_model\r\n    dist_optimizer = keras_utils.get_horovod().DistributedOptimizer(**dist_optimizer_args)\r\n  File \"/Users/heguanwang/Library/Python/3.7/lib/python/site-packages/horovod/spark/keras/util.py\", line 83, in get_horovod\r\n    return TFKerasUtil.horovod_fn()()\r\n  File \"/Users/heguanwang/Library/Python/3.7/lib/python/site-packages/horovod/spark/keras/util.py\", line 88, in fn\r\n    import horovod.tensorflow.keras as hvd\r\n  File \"/Users/heguanwang/Library/Python/3.7/lib/python/site-packages/horovod/tensorflow/__init__.py\", line 28, in <module>\r\n    from horovod.tensorflow.mpi_ops import allgather, broadcast, _allreduce\r\n  File \"/Users/heguanwang/Library/Python/3.7/lib/python/site-packages/horovod/tensorflow/mpi_ops.py\", line 49, in <module>\r\n    MPI_LIB = _load_library('mpi_lib' + get_ext_suffix())\r\n  File \"/Users/heguanwang/Library/Python/3.7/lib/python/site-packages/horovod/tensorflow/mpi_ops.py\", line 45, in _load_library\r\n    library = load_library.load_op_library(filename)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/load_library.py\", line 58, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\n\r\ntensorflow.python.framework.errors_impl.NotFoundError: dlopen(/Users/heguanwang/Library/Python/3.7/lib/python/site-packages/horovod/tensorflow/mpi_lib.cpython-37m-darwin.so, 6): Symbol not found: __ZN10tensorflow11GetNodeAttrERKNS_9AttrSliceEN4absl11string_viewEPi\r\n  Referenced from: /Users/heguanwang/Library/Python/3.7/lib/python/site-packages/horovod/tensorflow/mpi_lib.cpython-37m-darwin.so\r\n  Expected in: /usr/local/lib/python3.7/site-packages/tensorflow/libtensorflow_framework.2.3.0.dylib\r\n in /Users/heguanwang/Library/Python/3.7/lib/python/site-packages/horovod/tensorflow/mpi_lib.cpython-37m-darwin.so\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2309/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2309/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2299", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2299/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2299/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2299/events", "html_url": "https://github.com/horovod/horovod/issues/2299", "id": 705282947, "node_id": "MDU6SXNzdWU3MDUyODI5NDc=", "number": 2299, "title": "Horovod test segfaults with MXNet 1.7.0", "user": {"login": "austinmw", "id": 12224358, "node_id": "MDQ6VXNlcjEyMjI0MzU4", "avatar_url": "https://avatars.githubusercontent.com/u/12224358?v=4", "gravatar_id": "", "url": "https://api.github.com/users/austinmw", "html_url": "https://github.com/austinmw", "followers_url": "https://api.github.com/users/austinmw/followers", "following_url": "https://api.github.com/users/austinmw/following{/other_user}", "gists_url": "https://api.github.com/users/austinmw/gists{/gist_id}", "starred_url": "https://api.github.com/users/austinmw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/austinmw/subscriptions", "organizations_url": "https://api.github.com/users/austinmw/orgs", "repos_url": "https://api.github.com/users/austinmw/repos", "events_url": "https://api.github.com/users/austinmw/events{/privacy}", "received_events_url": "https://api.github.com/users/austinmw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-09-21T05:02:15Z", "updated_at": "2020-11-09T22:01:58Z", "closed_at": "2020-11-09T22:01:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: MXNet\r\n2. Framework version: 1.7.0\r\n3. Horovod version: 0.20.0\r\n4. MPI version: 4.0.0\r\n5. CUDA version: 10.1\r\n6. NCCL version: 2.7.8-1+cuda10.1\r\n7. Python version: 3.7\r\n8. Spark / PySpark version: X\r\n9. OS and version: Ubuntu 18.04\r\n10. GCC version: 7.5.0\r\n11. CMake version: 3.10.2\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc] (https://github.com/horovod/horovod/blob/master/docs/docker.rst)? Yes\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Bug report:**\r\n\r\nI built the GPU Dockerfile and replaced `ENV MXNET_VERSION=1.6.0.post0` with `ENV MXNET_VERSION=1.7.0`. The following test then segfaults (running on an `ml.p3.8xlarge` EC2 instance):\r\n\r\n```bash\r\nnvidia-docker run -it --network=host horovod:latest\r\nhorovodrun -np 4 -H localhost:4 python mxnet_mnist.py\r\n```\r\n\r\nOutput:\r\n\r\n```\r\n2020-09-21 04:53:46.358824: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n[1,2]<stderr>:INFO:root:Namespace(batch_size=64, dtype='float32', epochs=5, gradient_predivide_factor=1.0, lr=0.01, momentum=0.9, no_cuda=False)\r\n[1,0]<stderr>:INFO:root:Namespace(batch_size=64, dtype='float32', epochs=5, gradient_predivide_factor=1.0, lr=0.01, momentum=0.9, no_cuda=False)\r\n[1,3]<stderr>:INFO:root:Namespace(batch_size=64, dtype='float32', epochs=5, gradient_predivide_factor=1.0, lr=0.01, momentum=0.9, no_cuda=False)\r\n[1,1]<stderr>:INFO:root:Namespace(batch_size=64, dtype='float32', epochs=5, gradient_predivide_factor=1.0, lr=0.01, momentum=0.9, no_cuda=False)\r\n[1,3]<stderr>:INFO:root:downloaded http://data.mxnet.io/mxnet/data/mnist.zip into data-3/mnist.zip successfully\r\n[1,1]<stderr>:INFO:root:downloaded http://data.mxnet.io/mxnet/data/mnist.zip into data-1/mnist.zip successfully\r\n[1,2]<stderr>:INFO:root:downloaded http://data.mxnet.io/mxnet/data/mnist.zip into data-2/mnist.zip successfully\r\n[1,3]<stderr>:[04:53:51] src/io/iter_mnist.cc:113: MNISTIter: load 15000 images, shuffle=1, shape=[64,1,28,28]\r\n[1,1]<stderr>:[04:53:51] src/io/iter_mnist.cc:113: MNISTIter: load 15000 images, shuffle=1, shape=[[1,1]<stderr>:64,1,28,28]\r\n[1,2]<stderr>:[04:53:51] src/io/iter_mnist.cc:113: MNISTIter: load 15000 images, shuffle=1, shape=[64,1,28,28]\r\n[1,1]<stderr>:[04:53:51] src/io/iter_mnist.cc:113: MNISTIter: load 10000 images, shuffle=1, shape=[64,1,28,28]\r\n[1,3]<stderr>:[04:53:51] src/io/iter_mnist.cc:113: MNISTIter: load 10000 images, shuffle=1, shape=[64,1,28,28]\r\n[1,2]<stderr>:[04:53:51] src/io/iter_mnist.cc:113: MNISTIter: load 10000 images, shuffle=1, shape=[64,1,28,28]\r\n[1,0]<stderr>:INFO:root:downloaded http://data.mxnet.io/mxnet/data/mnist.zip into data-0/mnist.zip successfully\r\n[1,0]<stderr>:[04:53:52] src/io/iter_mnist.cc:113: MNISTIter: load 15000 images, shuffle=1, shape=[64,1,28,28]\r\n[1,0]<stderr>:[04:53:53] src/io/iter_mnist.cc:113: MNISTIter: load 10000 images, shuffle=1, shape=[64,1,28,28]\r\n[1,1]<stderr>:\r\n[1,1]<stderr>:Segmentation fault: 11\r\n[1,1]<stderr>:\r\n[1,1]<stderr>:free(): invalid pointer\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] *** Process received signal ***\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] Signal: Aborted (6)\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] Signal code:  (-6)\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x3efd0)[0x7f23c49b0fd0]\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] [ 1] [1,1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(gsignal+0xc7)[0x7f23c49b0f47]\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] [ 2] /lib/x86_64-linux-gnu/libc.so.6(abort+0x141)[0x7f23c49b28b1]\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] [ 3] [1,1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(+0x89907)[0x7f23c49fb907]\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] [ 4] /lib/x86_64-linux-gnu/libc.so.6(+0x9097a)[0x7f23c4a0297a]\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] [1,1]<stderr>:[ 5] /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4cc)[0x7f23c4a09e8c]\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] [ 6] [1,1]<stderr>:/usr/local/lib/python3.7/dist-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(_ZN7horovod6common11NCCLContext8ShutDownEv+0x11f)[0x7f2288f5a0ef]\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] [ 7] /usr/local/lib/python3.7/dist-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(+0x6c490)[0x7f2288efd490]\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] [ 8] [1,1]<stderr>:/usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xbd6df)[0x7f23bf6b96df]\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] [ 9] /lib/x86_64-linux-gnu/libpthread.so.0(+0x76db)[0x7f23c475a6db]\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] [10] [1,1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(clone+0x3f)[0x7f23c4a93a3f]\r\n[1,1]<stderr>:[ip-172-31-64-63:00148] *** End of error message ***\r\n[1,2]<stderr>:\r\n[1,2]<stderr>:Segmentation fault: 11\r\n[1,2]<stderr>:\r\n[1,3]<stderr>:\r\n[1,3]<stderr>:Segmentation fault: 11\r\n[1,3]<stderr>:\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:Segmentation fault: 11\r\n[1,0]<stderr>:\r\n--------------------------------------------------------------------------\r\nmpirun noticed that process rank 1 with PID 0 on node ip-172-31-64-63 exited on signal 6 (Aborted).\r\n--------------------------------------------------------------------------\r\n```\r\n\r\n-----\r\nI would just use 1.6.0, but MXNet doesn't have `ModulatedDeformableConvolution` until 1.7.0, which is required for some of GluonCV's CenterNet detection backbones.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2299/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2299/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2285", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2285/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2285/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2285/events", "html_url": "https://github.com/horovod/horovod/issues/2285", "id": 703598440, "node_id": "MDU6SXNzdWU3MDM1OTg0NDA=", "number": 2285, "title": "tf-keras example is not working well when scale worker up in elastic mode", "user": {"login": "BobLiu20", "id": 6102702, "node_id": "MDQ6VXNlcjYxMDI3MDI=", "avatar_url": "https://avatars.githubusercontent.com/u/6102702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BobLiu20", "html_url": "https://github.com/BobLiu20", "followers_url": "https://api.github.com/users/BobLiu20/followers", "following_url": "https://api.github.com/users/BobLiu20/following{/other_user}", "gists_url": "https://api.github.com/users/BobLiu20/gists{/gist_id}", "starred_url": "https://api.github.com/users/BobLiu20/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BobLiu20/subscriptions", "organizations_url": "https://api.github.com/users/BobLiu20/orgs", "repos_url": "https://api.github.com/users/BobLiu20/repos", "events_url": "https://api.github.com/users/BobLiu20/events{/privacy}", "received_events_url": "https://api.github.com/users/BobLiu20/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-09-17T13:39:00Z", "updated_at": "2020-09-21T23:12:24Z", "closed_at": "2020-09-21T23:12:24Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: tf-keras\r\n2. Framework version: 1.15.0\r\n3. Horovod version: v0.20.0\r\n\r\n**Bug report:**\r\nJust run this example ```examples/elastic/tensorflow_keras_mnist_elastic.py``` in elastic mode. It will be blocked when try to scale worker up.\r\n\r\n**FYI**\r\nI am trying to resolve this issue. Unfortunately, I can't find out how to reset the uniq id of op name. \r\nFor example, sync state in first time, the name is ```dict.sz```. But the second time is ```dict.sz_1``` and so on. In this case the new worker's name is ```dict.sz``` in first time. It is mismatch between new and old worker.\r\nAny idea for this issue?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2285/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2285/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2259", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2259/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2259/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2259/events", "html_url": "https://github.com/horovod/horovod/issues/2259", "id": 698290006, "node_id": "MDU6SXNzdWU2OTgyOTAwMDY=", "number": 2259, "title": "NCCL-based alltoall crashes for some edge cases", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-09-10T17:45:50Z", "updated_at": "2020-09-16T19:54:07Z", "closed_at": "2020-09-15T22:13:46Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.15.2\r\n3. Horovod version: b94d8b447f415f76f23e0cb4b38a57bf27b1eb24\r\n4. MPI version: Open MPI 4.0.2\r\n5. CUDA version: 10.0.130-1\r\n6. NCCL version: 2.7.8-1+cuda10.0 (built manually)\r\n7. Python version: 3.7.5\r\n8. Spark / PySpark version:\r\n9. OS and version: Ubuntu 16.04.7 LTS\r\n10. GCC version: g++-4.9 (Ubuntu 4.9.4-2ubuntu1~16.04) 4.9.4\r\n11. CMake version: 3.5.1\r\n\r\nI built Horovod via `HOROVOD_WITHOUT_GLOO=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITHOUT_MXNET=1 HOROVOD_WITH_TENSORFLOW=1 HOROVOD_GPU_OPERATIONS=NCCL python setup.py install`\r\n\r\n**Bug report:**\r\nUsing NCCL-based GPU variation of `alltoall`, Horovod crashes under some conditions and produces NCCL error messages:\r\n\r\n1. When one tries to send empty tensors -> `ncclGroupEnd failed: invalid usage`\r\n2. All ranks send data, but one rank does not receive any data (so the entry of `splits` corresponding to that rank is set to zero on all ranks) -> `ncclGroupEnd failed: invalid usage`\r\n3. Half the ranks neither send nor receive any data -> `ncclCommInitRank failed: invalid usage`\r\n\r\nThe MPI-based CPU implementation works fine in all of these cases.\r\n\r\nI wrote a bunch of unit tests to reproduce these, which I will try to share via a draft PR.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2259/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2259/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2236", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2236/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2236/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2236/events", "html_url": "https://github.com/horovod/horovod/issues/2236", "id": 692771991, "node_id": "MDU6SXNzdWU2OTI3NzE5OTE=", "number": 2236, "title": "Logic error fails in building cuda_util.cc", "user": {"login": "joequant", "id": 2908185, "node_id": "MDQ6VXNlcjI5MDgxODU=", "avatar_url": "https://avatars.githubusercontent.com/u/2908185?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joequant", "html_url": "https://github.com/joequant", "followers_url": "https://api.github.com/users/joequant/followers", "following_url": "https://api.github.com/users/joequant/following{/other_user}", "gists_url": "https://api.github.com/users/joequant/gists{/gist_id}", "starred_url": "https://api.github.com/users/joequant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joequant/subscriptions", "organizations_url": "https://api.github.com/users/joequant/orgs", "repos_url": "https://api.github.com/users/joequant/repos", "events_url": "https://api.github.com/users/joequant/events{/privacy}", "received_events_url": "https://api.github.com/users/joequant/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-09-04T06:19:22Z", "updated_at": "2020-09-21T20:02:20Z", "closed_at": "2020-09-21T20:02:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version: 0.20.0\r\n4. MPI version:\r\n5. CUDA version:  None\r\n6. NCCL version:\r\n7. Python version: 3.8\r\n8. Spark / PySpark version:\r\n9. OS and version: Mageia Linux\r\n10. GCC version: 10.2\r\n\r\n**Bug report:**\r\n\r\nCompiler fails on non-CUDA builds because of a missing header.  cuda_util.cc does not include <stdexcept>\r\n\r\n01-install-python.sh\thorovod\t  distcc[33436] ERROR: compile /tmp/pip-install-_9_4iuqp/horovod/horovod/mxnet/cuda_util.cc on 172.17.0.1,cpp,lzo failed\r\n01-install-python.sh\thorovod\t  distcc[33436] (dcc_build_somewhere) Warning: remote compilation of '/tmp/pip-install-_9_4iuqp/horovod/horovod/mxnet/cuda_util.cc' failed, retrying locally\r\n01-install-python.sh\thorovod\t  distcc[33436] Warning: failed to distribute /tmp/pip-install-_9_4iuqp/horovod/horovod/mxnet/cuda_util.cc to 172.17.0.1,cpp,lzo, running locally instead\r\n01-install-python.sh\thorovod\t  /tmp/pip-install-_9_4iuqp/horovod/horovod/mxnet/cuda_util.cc: In constructor \u2018horovod::mxnet::with_device::with_device(int)\u2019:\r\n01-install-python.sh\thorovod\t  /tmp/pip-install-_9_4iuqp/horovod/horovod/mxnet/cuda_util.cc:36:16: error: \u2018logic_error\u2019 is not a member of \u2018std\u2019\r\n01-install-python.sh\thorovod\t     36 |     throw std::logic_error(\"Internal error. Requested device context manager \"\r\n01-install-python.sh\thorovod\t        |                ^~~~~~~~~~~\r\n01-install-python.sh\thorovod\t  distcc[33436] ERROR: compile /tmp/pip-install-_9_4iuqp/horovod/horovod/mxnet/cuda_util.cc on localhost failed\r\n01-install-python.sh\thorovod\t  gmake[2]: *** [horovod/mxnet/CMakeFiles/mxnet.dir/build.make:472: horovod/mxnet/CMakeFiles/mxnet.dir/cuda_util.cc.o] Error 1\r\n01-install-python.sh\thorovod\t  gmake[2]: *** Waiting for unfinished jobs....\r\n01-install-python.sh\thorovod\t  [ 76%] Building CXX object horovod/torch/CMakeFiles/pytor\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2236/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2236/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2232", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2232/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2232/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2232/events", "html_url": "https://github.com/horovod/horovod/issues/2232", "id": 691858566, "node_id": "MDU6SXNzdWU2OTE4NTg1NjY=", "number": 2232, "title": "Can't install Horovod with newest TF because of error: \u2018bfloat16\u2019 in namespace \u2018Eigen\u2019 does not name a type", "user": {"login": "Zantares", "id": 38638514, "node_id": "MDQ6VXNlcjM4NjM4NTE0", "avatar_url": "https://avatars.githubusercontent.com/u/38638514?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zantares", "html_url": "https://github.com/Zantares", "followers_url": "https://api.github.com/users/Zantares/followers", "following_url": "https://api.github.com/users/Zantares/following{/other_user}", "gists_url": "https://api.github.com/users/Zantares/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zantares/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zantares/subscriptions", "organizations_url": "https://api.github.com/users/Zantares/orgs", "repos_url": "https://api.github.com/users/Zantares/repos", "events_url": "https://api.github.com/users/Zantares/events{/privacy}", "received_events_url": "https://api.github.com/users/Zantares/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-09-03T10:44:37Z", "updated_at": "2020-09-04T02:18:30Z", "closed_at": "2020-09-03T13:37:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: commit id(64fa2fe6ce8582582210806acf3d78d423cde196)\r\n3. Horovod version: 0.19.5\r\n4. MPI version: 3.1\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.6\r\n8. Spark / PySpark version: N/A\r\n9. OS and version: \r\n10. GCC version: 7.4.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\ntry to pip install Horovod with source build TensorFlow, but an error was reported:\r\n```\r\nerror: \u2018bfloat16\u2019 in namespace \u2018Eigen\u2019 does not name a type\r\n   typedef Eigen::bfloat16 bfloat16;\r\n```\r\nI believe it's caused by missing build dependency for Horovod after TF upgrade the usage of Eigen::bfloat16. Maybe need to fix BUILD file somewhere in Horovod.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2232/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2232/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2206", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2206/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2206/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2206/events", "html_url": "https://github.com/horovod/horovod/issues/2206", "id": 685953981, "node_id": "MDU6SXNzdWU2ODU5NTM5ODE=", "number": 2206, "title": "horovodrun autotune does not log the parameters explored", "user": {"login": "zhao1157", "id": 12959339, "node_id": "MDQ6VXNlcjEyOTU5MzM5", "avatar_url": "https://avatars.githubusercontent.com/u/12959339?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhao1157", "html_url": "https://github.com/zhao1157", "followers_url": "https://api.github.com/users/zhao1157/followers", "following_url": "https://api.github.com/users/zhao1157/following{/other_user}", "gists_url": "https://api.github.com/users/zhao1157/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhao1157/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhao1157/subscriptions", "organizations_url": "https://api.github.com/users/zhao1157/orgs", "repos_url": "https://api.github.com/users/zhao1157/repos", "events_url": "https://api.github.com/users/zhao1157/events{/privacy}", "received_events_url": "https://api.github.com/users/zhao1157/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-26T02:23:26Z", "updated_at": "2020-08-26T02:29:00Z", "closed_at": "2020-08-26T02:29:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was trying to get myself familiar with the autotune feature provided in `horovodrun`, however, the option `--autotune --autotune-log-file log.cvs` did not return what I expected. In `log.csv`, there is only one head line `hierarchical_allreduce,hierarchical_allgather,cache_enabled,cycle_time_ms,tensor_fusion_threshold,score`. I tried increasing training steps from 100 to 200, still got the same log file. Am I supposed to get a log file with all the parameters explored in performance tuning?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2206/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2206/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2194", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2194/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2194/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2194/events", "html_url": "https://github.com/horovod/horovod/issues/2194", "id": 682194880, "node_id": "MDU6SXNzdWU2ODIxOTQ4ODA=", "number": 2194, "title": "horovod docker build file is broken", "user": {"login": "deepbrain", "id": 10003025, "node_id": "MDQ6VXNlcjEwMDAzMDI1", "avatar_url": "https://avatars.githubusercontent.com/u/10003025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deepbrain", "html_url": "https://github.com/deepbrain", "followers_url": "https://api.github.com/users/deepbrain/followers", "following_url": "https://api.github.com/users/deepbrain/following{/other_user}", "gists_url": "https://api.github.com/users/deepbrain/gists{/gist_id}", "starred_url": "https://api.github.com/users/deepbrain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deepbrain/subscriptions", "organizations_url": "https://api.github.com/users/deepbrain/orgs", "repos_url": "https://api.github.com/users/deepbrain/repos", "events_url": "https://api.github.com/users/deepbrain/events{/privacy}", "received_events_url": "https://api.github.com/users/deepbrain/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-19T21:31:09Z", "updated_at": "2020-09-02T12:48:50Z", "closed_at": "2020-09-02T12:44:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "The docker build fails at multiple points:\r\n1. With the default latest wheel the code python -c \"import wheel.pep425tags as w\" fails, so I had to roll back to\r\npip install wheel==0.34.2\r\n\r\n2. MXNET pip install fails to find the specified version\r\n\r\n3. horovod install inside the docker fails with error:\r\nlibcudart.so.10.2: cannot open shared object file: No such file or directory\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2194/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2194/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2193", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2193/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2193/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2193/events", "html_url": "https://github.com/horovod/horovod/issues/2193", "id": 682120640, "node_id": "MDU6SXNzdWU2ODIxMjA2NDA=", "number": 2193, "title": "Horovod pyarrow IndexError: list index out of range", "user": {"login": "ZhenyiLin", "id": 22970825, "node_id": "MDQ6VXNlcjIyOTcwODI1", "avatar_url": "https://avatars.githubusercontent.com/u/22970825?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZhenyiLin", "html_url": "https://github.com/ZhenyiLin", "followers_url": "https://api.github.com/users/ZhenyiLin/followers", "following_url": "https://api.github.com/users/ZhenyiLin/following{/other_user}", "gists_url": "https://api.github.com/users/ZhenyiLin/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZhenyiLin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZhenyiLin/subscriptions", "organizations_url": "https://api.github.com/users/ZhenyiLin/orgs", "repos_url": "https://api.github.com/users/ZhenyiLin/repos", "events_url": "https://api.github.com/users/ZhenyiLin/events{/privacy}", "received_events_url": "https://api.github.com/users/ZhenyiLin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-19T19:32:26Z", "updated_at": "2021-11-04T15:17:34Z", "closed_at": "2021-11-04T15:17:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.14\r\n3. Horovod version: 0.19.5\r\n4. MPI version: 4.0.4\r\n5. CUDA version: NA\r\n6. NCCL version: NA\r\n7. Python version: 3.6\r\n8. Spark / PySpark version: 2.4.4\r\n9. OS and version: Amazon Linux\r\n10. GCC version: 7.2.1\r\n11. pyarrow version: 0.15.1\r\n\r\n\r\nThe nmist example. error is on the model fitting:\r\n```\r\n>>> #store = Store.create(\"hdfs:///user/hvd\")\r\n... # Train a Horovod Spark Estimator on the DataFrame\r\n... keras_estimator = hvd.KerasEstimator(num_proc=1,\r\n...                                      store=store,\r\n...                                      model=model,\r\n...                                      optimizer=optimizer,\r\n...                                      loss=loss,\r\n...                                      metrics=['accuracy'],\r\n...                                      feature_cols=['features'],\r\n...                                      label_cols=['label_vec'],\r\n...                                      batch_size=256,\r\n...                                      epochs=10,\r\n...                                      verbose=3)\r\n>>>\r\n>>> keras_model = keras_estimator.fit(train_df).setOutputCols(['label_prob'])\r\nnum_partitions=10\r\nwriting dataframes\r\ntrain_data_path=file:///var/lib/hvd/intermediate_train_data.0\r\nval_data_path=file:///var/lib/hvd/intermediate_val_data.0\r\ntrain_partitions=10\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/hadoop/conda/envs/py36/lib/python3.6/site-packages/horovod/spark/common/estimator.py\", line 37, in fit\r\n    return super(HorovodEstimator, self).fit(df, params)\r\n  File \"/usr/lib/spark/python/pyspark/ml/base.py\", line 132, in fit\r\n    return self._fit(dataset)\r\n  File \"/home/hadoop/conda/envs/py36/lib/python3.6/site-packages/horovod/spark/common/estimator.py\", line 78, in _fit\r\n    verbose=self.getVerbose()) as dataset_idx:\r\n  File \"/home/hadoop/conda/envs/py36/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/hadoop/conda/envs/py36/lib/python3.6/site-packages/horovod/spark/common/util.py\", line 637, in prepare_data\r\n    num_partitions, num_processes, verbose)\r\n  File \"/home/hadoop/conda/envs/py36/lib/python3.6/site-packages/horovod/spark/common/util.py\", line 573, in _get_or_create_dataset\r\n    store, label_columns, feature_columns, sample_weight_col, dataset_idx)\r\n  File \"/home/hadoop/conda/envs/py36/lib/python3.6/site-packages/horovod/spark/common/util.py\", line 457, in get_simple_meta_from_parquet\r\n    train_data = store.get_parquet_dataset(train_data_path)\r\n  File \"/home/hadoop/conda/envs/py36/lib/python3.6/site-packages/horovod/spark/common/store.py\", line 176, in get_parquet_dataset\r\n    return pq.ParquetDataset(self.get_localized_path(path), filesystem=self.get_filesystem())\r\n  File \"/home/hadoop/conda/envs/py36/lib/python3.6/site-packages/pyarrow/parquet.py\", line 1060, in __init__\r\n    self.validate_schemas()\r\n  File \"/home/hadoop/conda/envs/py36/lib/python3.6/site-packages/pyarrow/parquet.py\", line 1092, in validate_schemas\r\n    self.schema = self.pieces[0].get_metadata().schema\r\nIndexError: list index out of range\r\n```\r\n\r\nI have 1 master node and 1 worker node and the Spark is running in the client mode. \r\nWhen I checked the `intermediate_train_data.0` folder. In the master node, it has only a `_SUCCESS` file; In the worker node, it has `_temporary` file.  It seems the writing process hasn't been completed yet in this worker node before the file being read. \r\nThere are no `intermediate_val_data` in both nodes.\r\n\r\n\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2193/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2193/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2126", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2126/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2126/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2126/events", "html_url": "https://github.com/horovod/horovod/issues/2126", "id": 663452074, "node_id": "MDU6SXNzdWU2NjM0NTIwNzQ=", "number": 2126, "title": "Horovod deadlock in fork-path model", "user": {"login": "shinleylee", "id": 25567460, "node_id": "MDQ6VXNlcjI1NTY3NDYw", "avatar_url": "https://avatars.githubusercontent.com/u/25567460?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shinleylee", "html_url": "https://github.com/shinleylee", "followers_url": "https://api.github.com/users/shinleylee/followers", "following_url": "https://api.github.com/users/shinleylee/following{/other_user}", "gists_url": "https://api.github.com/users/shinleylee/gists{/gist_id}", "starred_url": "https://api.github.com/users/shinleylee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shinleylee/subscriptions", "organizations_url": "https://api.github.com/users/shinleylee/orgs", "repos_url": "https://api.github.com/users/shinleylee/repos", "events_url": "https://api.github.com/users/shinleylee/events{/privacy}", "received_events_url": "https://api.github.com/users/shinleylee/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-22T03:49:09Z", "updated_at": "2020-07-24T13:50:08Z", "closed_at": "2020-07-24T13:50:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "Sagemaker: 5 * ml.m5.4xlarge\uff0c kernel: tensorflow_p36\r\n**Environment:**\r\n1. Framework: TensorFlow.keras\r\n2. Framework version: 2.0.0\r\n3. Horovod version: 0.18.2\r\n4. MPI version: mpi4py 3.0.3\r\n7. Python version: 3.6\r\n\r\n**Bug report:**\r\nWhen training a model with a fork path (in the attached graph, feature1 was embedded by two layer separately and multiplied at last after distinct processes), and a deadlock emerged right at the forked tensor, leading to a failure in training.\r\nlog\uff1a\r\n```\r\n[1,0]<stderr>:INFO:tensorflow:hvd.rank: 0, train_row_number: 1729685\r\n[1,0]<stderr>:INFO:tensorflow:hvd.rank: 0, validation_row_number: 1235605\r\n[1,1]<stderr>:INFO:tensorflow:hvd.rank: 1, train_row_number: 1729868\r\n[1,1]<stderr>:INFO:tensorflow:hvd.rank: 1, validation_row_number: 1235605\r\n[1,4]<stderr>:INFO:tensorflow:hvd.rank: 4, train_row_number: 1729977\r\n[1,4]<stderr>:INFO:tensorflow:hvd.rank: 4, validation_row_number: 1235605\r\n[1,2]<stderr>:INFO:tensorflow:hvd.rank: 2, train_row_number: 1729496\r\n[1,2]<stderr>:INFO:tensorflow:hvd.rank: 2, validation_row_number: 1235605\r\n[1,3]<stderr>:INFO:tensorflow:hvd.rank: 3, train_row_number: 1730209\r\n[1,3]<stderr>:INFO:tensorflow:hvd.rank: 3, validation_row_number: 1235605\r\n[1,0]<stderr>:INFO:tensorflow:hvd.rank: 0, steps per epoch: 844\r\n[1,0]<stderr>:INFO:tensorflow:hvd.rank: 0, steps in validation: 604\r\n[1,1]<stderr>:INFO:tensorflow:hvd.rank: 1, steps per epoch: 844\r\n[1,1]<stderr>:INFO:tensorflow:hvd.rank: 1, steps in validation: 604\r\n[1,4]<stderr>:INFO:tensorflow:hvd.rank: 4, steps per epoch: 844\r\n[1,4]<stderr>:INFO:tensorflow:hvd.rank: 4, steps in validation: 604\r\n[1,0]<stdout>:Epoch 1/6\r\n[1,2]<stderr>:INFO:tensorflow:hvd.rank: 2, steps per epoch: 844\r\n[1,2]<stderr>:INFO:tensorflow:hvd.rank: 2, steps in validation: 604\r\n[1,3]<stderr>:INFO:tensorflow:hvd.rank: 3, steps per epoch: 844\r\n[1,3]<stderr>:INFO:tensorflow:hvd.rank: 3, steps in validation: 604\r\n[ip-10-0-222-34.ec2.internal:00114] 4 more processes have sent help message help-orte-odls-default.txt / memory not bound\r\n[ip-10-0-222-34.ec2.internal:00114] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\r\n[1,0]<stderr>:[2020-07-15 08:18:52.425933: W horovod/common/stall_inspector.cc:105] One or more tensors were submitted to be reduced, gathered or \r\n    broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are \r\n    trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. \r\n[1,0]<stderr>:Stalled ranks:\r\n[1,0]<stderr>:0: [training/Adam_Allreduce/HorovodAllgather_training_Adam_gradients_gradients_feature1_factor_embedding_lookup_grad_Reshape_1_0]\r\n[1,0]<stderr>:1: [training/Adam_Allreduce/HorovodAllgather_training_Adam_gradients_gradients_feature1_factor_embedding_lookup_grad_Reshape_1_0]\r\n[1,0]<stderr>:2: [training/Adam_Allreduce/HorovodAllgather_training_Adam_gradients_gradients_feature1_factor_embedding_lookup_grad_Reshape_1_0]\r\n[1,0]<stderr>:3: [training/Adam_Allreduce/HorovodAllgather_training_Adam_gradients_gradients_feature1_embedding_embedding_lookup_grad_Reshape_1_0]\r\n[1,0]<stderr>:4: [training/Adam_Allreduce/HorovodAllgather_training_Adam_gradients_gradients_feature1_factor_embedding_lookup_grad_Reshape_1_0]\r\n```\r\n\r\nThe steps were consistent between workers (batch size 2048).\r\nCPU, Memory, Disk Utilization were healthy.\r\nA minimun model to reproduce this deadlock is here:\r\n![model](https://user-images.githubusercontent.com/25567460/88131605-f5e19980-cc0f-11ea-8a35-4305993d40e0.png)\r\n\r\nThe data is unlikely to be provided, but feature1 can be regarded as week_of_day indexes for instance. And feature2 can be regarded as is_weekend.\r\nDoes anyone have any ideas how this come?\r\n(If more information needed pls let me know)", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2126/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2126/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2110", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2110/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2110/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2110/events", "html_url": "https://github.com/horovod/horovod/issues/2110", "id": 657806870, "node_id": "MDU6SXNzdWU2NTc4MDY4NzA=", "number": 2110, "title": "Error in computing gradients when using allgather", "user": {"login": "hoyden", "id": 18378559, "node_id": "MDQ6VXNlcjE4Mzc4NTU5", "avatar_url": "https://avatars.githubusercontent.com/u/18378559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hoyden", "html_url": "https://github.com/hoyden", "followers_url": "https://api.github.com/users/hoyden/followers", "following_url": "https://api.github.com/users/hoyden/following{/other_user}", "gists_url": "https://api.github.com/users/hoyden/gists{/gist_id}", "starred_url": "https://api.github.com/users/hoyden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hoyden/subscriptions", "organizations_url": "https://api.github.com/users/hoyden/orgs", "repos_url": "https://api.github.com/users/hoyden/repos", "events_url": "https://api.github.com/users/hoyden/events{/privacy}", "received_events_url": "https://api.github.com/users/hoyden/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-16T03:07:22Z", "updated_at": "2020-07-21T12:58:02Z", "closed_at": "2020-07-21T03:24:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.0\r\n3. Horovod version:  0.18.2\r\n\r\nI am trying to get the median of a tensor computed across all batches and all processes. However, I got an error TypeError: Expected int32, got None of type 'NoneType' instead.It seems that computing gradients does not work well with horovod's allgather operation. A simple illustration of what I would like to achieve is as follows:\r\n\r\n>with tf.GradientTape() as tape: \r\n&ensp;&ensp;&ensp;&ensp;my_tensor = compute_my_tensor() \r\n&ensp;&ensp;&ensp;&ensp;gathered_my_tensor = hvd.allgather(my_tensor)  \r\n&ensp;&ensp;&ensp;&ensp;median = get_median(gathered_my_tensor)\r\n&ensp;&ensp;&ensp;&ensp;loss = get_loss(my_tensor, median, training=True)\r\ntape = hvd.DistributedGradientTape(tape)\r\ngrads = tape.gradient(loss, trainable_variables)\r\noptimizer.apply_gradients(zip(grads, trainable_variables))\r\n\r\nBTW, when I use eager mode of tensorflow, there will be no error\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2110/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2110/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2065", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2065/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2065/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2065/events", "html_url": "https://github.com/horovod/horovod/issues/2065", "id": 646760865, "node_id": "MDU6SXNzdWU2NDY3NjA4NjU=", "number": 2065, "title": "Fix SparkTests.test_get_available_devices", "user": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2020-06-27T20:46:03Z", "updated_at": "2020-06-29T20:52:55Z", "closed_at": "2020-06-29T20:52:55Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "We can't move from Spark 3.0.0-dev2 to the 3.0.0 release because test `SparkTests.test_get_available_devices` breaks. Fix the test and move to Spark 3.0.0 again (see #2064). I have raised [Jira ticket SPARK-32120](https://issues.apache.org/jira/browse/SPARK-32120) to see if this is a bug or a new feature in 3.0.0 release.\r\n\r\nThat test might have been fixed by https://github.com/horovod/horovod/pull/2063#issuecomment-650811959.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2065/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2065/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2055", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2055/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2055/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2055/events", "html_url": "https://github.com/horovod/horovod/issues/2055", "id": 644205279, "node_id": "MDU6SXNzdWU2NDQyMDUyNzk=", "number": 2055, "title": "PyTorch and MXNet unit tests are missing absolute values", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-23T23:12:51Z", "updated_at": "2020-07-18T01:54:23Z", "closed_at": "2020-07-18T01:54:23Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Unit tests that compare \"actual\" and \"expected\" tensors use a pattern of subtracting one tensor from the other and taking the max values:\r\n\r\n```\r\nmax_difference = actual.data.sub(expected).max()\r\n```\r\n\r\nThis difference is then compared against a threshold (for floating point values):\r\n\r\n```\r\nassert max_difference <= threshold, 'hvd.allreduce produces incorrect results'\r\n```\r\n\r\nHowever, because this value does not take the absolute value, it is possible that all values are negative, and the \"max value\" reported is also negative, resulting in the test passing when it should fail.\r\n\r\ncc @romerojosh ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2055/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2055/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2037", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2037/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2037/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2037/events", "html_url": "https://github.com/horovod/horovod/issues/2037", "id": 641763424, "node_id": "MDU6SXNzdWU2NDE3NjM0MjQ=", "number": 2037, "title": "Running horovod.spark.run with env=os.environ fails", "user": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2020-06-19T07:20:23Z", "updated_at": "2020-06-19T17:23:09Z", "closed_at": "2020-06-19T17:23:09Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Example:\r\n\r\n    horovod.spark.run(fn, num_proc=2, env=os.environ)\r\n\r\nThat `env` is an object, not a dictionary. It cannot be pickled:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"horovod/run/common/util/tiny_shell_exec.py\", line 32, in execute\r\n    exit_code = safe_shell_exec.execute(command, env=env, stdout=output, stderr=output)\r\n  File \"horovod/run/common/util/safe_shell_exec.py\", line 183, in execute\r\n    middleman.start()\r\n  File \"multiprocessing/process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"multiprocessing/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"multiprocessing/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"multiprocessing/popen_spawn_posix.py\", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  File \"multiprocessing/reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nAttributeError: Can't pickle local object '_createenviron.<locals>.encode'\r\n```\r\n\r\nIt works with\r\n\r\n    horovod.spark.run(fn, num_proc=2, env=os.environ.copy())\r\n\r\nThe `run` function needs to copy `env` itself first.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2037/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2037/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2033", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2033/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2033/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2033/events", "html_url": "https://github.com/horovod/horovod/issues/2033", "id": 640934130, "node_id": "MDU6SXNzdWU2NDA5MzQxMzA=", "number": 2033, "title": "Horovod spark raise error No module named 'pyspark'", "user": {"login": "WeichenXu123", "id": 19235986, "node_id": "MDQ6VXNlcjE5MjM1OTg2", "avatar_url": "https://avatars.githubusercontent.com/u/19235986?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WeichenXu123", "html_url": "https://github.com/WeichenXu123", "followers_url": "https://api.github.com/users/WeichenXu123/followers", "following_url": "https://api.github.com/users/WeichenXu123/following{/other_user}", "gists_url": "https://api.github.com/users/WeichenXu123/gists{/gist_id}", "starred_url": "https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WeichenXu123/subscriptions", "organizations_url": "https://api.github.com/users/WeichenXu123/orgs", "repos_url": "https://api.github.com/users/WeichenXu123/repos", "events_url": "https://api.github.com/users/WeichenXu123/events{/privacy}", "received_events_url": "https://api.github.com/users/WeichenXu123/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-06-18T06:03:19Z", "updated_at": "2020-06-22T13:04:09Z", "closed_at": "2020-06-22T13:03:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Tensorflow\r\n2. Framework version: \r\n3. Horovod version: Horovod >= 0.19.2\r\n4. MPI version: N/A\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.7\r\n8. Spark / PySpark version: spark 2.6 (Note: Download spark tarball and deploy spark in a separate directory instead of install pyspark into python site-packages)\r\n9. OS and version: N/A\r\n10. GCC version: N/A\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\n**Reproduce steps**\r\n```\r\n# Note, don't install pyspark by \"pip\", if already install pyspark by \"pip\", uninstall it first.\r\n# Install horovod >= 0.19.2\r\npip3.7 install --no-cache-dir --force-reinstall horovod==0.19.4\r\n\r\n# Uninstall pyspark (if needed)\r\npip3.7 uninstall pyspark\r\n\r\n# Download and untar spark tarball\r\nwget http://apache.mirrors.hoobly.com/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop2.7.tgz\r\ntar -xf spark-3.0.0-preview2-bin-hadoop2.7.tgz\r\ncd spark-3.0.0-preview2-bin-hadoop2.7\r\n\r\n# enter pyspark REPL shell\r\nPYSPARK_PYTHON=python3.7 bin/pyspark\r\n```\r\n\r\nNow run test code in pyspark REPL shell:\r\n~~~python\r\nimport numpy as np\r\nimport horovod.tensorflow.keras as hvd\r\nimport horovod.spark\r\ndef test_tensorflow():\r\n  hvd.init()\r\n  gathered = hvd.allgather([hvd.rank()])\r\n  assert np.allclose(gathered, list(range(hvd.size())))\r\n  return hvd.rank()\r\nranks = horovod.spark.run(test_tensorflow, num_proc=2)\r\n~~~\r\n\r\nWill get error like:\r\n```\r\n  File \"/usr/lib/python3.7/runpy.py\", line 183, in _run_module_as_main\r\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\r\n  File \"/usr/lib/python3.7/runpy.py\", line 109, in _get_module_details\r\n    __import__(pkg_name)\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/__init__.py\", line 18, in <module>\r\n    from .runner import run\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/runner.py\", line 20, in <module>\r\n    import pyspark\r\nModuleNotFoundError: No module named 'pyspark'\r\n--------------------------------------------------------------------------\r\nORTE was unable to reliably start one or more daemons.\r\nThis usually is caused by:\r\n...\r\n--------------------------------------------------------------------------\r\nException in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/runner.py\", line 100, in run_spark\r\n    result = procs.mapPartitionsWithIndex(_make_mapper(driver.addresses(), settings, use_gloo)).collect()\r\n  File \"/home/weichen.xu/spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/rdd.py\", line 889, in collect\r\n    sock_info = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())\r\n  File \"/home/weichen.xu/spark-3.0.0-preview2-bin-hadoop2.7/python/lib/py4j-0.10.8.1-src.zip/py4j/java_gateway.py\", line 1286, in __call__\r\n    answer, self.gateway_client, self.target_id, self.name)\r\n  File \"/home/weichen.xu/spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 98, in deco\r\n    return f(*a, **kw)\r\n  File \"/home/weichen.xu/spark-3.0.0-preview2-bin-hadoop2.7/python/lib/py4j-0.10.8.1-src.zip/py4j/protocol.py\", line 328, in get_return_value\r\n    format(target_id, \".\", name), value)\r\npy4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\r\n: org.apache.spark.SparkException: Job 0 cancelled part of cancelled job group horovod.spark.run.0\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:1989)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1924)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleJobGroupCancelled$4(DAGScheduler.scala:937)\r\n\tat scala.runtime.java8.JFunction1$mcVI$sp.apply(JFunction1$mcVI$sp.java:23)\r\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobGroupCancelled(DAGScheduler.scala:936)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2175)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2155)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2144)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:758)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2116)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2137)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2156)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2181)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:168)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/runner.py\", line 227, in run\r\n    _launch_job(use_mpi, use_gloo, settings, driver, env, stdout, stderr)\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/runner.py\", line 123, in _launch_job\r\n    settings.verbose)\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/run/runner.py\", line 686, in run_controller\r\n    mpi_run()\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/runner.py\", line 121, in <lambda>\r\n    use_mpi, lambda: mpi_run(settings, nics, driver, env, stdout, stderr),\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/mpi_run.py\", line 54, in mpi_run\r\n    hr_mpi_run(settings, nics, env, command, stdout=stdout, stderr=stderr)\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/run/mpi_run.py\", line 201, in mpi_run\r\n    raise RuntimeError(\"mpirun failed with exit code {exit_code}\".format(exit_code=exit_code))\r\nRuntimeError: mpirun failed with exit code 1\r\n>>> 20/06/18 05:40:55 WARN PythonRunner: Incomplete task 0.0 in stage 0 (TID 0) interrupted: Attempting to kill Python Worker\r\n20/06/18 05:40:55 WARN PythonRunner: Incomplete task 1.0 in stage 0 (TID 1) interrupted: Attempting to kill Python Worker\r\n20/06/18 05:40:56 WARN TaskSetManager: Lost task 1.0 in stage 0.0 (TID 1, ip-10-20-4-87.us-west-2.compute.internal, executor driver): TaskKilled (Stage cancelled)\r\n20/06/18 05:40:56 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0, ip-10-20-4-87.us-west-2.compute.internal, executor driver): TaskKilled (Stage cancelled)\r\n```\r\n\r\nI made some investigation, and already confirmed that this bug was introduced in https://github.com/horovod/horovod/pull/1839\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2033/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2033/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2029", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2029/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2029/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2029/events", "html_url": "https://github.com/horovod/horovod/issues/2029", "id": 639170627, "node_id": "MDU6SXNzdWU2MzkxNzA2Mjc=", "number": 2029, "title": "hvd.keras_estimator.fit() throws Py4JJavaError caused by java.io.IOException", "user": {"login": "orwa-te", "id": 32763039, "node_id": "MDQ6VXNlcjMyNzYzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/32763039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/orwa-te", "html_url": "https://github.com/orwa-te", "followers_url": "https://api.github.com/users/orwa-te/followers", "following_url": "https://api.github.com/users/orwa-te/following{/other_user}", "gists_url": "https://api.github.com/users/orwa-te/gists{/gist_id}", "starred_url": "https://api.github.com/users/orwa-te/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/orwa-te/subscriptions", "organizations_url": "https://api.github.com/users/orwa-te/orgs", "repos_url": "https://api.github.com/users/orwa-te/repos", "events_url": "https://api.github.com/users/orwa-te/events{/privacy}", "received_events_url": "https://api.github.com/users/orwa-te/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2020-06-15T21:19:32Z", "updated_at": "2020-06-19T16:32:49Z", "closed_at": "2020-06-19T16:32:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): Tensorflow\r\n2. Framework version: 2.1.0\r\n3. Horovod version: 0.19.4\r\n4. MPI version: 4.0.3\r\n5. CUDA version: None\r\n6. NCCL version: None\r\n7. Python version: 3.7.0\r\n8. OS and version: Ubuntu 20\r\n9. GCC version: 9.3.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nI am trying to execute the example linked at [keras_spark_mnist.py](https://github.com/horovod/horovod/blob/master/examples/keras_spark_mnist.py) on my standalone Spark cluster which is an only single machine with 10 GB Ram and has one worker on the same machine.\r\nAfter a few seconds of execution, I get an error at line 114 \"**keras_model = keras_estimator.fit(train_df).setOutputCols(['label_prob'])**\" described below:\r\n\r\n\"Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob. : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 4 times, most recent failure: Lost task 0.3 in stage 4.0 (TID 9, 192.168.198.131, executor 0): java.io.IOException: Cannot run program \"python\": error=2, No such file or directory\"\r\n\r\nWhat could be the problem? How do I solve it?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2029/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2029/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2015", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2015/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2015/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2015/events", "html_url": "https://github.com/horovod/horovod/issues/2015", "id": 635755719, "node_id": "MDU6SXNzdWU2MzU3NTU3MTk=", "number": 2015, "title": "Hit Gloo exception when we scale up to 50+ nodes", "user": {"login": "aaron276h", "id": 5969899, "node_id": "MDQ6VXNlcjU5Njk4OTk=", "avatar_url": "https://avatars.githubusercontent.com/u/5969899?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaron276h", "html_url": "https://github.com/aaron276h", "followers_url": "https://api.github.com/users/aaron276h/followers", "following_url": "https://api.github.com/users/aaron276h/following{/other_user}", "gists_url": "https://api.github.com/users/aaron276h/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaron276h/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaron276h/subscriptions", "organizations_url": "https://api.github.com/users/aaron276h/orgs", "repos_url": "https://api.github.com/users/aaron276h/repos", "events_url": "https://api.github.com/users/aaron276h/events{/privacy}", "received_events_url": "https://api.github.com/users/aaron276h/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-09T21:01:53Z", "updated_at": "2020-06-17T16:46:21Z", "closed_at": "2020-06-17T16:46:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Tensorflow \r\n2. Framework version: 1.14 \r\n3. Horovod version: 0.19.3\r\n4. MPI version: N/A\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.6.4\r\n7. Python version: 3.6\r\n8. OS and version: Ubuntu 18.04\r\n9. GCC version: 4.8\r\n\r\n**Bug report:**\r\nWhen we scale up to 50+ machines we get the following exception from GLOO when running the same exact code that runs correctly at lower number of machines. \r\n\r\n\r\n```\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:terminate called after throwing an instance of 'gloo::IoException'\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:  what():  [horovod/common/gloo/http_store.cc:53] [horovod/common/gloo/http_store.cc:53] Wait timeout for key(s): 0\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:*** Received signal 6 ***\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:*** BEGIN MANGLED STACK TRACE ***\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so.1(+0xfed8db)[0x7f994dcc18db]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/lib/x86_64-linux-gnu/libpthread.so.0(+0x12890)[0x7f99e8a40890]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(gsignal+0xc7)[0x7f99e867be97]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(abort+0x141)[0x7f99e867d801]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/bin/../lib/libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xbc)[0x7f99e591484a]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/bin/../lib/libstdc++.so.6(+0xabf47)[0x7f99e5912f47]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/bin/../lib/libstdc++.so.6(+0xabf7d)[0x7f99e5912f7d]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/bin/../lib/libstdc++.so.6(__cxa_rethrow+0x0)[0x7f99e591315a]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common9HTTPStore4waitERKSt6vectorISsSaISsEERKNSt6chrono8durationIlSt5ratioILl1ELl1000EEEE+0x8c9)[0x7f9914455f39]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0xf8ee6)[0x7f99144bfee6]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common10RendezvousERKSsPKciiiRSt10shared_ptrIN4gloo9transport6DeviceEENSt6chrono8durationIlSt5ratioILl1ELl1000EEEE+0x3ed)[0x7f991444f08d]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common11GlooContext10InitializeERKSs+0x3f1)[0x7f991444fa31]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0x54cb3)[0x7f991441bcb3]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/bin/../lib/libstdc++.so.6(+0xc8421)[0x7f99e592f421]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/lib/x86_64-linux-gnu/libpthread.so.0(+0x76db)[0x7f99e8a356db]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(clone+0x3f)[0x7f99e875e88f]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:*** END MANGLED STACK TRACE ***\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:*** Begin stack trace ***\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\ttensorflow::CurrentStackTrace()\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\tgsignal\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\tabort\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t__gnu_cxx::__verbose_terminate_handler()\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t__cxa_rethrow\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\thorovod::common::HTTPStore::wait(std::vector<std::string, std::allocator<std::string> > const&, std::chrono::duration<long, std::ratio<1l, 1000l> > const&)\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\thorovod::common::Rendezvous(std::string const&, char const*, int, int, int, std::shared_ptr<gloo::transport::Device>&, std::chrono::duration<long, std::ratio<1l, 1000l> >)\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\thorovod::common::GlooContext::Initialize(std::string const&)\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\tclone\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:*** End stack trace ***\r\n[2020-06-09T20:10:41Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:41 2020[1]<stderr>:Aborted (core dumped)\r\n[2020-06-09T20:10:41Z] cf108822 [RUNNING] ||  Process 1 exit with status code 134.\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2015/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2015/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2000", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2000/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2000/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2000/events", "html_url": "https://github.com/horovod/horovod/issues/2000", "id": 627523991, "node_id": "MDU6SXNzdWU2Mjc1MjM5OTE=", "number": 2000, "title": "pyarrow 0.17 changed hdfs.connect api to remove driver parameter", "user": {"login": "tgravescs", "id": 4563792, "node_id": "MDQ6VXNlcjQ1NjM3OTI=", "avatar_url": "https://avatars.githubusercontent.com/u/4563792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgravescs", "html_url": "https://github.com/tgravescs", "followers_url": "https://api.github.com/users/tgravescs/followers", "following_url": "https://api.github.com/users/tgravescs/following{/other_user}", "gists_url": "https://api.github.com/users/tgravescs/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgravescs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgravescs/subscriptions", "organizations_url": "https://api.github.com/users/tgravescs/orgs", "repos_url": "https://api.github.com/users/tgravescs/repos", "events_url": "https://api.github.com/users/tgravescs/events{/privacy}", "received_events_url": "https://api.github.com/users/tgravescs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2020-05-29T20:35:30Z", "updated_at": "2020-06-02T17:21:09Z", "closed_at": "2020-06-02T17:21:09Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Keras Estimator example\r\n2. Framework version:\r\n3. Horovod version:  master branch\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nTrying to run with the latest horovod code with pyarrow 0.17.1 against HDFS for the working directory and it fails with:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"keras_spark_rossmann_estimator.py\", line 408, in <module>\r\n    store = Store.create(args.work_dir)\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/store.py\", line 141, in create\r\n    return HDFSStore(prefix_path, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/store.py\", line 337, in __init__\r\n    self._hdfs = self._get_filesystem_fn()()\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/store.py\", line 416, in fn\r\n    return pa.hdfs.connect(**hdfs_kwargs)\r\nTypeError: connect() got an unexpected keyword argument 'driver'\r\n```\r\n\r\nIt looks like pyarrow removed that parameter with commit:\r\nhttps://github.com/apache/arrow/commit/4e53749097ba687afd5e000067925def2e2802c9#diff-72abd78694ddde2b1a059b194978b77b\r\n\r\nNote I called it like:\r\npython keras_spark_rossmann_estimator.py --num-proc 2 --batch-size 1000 --epochs 2 --master spark://3ee9bf36f06b:7077 --work-dir hdfs:///rossmann\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/2000/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/2000/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1997", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1997/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1997/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1997/events", "html_url": "https://github.com/horovod/horovod/issues/1997", "id": 626984059, "node_id": "MDU6SXNzdWU2MjY5ODQwNTk=", "number": 1997, "title": "Timeline show NEGOTIATE_BROADCAST Did Not Finish", "user": {"login": "jmsking", "id": 4349983, "node_id": "MDQ6VXNlcjQzNDk5ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/4349983?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jmsking", "html_url": "https://github.com/jmsking", "followers_url": "https://api.github.com/users/jmsking/followers", "following_url": "https://api.github.com/users/jmsking/following{/other_user}", "gists_url": "https://api.github.com/users/jmsking/gists{/gist_id}", "starred_url": "https://api.github.com/users/jmsking/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jmsking/subscriptions", "organizations_url": "https://api.github.com/users/jmsking/orgs", "repos_url": "https://api.github.com/users/jmsking/repos", "events_url": "https://api.github.com/users/jmsking/events{/privacy}", "received_events_url": "https://api.github.com/users/jmsking/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-29T04:12:50Z", "updated_at": "2020-05-29T11:22:51Z", "closed_at": "2020-05-29T11:22:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Pytorch\r\n2. Framework version: 1.4.0+cu100\r\n3. Horovod version: 0.19.2\r\n4. MPI version: \r\n5. CUDA version: cu100\r\n6. NCCL version:\r\n7. Python version: 3.6\r\n8. OS and version: ubuntu 18\r\n9. GCC version: 7\r\n\r\n**Bug report:**\r\nI train a simple CNN model with MNIST data in k8s cluster. and my k8s info as follows:\r\ntotal nodes: 3, 2 for GPU node and 1 for CPU node\r\nand GPU nodes each have 8 gpu.\r\nwhen i create a mpijob, run command like:\r\n```mpirun -np 16 --allow-run-as-root -bind-to none -map-by slot -x LD_LIBRARY_PATH -x PATH -mca pml ob1 -mca btl ^openib -x HOROVOD_TIMELINE=/mnt/timeline.json python /mnt/horovod_pytorch.py```\r\nand i open the generated timeline.json with chrome://tracing, the picture is:\r\n![image](https://user-images.githubusercontent.com/4349983/83220133-cfb9f300-a1a4-11ea-8c58-466af6c44547.png)\r\nand i execute ```nvidia-smi`` in each GPU node, i found there only 13 processes running, and i don't know where are the other 3 processes?\r\nAnd i also found because the process will download the MNIST data from network, and i print the log, there are only 13 processes have download MNIST success\u3002\r\nAnd the container logs as follows:\r\n![image](https://user-images.githubusercontent.com/4349983/83220471-a2217980-a1a5-11ea-891c-00b0c48b3998.png)\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1997/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1997/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1969", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1969/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1969/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1969/events", "html_url": "https://github.com/horovod/horovod/issues/1969", "id": 622017625, "node_id": "MDU6SXNzdWU2MjIwMTc2MjU=", "number": 1969, "title": "When network interface isn't specified, task processes fail to connect to driver.", "user": {"login": "aaron276h", "id": 5969899, "node_id": "MDQ6VXNlcjU5Njk4OTk=", "avatar_url": "https://avatars.githubusercontent.com/u/5969899?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaron276h", "html_url": "https://github.com/aaron276h", "followers_url": "https://api.github.com/users/aaron276h/followers", "following_url": "https://api.github.com/users/aaron276h/following{/other_user}", "gists_url": "https://api.github.com/users/aaron276h/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaron276h/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaron276h/subscriptions", "organizations_url": "https://api.github.com/users/aaron276h/orgs", "repos_url": "https://api.github.com/users/aaron276h/repos", "events_url": "https://api.github.com/users/aaron276h/events{/privacy}", "received_events_url": "https://api.github.com/users/aaron276h/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}, {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2020-05-20T19:05:51Z", "updated_at": "2020-05-22T19:22:20Z", "closed_at": "2020-05-22T12:55:41Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): N/A\r\n2. Framework version: N/A\r\n3. Horovod version: 0.19.2\r\n4. MPI version: N/A (Using Gloo Controller)\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.6.4\r\n7. Python version: 3.6.10\r\n8. OS and version: Ubuntu 18.04\r\n9. GCC version: 4.8\r\n\r\n\r\n**Bug report:**\r\n\r\nWhen running multi-machine and not specifying a network interface, task processes fail to connect to driver. Note: using a GLOO controller.\r\n\r\nStack trace:\r\n\r\n```\r\nroot@ip-172-31-37-52:/# horovodrun -np 2 -H localhost:1,172.31.35.37:1 -p 12345 --verbose ls\r\nFiltering local host names.\r\nRemote host found: 172.31.35.37\r\nChecking ssh on all remote hosts.\r\nSSH was successful into all the remote hosts.\r\nTesting interfaces on all the hosts.\r\nLaunched horovod server.\r\nAttempted to launch horovod task servers.\r\nWaiting for the hosts to acknowledge.\r\n----------------------------------------\r\n----------------------------------------\r\nException happened during processing of request from ('127.0.0.1', 37436)\r\nException happened during processing of request from ('172.31.37.52', 52632)\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.37.52', 52636)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nTraceback (most recent call last):\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\n----------------------------------------\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.37.52', 55358)\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.37.52', 52642)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\nException happened during processing of request from ('127.0.0.1', 37442)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\nstruct.error: unpack requires a buffer of 4 bytes\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\n----------------------------------------\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.37.52', 55364)\r\n----------------------------------------\r\nException happened during processing of request from ('127.0.0.1', 37448)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n----------------------------------------\r\n----------------------------------------\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.37.52', 55368)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.35.37', 39790)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.35.37', 39796)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n----------------------------------------\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.35.37', 39798)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\nLaunching horovod task function was not successful:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/task_fn.py\", line 67, in <module>\r\n    _task_fn(index, driver_addresses, settings)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/task_fn.py\", line 27, in _task_fn\r\n    driver_addresses, settings.key, settings.verbose)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/driver/driver_service.py\", line 44, in __init__\r\n    match_intf=match_intf)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/service/driver_service.py\", line 159, in __init__\r\n    match_intf=match_intf)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 172, in __init__\r\n    'Linux.'.format(service_name=service_name, addresses=addresses))\r\nhorovod.run.common.util.network.NoValidAddressesFound: Horovod was unable to connect to horovod driver service on any of the following addresses: {'lo': [('127.0.0.1', 4548)], 'ens3': [('172.31.37.52', 4548)], 'docker0': [('172.17.0.1', 4548)]}.\r\n\r\nOne possible cause of this problem is that horovod currently requires every host to have at least one routable network interface with the same name across all of the hosts. You can run \"ifconfig -a\" on every host and check for the common routable interface. To fix the problem, you can rename interfaces on Linux.\r\n```\r\n\r\nWhen a network interface is specified, everything works as expected:\r\n```\r\nroot@ip-172-31-37-52:/# horovodrun -np 2 -H localhost:1,172.31.35.37:1 -p 12345 --network-interface ens3 ls\r\nWed May 20 19:01:46 2020[0]<stdout>:bin\r\nWed May 20 19:01:46 2020[0]<stdout>:boot\r\n.....\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1969/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1969/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1963", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1963/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1963/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1963/events", "html_url": "https://github.com/horovod/horovod/issues/1963", "id": 620579078, "node_id": "MDU6SXNzdWU2MjA1NzkwNzg=", "number": 1963, "title": "[Bug Report] `python setup.py install` is broken", "user": {"login": "DEKHTIARJonathan", "id": 10923599, "node_id": "MDQ6VXNlcjEwOTIzNTk5", "avatar_url": "https://avatars.githubusercontent.com/u/10923599?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DEKHTIARJonathan", "html_url": "https://github.com/DEKHTIARJonathan", "followers_url": "https://api.github.com/users/DEKHTIARJonathan/followers", "following_url": "https://api.github.com/users/DEKHTIARJonathan/following{/other_user}", "gists_url": "https://api.github.com/users/DEKHTIARJonathan/gists{/gist_id}", "starred_url": "https://api.github.com/users/DEKHTIARJonathan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DEKHTIARJonathan/subscriptions", "organizations_url": "https://api.github.com/users/DEKHTIARJonathan/orgs", "repos_url": "https://api.github.com/users/DEKHTIARJonathan/repos", "events_url": "https://api.github.com/users/DEKHTIARJonathan/events{/privacy}", "received_events_url": "https://api.github.com/users/DEKHTIARJonathan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-05-19T00:04:19Z", "updated_at": "2020-05-29T19:39:55Z", "closed_at": "2020-05-29T19:39:29Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "When installing Horovod from source, it seems that one of the \"common routes\" is broken:\r\n\r\n**Building as follows will generate an impressive number of issues at execution:**\r\n```\r\nexport HOROVOD_GPU_ALLREDUCE=NCCL\r\nexport HOROVOD_GPU_BROADCAST=NCCL\r\nexport HOROVOD_NCCL_INCLUDE=/usr/include\r\nexport HOROVOD_NCCL_LIB=/usr/lib/x86_64-linux-gnu\r\nexport HOROVOD_NCCL_LINK=SHARED\r\nexport HOROVOD_WITHOUT_PYTORCH=1\r\nexport HOROVOD_WITHOUT_MXNET=1\r\nexport HOROVOD_WITH_TENSORFLOW=1\r\nexport HOROVOD_WITH_MPI=1\r\nexport HOROVOD_BUILD_ARCH_FLAGS=\"-march=sandybridge -mtune=broadwell\"\r\npip uninstall horovod -y\r\npython setup.py clean\r\npython setup.py install\r\npython setup.py clean\r\n```\r\n\r\n**However, building as follows perfectly works:**\r\n```\r\nexport HOROVOD_GPU_ALLREDUCE=NCCL\r\nexport HOROVOD_GPU_BROADCAST=NCCL\r\nexport HOROVOD_NCCL_INCLUDE=/usr/include\r\nexport HOROVOD_NCCL_LIB=/usr/lib/x86_64-linux-gnu\r\nexport HOROVOD_NCCL_LINK=SHARED\r\nexport HOROVOD_WITHOUT_PYTORCH=1\r\nexport HOROVOD_WITHOUT_MXNET=1\r\nexport HOROVOD_WITH_TENSORFLOW=1\r\nexport HOROVOD_WITH_MPI=1\r\nexport HOROVOD_BUILD_ARCH_FLAGS=\"-march=sandybridge -mtune=broadwell\"\r\npip uninstall horovod -y\r\nrm -rf dist/*\r\npython setup.py sdist\r\npip install --no-cache --no-cache-dir dist/horovod-*.tar.gz\r\npython setup.py clean\r\n```\r\n\r\n---------------------------\r\n\r\nError Log:\r\n\r\n```\r\n2020-05-18 23:42:11.081786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/common/util/tiny_shell_exec.py\", line 33, in execute\r\n    exit_code = safe_shell_exec.execute(command, stdout=output, stderr=output)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/common/util/safe_shell_exec.py\", line 175, in execute\r\n    middleman.start()\r\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 42, in _launch\r\n    prep_data = spawn.get_preparation_data(process_obj._name)\r\n  File \"/usr/lib/python3.6/multiprocessing/spawn.py\", line 172, in get_preparation_data\r\n    main_mod_name = getattr(main_module.__spec__, \"name\", None)\r\nAttributeError: module '__main__' has no attribute '__spec__'\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/common/util/tiny_shell_exec.py\", line 33, in execute\r\n    exit_code = safe_shell_exec.execute(command, stdout=output, stderr=output)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/common/util/safe_shell_exec.py\", line 175, in execute\r\n    middleman.start()\r\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 42, in _launch\r\n    prep_data = spawn.get_preparation_data(process_obj._name)\r\n  File \"/usr/lib/python3.6/multiprocessing/spawn.py\", line 172, in get_preparation_data\r\n    main_mod_name = getattr(main_module.__spec__, \"name\", None)\r\nAttributeError: module '__main__' has no attribute '__spec__'\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/common/util/tiny_shell_exec.py\", line 33, in execute\r\n    exit_code = safe_shell_exec.execute(command, stdout=output, stderr=output)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/common/util/safe_shell_exec.py\", line 175, in execute\r\n    middleman.start()\r\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 42, in _launch\r\n    prep_data = spawn.get_preparation_data(process_obj._name)\r\n  File \"/usr/lib/python3.6/multiprocessing/spawn.py\", line 172, in get_preparation_data\r\n    main_mod_name = getattr(main_module.__spec__, \"name\", None)\r\nAttributeError: module '__main__' has no attribute '__spec__'\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/horovodrun\", line 4, in <module>\r\n    __import__('pkg_resources').run_script('horovod==0.19.2', 'horovodrun')\r\n  File \"/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\", line 667, in run_script\r\n    self.require(requires)[0].run_script(script_name, ns)\r\n  File \"/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\", line 1464, in run_script\r\n    exec(code, namespace, namespace)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/EGG-INFO/scripts/horovodrun\", line 21, in <module>\r\n    run_commandline()\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 723, in run_commandline\r\n    _run(args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 656, in _run\r\n    _launch_job(args, remote_host_names, settings, nics, command)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 717, in _launch_job\r\n    args.verbose)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 692, in run_controller\r\n    mpi_run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 709, in mpi_run_fn\r\n    mpi_run(settings, nics, env, command)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/mpi_run.py\", line 143, in mpi_run\r\n    raise Exception(_MPI_NOT_FOUND_ERROR_MSG)\r\nException: horovod does not find an installed MPI.\r\n\r\nChoose one of:\r\n1. Install Open MPI 4.0.0+ or IBM Spectrum MPI or MPICH and re-install Horovod (use --no-cache-dir pip option).\r\n2. Run distributed training script using the standard way provided by your MPI distribution (usually mpirun, srun, or jsrun).\r\n3. Use built-in gloo option (horovodrun --gloo ...).\r\n```\r\n\r\n@tgaddair FYI ;) ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1963/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1963/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1955", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1955/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1955/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1955/events", "html_url": "https://github.com/horovod/horovod/issues/1955", "id": 619320689, "node_id": "MDU6SXNzdWU2MTkzMjA2ODk=", "number": 1955, "title": "Account for dynamic world size when averaging gradients in TensorFlow", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1988239761, "node_id": "MDU6TGFiZWwxOTg4MjM5NzYx", "url": "https://api.github.com/repos/horovod/horovod/labels/elastic", "name": "elastic", "color": "40ce63", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/1", "html_url": "https://github.com/horovod/horovod/milestone/1", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/1/labels", "id": 5343023, "node_id": "MDk6TWlsZXN0b25lNTM0MzAyMw==", "number": 1, "title": "0.20.0", "description": "Elastic mode (autoscaling, fault tolerance)", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 8, "closed_issues": 11, "state": "closed", "created_at": "2020-04-23T23:49:44Z", "updated_at": "2021-02-11T18:48:13Z", "due_on": null, "closed_at": "2021-02-11T18:48:13Z"}, "comments": 0, "created_at": "2020-05-15T23:16:09Z", "updated_at": "2020-06-18T16:30:36Z", "closed_at": "2020-06-18T16:30:36Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Currently, the TensorFlow graph is constructed with the world size embedded as a constant tensor.  When running in elastic mode, this results in problems with averaging as the size is not updated as workers are added / removed.\r\n\r\n#357 provides an implementation of size ops that account for dynamic world sizes.  We should rebase and merge in this change to fix this.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1955/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1955/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1934", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1934/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1934/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1934/events", "html_url": "https://github.com/horovod/horovod/issues/1934", "id": 612010991, "node_id": "MDU6SXNzdWU2MTIwMTA5OTE=", "number": 1934, "title": "Can't find routable network interface when using Horovod Docker on two machines", "user": {"login": "Inception95", "id": 56369917, "node_id": "MDQ6VXNlcjU2MzY5OTE3", "avatar_url": "https://avatars.githubusercontent.com/u/56369917?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Inception95", "html_url": "https://github.com/Inception95", "followers_url": "https://api.github.com/users/Inception95/followers", "following_url": "https://api.github.com/users/Inception95/following{/other_user}", "gists_url": "https://api.github.com/users/Inception95/gists{/gist_id}", "starred_url": "https://api.github.com/users/Inception95/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Inception95/subscriptions", "organizations_url": "https://api.github.com/users/Inception95/orgs", "repos_url": "https://api.github.com/users/Inception95/repos", "events_url": "https://api.github.com/users/Inception95/events{/privacy}", "received_events_url": "https://api.github.com/users/Inception95/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-05-04T16:36:22Z", "updated_at": "2022-06-09T14:10:18Z", "closed_at": "2020-05-11T17:32:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Keras\r\n2. Framework version: 2.3.1 (TensorFlow 1.14.0 backend)\r\n3. Horovod version: 0.18.2\r\n4. MPI version: 1.10.2\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.8\r\n7. Python version: 3.6.8\r\n8. OS and version: Ubuntu 18.04 (Docker), Ubuntu 16.04 (Host)\r\n9. GCC version: \r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\nYes, similar issue: https://github.com/horovod/horovod/issues/1068, tried to add --start-timeout 300 but still didn't work.\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\nYes, but my passwordless ssh between the two machines is fine.\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\nYes, I followed this site to run training script.\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\nI checked but no.\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nHi, thanks for your great contribution!\r\n\r\nI used to use Horovod training image classification task on two machines with 16 GPUs (CentOS 7), now I try to do it on Ubuntu but failed. I am using Horovod Docker to run the task, when I run the task on one machine using Docker, it went well, but when running it on two machines (already set the passwordless ssh), it shows:\r\n\r\n`horovod.run.common.util.network was unable to connect to horovodrun driver on any of the following address.`\r\n\r\nThe command I used inside the docker after set the worker \"sleep infinitely\" and open the 12345 port is: \r\n`horovodrun --verbose -np 2 -H localhost:1,worker-ip:1 --start-timeout 300 -p 12345 python keras_mnist.py`\r\n\r\nit shows:\r\n```\r\nFiltering local host names.\r\nRemote host found: worker-ip\r\nChecking ssh on all remote hosts.\r\nSSH was successful into all the remote hosts.\r\nTesting interfaces on all the hosts.\r\nLanuched horovodrun server.\r\nAttempted to launch horovod task servers.\r\nWaiting for the hosts to acknowledge.\r\n```\r\n\r\nNow it just hangs here for about 10 mins, but firstly it shows:\r\nhorovod.run.common.util.network was unable to connect to horovodrun driver on any of the following address.\r\none possible caused of this problem is that horovodrun currently requires every host to have at least one routable network interfaces with the same name across all of the hosts. You can run \"ifconfig -a\" on every host and check for the common routable interface.\r\n\r\nI ran the \"ifconfig -a\" on two machines and their interfaces have the same name (I trained on the aws instances and asked the support center to check the network status, it seems fine). I also try to reproduce this training on CentOS instances but this problem shows again.\r\n\r\nIs there any possible reasons to my situation? Thanks in advance!\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1934/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1934/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1921", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1921/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1921/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1921/events", "html_url": "https://github.com/horovod/horovod/issues/1921", "id": 608786301, "node_id": "MDU6SXNzdWU2MDg3ODYzMDE=", "number": 1921, "title": "Keras LR callbacks have unintended behavior when resuming from checkpoint", "user": {"login": "sparticlesteve", "id": 6074319, "node_id": "MDQ6VXNlcjYwNzQzMTk=", "avatar_url": "https://avatars.githubusercontent.com/u/6074319?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sparticlesteve", "html_url": "https://github.com/sparticlesteve", "followers_url": "https://api.github.com/users/sparticlesteve/followers", "following_url": "https://api.github.com/users/sparticlesteve/following{/other_user}", "gists_url": "https://api.github.com/users/sparticlesteve/gists{/gist_id}", "starred_url": "https://api.github.com/users/sparticlesteve/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sparticlesteve/subscriptions", "organizations_url": "https://api.github.com/users/sparticlesteve/orgs", "repos_url": "https://api.github.com/users/sparticlesteve/repos", "events_url": "https://api.github.com/users/sparticlesteve/events{/privacy}", "received_events_url": "https://api.github.com/users/sparticlesteve/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/2", "html_url": "https://github.com/horovod/horovod/milestone/2", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/2/labels", "id": 5346062, "node_id": "MDk6TWlsZXN0b25lNTM0NjA2Mg==", "number": 2, "title": "0.19.2", "description": "Bugfix release, LSF support, last release with Python 2 support.", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 7, "state": "closed", "created_at": "2020-04-24T16:27:59Z", "updated_at": "2020-05-13T20:31:31Z", "due_on": "2020-05-08T07:00:00Z", "closed_at": "2020-05-13T20:31:31Z"}, "comments": 10, "created_at": "2020-04-29T05:22:41Z", "updated_at": "2020-05-04T15:46:41Z", "closed_at": "2020-05-04T14:53:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: tf.keras\r\n2. Framework version: TF 1.15.0\r\n3. Horovod version: 0.19.0\r\n4. MPI version: cray-mpich/7.7.10\r\n5. CUDA version: n/a\r\n6. NCCL version: n/a\r\n7. Python version: 3.7.4\r\n8. OS and version: Cray linux based on SLES 15\r\n9. GCC version: 7.3.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? n/a\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? n/a\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? yes\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nThere is a problem with the Keras learning rate callbacks (inheriting from `LearningRateScheduleCallbackImpl`) as implemented when using checkpoints and resuming training. This class pulls the `initial_lr` from the model optimizer in `on_train_begin`:\r\nhttps://github.com/horovod/horovod/blob/d1b13ec131af22b31d0ba999dae15a29991cfeae/horovod/_keras/callbacks.py#L137\r\nAll LR (and momentum) modifications are done with respect to that initial learning rate and the current epoch (or batch). However, if one is writing a checkpoint, the current modified learning rate and momentum are written to the checkpoint file. Then, upon loading that checkpoint and resuming training with the LR callback, it pulls the _modified_ LR as its new `initial_lr`. Unless the user takes care to reset the optimizer's LR (and momentum) after loading from checkpoint and before training, the original schedule applied will not produce the intended schedule. The Keras Imagenet resnet50 example is affected by this, for instance:\r\nhttps://github.com/horovod/horovod/blob/master/examples/keras_imagenet_resnet50.py\r\n\r\nIn contrast, the LR scheduler in Keras (and tf.keras) is implemented such that modifications depend on the _current_ learning rate. This slightly different approach is therefore not affected by the checkpoint resume issue. It doesn't have any momentum correction, though.\r\nhttps://github.com/tensorflow/tensorflow/blob/bab74a15d9ad6bb9066b3e31d601d6a45b1cb221/tensorflow/python/keras/callbacks.py#L1349\r\n\r\nI think there are a couple of possible reasonable solutions. One is to change the multiplier logic to match that of the Keras LR scheduler so that the new LR is a result of the multiplier times the current LR. This logic change would likely break folks' code, though. Another possible solution is to allow (or require!) the user to set the initial LR in the callback constructor. This way I can ensure that it is always set to the correct, intended value. Finally, as I alluded to above, the user can reset their optimizer LR (and appropriately scale the momentum) after loading from checkpoint and before training. However, I consider this a workaround rather than a solution.\r\n\r\nI'm hoping I explained it clearly enough that I don't need a MWE, but I can provide one if required.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1921/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1921/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1920", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1920/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1920/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1920/events", "html_url": "https://github.com/horovod/horovod/issues/1920", "id": 608766715, "node_id": "MDU6SXNzdWU2MDg3NjY3MTU=", "number": 1920, "title": "hvd.load_model not properly wrapping optimizer in tf.keras 1.15", "user": {"login": "sparticlesteve", "id": 6074319, "node_id": "MDQ6VXNlcjYwNzQzMTk=", "avatar_url": "https://avatars.githubusercontent.com/u/6074319?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sparticlesteve", "html_url": "https://github.com/sparticlesteve", "followers_url": "https://api.github.com/users/sparticlesteve/followers", "following_url": "https://api.github.com/users/sparticlesteve/following{/other_user}", "gists_url": "https://api.github.com/users/sparticlesteve/gists{/gist_id}", "starred_url": "https://api.github.com/users/sparticlesteve/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sparticlesteve/subscriptions", "organizations_url": "https://api.github.com/users/sparticlesteve/orgs", "repos_url": "https://api.github.com/users/sparticlesteve/repos", "events_url": "https://api.github.com/users/sparticlesteve/events{/privacy}", "received_events_url": "https://api.github.com/users/sparticlesteve/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/2", "html_url": "https://github.com/horovod/horovod/milestone/2", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/2/labels", "id": 5346062, "node_id": "MDk6TWlsZXN0b25lNTM0NjA2Mg==", "number": 2, "title": "0.19.2", "description": "Bugfix release, LSF support, last release with Python 2 support.", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 7, "state": "closed", "created_at": "2020-04-24T16:27:59Z", "updated_at": "2020-05-13T20:31:31Z", "due_on": "2020-05-08T07:00:00Z", "closed_at": "2020-05-13T20:31:31Z"}, "comments": 3, "created_at": "2020-04-29T04:20:51Z", "updated_at": "2020-05-05T17:26:16Z", "closed_at": "2020-05-05T17:26:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: tf.keras\r\n2. Framework version: TF 1.15.0\r\n3. Horovod version: 0.19.0\r\n4. MPI version: cray-mpich/7.7.10\r\n5. CUDA version: n/a\r\n6. NCCL version: n/a\r\n7. Python version: 3.7.4\r\n8. OS and version: Cray linux based on SLES 15\r\n9. GCC version: 7.3.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Oui\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? n/a\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? n/a\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Oui oui\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nI've been noticing bad training results when resuming from checkpoint with `hvd.load_model`. I tracked it down to diverging worker models, and noticed that my model optimizers from `hvd.load_model` were not properly wrapped in the horovod DistributedOptimizer. I believe it's a bug in this logic that determines all optimizer classes to wrap right here:\r\nhttps://github.com/horovod/horovod/blob/d1b13ec131af22b31d0ba999dae15a29991cfeae/horovod/_keras/__init__.py#L113\r\n\r\nThis part:\r\n\r\n    horovod_objects = {\r\n        subclass.__name__.lower(): wrap_optimizer(subclass)\r\n        for subclass in keras.optimizers.Optimizer.__subclasses__()\r\n        if subclass.__module__ == keras.optimizers.Optimizer.__module__\r\n    }\r\n\r\nThis check on the subclass module matching Optimizer module doesn't work in TF 1.15. E.g., for the SGD optimizer, the class module (the LHS) is actually\r\n\r\n    In [9]: tensorflow.python.keras.optimizer_v2.gradient_descent.SGD.__module__\r\n    Out[9]: 'tensorflow.python.keras.optimizer_v2.gradient_descent'\r\n\r\nwhereas the RHS is\r\n\r\n    In [10]: tf.keras.optimizers.Optimizer.__module__\r\n    Out[10]: 'tensorflow.python.keras.optimizer_v2.optimizer_v2\u2019\r\n\r\nI have for now implemented a workaround in my code that just removes the module equality comparison and confirm that my optimizers are correctly being wrapped in DistributedOptimizer.\r\n\r\nI don't have a suggestion for how to fix this in Horovod. Presumably the module paths are inconsistent across Keras and TF versions :(", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1920/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1920/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1891", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1891/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1891/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1891/events", "html_url": "https://github.com/horovod/horovod/issues/1891", "id": 603596230, "node_id": "MDU6SXNzdWU2MDM1OTYyMzA=", "number": 1891, "title": "Python 3.8 incompatibility with nccl_built check", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/2", "html_url": "https://github.com/horovod/horovod/milestone/2", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/2/labels", "id": 5346062, "node_id": "MDk6TWlsZXN0b25lNTM0NjA2Mg==", "number": 2, "title": "0.19.2", "description": "Bugfix release, LSF support, last release with Python 2 support.", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 7, "state": "closed", "created_at": "2020-04-24T16:27:59Z", "updated_at": "2020-05-13T20:31:31Z", "due_on": "2020-05-08T07:00:00Z", "closed_at": "2020-05-13T20:31:31Z"}, "comments": 0, "created_at": "2020-04-20T23:21:31Z", "updated_at": "2020-05-04T16:59:30Z", "closed_at": "2020-05-04T16:59:30Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "See: https://github.com/huge-success/sanic/issues/1774\r\n\r\n```\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/site-packages/horovod/common/util.py:110: in wrapper\r\n    retval = f(*args, **kwargs)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/site-packages/horovod/common/util.py:151: in nccl_built\r\n    result = _check_extension_lambda(\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/site-packages/horovod/common/util.py:90: in _check_extension_lambda\r\n    p.start()\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/process.py:121: in start\r\n    self._popen = self._Popen(self)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/context.py:224: in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/context.py:283: in _Popen\r\n    return Popen(process_obj)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/popen_spawn_posix.py:32: in __init__\r\n    super().__init__(process_obj)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/popen_fork.py:19: in __init__\r\n    self._launch(process_obj)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/popen_spawn_posix.py:47: in _launch\r\n    reduction.dump(process_obj, fp)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/reduction.py:60: in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nE   AttributeError: Can't pickle local object '_check_extension_lambda.<locals>._target_fn'\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1891/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1891/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1885", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1885/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1885/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1885/events", "html_url": "https://github.com/horovod/horovod/issues/1885", "id": 602418075, "node_id": "MDU6SXNzdWU2MDI0MTgwNzU=", "number": 1885, "title": "speed plunges when training locally", "user": {"login": "jasperzhong", "id": 25879526, "node_id": "MDQ6VXNlcjI1ODc5NTI2", "avatar_url": "https://avatars.githubusercontent.com/u/25879526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasperzhong", "html_url": "https://github.com/jasperzhong", "followers_url": "https://api.github.com/users/jasperzhong/followers", "following_url": "https://api.github.com/users/jasperzhong/following{/other_user}", "gists_url": "https://api.github.com/users/jasperzhong/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasperzhong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasperzhong/subscriptions", "organizations_url": "https://api.github.com/users/jasperzhong/orgs", "repos_url": "https://api.github.com/users/jasperzhong/repos", "events_url": "https://api.github.com/users/jasperzhong/events{/privacy}", "received_events_url": "https://api.github.com/users/jasperzhong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-18T09:23:15Z", "updated_at": "2020-04-25T08:16:53Z", "closed_at": "2020-04-25T08:16:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework:  mxnet-cu102 \r\n2. Framework version: 1.6.0\r\n3. Horovod version: 0.19.1\r\n4. MPI version: 3.1.0 \r\n5. CUDA version: 10.2\r\n6. NCCL version: 2.5.6\r\n7. Python version: 3.6\r\n8. OS and version: ubuntu18.04lts\r\n9. GCC version: 7.5.0\r\n\r\nHW: p3.16xlarge \r\n\r\n**Bug report:**\r\n\r\n```sh\r\nhorovodrun -np 8 -H localhost:8 python ~/repos/horovod/examples/mxnet_imagenet_resnet50.py --model resnet50_v2 --mode gluon --rec-train ~/data/ILSVRC2012/train.rec --rec-train-idx ~/data/ILSVRC2012/train.idx --rec-val ~/data/ILSVRC2012/val.rec --rec-val-idx ~/data/ILSVRC2012/val.idx --use-rec --batch-size 64 --num-epochs 120 --data-nthreads 2 --warmup-epochs 5 --lr 0.05 --lr-mode step --log-interval 1\r\n```\r\nAt first everything worked well. but later GPUs run so slow that i thought they did not run at all. I set `log-interval` to 1 and found it did run at an extremely slow speed, around 70img/s. \r\n\r\n![image](https://user-images.githubusercontent.com/25879526/79633480-6d7ad500-8198-11ea-941c-36d03e8a5434.png)\r\n\r\n[full log](https://github.com/horovod/horovod/files/4496373/hvd.log) can be found here.\r\n \r\n___\r\n\r\nBTW, I did not observe this phenomenon when training distributedly with 8 x p3.16xlarge. hvd can reach the speed of ~15000img/s. that's about 68% scaling efficiency. is that reasonable?  \r\n```sh\r\nhorovodrun -np 64 -H xxx:8 xxx:8 xxx:8 xxx:8 xxx:8 xxx:8 xxx:8 xxx:8  python ~/repos/horovod/examples/mxnet_imagenet_resnet50.py --model resnet50_v2 --mode gluon --rec-train ~/data/ILSVRC2012/train.rec --rec-train-idx ~/data/ILSVRC2012/train.idx --rec-val ~/data/ILSVRC2012/val.rec --rec-val-idx ~/data/ILSVRC2012/val.idx --use-rec --batch-size 64 --num-epochs 120 --data-nthreads 2 --warmup-epochs 5 --lr 0.05 --lr-mode step --log-interval 50\r\n```\r\n\r\nmy installation:\r\n```sh\r\nHOROVOD_NCCL_INCLUDE=/usr/local/cuda-10.2/include HOROVOD_NCCL_LIB=/usr/local/cuda-10.2/lib HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_GPU_BROADCAST=NCCL pip install --no-cache-dir horovod\r\n```\r\n\r\ni found similar issue #824 but in my case the data is just on each server's ssd. \r\n \r\n```sh\r\nubuntu@ip-xxx:~$ df -h\r\nFilesystem      Size  Used Avail Use% Mounted on\r\nudev            241G     0  241G   0% /dev\r\ntmpfs            49G  1.1M   49G   1% /run\r\n/dev/xvda1      993G  383G  611G  39% /\r\ntmpfs           241G  1.1G  240G   1% /dev/shm\r\ntmpfs           5.0M     0  5.0M   0% /run/lock\r\ntmpfs           241G     0  241G   0% /sys/fs/cgroup\r\n/dev/loop0       18M   18M     0 100% /snap/amazon-ssm-agent/1480\r\n/dev/loop2       94M   94M     0 100% /snap/core/8935\r\n/dev/loop1       18M   18M     0 100% /snap/amazon-ssm-agent/1566\r\n/dev/loop3       92M   92M     0 100% /snap/core/8689\r\ntmpfs            49G     0   49G   0% /run/user/1000\r\n```\r\n\r\nthe data path is /home/ubuntu/data, which is on /dev/xvda1. \r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1885/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1885/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1865", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1865/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1865/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1865/events", "html_url": "https://github.com/horovod/horovod/issues/1865", "id": 598415395, "node_id": "MDU6SXNzdWU1OTg0MTUzOTU=", "number": 1865, "title": "Deprecation warning due to invalid escape sequences in Python 3.7", "user": {"login": "tirkarthi", "id": 3972343, "node_id": "MDQ6VXNlcjM5NzIzNDM=", "avatar_url": "https://avatars.githubusercontent.com/u/3972343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tirkarthi", "html_url": "https://github.com/tirkarthi", "followers_url": "https://api.github.com/users/tirkarthi/followers", "following_url": "https://api.github.com/users/tirkarthi/following{/other_user}", "gists_url": "https://api.github.com/users/tirkarthi/gists{/gist_id}", "starred_url": "https://api.github.com/users/tirkarthi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tirkarthi/subscriptions", "organizations_url": "https://api.github.com/users/tirkarthi/orgs", "repos_url": "https://api.github.com/users/tirkarthi/repos", "events_url": "https://api.github.com/users/tirkarthi/events{/privacy}", "received_events_url": "https://api.github.com/users/tirkarthi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 728479138, "node_id": "MDU6TGFiZWw3Mjg0NzkxMzg=", "url": "https://api.github.com/repos/horovod/horovod/labels/contribution%20welcome", "name": "contribution welcome", "color": "138e05", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-12T05:34:44Z", "updated_at": "2020-04-15T18:12:28Z", "closed_at": "2020-04-15T18:12:28Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version: 3.7\r\n8. OS and version: Linux Ubuntu 18.04\r\n9. GCC version:\r\n\r\n**Bug report:**\r\n\r\nDeprecation warnings are raised due to invalid escape sequences. This can be fixed by using raw strings or escaping the literals.\r\n\r\n```\r\nfind . -iname '*.py' | grep -Ev 'example|utl|samples' | xargs -P 4 -I{} python3.8 -Wall -m py_compile {} \r\n./setup.py:1008: DeprecationWarning: invalid escape sequence \\d\r\n  m = re.match('^(\\d+)(?:\\.(\\d+))?(?:\\.(\\d+))?(?:\\.(\\d+))?', version_str)\r\n./test/test_run.py:332: DeprecationWarning: invalid escape sequence \\.\r\n  exception = 'Neither MPI nor Gloo support has been built\\. Try reinstalling Horovod ensuring that ' \\\r\n./test/test_run.py:333: DeprecationWarning: invalid escape sequence \\(\r\n  'either MPI is installed \\(MPI\\) or CMake is installed \\(Gloo\\)\\.'\r\n./test/test_run.py:322: DeprecationWarning: invalid escape sequence \\.\r\n  exception = '^MPI support has not been built\\.  If this is not expected, ensure MPI is installed ' \\\r\n./test/test_run.py:323: DeprecationWarning: invalid escape sequence \\.\r\n  'and reinstall Horovod with HOROVOD_WITH_MPI=1 to debug the build error\\.$'\r\n./test/test_run.py:312: DeprecationWarning: invalid escape sequence \\.\r\n  exception = '^MPI support has not been built\\.  If this is not expected, ensure MPI is installed ' \\\r\n./test/test_run.py:313: DeprecationWarning: invalid escape sequence \\.\r\n  'and reinstall Horovod with HOROVOD_WITH_MPI=1 to debug the build error\\.$'\r\n./test/test_run.py:306: DeprecationWarning: invalid escape sequence \\.\r\n  exception = '^Gloo support has not been built\\.  If this is not expected, ensure CMake is installed ' \\\r\n./test/test_run.py:307: DeprecationWarning: invalid escape sequence \\.\r\n  'and reinstall Horovod with HOROVOD_WITH_GLOO=1 to debug the build error\\.$'\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1865/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1865/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1851", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1851/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1851/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1851/events", "html_url": "https://github.com/horovod/horovod/issues/1851", "id": 596525497, "node_id": "MDU6SXNzdWU1OTY1MjU0OTc=", "number": 1851, "title": "Docker example fails", "user": {"login": "ilmarkov", "id": 8823584, "node_id": "MDQ6VXNlcjg4MjM1ODQ=", "avatar_url": "https://avatars.githubusercontent.com/u/8823584?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ilmarkov", "html_url": "https://github.com/ilmarkov", "followers_url": "https://api.github.com/users/ilmarkov/followers", "following_url": "https://api.github.com/users/ilmarkov/following{/other_user}", "gists_url": "https://api.github.com/users/ilmarkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/ilmarkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ilmarkov/subscriptions", "organizations_url": "https://api.github.com/users/ilmarkov/orgs", "repos_url": "https://api.github.com/users/ilmarkov/repos", "events_url": "https://api.github.com/users/ilmarkov/events{/privacy}", "received_events_url": "https://api.github.com/users/ilmarkov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2020-04-08T12:02:30Z", "updated_at": "2020-04-23T23:25:58Z", "closed_at": "2020-04-23T23:25:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Any of frameworks\r\n2. Framework version:\r\n3. Horovod version: 0.19.1\r\n4. MPI version: 3.0.0\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.7-1+cuda10.0\r\n7. Python version: 2.7\r\n8. OS and version: ubuntu16.04\r\n9. GCC version: g++-2.8\r\n\r\n**Bug report:**\r\n\r\nI build a docker image of the latest horovod sources from Dockerfile.test.gpu with a slight addition to support ssh (took a couple of lines installing OpenSSH-server from Dockerfile.gpu).\r\nRunning training on a single node inside a docker container worked perfectly.\r\nThen started 2 containers on separate machines following instructions in [documentation](https://github.com/horovod/horovod/blob/master/docs/docker.rst#running-on-multiple-machines). Passwordless ssh was established.\r\n\r\nThe issues are two-fold.\r\nThe first one looked like a typo [here](https://github.com/horovod/horovod/blob/master/horovod/run/driver/driver_service.py#L148). \"Settings doesn't have attribute nic\". There must be \"nics\".\r\n\r\nWhen I fixed it, the second problem came out.\r\nI'm trying to on host1 with following line:\r\n` horovodrun -np 4 -H localhost:2,host2:2 -p 1234 python pytorch_synthetic_benchmark.py`\r\nIt looks similar to issues #975, #971. Though, the error messages says it can't connect not to remote servers but to localhost:\r\n`horovod.run.common.util.network.NoValidAddressesFound: Horovod was unable to connect to horovod driver service on any of the following addresses: {'lo': [('127.0.0.1', 18524)], 'docker0': [('localhost_int_ip', 18524)], 'eno1': [('localhost_ip, 18524)]}.`\r\nAnd following error traceback:\r\n```\r\n self.RequestHandlerClass(request, client_address, self)\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 652, in __init__\r\n    self.handle()\r\n  File \"/usr/local/lib/python2.7/dist-packages/horovod/run/common/util/network.py\", line 107, in h$ndle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/usr/local/lib/python2.7/dist-packages/horovod/run/common/util/network.py\", line 80, in re$d\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nerror: unpack requires a string argument of length 4\r\n```\r\nWhen I try to run the following way:\r\n` horovodrun -np 4 -H host1:2,host2:2 -p 1234 python pytorch_synthetic_benchmark.py`\r\nIt fails with following error:\r\n`ssh: connect to host host1 port 1234: Connection refused`. Though, documentation doesn't state \r\nto run ssh in container starting the training. When I start `sshd` on host1 the problem described above comes out.\r\n\r\nBuilding docker image not from sources, but using Dockerfile.gpu, everything works fine. So there must be a problem with a current version.\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1851/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1851/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1791", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1791/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1791/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1791/events", "html_url": "https://github.com/horovod/horovod/issues/1791", "id": 580609317, "node_id": "MDU6SXNzdWU1ODA2MDkzMTc=", "number": 1791, "title": "Dockerfile needs to be updated", "user": {"login": "abcinje", "id": 33629617, "node_id": "MDQ6VXNlcjMzNjI5NjE3", "avatar_url": "https://avatars.githubusercontent.com/u/33629617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abcinje", "html_url": "https://github.com/abcinje", "followers_url": "https://api.github.com/users/abcinje/followers", "following_url": "https://api.github.com/users/abcinje/following{/other_user}", "gists_url": "https://api.github.com/users/abcinje/gists{/gist_id}", "starred_url": "https://api.github.com/users/abcinje/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abcinje/subscriptions", "organizations_url": "https://api.github.com/users/abcinje/orgs", "repos_url": "https://api.github.com/users/abcinje/repos", "events_url": "https://api.github.com/users/abcinje/events{/privacy}", "received_events_url": "https://api.github.com/users/abcinje/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-13T13:42:49Z", "updated_at": "2020-03-13T17:01:00Z", "closed_at": "2020-03-13T17:01:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version: 3.6\r\n8. OS and version: Ubuntu 18.04.4\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nHello. I've followed the instructions in the [docker guide](https://github.com/horovod/horovod/blob/master/docs/docker.rst).\r\nWhile building Horovod in docker by running\r\n```\r\n$ docker build -t horovod:latest horovod-docker-gpu\r\n```\r\nI've got the following error\r\n![bug](https://user-images.githubusercontent.com/33629617/76625760-4ae31400-657b-11ea-9e6e-8c28ef3ec12c.PNG)\r\n\r\nAs a workaround, I added an argument to `get_supported()` function like:\r\n```\r\nw.get_supported('.')\r\n```\r\nAnd it worked well.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1791/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1791/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1769", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1769/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1769/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1769/events", "html_url": "https://github.com/horovod/horovod/issues/1769", "id": 575671805, "node_id": "MDU6SXNzdWU1NzU2NzE4MDU=", "number": 1769, "title": "Broken Mac OS package", "user": {"login": "kahrabian", "id": 10699711, "node_id": "MDQ6VXNlcjEwNjk5NzEx", "avatar_url": "https://avatars.githubusercontent.com/u/10699711?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kahrabian", "html_url": "https://github.com/kahrabian", "followers_url": "https://api.github.com/users/kahrabian/followers", "following_url": "https://api.github.com/users/kahrabian/following{/other_user}", "gists_url": "https://api.github.com/users/kahrabian/gists{/gist_id}", "starred_url": "https://api.github.com/users/kahrabian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kahrabian/subscriptions", "organizations_url": "https://api.github.com/users/kahrabian/orgs", "repos_url": "https://api.github.com/users/kahrabian/repos", "events_url": "https://api.github.com/users/kahrabian/events{/privacy}", "received_events_url": "https://api.github.com/users/kahrabian/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-04T18:54:51Z", "updated_at": "2020-03-06T01:50:04Z", "closed_at": "2020-03-06T01:50:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.4.0\r\n3. Horovod version: 0.19.0\r\n4. MPI version: 4.0.2\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.8.1\r\n8. OS and version: Mac OS 10.15.3 (19D76)\r\n9. GCC version: 9.2.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?  Yes\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?  Yes\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Bug report:**\r\nWhile running `horovodrun --check-build` the following error occurs:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/kahrabian/miniconda3/envs/gg/bin/horovodrun\", line 18, in <module>\r\n    from horovod.run.run import run_commandline\r\n  File \"/Users/kahrabian/miniconda3/envs/gg/lib/python3.8/site-packages/horovod/run/__init__.py\", line 16, in <module>\r\n    from .run import run\r\n  File \"/Users/kahrabian/miniconda3/envs/gg/lib/python3.8/site-packages/horovod/run/run.py\", line 26, in <module>\r\n    from psutil import net_if_addrs\r\n  File \"/Users/kahrabian/miniconda3/envs/gg/lib/python3.8/site-packages/psutil/__init__.py\", line 161, in <module>\r\n    from . import _psosx as _psplatform\r\n  File \"/Users/kahrabian/miniconda3/envs/gg/lib/python3.8/site-packages/psutil/_psosx.py\", line 15, in <module>\r\n    from . import _psutil_osx as cext\r\nImportError: dlopen(/Users/kahrabian/miniconda3/envs/gg/lib/python3.8/site-packages/psutil/_psutil_osx.cpython-38-darwin.so, 2): Symbol not found: ___CFConstantStringClassReference\r\n  Referenced from: /Users/kahrabian/miniconda3/envs/gg/lib/python3.8/site-packages/psutil/_psutil_osx.cpython-38-darwin.so\r\n  Expected in: flat namespace\r\n in /Users/kahrabian/miniconda3/envs/gg/lib/python3.8/site-packages/psutil/_psutil_osx.cpython-38-darwin.so\r\n```\r\n\r\nI recently upgrade my OS and the library stopped working after this upgrade.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1769/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1769/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1762", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1762/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1762/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1762/events", "html_url": "https://github.com/horovod/horovod/issues/1762", "id": 574861085, "node_id": "MDU6SXNzdWU1NzQ4NjEwODU=", "number": 1762, "title": "DenseVectors metadata missing when Model is fitted on parquete", "user": {"login": "m-mallory", "id": 30811798, "node_id": "MDQ6VXNlcjMwODExNzk4", "avatar_url": "https://avatars.githubusercontent.com/u/30811798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/m-mallory", "html_url": "https://github.com/m-mallory", "followers_url": "https://api.github.com/users/m-mallory/followers", "following_url": "https://api.github.com/users/m-mallory/following{/other_user}", "gists_url": "https://api.github.com/users/m-mallory/gists{/gist_id}", "starred_url": "https://api.github.com/users/m-mallory/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/m-mallory/subscriptions", "organizations_url": "https://api.github.com/users/m-mallory/orgs", "repos_url": "https://api.github.com/users/m-mallory/repos", "events_url": "https://api.github.com/users/m-mallory/events{/privacy}", "received_events_url": "https://api.github.com/users/m-mallory/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2020-03-03T18:34:54Z", "updated_at": "2020-03-06T01:08:44Z", "closed_at": "2020-03-06T01:08:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version: 0.19.0\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nWhen fitting an estimator using parquete training data ([fit_on_parquet()](https://github.com/horovod/horovod/blob/586dbcdc448739b3ab3108a9549ad478afae9e17/horovod/spark/common/estimator.py#L39)).\r\nIn [get_simple_metadata_from_parquet()](https://github.com/horovod/horovod/blob/586dbcdc448739b3ab3108a9549ad478afae9e17/horovod/spark/common/util.py#L387)\r\n\r\nthe `'shape'` of the metadata field is set null. \r\n\r\n\r\nHowever, when applying the fitted model, in [_transform()](https://github.com/horovod/horovod/blob/586dbcdc448739b3ab3108a9549ad478afae9e17/horovod/spark/torch/estimator.py#L375), \r\nThe shape of dense vectors are used:\r\n```\r\nif col_type == DenseVector:\r\n                        shape = meta['shape']\r\n                        flattened_pred = pred.reshape(shape, )\r\n                        field = DenseVector(flattened_pred)\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1762/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1762/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1757", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1757/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1757/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1757/events", "html_url": "https://github.com/horovod/horovod/issues/1757", "id": 573970301, "node_id": "MDU6SXNzdWU1NzM5NzAzMDE=", "number": 1757, "title": "error on 'pip install' for PyTorch 1.5", "user": {"login": "thnkim", "id": 7189259, "node_id": "MDQ6VXNlcjcxODkyNTk=", "avatar_url": "https://avatars.githubusercontent.com/u/7189259?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thnkim", "html_url": "https://github.com/thnkim", "followers_url": "https://api.github.com/users/thnkim/followers", "following_url": "https://api.github.com/users/thnkim/following{/other_user}", "gists_url": "https://api.github.com/users/thnkim/gists{/gist_id}", "starred_url": "https://api.github.com/users/thnkim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thnkim/subscriptions", "organizations_url": "https://api.github.com/users/thnkim/orgs", "repos_url": "https://api.github.com/users/thnkim/repos", "events_url": "https://api.github.com/users/thnkim/events{/privacy}", "received_events_url": "https://api.github.com/users/thnkim/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-02T13:21:51Z", "updated_at": "2020-03-02T13:36:03Z", "closed_at": "2020-03-02T13:36:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) PyTorch\r\n2. Framework version: '1.5.0a0+ad769d7'\r\n3. Horovod version: unknown\r\n4. MPI version: 4.0.2\r\n5. CUDA version: 10.2\r\n6. NCCL version: 2.5.6 (nccl-repo-ubuntu1604-2.5.6-ga-cuda10.2_1-1_amd64.deb)\r\n7. Python version: 3.7.4 (Anaconda)\r\n8. OS and version: Ubuntu 16.04.12\r\n9. GCC version: 5.4.0 20160609\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nI tried to install horovod with\r\n```HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_GPU_BROADCAST=NCCL HOROVOD_WITH_PYTORCH=1 pip install --no-cache-dir horovod```\r\nBut I got errors as follows:\r\n```\r\n    /usr/bin/gcc -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -DHOROVOD_GPU_BROADCAST='N' -DTORCH_VERSION=1005000000 -D_GLIBCXX_USE_CXX11_ABI=1 -DTORCH_API_INCLUDE_EXTENSION_H=1 -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -Ihorovod/common/ops/cuda -I/home/polphit/anaconda3/lib/python3.7/site-packages/torch/include -I/home/polphit/anaconda3/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/home/polphit/anaconda3/lib/python3.7/site-packages/torch/include/TH -I/home/polphit/anaconda3/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/polphit/anaconda3/include/python3.7m -c horovod/torch/ready_event.cc -o build/temp.linux-x86_64-3.7/horovod/torch/ready_event.o -std=c++14 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    horovod/torch/ready_event.cc: In constructor \u2018horovod::torch::TorchReadyEvent::TorchReadyEvent(int)\u2019:\r\n    horovod/torch/ready_event.cc:57:65: error: \u2018THCState_getCurrentStreamOnDevice\u2019 was not declared in this scope\r\n       auto stream = THCState_getCurrentStreamOnDevice(state, device_);\r\n                                                                     ^\r\n    error: command '/usr/bin/gcc' failed with exit status 1\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /home/polphit/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-z07e4ys3/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-z07e4ys3/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-ts3dcs8y/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1757/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1757/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1752", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1752/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1752/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1752/events", "html_url": "https://github.com/horovod/horovod/issues/1752", "id": 573281331, "node_id": "MDU6SXNzdWU1NzMyODEzMzE=", "number": 1752, "title": "Importing ABC directly from collections was deprecated and will be removed in Python 3.10. Use collections.abc instead.", "user": {"login": "tirkarthi", "id": 3972343, "node_id": "MDQ6VXNlcjM5NzIzNDM=", "avatar_url": "https://avatars.githubusercontent.com/u/3972343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tirkarthi", "html_url": "https://github.com/tirkarthi", "followers_url": "https://api.github.com/users/tirkarthi/followers", "following_url": "https://api.github.com/users/tirkarthi/following{/other_user}", "gists_url": "https://api.github.com/users/tirkarthi/gists{/gist_id}", "starred_url": "https://api.github.com/users/tirkarthi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tirkarthi/subscriptions", "organizations_url": "https://api.github.com/users/tirkarthi/orgs", "repos_url": "https://api.github.com/users/tirkarthi/repos", "events_url": "https://api.github.com/users/tirkarthi/events{/privacy}", "received_events_url": "https://api.github.com/users/tirkarthi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-29T11:56:08Z", "updated_at": "2020-03-01T16:55:54Z", "closed_at": "2020-03-01T16:55:54Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Bug report:**\r\n\r\n```\r\ntest/test_torch.py\r\n1114:                if not isinstance(p, collections.Iterable):\r\nhorovod/torch/__init__.py\r\n526:        if isinstance(x, collections.Iterable):\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1752/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1752/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1725", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1725/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1725/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1725/events", "html_url": "https://github.com/horovod/horovod/issues/1725", "id": 566376510, "node_id": "MDU6SXNzdWU1NjYzNzY1MTA=", "number": 1725, "title": "PID KeyError in broadcast_optimizer_state", "user": {"login": "kangp3", "id": 4926047, "node_id": "MDQ6VXNlcjQ5MjYwNDc=", "avatar_url": "https://avatars.githubusercontent.com/u/4926047?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kangp3", "html_url": "https://github.com/kangp3", "followers_url": "https://api.github.com/users/kangp3/followers", "following_url": "https://api.github.com/users/kangp3/following{/other_user}", "gists_url": "https://api.github.com/users/kangp3/gists{/gist_id}", "starred_url": "https://api.github.com/users/kangp3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kangp3/subscriptions", "organizations_url": "https://api.github.com/users/kangp3/orgs", "repos_url": "https://api.github.com/users/kangp3/repos", "events_url": "https://api.github.com/users/kangp3/events{/privacy}", "received_events_url": "https://api.github.com/users/kangp3/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-02-17T15:36:45Z", "updated_at": "2020-02-24T05:52:11Z", "closed_at": "2020-02-18T01:55:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: `torch==1.4.0`, `torchvision==0.5.0`\r\n3. Horovod version: `horovod==0.19.0`\r\n4. MPI version: Open MPI 4.0.0\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.2-1+cuda10.0\r\n7. Python version: 3.7.6\r\n8. OS and version: Ubuntu 18.04\r\n9. GCC version: 7.4.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nWhen calling `broadcast_optimizer_state` we're seeing KeyErrors when trying to access the `state_dict` for apparently nonexistent pids on all processes, example stack trace attached:\r\n```\r\nTraceback (most recent call last):\r\n  ...\r\n  File ************\r\n    HVD.broadcast_optimizer_state(optimizer, root_rank=0)\r\n  File \"/usr/local/lib/python3.7/dist-packages/horovod/torch/__init__.py\", line 572, in broadcast_optimizer_state\r\n    param_state = state_dict['state'][pid]\r\nKeyError: 140137585983888\r\n```\r\nThis is running on a single multi-GPU instance, and all processes are failing the same way (although with different pids). Any pointers appreciated, thanks!", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1725/reactions", "total_count": 3, "+1": 3, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1725/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1724", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1724/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1724/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1724/events", "html_url": "https://github.com/horovod/horovod/issues/1724", "id": 566373470, "node_id": "MDU6SXNzdWU1NjYzNzM0NzA=", "number": 1724, "title": "Horovod.run.run on multiple hosts kills jupyter notebook session", "user": {"login": "brandon-biggs", "id": 57197526, "node_id": "MDQ6VXNlcjU3MTk3NTI2", "avatar_url": "https://avatars.githubusercontent.com/u/57197526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brandon-biggs", "html_url": "https://github.com/brandon-biggs", "followers_url": "https://api.github.com/users/brandon-biggs/followers", "following_url": "https://api.github.com/users/brandon-biggs/following{/other_user}", "gists_url": "https://api.github.com/users/brandon-biggs/gists{/gist_id}", "starred_url": "https://api.github.com/users/brandon-biggs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brandon-biggs/subscriptions", "organizations_url": "https://api.github.com/users/brandon-biggs/orgs", "repos_url": "https://api.github.com/users/brandon-biggs/repos", "events_url": "https://api.github.com/users/brandon-biggs/events{/privacy}", "received_events_url": "https://api.github.com/users/brandon-biggs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 11, "created_at": "2020-02-17T15:31:24Z", "updated_at": "2020-03-25T18:03:46Z", "closed_at": "2020-03-25T18:03:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (**TensorFlow**, Keras, PyTorch, MXNet)\r\n2. Framework version: 2.0\r\n3. Horovod version: 0.19.0\r\n4. MPI version: \r\n```\r\nmpirun --version\r\nmpirun (Open MPI) 4.0.2\r\n```\r\n5. CUDA version: 10.2\r\n6. NCCL version: 2.5.6\r\n7. Python version: 2.7\r\n8. OS and version: Centos 7,7\r\n9. GCC version:\r\n```\r\n$ gcc --version\r\ngcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)\r\n```\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? No\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? Don't think it's about hang\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? Not about docker\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Couldn't find it\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nI have horovod.run.run working on 1 server with four GPUs finally after the issues I had in #1691. However, now when I try to run horovod.run.run on multiple servers with multiple GPUs, my Jupyter notebook runs for a few seconds and then crashes. The error message is:\r\n```\r\nThe kernel appears to have died. It will restart automatically.\r\n```\r\nHere's my first cell:\r\n```\r\nimport horovod\r\nimport horovod.run\r\nimport tensorflow as tf\r\nimport horovod.tensorflow as hvd\r\n\r\ndef test_main():\r\n    # Horovod: initialize Horovod.\r\n    hvd.init()\r\n    # Horovod: pin GPU to be used to process local rank (one GPU per process)\r\n    gpus = tf.config.experimental.list_physical_devices('GPU')\r\n    for gpu in gpus:\r\n        tf.config.experimental.set_memory_growth(gpu, True)\r\n    if gpus:\r\n        tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\r\n    print(f\"Hello world from {hvd.local_rank()}\")\r\n```\r\nThen I make my horovod.run.run call in my second cell:\r\n```\r\nhorovod.run.run(test_main, np=2, hosts=\"host1:4, host2:4\", verbose=True, disable_cache=True)\r\n```\r\nI do get a little output before it crashes:\r\n\r\n> Filtering local host names.\r\n> Remote host found: host1\r\n> Checking ssh on all remote hosts.\r\n> SSH was successful into all the remote hosts.\r\n> Testing interfaces on all the hosts.\r\n> Launched horovodrun server.\r\n> Attempted to launch horovod task servers.\r\n> Waiting for the hosts to acknowledge.\r\n> Notified all the hosts that the registration is complete.\r\n> Waiting for hosts to perform host-to-host interface checking.\r\n\r\nAfter this it immediately crashes. I figured there might be a brief wait, but there is not. Looking at the code, the crash appears to be occurring in [run.py)[https://github.com/horovod/horovod/blob/master/horovod/run/run.py#L252].\r\n\r\nI can run this script with just mpi and it works on host1:4 and host2:4 just fine, so I don't think it's that. If y'all have any ideas, let me know. \r\n\r\nI'd like to scale horovod.run.run up to a _few_ more than just these two nodes if possible. :)", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1724/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1724/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1690", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1690/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1690/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1690/events", "html_url": "https://github.com/horovod/horovod/issues/1690", "id": 555051567, "node_id": "MDU6SXNzdWU1NTUwNTE1Njc=", "number": 1690, "title": "horovodrun convenience script does not account for 'OpenRTE' in the output of mpirun --version", "user": {"login": "nskool", "id": 10671803, "node_id": "MDQ6VXNlcjEwNjcxODAz", "avatar_url": "https://avatars.githubusercontent.com/u/10671803?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nskool", "html_url": "https://github.com/nskool", "followers_url": "https://api.github.com/users/nskool/followers", "following_url": "https://api.github.com/users/nskool/following{/other_user}", "gists_url": "https://api.github.com/users/nskool/gists{/gist_id}", "starred_url": "https://api.github.com/users/nskool/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nskool/subscriptions", "organizations_url": "https://api.github.com/users/nskool/orgs", "repos_url": "https://api.github.com/users/nskool/repos", "events_url": "https://api.github.com/users/nskool/events{/privacy}", "received_events_url": "https://api.github.com/users/nskool/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-01-25T06:49:06Z", "updated_at": "2020-01-28T17:07:23Z", "closed_at": "2020-01-28T17:07:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, PyTorch)\r\n2. Framework version: 1.14.0\r\n3. Horovod version: 0.16.4\r\n4. MPI version: 3.1.4/4.0.1\r\n5. CUDA version: 10.1\r\n6. NCCL version: 2.4.8\r\n7. Python version: 3.6\r\n8. OS and version: Ubuntu, Docker\r\n9. GCC version:5.4.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\nYes, hasn't been specifically asked\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\n1. horovodrun outputs the following, when using with Open MPI 4.0.1.\r\n```\r\nhorovodrun -np 1 -H localhost:1 python pytorch_mnist.py\r\nOpen MPI not found in output of mpirun --version.\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/bin/horovodrun\", line 21, in <module>\r\n    run.run()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/run.py\", line 448, in run\r\n    'horovodrun convenience script currently only supports '\r\nException: horovodrun convenience script currently only supports Open MPI.\r\n\r\nChoose one of:\r\n1. Install Open MPI 4.0.0+ and re-install Horovod (use --no-cache-dir pip option).\r\n2. Run distributed training script using the standard way provided by your MPI distribution (usually mpirun, srun, or jsrun).\r\nroot@3da487b92c3d:/horovod/examples# mpirun --version\r\nmpirun.real (OpenRTE) 4.0.1\r\n\r\nReport bugs to http://www.open-mpi.org/community/help/\r\n```\r\n2. When Open MPI is installed as follows:\r\n```\r\nRUN wget https://www.open-mpi.org/software/ompi/v4.0/downloads/openmpi-$OPEN_MPI_VERSION.tar.gz \\\r\n && gunzip -c openmpi-$OPEN_MPI_VERSION.tar.gz | tar xf - \\\r\n && cd openmpi-$OPEN_MPI_VERSION \\\r\n && ./configure --prefix=/home/.openmpi \\\r\n && make all install \\\r\n && cd .. \\\r\n && rm openmpi-$OPEN_MPI_VERSION.tar.gz \\\r\n && rm -rf openmpi-$OPEN_MPI_VERSION\r\n```\r\n3. The horovodrun check expects 'OpenMPI' to be present in the output of `mpirun --version`. [[link](https://github.com/horovod/horovod/blob/master/horovod/run/mpi_run.py)]. However, when installed as above, OpenMPI has the following in output:\r\n```\r\nroot@3b5149353790:/horovod/examples# mpirun --version\r\nmpirun.real (OpenRTE) 4.0.1\r\n\r\nReport bugs to http://www.open-mpi.org/community/help/\r\n```\r\n4. Either openmpi was installed incorrectly (in which case, can horovod documentation clarify how to install it correctly?), or the horovodrun convenience script does not account for presence of 'OpenRTE' in the `mpirun --version`.\r\n\r\nI'm unable to understand when is 'OpenRTE' visible in mpirun --version, and it isn't? I saw the option --enable-orterun-prefix-by-default, but I'm not using it to build open-mpi.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1690/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1690/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1688", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1688/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1688/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1688/events", "html_url": "https://github.com/horovod/horovod/issues/1688", "id": 554949553, "node_id": "MDU6SXNzdWU1NTQ5NDk1NTM=", "number": 1688, "title": "TensorFlow master branch (tf-nightly) compatibility", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2020-01-24T20:55:03Z", "updated_at": "2020-03-10T16:30:18Z", "closed_at": "2020-03-10T16:30:18Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "See: https://github.com/tensorflow/tensorflow/issues/35138\r\n\r\nIn TensorFlow 2.1, `experimental_run_tf_function` was removed from `tf.keras.Model.compile` at this commit: c73c99c#diff-de9b96ac2d81503324cbbbe21732031fR1159\r\n\r\nIn Horovod, this flag / graph mode is necessary in order for `Optimizer.get_gradients()` to be called, which aggregates gradients across workers. Since this flag has been removed, distributed training in Horovod with tf.keras isn't working in the example scripts for TensorFlow 2.1.\r\n\r\n@abditag2 is currently investigating a workaround.  Note that we cannot perform the allreduce aggregation in apply_gradients due to interactions with gradient clipping and loss scaling (see horovod/horovod#1347).", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1688/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1688/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1681", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1681/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1681/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1681/events", "html_url": "https://github.com/horovod/horovod/issues/1681", "id": 553022177, "node_id": "MDU6SXNzdWU1NTMwMjIxNzc=", "number": 1681, "title": "Incompatible pickle cache support on Python 2.7", "user": {"login": "karan6181", "id": 12561286, "node_id": "MDQ6VXNlcjEyNTYxMjg2", "avatar_url": "https://avatars.githubusercontent.com/u/12561286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karan6181", "html_url": "https://github.com/karan6181", "followers_url": "https://api.github.com/users/karan6181/followers", "following_url": "https://api.github.com/users/karan6181/following{/other_user}", "gists_url": "https://api.github.com/users/karan6181/gists{/gist_id}", "starred_url": "https://api.github.com/users/karan6181/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karan6181/subscriptions", "organizations_url": "https://api.github.com/users/karan6181/orgs", "repos_url": "https://api.github.com/users/karan6181/repos", "events_url": "https://api.github.com/users/karan6181/events{/privacy}", "received_events_url": "https://api.github.com/users/karan6181/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-01-21T17:26:29Z", "updated_at": "2020-01-21T23:15:47Z", "closed_at": "2020-01-21T23:15:47Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: MXNet\r\n2. Framework version: 1.5.1\r\n3. Horovod version: 0.19.0\r\n4. MPI version: 3.1.0\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.8\r\n7. Python version: 2.7\r\n8. OS and version: Ubuntu 16.04\r\n9. GCC version: 5.4.0\r\n\r\nI was trying to install and run horovod with MXNet backend on a linux machine(EC2_GPU) with python 2.7. I was able to install horovod successfully but unable to run some example script(e.g. mxnet_mnist.py). I saw below error:\r\n\r\n```\r\nThere is an error with reading cache file. You can delete the corrupt file: /home/ubuntu/.horovod/cache.bin.\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/anaconda3/envs/mxnet_p27/bin/horovodrun\", line 21, in <module>\r\n    run_commandline()\r\n  File \"/home/ubuntu/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages/horovod/run/run.py\", line 867, in run_commandline\r\n    _run(args)\r\n  File \"/home/ubuntu/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages/horovod/run/run.py\", line 756, in _run\r\n    parameters_hash)\r\n  File \"/home/ubuntu/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages/horovod/run/util/cache.py\", line 45, in __init__\r\n    content = cloudpickle.load(cf)\r\n  File \"/home/ubuntu/anaconda3/envs/mxnet_p27/lib/python2.7/pickle.py\", line 1384, in load\r\n    return Unpickler(file).load()\r\n  File \"/home/ubuntu/anaconda3/envs/mxnet_p27/lib/python2.7/pickle.py\", line 864, in load\r\n    dispatch[key](self)\r\n  File \"/home/ubuntu/anaconda3/envs/mxnet_p27/lib/python2.7/pickle.py\", line 892, in load_proto\r\n    raise ValueError, \"unsupported pickle protocol: %d\" % proto\r\nValueError: unsupported pickle protocol: 4\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1681/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1681/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1680", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1680/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1680/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1680/events", "html_url": "https://github.com/horovod/horovod/issues/1680", "id": 552989803, "node_id": "MDU6SXNzdWU1NTI5ODk4MDM=", "number": 1680, "title": "Help running the examples provided", "user": {"login": "sonNeturo", "id": 45131840, "node_id": "MDQ6VXNlcjQ1MTMxODQw", "avatar_url": "https://avatars.githubusercontent.com/u/45131840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sonNeturo", "html_url": "https://github.com/sonNeturo", "followers_url": "https://api.github.com/users/sonNeturo/followers", "following_url": "https://api.github.com/users/sonNeturo/following{/other_user}", "gists_url": "https://api.github.com/users/sonNeturo/gists{/gist_id}", "starred_url": "https://api.github.com/users/sonNeturo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sonNeturo/subscriptions", "organizations_url": "https://api.github.com/users/sonNeturo/orgs", "repos_url": "https://api.github.com/users/sonNeturo/repos", "events_url": "https://api.github.com/users/sonNeturo/events{/privacy}", "received_events_url": "https://api.github.com/users/sonNeturo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-01-21T16:31:50Z", "updated_at": "2020-04-22T15:54:12Z", "closed_at": "2020-01-21T16:37:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: pytorch\r\n2. Framework version: 1.3.1\r\n3. Horovod version: 0.19.0\r\n4. MPI version: 4.0.1\r\n5. CUDA version: V10.0.130\r\n6. NCCL version: 2.3 I guess, since it's a google VM\r\n7. Python version: Python 3.6.10\r\n8. OS and version: Debian GNU/Linux 9 (stretch)\r\n9. GCC version: g++ (Debian 6.3.0-18+deb9u1)\r\n\r\nwhere running `python horovod/examples/pytorch_mnist.py`\r\n\r\nI get the following error message:\r\n\r\n```\r\n--------------------------------------------------------------------------\r\nIt looks like opal_init failed for some reason; your parallel process is\r\nlikely to abort.  There are many reasons that a parallel process can\r\nfail during opal_init; some of which are due to configuration or\r\nenvironment problems.  This failure appears to be an internal failure;\r\nhere's some additional information (which may only be relevant to an\r\nOpen MPI developer):\r\n\r\n  opal_shmem_base_select failed\r\n  --> Returned value -1 instead of OPAL_SUCCESS\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nIt looks like orte_init failed for some reason; your parallel process is\r\nlikely to abort.  There are many reasons that a parallel process can\r\nfail during orte_init; some of which are due to configuration or\r\nenvironment problems.  This failure appears to be an internal failure;\r\nhere's some additional information (which may only be relevant to an\r\nOpen MPI developer):\r\n\r\n  opal_init failed\r\n  --> Returned value Error (-1) instead of ORTE_SUCCESS\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nIt looks like MPI_INIT failed for some reason; your parallel process is\r\nlikely to abort.  There are many reasons that a parallel process can\r\nfail during MPI_INIT; some of which are due to configuration or environment\r\nproblems.  This failure appears to be an internal failure; here's some\r\nadditional information (which may only be relevant to an Open MPI\r\ndeveloper):\r\n\r\n  ompi_mpi_init: ompi_rte_init failed\r\n  --> Returned \"Error\" (-1) instead of \"Success\" (0)\r\n--------------------------------------------------------------------------\r\n*** An error occurred in MPI_Init_thread\r\n*** on a NULL communicator\r\n*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,\r\n***    and potentially your MPI job)\r\n[rapids-instance:08553] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!\r\n```\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1680/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1680/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1677", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1677/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1677/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1677/events", "html_url": "https://github.com/horovod/horovod/issues/1677", "id": 552453397, "node_id": "MDU6SXNzdWU1NTI0NTMzOTc=", "number": 1677, "title": "Horovodrun can't run when translating to mpirun because of '-H'", "user": {"login": "brandon-biggs", "id": 57197526, "node_id": "MDQ6VXNlcjU3MTk3NTI2", "avatar_url": "https://avatars.githubusercontent.com/u/57197526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brandon-biggs", "html_url": "https://github.com/brandon-biggs", "followers_url": "https://api.github.com/users/brandon-biggs/followers", "following_url": "https://api.github.com/users/brandon-biggs/following{/other_user}", "gists_url": "https://api.github.com/users/brandon-biggs/gists{/gist_id}", "starred_url": "https://api.github.com/users/brandon-biggs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brandon-biggs/subscriptions", "organizations_url": "https://api.github.com/users/brandon-biggs/orgs", "repos_url": "https://api.github.com/users/brandon-biggs/repos", "events_url": "https://api.github.com/users/brandon-biggs/events{/privacy}", "received_events_url": "https://api.github.com/users/brandon-biggs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2020-01-20T18:32:12Z", "updated_at": "2020-01-28T19:01:16Z", "closed_at": "2020-01-28T19:01:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (**TensorFlow**)\r\n2. Framework version: 2.0 GPU\r\n3. Horovod version: 0.19.0\r\n4. MPI version: 1.10.7\r\n5. CUDA version: 10.2\r\n6. NCCL version: 2.5.6\r\n7. Python version: 3.7\r\n8. OS and version: Centos 7.7\r\n9. GCC version: 4.8.5\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? I looked for it, couldn't find it.\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? Not about hang\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? Not about docker\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Not in the guide\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nWhen running `horovodrun` from the terminal, you can pass a hostfile with, `-hostfile/--hostfile`. If you use `--verbose`, you can see the equivalent Open MPI command. I noticed that horovodrun converts the `--hostfile` to -H for hosts. This isn't an exact conversion from `horovodrun` to `mpirun`, and for some reason is causing issues in my environment.\r\n\r\nI installed openmpi with yum. There's some kind of weird bug that I haven't fully figured out yet where specifying just the host with -H causes the `ORTE was unable to reliably start one or more daemons.` error, but `--hostfile` does not cause this issue. However, because `horovodrun` translates both `--hostfiles` and `-H` to `mpirun -H, horovodrun` will not work. Because I installed openmpi from yum and didn't make any changes, I thought this may be an important bug to note for others who may also run into this issue. \r\n\r\nExample from the [documentation](https://horovod.readthedocs.io/en/latest/mpirun.html): \r\n`horovodrun -np 16 -H server1:4,server2:4,server3:4,server4:4 python train.py`\r\nEquivalent:\r\n```\r\nmpirun -np 16 \\\r\n    -H server1:4,server2:4,server3:4,server4:4 \\\r\n    -bind-to none -map-by slot \\\r\n    -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH \\\r\n    -mca pml ob1 -mca btl ^openib \\\r\n    python train.py\r\n```\r\nHowever,\r\n`horovodrun -np 16 --hostfile hostfile python train.py`\r\nis not equivalent to:\r\n```\r\nmpirun -np 16 \\\r\n    --hostfile hostfile \\\r\n    -bind-to none -map-by slot \\\r\n    -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH \\\r\n    -mca pml ob1 -mca btl ^openib \\\r\n    python train.py\r\n```\r\nbut is equivalent to the original, which in my case, causes problems, not sure why. \r\n```\r\nmpirun -np 16 \\\r\n    -H server1:4,server2:4,server3:4,server4:4 \\\r\n    -bind-to none -map-by slot \\\r\n    -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH \\\r\n    -mca pml ob1 -mca btl ^openib \\\r\n    python train.py\r\n```\r\n\r\nI'm recompiling mpi. Hopefully that will resolve my issues, but I wanted to bring this to everyone's attention. Let me know if there are any questions about this report. This may definitely be by design, or maybe there's an easy workaround that I'm just not aware of. ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1677/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1677/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1669", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1669/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1669/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1669/events", "html_url": "https://github.com/horovod/horovod/issues/1669", "id": 549822337, "node_id": "MDU6SXNzdWU1NDk4MjIzMzc=", "number": 1669, "title": "mxnet allgather is borken. it crashed when using GPU and produces wrong results when using CPU", "user": {"login": "ahmadki", "id": 8809320, "node_id": "MDQ6VXNlcjg4MDkzMjA=", "avatar_url": "https://avatars.githubusercontent.com/u/8809320?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ahmadki", "html_url": "https://github.com/ahmadki", "followers_url": "https://api.github.com/users/ahmadki/followers", "following_url": "https://api.github.com/users/ahmadki/following{/other_user}", "gists_url": "https://api.github.com/users/ahmadki/gists{/gist_id}", "starred_url": "https://api.github.com/users/ahmadki/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ahmadki/subscriptions", "organizations_url": "https://api.github.com/users/ahmadki/orgs", "repos_url": "https://api.github.com/users/ahmadki/repos", "events_url": "https://api.github.com/users/ahmadki/events{/privacy}", "received_events_url": "https://api.github.com/users/ahmadki/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "apeforest", "id": 6807113, "node_id": "MDQ6VXNlcjY4MDcxMTM=", "avatar_url": "https://avatars.githubusercontent.com/u/6807113?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apeforest", "html_url": "https://github.com/apeforest", "followers_url": "https://api.github.com/users/apeforest/followers", "following_url": "https://api.github.com/users/apeforest/following{/other_user}", "gists_url": "https://api.github.com/users/apeforest/gists{/gist_id}", "starred_url": "https://api.github.com/users/apeforest/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apeforest/subscriptions", "organizations_url": "https://api.github.com/users/apeforest/orgs", "repos_url": "https://api.github.com/users/apeforest/repos", "events_url": "https://api.github.com/users/apeforest/events{/privacy}", "received_events_url": "https://api.github.com/users/apeforest/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "apeforest", "id": 6807113, "node_id": "MDQ6VXNlcjY4MDcxMTM=", "avatar_url": "https://avatars.githubusercontent.com/u/6807113?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apeforest", "html_url": "https://github.com/apeforest", "followers_url": "https://api.github.com/users/apeforest/followers", "following_url": "https://api.github.com/users/apeforest/following{/other_user}", "gists_url": "https://api.github.com/users/apeforest/gists{/gist_id}", "starred_url": "https://api.github.com/users/apeforest/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apeforest/subscriptions", "organizations_url": "https://api.github.com/users/apeforest/orgs", "repos_url": "https://api.github.com/users/apeforest/repos", "events_url": "https://api.github.com/users/apeforest/events{/privacy}", "received_events_url": "https://api.github.com/users/apeforest/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2020-01-14T21:15:07Z", "updated_at": "2020-07-13T18:30:00Z", "closed_at": "2020-07-13T18:30:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: MXNet\r\n2. Framework version: 1.5.1\r\n3. Horovod version: built from source\r\n4. MPI version: 3.1.1\r\n5. CUDA version: 10.2\r\n6. NCCL version: 2.5.6\r\n7. Python version: 3.6.9\r\n8. OS and version: Linux Ubuntu 18.04.3\r\n9. GCC version: 7.4.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? Yes\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nFollowing PR #1639, `allgather()` in mxnet is still borken. It produces incorrect results when using CPU and crashes when using GPUs\r\n\r\n\r\nI installed horovod from source:\r\n```bash\r\ngit clone --recurse-submodules -j8 https://github.com/horovod/horovod.git\r\ncd horovod\r\nexport HOROVOD_GPU_ALLREDUCE=NCCL\r\nexport HOROVOD_NCCL_INCLUDE=/usr/include\r\nexport HOROVOD_NCCL_LIB=/usr/lib/x86_64-linux-gnu\r\nexport HOROVOD_NCCL_LINK=SHARED\r\nexport HOROVOD_WITHOUT_PYTORCH=1\r\nexport HOROVOD_WITHOUT_TENSORFLOW=1\r\nexport HOROVOD_WITH_MXNET=1\r\nexport HOROVOD_WITH_MPI=1\r\nln -s /usr/local/cuda/lib64/stubs/libcuda.so ./libcuda.so.1\r\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$PWD\r\npython setup.py install\r\n```\r\n\r\nThen ran the following sample code:\r\n\r\n```python\r\n# CUDA_VISIBLE_DEVICES=0,1 mpiexec -n 2 --allow-run-as-root python all_gather_bug.py\r\nimport mxnet as mx\r\nfrom mxnet import ndarray\r\nimport horovod.mxnet as hvd\r\nfrom mpi4py import MPI\r\n\r\nuse_gpu = False\r\nuse_mpi4py = False\r\n\r\nif use_mpi4py:\r\n    comm = MPI.COMM_WORLD\r\n    hvd.init(comm=comm)\r\n    local_rank = comm.Get_rank()\r\nelse:\r\n    hvd.init()\r\n    local_rank = hvd.local_rank()\r\n\r\nctx = mx.gpu(local_rank) if use_gpu else mx.cpu(local_rank)\r\nmx.random.seed(local_rank)\r\n\r\na = ndarray.random.uniform(shape=[10, 100, 100], ctx=ctx)\r\nprint(\"(before) a.shape = {}\".format(a.shape))\r\nprint(\"(before) a[0]={}\".format(a[0]))\r\n\r\na = hvd.allgather(a)\r\nprint(\"(after) a.shape = {}\".format(a.shape))\r\nprint(\"(after) a[0]={}\".format(a[0]))\r\n\r\nmx.nd.waitall()\r\nhvd.shutdown()\r\n```\r\n\r\n\r\n\r\nWhen using CPU, it looks like rank 0 is overwritting other ranks (ie broadcast instead of allgather):\r\n```\r\n(before) a.shape = (10, 100, 100)\r\n(before) a.shape = (10, 100, 100)\r\n(before) a[0]=\r\n[[5.4881352e-01 5.9284461e-01 7.1518934e-01 ... 6.0783064e-01\r\n  4.1702199e-01 9.9718481e-01]\r\n [7.2032452e-01 9.3255734e-01 1.1438108e-04 ... 1.8508208e-01\r\n  2.5926229e-02 9.3154085e-01]\r\n [5.4966247e-01 9.4773060e-01 4.3532240e-01 ... 8.3994907e-01\r\n  2.9090473e-01 1.2132858e-01]\r\n ...\r\n [2.0300540e-01 3.4745708e-01 6.7227858e-01 ... 9.6727759e-01\r\n  4.6623814e-01 1.4771296e-01]\r\n [5.4340494e-01 6.7115563e-01 2.7836940e-01 ... 1.1400783e-02\r\n  5.1639861e-01 5.5254018e-01]\r\n [5.7066756e-01 9.5268434e-01 2.8474227e-02 ... 3.9755744e-01\r\n  6.7598689e-01 4.6260124e-01]]\r\n<NDArray 100x100 @cpu(0)>\r\n(after) a.shape = (10, 100, 100)\r\n(before) a[0]=\r\n[[0.52383333 0.05501367 0.03996297 ... 0.57466674 0.86663705 0.89201903]\r\n [0.26314485 0.8478666  0.13140848 ... 0.47916418 0.26825976 0.62353116]\r\n [0.60529524 0.56331843 0.08485638 ... 0.32175666 0.5547923  0.8856785 ]\r\n ...\r\n [0.8128833  0.50981677 0.89495724 ... 0.37793323 0.36698005 0.35633445]\r\n [0.12747145 0.10071229 0.580568   ... 0.38354123 0.4238108  0.21727636]\r\n [0.54174274 0.33404106 0.6885549  ... 0.9920475  0.7385572  0.32574102]]\r\n<NDArray 100x100 @cpu(1)>\r\n(after) a.shape = (10, 100, 100)\r\n(after) a[0]=\r\n[[5.4881352e-01 5.9284461e-01 7.1518934e-01 ... 6.0783064e-01\r\n  4.1702199e-01 9.9718481e-01]\r\n [7.2032452e-01 9.3255734e-01 1.1438108e-04 ... 1.8508208e-01\r\n  2.5926229e-02 9.3154085e-01]\r\n [5.4966247e-01 9.4773060e-01 4.3532240e-01 ... 8.3994907e-01\r\n  2.9090473e-01 1.2132858e-01]\r\n ...\r\n [2.0300540e-01 3.4745708e-01 6.7227858e-01 ... 9.6727759e-01\r\n  4.6623814e-01 1.4771296e-01]\r\n [5.4340494e-01 6.7115563e-01 2.7836940e-01 ... 1.1400783e-02\r\n  5.1639861e-01 5.5254018e-01]\r\n [5.7066756e-01 9.5268434e-01 2.8474227e-02 ... 3.9755744e-01\r\n  6.7598689e-01 4.6260124e-01]]\r\n<NDArray 100x100 @cpu(0)>\r\n(after) a[0]=\r\n[[5.4881352e-01 5.9284461e-01 7.1518934e-01 ... 6.0783064e-01\r\n  4.1702199e-01 9.9718481e-01]\r\n [7.2032452e-01 9.3255734e-01 1.1438108e-04 ... 1.8508208e-01\r\n  2.5926229e-02 9.3154085e-01]\r\n [5.4966247e-01 9.4773060e-01 4.3532240e-01 ... 8.3994907e-01\r\n  2.9090473e-01 1.2132858e-01]\r\n ...\r\n [2.0300540e-01 3.4745708e-01 6.7227858e-01 ... 9.6727759e-01\r\n  4.6623814e-01 1.4771296e-01]\r\n [5.4340494e-01 6.7115563e-01 2.7836940e-01 ... 1.1400783e-02\r\n  5.1639861e-01 5.5254018e-01]\r\n [5.7066756e-01 9.5268434e-01 2.8474227e-02 ... 3.9755744e-01\r\n  6.7598689e-01 4.6260124e-01]]\r\n<NDArray 100x100 @cpu(1)>\r\n```\r\n\r\n\r\nWhen using GPUs the operation fails:\r\n```\r\n(before) a.shape = (10, 100, 100)\r\n(before) a[0]=\r\n[[0.6686509  0.17409194 0.3850025  ... 0.43011498 0.0661214  0.2502998 ]\r\n [0.7005292  0.19000232 0.6673837  ... 0.27718288 0.16084558 0.223108  ]\r\n [0.96042585 0.81086403 0.54152083 ... 0.5650488  0.5196334  0.6767488 ]\r\n ...\r\n [0.96879214 0.9387428  0.04036242 ... 0.13176239 0.3436321  0.47154343]\r\n [0.8069018  0.91234195 0.01141495 ... 0.35816687 0.57390726 0.68393874]\r\n [0.72049534 0.67948174 0.44702923 ... 0.87448525 0.63809574 0.7006303 ]]\r\n<NDArray 100x100 @gpu(0)>\r\n(after) a.shape = (10, 100, 100)\r\n(before) a.shape = (10, 100, 100)\r\n(before) a[0]=\r\n[[0.7685592  0.10232276 0.8685353  ... 0.93769354 0.62144864 0.21535844]\r\n [0.85973674 0.3420865  0.6202223  ... 0.5464046  0.41442537 0.32170743]\r\n [0.11786121 0.23281038 0.95843846 ... 0.17739207 0.5901362  0.28355032]\r\n ...\r\n [0.70749086 0.61171615 0.37854642 ... 0.3485002  0.29636437 0.7359518 ]\r\n [0.4345038  0.90834665 0.5242443  ... 0.0793817  0.40161872 0.6579807 ]\r\n [0.8531954  0.18177992 0.7053579  ... 0.5257004  0.24457276 0.74836564]]\r\n<NDArray 100x100 @gpu(1)>\r\n(after) a.shape = (10, 100, 100)\r\nTraceback (most recent call last):\r\n  File \"all_gather_bug.py\", line 29, in <module>\r\n    print(\"(after) a[0]={}\".format(a[0]))\r\n  File \"/opt/mxnet/python/mxnet/ndarray/ndarray.py\", line 194, in __repr__\r\n    return '\\n%s\\n<%s %s @%s>' % (str(self.asnumpy()),\r\n  File \"/opt/mxnet/python/mxnet/ndarray/ndarray.py\", line 1996, in asnumpy\r\n    ctypes.c_size_t(data.size)))\r\n  File \"/opt/mxnet/python/mxnet/base.py\", line 252, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: MPI_Allgatherv failed, see MPI output for details.\r\nTraceback (most recent call last):\r\n  File \"all_gather_bug.py\", line 29, in <module>\r\n    print(\"(after) a[0]={}\".format(a[0]))\r\n  File \"/opt/mxnet/python/mxnet/ndarray/ndarray.py\", line 194, in __repr__\r\n    return '\\n%s\\n<%s %s @%s>' % (str(self.asnumpy()),\r\n  File \"/opt/mxnet/python/mxnet/ndarray/ndarray.py\", line 1996, in asnumpy\r\n    ctypes.c_size_t(data.size)))\r\n  File \"/opt/mxnet/python/mxnet/base.py\", line 252, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: MPI_Allgatherv failed, see MPI output for details.\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpiexec detected that one or more processes exited with non-zero status, thus causing\r\nthe job to be terminated. The first process to do so was:\r\n\r\n  Process name: [[59002,1],1]\r\n  Exit code:    1\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1669/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1669/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1660", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1660/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1660/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1660/events", "html_url": "https://github.com/horovod/horovod/issues/1660", "id": 548591035, "node_id": "MDU6SXNzdWU1NDg1OTEwMzU=", "number": 1660, "title": "Failed to run in-stock example with TensorFlow 1.15 and Horovod 0.18.2", "user": {"login": "byronyi", "id": 2613663, "node_id": "MDQ6VXNlcjI2MTM2NjM=", "avatar_url": "https://avatars.githubusercontent.com/u/2613663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byronyi", "html_url": "https://github.com/byronyi", "followers_url": "https://api.github.com/users/byronyi/followers", "following_url": "https://api.github.com/users/byronyi/following{/other_user}", "gists_url": "https://api.github.com/users/byronyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/byronyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byronyi/subscriptions", "organizations_url": "https://api.github.com/users/byronyi/orgs", "repos_url": "https://api.github.com/users/byronyi/repos", "events_url": "https://api.github.com/users/byronyi/events{/privacy}", "received_events_url": "https://api.github.com/users/byronyi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-01-12T16:10:31Z", "updated_at": "2020-01-13T10:24:15Z", "closed_at": "2020-01-13T10:24:15Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow \r\n2. Framework version: 1.15.0\r\n3. Horovod version: 0.18.2\r\n4. MPI version: 2.1.1\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 2.7\r\n8. OS and version: Ubuntu 18.04\r\n9. GCC version: 7.4.0\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nUse the following Dockerfile:\r\n\r\n```Dockerfile\r\nFROM ubuntu:18.04\r\n\r\nRUN apt-get update && \\\r\n    apt-get install -yq --no-install-recommends \\\r\n        build-essential \\\r\n        libopenmpi-dev \\\r\n        libpython-dev \\\r\n        openmpi-bin \\\r\n        openssh-client \\\r\n        openssh-server \\\r\n        python-pip \\\r\n        python-setuptools \\\r\n        && \\\r\n    rm -rf /var/lib/apt/lists/*\r\n\r\nRUN pip install --no-cache-dir -U pip setuptools\r\n\r\nRUN pip install --no-cache-dir tensorflow==1.15.0\r\n\r\nRUN pip install --no-cache-dir horovod==0.18.2\r\n\r\nADD https://raw.githubusercontent.com/horovod/horovod/v0.18.2/examples/tensorflow_keras_mnist.py /tensorflow_keras_mnist.py\r\n\r\nENV LD_PRELOAD \"/usr/lib/x86_64-linux-gnu/libhwloc.so\"\r\n\r\nCMD [\"python\", \"/tensorflow_keras_mnist.py\"]\r\n```\r\n\r\nAfter build, run it and it crashes immediately:\r\n\r\n```\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\r\n\r\nWARNING:tensorflow:From /tensorflow_keras_mnist.py:19: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\r\n\r\nWARNING:tensorflow:From /tensorflow_keras_mnist.py:22: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\r\n\r\nWARNING:tensorflow:From /tensorflow_keras_mnist.py:22: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\r\n\r\n2020-01-12 16:09:18.410913: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-01-12 16:09:18.419296: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\r\n2020-01-12 16:09:18.420862: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560439498890 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-01-12 16:09:18.420888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-01-12 16:09:18.422478: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-01-12 16:09:18.422508: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-01-12 16:09:18.422535: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\r\n2020-01-12 16:09:18.422555: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Not found: no CUDA devices found\r\n[c563eba00ab0:00001] *** Process received signal ***\r\n[c563eba00ab0:00001] Signal: Aborted (6)\r\n[c563eba00ab0:00001] Signal code:  (-6)\r\n[c563eba00ab0:00001] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x3ef20)[0x7f3a08a61f20]\r\n[c563eba00ab0:00001] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xc7)[0x7f3a08a61e97]\r\n[c563eba00ab0:00001] [ 2] /lib/x86_64-linux-gnu/libc.so.6(abort+0x141)[0x7f3a08a63801]\r\n[c563eba00ab0:00001] [ 3] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(+0xadf9c74)[0x7f39b3e79c74]\r\n[c563eba00ab0:00001] [ 4] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN15stream_executor4port17internal_statusor6Helper5CrashERKN10tensorflow6StatusE+0x4e)[0x7f39b3d7de9e]\r\n[c563eba00ab0:00001] [ 5] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZNK10tensorflow9XlaDevice6clientEv+0xdd)[0x7f39af124e5d]\r\n[c563eba00ab0:00001] [ 6] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow9XlaDevice22GetDeviceContextLockedEv+0x43)[0x7f39af125933]\r\n[c563eba00ab0:00001] [ 7] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow9XlaDevice16UseGpuDeviceInfoEv+0x37)[0x7f39af126687]\r\n[c563eba00ab0:00001] [ 8] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow19XlaGpuDeviceFactory13CreateDevicesERKNS_14SessionOptionsERKSsPSt6vectorISt10unique_ptrINS_6DeviceESt14default_deleteIS8_EESaISB_EE+0x65c)[0x7f39af110afc]\r\n[c563eba00ab0:00001] [ 9] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.1(_ZN10tensorflow13DeviceFactory10AddDevicesERKNS_14SessionOptionsERKSsPSt6vectorISt10unique_ptrINS_6DeviceESt14default_deleteIS8_EESaISB_EE+0xed)[0x7f39a82dd29d]\r\n[c563eba00ab0:00001] [10] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow20DirectSessionFactory10NewSessionERKNS_14SessionOptionsEPPNS_7SessionE+0x32b)[0x7f39ae5c93fb]\r\n[c563eba00ab0:00001] [11] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.1(_ZN10tensorflow10NewSessionERKNS_14SessionOptionsEPPNS_7SessionE+0xb0)[0x7f39a835e300]\r\n[c563eba00ab0:00001] [12] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(TF_NewSession+0x24)[0x7f39aba365d4]\r\n[c563eba00ab0:00001] [13] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow16TF_NewSessionRefEP8TF_GraphPK17TF_SessionOptionsP9TF_Status+0x12)[0x7f39ab3950c2]\r\n[c563eba00ab0:00001] [14] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(+0x22a9f81)[0x7f39ab329f81]\r\n[c563eba00ab0:00001] [15] python(PyEval_EvalFrameEx+0x56a)[0x5604359a7e6a]\r\n[c563eba00ab0:00001] [16] python(PyEval_EvalCodeEx+0x6da)[0x5604359a561a]\r\n[c563eba00ab0:00001] [17] python(PyEval_EvalFrameEx+0x56fe)[0x5604359acffe]\r\n[c563eba00ab0:00001] [18] python(PyEval_EvalCodeEx+0x6da)[0x5604359a561a]\r\n[c563eba00ab0:00001] [19] python(+0x10e7cc)[0x5604359c17cc]\r\n[c563eba00ab0:00001] [20] python(+0x126f8e)[0x5604359d9f8e]\r\n[c563eba00ab0:00001] [21] python(+0x126b3a)[0x5604359d9b3a]\r\n[c563eba00ab0:00001] [22] python(+0xe30ab)[0x5604359960ab]\r\n[c563eba00ab0:00001] [23] python(PyEval_EvalFrameEx+0x5500)[0x5604359ace00]\r\n[c563eba00ab0:00001] [24] python(PyEval_EvalCodeEx+0x6da)[0x5604359a561a]\r\n[c563eba00ab0:00001] [25] python(PyEval_EvalCode+0x19)[0x5604359a4f39]\r\n[c563eba00ab0:00001] [26] python(+0x12304f)[0x5604359d604f]\r\n[c563eba00ab0:00001] [27] python(PyRun_FileExFlags+0x82)[0x5604359d1292]\r\n[c563eba00ab0:00001] [28] python(PyRun_SimpleFileExFlags+0x18d)[0x5604359d0cbd]\r\n[c563eba00ab0:00001] [29] python(Py_Main+0x616)[0x56043597f3e6]\r\n[c563eba00ab0:00001] *** End of error message ***\r\n[c563eba00ab0:00001] *** Process received signal ***\r\n[c563eba00ab0:00001] Signal: Segmentation fault (11)\r\n[c563eba00ab0:00001] Signal code:  (128)\r\n[c563eba00ab0:00001] Failing at address: (nil)\r\n[c563eba00ab0:00001] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x3ef20)[0x7f3a08a61f20]\r\n[c563eba00ab0:00001] [ 1] /lib/x86_64-linux-gnu/libc.so.6(abort+0x230)[0x7f3a08a638f0]\r\n[c563eba00ab0:00001] [ 2] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(+0xadf9c74)[0x7f39b3e79c74]\r\n[c563eba00ab0:00001] [ 3] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN15stream_executor4port17internal_statusor6Helper5CrashERKN10tensorflow6StatusE+0x4e)[0x7f39b3d7de9e]\r\n[c563eba00ab0:00001] [ 4] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZNK10tensorflow9XlaDevice6clientEv+0xdd)[0x7f39af124e5d]\r\n[c563eba00ab0:00001] [ 5] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow9XlaDevice22GetDeviceContextLockedEv+0x43)[0x7f39af125933]\r\n[c563eba00ab0:00001] [ 6] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow9XlaDevice16UseGpuDeviceInfoEv+0x37)[0x7f39af126687]\r\n[c563eba00ab0:00001] [ 7] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow19XlaGpuDeviceFactory13CreateDevicesERKNS_14SessionOptionsERKSsPSt6vectorISt10unique_ptrINS_6DeviceESt14default_deleteIS8_EESaISB_EE+0x65c)[0x7f39af110afc]\r\n[c563eba00ab0:00001] [ 8] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.1(_ZN10tensorflow13DeviceFactory10AddDevicesERKNS_14SessionOptionsERKSsPSt6vectorISt10unique_ptrINS_6DeviceESt14default_deleteIS8_EESaISB_EE+0xed)[0x7f39a82dd29d]\r\n[c563eba00ab0:00001] [ 9] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow20DirectSessionFactory10NewSessionERKNS_14SessionOptionsEPPNS_7SessionE+0x32b)[0x7f39ae5c93fb]\r\n[c563eba00ab0:00001] [10] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.1(_ZN10tensorflow10NewSessionERKNS_14SessionOptionsEPPNS_7SessionE+0xb0)[0x7f39a835e300]\r\n[c563eba00ab0:00001] [11] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(TF_NewSession+0x24)[0x7f39aba365d4]\r\n[c563eba00ab0:00001] [12] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow16TF_NewSessionRefEP8TF_GraphPK17TF_SessionOptionsP9TF_Status+0x12)[0x7f39ab3950c2]\r\n[c563eba00ab0:00001] [13] /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(+0x22a9f81)[0x7f39ab329f81]\r\n[c563eba00ab0:00001] [14] python(PyEval_EvalFrameEx+0x56a)[0x5604359a7e6a]\r\n[c563eba00ab0:00001] [15] python(PyEval_EvalCodeEx+0x6da)[0x5604359a561a]\r\n[c563eba00ab0:00001] [16] python(PyEval_EvalFrameEx+0x56fe)[0x5604359acffe]\r\n[c563eba00ab0:00001] [17] python(PyEval_EvalCodeEx+0x6da)[0x5604359a561a]\r\n[c563eba00ab0:00001] [18] python(+0x10e7cc)[0x5604359c17cc]\r\n[c563eba00ab0:00001] [19] python(+0x126f8e)[0x5604359d9f8e]\r\n[c563eba00ab0:00001] [20] python(+0x126b3a)[0x5604359d9b3a]\r\n[c563eba00ab0:00001] [21] python(+0xe30ab)[0x5604359960ab]\r\n[c563eba00ab0:00001] [22] python(PyEval_EvalFrameEx+0x5500)[0x5604359ace00]\r\n[c563eba00ab0:00001] [23] python(PyEval_EvalCodeEx+0x6da)[0x5604359a561a]\r\n[c563eba00ab0:00001] [24] python(PyEval_EvalCode+0x19)[0x5604359a4f39]\r\n[c563eba00ab0:00001] [25] python(+0x12304f)[0x5604359d604f]\r\n[c563eba00ab0:00001] [26] python(PyRun_FileExFlags+0x82)[0x5604359d1292]\r\n[c563eba00ab0:00001] [27] python(PyRun_SimpleFileExFlags+0x18d)[0x5604359d0cbd]\r\n[c563eba00ab0:00001] [28] python(Py_Main+0x616)[0x56043597f3e6]\r\n[c563eba00ab0:00001] [29] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xe7)[0x7f3a08a44b97]\r\n[c563eba00ab0:00001] *** End of error message ***\r\n```\r\n\r\nPing @alsrgv; I suspect it is because that TF >= 1.15 uses devtoolset (gcc-7.3 frontend with gcc-4.4 backend) and results in ABI mismatch.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1660/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1660/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1622", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1622/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1622/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1622/events", "html_url": "https://github.com/horovod/horovod/issues/1622", "id": 543325542, "node_id": "MDU6SXNzdWU1NDMzMjU1NDI=", "number": 1622, "title": "Keras shape error when utilising multiple devices ", "user": {"login": "jon-chuang", "id": 9093549, "node_id": "MDQ6VXNlcjkwOTM1NDk=", "avatar_url": "https://avatars.githubusercontent.com/u/9093549?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jon-chuang", "html_url": "https://github.com/jon-chuang", "followers_url": "https://api.github.com/users/jon-chuang/followers", "following_url": "https://api.github.com/users/jon-chuang/following{/other_user}", "gists_url": "https://api.github.com/users/jon-chuang/gists{/gist_id}", "starred_url": "https://api.github.com/users/jon-chuang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jon-chuang/subscriptions", "organizations_url": "https://api.github.com/users/jon-chuang/orgs", "repos_url": "https://api.github.com/users/jon-chuang/repos", "events_url": "https://api.github.com/users/jon-chuang/events{/privacy}", "received_events_url": "https://api.github.com/users/jon-chuang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-29T06:23:59Z", "updated_at": "2019-12-29T07:00:23Z", "closed_at": "2019-12-29T07:00:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Keras\r\n2. Framework version: 2.2.5\r\n3. Horovod version: 0.18.2\r\n4. MPI version: 3.1.4\r\n5. CUDA version: 10.1\r\n6. NCCL version:\r\n7. Python version: 3.6\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Bug report:**\r\nWhen running Horovod with multiple devices with the Yolov3 model, I get the error `expected input_2 to have shape (15, 20, 3, 54) but got array with shape (3, 4, 3, 54)` on all processes except the main process (rank 0). When running horovod on a single device, I am able to train the model.\r\n\r\nAdditional details: I am running using `mpirun` using singularity containers as is documented here (https://devblogs.nvidia.com/how-to-run-ngc-deep-learning-containers-with-singularity/)\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1622/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1622/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1616", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1616/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1616/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1616/events", "html_url": "https://github.com/horovod/horovod/issues/1616", "id": 542551549, "node_id": "MDU6SXNzdWU1NDI1NTE1NDk=", "number": 1616, "title": "Horovodrun stops unexpectedly without any notifications", "user": {"login": "hoangcuong2011", "id": 8759715, "node_id": "MDQ6VXNlcjg3NTk3MTU=", "avatar_url": "https://avatars.githubusercontent.com/u/8759715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hoangcuong2011", "html_url": "https://github.com/hoangcuong2011", "followers_url": "https://api.github.com/users/hoangcuong2011/followers", "following_url": "https://api.github.com/users/hoangcuong2011/following{/other_user}", "gists_url": "https://api.github.com/users/hoangcuong2011/gists{/gist_id}", "starred_url": "https://api.github.com/users/hoangcuong2011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hoangcuong2011/subscriptions", "organizations_url": "https://api.github.com/users/hoangcuong2011/orgs", "repos_url": "https://api.github.com/users/hoangcuong2011/repos", "events_url": "https://api.github.com/users/hoangcuong2011/events{/privacy}", "received_events_url": "https://api.github.com/users/hoangcuong2011/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-12-26T13:07:12Z", "updated_at": "2020-02-21T10:58:58Z", "closed_at": "2020-02-21T10:58:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) TensorFlow Keras\r\n2. Framework version:  1.15.0\r\n3. Horovod version: 0.18.2\r\n4. MPI version: openmpi-4.0.2\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.5.6\r\n7. Python version: 3.6\r\n8. OS and version: Ubuntu\r\n9. GCC version: 5.4.0\r\n\r\nI run my abc python file as:\r\n`horovodrun -np 4 -H localhost:4 python abc.py`\r\n\r\nJust in case: my model is a seq2seq model. It has a large amount of parameters (80Million). The batch size for training the model is 50.\r\n\r\nI runs successfully, but then exists for no reason sometimes later (iterations 240 of 2667 from the third epoch) (see picture - the program just exists)\r\n\r\n![image](https://user-images.githubusercontent.com/8759715/71476995-46c81580-281a-11ea-9ddd-14c535fe2d20.png)\r\n\r\nI would also highlight that there is no warning, error. It just stops without any thing. \r\nAlso I run the code another time and got similar result. The only difference is that it stops somewhere in epoch 2, not epoch 3 as the above.\r\n\r\nSo I wonder whether it is a bug? Did you ever observe this before?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1616/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1616/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1608", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1608/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1608/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1608/events", "html_url": "https://github.com/horovod/horovod/issues/1608", "id": 541898154, "node_id": "MDU6SXNzdWU1NDE4OTgxNTQ=", "number": 1608, "title": "RuntimeError: For integral input tensors, argument alpha must not be a floating point number", "user": {"login": "una-dinosauria", "id": 3733964, "node_id": "MDQ6VXNlcjM3MzM5NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/3733964?v=4", "gravatar_id": "", "url": "https://api.github.com/users/una-dinosauria", "html_url": "https://github.com/una-dinosauria", "followers_url": "https://api.github.com/users/una-dinosauria/followers", "following_url": "https://api.github.com/users/una-dinosauria/following{/other_user}", "gists_url": "https://api.github.com/users/una-dinosauria/gists{/gist_id}", "starred_url": "https://api.github.com/users/una-dinosauria/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/una-dinosauria/subscriptions", "organizations_url": "https://api.github.com/users/una-dinosauria/orgs", "repos_url": "https://api.github.com/users/una-dinosauria/repos", "events_url": "https://api.github.com/users/una-dinosauria/events{/privacy}", "received_events_url": "https://api.github.com/users/una-dinosauria/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-12-23T20:45:44Z", "updated_at": "2020-01-09T21:03:49Z", "closed_at": "2020-01-09T21:03:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): Pytorch\r\n2. Framework version: 1.3.0\r\n3. Horovod version: 0.16.1\r\n4. MPI version: 3.1.2 (?)\r\n5. CUDA version: 10.2\r\n6. NCCL version: ? (probably not important)\r\n7. Python version: 2.7\r\n8. OS and version: Ubuntu 14.04.4 (probably not important)\r\n9. GCC version: 4.8.4 (probably not important)\r\n\r\n**Bug report:**\r\nHorovod does not like it when my module has integer parameters, even if they do not require a gradient. It says\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/.../mwe.py\", line 30, in <module>\r\n    hvd.broadcast_optimizer_state(optimizer, root_rank=0)\r\n  File \"/.../python2.7/dist-packages/horovod-0.16.1-py2.7-linux-x86_64.egg/horovod/torch/__init__.py\", line 261, in broadcast_optimizer_state\r\n    super(optimizer.__class__, optimizer).step()\r\n  File \"/.../torch/optim/sgd.py\", line 106, in step\r\n    p.data.add_(-group['lr'], d_p)\r\nRuntimeError: For integral input tensors, argument alpha must not be a floating point number.\r\n\r\n```\r\n\r\nMWE\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.optim as optim\r\n\r\nimport horovod.torch as hvd\r\n\r\n\r\nclass A(nn.Module):\r\n\r\n    def __init__(self, a, b):\r\n        super(A, self).__init__()\r\n        self.a = nn.Parameter(a.int(), requires_grad=False)   # change to a.float() and hvd is happy\r\n        self.b = nn.Parameter(b)\r\n\r\n    def forward(self, x):\r\n        return torch.index_select(self.b, 0, self.a.long()) * x\r\n\r\n\r\nhvd.init()\r\n\r\na = torch.Tensor([1, 3])\r\nb = torch.rand(4)\r\n\r\nmodel = A(a, b).cuda()\r\n\r\noptimizer = optim.SGD(model.parameters(), lr=0.01)\r\noptimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters())\r\n\r\nhvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\nhvd.broadcast_optimizer_state(optimizer, root_rank=0)  # <-- hvd is sad :(\r\n\r\nmodel.train()\r\n\r\nfor i in range(1000):\r\n\r\n    x = torch.Tensor(torch.rand(2)).cuda()\r\n\r\n    optimizer.zero_grad()\r\n\r\n    loss = torch.mean((model(x) - 0) ** 2)\r\n\r\n    loss.backward()\r\n    optimizer.step()\r\n\r\n    if hvd.rank() == 0:\r\n        print(i, loss.detach())\r\n\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1608/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1608/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1593", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1593/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1593/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1593/events", "html_url": "https://github.com/horovod/horovod/issues/1593", "id": 539439921, "node_id": "MDU6SXNzdWU1Mzk0Mzk5MjE=", "number": 1593, "title": "pytorch1.0.0 + horovod 0.15.2  !=  pytorch1.1.0 + horovod 0.18.2", "user": {"login": "Fangyh09", "id": 9389269, "node_id": "MDQ6VXNlcjkzODkyNjk=", "avatar_url": "https://avatars.githubusercontent.com/u/9389269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Fangyh09", "html_url": "https://github.com/Fangyh09", "followers_url": "https://api.github.com/users/Fangyh09/followers", "following_url": "https://api.github.com/users/Fangyh09/following{/other_user}", "gists_url": "https://api.github.com/users/Fangyh09/gists{/gist_id}", "starred_url": "https://api.github.com/users/Fangyh09/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Fangyh09/subscriptions", "organizations_url": "https://api.github.com/users/Fangyh09/orgs", "repos_url": "https://api.github.com/users/Fangyh09/repos", "events_url": "https://api.github.com/users/Fangyh09/events{/privacy}", "received_events_url": "https://api.github.com/users/Fangyh09/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-18T04:10:15Z", "updated_at": "2019-12-19T14:27:32Z", "closed_at": "2019-12-19T14:27:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\nthese two different configurations gave different results. What are the possible reasons?\r\nI used these two configurations to train a CNN.\r\nconfiguration1:  pytorch1.0.0 + horovod 0.15.2, train the CNN successfully\r\nconfiguration2:  pytorch1.1.0 + horovod 0.18.2, output NaN\r\n\r\n---\r\n**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: \r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version: 9.0\r\n6. NCCL version:\r\n7. Python version: \r\n8. OS and version: ubuntu\r\n9. GCC version:\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1593/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1593/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1581", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1581/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1581/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1581/events", "html_url": "https://github.com/horovod/horovod/issues/1581", "id": 536093750, "node_id": "MDU6SXNzdWU1MzYwOTM3NTA=", "number": 1581, "title": "Retrain in Tensorflow will make the master rank exit earlier than other ranks", "user": {"login": "AHEADer", "id": 10228507, "node_id": "MDQ6VXNlcjEwMjI4NTA3", "avatar_url": "https://avatars.githubusercontent.com/u/10228507?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AHEADer", "html_url": "https://github.com/AHEADer", "followers_url": "https://api.github.com/users/AHEADer/followers", "following_url": "https://api.github.com/users/AHEADer/following{/other_user}", "gists_url": "https://api.github.com/users/AHEADer/gists{/gist_id}", "starred_url": "https://api.github.com/users/AHEADer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AHEADer/subscriptions", "organizations_url": "https://api.github.com/users/AHEADer/orgs", "repos_url": "https://api.github.com/users/AHEADer/repos", "events_url": "https://api.github.com/users/AHEADer/events{/privacy}", "received_events_url": "https://api.github.com/users/AHEADer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-12-11T01:51:55Z", "updated_at": "2019-12-19T06:52:32Z", "closed_at": "2019-12-19T06:52:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Tensorflow\r\n2. Framework version: 1.14\r\n3. Horovod version: \r\n4. MPI version:\r\n5. CUDA version: 2.4.7\r\n6. NCCL version:\r\n7. Python version: 3.6.8\r\n8. OS and version: Ubuntu 16.04\r\n9. GCC version: 4.9.3\r\n\r\n**Bug report:**\r\nAfter training in Tensorflow, I will get a trained model containing its training steps. \r\n\r\nIf I train with the same model_dir again, tf.estimator.train() will detect if maximum_step is equal or smaller than steps trained in model_dir. I do not change any config so in this situation, the maximum_step is equal to trained steps. Therefore train() method will end immediately and will not start a session, then the master rank ends.  I set only the master rank can read the model_dir. In this way, the master rank will not broadcast the tensor to other ranks because it does not run session(so hooks are useless). Other ranks start their own train() process but end with an error saying cannot connect the master rank.\r\n\r\nI wonder if there's any way that the master rank can notify other ranks to stop their processes.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1581/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1581/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1576", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1576/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1576/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1576/events", "html_url": "https://github.com/horovod/horovod/issues/1576", "id": 534371021, "node_id": "MDU6SXNzdWU1MzQzNzEwMjE=", "number": 1576, "title": "MXNet crashes with broadcast(name=name)", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-07T08:09:05Z", "updated_at": "2019-12-08T04:59:18Z", "closed_at": "2019-12-08T04:59:18Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): MXNet\r\n2. Framework version: mxnet-cu101==1.6.0b20191122\r\n3. Horovod version: 0.18.2 \r\n4. MPI version: mpirun (Open MPI) 3.1.0\r\n5. CUDA version: 10.1\r\n6. NCCL version: \r\n7. Python version: 3.6.5\r\n8. OS and version: ubuntu\r\n9. GCC version: 5.4.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\n```\r\nimport mxnet as mx\r\nimport horovod.mxnet as hvd\r\nimport numpy as np\r\nimport argparse\r\n\r\n# parser\r\nparser = argparse.ArgumentParser(description='kvstore test')\r\nparser.add_argument('--name', action='store_true')\r\nargs = parser.parse_args()\r\n\r\nhvd.init()\r\nmy_rank = hvd.rank()\r\ncur_keys = list(range(100))\r\ncur_shape = (1,)\r\n\r\nctx = mx.gpu(my_rank)\r\nfor i in range(len(cur_keys)):\r\n    name = cur_keys[i] if args.name else None\r\n    print('iter = ', i, 'name = ', name)\r\n    value = mx.nd.ones(cur_shape, ctx) * i\r\n    out = hvd.broadcast(value, root_rank=0, name=name)\r\n    assert out.asscalar() == i\r\n```\r\n\r\n`mpirun -np 2 python test.py` works fine. Below is the result of `mpirun -np 2 python test.py --name`\r\n```\r\nubuntu@ip-172-31-40-233:~/mxnet/tests/nightly$ mpirun -np 2 python test.py --name\r\niter =  0 name =  0\r\niter =  0 name =  0\r\niter =  1 name =  1\r\niter =  1 name =  1\r\n[ip-172-31-40-233:45034] *** Process received signal ***\r\n[ip-172-31-40-233:45034] Signal: Segmentation fault (11)\r\n[ip-172-31-40-233:45034] Signal code: Address not mapped (1)\r\n[ip-172-31-40-233:45034] Failing at address: 0x1\r\n[ip-172-31-40-233:45035] *** Process received signal ***\r\n[ip-172-31-40-233:45035] Signal: Segmentation fault (11)\r\n[ip-172-31-40-233:45035] Signal code: Address not mapped (1)\r\n[ip-172-31-40-233:45035] Failing at address: 0x1\r\n[ip-172-31-40-233:45034] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x354b0)[0x7f6315e974b0]\r\n[ip-172-31-40-233:45034] [ 1] /lib/x86_64-linux-gnu/libc.so.6(strlen+0x26)[0x7f6315eed746]\r\n[ip-172-31-40-233:45034] [ 2] /home/ubuntu/anaconda3/lib/python3.6/site-packages/horovod/mxnet/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0xb63c3)[0x7f625b02f3c3]\r\n[ip-172-31-40-233:45034] [ 3] /home/ubuntu/anaconda3/lib/python3.6/site-packages/horovod/mxnet/mpi_lib.cpython-36m-x86_64-linux-gnu.so(horovod_mxnet_broadcast_async+0x7a)[0x7f625b03274a]\r\n[ip-172-31-40-233:45034] [ 4] /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c)[0x7f6314c79ec0]\r\n[ip-172-31-40-233:45034] [ 5] /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d)[0x7f6314c7987d]\r\n[ip-172-31-40-233:45034] [ 6] /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce)[0x7f6314e8ee2e]\r\n[ip-172-31-40-233:45034] [ 7] /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12865)[0x7f6314e8f865]\r\n[ip-172-31-40-233:45034] [ 8] python(_PyObject_FastCallDict+0x8b)[0x561c8af2fd7b]\r\n[ip-172-31-40-233:45034] [ 9] [ip-172-31-40-233:45035] [ 0] python(+0x19e7ce)[0x561c8afbf7ce]\r\n[ip-172-31-40-233:45034] [10] python(_PyEval_EvalFrameDefault+0x2fa)[0x561c8afe1cba]\r\n[ip-172-31-40-233:45034] [11] /lib/x86_64-linux-gnu/libc.so.6(+0x354b0)[0x7f1a2bf964b0]\r\n[ip-172-31-40-233:45035] [ 1] python(+0x197a94)[0x561c8afb8a94]\r\n[ip-172-31-40-233:45034] [12] /lib/x86_64-linux-gnu/libc.so.6(strlen+0x26)[0x7f1a2bfec746]\r\n[ip-172-31-40-233:45035] [ 2] python(+0x198941)[0x561c8afb9941]\r\n[ip-172-31-40-233:45034] [13] python(+0x19e755)[0x561c8afbf755]\r\n[ip-172-31-40-233:45034] [14] /home/ubuntu/anaconda3/lib/python3.6/site-packages/horovod/mxnet/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0xb63c3)[0x7f19711143c3]\r\n[ip-172-31-40-233:45035] [ 3] python(_PyEval_EvalFrameDefault+0x10ba)[0x561c8afe2a7a]\r\n[ip-172-31-40-233:45034] [15] /home/ubuntu/anaconda3/lib/python3.6/site-packages/horovod/mxnet/mpi_lib.cpython-36m-x86_64-linux-gnu.so(horovod_mxnet_broadcast_async+0x7a)[0x7f197111774a]\r\n[ip-172-31-40-233:45035] [ 4] /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c)[0x7f1a2ad78ec0]\r\n[ip-172-31-40-233:45035] [ 5] /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d)[0x7f1a2ad7887d]\r\n[ip-172-31-40-233:45035] [ 6] python(PyEval_EvalCodeEx+0x329)[0x561c8afba459]\r\n[ip-172-31-40-233:45034] [16] /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce)[0x7f1a2af8de2e]\r\n[ip-172-31-40-233:45035] [ 7] /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12865)[0x7f1a2af8e865]\r\n[ip-172-31-40-233:45035] [ 8] python(PyEval_EvalCode+0x1c)[0x561c8afbb1ec]\r\n[ip-172-31-40-233:45034] [17] python(_PyObject_FastCallDict+0x8b)[0x563e0fcf6d7b]\r\n[ip-172-31-40-233:45035] [ 9] python(+0x2149a4)[0x561c8b0359a4]\r\n[ip-172-31-40-233:45034] [18] python(PyRun_FileExFlags+0xa1)[0x561c8b035da1]\r\n[ip-172-31-40-233:45034] [19] python(+0x19e7ce)[0x563e0fd867ce]\r\n[ip-172-31-40-233:45035] [10] python(PyRun_SimpleFileExFlags+0x1c4)[0x561c8b035fa4]\r\n[ip-172-31-40-233:45034] [20] python(_PyEval_EvalFrameDefault+0x2fa)[0x563e0fda8cba]\r\n[ip-172-31-40-233:45035] [11] python(Py_Main+0x63e)[0x561c8b039a9e]\r\n[ip-172-31-40-233:45034] [21] python(+0x197a94)[0x563e0fd7fa94]\r\n[ip-172-31-40-233:45035] [12] python(main+0xee)[0x561c8af014be]\r\n[ip-172-31-40-233:45034] [22] python(+0x198941)[0x563e0fd80941]\r\n[ip-172-31-40-233:45035] [13] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f6315e82830]\r\n[ip-172-31-40-233:45034] [23] python(+0x19e755)[0x563e0fd86755]\r\n[ip-172-31-40-233:45035] [14] python(+0x1c7773)[0x561c8afe8773]\r\n[ip-172-31-40-233:45034] *** End of error message ***\r\npython(_PyEval_EvalFrameDefault+0x10ba)[0x563e0fda9a7a]\r\n[ip-172-31-40-233:45035] [15] python(PyEval_EvalCodeEx+0x329)[0x563e0fd81459]\r\n[ip-172-31-40-233:45035] [16] python(PyEval_EvalCode+0x1c)[0x563e0fd821ec]\r\n[ip-172-31-40-233:45035] [17] python(+0x2149a4)[0x563e0fdfc9a4]\r\n[ip-172-31-40-233:45035] [18] python(PyRun_FileExFlags+0xa1)[0x563e0fdfcda1]\r\n[ip-172-31-40-233:45035] [19] python(PyRun_SimpleFileExFlags+0x1c4)[0x563e0fdfcfa4]\r\n[ip-172-31-40-233:45035] [20] python(Py_Main+0x63e)[0x563e0fe00a9e]\r\n[ip-172-31-40-233:45035] [21] python(main+0xee)[0x563e0fcc84be]\r\n[ip-172-31-40-233:45035] [22] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f1a2bf81830]\r\n[ip-172-31-40-233:45035] [23] python(+0x1c7773)[0x563e0fdaf773]\r\n[ip-172-31-40-233:45035] *** End of error message ***\r\n-------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n-------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun noticed that process rank 1 with PID 0 on node ip-172-31-40-233 exited on signal 11 (Segmentation fault).\r\n--------------------------------------------------------------------------\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1576/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1576/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1573", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1573/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1573/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1573/events", "html_url": "https://github.com/horovod/horovod/issues/1573", "id": 534050139, "node_id": "MDU6SXNzdWU1MzQwNTAxMzk=", "number": 1573, "title": "tf.keras.optimizers.schedules not supported by distributed optimizer", "user": {"login": "pstjohn", "id": 2576846, "node_id": "MDQ6VXNlcjI1NzY4NDY=", "avatar_url": "https://avatars.githubusercontent.com/u/2576846?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pstjohn", "html_url": "https://github.com/pstjohn", "followers_url": "https://api.github.com/users/pstjohn/followers", "following_url": "https://api.github.com/users/pstjohn/following{/other_user}", "gists_url": "https://api.github.com/users/pstjohn/gists{/gist_id}", "starred_url": "https://api.github.com/users/pstjohn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pstjohn/subscriptions", "organizations_url": "https://api.github.com/users/pstjohn/orgs", "repos_url": "https://api.github.com/users/pstjohn/repos", "events_url": "https://api.github.com/users/pstjohn/events{/privacy}", "received_events_url": "https://api.github.com/users/pstjohn/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-06T14:56:31Z", "updated_at": "2020-01-10T21:32:18Z", "closed_at": "2020-01-09T21:03:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\ntensorflow\r\n2. Framework version:\r\n2.0.0\r\n3. Horovod version:\r\n0.18.2\r\n4. MPI version:\r\nopenmpi/3.1.3\r\n5. CUDA version:\r\ncuda/10.0.130\r\n6. NCCL version:\r\n2.4.8\r\n7. Python version:\r\n3.7\r\n8. OS and version:\r\ncentos 7\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nUsing tensorflow's [LearningRateSchedules](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay) doesn't appear to work with horovod's distributed optimizer. This might be an easier way of implementing warmup than horovod's keras callbacks.\r\n\r\nModifying the example `tensorflow_keras_mnist.py` with the following lines gives this error message\r\n```python\r\n# Horovod: adjust learning rate based on number of GPUs.\r\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\r\n    0.001 * hvd.size(),\r\n    decay_steps=100000,\r\n    decay_rate=0.96,\r\n    staircase=True)\r\nopt = tf.keras.optimizers.Adam(lr_schedule)\r\n\r\n# Horovod: add Horovod DistributedOptimizer.\r\nopt = hvd.DistributedOptimizer(opt)\r\n```\r\n\r\n```\r\n[1,0]<stderr>:Traceback (most recent call last):\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 541, in __getattribute__\r\n[1,0]<stderr>:    return super(OptimizerV2, self).__getattribute__(name)\r\n[1,0]<stderr>:AttributeError: 'Adam' object has no attribute 'lr'\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:During handling of the above exception, another exception occurred:\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:Traceback (most recent call last):\r\n[1,0]<stderr>:  File \"tensorflow_keras_mnist.py\", line 94, in <module>\r\n[1,0]<stderr>:    mnist_model.fit(dataset, steps_per_epoch=500 // hvd.size(), callbacks=callbacks, epochs=24, verbose=verbose)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\r\n[1,0]<stderr>:    use_multiprocessing=use_multiprocessing)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 693, in fit\r\n[1,0]<stderr>:    steps_name='steps_per_epoch')\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 196, in model_iteration\r\n[1,0]<stderr>:    callbacks._call_begin_hook(mode)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\", line 249, in _call_begin_hook\r\n[1,0]<stderr>:    self.on_train_begin()\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\", line 365, in on_train_begin\r\n[1,0]<stderr>:    callback.on_train_begin(logs)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/horovod/_keras/callbacks.py\", line 137, in on_train_begin\r\n[1,0]<stderr>:    self.initial_lr = self.backend.get_value(self.model.optimizer.lr)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 550, in __getattribute__\r\n[1,0]<stderr>:    return self._get_hyper(name)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 527, in _get_hyper\r\n[1,0]<stderr>:    self._create_hypers()\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 643, in _create_hypers\r\n[1,0]<stderr>:    aggregation=tf_variables.VariableAggregation.ONLY_FIRST_REPLICA)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 805, in add_weight\r\n[1,0]<stderr>:    aggregation=aggregation)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\", line 744, in _add_variable_with_custom_getter\r\n[1,0]<stderr>:    **kwargs_for_getter)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 139, in make_variable\r\n[1,0]<stderr>:    shape=variable_shape if variable_shape else None)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 258, in __call__\r\n[1,0]<stderr>:    return cls._variable_v1_call(*args, **kwargs)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\r\n[1,0]<stderr>:    shape=shape)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\r\n[1,0]<stderr>:    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 2507, in default_variable_creator\r\n[1,0]<stderr>:    shape=shape)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\r\n[1,0]<stderr>:    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1406, in __init__\r\n[1,0]<stderr>:    distribute_strategy=distribute_strategy)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resourc[1,0]<stderr>:e_variable_ops.py\", line 1538, in _init_from_args\r\n[1,0]<stderr>:    name=\"initial_value\", dtype=dtype)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1184, in convert_to_tensor\r\n[1,0]<stderr>:    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1242, in convert_to_tensor_v2\r\n[1,0]<stderr>:    as_ref=False)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1296, in internal_convert_to_tensor\r\n[1,0]<stderr>:    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 286, in _constant_tensor_conversion_function\r\n[1,0]<stderr>:    return constant(v, dtype=dtype, name=name)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 227, in constant\r\n[1,0]<stderr>:    allow_broadcast=True)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 235, in _constant_impl\r\n[1,0]<stderr>:    t = convert_to_eager_tensor(value, ctx, dtype)\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 96, in convert_to_eager_tensor\r\n[1,0]<stderr>:    return ops.EagerTensor(value, ctx.device_name, dtype)\r\n[1,0]<stderr>:ValueError: Attempt to convert a value ({'class_name': 'ExponentialDecay', 'config': {'initial_learning_rate': 0.001, 'decay_steps': 100000, 'decay_rate': 0.96, 'staircase': True, 'name': None}}) with an unsupported type (<class 'dict'>) to a Tensor.\r\n[1,0]<stderr>:Exception ignored in: <function _RandomSeedGeneratorDeleter.__del__ at 0x7f7dec944a70>\r\n[1,0]<stderr>:Traceback (most recent call last):\r\n[1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3009, in __del__\r\n[1,0]<stderr>:AttributeError: 'NoneType' object has no attribute 'device'\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1573/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1573/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1568", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1568/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1568/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1568/events", "html_url": "https://github.com/horovod/horovod/issues/1568", "id": 533423070, "node_id": "MDU6SXNzdWU1MzM0MjMwNzA=", "number": 1568, "title": "Failing on checking if extension is built with GLOO.", "user": {"login": "aaron276h", "id": 5969899, "node_id": "MDQ6VXNlcjU5Njk4OTk=", "avatar_url": "https://avatars.githubusercontent.com/u/5969899?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaron276h", "html_url": "https://github.com/aaron276h", "followers_url": "https://api.github.com/users/aaron276h/followers", "following_url": "https://api.github.com/users/aaron276h/following{/other_user}", "gists_url": "https://api.github.com/users/aaron276h/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaron276h/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaron276h/subscriptions", "organizations_url": "https://api.github.com/users/aaron276h/orgs", "repos_url": "https://api.github.com/users/aaron276h/repos", "events_url": "https://api.github.com/users/aaron276h/events{/privacy}", "received_events_url": "https://api.github.com/users/aaron276h/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-12-05T15:29:08Z", "updated_at": "2019-12-06T00:09:02Z", "closed_at": "2019-12-06T00:09:02Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) TF, PyTorch\r\n2. Framework version: TF 1.14, PyTorch 1.2\r\n3. Horovod version: Tip of Master (`e97ca10aaa9c5b1e063ab4afa85b297bacf77267`)\r\n4. MPI version: N/A\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.7\r\n7. Python version: 3.6\r\n8. OS and version: Ubuntu 16\r\n9. GCC version: 4.8\r\n\r\n**Bug report:**\r\nWe build horovod using GLOO (`HOROVOD_WITHOUT_MPI`). We are failing the newly put in checks of if frameworks are build with GLOO. \r\n1) Could you provide some insight into why these checks are relevant, we had previously observed no issues using Horovod with a GLOO controller.\r\n2) Do you have a recommended way of passing these checks? Or should we just remove them.\r\n\r\nStack trace:\r\n```\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Checking whether extension tensorflow was built with MPI.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Traceback (most recent call last):\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 73, in _target_fn\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     ext = importlib.import_module('.' + ext_base_name, 'horovod')\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     return _bootstrap._gcd_import(name[level:], package, level)\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/tensorflow/__init__.py\", line 43, in <module>\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     has_gpu = gpu_available('tensorflow')\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 104, in gpu_available\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     ext_base_name, available_fn, 'running with GPU', verbose) or False\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 90, in _check_extension_lambda\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     p.start()\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 103, in start\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     'daemonic processes are not allowed to have children'\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || AssertionError: daemonic processes are not allowed to have children\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Extension tensorflow was NOT built with MPI.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Checking whether extension torch was built with MPI.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Traceback (most recent call last):\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 73, in _target_fn\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     ext = importlib.import_module('.' + ext_base_name, 'horovod')\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     return _bootstrap._gcd_import(name[level:], package, level)\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/torch/__init__.py\", line 39, in <module>\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     from horovod.torch.mpi_ops import allreduce, allreduce_async, allreduce_, allreduce_async_\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 80, in <module>\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     _has_gpu = gpu_available('torch')\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 104, in gpu_available\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     ext_base_name, available_fn, 'running with GPU', verbose) or False\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 90, in _check_extension_lambda\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     p.start()\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 103, in start\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     'daemonic processes are not allowed to have children'\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || AssertionError: daemonic processes are not allowed to have children\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Extension torch was NOT built with MPI.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Checking whether extension mxnet was built with MPI.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Traceback (most recent call last):\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 73, in _target_fn\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     ext = importlib.import_module('.' + ext_base_name, 'horovod')\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     return _bootstrap._gcd_import(name[level:], package, level)\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/mxnet/__init__.py\", line 23, in <module>\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     __file__, 'mpi_lib')\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 51, in check_extension\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     'Horovod with %s=1 to debug the build error.' % (ext_name, ext_env_var))\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Extension mxnet was NOT built with MPI.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || ImportError: Extension horovod.mxnet has not been built.  If this is not expected, reinstall Horovod with HOROVOD_WITH_MXNET=1 to debug the build error.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Checking whether extension tensorflow was built with Gloo.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || /opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Traceback (most recent call last):\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 73, in _target_fn\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     ext = importlib.import_module('.' + ext_base_name, 'horovod')\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     return _bootstrap._gcd_import(name[level:], package, level)\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/tensorflow/__init__.py\", line 43, in <module>\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     has_gpu = gpu_available('tensorflow')\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 104, in gpu_available\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     ext_base_name, available_fn, 'running with GPU', verbose) or False\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 90, in _check_extension_lambda\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     p.start()\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 103, in start\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     'daemonic processes are not allowed to have children'\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || AssertionError: daemonic processes are not allowed to have children\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Extension tensorflow was NOT built with Gloo.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Checking whether extension torch was built with Gloo.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Traceback (most recent call last):\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 73, in _target_fn\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     ext = importlib.import_module('.' + ext_base_name, 'horovod')\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     return _bootstrap._gcd_import(name[level:], package, level)\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/torch/__init__.py\", line 39, in <module>\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     from horovod.torch.mpi_ops import allreduce, allreduce_async, allreduce_, allreduce_async_\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 80, in <module>\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     _has_gpu = gpu_available('torch')\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 104, in gpu_available\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     ext_base_name, available_fn, 'running with GPU', verbose) or False\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 90, in _check_extension_lambda\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     p.start()\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 103, in start\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     'daemonic processes are not allowed to have children'\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || AssertionError: daemonic processes are not allowed to have children\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Extension torch was NOT built with Gloo.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Checking whether extension mxnet was built with Gloo.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Traceback (most recent call last):\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 73, in _target_fn\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     ext = importlib.import_module('.' + ext_base_name, 'horovod')\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     return _bootstrap._gcd_import(name[level:], package, level)\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/mxnet/__init__.py\", line 23, in <module>\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     __file__, 'mpi_lib')\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 51, in check_extension\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     'Horovod with %s=1 to debug the build error.' % (ext_name, ext_env_var))\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || ImportError: Extension horovod.mxnet has not been built.  If this is not expected, reinstall Horovod with HOROVOD_WITH_MXNET=1 to debug the build error.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Extension mxnet was NOT built with Gloo.\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || Traceback (most recent call last):\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/bin/horovodrun\", line 21, in <module>\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     run_commandline()\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/run/run.py\", line 860, in run_commandline\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     _run(args)\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/run/run.py\", line 828, in _run\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     _launch_job(args, remote_host_names, settings, common_intfs, command)\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/run/run.py\", line 850, in _launch_job\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     elif gloo_built(verbose=(settings.verbose >= 2)):\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||   File \"/opt/conda/lib/python3.6/site-packages/horovod/common/util.py\", line 124, in gloo_built\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 ||     raise RuntimeError('Failed to determine if Gloo support has been built. '\r\nd996a8f8-e1d4-4e1e-8d9e-e3c5804c0369 || RuntimeError: Failed to determine if Gloo support has been built. Run again with --verbose for more details.\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1568/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1568/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1564", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1564/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1564/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1564/events", "html_url": "https://github.com/horovod/horovod/issues/1564", "id": 533019960, "node_id": "MDU6SXNzdWU1MzMwMTk5NjA=", "number": 1564, "title": "AssertionError: daemonic processes are not allowed to have children", "user": {"login": "rb-determined-ai", "id": 47791514, "node_id": "MDQ6VXNlcjQ3NzkxNTE0", "avatar_url": "https://avatars.githubusercontent.com/u/47791514?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rb-determined-ai", "html_url": "https://github.com/rb-determined-ai", "followers_url": "https://api.github.com/users/rb-determined-ai/followers", "following_url": "https://api.github.com/users/rb-determined-ai/following{/other_user}", "gists_url": "https://api.github.com/users/rb-determined-ai/gists{/gist_id}", "starred_url": "https://api.github.com/users/rb-determined-ai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rb-determined-ai/subscriptions", "organizations_url": "https://api.github.com/users/rb-determined-ai/orgs", "repos_url": "https://api.github.com/users/rb-determined-ai/repos", "events_url": "https://api.github.com/users/rb-determined-ai/events{/privacy}", "received_events_url": "https://api.github.com/users/rb-determined-ai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-12-04T23:58:17Z", "updated_at": "2019-12-06T19:58:54Z", "closed_at": "2019-12-06T00:08:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) `tensorflow-gpu==1.14.0`\r\n2. Framework version: `tensorflow-gpu==1.14.0`\r\n3. Horovod version: `5fa1d7aea2c89fdfa15a688aa413ea49a480ab38`\r\n4. MPI version: N/A\r\n5. CUDA version: 10.0\r\n6. NCCL version: tip of master\r\n7. Python version: 3.6.9\r\n8. OS and version: Ubuntu 18.04\r\n9. GCC version: 4.8 (I think that's what gets selected)\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? N/A\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? N/A\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? yes\r\n\r\n**Bug report:**\r\n\r\nThere appears to be some regression introduced by the commit `5fa1d7aea2c89fdfa15a688aa413ea49a480ab38`.  At some point some process is doing something that is apparently not acceptable, and the whole job crashes.  I have no problem with the commit just before it.\r\n\r\nI have two GCP ubuntu machines with the configuration above.  Horovod was installed like this:\r\n\r\n```\r\ngit co --recurse-submodules 5fa1d7aea2c89fdfa15a688aa413ea49a480ab38\r\nenv \\\r\n    HOROVOD_WITHOUT_MPI=1 \\\r\n    HOROVOD_WITH_GLOO=1 \\\r\n    HOROVOD_WITH_TENSORFLOW=1 \\\r\n    HOROVOD_WITHOUT_PYTORCH=1 \\\r\n    HOROVOD_WITHOUT_MXNET=1 \\\r\n    HOROVOD_GPU_ALLREDUCE=NCCL \\\r\n    pip install . -v\r\n```\r\n\r\nThen I ran it like this:\r\n\r\n    horovodrun -np 2 -H localhost:1,rb2:1 --network-interface ens8 --gloo --verbose --verbose python3 learn_horovod.py\r\n\r\nAnd here is the full output:\r\n\r\n```\r\nFiltering local host names.\r\nRemote host found: rb2\r\nChecking ssh on all remote hosts.\r\nSSH was successful into all the remote hosts.\r\nTesting interfaces on all the hosts.\r\nInterfaces on all the hosts were successfully checked.\r\nCommon interface found: ens8\r\nChecking whether extension tensorflow was built with Gloo.\r\nExtension tensorflow was NOT built with Gloo.\r\n/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\nTraceback (most recent call last):\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/common/util.py\", line 73, in _target_fn\r\n    ext = importlib.import_module('.' + ext_base_name, 'horovod')\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/tensorflow/__init__.py\", line 43, in <module>\r\n    has_gpu = gpu_available('tensorflow')\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/common/util.py\", line 103, in gpu_available\r\n    ext_base_name, available_fn, 'running with GPU', verbose) or False\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/common/util.py\", line 90, in _check_extension_lambda\r\n    p.start()\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/multiprocessing/process.py\", line 103, in start\r\n    'daemonic processes are not allowed to have children'\r\nAssertionError: daemonic processes are not allowed to have children\r\nChecking whether extension torch was built with Gloo.\r\nExtension torch was NOT built with Gloo.\r\nTraceback (most recent call last):\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/torch/__init__.py\", line 28, in <module>\r\n    __file__, 'mpi_lib_v2')\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/common/util.py\", line 51, in check_extension\r\n    'Horovod with %s=1 to debug the build error.' % (ext_name, ext_env_var))\r\nImportError: Extension horovod.torch has not been built.  If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/common/util.py\", line 73, in _target_fn\r\n    ext = importlib.import_module('.' + ext_base_name, 'horovod')\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/torch/__init__.py\", line 31, in <module>\r\n    __file__, 'mpi_lib', '_mpi_lib')\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/common/util.py\", line 51, in check_extension\r\n    'Horovod with %s=1 to debug the build error.' % (ext_name, ext_env_var))\r\nImportError: Extension horovod.torch has not been built.  If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\r\nChecking whether extension mxnet was built with Gloo.\r\nExtension mxnet was NOT built with Gloo.\r\nTraceback (most recent call last):\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/common/util.py\", line 73, in _target_fn\r\n    ext = importlib.import_module('.' + ext_base_name, 'horovod')\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/mxnet/__init__.py\", line 23, in <module>\r\n    __file__, 'mpi_lib')\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/common/util.py\", line 51, in check_extension\r\n    'Horovod with %s=1 to debug the build error.' % (ext_name, ext_env_var))\r\nImportError: Extension horovod.mxnet has not been built.  If this is not expected, reinstall Horovod with HOROVOD_WITH_MXNET=1 to debug the build error.\r\nTraceback (most recent call last):\r\n  File \"/home/rb/miniconda3/envs/pedl/bin/horovodrun\", line 21, in <module>\r\n    run_commandline()\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/run/run.py\", line 860, in run_commandline\r\n    _run(args)\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/run/run.py\", line 828, in _run\r\n    _launch_job(args, remote_host_names, settings, common_intfs, command)\r\n  File \"/home/rb/miniconda3/envs/pedl/lib/python3.6/site-packages/horovod/run/run.py\", line 839, in _launch_job\r\n    raise ValueError('Gloo support has not been built.  If this is not expected, ensure CMake is installed '\r\nValueError: Gloo support has not been built.  If this is not expected, ensure CMake is installed and reinstall Horovod with HOROVOD_WITH_GLOO=1 to debug the build error.\r\n```\r\n\r\nThe file `learn_horovod.py` looks like:\r\n\r\n```\r\nimport sys\r\nimport tensorflow as tf\r\n\r\nimport horovod.tensorflow as hvd\r\n\r\n# Initialize Horovod\r\nhvd.init()\r\n\r\n# Pin GPU to be used to process local rank (one GPU per process)\r\nconfig = tf.ConfigProto()\r\nprint(f\"using gpu {hvd.local_rank()}\")\r\nconfig.gpu_options.visible_device_list = str(hvd.local_rank())\r\n\r\n# Build dataset\r\ndata_ds = tf.data.Dataset.range(1,100).batch(10).repeat()\r\nlabel_ds = tf.data.Dataset.range(1,100).map(lambda x: 2*x).batch(10).repeat()\r\nds = tf.data.Dataset.zip({\"data\":data_ds, \"label\":label_ds})\r\n# Deref dataset\r\niterator = ds.make_one_shot_iterator()\r\nrecord = iterator.get_next()\r\n# Build model\r\nw = tf.get_variable(\"weight\", [1], dtype=tf.float32, initializer=tf.zeros_initializer)\r\npred = w * tf.cast(record[\"data\"], tf.float32)\r\nloss = tf.losses.mean_squared_error(pred, tf.cast(record[\"label\"], tf.float32))\r\n\r\n# Optimizer\r\nopt = tf.train.AdagradOptimizer(0.01 * hvd.size())\r\n\r\n# Add Horovod Distributed Optimizer\r\nopt = hvd.DistributedOptimizer(opt)\r\n\r\n# Add hook to broadcast variables from rank 0 to all other processes during\r\n# initialization.\r\nhooks = [hvd.BroadcastGlobalVariablesHook(0), tf.train.StopAtStepHook(last_step=4)]\r\n\r\n# Make training operation\r\ntrain_op = opt.minimize(loss, global_step=tf.train.create_global_step())\r\n\r\n# Save checkpoints only on worker 0 to prevent other workers from corrupting them.\r\ncheckpoint_dir = '/tmp/train_logs' if hvd.rank() == 0 else None\r\n\r\n# The MonitoredTrainingSession takes care of session initialization,\r\n# restoring from a checkpoint, saving to a checkpoint, and closing when done\r\n# or an error occurs.\r\nwith tf.train.MonitoredTrainingSession(\r\n    checkpoint_dir=checkpoint_dir, config=config, hooks=hooks\r\n) as mon_sess:\r\n    while not mon_sess.should_stop():\r\n        # Perform synchronous training.\r\n        mon_sess.run(train_op)\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1564/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1564/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1559", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1559/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1559/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1559/events", "html_url": "https://github.com/horovod/horovod/issues/1559", "id": 531841792, "node_id": "MDU6SXNzdWU1MzE4NDE3OTI=", "number": 1559, "title": "tf.AUTO_REUSE cause Mismatched ALLREDUCE tensor shapes error", "user": {"login": "chenbiaolong", "id": 9475734, "node_id": "MDQ6VXNlcjk0NzU3MzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/9475734?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenbiaolong", "html_url": "https://github.com/chenbiaolong", "followers_url": "https://api.github.com/users/chenbiaolong/followers", "following_url": "https://api.github.com/users/chenbiaolong/following{/other_user}", "gists_url": "https://api.github.com/users/chenbiaolong/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenbiaolong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenbiaolong/subscriptions", "organizations_url": "https://api.github.com/users/chenbiaolong/orgs", "repos_url": "https://api.github.com/users/chenbiaolong/repos", "events_url": "https://api.github.com/users/chenbiaolong/events{/privacy}", "received_events_url": "https://api.github.com/users/chenbiaolong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-03T09:25:05Z", "updated_at": "2020-02-06T17:31:08Z", "closed_at": "2020-02-06T17:31:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow \r\n2. Framework version: 1.12\r\n3. Horovod version: v0.18.2\r\n4. MPI version: 4.0.2\r\n5. CUDA version: 9.0\r\n6. NCCL version: nccl_2.5.6-1+cuda9.0_x86_64\r\n7. Python version: 3.5\r\n8. OS and version: centos7.4\r\n9. GCC version: gcc version 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC) \r\n\r\nI try to use horovod to train retinanet which use `tf.AUTO_REUSE`  in its class and bbox subnet. some of my retinanet code show as below\r\n\r\n```python\r\nclass RetinaHead(AnchorHead):\r\n    def __init__(self,\r\n                 num_classes,\r\n                 image_size,\r\n                 feature_map_shape_list,\r\n                 box_code_size = 4,\r\n                 stacked_convs = 4,\r\n                 conv_cfg = None,\r\n                 anchor_generator_cfg = None,\r\n                 cls_loss_cfg = None,\r\n                 bbox_loss_cfg = None,\r\n                 name = 'RetinaHead',\r\n                 **kwargs):\r\n        self._num_classes = num_classes\r\n        self._stacked_conv = stacked_convs\r\n        self._conv_cfg = conv_cfg\r\n        self._box_code_size = box_code_size\r\n        self._cls_loss_cfg = cls_loss_cfg\r\n        self._bbox_loss_cfg = bbox_loss_cfg\r\n        super(RetinaHead, self).__init__(\r\n            num_classes = num_classes,\r\n            image_size = image_size,\r\n            anchor_generator_cfg = anchor_generator_cfg,\r\n            feature_map_shape_list = feature_map_shape_list,\r\n            cls_loss_cfg = cls_loss_cfg,\r\n            bbox_loss_cfg = bbox_loss_cfg,\r\n            name = name,\r\n            **kwargs\r\n            )\r\n        # self._num_anchors get from BaseClass AnchorHead \r\n        num_anchor = self._num_anchors\r\n\r\n    def cls_subnet(self, x, level_name, num_anchor_per_location, \r\n                    activation = tf.nn.relu, is_training = True):\r\n        \"\"\" classification subnet of retinanet\r\n        Args:\r\n            num_anchor_per_location:\r\n                num of anchor per pixel of feature_map\r\n        Returns:\r\n            classes: tensor with shape:\r\n                [batch_size, num_anchor_of_this_featuemap, num_classes]\r\n                Note: num_classes **NOT** include the background class\r\n        \"\"\"\r\n        for i in range(self._stacked_conv):\r\n            # this conv params will be shared among all levels\r\n            conv = ConvBlock(self._conv_cfg, name = 'class%d_conv'%i)\r\n            x = conv(x)\r\n            # The convolution layers in the class net are shared among all levels, but\r\n            # each level has its batch normlization to capture the statistical\r\n            # difference among different levels.\r\n            x = batch_norm_activation(x, is_training, activation, name = 'class-%d-bn-%s' % (i, level_name))\r\n        classes = tf.layers.conv2d(\r\n            x,\r\n            (self._num_classes) * num_anchor_per_location,\r\n            kernel_size=(1, 1),\r\n            bias_initializer=tf.constant_initializer(-np.log((1 - 0.01) / 0.01)),\r\n            kernel_initializer=tf.random_normal_initializer(stddev=0.01),\r\n            padding='same',\r\n            name='class-predict')\r\n        batch_size = tf.shape(classes)[0]\r\n        classes = tf.reshape(classes, [batch_size, -1, self._num_classes])\r\n        return classes\r\n    \r\n    def bbox_subnet(self, x, level_name, num_anchor_per_location, \r\n            activation = tf.nn.relu, is_training = True):\r\n        \"\"\" bbox regression subnet of retinanet\r\n        Args:\r\n            num_anchor_per_location:\r\n                num of anchor per pixel of feature_map\r\n        Returns:\r\n            bbox: tensor with shape:\r\n                [batch_size, num_anchor_of_this_featuemap, box_coder_dim]\r\n\r\n        \"\"\"\r\n        for i in range(self._stacked_conv):\r\n            # this conv params will be shared among all levels\r\n            conv = ConvBlock(self._conv_cfg, name = 'bbox%d_conv'%i)\r\n            x = conv(x)\r\n            # The convolution layers in the class net are shared among all levels, but\r\n            # each level has its batch normlization to capture the statistical\r\n            # difference among different levels.\r\n            x = batch_norm_activation(x, is_training, activation, \r\n                name = 'bbox-%d-bn-%s' % (i, level_name))\r\n        bbox = tf.layers.conv2d(\r\n            x,\r\n            num_anchor_per_location * self._box_code_size,\r\n            kernel_size=(1, 1),\r\n            bias_initializer=tf.constant_initializer(-np.log((1 - 0.01) / 0.01)),\r\n            kernel_initializer=tf.random_normal_initializer(stddev=0.01),\r\n            padding='same',\r\n            name='bbox-predict')\r\n        batch_size = tf.shape(bbox)[0]\r\n        bbox = tf.reshape(bbox, [batch_size, -1, self._box_code_size])\r\n        return bbox\r\n    \r\n    def forward(self, features, is_training = True):\r\n        \"\"\" \r\n        Args:\r\n            features : FPN feature-map tensors list in high to low resolution.\r\n                Each tensor in the list correspond to different feature levels.\r\n        Returns:\r\n            cls_scores: scores list\r\n            bbox_preds: bbox list\r\n        \"\"\"\r\n        cls_scores = []\r\n        bbox_preds = []\r\n        for idx, feat in enumerate(features):\r\n            num_anchor_per_location = self._num_anchors_per_location[idx]\r\n           ## !!!!this casue the ALLREDUCE error!!!!!\r\n            with tf.variable_scope('class_net', reuse=tf.AUTO_REUSE):\r\n                cls_scores.append(self.cls_subnet(feat, 'feature%d'%idx, num_anchor_per_location, \r\n                    is_training = is_training))\r\n            with tf.variable_scope('bbox_net', reuse=tf.AUTO_REUSE):\r\n                bbox_preds.append(self.bbox_subnet(feat, 'feature%d'%idx, num_anchor_per_location,\r\n                    is_training = is_training))\r\n        return cls_scores, bbox_preds\r\n```\r\nwhen I ran the training code in 1 server 4 GPUs, horovod report the error(I use tensorflow1.12, not 1.14, I didn't change the virtualenv name):\r\n```shell\r\n\r\nCaused by op 'DistributedRMSPropOptimizer_Allreduce/HorovodAllreduce_gradients_AddN_5_0', defined at:\r\n  File \"./detection/models/main.py\", line 86, in <module>\r\n    main()\r\n  File \"./detection/models/main.py\", line 82, in main\r\n    excutor.train(args.steps)\r\n  File \"/export/chenbiaolong/imba-common/detection/detection/models/core/executor.py\", line 57, in train\r\n    hooks=[bcast_hook]\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1207, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1237, in _train_model_default\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/export/chenbiaolong/imba-common/detection/detection/models/model_builder.py\", line 56, in __call__\r\n    return self._model.train(features, labels)\r\n  File \"/export/chenbiaolong/imba-common/detection/detection/models/meta_arch/retinanet.py\", line 189, in train\r\n    train_op = self.optimize(total_loss)\r\n  File \"/export/chenbiaolong/imba-common/detection/detection/models/core/base_model.py\", line 242, in optimize\r\n    total_loss, global_step, var_list=train_var_list)\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 400, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/horovod/tensorflow/__init__.py\", line 256, in compute_gradients\r\n    avg_grads = self._allreduce_grads(grads)\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/horovod/tensorflow/__init__.py\", line 210, in allreduce_grads\r\n    for grad in grads]\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/horovod/tensorflow/__init__.py\", line 210, in <listcomp>\r\n    for grad in grads]\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/horovod/tensorflow/__init__.py\", line 80, in allreduce\r\n    summed_tensor_compressed = _allreduce(tensor_compressed)\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/horovod/tensorflow/mpi_ops.py\", line 89, in _allreduce\r\n    return MPI_LIB.horovod_allreduce(tensor, name=name)\r\n  File \"<string>\", line 51, in horovod_allreduce\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\r\n    op_def=op_def)\r\n  File \"/home/chenbiaolong/tf-r1.14/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nFailedPreconditionError (see above for traceback): Mismatched ALLREDUCE tensor shapes: One rank sent a tensor of shape [540], but another rank sent a tensor of shape [1, 1, 256, 24].\r\n         [[node DistributedRMSPropOptimizer_Allreduce/HorovodAllreduce_gradients_AddN_5_0 (defined at <string>:51)  = HorovodAllreduce[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/AddN_5)]]\r\n```\r\nI believe it is caused by the `tf.AUTO_REUSE`, because when I change the network and remove the `tf.AUTO_REUSE`, everything seems go well. Is this a bug of horovod or did I miss something?\r\nmy start scrip:\r\n```shell\r\nmpirun -np 4 -H localhost:4 -bind-to none -map-by slot  -x NCCL_DEBUG=INFO  \\\r\n  -x LD_LIBRARY_PATH -x PATH \\\r\n  -x NCCL_SOCKET_IFNAME=^lo,docker0 \\\r\n  -mca pml ob1 -mca btl ^openib \\\r\n  -mca btl_tcp_if_exclude lo,docker0 \\\r\n  python ./detection/models/main.py\r\n```\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1559/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1559/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1533", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1533/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1533/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1533/events", "html_url": "https://github.com/horovod/horovod/issues/1533", "id": 527739443, "node_id": "MDU6SXNzdWU1Mjc3Mzk0NDM=", "number": 1533, "title": "mxnet crashes", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-11-24T18:48:53Z", "updated_at": "2020-01-09T15:48:57Z", "closed_at": "2020-01-09T15:48:57Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): mxnet\r\n2. Framework version: mxnet-cu100 20191123\r\n3. Horovod version: 0.18.2\r\n4. MPI version: 3.1.4\r\n5. CUDA version: 10.0 \r\n6. NCCL version: \r\n7. Python version: 3.7 \r\n8. OS and version: amazon linux\r\n9. GCC version: \r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\n\r\n```\r\n(base) [ec2-user@ip-172-31-4-79 bert]$ mpirun -np 8 python -c \"import mxnet as mx; import horovod.mxnet as hvd; hvd.init(); a = mx.nd.ones((1),ctx=mx.gpu(hvd.rank())); b = hvd.allreduce(a * 1, average=False); mx.nd.waitall(); import time; time.sleep(10); print(b)\"\r\n\r\nSegmentation fault: 11\r\n\r\nStack trace:\r\n  [bt] (0) /home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x3a14c70) [0x7f137e617c70]\r\n  [bt] (1) /lib64/libc.so.6(+0x362f0) [0x7f145e91b2f0]\r\n  [bt] (2) /lib64/libc.so.6(+0x156680) [0x7f145ea3b680]\r\n  [bt] (3) /opt/amazon//openmpi/lib64/libopen-pal.so.40(+0x456b3) [0x7f1321a416b3]\r\n  [bt] (4) /opt/amazon//openmpi/lib64/libmpi.so.40(ompi_coll_base_allreduce_intra_recursivedoubling+0x125) [0x7f1322050b85]\r\n  [bt] (5) /opt/amazon//openmpi/lib64/libmpi.so.40(PMPI_Allreduce+0x14f) [0x7f13220111af]\r\n  [bt] (6) /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(horovod::common::MPIAllreduce::Execute(std::vector<horovod::common::TensorTableEntry, std::allocator<horovod::common::TensorTableEntry> >&, horovod::common::Response const&)+0x1ad) [0x7f1309fb38dd]\r\n  [bt] (7) /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(horovod::common::OperationManager::ExecuteAllreduce(std::vector<horovod::common::TensorTableEntry, std::allocator<horovod::common::TensorTableEntry> >&, horovod::common::Response const&) const+0x61) [0x7f1309f9a8f1]\r\n  [bt] (8) /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(horovod::common::OperationManager::ExecuteOperation(std::vector<horovod::common::TensorTableEntry, std::allocator<horovod::common::TensorTableEntry> >&, horovod::common::Response const&) const+0x81) [0x7f1309f9acc1]\r\nterminate called after throwing an instance of 'std::system_error'\r\n  what():  Resource deadlock avoided\r\n[ip-172-31-4-79:34873] *** Process received signal ***\r\n[ip-172-31-4-79:34873] Signal: Aborted (6)\r\n[ip-172-31-4-79:34873] Signal code:  (-6)\r\n[ip-172-31-4-79:34873] [ 0] /lib64/libpthread.so.0(+0xf5e0)[0x7f145ecc15e0]\r\n[ip-172-31-4-79:34873] [ 1] /lib64/libc.so.6(gsignal+0x37)[0x7f145e91b277]\r\n[ip-172-31-4-79:34873] [ 2] /lib64/libc.so.6(abort+0x148)[0x7f145e91c968]\r\n[ip-172-31-4-79:34873] [ 3] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xbc)[0x7f14547ba3df]\r\n[ip-172-31-4-79:34873] [ 4] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(+0x9cb16)[0x7f14547b8b16]\r\n[ip-172-31-4-79:34873] [ 5] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(+0x9bf91)[0x7f14547b7f91]\r\n[ip-172-31-4-79:34873] [ 6] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(__gxx_personality_v0+0x33e)[0x7f14547b879d]\r\n[ip-172-31-4-79:34873] [ 7] /home/ec2-user/anaconda3/bin/../lib/libgcc_s.so.1(+0xcf56)[0x7f14546edf56]\r\n[ip-172-31-4-79:34873] [ 8] /home/ec2-user/anaconda3/bin/../lib/libgcc_s.so.1(_Unwind_RaiseException+0xe6)[0x7f14546ee244]\r\n[ip-172-31-4-79:34873] [ 9] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(__cxa_throw+0x42)[0x7f14547b8d1b]\r\n[ip-172-31-4-79:34873] [10] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(_ZSt20__throw_system_errori+0x73)[0x7f14547d43bd]\r\n[ip-172-31-4-79:34873] [11] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(_ZNSt6thread4joinEv+0x25)[0x7f14547d4541]\r\n[ip-172-31-4-79:34873] [12] /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(_ZN7horovod6common18HorovodGlobalStateD1Ev+0x548)[0x7f1309f86388]\r\n[ip-172-31-4-79:34873] [13] /lib64/libc.so.6(+0x39bd9)[0x7f145e91ebd9]\r\n[ip-172-31-4-79:34873] [14] /lib64/libc.so.6(+0x39c27)[0x7f145e91ec27]\r\n[ip-172-31-4-79:34873] [15] /home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x3a14ca8)[0x7f137e617ca8]\r\n[ip-172-31-4-79:34873] [16] /lib64/libc.so.6(+0x362f0)[0x7f145e91b2f0]\r\n[ip-172-31-4-79:34873] [17] /lib64/libc.so.6(+0x156680)[0x7f145ea3b680]\r\n[ip-172-31-4-79:34873] [18] /opt/amazon//openmpi/lib64/libopen-pal.so.40(+0x456b3)[0x7f1321a416b3]\r\n[ip-172-31-4-79:34873] [19] /opt/amazon//openmpi/lib64/libmpi.so.40(ompi_coll_base_allreduce_intra_recursivedoubling+0x125)[0x7f1322050b85]\r\n[ip-172-31-4-79:34873] [20] /opt/amazon//openmpi/lib64/libmpi.so.40(PMPI_Allreduce+0x14f)[0x7f13220111af]\r\n[ip-172-31-4-79:34873] [21] /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(_ZN7horovod6common12MPIAllreduce7ExecuteERSt6vectorINS0_16TensorTableEntryESaIS3_EERKNS0_8ResponseE+0x1ad)[0x7f1309fb38dd]\r\n[ip-172-31-4-79:34873] [22] /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(_ZNK7horovod6common16OperationManager16ExecuteAllreduceERSt6vectorINS0_16TensorTableEntryESaIS3_EERKNS0_8ResponseE+0x61)[0x7f1309f9a8f1]\r\n[ip-172-31-4-79:34873] [23] /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(_ZNK7horovod6common16OperationManager16ExecuteOperationERSt6vectorINS0_16TensorTableEntryESaIS3_EERKNS0_8ResponseE+0x81)[0x7f1309f9acc1]\r\n[ip-172-31-4-79:34873] [24] /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(+0x595f2)[0x7f1309f805f2]\r\n[ip-172-31-4-79:34873] [25] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(+0xb8678)[0x7f14547d4678]\r\n[ip-172-31-4-79:34873] [26] /lib64/libpthread.so.0(+0x7de5)[0x7f145ecb9de5]\r\n[ip-172-31-4-79:34873] [27] /lib64/libc.so.6(clone+0x6d)[0x7f145e9e2f1d]\r\n[ip-172-31-4-79:34873] *** End of error message ***\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun noticed that process rank 3 with PID 0 on node ip-172-31-4-79 exited on signal 6 (Aborted).\r\n--------------------------------------------------------------------------\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1533/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1533/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1519", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1519/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1519/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1519/events", "html_url": "https://github.com/horovod/horovod/issues/1519", "id": 524138416, "node_id": "MDU6SXNzdWU1MjQxMzg0MTY=", "number": 1519, "title": "allgather doesn't concatenate tensors", "user": {"login": "chandana1332", "id": 8731489, "node_id": "MDQ6VXNlcjg3MzE0ODk=", "avatar_url": "https://avatars.githubusercontent.com/u/8731489?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chandana1332", "html_url": "https://github.com/chandana1332", "followers_url": "https://api.github.com/users/chandana1332/followers", "following_url": "https://api.github.com/users/chandana1332/following{/other_user}", "gists_url": "https://api.github.com/users/chandana1332/gists{/gist_id}", "starred_url": "https://api.github.com/users/chandana1332/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chandana1332/subscriptions", "organizations_url": "https://api.github.com/users/chandana1332/orgs", "repos_url": "https://api.github.com/users/chandana1332/repos", "events_url": "https://api.github.com/users/chandana1332/events{/privacy}", "received_events_url": "https://api.github.com/users/chandana1332/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-11-18T05:09:06Z", "updated_at": "2021-03-27T15:47:43Z", "closed_at": "2021-03-27T15:47:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: MXNet\r\n2. Framework version: 1.4.1\r\n3. Horovod version: 0.16.4\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nI'm running this to test allgather:\r\n\r\ntest = mx.ndarray.ones((2,3,2))\r\nprint(test)\r\nnew_test = hvd.allgather(test)\r\nprint(new_test)\r\n\r\nIf there are 4 processes, the expected shape of new_test is (8,3,2)\r\n\r\nBut the behaviour I notice is that the output shape is (2,3,2)\r\n\r\nIs the usage of allgather accurate? If not, can you help figure out what might be wrong?\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1519/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1519/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1516", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1516/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1516/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1516/events", "html_url": "https://github.com/horovod/horovod/issues/1516", "id": 523599114, "node_id": "MDU6SXNzdWU1MjM1OTkxMTQ=", "number": 1516, "title": "mca_btl_tcp_endpoint_recv_connect_ack] received unexpected process identifier", "user": {"login": "vilmara", "id": 30601934, "node_id": "MDQ6VXNlcjMwNjAxOTM0", "avatar_url": "https://avatars.githubusercontent.com/u/30601934?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vilmara", "html_url": "https://github.com/vilmara", "followers_url": "https://api.github.com/users/vilmara/followers", "following_url": "https://api.github.com/users/vilmara/following{/other_user}", "gists_url": "https://api.github.com/users/vilmara/gists{/gist_id}", "starred_url": "https://api.github.com/users/vilmara/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vilmara/subscriptions", "organizations_url": "https://api.github.com/users/vilmara/orgs", "repos_url": "https://api.github.com/users/vilmara/repos", "events_url": "https://api.github.com/users/vilmara/events{/privacy}", "received_events_url": "https://api.github.com/users/vilmara/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-15T17:33:55Z", "updated_at": "2019-11-15T19:01:33Z", "closed_at": "2019-11-15T19:01:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:** \r\n\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): TensorFlow\r\n2. Framework version: TensorFlow 1.14.0\r\n3. Horovod version: horovod-0.18.2 \r\n4. MPI version: openmpi-4.0.0\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.7-1\r\n7. Python version: 2.7\r\n8. OS and version:  Ubunto18.04\r\n9. GCC version: 4.8\r\n10. Mellanox: MLNX_OFED_LINUX-4.7-1.0.0.1\r\n\r\n**Bug report:**\r\nHi, I am running TensorFlow benchmarks in multi-node mode over InfiniBand with, running via Horovod docker with Mellanox support, and the master node hangs, see below:\r\n\r\n**Command-line to replicate:**\r\n`mpirun -np 8 -H <ib0 master node>:4,<ib0 second node>:4 --allow-run-as-root -x NCCL_IB_DISABLE=0 -x NCCL_IB_CUDA_SUPPORT=1 -x NCCL_SOCKET_IFNAME=ib0 -x NCCL_DEBUG=INFO --bind-to none --map-by slot --mca plm_rsh_args \"-p 50000\" python tf_cnn_benchmarks.py --variable_update=horovod --model=resnet50 --batch_size=128`\r\n\r\n**Error:** \r\n`[second-node][[22157,1],4][btl_tcp_endpoint.c:626:mca_btl_tcp_endpoint_recv_connect_ack] received unexpected process identifier [[22157,1],7]`\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1516/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1516/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1497", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1497/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1497/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1497/events", "html_url": "https://github.com/horovod/horovod/issues/1497", "id": 517650223, "node_id": "MDU6SXNzdWU1MTc2NTAyMjM=", "number": 1497, "title": "Memory usage issue when using Horovod with spark-submit and YARN", "user": {"login": "alasdairm-gr", "id": 57347618, "node_id": "MDQ6VXNlcjU3MzQ3NjE4", "avatar_url": "https://avatars.githubusercontent.com/u/57347618?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alasdairm-gr", "html_url": "https://github.com/alasdairm-gr", "followers_url": "https://api.github.com/users/alasdairm-gr/followers", "following_url": "https://api.github.com/users/alasdairm-gr/following{/other_user}", "gists_url": "https://api.github.com/users/alasdairm-gr/gists{/gist_id}", "starred_url": "https://api.github.com/users/alasdairm-gr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alasdairm-gr/subscriptions", "organizations_url": "https://api.github.com/users/alasdairm-gr/orgs", "repos_url": "https://api.github.com/users/alasdairm-gr/repos", "events_url": "https://api.github.com/users/alasdairm-gr/events{/privacy}", "received_events_url": "https://api.github.com/users/alasdairm-gr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-11-05T09:28:15Z", "updated_at": "2019-11-20T21:30:06Z", "closed_at": "2019-11-20T21:29:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Keras (but it doesn't matter)\r\n2. Framework version:\r\n3. Horovod version: 0.18.2\r\n4. MPI version: 4\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.6\r\n8. OS and version: N/A\r\n9. GCC version: N/A\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? N/A\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?  N/A\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Bug report:**\r\nWe have found an issue when using Horovod with YARN.  We are happy to fix this ourselves.  We would like some guidance from the Horovod community on what would be the best approach.\r\n\r\nScenario:\r\n- You have a YARN cluster of 4 nodes\r\n- You run horovod via spark-submit with 5 executors, 32GB per executor and 8 cores per executor\r\n\r\nResult:\r\n- 5 executors (YARN containers) are created\r\n- One node gets 2 executors (YARN containers)\r\n- That node gets 16 cores allocated\r\n- 16 keras processes are started on that node through openmpi\r\n- The 16 keras processes all share 32GB memory because they are all started inside the same YARN container\r\n- Your process runs out of memory and crashes because you do not expect to have 16 keras processes sharing 32GB data; you expect them to be split into 2 separate containers with 8 processes sharing 32GB data\r\n\r\nI think i found the code that causes this to happen:\r\nhttps://github.com/horovod/horovod/blob/6cc9ca78515efaf3b1e553ed66f5410c86393ed8/horovod/spark/driver/mpirun_rsh.py#L32 Horovod makes the assumption that all processes on the same host have shared memory. This is not a correct assumption when you are using YARN.\r\n\r\nPossible solutions:\r\nBelow are the solutions I can think of.  I would appreciate some advice on other approaches.\r\n\r\n- Change the way we calculate host hashes, use one host hash per YARN container\r\n- When starting the MPI processes, somehow work out how many containers we have on each node and then start the process on the right container (not sure how this would work)\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1497/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1497/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1492", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1492/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1492/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1492/events", "html_url": "https://github.com/horovod/horovod/issues/1492", "id": 516346017, "node_id": "MDU6SXNzdWU1MTYzNDYwMTc=", "number": 1492, "title": "Horovod would not build with TF1.15 due to protobuf version mismatch", "user": {"login": "yselivonchyk", "id": 4716569, "node_id": "MDQ6VXNlcjQ3MTY1Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/4716569?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yselivonchyk", "html_url": "https://github.com/yselivonchyk", "followers_url": "https://api.github.com/users/yselivonchyk/followers", "following_url": "https://api.github.com/users/yselivonchyk/following{/other_user}", "gists_url": "https://api.github.com/users/yselivonchyk/gists{/gist_id}", "starred_url": "https://api.github.com/users/yselivonchyk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yselivonchyk/subscriptions", "organizations_url": "https://api.github.com/users/yselivonchyk/orgs", "repos_url": "https://api.github.com/users/yselivonchyk/repos", "events_url": "https://api.github.com/users/yselivonchyk/events{/privacy}", "received_events_url": "https://api.github.com/users/yselivonchyk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-01T21:03:11Z", "updated_at": "2019-11-04T21:20:04Z", "closed_at": "2019-11-04T21:20:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Tensorflow\r\n2. Framework version: 1.15\r\n3. Horovod version: 0.18.2 (pip install horovod)\r\n4. MPI version: 4.0.1\r\n5. CUDA version: 10.0\r\n6. NCCL version: \r\n7. Python version: Python 3.6.6 :: Anaconda, Inc.\r\n8. OS and version: 16.04\r\n9. GCC version: gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.11)\r\n\r\n**Bug report:**\r\nError while installing horovod with TF1.15. Complains about protobuf version, yet the latest protobuf is installed `Requirement already satisfied: protobuf in /home/ubuntu/env/t15hvd/lib/python3.6/site-packages (3.10.0)`\r\n\r\nInstallation process:\r\n```\r\nsudo rm -rf /usr/local/lib/openmpi /usr/local/lib/libmca* /usr/local/lib/libmpi* /usr/local/lib/libompitrace* /usr/local/lib/libopen* /usr/local/lib/liboshmem* /usr/local/lib/mpi_*\r\nmkdir ~/tmp/\r\ncd ~/tmp/\r\nwget https://download.open-mpi.org/release/open-mpi/v4.0/openmpi-4.0.1.tar.gz\r\ngunzip -c openmpi-4.0.1.tar.gz | tar xf -\r\ncd openmpi-4.0.1\r\n./configure --prefix=/usr/local; sudo make -j 16 all install\r\nexport CC=/usr/bin/gcc-5\r\nexport CXX=/usr/bin/gcc-5\r\nHOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_WITH_TENSORFLOW=1 pip install --user --no-cache-dir horovod\r\n```\r\n\r\n\r\nIssue:\r\n```\r\n    ...\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/common/half.cc -o build/temp.linux-x86_64-3.6/horovod/common/half.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    In file included from horovod/common/half.cc:16:0:\r\n    horovod/common/half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/common/mpi/mpi_context.cc -o build/temp.linux-x86_64-3.6/horovod/common/mpi/mpi_context.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    In file included from horovod/common/mpi/mpi_context.h:25:0,\r\n                     from horovod/common/mpi/mpi_context.cc:17:\r\n    horovod/common/mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/common/mpi/mpi_controller.cc -o build/temp.linux-x86_64-3.6/horovod/common/mpi/mpi_controller.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    In file included from horovod/common/mpi/mpi_context.h:25:0,\r\n                     from horovod/common/mpi/mpi_controller.h:19,\r\n                     from horovod/common/mpi/mpi_controller.cc:16:\r\n    horovod/common/mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/common/ops/mpi_operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/mpi_operations.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    In file included from horovod/common/ops/../mpi/mpi_context.h:25:0,\r\n                     from horovod/common/ops/mpi_operations.h:27,\r\n                     from horovod/common/ops/mpi_operations.cc:17:\r\n    horovod/common/ops/../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/ops/../mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/common/gloo/gloo_context.cc -o build/temp.linux-x86_64-3.6/horovod/common/gloo/gloo_context.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    In file included from horovod/common/gloo/../mpi/mpi_context.h:25:0,\r\n                     from horovod/common/gloo/gloo_context.h:25,\r\n                     from horovod/common/gloo/gloo_context.cc:16:\r\n    horovod/common/gloo/../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/gloo/../mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/common/gloo/gloo_controller.cc -o build/temp.linux-x86_64-3.6/horovod/common/gloo/gloo_controller.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    In file included from horovod/common/gloo/../mpi/mpi_context.h:25:0,\r\n                     from horovod/common/gloo/gloo_context.h:25,\r\n                     from horovod/common/gloo/gloo_controller.h:19,\r\n                     from horovod/common/gloo/gloo_controller.cc:16:\r\n    horovod/common/gloo/../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/gloo/../mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/common/gloo/http_store.cc -o build/temp.linux-x86_64-3.6/horovod/common/gloo/http_store.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/common/gloo/memory_store.cc -o build/temp.linux-x86_64-3.6/horovod/common/gloo/memory_store.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/common/ops/gloo_operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/gloo_operations.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    In file included from horovod/common/ops/../gloo/../mpi/mpi_context.h:25:0,\r\n                     from horovod/common/ops/../gloo/gloo_context.h:25,\r\n                     from horovod/common/ops/gloo_operations.h:20,\r\n                     from horovod/common/ops/gloo_operations.cc:16:\r\n    horovod/common/ops/../gloo/../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/ops/../gloo/../mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    In file included from horovod/common/ops/gloo_operations.cc:22:0:\r\n    third_party/gloo/gloo/math.h: In instantiation of \u2018void gloo::sum(void*, const void*, const void*, size_t) [with T = bool; size_t = long unsigned int]\u2019:\r\n    horovod/common/ops/gloo_operations.cc:69:68:   required from \u2018void horovod::common::GlooAlgorithms<T>::Allreduce(void*, int) [with T = bool]\u2019\r\n    horovod/common/ops/gloo_operations.cc:279:1:   required from here\r\n    third_party/gloo/gloo/math.h:20:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       for (auto i = 0; i < n; i++) {\r\n                          ^\r\n    third_party/gloo/gloo/math.h: In instantiation of \u2018void gloo::sum(void*, const void*, const void*, size_t) [with T = double; size_t = long unsigned int]\u2019:\r\n    horovod/common/ops/gloo_operations.cc:69:68:   required from \u2018void horovod::common::GlooAlgorithms<T>::Allreduce(void*, int) [with T = double]\u2019\r\n    horovod/common/ops/gloo_operations.cc:279:1:   required from here\r\n    third_party/gloo/gloo/math.h:20:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n    third_party/gloo/gloo/math.h: In instantiation of \u2018void gloo::sum(void*, const void*, const void*, size_t) [with T = float; size_t = long unsigned int]\u2019:\r\n    horovod/common/ops/gloo_operations.cc:69:68:   required from \u2018void horovod::common::GlooAlgorithms<T>::Allreduce(void*, int) [with T = float]\u2019\r\n    horovod/common/ops/gloo_operations.cc:279:1:   required from here\r\n    third_party/gloo/gloo/math.h:20:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n    third_party/gloo/gloo/math.h: In instantiation of \u2018void gloo::sum(void*, const void*, const void*, size_t) [with T = gloo::float16; size_t = long unsigned int]\u2019:\r\n    horovod/common/ops/gloo_operations.cc:69:68:   required from \u2018void horovod::common::GlooAlgorithms<T>::Allreduce(void*, int) [with T = gloo::float16]\u2019\r\n    horovod/common/ops/gloo_operations.cc:279:1:   required from here\r\n    third_party/gloo/gloo/math.h:20:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n    third_party/gloo/gloo/math.h: In instantiation of \u2018void gloo::sum(void*, const void*, const void*, size_t) [with T = long int; size_t = long unsigned int]\u2019:\r\n    horovod/common/ops/gloo_operations.cc:69:68:   required from \u2018void horovod::common::GlooAlgorithms<T>::Allreduce(void*, int) [with T = long int]\u2019\r\n    horovod/common/ops/gloo_operations.cc:279:1:   required from here\r\n    third_party/gloo/gloo/math.h:20:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n    third_party/gloo/gloo/math.h: In instantiation of \u2018void gloo::sum(void*, const void*, const void*, size_t) [with T = int; size_t = long unsigned int]\u2019:\r\n    horovod/common/ops/gloo_operations.cc:69:68:   required from \u2018void horovod::common::GlooAlgorithms<T>::Allreduce(void*, int) [with T = int]\u2019\r\n    horovod/common/ops/gloo_operations.cc:279:1:   required from here\r\n    third_party/gloo/gloo/math.h:20:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n    third_party/gloo/gloo/math.h: In instantiation of \u2018void gloo::sum(void*, const void*, const void*, size_t) [with T = short int; size_t = long unsigned int]\u2019:\r\n    horovod/common/ops/gloo_operations.cc:69:68:   required from \u2018void horovod::common::GlooAlgorithms<T>::Allreduce(void*, int) [with T = short int]\u2019\r\n    horovod/common/ops/gloo_operations.cc:279:1:   required from here\r\n    third_party/gloo/gloo/math.h:20:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n    third_party/gloo/gloo/math.h: In instantiation of \u2018void gloo::sum(void*, const void*, const void*, size_t) [with T = short unsigned int; size_t = long unsigned int]\u2019:\r\n    horovod/common/ops/gloo_operations.cc:69:68:   required from \u2018void horovod::common::GlooAlgorithms<T>::Allreduce(void*, int) [with T = short unsigned int]\u2019\r\n    horovod/common/ops/gloo_operations.cc:279:1:   required from here\r\n    third_party/gloo/gloo/math.h:20:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n    third_party/gloo/gloo/math.h: In instantiation of \u2018void gloo::sum(void*, const void*, const void*, size_t) [with T = signed char; size_t = long unsigned int]\u2019:\r\n    horovod/common/ops/gloo_operations.cc:69:68:   required from \u2018void horovod::common::GlooAlgorithms<T>::Allreduce(void*, int) [with T = signed char]\u2019\r\n    horovod/common/ops/gloo_operations.cc:279:1:   required from here\r\n    third_party/gloo/gloo/math.h:20:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n    third_party/gloo/gloo/math.h: In instantiation of \u2018void gloo::sum(void*, const void*, const void*, size_t) [with T = unsigned char; size_t = long unsigned int]\u2019:\r\n    horovod/common/ops/gloo_operations.cc:69:68:   required from \u2018void horovod::common::GlooAlgorithms<T>::Allreduce(void*, int) [with T = unsigned char]\u2019\r\n    horovod/common/ops/gloo_operations.cc:279:1:   required from here\r\n    third_party/gloo/gloo/math.h:20:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/common/ops/cuda_operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/cuda_operations.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/common/ops/mpi_cuda_operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/mpi_cuda_operations.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    In file included from horovod/common/ops/../mpi/mpi_context.h:25:0,\r\n                     from horovod/common/ops/mpi_cuda_operations.h:21,\r\n                     from horovod/common/ops/mpi_cuda_operations.cc:17:\r\n    horovod/common/ops/../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/ops/../mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/common/ops/nccl_operations.cc -o build/temp.linux-x86_64-3.6/horovod/common/ops/nccl_operations.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    In file included from horovod/common/ops/../mpi/mpi_context.h:25:0,\r\n                     from horovod/common/ops/nccl_operations.h:23,\r\n                     from horovod/common/ops/nccl_operations.cc:17:\r\n    horovod/common/ops/../mpi/../half.h: In function \u2018void horovod::common::HalfBits2Float(short unsigned int*, float*)\u2019:\r\n    horovod/common/ops/../mpi/../half.h:70:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n       *res = *reinterpret_cast<float const*>(&f);\r\n                                                ^\r\n    /usr/bin/gcc-5 -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_MPI=1 -DHAVE_GLOO=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/usr/local/cuda/include -I/home/ubuntu/anaconda3/include/python3.6m -c horovod/tensorflow/mpi_ops.cc -o build/temp.linux-x86_64-3.6/horovod/tensorflow/mpi_ops.o -std=c++11 -fPIC -O2 -Wall -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/anaconda3/include -pthread -Wl,-rpath -Wl,/home/ubuntu/anaconda3/lib -Wl,--enable-new-dtags -L/home/ubuntu/anaconda3/lib -lmpi_cxx -lmpi -I/home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def_builder.h:24:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def.pb.h:35:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def_builder.h:24,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/attr_value.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/attr_value.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/attr_value.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/attr_value.pb.h:38:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def.pb.h:35,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def_builder.h:24,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor.pb.h:35:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/attr_value.pb.h:38,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def.pb.h:35,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def_builder.h:24,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/resource_handle.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/resource_handle.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/resource_handle.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/resource_handle.pb.h:35:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor.pb.h:35,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/attr_value.pb.h:38,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def.pb.h:35,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def_builder.h:24,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_shape.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_shape.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_shape.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/resource_handle.pb.h:36:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor.pb.h:35,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/attr_value.pb.h:38,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def.pb.h:35,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def_builder.h:24,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/types.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/types.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/types.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/lib/core/status.h:23:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def_builder.h:25,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/lib/core/error_codes.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/lib/core/error_codes.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/lib/core/error_codes.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def_util.h:23:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op.h:24,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/api_def.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/api_def.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/api_def.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:29:0,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/graph.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/graph.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/graph.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/graph.pb.h:35:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:29,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/node_def.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/node_def.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/node_def.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/graph.pb.h:36:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:29,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/function.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/function.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/function.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/graph.pb.h:37:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:29,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/versions.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/versions.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/versions.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:30:0,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/kernel_def.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/kernel_def.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/kernel_def.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:56:0,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/config.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/config.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/config.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/config.pb.h:39:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:56,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/cost_graph.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/cost_graph.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/cost_graph.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/config.pb.h:41:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:56,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/step_stats.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/step_stats.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/step_stats.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/step_stats.pb.h:38:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/config.pb.h:41,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:56,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/allocation_description.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/allocation_description.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/allocation_description.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/step_stats.pb.h:39:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/config.pb.h:41,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:56,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_description.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_description.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_description.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/config.pb.h:42:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:56,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/cluster.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/cluster.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/cluster.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/config.pb.h:43:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:56,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/debug.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/debug.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/debug.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/config.pb.h:44:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:56,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/rewriter_config.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/rewriter_config.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/rewriter_config.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/rewriter_config.pb.h:40:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/config.pb.h:44,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:56,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/verifier_config.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/verifier_config.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/protobuf/verifier_config.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/stream_executor/dnn.h:34:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/stream_executor/stream.h:32,\r\n                     from horovod/tensorflow/mpi_ops.cc:29:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/stream_executor/dnn.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/stream_executor/dnn.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers. Please update\r\n      ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/stream_executor/dnn.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/resource_handle.pb.h:35:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor.pb.h:35,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/attr_value.pb.h:38,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def.pb.h:35,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def_builder.h:24,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_shape.pb.h:38:1: error: \u2018PROTOBUF_NAMESPACE_OPEN\u2019 does not name a type\r\n     PROTOBUF_NAMESPACE_OPEN\r\n     ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_shape.pb.h:42:1: error: \u2018PROTOBUF_NAMESPACE_CLOSE\u2019 does not name a type\r\n     PROTOBUF_NAMESPACE_CLOSE\r\n     ^\r\n    In file included from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/resource_handle.pb.h:35:0,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor.pb.h:35,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/attr_value.pb.h:38,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def.pb.h:35,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op_def_builder.h:24,\r\n                     from /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_shape.pb.h:65:1: error: \u2018PROTOBUF_NAMESPACE_OPEN\u2019 does not name a type\r\n     PROTOBUF_NAMESPACE_OPEN\r\n     ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_shape.pb.h:67:48: error: \u2018Arena\u2019 has not been declared\r\n     template<> ::tensorflow::TensorShapeProto_Dim* Arena::CreateMaybeMessage<::tensorflow::TensorShapeProto_Dim>(Arena*);\r\n                                                    ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_shape.pb.h:67:73: error: expected initializer before \u2018<\u2019 token\r\n     template<> ::tensorflow::TensorShapeProto_Dim* Arena::CreateMaybeMessage<::tensorflow::TensorShapeProto_Dim>(Arena*);\r\n                                                                             ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_shape.pb.h:68:1: error: \u2018PROTOBUF_NAMESPACE_CLOSE\u2019 does not name a type\r\n     PROTOBUF_NAMESPACE_CLOSE\r\n     ^\r\n    /home/ubuntu/env/t15/lib/python3.6/site-packages/tensorflow_core/include/tensorflow/core/framework/tensor_shape.pb.h:396:30: error: expected declaration before end of line\r\n    error: command '/usr/bin/gcc-5' failed with exit status 1\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /home/ubuntu/env/t15/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-dl54mun7/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-dl54mun7/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-xbrj1hw0/install-record.txt --single-version-externally-managed --compile --install-headers /home/ubuntu/env/t15/include/site/python3.6/horovod Check the logs for full command output.\r\n```\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1492/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1492/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1490", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1490/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1490/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1490/events", "html_url": "https://github.com/horovod/horovod/issues/1490", "id": 515940891, "node_id": "MDU6SXNzdWU1MTU5NDA4OTE=", "number": 1490, "title": "pytorch multi optimizer error", "user": {"login": "jasstionzyf", "id": 5241459, "node_id": "MDQ6VXNlcjUyNDE0NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/5241459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasstionzyf", "html_url": "https://github.com/jasstionzyf", "followers_url": "https://api.github.com/users/jasstionzyf/followers", "following_url": "https://api.github.com/users/jasstionzyf/following{/other_user}", "gists_url": "https://api.github.com/users/jasstionzyf/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasstionzyf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasstionzyf/subscriptions", "organizations_url": "https://api.github.com/users/jasstionzyf/orgs", "repos_url": "https://api.github.com/users/jasstionzyf/repos", "events_url": "https://api.github.com/users/jasstionzyf/events{/privacy}", "received_events_url": "https://api.github.com/users/jasstionzyf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-01T06:43:29Z", "updated_at": "2019-11-01T07:04:24Z", "closed_at": "2019-11-01T07:02:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "i want to apply different learning rate at different layers within one model, so i write following code:\r\n  ```\r\n     optimizers=[]\r\n      for layerName, lr in layersLrMap.items():\r\n            layer = getattr(model, layerName)\r\n\r\n            optimizer = optim.Adam(layer.parameters(), lr=lr * pt_hvd.size())\r\n            optimizer = pt_hvd.DistributedOptimizer(optimizer, named_parameters=layer.named_parameters(),\r\n                                                    compression=compression)\r\n            optimizers.append(optimizer)\r\n```\r\nthen \r\n```\r\n loss.backward()\r\n             for optimizer in optimizers:\r\n                 optimizer.step()\r\n```\r\nbut throw error:\r\n```\r\nFile \"/data/conda/imageAI/lib/python3.7/site-packages/torch/tensor.py\", line 118, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n  File \"/data/conda/imageAI/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 93, in backward\r\n    allow_unreachable=True)  # allow_unreachable flag\r\n  File \"/data/conda/imageAI/lib/python3.7/site-packages/horovod/torch/__init__.py\", line 141, in hook\r\n    handle, ctx = self._allreduce_grad_async(p)\r\n  File \"/data/conda/imageAI/lib/python3.7/site-packages/horovod/torch/__init__.py\", line 124, in _allreduce_grad_async\r\n    handle = allreduce_async_(tensor_compressed, average=True, name=name)\r\n  File \"/data/conda/imageAI/lib/python3.7/site-packages/horovod/torch/mpi_ops.py\", line 183, in allreduce_async_\r\n    return _allreduce_async(tensor, tensor, average, name)\r\n  File \"/data/conda/imageAI/lib/python3.7/site-packages/horovod/torch/mpi_ops.py\", line 88, in _allreduce_async\r\n    name.encode() if name is not None else _NULL)\r\nValueError: Requested to allreduce, allgather, or broadcast a tensor with the same name as another tensor that is currently being processed.  If you want to request another tensor, use a different tensor name.\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1490/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1490/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1469", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1469/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1469/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1469/events", "html_url": "https://github.com/horovod/horovod/issues/1469", "id": 512190462, "node_id": "MDU6SXNzdWU1MTIxOTA0NjI=", "number": 1469, "title": "Setup.py fails to detect the correct tensorflow 1.15.0 ABI", "user": {"login": "hanyucui", "id": 9649417, "node_id": "MDQ6VXNlcjk2NDk0MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/9649417?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hanyucui", "html_url": "https://github.com/hanyucui", "followers_url": "https://api.github.com/users/hanyucui/followers", "following_url": "https://api.github.com/users/hanyucui/following{/other_user}", "gists_url": "https://api.github.com/users/hanyucui/gists{/gist_id}", "starred_url": "https://api.github.com/users/hanyucui/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hanyucui/subscriptions", "organizations_url": "https://api.github.com/users/hanyucui/orgs", "repos_url": "https://api.github.com/users/hanyucui/repos", "events_url": "https://api.github.com/users/hanyucui/events{/privacy}", "received_events_url": "https://api.github.com/users/hanyucui/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-24T21:28:11Z", "updated_at": "2019-10-25T16:25:27Z", "closed_at": "2019-10-25T16:25:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.15.0\r\n3. Horovod version: 0.18.1\r\n4. MPI version: 3.0.0\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.7.3\r\n8. OS and version: Ubuntu 16.04\r\n9. GCC version: 7.4\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nI installed tensorflow 1.15.0 (`tf.version.COMPILER_VERSION` shows `7.3.1 20180303`) and then installed horovod 0.18.1. After that, I got an undefined symbol error when running tests: `tensorflow::OpKernel::name[abi:cxx11]() const` (unmangled). However, I found this version of tensorflow was compiled with the older ABI and only `tensorflow::OpKernel::name() const` (non cxx11) exists. And I have to apply this [patch](https://github.com/hanyucui/horovod/pull/1) to force horovod use the older ABI. I suspect there is a bug in the ABI detection code. \r\n\r\nI dug deeper and found tensorflow actually has two definitions for that function built against different ABIs (using the `nm` command):\r\n- `0000000000cf2b80 T tensorflow::OpKernel::name[abi:cxx11]() const` (lib/python3.7/site-packages/tensorflow/libtensorflow_framework.so.1)\r\n- `0000000000c6c100 T tensorflow::OpKernel::name() const` (lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1)\r\n\r\nI suspect Horovod is trying to load the one in `tensorflow_core/`, which uses the old (pre-C++11) ABI.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1469/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1469/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1468", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1468/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1468/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1468/events", "html_url": "https://github.com/horovod/horovod/issues/1468", "id": 512133774, "node_id": "MDU6SXNzdWU1MTIxMzM3NzQ=", "number": 1468, "title": "Installation with TensorFlow support failed on Mac OS", "user": {"login": "zarzen", "id": 1150493, "node_id": "MDQ6VXNlcjExNTA0OTM=", "avatar_url": "https://avatars.githubusercontent.com/u/1150493?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zarzen", "html_url": "https://github.com/zarzen", "followers_url": "https://api.github.com/users/zarzen/followers", "following_url": "https://api.github.com/users/zarzen/following{/other_user}", "gists_url": "https://api.github.com/users/zarzen/gists{/gist_id}", "starred_url": "https://api.github.com/users/zarzen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zarzen/subscriptions", "organizations_url": "https://api.github.com/users/zarzen/orgs", "repos_url": "https://api.github.com/users/zarzen/repos", "events_url": "https://api.github.com/users/zarzen/events{/privacy}", "received_events_url": "https://api.github.com/users/zarzen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-10-24T19:21:49Z", "updated_at": "2019-10-28T18:14:40Z", "closed_at": "2019-10-28T18:14:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.14\r\n3. Horovod version: 0.18.2\r\n4. MPI version: 4.0.2\r\n5. CUDA version: X\r\n6. NCCL version: X\r\n7. Python version: 3.7.1\r\n8. OS and version: Mac Catalina\r\n9. GCC version: clang version 11.0.0\r\n\r\n**Bug report:**\r\nInstallation through `HOROVOD_WITH_TENSORFLOW=1 pip install horovod` fails, because of following error:\r\n```\r\n-L/Users/zarzen/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow -l:libtensorflow_framework.1.dylib\r\n    ld: library not found for -l:libtensorflow_framework.1.dylib\r\n```\r\n\r\nI think the problem is due to the `-l` flag: `-l:libtensorflow_framework.1.dylib` should be `-ltensorflow_framework`. \r\n\r\nI changed the `setup.py` at [line249](https://github.com/horovod/horovod/blob/master/setup.py#L249) as following to get it successfully installed on my laptop. \r\n```\r\nlink_flags = ['-L/Users/zarzen/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow', '-ltensorflow_framework']\r\n        return tf.sysconfig.get_compile_flags(), link_flags\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1468/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1468/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1437", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1437/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1437/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1437/events", "html_url": "https://github.com/horovod/horovod/issues/1437", "id": 504944334, "node_id": "MDU6SXNzdWU1MDQ5NDQzMzQ=", "number": 1437, "title": "DistributedOptimzer is not compatible with keras.Optimizer", "user": {"login": "yselivonchyk", "id": 4716569, "node_id": "MDQ6VXNlcjQ3MTY1Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/4716569?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yselivonchyk", "html_url": "https://github.com/yselivonchyk", "followers_url": "https://api.github.com/users/yselivonchyk/followers", "following_url": "https://api.github.com/users/yselivonchyk/following{/other_user}", "gists_url": "https://api.github.com/users/yselivonchyk/gists{/gist_id}", "starred_url": "https://api.github.com/users/yselivonchyk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yselivonchyk/subscriptions", "organizations_url": "https://api.github.com/users/yselivonchyk/orgs", "repos_url": "https://api.github.com/users/yselivonchyk/repos", "events_url": "https://api.github.com/users/yselivonchyk/events{/privacy}", "received_events_url": "https://api.github.com/users/yselivonchyk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-10-09T23:17:32Z", "updated_at": "2019-10-13T20:55:10Z", "closed_at": "2019-10-13T20:55:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version: 1.14\r\n3. Horovod version: 0.16.4\r\n7. Python version: 3.6.8\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\nHorovod DistributedOptimzer wrapper is not compatible with keras:\r\n\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nimport horovod.tensorflow.keras as hvd\r\n\r\nhvd.init()\r\nopt = tf.keras.optimizers.Adam()\r\nhopt = hvd.DistributedOptimizer(opt)\r\nopt.get_config()\r\ncfg = hopt.get_config()\r\nopt_copy = opt.from_config(cfg)\r\nopt_copy = opt.__class__.from_config(cfg)\r\nhopt_copy = hopt.from_config(cfg) # TypeError: __init__() got an unexpected keyword argument 'learning_rate'\r\nhopt_copy = hopt.__class__.from_config(cfg) # TypeError: __init__() got an unexpected keyword argument 'learning_rate'\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1437/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1437/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1431", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1431/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1431/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1431/events", "html_url": "https://github.com/horovod/horovod/issues/1431", "id": 504036050, "node_id": "MDU6SXNzdWU1MDQwMzYwNTA=", "number": 1431, "title": "Horovod hang when running cpu training in two nodes", "user": {"login": "Keepmoving-ZXY", "id": 19542656, "node_id": "MDQ6VXNlcjE5NTQyNjU2", "avatar_url": "https://avatars.githubusercontent.com/u/19542656?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Keepmoving-ZXY", "html_url": "https://github.com/Keepmoving-ZXY", "followers_url": "https://api.github.com/users/Keepmoving-ZXY/followers", "following_url": "https://api.github.com/users/Keepmoving-ZXY/following{/other_user}", "gists_url": "https://api.github.com/users/Keepmoving-ZXY/gists{/gist_id}", "starred_url": "https://api.github.com/users/Keepmoving-ZXY/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Keepmoving-ZXY/subscriptions", "organizations_url": "https://api.github.com/users/Keepmoving-ZXY/orgs", "repos_url": "https://api.github.com/users/Keepmoving-ZXY/repos", "events_url": "https://api.github.com/users/Keepmoving-ZXY/events{/privacy}", "received_events_url": "https://api.github.com/users/Keepmoving-ZXY/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-10-08T13:12:41Z", "updated_at": "2019-10-15T06:09:00Z", "closed_at": "2019-10-15T06:09:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)TensorFlow\r\n2. Framework version:1.14.0\r\n3. Horovod version:0.18.1\r\n4. MPI version:3.1.3\r\n5. CUDA version:N/A\r\n6. NCCL version:N/A\r\n7. Python version:2.7.16\r\n8. OS and version:CentOS Linux release 7.5.1804 (Core)  \r\n9. GCC version:7.3.0\r\n\r\nHi, these days I run distributed cpu training with horovod and intel mkl support in two cpu nodes, the base environment is `Anaconda 2`.  After I install `Anaconda2`, I install tensorflow and horovod using below command in the two cpu nodes:  \r\n```\r\n# faster anaconda source\r\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\r\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/\r\nconda config --set show_channel_urls yes\r\n\r\n# install tensorflow with mkl support.\r\nconda install tensorflow\r\n\r\n# upgrade gcc to 7.\r\nscl enable devtoolset-7 bash\r\n\r\n# compile horovod.\r\nexport PATH=$PATH:/usr/lib64/openmpi3/bin\r\nexport LD_LIBRARY_PATH=/usr/lib64/openmpi3/lib:$LD_LIBRARY_PATH\r\n\r\npip uninstall horovod\r\nconda install gcc_linux-64 gxx_linux-64\r\nconda run pip install --no-cache-dir horovod\r\n````\r\n\r\nAfter install, I run horovod train with below command:\r\n```\r\n#!/bin/bash\r\n\r\n# set -e\r\n# set -x\r\n\r\nLOG_BASE=\"/root/tensorflow_log\"\r\nDATE=`date '+%Y-%m-%d'`\r\nLOG_DIR=\"${LOG_BASE}/${DATE}\"\r\n\r\nif [ ! -d \"${LOG_DIR}\" ]; then\r\n    mkdir -p ${LOG_DIR}\r\nelse\r\n    echo \"LOG DIR ${LOG_DIR} already exist\"\r\nfi\r\n\r\n# log file\r\nPID=$$\r\nDATE=`date '+%H-%M-%S'`\r\nFILE_NAME=\"horovod_${PID}_${DATE}.txt\"\r\nLOG_FILE=\"${LOG_DIR}/${FILE_NAME}\"\r\necho \"LOG_FILE: $LOG_FILE\"\r\n\r\nstart=$(date +%s)\r\necho \"start: $start\"\r\n\r\necho 1 > /proc/sys/vm/compact_memory\r\necho 3 > /proc/sys/vm/drop_caches\r\necho 100 > /sys/devices/system/cpu/intel_pstate/min_perf_pct\r\necho 0 > /sys/devices/system/cpu/intel_pstate/no_turbo\r\necho 0 > /proc/sys/kernel/numa_balancing\r\nexport HOROVOD_FUSION_THRESHOLD=134217728\r\nexport OMP_NUM_THREADS=8\r\n\r\nCOMMON_ARGS=\"\\\r\n        --batch_size=128 \\\r\n        --model=resnet50 \\\r\n        --display_every=5 \\\r\n        --data_format=NCHW \\\r\n        --optimizer=momentum \\\r\n        --device=cpu \\\r\n        --mkl=TRUE \\\r\n        --variable_update=horovod \\\r\n        --horovod_device=cpu \\\r\n        --local_parameter_device=cpu \\\r\n        --kmp_blocktime=1\"\r\n\r\n/usr/lib64/openmpi3/bin/mpirun -np 8 --allow-run-as-root \\\r\n        -H 192.168.1.137,192.168.1.138 \\\r\n        --map-by ppr:2:socket,pe=${OMP_NUM_THREADS} \\\r\n        --report-bindings \\\r\n        --oversubscribe \\\r\n        -x HOROVOD_MPI_THREADS_DISABLE=1 \\\r\n        -x HOROVOD_GLOO_IFACE=eno1 \\\r\n        -x HOROVOD_FUSION_THRESHOLD \\\r\n        -x LD_LIBRARY_PATH \\\r\n        -x PATH \\\r\n        -x OMP_NUM_THREADS \\\r\n        /root/anaconda2/bin/python2 /root/zls/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py  $COMMON_ARGS \\\r\n        --num_intra_threads=${OMP_NUM_THREADS} 2>&1 | tee ${LOG_FILE}\r\n\r\nend=$(date +%s)\r\necho \"end: $end\"\r\n\r\nelapse=$((end-start))\r\n\r\necho \"TRAINING TIME: $elapse seconds\"\r\n\r\necho \"\" >> ${LOG_FILE}\r\necho \"TRAINING TIME: $elapse seconds\" >> ${LOG_FILE}\r\necho \"LOG SAVES TO: ${LOG_FILE}\"\r\n```\r\n\r\nafter run this script, `openmpi` create 8 processes, 4 in `192.168.1.137` and 4 in `192.168.1.138`. I find that any process in `192.168.1.137`  hang all the time, below is stack when hang occurs:\r\n```\r\n#0  0x00007f1fc1fbdf3d in nanosleep () from /lib64/libpthread.so.0\r\n#1  0x00007f1f7ed53ca5 in horovod::common::(anonymous namespace)::InitializeHorovodOnce(int const*, int) ()\r\n   from /root/anaconda2/lib/python2.7/site-packages/horovod/tensorflow/mpi_lib.so\r\n#2  0x00007f1fba4f5ec0 in ffi_call_unix64 () from /root/anaconda2/lib/python2.7/lib-dynload/../../libffi.so.6\r\n#3  0x00007f1fba4f587d in ffi_call () from /root/anaconda2/lib/python2.7/lib-dynload/../../libffi.so.6\r\n#4  0x00007f1fba70c99e in _ctypes_callproc () from /root/anaconda2/lib/python2.7/lib-dynload/_ctypes.so\r\n#5  0x00007f1fba702b61 in PyCFuncPtr_call () from /root/anaconda2/lib/python2.7/lib-dynload/_ctypes.so\r\n#6  0x00007f1fc2255b73 in PyObject_Call () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#7  0x00007f1fc22ec119 in PyEval_EvalFrameEx () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#8  0x00007f1fc22f1a99 in PyEval_EvalCodeEx () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#9  0x00007f1fc22eef68 in PyEval_EvalFrameEx () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#10 0x00007f1fc22f1a99 in PyEval_EvalCodeEx () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#11 0x00007f1fc22eef68 in PyEval_EvalFrameEx () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#12 0x00007f1fc22f1a99 in PyEval_EvalCodeEx () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#13 0x00007f1fc22eef68 in PyEval_EvalFrameEx () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#14 0x00007f1fc22f1a99 in PyEval_EvalCodeEx () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#15 0x00007f1fc22eef68 in PyEval_EvalFrameEx () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#16 0x00007f1fc22f1a99 in PyEval_EvalCodeEx () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#17 0x00007f1fc22eef68 in PyEval_EvalFrameEx () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#18 0x00007f1fc22f1a99 in PyEval_EvalCodeEx () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#19 0x00007f1fc22f1cba in PyEval_EvalCode () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#20 0x00007f1fc230b01d in run_mod () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#21 0x00007f1fc230c1c8 in PyRun_FileExFlags () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#22 0x00007f1fc230d3e8 in PyRun_SimpleFileExFlags () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#23 0x00007f1fc231f67c in Py_Main () from /root/anaconda2/bin/../lib/libpython2.7.so.1.0\r\n#24 0x00007f1fc14fb445 in __libc_start_main () from /lib64/libc.so.6\r\n#25 0x000055a65f53d07f in _start () at ../sysdeps/x86_64/elf/start.S:103\r\n``` \r\nafter I checkout code of `InitializeHorovodOnce`, I think horovod is hanging on initialize of `openmpi`. and I find another thread has stack as below:\r\n```\r\n#0  0x00007f994e69756d in nanosleep () from /lib64/libc.so.6\r\n#1  0x00007f994e6c8404 in usleep () from /lib64/libc.so.6\r\n#2  0x00007f990b92f824 in ompi_mpi_init () from /usr/lib64/openmpi3/lib/libmpi.so.40\r\n#3  0x00007f990b959561 in PMPI_Init_thread () from /usr/lib64/openmpi3/lib/libmpi.so.40\r\n#4  0x00007f990be76345 in horovod::common::MPIContextManager::EnvInitialize(int) () from /root/anaconda2/lib/python2.7/site-packages/horovod/tensorflow/mpi_lib.so\r\n#5  0x00007f990be76b11 in horovod::common::MPIContext::Initialize(std::vector<int, std::allocator<int> > const&, horovod::common::MPIContextManager&) ()\r\n   from /root/anaconda2/lib/python2.7/site-packages/horovod/tensorflow/mpi_lib.so\r\n#6  0x00007f990be47a05 in horovod::common::(anonymous namespace)::BackgroundThreadLoop(horovod::common::HorovodGlobalState&) ()\r\n   from /root/anaconda2/lib/python2.7/site-packages/horovod/tensorflow/mpi_lib.so\r\n#7  0x00007f9925308408 in std::execute_native_thread_routine (__p=0x5612794a9350)\r\n    at /opt/conda/conda-bld/compilers_linux-64_1534514838838/work/.build/x86_64-conda_cos6-linux-gnu/src/gcc/libstdc++-v3/src/c++11/thread.cc:80\r\n#8  0x00007f994f0afe25 in start_thread () from /lib64/libpthread.so.0\r\n#9  0x00007f994e6d0bad in clone () from /lib64/libc.so.6\r\n```\r\nit seems that this thread will sleep forever which case `InitializeHorovodOnce` hang all the time. how can I deal with this problem? thank you.\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1431/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1431/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1428", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1428/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1428/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1428/events", "html_url": "https://github.com/horovod/horovod/issues/1428", "id": 502506294, "node_id": "MDU6SXNzdWU1MDI1MDYyOTQ=", "number": 1428, "title": "horovodrun with --hostfile option is not working", "user": {"login": "apeforest", "id": 6807113, "node_id": "MDQ6VXNlcjY4MDcxMTM=", "avatar_url": "https://avatars.githubusercontent.com/u/6807113?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apeforest", "html_url": "https://github.com/apeforest", "followers_url": "https://api.github.com/users/apeforest/followers", "following_url": "https://api.github.com/users/apeforest/following{/other_user}", "gists_url": "https://api.github.com/users/apeforest/gists{/gist_id}", "starred_url": "https://api.github.com/users/apeforest/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apeforest/subscriptions", "organizations_url": "https://api.github.com/users/apeforest/orgs", "repos_url": "https://api.github.com/users/apeforest/repos", "events_url": "https://api.github.com/users/apeforest/events{/privacy}", "received_events_url": "https://api.github.com/users/apeforest/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-10-04T08:38:07Z", "updated_at": "2019-12-26T18:29:05Z", "closed_at": "2019-12-26T18:29:05Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: MXNet\r\n2. Framework version: 1.5.1\r\n3. Horovod version: 0.18.2\r\n4. MPI version: 3.1.4\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.6\r\n7. Python version: 3.7.3\r\n8. OS and version: Ubuntu 16.04\r\n9. GCC version: 5.4\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nhorovodrun with --hostfile is not working if there are multiple hosts in the format:\r\n172.31.1.0 slots=8\r\n172.31.2.0 slots=8\r\n\r\nThe culprit is this PR: https://github.com/horovod/horovod/pull/1181\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1428/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1428/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1411", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1411/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1411/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1411/events", "html_url": "https://github.com/horovod/horovod/issues/1411", "id": 497571680, "node_id": "MDU6SXNzdWU0OTc1NzE2ODA=", "number": 1411, "title": "pytorch", "user": {"login": "molyswu", "id": 11438784, "node_id": "MDQ6VXNlcjExNDM4Nzg0", "avatar_url": "https://avatars.githubusercontent.com/u/11438784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/molyswu", "html_url": "https://github.com/molyswu", "followers_url": "https://api.github.com/users/molyswu/followers", "following_url": "https://api.github.com/users/molyswu/following{/other_user}", "gists_url": "https://api.github.com/users/molyswu/gists{/gist_id}", "starred_url": "https://api.github.com/users/molyswu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/molyswu/subscriptions", "organizations_url": "https://api.github.com/users/molyswu/orgs", "repos_url": "https://api.github.com/users/molyswu/repos", "events_url": "https://api.github.com/users/molyswu/events{/privacy}", "received_events_url": "https://api.github.com/users/molyswu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-09-24T09:33:46Z", "updated_at": "2019-09-26T09:12:58Z", "closed_at": "2019-09-26T09:11:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1411/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1411/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1409", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1409/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1409/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1409/events", "html_url": "https://github.com/horovod/horovod/issues/1409", "id": 497400503, "node_id": "MDU6SXNzdWU0OTc0MDA1MDM=", "number": 1409, "title": "SegFault when using horovod.mxnet.allgather", "user": {"login": "yjxiong", "id": 6830199, "node_id": "MDQ6VXNlcjY4MzAxOTk=", "avatar_url": "https://avatars.githubusercontent.com/u/6830199?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yjxiong", "html_url": "https://github.com/yjxiong", "followers_url": "https://api.github.com/users/yjxiong/followers", "following_url": "https://api.github.com/users/yjxiong/following{/other_user}", "gists_url": "https://api.github.com/users/yjxiong/gists{/gist_id}", "starred_url": "https://api.github.com/users/yjxiong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yjxiong/subscriptions", "organizations_url": "https://api.github.com/users/yjxiong/orgs", "repos_url": "https://api.github.com/users/yjxiong/repos", "events_url": "https://api.github.com/users/yjxiong/events{/privacy}", "received_events_url": "https://api.github.com/users/yjxiong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-09-24T01:08:00Z", "updated_at": "2020-07-13T18:30:00Z", "closed_at": "2020-07-13T18:30:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: MXNet\r\n2. Framework version: 1.5.0\r\n3. Horovod version: 0.18.1\r\n4. MPI version: 4.0.1\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.3.7\r\n7. Python version: 3.6.8\r\n8. OS and version: Linux 4.14.138-89.102.amzn1.x86_64 (EC2 instance on AWS)\r\n9. GCC version: 4.8.5\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? N/A\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? N/A\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? N/A\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nThe function `horovod.mxnet.allgather` will lead to `Segmentation fault: 11` when I use more than 1 worker. The minimal code block to reproduce the error is as below:\r\n```\r\nimport horovod.mxnet as hvd\r\nimport mxnet as mx\r\n\r\nhvd.init()\r\n\r\nctx = mx.gpu(hvd.local_rank())\r\n\r\nv = mx.nd.ones((100, 50), ctx=ctx)\r\n\r\nr = hvd.allgather(v)\r\n\r\nprint(r.shape)\r\nprint(r)\r\n```\r\n\r\nRunning it with the command `horovodrun -np 2 -H localhost:2 python3 test_allgather.py`  will result in stack traces pasted below:\r\n\r\n```\r\n[1,1]<stderr>:\r\n[1,1]<stderr>:Segmentation fault: 11\r\n[1,1]<stderr>:\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:Segmentation fault: 11\r\n[1,0]<stderr>:\r\n[1,1]<stderr>:Stack trace:\r\n[1,1]<stderr>:  [bt] (0) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2e6b160) [0x7f5c59089160]\r\n[1,1]<stderr>:  [bt] (1) /lib64/libc.so.6(+0x362f0) [0x7f5d3593b2f0]\r\n[1,1]<stderr>:  [bt] (2) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(void mxnet::CopyFromToImpl<mshadow::cpu, mshadow::gpu>(mxnet::NDArray const&, mxnet::NDArray const&, mxnet::RunContext, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&)+0x119) [0x7f5c589f7399]\r\n[1,1]<stderr>:  [bt] (3) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x27d9895) [0x7f5c589f7895]\r\n[1,1]<stderr>:  [bt] (4) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25c1ce1) [0x7f5c587dfce1]\r\n[1,1]<stderr>:  [bt] (5) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25c80c0) [0x7f5c587e60c0]\r\n[1,1]<stderr>:  [bt] (6) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25c8356) [0x7f5c587e6356]\r\n[1,1]<stderr>:  [bt] (7) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25c0444) [0x7f5c587de444]\r\n[1,1]<stderr>:  [bt] (8) /usr/lib64/libstdc++.so.6(+0xbb890) [0x7f5d29649890]\r\n[1,0]<stderr>:Stack trace:\r\n[1,0]<stderr>:  [bt] (0) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2e6b160) [0x7fd67db0b160]\r\n[1,0]<stderr>:  [bt] (1) /lib64/libc.so.6(+0x362f0) [0x7fd75a3bd2f0]\r\n[1,0]<stderr>:  [bt] (2) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(void mxnet::CopyFromToImpl<mshadow::cpu, mshadow::gpu>(mxnet::NDArray const&, mxnet::NDArray const&, mxnet::RunContext, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&)+0x119) [0x7fd67d479399]\r\n[1,0]<stderr>:  [bt] (3) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x27d9895) [0x7fd67d479895]\r\n[1,0]<stderr>:  [bt] (4) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25c1ce1) [0x7fd67d261ce1]\r\n[1,0]<stderr>:  [bt] (5) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25c80c0) [0x7fd67d2680c0]\r\n[1,0]<stderr>:  [bt] (6) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25c8356) [0x7fd67d268356]\r\n[1,0]<stderr>:  [bt] (7) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25c0444) [0x7fd67d260444]\r\n[1,0]<stderr>:  [bt] (8) /usr/lib64/libstdc++.so.6(+0xbb890) [0x7fd74f242890]\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:Segmentation fault: 11\r\n[1,0]<stderr>:\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] *** Process received signal ***\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] Signal: Aborted (6)\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] Signal code:  (-6)\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] [ 0] /lib64/libpthread.so.0(+0xf5e0)[0x7f5d363ea5e0]\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] [ 1] [1,1]<stderr>:/lib64/libc.so.6(gsignal+0x37)[0x7f5d3593b277]\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] [ 2] [1,1]<stderr>:/lib64/libc.so.6(abort+0x148)[0x7f5d3593c968]\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] [ 3] [1,1]<stderr>:/lib64/libc.so.6(+0x78d97)[0x7f5d3597dd97]\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] [ 4] [1,1]<stderr>:/lib64/libc.so.6(+0x814f9)[0x7f5d359864f9]\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] [ 5] [1,1]<stderr>:/usr/lib64/python3.6/dist-packages/horovod/mxnet/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common11NCCLContext8ShutDownEv+0xf6)[0x7f5c174dd346]\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] [ 6] [1,1]<stderr>:/usr/lib64/python3.6/dist-packages/horovod/mxnet/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0x53f38)[0x7f5c1748bf38]\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] [ 7] [1,1]<stderr>:/usr/lib64/libstdc++.so.6(+0xbb890)[0x7f5d29649890]\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] [ 8] /lib64/libpthread.so.0(+0x7de5)[0x7f5d363e2de5]\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] [1,1]<stderr>:[ 9] [1,1]<stderr>:/lib64/libc.so.6(clone+0x6d)[0x7f5d35a02f1d]\r\n[1,1]<stderr>:[ip-172-31-20-44:29671] *** End of error message ***\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun noticed that process rank 1 with PID 0 on node ip-172-31-20-44 exited on signal 6 (Aborted).\r\n--------------------------------------------------------------------------\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1409/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1409/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1385", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1385/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1385/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1385/events", "html_url": "https://github.com/horovod/horovod/issues/1385", "id": 490083099, "node_id": "MDU6SXNzdWU0OTAwODMwOTk=", "number": 1385, "title": "Daily build failed.", "user": {"login": "WeichenXu123", "id": 19235986, "node_id": "MDQ6VXNlcjE5MjM1OTg2", "avatar_url": "https://avatars.githubusercontent.com/u/19235986?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WeichenXu123", "html_url": "https://github.com/WeichenXu123", "followers_url": "https://api.github.com/users/WeichenXu123/followers", "following_url": "https://api.github.com/users/WeichenXu123/following{/other_user}", "gists_url": "https://api.github.com/users/WeichenXu123/gists{/gist_id}", "starred_url": "https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WeichenXu123/subscriptions", "organizations_url": "https://api.github.com/users/WeichenXu123/orgs", "repos_url": "https://api.github.com/users/WeichenXu123/repos", "events_url": "https://api.github.com/users/WeichenXu123/events{/privacy}", "received_events_url": "https://api.github.com/users/WeichenXu123/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-09-06T01:26:33Z", "updated_at": "2019-09-08T05:07:52Z", "closed_at": "2019-09-08T05:07:52Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "See https://buildkite.com/horovod/horovod/builds/1135\r\nTest on Tensorflow 2.0 were failed.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1385/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1385/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1383", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1383/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1383/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1383/events", "html_url": "https://github.com/horovod/horovod/issues/1383", "id": 489941352, "node_id": "MDU6SXNzdWU0ODk5NDEzNTI=", "number": 1383, "title": "mpi support via pip3 install ", "user": {"login": "vlimant", "id": 4989875, "node_id": "MDQ6VXNlcjQ5ODk4NzU=", "avatar_url": "https://avatars.githubusercontent.com/u/4989875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vlimant", "html_url": "https://github.com/vlimant", "followers_url": "https://api.github.com/users/vlimant/followers", "following_url": "https://api.github.com/users/vlimant/following{/other_user}", "gists_url": "https://api.github.com/users/vlimant/gists{/gist_id}", "starred_url": "https://api.github.com/users/vlimant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vlimant/subscriptions", "organizations_url": "https://api.github.com/users/vlimant/orgs", "repos_url": "https://api.github.com/users/vlimant/repos", "events_url": "https://api.github.com/users/vlimant/events{/privacy}", "received_events_url": "https://api.github.com/users/vlimant/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2019-09-05T18:59:16Z", "updated_at": "2019-09-12T15:57:59Z", "closed_at": "2019-09-12T15:57:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TF,keras\r\n2. Framework version: tensorflow-gpu==1.14.0 Keras==2.2.4\r\n3. Horovod version: 0.18.1\r\n4. MPI version: openmpi-3.1.0\r\n5. CUDA version: 10\r\n6. NCCL version: N/A\r\n7. Python version: 3.6.8\r\n8. OS and version: centos7\r\n9. GCC version: 4.8.5\r\n\r\n**Bug report:**\r\nI have extensively looked at the existing GH issues and other possible solutions out there.\r\nI am making a singularity image with all the packages I need for the environment, and\r\n\r\nHOROVOD_WITH_MPI=1 HOROVOD_GPU_ALLREDUCE=MPI HOROVOD_GPU_ALLGATHER=MPI HOROVOD_GPU_BROADCAST=MPI pip3 install --no-cache-dir horovod\r\n\r\nproduces\r\n\r\n> Successfully installed mpi4py-3.0.2\r\n> + mpicxx -show\r\n> g++ -I/opt/openmpi-3.1.0/include -pthread -Wl,-rpath -Wl,/opt/openmpi-3.1.0/lib -Wl,--enable-new-dtags -L/opt/openmpi-3.1.0/lib -lmpi\r\n> + HOROVOD_WITH_MPI=1\r\n> + HOROVOD_GPU_ALLREDUCE=MPI\r\n> + HOROVOD_GPU_ALLGATHER=MPI\r\n> + HOROVOD_GPU_BROADCAST=MPI\r\n> + pip3 install --no-cache-dir horovod\r\n> Collecting horovod\r\n>   Downloading https://files.pythonhosted.org/packages/8b/a0/27b00807e6ed78bcab146594acd680e6493d9e49b43ed1649ccf70e2a95d/horovod-0.18.1.tar.gz (2.8MB)\r\n>      |################################| 2.8MB 25.8MB/s\r\n> Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/site-packages (from horovod) (1.2.1)\r\n> Requirement already satisfied: psutil in /usr/local/lib64/python3.6/site-packages (from horovod) (5.6.3)\r\n> Requirement already satisfied: pyyaml in /usr/local/lib64/python3.6/site-packages (from horovod) (5.1.2)\r\n> Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from horovod) (1.12.0)\r\n> Requirement already satisfied: cffi>=1.4.0 in /usr/local/lib64/python3.6/site-packages (from horovod) (1.12.3)\r\n> Requirement already satisfied: pycparser in /usr/local/lib/python3.6/site-packages (from cffi>=1.4.0->horovod) (2.19)\r\n> Building wheels for collected packages: horovod\r\n>   Building wheel for horovod (setup.py) ... done\r\n>   Created wheel for horovod: filename=horovod-0.18.1-cp36-cp36m-linux_x86_64.whl size=5260519 sha256=fb13f18796fb4f8bd6e835c4a39b76bd37026e8cdc4d161cccca0411f6cf1652\r\n>   Stored in directory: /tmp/pip-ephem-wheel-cache-2t9bp34e/wheels/88/76/56/a6791c1aa449d2fda06a77192ce2fd99949eddd33d0cc1c1ef\r\n> Successfully built horovod\r\n> Installing collected packages: horovod\r\n> Successfully installed horovod-0.18.1\r\n\r\nat build time, and fails to get me a horovod with MPI support, as at runtime I get\r\n\r\n>   File \"/usr/local/lib64/python3.6/site-packages/horovod/common/basics.py\", line 46, in init\r\n>     'Horovod MPI is not enabled; Please make sure it\\'s installed and enabled.')\r\n> ValueError: Horovod MPI is not enabled; Please make sure it's installed and enabled.\r\n\r\ndo I have to build from source to get mpi support (and follow question with nccl once I get passed this issue). Apologies if this has been addressed already.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1383/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1383/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1381", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1381/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1381/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1381/events", "html_url": "https://github.com/horovod/horovod/issues/1381", "id": 489632122, "node_id": "MDU6SXNzdWU0ODk2MzIxMjI=", "number": 1381, "title": "hvd.init() hangs with error message help-opal-shmem-mmap.txt ", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-09-05T09:20:02Z", "updated_at": "2020-01-20T15:55:53Z", "closed_at": "2020-01-20T15:55:53Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.13.1, custom built without XLA\r\n3. Horovod version: 0.16.4\r\n4. MPI version: Open MPI 4.0.1\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.3.7-1+cuda10.0\r\n7. Python version: 2.7.12\r\n8. OS and version: Ubuntu 16.04.5 LTS\r\n9. GCC version: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609\r\n\r\nMellanox OFED 4.4-2.0.7.0 is installed.\r\n\r\n**Bug report:**\r\nRecently, our custom Horovod-based training code sometimes produces an error message after each worker rank called `hvd.init()`. The processes then hang without exiting. Here is the error message:\r\n```\r\n--------------------------------------------------------------------------\r\nA system call failed during shared memory initialization that should\r\nnot have.  It is likely that your MPI job will now either abort or\r\nexperience performance degradation.\r\n\r\n  Local host:  heinzel101\r\n  System call: open(2)\r\n  Error:       No such file or directory (errno 2)\r\n--------------------------------------------------------------------------\r\n[training_host:330371] 3 more processes have sent help message help-opal-shmem-mmap.txt / sys call fail\r\n[training_host:330371] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\r\n```\r\n\r\nWe start the training like this (5 local workers in this case): `mpirun --prefix /opt/openmpi -np 5 -H training_host:5 -bind-to none -map-by slot -x NCCL_DEBUG=INFO -x NCCL_DEBUG_FILE=/dev/stderr -x LD_LIBRARY_PATH -x PATH -mca pml ob1 -mca btl ^openib --tag-output --timestamp-output python [training_script]`.\r\n\r\nHere are gdb backtraces for all threads for one of the workers: https://gist.github.com/maxhgerlach/7e7ccbd16714c7a070156f88fce7d291 It looks like the hang is inside `BackgroundThreadLoop()` at line 929:\r\n```\r\n    // No ranks were given and no communicator provided to horovod_init() so use\r\n    // MPI_COMM_WORLD\r\n    MPI_Comm_dup(MPI_COMM_WORLD, &(ctx.mpi_comm));\r\n```\r\n\r\nAs in #1102 for each worker we still fork out a process via multiprocessing to do IO and preprocessing _before_ initializing Horovod or MPI in the parent process. Does the error sound as if it might be related to this?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1381/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1381/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1375", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1375/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1375/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1375/events", "html_url": "https://github.com/horovod/horovod/issues/1375", "id": 488289634, "node_id": "MDU6SXNzdWU0ODgyODk2MzQ=", "number": 1375, "title": "Bug", "user": {"login": "lucifer2503", "id": 46479501, "node_id": "MDQ6VXNlcjQ2NDc5NTAx", "avatar_url": "https://avatars.githubusercontent.com/u/46479501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucifer2503", "html_url": "https://github.com/lucifer2503", "followers_url": "https://api.github.com/users/lucifer2503/followers", "following_url": "https://api.github.com/users/lucifer2503/following{/other_user}", "gists_url": "https://api.github.com/users/lucifer2503/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucifer2503/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucifer2503/subscriptions", "organizations_url": "https://api.github.com/users/lucifer2503/orgs", "repos_url": "https://api.github.com/users/lucifer2503/repos", "events_url": "https://api.github.com/users/lucifer2503/events{/privacy}", "received_events_url": "https://api.github.com/users/lucifer2503/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-02T18:34:42Z", "updated_at": "2019-09-03T00:05:15Z", "closed_at": "2019-09-03T00:05:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1375/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1375/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1364", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1364/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1364/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1364/events", "html_url": "https://github.com/horovod/horovod/issues/1364", "id": 486966050, "node_id": "MDU6SXNzdWU0ODY5NjYwNTA=", "number": 1364, "title": "Multi machine example crashes when using GLOO controller. ", "user": {"login": "aaron276h", "id": 5969899, "node_id": "MDQ6VXNlcjU5Njk4OTk=", "avatar_url": "https://avatars.githubusercontent.com/u/5969899?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaron276h", "html_url": "https://github.com/aaron276h", "followers_url": "https://api.github.com/users/aaron276h/followers", "following_url": "https://api.github.com/users/aaron276h/following{/other_user}", "gists_url": "https://api.github.com/users/aaron276h/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaron276h/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaron276h/subscriptions", "organizations_url": "https://api.github.com/users/aaron276h/orgs", "repos_url": "https://api.github.com/users/aaron276h/repos", "events_url": "https://api.github.com/users/aaron276h/events{/privacy}", "received_events_url": "https://api.github.com/users/aaron276h/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2019-08-29T13:41:18Z", "updated_at": "2019-08-30T14:46:26Z", "closed_at": "2019-08-30T14:46:26Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) TF \r\n2. Framework version: 1.14.0\r\n3. Horovod version: Latest: `83eaa163b395ae8866a404f94facf82cc8127642`\r\n4. MPI version: N/A\r\n5. CUDA version: 10\r\n6. NCCL version: 2.4.7\r\n7. Python version: 3.6\r\n8. OS and version: ubuntu 16.04\r\n9. GCC version: 4.8\r\n\r\n\r\n**Bug report:**\r\nAfter installing Horovod without MPI (using GLOO controller), when I run the `tensorflow_keras_mnist` example on multiple machines I get an error. When run on multi-gpus within the same machine it works.\r\n\r\nNote: Running this inside docker containers, and have set up SSH between nodes. Have also ran `export HOROVOD_GLOO_IFACE=ens13`. \r\n\r\nAlso on a related question, why do we need to support SSH between machines when using a non MPI controller?\r\n\r\n```\r\nroot@aaron-host-1:/# NCCL_DEBUG=INFO horovodrun -np 2 -H aaron-host-1:1,aaron-host-3:1 -p 12345 python /home/aaronharlap/repos/horovod/examples/tensorflow_keras_mnist.py\r\nThu Aug 29 13:34:16 2019[0]<stderr>:WARNING: Logging before flag parsing goes to stderr.\r\nThu Aug 29 13:34:16 2019[0]<stderr>:W0829 13:34:16.496224 139811790628608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\r\nThu Aug 29 13:34:16 2019[0]<stderr>:\r\nThu Aug 29 13:34:16 2019[0]<stderr>:W0829 13:34:16.496506 139811790628608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\r\nThu Aug 29 13:34:16 2019[0]<stderr>:\r\nThu Aug 29 13:34:16 2019[1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\r\nThu Aug 29 13:34:16 2019[1]<stderr>:\r\nThu Aug 29 13:34:16 2019[1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\r\nThu Aug 29 13:34:16 2019[1]<stderr>:\r\nThu Aug 29 13:34:17 2019[0]<stderr>:terminate called after throwing an instance of 'gloo::EnforceNotMet'\r\nThu Aug 29 13:34:17 2019[0]<stderr>:  what():  [enforce fail at /tmp/pip-req-build-mg8d79w1/third_party/gloo/gloo/allgather.cc:31] context->getPair(recvRank). missing connection between rank 0 (this process) and rank 0\r\nThu Aug 29 13:34:17 2019[0]<stderr>:Fatal Python error: Aborted\r\nThu Aug 29 13:34:17 2019[0]<stderr>:\r\nThu Aug 29 13:34:17 2019[0]<stderr>:Thread 0x00007f28781da700 (most recent call first):\r\nThu Aug 29 13:34:17 2019[0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/horovod/common/basics.py\", line 60 in init\r\nThu Aug 29 13:34:17 2019[0]<stderr>:  File \"/home/aaronharlap/repos/horovod/examples/tensorflow_keras_mnist.py\", line 16 in <module>\r\nThu Aug 29 13:34:17 2019[1]<stderr>:terminate called after throwing an instance of 'gloo::EnforceNotMet'\r\nThu Aug 29 13:34:17 2019[1]<stderr>:  what():  [enforce fail at /tmp/pip-req-build-_xbb0q7w/third_party/gloo/gloo/allgather.cc:31] context->getPair(recvRank). missing connection between rank 0 (this process) and rank 0\r\nThu Aug 29 13:34:17 2019[1]<stderr>:Fatal Python error: Aborted\r\nThu Aug 29 13:34:17 2019[1]<stderr>:\r\nThu Aug 29 13:34:17 2019[1]<stderr>:Thread 0x00007f0bba97b700 (most recent call first):\r\nThu Aug 29 13:34:17 2019[1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/horovod/common/basics.py\", line 60 in init\r\nThu Aug 29 13:34:17 2019[1]<stderr>:  File \"/home/aaronharlap/repos/horovod/examples/tensorflow_keras_mnist.py\", line 16 in <module>\r\nThu Aug 29 13:34:17 2019[0]<stderr>:Aborted (core dumped)\r\nProcess 0 exit with status code 134.\r\nThu Aug 29 13:34:17 2019[1]<stderr>:bash: line 1:   211 Aborted                 (core dumped) HOROVOD_RANK=1 HOROVOD_SIZE=2 HOROVOD_LOCAL_RANK=0 HOROVOD_LOCAL_SIZE=1 HOROVOD_CROSS_RANK=1 HOROVOD_CROSS_SIZE=2 NCCL_DEBUG=INFO PEDL_TRIAL_SEED=295549675 CUDNN_VERSION=7.6.2.24 PEDL_HPARAMS='{\"batch_size\": 32, \"height_shift_range\": 0.1, \"horizontal_flip\": true, \"layer1_dropout\": 0.25, \"layer2_dropout\": 0.25, \"layer3_dropout\": 0.5, \"learning_rate\": 0.0001, \"learning_rate_decay\": 1e-06, \"width_shift_range\": 0.1}' PEDL_EXPERIMENT_ID=142 HOSTNAME=aaron-host-1 PEDL_MASTER_PORT=8080 NVIDIA_REQUIRE_CUDA='cuda>=10.0 brand=tesla,driver>=384,driver<385 brand=tesla,driver>=410,driver<411' PEDL_LATEST_CHECKPOINT=null PEDL_EXPERIMENT_CONFIG='{\"batches_per_step\": 100, \"bind_mounts\": [{\"container_path\": \"/home\", \"host_path\": \"/home\", \"propagation\": \"rprivate\", \"read_only\": false}], \"checkpoint_policy\": \"best\", \"checkpoint_storage\": {\"access_key\": \"AKIAJGK24F32WWJ25AEA\", \"bucket\": \"determined-ai-examples\", \"save_experiment_best\": 0, \"save_trial_best\": 1, \"save_trial_latest\": 1, \"secret_key\": \"08OM18juqj9p2ivz0kBkxsFVuY/yoC9A0fDHmSeA\", \"type\": \"s3\"}, \"data\": {\"acceleration\": {\"use_multiprocessing\": true, \"workers\": 1}, \"url\": \"https://s3-us-west-2.amazonaws.com/determined-ai-datasets/cifar10/cifar-10-python.tar.gz\"}, \"debug\": false, \"description\": \"cifar10_keras_const\", \"environment\": {\"cuda\": \"10.0\", \"custom_image\": null, \"debug\": \"none\", \"environment_variables\": {}, \"force_pull_image\": false, \"internal\": {\"inject_harness\": true}, \"keras\": \"2.2.4\", \"os\": \"ubuntu16.04\", \"ports\": null, \"python\": \"3.6.9\", \"pytorch\": \"1.0.1.post2\", \"registry_auth\": null, \"runtime_commands\": {}, \"runtime_packages\": {}, \"tensorflow\": \"1.14.0\"}, \"hyperparameters\": {\"batch_size\": {\"type\": \"const\", \"val\": 32}, \"height_shift_range\": {\"type\": \"const\", \"val\": 0.1}, \"horizontal_flip\": {\"type\": \"const\", \"val\": true}, \"layer1_dropout\": {\"type\": \"const\", \"val\": 0.25}, \"layer2_dropout\": {\"type\": \"const\", \"val\": 0.25}, \"layer3_dropout\": {\"type\": \"const\", \"val\": 0.5}, \"learning_rate\": {\"type\": \"const\", \"val\": 0.0001}, \"learning_rate_decay\": {\"type\": \"const\", \"val\": 1e-06}, \"width_shift_range\": {\"type\": \"const\", \"val\": 0.1}}, \"max_restarts\": 0, \"min_checkpoint_period\": null, \"min_validation_period\": null, \"reproducibility\": {\"experiment_seed\": 1567085116}, \"resources\": {\"distributed\": true, \"slots_per_trial\": 16, \"weight\": 1}, \"searcher\": {\"max_steps\": 50, \"metric\": \"validation_error\", \"name\": \"single\", \"smaller_is_better\": true, \"source_checkpoint_uuid\": null, \"source_trial_id\": null}}' PEDL_USE_GPU=True TERM=xterm PEDL_RENDEZVOUS_PORTS=1734,1742 PEDL_INITIAL_WORKLOAD='{\"kind\": \"RUN_STEP\", \"experiment_id\": 142, \"trial_id\": 140, \"step_id\": 1}' LIBRARY_PATH=/usr/local/cuda/lib64/stubs PYTHONUNBUFFERED=1 PEDL_TRIAL_RUNNER_NETWORK=host PEDL_CONTAINER_ID=671d3182-6205-4515-b47a-814567b63d53 LS_COLORS='rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:' LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 NVIDIA_VISIBLE_DEVICES=GPU-51462de1-174d-ae38-8b2b-46496394e931,GPU-8ecbfcb3-9e9b-45b9-6535-207b3efb2743,GPU-b4974d41-02f7-2b89-cc5d-03200bf72ae4,GPU-57e39e40-ba6e-5757-870b-ba5501102744,GPU-05321802-b3da-069a-156e-4a9c10ab83f5,GPU-f086a21c-d470-6bad-73c2-9862973a5fe2,GPU-58a10c5b-c21f-a140-16a9-65920058e059,GPU-bb46ccbf-97c7-6411-1ff2-3e5a10be6ebe NVIDIA_DRIVER_CAPABILITIES=compute,utility PEDL_MODEL_PATH=/model_def PEDL_SLOT_IDS='[0, 1, 2, 3, 4, 5, 6, 7]' PEDL_TRIAL_ID=140 PYTHONHASHSEED=0 PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/ PYTHONFAULTHANDLER=1 PEDL_MASTER_ADDR=10.128.15.205 PEDL_WORKLOAD_MANAGER_TYPE=TRIAL_WORKLOAD_MANAGER CUDA_PKG_VERSION=10-0=10.0.130-1 CUDA_VERSION=10.0.130 HOROVOD_GLOO_IFACE=ens13 SHLVL=1 HOME=/root NCCL_VERSION=2.4.7 PYTHONPATH=/ PEDL_AGENT_ID=aaron-host-1 LESSOPEN='| /usr/bin/lesspipe %s' LESSCLOSE='/usr/bin/lesspipe %s %s' _=/usr/local/bin/horovodrun HOROVOD_STALL_CHECK_TIME_SECONDS=60 HOROVOD_STALL_SHUTDOWN_TIME_SECONDS=0 HOROVOD_NUM_NCCL_STREAMS=1 HOROVOD_MLSL_BGT_AFFINITY=0 HOROVOD_GLOO_RENDEZVOUS_ADDR=10.128.15.205 HOROVOD_GLOO_RENDEZVOUS_PORT=31239 HOROVOD_CONTROLLER=gloo HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=ens13 NCCL_SOCKET_IFNAME=ens13 python /home/aaronharlap/repos/horovod/examples/tensorflow_keras_mnist.py\r\nProcess 1 exit with status code 134.\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1364/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1364/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1338", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1338/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1338/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1338/events", "html_url": "https://github.com/horovod/horovod/issues/1338", "id": 484361308, "node_id": "MDU6SXNzdWU0ODQzNjEzMDg=", "number": 1338, "title": "horovodrun times out but mpirun works", "user": {"login": "oskotsky", "id": 32287639, "node_id": "MDQ6VXNlcjMyMjg3NjM5", "avatar_url": "https://avatars.githubusercontent.com/u/32287639?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oskotsky", "html_url": "https://github.com/oskotsky", "followers_url": "https://api.github.com/users/oskotsky/followers", "following_url": "https://api.github.com/users/oskotsky/following{/other_user}", "gists_url": "https://api.github.com/users/oskotsky/gists{/gist_id}", "starred_url": "https://api.github.com/users/oskotsky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oskotsky/subscriptions", "organizations_url": "https://api.github.com/users/oskotsky/orgs", "repos_url": "https://api.github.com/users/oskotsky/repos", "events_url": "https://api.github.com/users/oskotsky/events{/privacy}", "received_events_url": "https://api.github.com/users/oskotsky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2019-08-23T06:55:49Z", "updated_at": "2021-01-15T04:06:03Z", "closed_at": "2019-08-29T01:17:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow)\r\n2. Framework version: 1.14\r\n3. Horovod version: 0.17.1\r\n4. MPI version: Open MPI: 4.0.1\r\n5. CUDA version: 396.26\r\n6. NCCL version: 2.2.13\r\n7. Python version: 3.6\r\n8. OS and version: Amazon Linux\r\n9. GCC version: 4.8.5\r\n\r\nmpirun -np 2 -H localhost:1,10.0.7.54:1 python3 train.py runs fine\r\n\r\nthe same command through horovod:\r\nhorovodrun -np 2 -H localhost:1,10.0.7.54:1 python3 train.py fails (timeout):\r\nException: Timed out waiting for tasks to start. Please check connectivity between servers. You may need to increase the --start-timeout parameter if you have too many servers.\r\n\r\nthe single version:\r\nhorovodrun -np 1 -H localhost:1 python3 train.py\r\nruns on both instances\r\n\r\nPlease help. \r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1338/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1338/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1334", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1334/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1334/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1334/events", "html_url": "https://github.com/horovod/horovod/issues/1334", "id": 484013181, "node_id": "MDU6SXNzdWU0ODQwMTMxODE=", "number": 1334, "title": "Install error: None of TensorFlow, PyTorch, or MXNet plugins were built. See errors above.", "user": {"login": "beizhengren", "id": 22186249, "node_id": "MDQ6VXNlcjIyMTg2MjQ5", "avatar_url": "https://avatars.githubusercontent.com/u/22186249?v=4", "gravatar_id": "", "url": "https://api.github.com/users/beizhengren", "html_url": "https://github.com/beizhengren", "followers_url": "https://api.github.com/users/beizhengren/followers", "following_url": "https://api.github.com/users/beizhengren/following{/other_user}", "gists_url": "https://api.github.com/users/beizhengren/gists{/gist_id}", "starred_url": "https://api.github.com/users/beizhengren/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/beizhengren/subscriptions", "organizations_url": "https://api.github.com/users/beizhengren/orgs", "repos_url": "https://api.github.com/users/beizhengren/repos", "events_url": "https://api.github.com/users/beizhengren/events{/privacy}", "received_events_url": "https://api.github.com/users/beizhengren/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-22T14:00:39Z", "updated_at": "2019-08-23T03:27:55Z", "closed_at": "2019-08-22T21:56:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) PyTorch\r\n2. Framework version:1.2.0\r\n3. Horovod version:latest\r\n4. MPI version:4.0.0\r\n5. CUDA version:10.0\r\n6. NCCL version:no\r\n7. Python version:3.7.2\r\n8. OS and version:ubuntu18.04\r\n9. GCC version:7.4.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\nyes\r\n**Your question:**\r\nPlease ask your question here.\r\n\r\n**I have 2 questions:**\r\n- 1. Does tensorflow must be installed?\r\n- 2. I have installed PyTorch1.2.0, but when I run `pip install horovod ` there is an error as following, what should I do? Thank you!\r\n\r\n``` bash\r\n $ pip install horovod     \r\n```\r\n```\r\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\r\nCollecting horovod\r\n  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/8f/d9/67e496de0e04d314bb4bf3621442880486a560ab4e682f1c24ec7bf3c9b6/horovod-0.17.0.post1.tar.gz\r\nRequirement already satisfied: cloudpickle in /home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages (from horovod) (1.1.1)\r\nRequirement already satisfied: psutil in /home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages (from horovod) (5.6.2)\r\nRequirement already satisfied: six in /home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages (from horovod) (1.12.0)\r\nRequirement already satisfied: cffi>=1.4.0 in /home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages (from horovod) (1.12.3)\r\nRequirement already satisfied: pycparser in /home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages (from cffi>=1.4.0->horovod) (2.19)\r\nBuilding wheels for collected packages: horovod\r\n  Running setup.py bdist_wheel for horovod ... error\r\n  Complete output from command /home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/bin/python3.7 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-c74kecsx/horovod/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/pip-wheel-c74z94_t --python-tag cp37:\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib.linux-x86_64-3.7\r\n  creating build/lib.linux-x86_64-3.7/horovod\r\n  copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n  creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n  copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n  copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark\r\n  copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n  creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  creating build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  creating build/lib.linux-x86_64-3.7/horovod/keras\r\n  copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n  copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n  copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n  copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common\r\n  copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/task\r\n  copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n  copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/rendezvous\r\n  copying horovod/run/rendezvous/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/rendezvous\r\n  copying horovod/run/rendezvous/http_server.py -> build/lib.linux-x86_64-3.7/horovod/run/rendezvous\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  running build_ext\r\n  gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -std=c++11 -fPIC -O2 -Wall -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/include -I/home/wyz/.pyenv/versions/3.7.2/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n  gcc -pthread -shared -L/home/wyz/.pyenv/versions/3.7.2/lib -L/home/wyz/.pyenv/versions/3.7.2/lib build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.so\r\n  gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/include -I/home/wyz/.pyenv/versions/3.7.2/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o\r\n  gcc -pthread -shared -L/home/wyz/.pyenv/versions/3.7.2/lib -L/home/wyz/.pyenv/versions/3.7.2/lib -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.so\r\n  INFO: Unable to build TensorFlow plugin, will skip it.\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 72, in check_tf_version\r\n      import tensorflow as tf\r\n  ModuleNotFoundError: No module named 'tensorflow'\r\n  \r\n  During handling of the above exception, another exception occurred:\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 1375, in build_extensions\r\n      build_tf_extension(self, options)\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 851, in build_tf_extension\r\n      check_tf_version()\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 79, in check_tf_version\r\n      'import tensorflow failed, is it installed?\\n\\n%s' % traceback.format_exc())\r\n  distutils.errors.DistutilsPlatformError: import tensorflow failed, is it installed?\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 72, in check_tf_version\r\n      import tensorflow as tf\r\n  ModuleNotFoundError: No module named 'tensorflow'\r\n  \r\n  \r\n  gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -std=c++11 -fPIC -O2 -Wall -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages/torch/include -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages/torch/include/TH -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/include -I/home/wyz/.pyenv/versions/3.7.2/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_torch_cuda.cc -o build/temp.linux-x86_64-3.7/test_compile/test_torch_cuda.o\r\n  gcc -pthread -shared -L/home/wyz/.pyenv/versions/3.7.2/lib -L/home/wyz/.pyenv/versions/3.7.2/lib build/temp.linux-x86_64-3.7/test_compile/test_torch_cuda.o -o build/temp.linux-x86_64-3.7/test_compile/test_torch_cuda.so\r\n  /bin/sh: 1: /usr/lib/gcc: Permission denied\r\n  INFO: Unable to determine version of the compiler /usr/lib/gcc.\r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 767, in determine_gcc_version\r\n      shell=True, universal_newlines=True).split('\\n')\r\n    File \"/home/wyz/.pyenv/versions/3.7.2/lib/python3.7/subprocess.py\", line 395, in check_output\r\n      **kwargs).stdout\r\n    File \"/home/wyz/.pyenv/versions/3.7.2/lib/python3.7/subprocess.py\", line 487, in run\r\n      output=stdout, stderr=stderr)\r\n  subprocess.CalledProcessError: Command '/usr/lib/gcc -dM -E - </dev/null' returned non-zero exit status 126.\r\n  \r\n  INFO: Unable to build PyTorch plugin, will skip it.\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 1389, in build_extensions\r\n      build_torch_extension_v2(self, options, torch_version)\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 1274, in build_torch_extension_v2\r\n      find_matching_gcc_compiler_path(candidate_compiler_version)\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 801, in find_matching_gcc_compiler_path\r\n      if compiler_version == gxx_compiler_version:\r\n    File \"/home/wyz/.pyenv/versions/3.7.2/lib/python3.7/distutils/version.py\", line 46, in __eq__\r\n      c = self._cmp(other)\r\n    File \"/home/wyz/.pyenv/versions/3.7.2/lib/python3.7/distutils/version.py\", line 335, in _cmp\r\n      if self.version == other.version:\r\n  AttributeError: 'NoneType' object has no attribute 'version'\r\n  \r\n  -- The CXX compiler identification is GNU 7.4.0\r\n  -- The C compiler identification is GNU 7.4.0\r\n  -- Check for working CXX compiler: /usr/bin/c++\r\n  -- Check for working CXX compiler: /usr/bin/c++ -- works\r\n  -- Detecting CXX compiler ABI info\r\n  -- Detecting CXX compiler ABI info - done\r\n  -- Detecting CXX compile features\r\n  -- Detecting CXX compile features - done\r\n  -- Check for working C compiler: /usr/bin/cc\r\n  -- Check for working C compiler: /usr/bin/cc -- works\r\n  -- Detecting C compiler ABI info\r\n  -- Detecting C compiler ABI info - done\r\n  -- Detecting C compile features\r\n  -- Detecting C compile features - done\r\n  -- Found MPI_C: /usr/local/lib/libmpi.so (found version \"3.1\")\r\n  -- Found MPI_CXX: /usr/local/lib/libmpi.so (found version \"3.1\")\r\n  -- Found MPI: TRUE (found version \"3.1\")\r\n  -- MPI include path: /usr/local/include\r\n  -- MPI libraries: /usr/local/lib/libmpi.so\r\n  -- Configuring done\r\n  -- Generating done\r\n  -- Build files have been written to: /tmp/pip-install-c74kecsx/horovod/build/temp.linux-x86_64-3.7/gloo/mxnet\r\n  Scanning dependencies of target gloo\r\n  [  6%] Building CXX object gloo/CMakeFiles/gloo.dir/allgatherv.cc.o\r\n  [  6%] Building CXX object gloo/CMakeFiles/gloo.dir/allgather.cc.o\r\n  [  9%] Building CXX object gloo/CMakeFiles/gloo.dir/algorithm.cc.o\r\n  [ 12%] Building CXX object gloo/CMakeFiles/gloo.dir/allreduce.cc.o\r\n  [ 15%] Building CXX object gloo/CMakeFiles/gloo.dir/allreduce_local.cc.o\r\n  [ 18%] Building CXX object gloo/CMakeFiles/gloo.dir/barrier.cc.o\r\n  [ 21%] Building CXX object gloo/CMakeFiles/gloo.dir/broadcast.cc.o\r\n  [ 24%] Building CXX object gloo/CMakeFiles/gloo.dir/context.cc.o\r\n  [ 27%] Building CXX object gloo/CMakeFiles/gloo.dir/gather.cc.o\r\n  [ 30%] Building CXX object gloo/CMakeFiles/gloo.dir/reduce.cc.o\r\n  [ 36%] Building CXX object gloo/CMakeFiles/gloo.dir/scatter.cc.o\r\n  [ 36%] Building CXX object gloo/CMakeFiles/gloo.dir/types.cc.o\r\n  [ 39%] Building CXX object gloo/CMakeFiles/gloo.dir/common/linux.cc.o\r\n  [ 42%] Building CXX object gloo/CMakeFiles/gloo.dir/common/logging.cc.o\r\n  [ 45%] Building CXX object gloo/CMakeFiles/gloo.dir/mpi/context.cc.o\r\n  [ 48%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/context.cc.o\r\n  [ 51%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/file_store.cc.o\r\n  In file included from /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/mpi/context.cc:16:0:\r\n  /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/mpi/context.cc: In destructor \u2018gloo::mpi::MPIScope::~MPIScope()\u2019:\r\n  /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/common/logging.h:141:58: warning: throw will always call terminate() [-Wterminate]\r\n             r.get_message_and_free(MakeString(__VA_ARGS__))); \\\r\n                                                            ^\r\n  /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/common/logging.h:150:3: note: in expansion of macro \u2018GLOO_ENFORCE_THAT_IMPL\u2019\r\n     GLOO_ENFORCE_THAT_IMPL(Equals((x), (y)), #x \" == \" #y, __VA_ARGS__)\r\n     ^~~~~~~~~~~~~~~~~~~~~~\r\n  /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/mpi/context.cc:43:3: note: in expansion of macro \u2018GLOO_ENFORCE_EQ\u2019\r\n     GLOO_ENFORCE_EQ(rv, MPI_SUCCESS);\r\n     ^~~~~~~~~~~~~~~\r\n  /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/common/logging.h:141:58: note: in C++11 destructors default to noexcept\r\n             r.get_message_and_free(MakeString(__VA_ARGS__))); \\\r\n                                                            ^\r\n  /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/common/logging.h:150:3: note: in expansion of macro \u2018GLOO_ENFORCE_THAT_IMPL\u2019\r\n     GLOO_ENFORCE_THAT_IMPL(Equals((x), (y)), #x \" == \" #y, __VA_ARGS__)\r\n     ^~~~~~~~~~~~~~~~~~~~~~\r\n  /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/mpi/context.cc:43:3: note: in expansion of macro \u2018GLOO_ENFORCE_EQ\u2019\r\n     GLOO_ENFORCE_EQ(rv, MPI_SUCCESS);\r\n     ^~~~~~~~~~~~~~~\r\n  [ 54%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/hash_store.cc.o\r\n  [ 57%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/prefix_store.cc.o\r\n  [ 60%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/store.cc.o\r\n  [ 63%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/address.cc.o\r\n  [ 66%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/buffer.cc.o\r\n  [ 69%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/context.cc.o\r\n  [ 72%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/device.cc.o\r\n  [ 75%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/pair.cc.o\r\n  [ 78%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/unbound_buffer.cc.o\r\n  [ 81%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/address.cc.o\r\n  [ 84%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/buffer.cc.o\r\n  [ 87%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/context.cc.o\r\n  [ 90%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/device.cc.o\r\n  [ 93%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/pair.cc.o\r\n  [ 96%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/unbound_buffer.cc.o\r\n  [100%] Linking CXX static library /tmp/pip-install-c74kecsx/horovod/build/temp.linux-x86_64-3.7/lib/mxnet/libgloo.a\r\n  [100%] Built target gloo\r\n  INFO: Unable to build MXNet plugin, will skip it.\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 88, in check_mx_version\r\n      import mxnet as mx\r\n  ModuleNotFoundError: No module named 'mxnet'\r\n  \r\n  During handling of the above exception, another exception occurred:\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 1403, in build_extensions\r\n      build_mx_extension(self, options)\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 1000, in build_mx_extension\r\n      check_mx_version()\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 95, in check_mx_version\r\n      'import mxnet failed, is it installed?\\n\\n%s' % traceback.format_exc())\r\n  distutils.errors.DistutilsPlatformError: import mxnet failed, is it installed?\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 88, in check_mx_version\r\n      import mxnet as mx\r\n  ModuleNotFoundError: No module named 'mxnet'\r\n  \r\n  \r\n  error: None of TensorFlow, PyTorch, or MXNet plugins were built. See errors above.\r\n  \r\n  ----------------------------------------\r\n  Failed building wheel for horovod\r\n  Running setup.py clean for horovod\r\nFailed to build horovod\r\nInstalling collected packages: horovod\r\n  Running setup.py install for horovod ... error\r\n    Complete output from command /home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/bin/python3.7 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-c74kecsx/horovod/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-zuqdc9ob/install-record.txt --single-version-externally-managed --compile --install-headers /home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/include/site/python3.7/horovod:\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.7\r\n    creating build/lib.linux-x86_64-3.7/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n    creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    creating build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    creating build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common\r\n    copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/task\r\n    copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n    copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/rendezvous\r\n    copying horovod/run/rendezvous/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/rendezvous\r\n    copying horovod/run/rendezvous/http_server.py -> build/lib.linux-x86_64-3.7/horovod/run/rendezvous\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    running build_ext\r\n    gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -std=c++11 -fPIC -O2 -Wall -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/include -I/home/wyz/.pyenv/versions/3.7.2/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n    gcc -pthread -shared -L/home/wyz/.pyenv/versions/3.7.2/lib -L/home/wyz/.pyenv/versions/3.7.2/lib build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.so\r\n    gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/include -I/home/wyz/.pyenv/versions/3.7.2/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o\r\n    gcc -pthread -shared -L/home/wyz/.pyenv/versions/3.7.2/lib -L/home/wyz/.pyenv/versions/3.7.2/lib -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.so\r\n    INFO: Unable to build TensorFlow plugin, will skip it.\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 72, in check_tf_version\r\n        import tensorflow as tf\r\n    ModuleNotFoundError: No module named 'tensorflow'\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 1375, in build_extensions\r\n        build_tf_extension(self, options)\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 851, in build_tf_extension\r\n        check_tf_version()\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 79, in check_tf_version\r\n        'import tensorflow failed, is it installed?\\n\\n%s' % traceback.format_exc())\r\n    distutils.errors.DistutilsPlatformError: import tensorflow failed, is it installed?\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 72, in check_tf_version\r\n        import tensorflow as tf\r\n    ModuleNotFoundError: No module named 'tensorflow'\r\n    \r\n    \r\n    gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -std=c++11 -fPIC -O2 -Wall -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -Ithird_party/HTTPRequest/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/eigen -Ithird_party/flatbuffers/include -Ithird_party/lbfgs/include -Ithird_party/gloo -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages/torch/include -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages/torch/include/TH -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/include -I/home/wyz/.pyenv/versions/3.7.2/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_torch_cuda.cc -o build/temp.linux-x86_64-3.7/test_compile/test_torch_cuda.o\r\n    gcc -pthread -shared -L/home/wyz/.pyenv/versions/3.7.2/lib -L/home/wyz/.pyenv/versions/3.7.2/lib build/temp.linux-x86_64-3.7/test_compile/test_torch_cuda.o -o build/temp.linux-x86_64-3.7/test_compile/test_torch_cuda.so\r\n    /bin/sh: 1: /usr/lib/gcc: Permission denied\r\n    INFO: Unable to determine version of the compiler /usr/lib/gcc.\r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 767, in determine_gcc_version\r\n        shell=True, universal_newlines=True).split('\\n')\r\n      File \"/home/wyz/.pyenv/versions/3.7.2/lib/python3.7/subprocess.py\", line 395, in check_output\r\n        **kwargs).stdout\r\n      File \"/home/wyz/.pyenv/versions/3.7.2/lib/python3.7/subprocess.py\", line 487, in run\r\n        output=stdout, stderr=stderr)\r\n    subprocess.CalledProcessError: Command '/usr/lib/gcc -dM -E - </dev/null' returned non-zero exit status 126.\r\n    \r\n    INFO: Unable to build PyTorch plugin, will skip it.\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 1389, in build_extensions\r\n        build_torch_extension_v2(self, options, torch_version)\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 1274, in build_torch_extension_v2\r\n        find_matching_gcc_compiler_path(candidate_compiler_version)\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 801, in find_matching_gcc_compiler_path\r\n        if compiler_version == gxx_compiler_version:\r\n      File \"/home/wyz/.pyenv/versions/3.7.2/lib/python3.7/distutils/version.py\", line 46, in __eq__\r\n        c = self._cmp(other)\r\n      File \"/home/wyz/.pyenv/versions/3.7.2/lib/python3.7/distutils/version.py\", line 335, in _cmp\r\n        if self.version == other.version:\r\n    AttributeError: 'NoneType' object has no attribute 'version'\r\n    \r\n    -- The CXX compiler identification is GNU 7.4.0\r\n    -- The C compiler identification is GNU 7.4.0\r\n    -- Check for working CXX compiler: /usr/bin/c++\r\n    -- Check for working CXX compiler: /usr/bin/c++ -- works\r\n    -- Detecting CXX compiler ABI info\r\n    -- Detecting CXX compiler ABI info - done\r\n    -- Detecting CXX compile features\r\n    -- Detecting CXX compile features - done\r\n    -- Check for working C compiler: /usr/bin/cc\r\n    -- Check for working C compiler: /usr/bin/cc -- works\r\n    -- Detecting C compiler ABI info\r\n    -- Detecting C compiler ABI info - done\r\n    -- Detecting C compile features\r\n    -- Detecting C compile features - done\r\n    -- Found MPI_C: /usr/local/lib/libmpi.so (found version \"3.1\")\r\n    -- Found MPI_CXX: /usr/local/lib/libmpi.so (found version \"3.1\")\r\n    -- Found MPI: TRUE (found version \"3.1\")\r\n    -- MPI include path: /usr/local/include\r\n    -- MPI libraries: /usr/local/lib/libmpi.so\r\n    -- Configuring done\r\n    -- Generating done\r\n    -- Build files have been written to: /tmp/pip-install-c74kecsx/horovod/build/temp.linux-x86_64-3.7/gloo/mxnet\r\n    Scanning dependencies of target gloo\r\n    [  6%] Building CXX object gloo/CMakeFiles/gloo.dir/allreduce.cc.o\r\n    [  6%] Building CXX object gloo/CMakeFiles/gloo.dir/allgather.cc.o\r\n    [  9%] Building CXX object gloo/CMakeFiles/gloo.dir/algorithm.cc.o\r\n    [ 12%] Building CXX object gloo/CMakeFiles/gloo.dir/allgatherv.cc.o\r\n    [ 15%] Building CXX object gloo/CMakeFiles/gloo.dir/allreduce_local.cc.o\r\n    [ 18%] Building CXX object gloo/CMakeFiles/gloo.dir/barrier.cc.o\r\n    [ 21%] Building CXX object gloo/CMakeFiles/gloo.dir/broadcast.cc.o\r\n    [ 24%] Building CXX object gloo/CMakeFiles/gloo.dir/context.cc.o\r\n    [ 27%] Building CXX object gloo/CMakeFiles/gloo.dir/gather.cc.o\r\n    [ 30%] Building CXX object gloo/CMakeFiles/gloo.dir/reduce.cc.o\r\n    [ 33%] Building CXX object gloo/CMakeFiles/gloo.dir/scatter.cc.o\r\n    [ 36%] Building CXX object gloo/CMakeFiles/gloo.dir/types.cc.o\r\n    [ 39%] Building CXX object gloo/CMakeFiles/gloo.dir/common/linux.cc.o\r\n    [ 42%] Building CXX object gloo/CMakeFiles/gloo.dir/common/logging.cc.o\r\n    [ 45%] Building CXX object gloo/CMakeFiles/gloo.dir/mpi/context.cc.o\r\n    [ 48%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/context.cc.o\r\n    [ 51%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/file_store.cc.o\r\n    In file included from /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/mpi/context.cc:16:0:\r\n    /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/mpi/context.cc: In destructor \u2018gloo::mpi::MPIScope::~MPIScope()\u2019:\r\n    /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/common/logging.h:141:58: warning: throw will always call terminate() [-Wterminate]\r\n               r.get_message_and_free(MakeString(__VA_ARGS__))); \\\r\n                                                              ^\r\n    /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/common/logging.h:150:3: note: in expansion of macro \u2018GLOO_ENFORCE_THAT_IMPL\u2019\r\n       GLOO_ENFORCE_THAT_IMPL(Equals((x), (y)), #x \" == \" #y, __VA_ARGS__)\r\n       ^~~~~~~~~~~~~~~~~~~~~~\r\n    /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/mpi/context.cc:43:3: note: in expansion of macro \u2018GLOO_ENFORCE_EQ\u2019\r\n       GLOO_ENFORCE_EQ(rv, MPI_SUCCESS);\r\n       ^~~~~~~~~~~~~~~\r\n    /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/common/logging.h:141:58: note: in C++11 destructors default to noexcept\r\n               r.get_message_and_free(MakeString(__VA_ARGS__))); \\\r\n                                                              ^\r\n    /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/common/logging.h:150:3: note: in expansion of macro \u2018GLOO_ENFORCE_THAT_IMPL\u2019\r\n       GLOO_ENFORCE_THAT_IMPL(Equals((x), (y)), #x \" == \" #y, __VA_ARGS__)\r\n       ^~~~~~~~~~~~~~~~~~~~~~\r\n    /tmp/pip-install-c74kecsx/horovod/third_party/gloo/gloo/mpi/context.cc:43:3: note: in expansion of macro \u2018GLOO_ENFORCE_EQ\u2019\r\n       GLOO_ENFORCE_EQ(rv, MPI_SUCCESS);\r\n       ^~~~~~~~~~~~~~~\r\n    [ 54%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/hash_store.cc.o\r\n    [ 57%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/prefix_store.cc.o\r\n    [ 60%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/store.cc.o\r\n    [ 63%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/address.cc.o\r\n    [ 66%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/buffer.cc.o\r\n    [ 69%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/context.cc.o\r\n    [ 72%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/device.cc.o\r\n    [ 75%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/pair.cc.o\r\n    [ 78%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/unbound_buffer.cc.o\r\n    [ 81%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/address.cc.o\r\n    [ 84%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/buffer.cc.o\r\n    [ 87%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/context.cc.o\r\n    [ 90%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/device.cc.o\r\n    [ 93%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/pair.cc.o\r\n    [ 96%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/unbound_buffer.cc.o\r\n    [100%] Linking CXX static library /tmp/pip-install-c74kecsx/horovod/build/temp.linux-x86_64-3.7/lib/mxnet/libgloo.a\r\n    [100%] Built target gloo\r\n    INFO: Unable to build MXNet plugin, will skip it.\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 88, in check_mx_version\r\n        import mxnet as mx\r\n    ModuleNotFoundError: No module named 'mxnet'\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 1403, in build_extensions\r\n        build_mx_extension(self, options)\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 1000, in build_mx_extension\r\n        check_mx_version()\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 95, in check_mx_version\r\n        'import mxnet failed, is it installed?\\n\\n%s' % traceback.format_exc())\r\n    distutils.errors.DistutilsPlatformError: import mxnet failed, is it installed?\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-c74kecsx/horovod/setup.py\", line 88, in check_mx_version\r\n        import mxnet as mx\r\n    ModuleNotFoundError: No module named 'mxnet'\r\n    \r\n    \r\n    error: None of TensorFlow, PyTorch, or MXNet plugins were built. See errors above.\r\n    \r\n    ----------------------------------------\r\nCommand \"/home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/bin/python3.7 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-c74kecsx/horovod/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-zuqdc9ob/install-record.txt --single-version-externally-managed --compile --install-headers /home/wyz/.pyenv/versions/3.7.2/envs/env-3.7.2/include/site/python3.7/horovod\" failed with error code 1 in /tmp/pip-install-c74kecsx/horovod/\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1334/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1334/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1328", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1328/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1328/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1328/events", "html_url": "https://github.com/horovod/horovod/issues/1328", "id": 483171095, "node_id": "MDU6SXNzdWU0ODMxNzEwOTU=", "number": 1328, "title": "multi-node training error: div_cpu", "user": {"login": "qingyu-wang", "id": 16367457, "node_id": "MDQ6VXNlcjE2MzY3NDU3", "avatar_url": "https://avatars.githubusercontent.com/u/16367457?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qingyu-wang", "html_url": "https://github.com/qingyu-wang", "followers_url": "https://api.github.com/users/qingyu-wang/followers", "following_url": "https://api.github.com/users/qingyu-wang/following{/other_user}", "gists_url": "https://api.github.com/users/qingyu-wang/gists{/gist_id}", "starred_url": "https://api.github.com/users/qingyu-wang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qingyu-wang/subscriptions", "organizations_url": "https://api.github.com/users/qingyu-wang/orgs", "repos_url": "https://api.github.com/users/qingyu-wang/repos", "events_url": "https://api.github.com/users/qingyu-wang/events{/privacy}", "received_events_url": "https://api.github.com/users/qingyu-wang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-21T02:48:01Z", "updated_at": "2019-09-26T05:57:57Z", "closed_at": "2019-08-22T08:20:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Docker: horovod/horovod:0.16.4-tf1.14.0-torch1.1.0-mxnet1.4.1-py3.6\r\n\r\n**Bug report:**\r\n\r\nI want to use horovod and apex together to try fp16 training, but when I run the demo, I got following error.\r\n\r\n```\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  \"div_cpu\" not implemented for 'Half' (operator() at /pytorch/build/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp.AVX2.cpp:60)\r\nframe #0: std::function<std::string ()>::operator()() const + 0x11 (0x7f35b27bb441 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\r\nframe #1: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x2a (0x7f35b27bad7a in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\r\nframe #2: <unknown function> + 0x14d7862 (0x7f351cdae862 in /usr/local/lib/python3.6/dist-packages/torch/lib/libcaffe2.so)\r\nframe #3: <unknown function> + 0x8b38d7 (0x7f351c18a8d7 in /usr/local/lib/python3.6/dist-packages/torch/lib/libcaffe2.so)\r\nframe #4: at::native::div_out(at::Tensor&, at::Tensor const&, at::Tensor const&) + 0x151 (0x7f351c1864a1 in /usr/local/lib/python3.6/dist-packages/torch/lib/libcaffe2.so)\r\nframe #5: at::native::div_(at::Tensor&, c10::Scalar) + 0x35 (0x7f351c186c85 in /usr/local/lib/python3.6/dist-packages/torch/lib/libcaffe2.so)\r\nframe #6: at::TypeDefault::div_(at::Tensor&, c10::Scalar) const + 0x60 (0x7f351c5c2380 in /usr/local/lib/python3.6/dist-packages/torch/lib/libcaffe2.so)\r\nframe #7: torch::autograd::VariableType::div_(at::Tensor&, c10::Scalar) const + 0x3e3 (0x7f35a35ce433 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch.so.1)\r\nframe #8: <unknown function> + 0x892ef (0x7f35116e82ef in /usr/local/lib/python3.6/dist-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\nframe #9: <unknown function> + 0x4370c (0x7f35116a270c in /usr/local/lib/python3.6/dist-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\nframe #10: <unknown function> + 0x46292 (0x7f35116a5292 in /usr/local/lib/python3.6/dist-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\nframe #11: <unknown function> + 0x4968e (0x7f35116a868e in /usr/local/lib/python3.6/dist-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\nframe #12: <unknown function> + 0xbd9e0 (0x7f35b22be9e0 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\r\nframe #13: <unknown function> + 0x76db (0x7f35b78466db in /lib/x86_64-linux-gnu/libpthread.so.0)\r\nframe #14: clone + 0x3f (0x7f35b7b7f88f in /lib/x86_64-linux-gnu/libc.so.6)\r\n\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  \"div_cpu\" not implemented for 'Half' (operator() at /pytorch/build/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp.AVX2.cpp:60)\r\nframe #0: std::function<std::string ()>::operator()() const + 0x11 (0x7fbd1b40b441 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\r\nframe #1: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x2a (0x7fbd1b40ad7a in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\r\nframe #2: <unknown function> + 0x14d7862 (0x7fbc859fe862 in /usr/local/lib/python3.6/dist-packages/torch/lib/libcaffe2.so)\r\nframe #3: <unknown function> + 0x8b38d7 (0x7fbc84dda8d7 in /usr/local/lib/python3.6/dist-packages/torch/lib/libcaffe2.so)\r\nframe #4: at::native::div_out(at::Tensor&, at::Tensor const&, at::Tensor const&) + 0x151 (0x7fbc84dd64a1 in /usr/local/lib/python3.6/dist-packages/torch/lib/libcaffe2.so)\r\nframe #5: at::native::div_(at::Tensor&, c10::Scalar) + 0x35 (0x7fbc84dd6c85 in /usr/local/lib/python3.6/dist-packages/torch/lib/libcaffe2.so)\r\nframe #6: at::TypeDefault::div_(at::Tensor&, c10::Scalar) const + 0x60 (0x7fbc85212380 in /usr/local/lib/python3.6/dist-packages/torch/lib/libcaffe2.so)\r\nframe #7: torch::autograd::VariableType::div_(at::Tensor&, c10::Scalar) const + 0x3e3 (0x7fbd19d81433 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch.so.1)\r\nframe #8: <unknown function> + 0x892ef (0x7fbc7a3382ef in /usr/local/lib/python3.6/dist-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\nframe #9: <unknown function> + 0x4370c (0x7fbc7a2f270c in /usr/local/lib/python3.6/dist-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\nframe #10: <unknown function> + 0x46292 (0x7fbc7a2f5292 in /usr/local/lib/python3.6/dist-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\nframe #11: <unknown function> + 0x4968e (0x7fbc7a2f868e in /usr/local/lib/python3.6/dist-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\nframe #12: <unknown function> + 0xbd9e0 (0x7fbd1af0e9e0 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\r\nframe #13: <unknown function> + 0x76db (0x7fbd204966db in /lib/x86_64-linux-gnu/libpthread.so.0)\r\nframe #14: clone + 0x3f (0x7fbd207cf88f in /lib/x86_64-linux-gnu/libc.so.6)\r\n```\r\n\r\nhere is my demo code, if `APEX = False`, multi-code trainning is fine.\r\n\r\n```\r\nimport time\r\n\r\nimport torch\r\nimport torch.backends.cudnn as cudnn\r\nimport torch.nn as nn\r\nimport torch.optim as optim\r\nimport torchvision\r\n# Horovod\r\nimport horovod.torch as hvd\r\n\r\nAPEX = True\r\n# Apex\r\nif APEX:\r\n    import apex\r\n    from apex import amp\r\n\r\nhvd.init()\r\n\r\ntime.sleep(0.1 * hvd.rank())\r\nprint(\"global [%2s/%2s], local [%2s/%2s]\" % (hvd.rank(), hvd.size(), hvd.local_rank(), hvd.local_size()))\r\ntime.sleep(0.1 * (hvd.size() - hvd.rank()))\r\n\r\ntorch.cuda.set_device(hvd.local_rank())\r\ncudnn.benchmark = True\r\n\r\ncudnn.deterministic = True\r\n\r\ntorch.manual_seed(4)\r\ntorch.cuda.manual_seed_all(4)\r\n\r\nmodel = torchvision.models.resnet50()\r\n\r\noptimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=1e-4)\r\n\r\n# Horovod\r\nFP16_ALLREDUCE = True\r\noptimizer = hvd.DistributedOptimizer(\r\n    optimizer,\r\n    named_parameters=model.named_parameters(),\r\n    compression=hvd.Compression.fp16 if APEX and FP16_ALLREDUCE else hvd.Compression.none\r\n)\r\n\r\n# Apex\r\nSYNC_BN = True\r\nif APEX and SYNC_BN:\r\n    model = apex.parallel.convert_syncbn_model(model)\r\n\r\nmodel.cuda()\r\n\r\n# Horovod\r\nhvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\nhvd.broadcast_optimizer_state(optimizer, root_rank=0)\r\n\r\n# Apex\r\nif APEX:\r\n    OPT_LEVEL = \"O1\"\r\n    KEEP_BATCHNORM_FP32 = None\r\n    LOSS_SCALE = True\r\n    model, optimizer = amp.initialize(model, optimizer,\r\n        opt_level=OPT_LEVEL,\r\n        keep_batchnorm_fp32=KEEP_BATCHNORM_FP32,\r\n        loss_scale=LOSS_SCALE\r\n    )\r\n\r\ncriterion = nn.CrossEntropyLoss().cuda()\r\n\r\n\r\n_inputs = (torch.LongTensor(64, 3, 224, 224).random_().cuda() % 255).float().add_(-127.5).mul_(1/255)\r\n\r\ntargets = (torch.LongTensor(64).random_().cuda() % 1000)\r\n\r\nepochs = 5\r\nbatches = 1\r\nfor epoch_idx in range(epochs):\r\n    for batch_idx in range(batches):\r\n\r\n        if hvd.rank() == 0:\r\n            print(\"\\n\\nepoch: %s, batch: %s\" % (epoch_idx, batch_idx))\r\n\r\n        seed = epoch_idx * batches + batch_idx\r\n        torch.manual_seed(seed)\r\n        torch.cuda.manual_seed_all(seed)\r\n\r\n        inputs = _inputs + (torch.LongTensor(64, 3, 224, 224).random_().cuda() % 255).float().add_(-127.5).mul_(1/25500)\r\n        if hvd.rank() == 0:\r\n            print(inputs[0, :, 0, 0])\r\n\r\n        outputs = model(inputs)\r\n        loss = criterion(outputs, targets)\r\n\r\n        optimizer.zero_grad()\r\n\r\n        # Apex\r\n        if APEX:\r\n            with amp.scale_loss(loss, optimizer) as scaled_loss:\r\n                scaled_loss.backward()\r\n        else:\r\n            loss.backward()\r\n\r\n        optimizer.step()\r\n\r\n        if hvd.rank() == 0:\r\n            print(targets.detach().cpu().numpy())\r\n            print(outputs.detach().cpu().numpy().argmax(axis=1))\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1328/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1328/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1325", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1325/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1325/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1325/events", "html_url": "https://github.com/horovod/horovod/issues/1325", "id": 482894191, "node_id": "MDU6SXNzdWU0ODI4OTQxOTE=", "number": 1325, "title": "Can no longer use IP for remote hostnames", "user": {"login": "kangp3", "id": 4926047, "node_id": "MDQ6VXNlcjQ5MjYwNDc=", "avatar_url": "https://avatars.githubusercontent.com/u/4926047?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kangp3", "html_url": "https://github.com/kangp3", "followers_url": "https://api.github.com/users/kangp3/followers", "following_url": "https://api.github.com/users/kangp3/following{/other_user}", "gists_url": "https://api.github.com/users/kangp3/gists{/gist_id}", "starred_url": "https://api.github.com/users/kangp3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kangp3/subscriptions", "organizations_url": "https://api.github.com/users/kangp3/orgs", "repos_url": "https://api.github.com/users/kangp3/repos", "events_url": "https://api.github.com/users/kangp3/events{/privacy}", "received_events_url": "https://api.github.com/users/kangp3/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-20T14:24:38Z", "updated_at": "2019-08-21T17:48:59Z", "closed_at": "2019-08-21T17:48:59Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\nTensorFlow\r\n\r\n2. Framework version:\r\n`1.14.0`\r\n\r\n3. Horovod version:\r\n`0.17.0.post1`\r\n\r\n4. MPI version:\r\n`4.0.0`\r\n\r\n5. CUDA version:\r\n`10.0`\r\n\r\n6. NCCL version:\r\n`2.4.2-1+cuda10.0`\r\n\r\n7. Python version:\r\n`3.6.8`\r\n\r\n8. OS and version:\r\n`Ubuntu 18.04.1 LTS`\r\n\r\n9. GCC version:\r\n`g++-4.8 4.8.5-4ubuntu8`\r\n\r\n**Bug report:**\r\nPreviously, we were able to use IPs to specify remote hosts, but since `0.17.0` (specifically [#1181](https://github.com/horovod/horovod/pull/1181/files#diff-202497121925143c32fd281b782c3d52R347-R363)) it seems that this functionality was removed. It's more convenient for us to continue to use raw IPs, so would it be possible to bring that functionality back?\r\n\r\n```\r\n# horovodrun --verbose -np 1 -H 10.0.0.3:1 -p 12345 python /horovod/examples/keras_mnist.py\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/horovodrun\", line 21, in <module>\r\n    run.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod/run/run.py\", line 396, in run\r\n    raise ValueError('Invalid host input, please make sure it has '\r\nValueError: Invalid host input, please make sure it has format as : worker-0:2,worker-1:2.\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1325/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1325/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1315", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1315/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1315/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1315/events", "html_url": "https://github.com/horovod/horovod/issues/1315", "id": 482403064, "node_id": "MDU6SXNzdWU0ODI0MDMwNjQ=", "number": 1315, "title": "TF 2 issue introduced in commit 2be9d149", "user": {"login": "DEKHTIARJonathan", "id": 10923599, "node_id": "MDQ6VXNlcjEwOTIzNTk5", "avatar_url": "https://avatars.githubusercontent.com/u/10923599?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DEKHTIARJonathan", "html_url": "https://github.com/DEKHTIARJonathan", "followers_url": "https://api.github.com/users/DEKHTIARJonathan/followers", "following_url": "https://api.github.com/users/DEKHTIARJonathan/following{/other_user}", "gists_url": "https://api.github.com/users/DEKHTIARJonathan/gists{/gist_id}", "starred_url": "https://api.github.com/users/DEKHTIARJonathan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DEKHTIARJonathan/subscriptions", "organizations_url": "https://api.github.com/users/DEKHTIARJonathan/orgs", "repos_url": "https://api.github.com/users/DEKHTIARJonathan/repos", "events_url": "https://api.github.com/users/DEKHTIARJonathan/events{/privacy}", "received_events_url": "https://api.github.com/users/DEKHTIARJonathan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "alsrgv", "id": 16640218, "node_id": "MDQ6VXNlcjE2NjQwMjE4", "avatar_url": "https://avatars.githubusercontent.com/u/16640218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alsrgv", "html_url": "https://github.com/alsrgv", "followers_url": "https://api.github.com/users/alsrgv/followers", "following_url": "https://api.github.com/users/alsrgv/following{/other_user}", "gists_url": "https://api.github.com/users/alsrgv/gists{/gist_id}", "starred_url": "https://api.github.com/users/alsrgv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alsrgv/subscriptions", "organizations_url": "https://api.github.com/users/alsrgv/orgs", "repos_url": "https://api.github.com/users/alsrgv/repos", "events_url": "https://api.github.com/users/alsrgv/events{/privacy}", "received_events_url": "https://api.github.com/users/alsrgv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "alsrgv", "id": 16640218, "node_id": "MDQ6VXNlcjE2NjQwMjE4", "avatar_url": "https://avatars.githubusercontent.com/u/16640218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alsrgv", "html_url": "https://github.com/alsrgv", "followers_url": "https://api.github.com/users/alsrgv/followers", "following_url": "https://api.github.com/users/alsrgv/following{/other_user}", "gists_url": "https://api.github.com/users/alsrgv/gists{/gist_id}", "starred_url": "https://api.github.com/users/alsrgv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alsrgv/subscriptions", "organizations_url": "https://api.github.com/users/alsrgv/orgs", "repos_url": "https://api.github.com/users/alsrgv/repos", "events_url": "https://api.github.com/users/alsrgv/events{/privacy}", "received_events_url": "https://api.github.com/users/alsrgv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-08-19T16:15:44Z", "updated_at": "2019-08-19T20:32:53Z", "closed_at": "2019-08-19T20:32:52Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "@alsrgv : Your last commit: 2be9d1492a1483a9d1f38343261d9350bdf1dcd5 introduces an issue with Tensorflow 2.\r\n\r\n```python\r\nFile \"/workspace/mask_rcnn/mask_rcnn_model.py\", line 459, in _model_fn\r\n    train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/experimental/loss_scale_optimizer.py\", line 183, in apply_gradients\r\n    self._distributed_apply, args=(grads_and_vars, global_step, name))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1940, in merge_call\r\n    return self._merge_call(merge_fn, args, kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1947, in _merge_call\r\n    return merge_fn(self._strategy, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/experimental/loss_scale_optimizer.py\", line 218, in _distributed_apply\r\n    control_flow_ops.no_op)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/smart_cond.py\", line 59, in smart_cond\r\n    name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 1174, in cond\r\n    return cond_v2.cond_v2(pred, true_fn, false_fn, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/cond_v2.py\", line 84, in cond_v2\r\n    op_return_value=pred)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/experimental/loss_scale_optimizer.py\", line 215, in apply_fn\r\n    name + '-wrapped')\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/experimental/loss_scale_optimizer.py\", line 226, in _apply_gradients\r\n    args=(grads_and_vars, global_step, name))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1810, in call_for_each_replica\r\n    return self._call_for_each_replica(fn, args, kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 2155, in _call_for_each_replica\r\n    return fn(*args, **kwargs)\r\nTypeError: apply_gradients() takes 2 positional arguments but 4 were given\r\n```\r\n\r\nIf I rollback to commit 61e62f7a0a6a73a567c96e61bb6edbe861c5181a, everything is fine ;)", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1315/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1315/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1282", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1282/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1282/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1282/events", "html_url": "https://github.com/horovod/horovod/issues/1282", "id": 478098467, "node_id": "MDU6SXNzdWU0NzgwOTg0Njc=", "number": 1282, "title": "Autotuner causes unstable training behavior at startup due to possible race condition", "user": {"login": "romerojosh", "id": 5974496, "node_id": "MDQ6VXNlcjU5NzQ0OTY=", "avatar_url": "https://avatars.githubusercontent.com/u/5974496?v=4", "gravatar_id": "", "url": "https://api.github.com/users/romerojosh", "html_url": "https://github.com/romerojosh", "followers_url": "https://api.github.com/users/romerojosh/followers", "following_url": "https://api.github.com/users/romerojosh/following{/other_user}", "gists_url": "https://api.github.com/users/romerojosh/gists{/gist_id}", "starred_url": "https://api.github.com/users/romerojosh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/romerojosh/subscriptions", "organizations_url": "https://api.github.com/users/romerojosh/orgs", "repos_url": "https://api.github.com/users/romerojosh/repos", "events_url": "https://api.github.com/users/romerojosh/events{/privacy}", "received_events_url": "https://api.github.com/users/romerojosh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2019-08-07T19:23:15Z", "updated_at": "2019-08-10T18:09:38Z", "closed_at": "2019-08-10T18:09:38Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Tensorflow\r\n2. Framework version: 1.14.0\r\n3. Horovod version: 0.16.4\r\n4. MPI version: OpenMPI 3.1.4\r\n5. CUDA version: 10.1\r\n6. NCCL version: 2.4.8\r\n7. Python version: 3.6.8\r\n8. OS and version: Ubuntu 18.04.2\r\n9. GCC version: 7.4.0\r\n\r\n**Bug report:**\r\nRecently, one of our developers has been running cases with TensorFlow + AMP and noticed some very unstable training behavior at startup while the autotuner is active, indicating some type of data corruption occurring with the gradients. The instability does not occur with the autotuner disabled.\r\n\r\nWe ran a lot of experiments and found that the issue appears to be related to modifications to `HOROVOD_FUSION_THRESHOLD`, as the training with autotuning stabilizes _if_ we set that parameter to a fixed value. \r\n\r\nI dug around in the code and I think it is possible that there may be a race condition which occurs when the fusion buffer size is updated by the autotuner. Since NCCL/CUDA operations are completed asynchronously w.r.t to the main Horovod thread, there seems to be a possibility that a subsequent op can trigger a reallocation of the fusion buffer *before* the previous NCCL/CUDA operation completes.\r\n\r\nTo test this hypothesis, I changed the `detach()` of the finalizer thread to `join()` to force the main thread to wait until NCCL/CUDA operations complete before continuing (see  romerojosh/horovod@5983aa6115bdc2cc039c249546270d8ee7fd0160) With this change, the training runs stably with the autotuner enabled and a variable fusion threshold. I don't think this is a proper fix as it introduces unnecessary serialization, however it does suggest that some type of sync is necessary when modifying the fusion threshold during training.\r\n\r\ncc @DEKHTIARJonathan\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1282/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1282/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1261", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1261/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1261/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1261/events", "html_url": "https://github.com/horovod/horovod/issues/1261", "id": 474279916, "node_id": "MDU6SXNzdWU0NzQyNzk5MTY=", "number": 1261, "title": "Errors: Signal: Segmentation fault / Signal code: Address not mapped (1)", "user": {"login": "vilmara", "id": 30601934, "node_id": "MDQ6VXNlcjMwNjAxOTM0", "avatar_url": "https://avatars.githubusercontent.com/u/30601934?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vilmara", "html_url": "https://github.com/vilmara", "followers_url": "https://api.github.com/users/vilmara/followers", "following_url": "https://api.github.com/users/vilmara/following{/other_user}", "gists_url": "https://api.github.com/users/vilmara/gists{/gist_id}", "starred_url": "https://api.github.com/users/vilmara/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vilmara/subscriptions", "organizations_url": "https://api.github.com/users/vilmara/orgs", "repos_url": "https://api.github.com/users/vilmara/repos", "events_url": "https://api.github.com/users/vilmara/events{/privacy}", "received_events_url": "https://api.github.com/users/vilmara/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-07-29T22:11:40Z", "updated_at": "2019-11-15T17:48:05Z", "closed_at": "2019-11-15T17:48:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): TF 1.14 \r\n2. Framework version: \r\n3. Horovod version: Horovod-0.16.4\r\n4. MPI version:  4.0.1\r\n5. CUDA version: 7.6.0.64-1+cuda10.0\r\n6. NCCL version: 2.4.7-1+cuda10.0\r\n7. Python version: 2.7\r\n8. OS and version: Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-143-generic x86_64)\r\n9. GCC version: gcc version 5.4.0 20160609\r\n10. Mellanox OFED: 4.6.1\r\n\r\n\r\n**Bug report:**\r\nI all, I have built Horovod docker with Mellanox OFED 4.6.1 support (with extended dockerfile) \r\nand run the tensorflow benchmarks in distributed mode but getting these errors:\r\n\r\n```\r\n[primary_node] *** Process received signal ***\r\n[primary_node] Signal: Segmentation fault (11)\r\n[primary_node] Signal code: Address not mapped (1)\r\n[primary_node] Failing at address: 0x88\r\n[primary_node] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7fe68648e390]\r\n[primary_node] [ 1] /usr/local/lib/python2.7/dist-packages/horovod/tensorflow/mpi_lib.so(+0x7cf30)[0x7fe59c1b5f30]\r\n[primary_node] [ 2] /usr/local/lib/python2.7/dist-packages/horovod/tensorflow/mpi_lib.so(+0x7e600)[0x7fe59c1b7600]\r\n[primary_node] [ 3] /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so.1(_ZN10tensorflow15shape_inference16InferenceContext3RunERKSt8functionIFNS_6StatusEPS1_EE+0x4d)[0x7fe5a8db1a9d]\r\n[primary_node] [ 4] /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow12ShapeRefiner10RunShapeFnEPKNS_4NodeEPKNS_18OpRegistrationDataEPNS_24ExtendedInferenceContextE+0x230)[0x7fe5b2026350]\r\n[primary_node] [ 5] /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow12ShapeRefiner7AddNodeEPKNS_4NodeE+0xcb8)[0x7fe5b2027e78]\r\n[primary_node] [ 6] /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(TF_FinishOperation+0x44a)[0x7fe5aee7575a]\r\n[primary_node] [ 7] /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x2991bd6)[0x7fe5ac6e8bd6]\r\n[primary_node] [ 8] python(PyEval_EvalFrameEx+0x5ca)[0x4bc4aa]\r\n[primary_node] [ 9] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[primary_node] [10] python(PyEval_EvalFrameEx+0x6076)[0x4c1f56]\r\n[primary_node] [11] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[primary_node] [12] python[0x4d57a3]\r\n[primary_node] [13] python[0x4eef5e]\r\n[primary_node] [14] python[0x4eeb66]\r\n[primary_node] [15] python[0x4aaafb]\r\n[primary_node] [16] python(PyEval_EvalFrameEx+0x578d)[0x4c166d]\r\n[primary_node] [17] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[primary_node] [18] python[0x4d57a3]\r\n[primary_node] [19] python(PyObject_Call+0x3e)[0x4a587e]\r\n[primary_node] [20] python(PyEval_EvalFrameEx+0x263e)[0x4be51e]\r\n[primary_node] [21] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[primary_node] [22] python(PyEval_EvalFrameEx+0x6076)[0x4c1f56]\r\n[primary_node] [23] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[primary_node] [24] python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]\r\n[primary_node] [25] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[primary_node] [26] python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]\r\n[primary_node] [27] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[primary_node] [28] python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]\r\n[primary_node] [29] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[primary_node] *** End of error message ***\r\n[secondary_node] *** Process received signal ***\r\n[secondary_node] Signal: Segmentation fault (11)\r\n[secondary_node] Signal code: Address not mapped (1)\r\n[secondary_node] Failing at address: 0x88\r\n[secondary_node] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7f38741ba390]\r\n[secondary_node] [ 1] /usr/local/lib/python2.7/dist-packages/horovod/tensorflow/mpi_lib.so(+0x7cf30)[0x7f3823895f30]\r\n[secondary_node] [ 2] /usr/local/lib/python2.7/dist-packages/horovod/tensorflow/mpi_lib.so(+0x7e600)[0x7f3823897600]\r\n[secondary_node] [ 3] /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so.1(_ZN10tensorflow15shape_inference16InferenceContext3RunERKSt8functionIFNS_6StatusEPS1_EE+0x4d)[0x7f3796adda9d]\r\n[secondary_node] [ 4] /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow12ShapeRefiner10RunShapeFnEPKNS_4NodeEPKNS_18OpRegistrationDataEPNS_24ExtendedInferenceContextE+0x230)[0x7f379fd52350]\r\n[secondary_node] [ 5] /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow12ShapeRefiner7AddNodeEPKNS_4NodeE+0xcb8)[0x7f379fd53e78]\r\n[secondary_node] [ 6] /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(TF_FinishOperation+0x44a)[0x7f379cba175a]\r\n[secondary_node] [ 7] /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x2991bd6)[0x7f379a414bd6]\r\n[secondary_node] [ 8] python(PyEval_EvalFrameEx+0x5ca)[0x4bc4aa]\r\n[secondary_node] [ 9] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[secondary_node] [10] python(PyEval_EvalFrameEx+0x6076)[0x4c1f56]\r\n[secondary_node] [11] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[secondary_node] [12] python[0x4d57a3]\r\n[secondary_node] [13] python[0x4eef5e]\r\n[secondary_node] [14] python[0x4eeb66]\r\n[secondary_node] [15] python[0x4aaafb]\r\n[secondary_node] [16] python(PyEval_EvalFrameEx+0x578d)[0x4c166d]\r\n[secondary_node] [17] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[secondary_node] [18] python[0x4d57a3]\r\n[secondary_node] [19] python(PyObject_Call+0x3e)[0x4a587e]\r\n[secondary_node] [20] python(PyEval_EvalFrameEx+0x263e)[0x4be51e]\r\n[secondary_node] [21] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[secondary_node] [22] python(PyEval_EvalFrameEx+0x6076)[0x4c1f56]\r\n[secondary_node] [23] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[secondary_node] [24] python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]\r\n[secondary_node] [25] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[secondary_node] [26] python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]\r\n[secondary_node] [27] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[secondary_node] [28] python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]\r\n[secondary_node] [29] python(PyEval_EvalCodeEx+0x306)[0x4b9b66]\r\n[secondary_node] *** End of error message ***\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun noticed that process rank 0 with PID 0 on node primary_node exited on signal 11 (Segmentation fault).\r\n```\r\n\r\n**Command to reproduce:**\r\n`mpirun -np 2 -H <ib0 ip primary node>:1,<ib0 ip secondary node>:1 --allow-run-as-root -x NCCL_IB_DISABLE=0 -x NCCL_IB_CUDA_SUPPORT=1 -mca btl_tcp_if_include ib0 -x NCCL_SOCKET_IFNAME=ib0 -x NCCL_DEBUG=INFO --bind-to none --map-by slot --mca plm_rsh_args \"-p 50000\" python tf_cnn_benchmarks.py --device=gpu --data_format=NCHW --optimizer=sgd --distortions=false --use_fp16=True --local_parameter_device=gpu  --variable_update=horovod --horovod_device=gpu --datasets_num_private_threads=4 --data_dir=/data/imagenet_tfrecord/train --data_name=imagenet --display_every=1 --model=vgg16 --batch_size=32`\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1261/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1261/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1225", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1225/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1225/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1225/events", "html_url": "https://github.com/horovod/horovod/issues/1225", "id": 468590513, "node_id": "MDU6SXNzdWU0Njg1OTA1MTM=", "number": 1225, "title": "Horovod 0.16.4 fails to build with tf-nightly==1.15.0.dev20190716", "user": {"login": "byronyi", "id": 2613663, "node_id": "MDQ6VXNlcjI2MTM2NjM=", "avatar_url": "https://avatars.githubusercontent.com/u/2613663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byronyi", "html_url": "https://github.com/byronyi", "followers_url": "https://api.github.com/users/byronyi/followers", "following_url": "https://api.github.com/users/byronyi/following{/other_user}", "gists_url": "https://api.github.com/users/byronyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/byronyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byronyi/subscriptions", "organizations_url": "https://api.github.com/users/byronyi/orgs", "repos_url": "https://api.github.com/users/byronyi/repos", "events_url": "https://api.github.com/users/byronyi/events{/privacy}", "received_events_url": "https://api.github.com/users/byronyi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-07-16T11:04:15Z", "updated_at": "2019-07-19T18:31:18Z", "closed_at": "2019-07-17T11:17:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "```\r\n$ pip install -U tf-nightly\r\nCollecting tf-nightly\r\n  Downloading https://files.pythonhosted.org/packages/8f/4c/10b94ba3bfc282fa584cb97f4d17f3153d123fcf54c4033a64c0d3cc7ac8/tf_nightly-1.15.0.dev20190716-cp37-cp37m-manylinux1_x86_64.whl (101.2MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 101.2MB 1.4MB/s\r\nRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (3.8.0)\r\nRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (1.1.0)\r\nRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (1.1.0)\r\nRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (1.22.0)\r\nRequirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (1.0.8)\r\nRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (1.16.4)\r\nRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (0.8.0)\r\nRequirement already satisfied, skipping upgrade: wheel>=0.26 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (0.33.4)\r\nRequirement already satisfied, skipping upgrade: six>=1.10.0 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (1.12.0)\r\nRequirement already satisfied, skipping upgrade: gast>=0.2.0 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (0.2.2)\r\nCollecting tb-nightly<1.16.0a0,>=1.15.0a0 (from tf-nightly)\r\n  Downloading https://files.pythonhosted.org/packages/b5/e1/6870e90450a7d0ce7bc0f50654c008f2de3d824fd94105e19577c8446b35/tb_nightly-1.15.0a20190715-py3-none-any.whl (3.9MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.9MB 45.6MB/s\r\nRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (2.3.2)\r\nRequirement already satisfied, skipping upgrade: tf-estimator-nightly in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (1.14.0.dev2019070501)\r\nRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (1.11.2)\r\nRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (0.7.1)\r\nRequirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tf-nightly) (0.1.7)\r\nRequirement already satisfied, skipping upgrade: setuptools in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from protobuf>=3.6.1->tf-nightly) (41.0.1)\r\nRequirement already satisfied, skipping upgrade: h5py in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from keras-applications>=1.0.8->tf-nightly) (2.9.0)\r\nRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly) (3.1.1)\r\nRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly) (0.15.4)\r\nInstalling collected packages: tb-nightly, tf-nightly\r\n  Found existing installation: tb-nightly 1.14.0a20190614\r\n    Uninstalling tb-nightly-1.14.0a20190614:\r\n      Successfully uninstalled tb-nightly-1.14.0a20190614\r\n  Found existing installation: tf-nightly 1.15.0.dev20190705\r\n    Uninstalling tf-nightly-1.15.0.dev20190705:\r\n      Successfully uninstalled tf-nightly-1.15.0.dev20190705\r\nSuccessfully installed tb-nightly-1.15.0a20190715 tf-nightly-1.15.0.dev20190716\r\n$ HOROVOD_WITH_TENSORFLOW=1 pip install horovod\r\nCollecting horovod\r\n  Downloading https://files.pythonhosted.org/packages/42/f8/0a2fedf45122d8a1b2dbd573e737ccb32cd0776aa4c4b157d3f18b9ff0ca/horovod-0.16.4.tar.gz (2.6MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.6MB 492kB/s\r\nCollecting cloudpickle (from horovod)\r\n  Downloading https://files.pythonhosted.org/packages/09/f4/4a080c349c1680a2086196fcf0286a65931708156f39568ed7051e42ff6a/cloudpickle-1.2.1-py2.py3-none-any.whl\r\nCollecting psutil (from horovod)\r\n  Using cached https://files.pythonhosted.org/packages/1c/ca/5b8c1fe032a458c2c4bcbe509d1401dca9dda35c7fc46b36bb81c2834740/psutil-5.6.3.tar.gz\r\nRequirement already satisfied: six in /home/byronyi/.virtualenv/tf/lib/python3.7/site-packages (from horovod) (1.12.0)\r\nCollecting cffi>=1.4.0 (from horovod)\r\n  Downloading https://files.pythonhosted.org/packages/a0/ea/37fe21475c884f88a2ae496cab10e8f84f0cc11137be860af9eb37a3edb9/cffi-1.12.3-cp37-cp37m-manylinux1_x86_64.whl (430kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 440kB 31.7MB/s\r\nCollecting pycparser (from cffi>=1.4.0->horovod)\r\nBuilding wheels for collected packages: horovod, psutil\r\n  Building wheel for horovod (setup.py) ... error\r\n  ERROR: Complete output from command /home/byronyi/.virtualenv/tf/bin/python3 -u -c 'import setuptools, tokenize;__file__='\"'\"'/tmp/pip-install-1zoqwith/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-2abx3ylr --python-tag cp37:\r\n  ERROR:\r\n  Installed /tmp/pip-install-1zoqwith/horovod/.eggs/psutil-5.6.3-py3.7-linux-x86_64.egg\r\n  Searching for cloudpickle\r\n  Reading https://pypi.org/simple/cloudpickle/\r\n  Downloading https://files.pythonhosted.org/packages/09/f4/4a080c349c1680a2086196fcf0286a65931708156f39568ed7051e42ff6a/cloudpickle-1.2.1-py2.py3-none-any.whl#sha256=b8ba7e322f2394b9bbbdc1c976e6442c2c02acc784cb9e553cee9186166a6890\r\n  Best match: cloudpickle 1.2.1\r\n  Processing cloudpickle-1.2.1-py2.py3-none-any.whl\r\n  Installing cloudpickle-1.2.1-py2.py3-none-any.whl to /tmp/pip-install-1zoqwith/horovod/.eggs\r\n\r\n  Installed /tmp/pip-install-1zoqwith/horovod/.eggs/cloudpickle-1.2.1-py3.7.egg\r\n  Searching for pycparser\r\n  Reading https://pypi.org/simple/pycparser/\r\n  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz#sha256=a988718abfad80b6b157acce7bf130a30876d27603738ac39f140993246b25b3\r\n  Best match: pycparser 2.19\r\n  Processing pycparser-2.19.tar.gz\r\n  Writing /tmp/easy_install-yac8lgye/pycparser-2.19/setup.cfg\r\n  Running pycparser-2.19/setup.py -q bdist_egg --dist-dir /tmp/easy_install-yac8lgye/pycparser-2.19/egg-dist-tmp-staopu11\r\n  warning: no previously-included files found matching 'setup.pyc'\r\n  warning: no previously-included files matching 'yacctab.*' found under directory 'tests'\r\n  warning: no previously-included files matching 'lextab.*' found under directory 'tests'\r\n  warning: no previously-included files matching 'yacctab.*' found under directory 'examples'\r\n  warning: no previously-included files matching 'lextab.*' found under directory 'examples'\r\n  zip_safe flag not set; analyzing archive contents...\r\n  pycparser.ply.__pycache__.lex.cpython-37: module references __file__\r\n  pycparser.ply.__pycache__.lex.cpython-37: module MAY be using inspect.getsourcefile\r\n  pycparser.ply.__pycache__.yacc.cpython-37: module references __file__\r\n  pycparser.ply.__pycache__.yacc.cpython-37: module MAY be using inspect.getsourcefile\r\n  pycparser.ply.__pycache__.yacc.cpython-37: module MAY be using inspect.stack\r\n  pycparser.ply.__pycache__.ygen.cpython-37: module references __file__\r\n  creating /tmp/pip-install-1zoqwith/horovod/.eggs/pycparser-2.19-py3.7.egg\r\n  Extracting pycparser-2.19-py3.7.egg to /tmp/pip-install-1zoqwith/horovod/.eggs\r\n\r\n  Installed /tmp/pip-install-1zoqwith/horovod/.eggs/pycparser-2.19-py3.7.egg\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib.linux-x86_64-3.7\r\n  creating build/lib.linux-x86_64-3.7/horovod\r\n  copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark\r\n  copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n  creating build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  creating build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n  copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n  copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  creating build/lib.linux-x86_64-3.7/horovod/keras\r\n  copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n  copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/task\r\n  copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n  copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common\r\n  copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n  copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n  copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n  running build_ext\r\n  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -std=c++11 -fPIC -O2 -Wall -I/usr/include/python3.7m -I/home/byronyi/.virtualenv/tf/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n  x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.so\r\n  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.7m -I/home/byronyi/.virtualenv/tf/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o\r\n  x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.so\r\n  error: Your TensorFlow version is outdated.  Horovod requires tensorflow>=1.1.0\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n  Running setup.py clean for horovod\r\n  Building wheel for psutil (setup.py) ... done\r\n  Stored in directory: /home/byronyi/.cache/pip/wheels/90/7e/74/bb640d77775e6b6a78bcc3120f9fea4d2a28b2706de1cff37d\r\nSuccessfully built psutil\r\nFailed to build horovod\r\nInstalling collected packages: cloudpickle, psutil, pycparser, cffi, horovod\r\n  Running setup.py install for horovod ... error\r\n    ERROR: Complete output from command /home/byronyi/.virtualenv/tf/bin/python3 -u -c 'import setuptools, tokenize;__file__='\"'\"'/tmp/pip-install-1zoqwith/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-cxfrfhv7/install-record.txt --single-version-externally-managed --compile --install-headers /home/byronyi/.virtualenv/tf/include/site/python3.7/horovod:\r\n    ERROR: running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.7\r\n    creating build/lib.linux-x86_64-3.7/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    creating build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    creating build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    creating build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/task\r\n    copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n    copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common\r\n    copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    running build_ext\r\n    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -std=c++11 -fPIC -O2 -Wall -I/usr/include/python3.7m -I/home/byronyi/.virtualenv/tf/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n    x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.so\r\n    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.7m -I/home/byronyi/.virtualenv/tf/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o\r\n    x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.so\r\n    error: Your TensorFlow version is outdated.  Horovod requires tensorflow>=1.1.0\r\n    ----------------------------------------\r\nERROR: Command \"/home/byronyi/.virtualenv/tf/bin/python3 -u -c 'import setuptools, tokenize;__file__='\"'\"'/tmp/pip-install-1zoqwith/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-cxfrfhv7/install-record.txt --single-version-externally-managed --compile --install-headers /home/byronyi/.virtualenv/tf/include/site/python3.7/horovod\" failed with error code 1 in /tmp/pip-install-1zoqwith/horovod/\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1225/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1225/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1222", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1222/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1222/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1222/events", "html_url": "https://github.com/horovod/horovod/issues/1222", "id": 467858936, "node_id": "MDU6SXNzdWU0Njc4NTg5MzY=", "number": 1222, "title": "horovod spark toy example got hang on CDH 5.14.0 cluster", "user": {"login": "hero78119", "id": 3962077, "node_id": "MDQ6VXNlcjM5NjIwNzc=", "avatar_url": "https://avatars.githubusercontent.com/u/3962077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hero78119", "html_url": "https://github.com/hero78119", "followers_url": "https://api.github.com/users/hero78119/followers", "following_url": "https://api.github.com/users/hero78119/following{/other_user}", "gists_url": "https://api.github.com/users/hero78119/gists{/gist_id}", "starred_url": "https://api.github.com/users/hero78119/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hero78119/subscriptions", "organizations_url": "https://api.github.com/users/hero78119/orgs", "repos_url": "https://api.github.com/users/hero78119/repos", "events_url": "https://api.github.com/users/hero78119/events{/privacy}", "received_events_url": "https://api.github.com/users/hero78119/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-07-14T16:26:47Z", "updated_at": "2019-08-05T14:36:29Z", "closed_at": "2019-07-29T16:27:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): Tensorflow\r\n2. Framework version:1.13.1\r\n3. Horovod version: 0.16.4\r\n4. MPI version: 4.0.1\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 2.7.12\r\n8. OS and version: ubuntu 16.04\r\n9. GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0\r\n\r\nHi,\r\n\r\nI try to run horovod spark toy example (follow https://github.com/horovod/horovod/blob/master/docs/spark.rst) on an existing yarn cluster to experiment CPUs trainings but unfortunately not work on my side. (with 1 driver and 2 executors, 2 executor got allocated on same host with different port, CDH 5.14.0, spark version 2.2.0)\r\n\r\nBelow is the error I got on spark driver\r\n```\r\nException happened during processing of request from ('127.0.0.1', 44334)\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 596, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 331, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 652, in __init__\r\n    self.handle()\r\n  File \"/data23/yarn/nm/usercache/ld-wusm/appcache/application_1547982120377_497782/container_1547982120377_497782_01_000001/Python/lib/python2.7/site-packages/horovod/run/common/util/network.py\", line 117, in handle\r\n    resp = server._handle(req, self.client_address)\r\n  File \"/data23/yarn/nm/usercache/ld-wusm/appcache/application_1547982120377_497782/container_1547982120377_497782_01_000001/Python/lib/python2.7/site-packages/horovod/spark/driver/driver_service.py\", line 77, in _handle\r\n    return TaskHostHashIndicesResponse(self._task_host_hash_indices[req.host_hash])\r\nKeyError: 'yarn-node-1'\r\n```\r\n\r\nI try to add debug log to print `_task_host_hash_indices` \r\n```\r\n{'yarn-node-1.mydomain.com-3f1b8d32ce24bc926c4f2c7726cd9d81': [0, 1]}\r\n```\r\nSo apparently `yarn-node-1` not a valid key, seems hostname got trim to`yarn-node-1`. \r\n\r\nAfter reading related issue and I manually applied #1201 fix (cause it haven't bump to horovod 0.16.5), the spark job then just got hang. After changing verbose level, on spark **driver** I notice the mpirun command looks like below\r\n```\r\n+ mpirun --allow-run-as-root --tag-output -np 2 -H yarn-node-1-eb5f156d4c844f36de9cfc251398d421:2 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca btl_tcp_if_include lo,bond0.1148 -x NCCL_DEBUG=INFO -x NCCL_SOCKET_IFNAME=lo,bond0.1148 -x CMF_PACKAGE_DIR -x CM_STATUS_CODES -x CGROUP_ROOT_CPUACCT -x SHELL -x CDH_VERSION -x CDH_SQOOP2_HOME -x KEYTRUSTEE_SERVER_HOME -x YARN_RESOURCEMANAGER_OPTS -x JSVC_HOME -x SUPERVISOR_ENABLED -x CLOUDERA_POSTGRESQL_JDBC_JAR -x CGROUP_GROUP_CPUACCT -x JAVA_HOME -x YARN_ROOT_LOGGER -x IS_KERBERIZED -x CDH_ZOOKEEPER_HOME -x XDG_RUNTIME_DIR -x CONF_DIR -x PYTHONPATH -x CLOUDERA_MYSQL_CONNECTOR_JAR -x HADOOP_CONF_DIR -x XDG_SESSION_ID -x MAX_APP_ATTEMPTS -x CGROUP_ROOT_BLKIO -x CDH_HTTPFS_HOME -x WEBHCAT_DEFAULT_XML -x CDH_KAFKA_HOME -x SCM_DEFINES_SCRIPTS -x PARCELS_ROOT -x PYSPARK_PYTHON -x HADOOP_HOME_WARN_SUPPRESS -x CDH_PARQUET_HOME -x CMF_CONF_DIR -x MGMT_HOME -x SPARK_USER -x NM_LOCAL_DIRS -x NM_HTTP_PORT -x SUPERVISOR_GROUP_NAME -x CDH_HDFS_HOME -x PYTHONUNBUFFERED -x CDH_HUE_PLUGINS_HOME -x CLOUDERA_ORACLE_CONNECTOR_JAR -x LANGUAGE -x HADOOP_PREFIX -x SHLVL -x CDH_MR2_HOME -x HADOOP_YARN_HOME -x PYSPARK_DRIVER_PYTHON -x CDH_KMS_HOME -x CDH_HBASE_HOME -x _HOROVOD_SECRET_KEY -x NM_PORT -x SPARK_YARN_MODE -x JVM_PID -x CGROUP_ROOT_MEMORY -x LOCAL_DIRS -x CLASSPATH -x LOG_DIRS -x SUPERVISOR_PROCESS_NAME -x YARN_LOGFILE -x APPLICATION_WEB_PROXY_BASE -x MAIL -x NM_AUX_SERVICE_spark_shuffle -x HADOOP_HDFS_HOME -x _ -x YARN_CONF_DIR -x CDH_LLAMA_HOME -x CDH_HIVE_HOME -x CDH_SENTRY_HOME -x CDH_SPARK_HOME -x CDH_SOLR_HOME -x HADOOP_JOB_HISTORYSERVER_OPTS -x YARN_NODEMANAGER_OPTS -x CDH_MR1_HOME -x _SYSTEMCTL_SKIP_REDIRECT -x CGROUP_GROUP_CPU -x HOME -x HADOOP_CLIENT_CONF_DIR -x LD_LIBRARY_PATH -x LANG -x KEYTRUSTEE_KP_HOME -x HADOOP_COMMON_HOME -x HIVE_DEFAULT_XML -x PYTHONHASHSEED -x CDH_IMPALA_HOME -x CDH_SQOOP_HOME -x HADOOP_TOKEN_FILE_LOCATION -x HADOOP_MAPRED_HOME -x CGROUP_GROUP_BLKIO -x CDH_AVRO_HOME -x SPARK_YARN_STAGING_DIR -x CDH_CRUNCH_HOME -x CDH_HADOOP_HOME -x CONTAINER_ID -x YARN_LOG_DIR -x SPARK_DIST_CLASSPATH -x USER -x HADOOP_CLASSPATH -x CDH_HADOOP_BIN -x CGROUP_ROOT_CPU -x LOGNAME -x APP_SUBMIT_TIME_ENV -x PATH -x PARCEL_DIRNAMES -x CDH_KUDU_HOME -x CDH_YARN_HOME -x PYSPARK_GATEWAY_PORT -x MALLOC_ARENA_MAX -x CDH_HCAT_HOME -x CDH_OOZIE_HOME -x CDH_HUE_HOME -x CGROUP_GROUP_MEMORY -x SUPERVISOR_SERVER_URL -x HADOOP_LIBEXEC_DIR -x CDH_PIG_HOME -x NM_AUX_SERVICE_mapreduce_shuffle -x YARN_OPTS -x SEARCH_HOME -x ORACLE_HOME -x NM_HOST -x PWD -x CDH_HBASE_INDEXER_HOME -x TOMCAT_HOME -x CDH_FLUME_HOME -mca plm_rsh_agent \"/usr/bin/python -m horovod.spark.driver.mpirun_rsh {base64 encode message} {base64}\" /usr/bin/python -m horovod.spark.task.mpirun_exec_fn {base64 encode message} {base64}\r\n```\r\nwhere the hostname `yarn-node-1-eb5f156d4c844f36de9cfc251398d421` is executors hostname.\r\nand spark job got hang forever without error, and **NO** `print('Hello, rank = %d, local_rank = %d, size = %d, local_size = %d, magic_number = %d' % (hvd.rank(), hvd.local_rank(), hvd.size(), hvd.local_size(), magic_number))` output, seems it stuck at `hvd.init()` \r\n\r\nAfter inserting some debug log on `mpirun_rsh.py` and `mpirun_exec_fn.py`manually, I notice that `mpirun`  only invoked `mpirun_rsh.py` on driver node itself, and none of executors get invoked.\r\n\r\nMy question is, \r\n\r\n-  how mpirun recognize hostname after apply #1201 ? because https://github.com/horovod/horovod/blob/master/horovod/spark/__init__.py#L200 still use host_hash as hostname and `mpirun` do not specify hostfile.\r\n\r\n- Does this hang related to openmpi 4.0.1 ?\r\n\r\n- Do I miss other un-release changes other than #1201 ?\r\n\r\n- any parameters I should add to show more debug log ?\r\n\r\nThanks!\r\n\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1222/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1222/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1219", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1219/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1219/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1219/events", "html_url": "https://github.com/horovod/horovod/issues/1219", "id": 467694805, "node_id": "MDU6SXNzdWU0Njc2OTQ4MDU=", "number": 1219, "title": "Segmentation fault: address not mapped to object at address 0x88 when run horovod examples for tf1.14", "user": {"login": "shellhue", "id": 12797502, "node_id": "MDQ6VXNlcjEyNzk3NTAy", "avatar_url": "https://avatars.githubusercontent.com/u/12797502?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shellhue", "html_url": "https://github.com/shellhue", "followers_url": "https://api.github.com/users/shellhue/followers", "following_url": "https://api.github.com/users/shellhue/following{/other_user}", "gists_url": "https://api.github.com/users/shellhue/gists{/gist_id}", "starred_url": "https://api.github.com/users/shellhue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shellhue/subscriptions", "organizations_url": "https://api.github.com/users/shellhue/orgs", "repos_url": "https://api.github.com/users/shellhue/repos", "events_url": "https://api.github.com/users/shellhue/events{/privacy}", "received_events_url": "https://api.github.com/users/shellhue/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-07-13T09:06:31Z", "updated_at": "2019-07-17T12:52:12Z", "closed_at": "2019-07-17T12:52:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.14\r\n3. Horovod version: 0.16.4\r\n4. MPI version: openmpi-4.0.1\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.7\r\n7. Python version: 3.6.8\r\n8. OS and version: ubuntu 16.04\r\n9. GCC version: 5.4.0\r\n\r\nWhen i run the tensorflow minist example with the cmd below:\r\n```\r\n# horovod repository is located at user home directory\r\n# horovod repository is at commit 35b55c5\r\ncd ~/horovod/examples\r\nhorovodrun -np 8 python tensorflow_minist.py\r\n```\r\nThe logging info is:\r\n```\r\n[1,4]<stderr>:WARNING: Logging before flag parsing goes to stderr.\r\n[1,4]<stderr>:W0713 17:04:22.895230 140269850093312 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\r\n[1,4]<stderr>:\r\n[1,4]<stderr>:W0713 17:04:22.895446 140269850093312 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n[1,4]<stderr>:\r\n[1,4]<stderr>:W0713 17:04:22.895594 140269850093312 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n[1,4]<stderr>:\r\n[1,4]<stderr>:W0713 17:04:22.895655 140269850093312 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n[1,4]<stderr>:\r\n[1,4]<stderr>:W0713 17:04:22.895716 140269850093312 deprecation_wrapper.py:119] From tensorflow_mnist.py:160: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n[1,4]<stderr>:\r\n[1,1]<stderr>:WARNING: Logging before flag parsing goes to stderr.\r\n[1,1]<stderr>:W0713 17:04:22.912902 140454302607104 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\r\n[1,1]<stderr>:\r\n[1,1]<stderr>:W0713 17:04:22.913113 140454302607104 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n[1,1]<stderr>:\r\n[1,1]<stderr>:W0713 17:04:22.913270 140454302607104 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n[1,1]<stderr>:\r\n[1,1]<stderr>:W0713 17:04:22.913332 140454302607104 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n[1,1]<stderr>:\r\n[1,1]<stderr>:W0713 17:04:22.913394 140454302607104 deprecation_wrapper.py:119] From tensorflow_mnist.py:160: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n[1,1]<stderr>:\r\n[1,5]<stderr>:WARNING: Logging before flag parsing goes to stderr.\r\n[1,5]<stderr>:W0713 17:04:22.921228 140048297711360 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\r\n[1,5]<stderr>:\r\n[1,6]<stderr>:WARNING: Logging before flag parsing goes to stderr.\r\n[1,6]<stderr>:W0713 17:04:22.921242 140400193689344 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\r\n[1,6]<stderr>:\r\n[1,5]<stderr>:W0713 17:04:22.921417 140048297711360 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n[1,5]<stderr>:\r\n[1,6]<stderr>:W0713 17:04:22.921437 140400193689344 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n[1,6]<stderr>:\r\n[1,5]<stderr>:W0713 17:04:22.921562 140048297711360 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n[1,5]<stderr>:\r\n[1,6]<stderr>:W0713 17:04:22.921590 140400193689344 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n[1,6]<stderr>:\r\n[1,5]<stderr>:W0713 17:04:22.921625 140048297711360 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n[1,5]<stderr>:\r\n[1,6]<stderr>:W0713 17:04:22.921654 140400193689344 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n[1,6]<stderr>:\r\n[1,5]<stderr>:W0713 17:04:22.921683 140048297711360 deprecation_wrapper.py:119] From tensorflow_mnist.py:160: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n[1,5]<stderr>:\r\n[1,6]<stderr>:W0713 17:04:22.921713 140400193689344 deprecation_wrapper.py:119] From tensorflow_mnist.py:160: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n[1,6]<stderr>:\r\n[1,2]<stderr>:WARNING: Logging before flag parsing goes to stderr.\r\n[1,2]<stderr>:W0713 17:04:22.925751 140014709597952 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\r\n[1,2]<stderr>:\r\n[1,2]<stderr>:W0713 17:04:22.925948 140014709597952 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n[1,2]<stderr>:\r\n[1,2]<stderr>:W0713 17:04:22.926099 140014709597952 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n[1,2]<stderr>:\r\n[1,2]<stderr>:W0713 17:04:22.926163 140014709597952 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n[1,2]<stderr>:\r\n[1,2]<stderr>:W0713 17:04:22.926224 140014709597952 deprecation_wrapper.py:119] From tensorflow_mnist.py:160: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n[1,2]<stderr>:\r\n[1,0]<stderr>:WARNING: Logging before flag parsing goes to stderr.\r\n[1,0]<stderr>:W0713 17:04:22.936594 139794684401408 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:W0713 17:04:22.936803 139794684401408 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:W0713 17:04:22.936956 139794684401408 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:W0713 17:04:22.937021 139794684401408 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:W0713 17:04:22.937080 139794684401408 deprecation_wrapper.py:119] From tensorflow_mnist.py:160: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n[1,0]<stderr>:\r\n[1,3]<stderr>:WARNING: Logging before flag parsing goes to stderr.\r\n[1,3]<stderr>:W0713 17:04:22.935456 139779192895232 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\r\n[1,3]<stderr>:\r\n[1,3]<stderr>:W0713 17:04:22.935671 139779192895232 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n[1,3]<stderr>:\r\n[1,3]<stderr>:W0713 17:04:22.935815 139779192895232 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n[1,3]<stderr>:\r\n[1,3]<stderr>:W0713 17:04:22.935876 139779192895232 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n[1,3]<stderr>:\r\n[1,3]<stderr>:W0713 17:04:22.935936 139779192895232 deprecation_wrapper.py:119] From tensorflow_mnist.py:160: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n[1,3]<stderr>:\r\n[1,7]<stderr>:WARNING: Logging before flag parsing goes to stderr.\r\n[1,7]<stderr>:W0713 17:04:22.986232 139700469495552 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\r\n[1,7]<stderr>:\r\n[1,7]<stderr>:W0713 17:04:22.986442 139700469495552 deprecation_wrapper.py:119] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n[1,7]<stderr>:\r\n[1,7]<stderr>:W0713 17:04:22.986586 139700469495552 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n[1,7]<stderr>:\r\n[1,7]<stderr>:W0713 17:04:22.986647 139700469495552 deprecation_wrapper.py:119] From tensorflow_mnist.py:26: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n[1,7]<stderr>:\r\n[1,7]<stderr>:W0713 17:04:22.986707 139700469495552 deprecation_wrapper.py:119] From tensorflow_mnist.py:160: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n[1,7]<stderr>:\r\n[1,6]<stdout>:A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 8a61469f7ea1b51cbae51d4f78837e45 so we will re-download the data.\r\n[1,6]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,7]<stdout>:A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 8a61469f7ea1b51cbae51d4f78837e45 so we will re-download the data.\r\n[1,7]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,1]<stdout>:A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 8a61469f7ea1b51cbae51d4f78837e45 so we will re-download the data.\r\n[1,1]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,5]<stdout>:A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 8a61469f7ea1b51cbae51d4f78837e45 so we will re-download the data.\r\n[1,5]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,4]<stdout>:A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 8a61469f7ea1b51cbae51d4f78837e45 so we will re-download the data.\r\n[1,4]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n[1,0]<stderr>:W0713 17:04:23.390945 139794684401408 deprecation_wrapper.py:119] From tensorflow_mnist.py:110: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:W0713 17:04:23.405913 139794684401408 deprecation_wrapper.py:119] From tensorflow_mnist.py:40: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\r\n[1,0]<stderr>:\r\n[1,3]<stderr>:W0713 17:04:23.406030 139779192895232 deprecation_wrapper.py:119] From tensorflow_mnist.py:110: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\r\n[1,3]<stderr>:\r\n[1,0]<stderr>:W0713 17:04:23.406339 139794684401408 deprecation.py:323] From tensorflow_mnist.py:42: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\r\n[1,0]<stderr>:Instructions for updating:\r\n[1,0]<stderr>:Use `tf.keras.layers.Conv2D` instead.\r\n[1,0]<stderr>:W0713 17:04:23.410241 139794684401408 deprecation.py:506] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\n[1,0]<stderr>:Instructions for updating:\r\n[1,0]<stderr>:Call initializer instance with the dtype argument instead of passing it to the constructor\r\n[1,3]<stderr>:W0713 17:04:23.413235 139779192895232 deprecation_wrapper.py:119] From tensorflow_mnist.py:40: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\r\n[1,3]<stderr>:\r\n[1,3]<stderr>:W0713 17:04:23.413583 139779192895232 deprecation.py:323] From tensorflow_mnist.py:42: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\r\n[1,3]<stderr>:Instructions for updating:\r\n[1,3]<stderr>:Use `tf.keras.layers.Conv2D` instead.\r\n[1,3]<stderr>:W0713 17:04:23.417308 139779192895232 deprecation.py:506] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\n[1,3]<stderr>:Instructions for updating:\r\n[1,3]<stderr>:Call initializer instance with the dtype argument instead of passing it to the constructor\r\n[1,2]<stderr>:W0713 17:04:23.418197 140014709597952 deprecation_wrapper.py:119] From tensorflow_mnist.py:110: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\r\n[1,2]<stderr>:\r\n[1,2]<stderr>:W0713 17:04:23.428673 140014709597952 deprecation_wrapper.py:119] From tensorflow_mnist.py:40: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\r\n[1,2]<stderr>:\r\n[1,2]<stderr>:W0713 17:04:23.429009 140014709597952 deprecation.py:323] From tensorflow_mnist.py:42: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\r\n[1,2]<stderr>:Instructions for updating:\r\n[1,2]<stderr>:Use `tf.keras.layers.Conv2D` instead.\r\n[1,2]<stderr>:W0713 17:04:23.432641 140014709597952 deprecation.py:506] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\n[1,2]<stderr>:Instructions for updating:\r\n[1,2]<stderr>:Call initializer instance with the dtype argument instead of passing it to the constructor\r\n[1,3]<stderr>:W0713 17:04:23.586099 139779192895232 deprecation_wrapper.py:119] From tensorflow_mnist.py:43: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\r\n[1,3]<stderr>:\r\n[1,3]<stderr>:W0713 17:04:23.599879 139779192895232 deprecation.py:323] From tensorflow_mnist.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\n[1,3]<stderr>:Instructions for updating:\r\n[1,3]<stderr>:Use keras.layers.dense instead.\r\n[1,0]<stderr>:W0713 17:04:23.601578 139794684401408 deprecation_wrapper.py:119] From tensorflow_mnist.py:43: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:W0713 17:04:23.615322 139794684401408 deprecation.py:323] From tensorflow_mnist.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\n[1,0]<stderr>:Instructions for updating:\r\n[1,0]<stderr>:Use keras.layers.dense instead.\r\n[1,2]<stderr>:W0713 17:04:23.622808 140014709597952 deprecation_wrapper.py:119] From tensorflow_mnist.py:43: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\r\n[1,2]<stderr>:\r\n[1,2]<stderr>:W0713 17:04:23.638082 140014709597952 deprecation.py:323] From tensorflow_mnist.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\n[1,2]<stderr>:Instructions for updating:\r\n[1,2]<stderr>:Use keras.layers.dense instead.\r\n[1,3]<stderr>:W0713 17:04:23.791903 139779192895232 deprecation.py:323] From tensorflow_mnist.py:58: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\n[1,3]<stderr>:Instructions for updating:\r\n[1,3]<stderr>:Use keras.layers.dropout instead.\r\n[1,0]<stderr>:W0713 17:04:23.805643 139794684401408 deprecation.py:323] From tensorflow_mnist.py:58: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\n[1,0]<stderr>:Instructions for updating:\r\n[1,0]<stderr>:Use keras.layers.dropout instead.\r\n[1,2]<stderr>:W0713 17:04:23.829373 140014709597952 deprecation.py:323] From tensorflow_mnist.py:58: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\n[1,2]<stderr>:Instructions for updating:\r\n[1,2]<stderr>:Use keras.layers.dropout instead.\r\n[1,3]<stderr>:W0713 17:04:23.840426 139779192895232 deprecation_wrapper.py:119] From tensorflow_mnist.py:62: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\r\n[1,3]<stderr>:\r\n[1,0]<stderr>:W0713 17:04:23.854386 139794684401408 deprecation_wrapper.py:119] From tensorflow_mnist.py:62: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\r\n[1,0]<stderr>:\r\n[1,3]<stderr>:W0713 17:04:23.861858 139779192895232 deprecation.py:323] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\n[1,3]<stderr>:Instructions for updating:\r\n[1,3]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\r\n[1,3]<stderr>:W0713 17:04:23.869239 139779192895232 deprecation_wrapper.py:119] From tensorflow_mnist.py:115: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\r\n[1,3]<stderr>:\r\n[1,3]<stderr>:W0713 17:04:23.869384 139779192895232 deprecation_wrapper.py:119] From tensorflow_mnist.py:120: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n[1,3]<stderr>:\r\n[1,0]<stderr>:W0713 17:04:23.875179 139794684401408 deprecation.py:323] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\n[1,0]<stderr>:Instructions for updating:\r\n[1,0]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\r\n[1,2]<stderr>:W0713 17:04:23.878428 140014709597952 deprecation_wrapper.py:119] From tensorflow_mnist.py:62: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\r\n[1,2]<stderr>:\r\n[1,0]<stderr>:W0713 17:04:23.882385 139794684401408 deprecation_wrapper.py:119] From tensorflow_mnist.py:115: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:W0713 17:04:23.882552 139794684401408 deprecation_wrapper.py:119] From tensorflow_mnist.py:120: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n[1,0]<stderr>:\r\n[1,2]<stderr>:W0713 17:04:23.900639 140014709597952 deprecation.py:323] From /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\n[1,2]<stderr>:Instructions for updating:\r\n[1,2]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\r\n[1,2]<stderr>:W0713 17:04:23.908187 140014709597952 deprecation_wrapper.py:119] From tensorflow_mnist.py:115: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\r\n[1,2]<stderr>:\r\n[1,2]<stderr>:W0713 17:04:23.908324 140014709597952 deprecation_wrapper.py:119] From tensorflow_mnist.py:120: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n[1,2]<stderr>:\r\n[1,3]<stderr>:[comput3:105579:0:105579] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x88)\r\n[1,3]<stderr>:==== backtrace ====\r\n[1,3]<stderr>:    0  /usr/lib/libucs.so.0(+0x1fcec) [0x7f2046952cec]\r\n[1,3]<stderr>:    1  /usr/lib/libucs.so.0(+0x1ff64) [0x7f2046952f64]\r\n[1,3]<stderr>:    2  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0x7ff90) [0x7f205bd66f90]\r\n[1,3]<stderr>:    3  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0x81660) [0x7f205bd68660]\r\n[1,3]<stderr>:    4  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so.1(_ZN10tensorflow15shape_inference16InferenceContext3RunERKSt8functionIFNS_6StatusEPS1_EE+0x4d) [0x7f2068268a9d]\r\n[1,3]<stderr>:    5  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow12ShapeRefiner10RunShapeFnEPKNS_4NodeEPKNS_18OpRegistrationDataEPNS_24ExtendedInferenceContextE+0x230) [0x7f20714dd3b0]\r\n[1,3]<stderr>:    6  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow12ShapeRefiner7AddNodeEPKNS_4NodeE+0xcb8) [0x7f20714deed8]\r\n[1,3]<stderr>:    7  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(TF_FinishOperation+0x44a) [0x7f206e32c7ba]\r\n[1,3]<stderr>:    8  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x29917d6) [0x7f206bb9f7d6]\r\n[1,3]<stderr>:    9  python(_PyCFunction_FastCallDict+0x91) [0x5606eab55681]\r\n[1,3]<stderr>:   10  python(+0x19842c) [0x5606eabdc42c]\r\n[1,3]<stderr>:   11  python(_PyEval_EvalFrameDefault+0x30a) [0x5606eac0138a]\r\n[1,3]<stderr>:   12  python(+0x19253b) [0x5606eabd653b]\r\n[1,3]<stderr>:   13  python(+0x198505) [0x5606eabdc505]\r\n[1,3]<stderr>:   14  python(_PyEval_EvalFrameDefault+0x30a) [0x5606eac0138a]\r\n[1,3]<stderr>:   15  python(+0x191bfe) [0x5606eabd5bfe]\r\n[1,3]<stderr>:   16  python(_PyFunction_FastCallDict+0x3da) [0x5606eabd6e6a]\r\n[1,3]<stderr>:   17  python(_PyObject_FastCallDict+0x26f) [0x5606eab55b0f]\r\n[1,3]<stderr>:   18  python(_PyObject_Call_Prepend+0x63) [0x5606eab5a6a3]\r\n[1,3]<stderr>:   19  python(PyObject_Call+0x3e) [0x5606eab5554e]\r\n[1,3]<stderr>:   20  python(+0x16b0fb) [0x5606eabaf0fb]\r\n[1,3]<stderr>:   21  python(+0x198767) [0x5606eabdc767]\r\n[1,3]<stderr>:   22  python(_PyObject_FastCallDict+0x8b) [0x5606eab5592b]\r\n[1,3]<stderr>:   23  python(_PyObject_FastCallKeywords+0xaa) [0x5606eabd6a5a]\r\n[1,3]<stderr>:   24  python(+0x19857e) [0x5606eabdc57e]\r\n[1,3]<stderr>:   25  python(_PyEval_EvalFrameDefault+0x10c7) [0x5606eac02147]\r\n[1,3]<stderr>:   26  python(PyEval_EvalCodeEx+0x329) [0x5606eabd7289]\r\n[1,3]<stderr>:   27  python(+0x1941a6) [0x5606eabd81a6]\r\n[1,3]<stderr>:   28  python(PyObject_Call+0x3e) [0x5606eab5554e]\r\n[1,3]<stderr>:   29  python(_PyEval_EvalFrameDefault+0x19ec) [0x5606eac02a6c]\r\n[1,3]<stderr>:   30  python(+0x191bfe) [0x5606eabd5bfe]\r\n[1,3]<stderr>:   31  python(+0x192771) [0x5606eabd6771]\r\n[1,3]<stderr>:   32  python(+0x198505) [0x5606eabdc505]\r\n[1,3]<stderr>:   33  python(_PyEval_EvalFrameDefault+0x10c7) [0x5606eac02147]\r\n[1,3]<stderr>:   34  python(+0x191bfe) [0x5606eabd5bfe]\r\n[1,3]<stderr>:   35  python(+0x192771) [0x5606eabd6771]\r\n[1,3]<stderr>:   36  python(+0x198505) [0x5606eabdc505]\r\n[1,3]<stderr>:   37  python(_PyEval_EvalFrameDefault+0x10c7) [0x5606eac02147]\r\n[1,3]<stderr>:   38  python(+0x1918e4) [0x5606eabd58e4]\r\n[1,3]<stderr>:   39  python(+0x192771) [0x5606eabd6771]\r\n[1,3]<stderr>:   40  python(+0x198505) [0x5606eabdc505]\r\n[1,3]<stderr>:   41  python(_PyEval_EvalFrameDefault+0x10c7) [0x5606eac02147]\r\n[1,3]<stderr>:   42  python(+0x1918e4) [0x5606eabd58e4]\r\n[1,3]<stderr>:   43  python(+0x192771) [0x5606eabd6771]\r\n[1,3]<stderr>:   44  python(+0x198505) [0x5606eabdc505]\r\n[1,3]<stderr>:   45  python(_PyEval_EvalFrameDefault+0x30a) [0x5606eac0138a]\r\n[1,3]<stderr>:   46  python(+0x1918e4) [0x5606eabd58e4]\r\n[1,3]<stderr>:   47  python(+0x192771) [0x5606eabd6771]\r\n[1,3]<stderr>:   48  python(+0x198505) [0x5606eabdc505]\r\n[1,3]<stderr>:   49  python(_PyEval_EvalFrameDefault+0x10c7) [0x5606eac02147]\r\n[1,3]<stderr>:   50  python(+0x191a76) [0x5606eabd5a76]\r\n[1,3]<stderr>:   51  python(+0x192771) [0x5606eabd6771]\r\n[1,3]<stderr>:   52  python(+0x198505) [0x5606eabdc505]\r\n[1,3]<stderr>:   53  python(_PyEval_EvalFrameDefault+0x30a) [0x5606eac0138a]\r\n[1,3]<stderr>:   54  python(+0x191a76) [0x5606eabd5a76]\r\n[1,3]<stderr>:   55  python(+0x192771) [0x5606eabd6771]\r\n[1,3]<stderr>:   56  python(+0x198505) [0x5606eabdc505]\r\n[1,3]<stderr>:   57  python(_PyEval_EvalFrameDefault+0x30a) [0x5606eac0138a]\r\n[1,3]<stderr>:   58  python(+0x1918e4) [0x5606eabd58e4]\r\n[1,3]<stderr>:   59  python(+0x192771) [0x5606eabd6771]\r\n[1,3]<stderr>:   60  python(+0x198505) [0x5606eabdc505]\r\n[1,3]<stderr>:===================\r\n[1,0]<stderr>:[comput3:105576:0:105576] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x88)\r\n[1,0]<stderr>:==== backtrace ====\r\n[1,2]<stderr>:[comput3:105578:0:105578] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x88)\r\n[1,2]<stderr>:==== backtrace ====\r\n[1,0]<stderr>:    0  /usr/lib/libucs.so.0(+0x1fcec) [0x7f23e1edacec]\r\n[1,0]<stderr>:    1  /usr/lib/libucs.so.0(+0x1ff64) [0x7f23e1edaf64]\r\n[1,0]<stderr>:    2  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0x7ff90) [0x7f23f7340f90]\r\n[1,0]<stderr>:    3  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0x81660) [0x7f23f7342660]\r\n[1,0]<stderr>:    4  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so.1(_ZN10tensorflow15shape_inference16InferenceContext3RunERKSt8functionIFNS_6StatusEPS1_EE+0x4d) [0x7f2403842a9d]\r\n[1,0]<stderr>:    5  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow12ShapeRefiner10RunShapeFnEPKNS_4NodeEPKNS_18OpRegistrationDataEPNS_24ExtendedInferenceContextE+0x230) [0x7f240cab73b0]\r\n[1,0]<stderr>:    6  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow12ShapeRefiner7AddNodeEPKNS_4NodeE+0xcb8) [0x7f240cab8ed8]\r\n[1,0]<stderr>:    7  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(TF_FinishOperation+0x44a) [0x7f24099067ba]\r\n[1,0]<stderr>:    8  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x29917d6) [0x7f24071797d6]\r\n[1,0]<stderr>:    9  python(_PyCFunction_FastCallDict+0x91) [0x55613adab681]\r\n[1,0]<stderr>:   10  python(+0x19842c) [0x55613ae3242c]\r\n[1,0]<stderr>:   11  python(_PyEval_EvalFrameDefault+0x30a) [0x55613ae5738a]\r\n[1,0]<stderr>:   12  python(+0x19253b) [0x55613ae2c53b]\r\n[1,0]<stderr>:   13  python(+0x198505) [0x55613ae32505]\r\n[1,0]<stderr>:   14  python(_PyEval_EvalFrameDefault+0x30a) [0x55613ae5738a]\r\n[1,0]<stderr>:   15  python(+0x191bfe) [0x55613ae2bbfe]\r\n[1,0]<stderr>:   16  python(_PyFunction_FastCallDict+0x3da) [0x55613ae2ce6a]\r\n[1,0]<stderr>:   17  python(_PyObject_FastCallDict+0x26f) [0x55613adabb0f]\r\n[1,0]<stderr>:   18  python(_PyObject_Call_Prepend+0x63) [0x55613adb06a3]\r\n[1,0]<stderr>:   19  python(PyObject_Call+0x3e) [0x55613adab54e]\r\n[1,0]<stderr>:   20  python(+0x16b0fb) [0x55613ae050fb]\r\n[1,0]<stderr>:   21  python(+0x198767) [0x55613ae32767]\r\n[1,0]<stderr>:   22  python(_PyObject_FastCallDict+0x8b) [0x55613adab92b]\r\n[1,0]<stderr>:   23  python(_PyObject_FastCallKeywords+0xaa) [0x55613ae2ca5a]\r\n[1,0]<stderr>:   24  python(+0x19857e) [0x55613ae3257e]\r\n[1,0]<stderr>:   25  python(_PyEval_EvalFrameDefault+0x10c7) [0x55613ae58147]\r\n[1,0]<stderr>:   26  python(PyEval_EvalCodeEx+0x329) [0x55613ae2d289]\r\n[1,0]<stderr>:   27  python(+0x1941a6) [0x55613ae2e1a6]\r\n[1,0]<stderr>:   28  python(PyObject_Call+0x3e) [0x55613adab54e]\r\n[1,0]<stderr>:   29  python(_PyEval_EvalFrameDefault+0x19ec) [0x55613ae58a6c]\r\n[1,0]<stderr>:   30  python(+0x191bfe) [0x55613ae2bbfe]\r\n[1,0]<stderr>:   31  python(+0x192771) [0x55613ae2c771]\r\n[1,0]<stderr>:   32  python(+0x198505) [0x55613ae32505]\r\n[1,0]<stderr>:   33  python(_PyEval_EvalFrameDefault+0x10c7) [0x55613ae58147]\r\n[1,0]<stderr>:   34  python(+0x191bfe) [0x55613ae2bbfe]\r\n[1,0]<stderr>:   35  python(+0x192771) [0x55613ae2c771]\r\n[1,0]<stderr>:   36  python(+0x198505) [0x55613ae32505]\r\n[1,0]<stderr>:   37  python(_PyEval_EvalFrameDefault+0x10c7) [0x55613ae58147]\r\n[1,0]<stderr>:   38  python(+0x1918e4) [0x55613ae2b8e4]\r\n[1,0]<stderr>:   39  python(+0x192771) [0x55613ae2c771]\r\n[1,0]<stderr>:   40  python(+0x198505) [0x55613ae32505]\r\n[1,0]<stderr>:   41  python(_PyEval_EvalFrameDefault+0x10c7) [0x55613ae58147]\r\n[1,0]<stderr>:   42  python(+0x1918e4) [0x55613ae2b8e4]\r\n[1,0]<stderr>:   43  python(+0x192771) [0x55613ae2c771]\r\n[1,0]<stderr>:   44  python(+0x198505) [0x55613ae32505]\r\n[1,0]<stderr>:   45  python(_PyEval_EvalFrameDefault+0x30a) [0x55613ae5738a]\r\n[1,0]<stderr>:   46  python(+0x1918e4) [0x55613ae2b8e4]\r\n[1,0]<stderr>:   47  python(+0x192771) [0x55613ae2c771]\r\n[1,0]<stderr>:   48  python(+0x198505) [0x55613ae32505]\r\n[1,0]<stderr>:   49  python(_PyEval_EvalFrameDefault+0x10c7) [0x55613ae58147]\r\n[1,0]<stderr>:   50  python(+0x191a76) [0x55613ae2ba76]\r\n[1,0]<stderr>:   51  python(+0x192771) [0x55613ae2c771]\r\n[1,0]<stderr>:   52  python(+0x198505) [0x55613ae32505]\r\n[1,0]<stderr>:   53  python(_PyEval_EvalFrameDefault+0x30a) [0x55613ae5738a]\r\n[1,0]<stderr>:   54  python(+0x191a76) [0x55613ae2ba76]\r\n[1,0]<stderr>:   55  python(+0x192771) [0x55613ae2c771]\r\n[1,0]<stderr>:   56  python(+0x198505) [0x55613ae32505]\r\n[1,0]<stderr>:   57  python(_PyEval_EvalFrameDefault+0x30a) [0x55613ae5738a]\r\n[1,0]<stderr>:   58  python(+0x1918e4) [0x55613ae2b8e4]\r\n[1,0]<stderr>:   59  python(+0x192771) [0x55613ae2c771]\r\n[1,0]<stderr>:   60  python(+0x198505) [0x55613ae32505]\r\n[1,0]<stderr>:===================\r\n[1,2]<stderr>:    0  /usr/lib/libucs.so.0(+0x1fcec) [0x7f571c66ecec]\r\n[1,2]<stderr>:    1  /usr/lib/libucs.so.0(+0x1ff64) [0x7f571c66ef64]\r\n[1,2]<stderr>:    2  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0x7ff90) [0x7f5731ba1f90]\r\n[1,2]<stderr>:    3  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0x81660) [0x7f5731ba3660]\r\n[1,2]<stderr>:    4  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so.1(_ZN10tensorflow15shape_inference16InferenceContext3RunERKSt8functionIFNS_6StatusEPS1_EE+0x4d) [0x7f573e0a3a9d]\r\n[1,2]<stderr>:    5  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow12ShapeRefiner10RunShapeFnEPKNS_4NodeEPKNS_18OpRegistrationDataEPNS_24ExtendedInferenceContextE+0x230) [0x7f57473183b0]\r\n[1,2]<stderr>:    6  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow12ShapeRefiner7AddNodeEPKNS_4NodeE+0xcb8) [0x7f5747319ed8]\r\n[1,2]<stderr>:    7  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(TF_FinishOperation+0x44a) [0x7f57441677ba]\r\n[1,2]<stderr>:    8  /home/huangzeyu/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x29917d6) [0x7f57419da7d6]\r\n[1,2]<stderr>:    9  python(_PyCFunction_FastCallDict+0x91) [0x55f372382681]\r\n[1,2]<stderr>:   10  python(+0x19842c) [0x55f37240942c]\r\n[1,2]<stderr>:   11  python(_PyEval_EvalFrameDefault+0x30a) [0x55f37242e38a]\r\n[1,2]<stderr>:   12  python(+0x19253b) [0x55f37240353b]\r\n[1,2]<stderr>:   13  python(+0x198505) [0x55f372409505]\r\n[1,2]<stderr>:   14  python(_PyEval_EvalFrameDefault+0x30a) [0x55f37242e38a]\r\n[1,2]<stderr>:   15  python(+0x191bfe) [0x55f372402bfe]\r\n[1,2]<stderr>:   16  python(_PyFunction_FastCallDict+0x3da) [0x55f372403e6a]\r\n[1,2]<stderr>:   17  python(_PyObject_FastCallDict+0x26f) [0x55f372382b0f]\r\n[1,2]<stderr>:   18  python(_PyObject_Call_Prepend+0x63) [0x55f3723876a3]\r\n[1,2]<stderr>:   19  python(PyObject_Call+0x3e) [0x55f37238254e]\r\n[1,2]<stderr>:   20  python(+0x16b0fb) [0x55f3723dc0fb]\r\n[1,2]<stderr>:   21  python(+0x198767) [0x55f372409767]\r\n[1,2]<stderr>:   22  python(_PyObject_FastCallDict+0x8b) [0x55f37238292b]\r\n[1,2]<stderr>:   23  python(_PyObject_FastCallKeywords+0xaa) [0x55f372403a5a]\r\n[1,2]<stderr>:   24  python(+0x19857e) [0x55f37240957e]\r\n[1,2]<stderr>:   25  python(_PyEval_EvalFrameDefault+0x10c7) [0x55f37242f147]\r\n[1,2]<stderr>:   26  python(PyEval_EvalCodeEx+0x329) [0x55f372404289]\r\n[1,2]<stderr>:   27  python(+0x1941a6) [0x55f3724051a6]\r\n[1,2]<stderr>:   28  python(PyObject_Call+0x3e) [0x55f37238254e]\r\n[1,2]<stderr>:   29  python(_PyEval_EvalFrameDefault+0x19ec) [0x55f37242fa6c]\r\n[1,2]<stderr>:   30  python(+0x191bfe) [0x55f372402bfe]\r\n[1,2]<stderr>:   31  python(+0x192771) [0x55f372403771]\r\n[1,2]<stderr>:   32  python(+0x198505) [0x55f372409505]\r\n[1,2]<stderr>:   33  python(_PyEval_EvalFrameDefault+0x10c7) [0x55f37242f147]\r\n[1,2]<stderr>:   34  python(+0x191bfe) [0x55f372402bfe]\r\n[1,2]<stderr>:   35  python(+0x192771) [0x55f372403771]\r\n[1,2]<stderr>:   36  python(+0x198505) [0x55f372409505]\r\n[1,2]<stderr>:   37  python(_PyEval_EvalFrameDefault+0x10c7) [0x55f37242f147]\r\n[1,2]<stderr>:   38  python(+0x1918e4) [0x55f3724028e4]\r\n[1,2]<stderr>:   39  python(+0x192771) [0x55f372403771]\r\n[1,2]<stderr>:   40  python(+0x198505) [0x55f372409505]\r\n[1,2]<stderr>:   41  python(_PyEval_EvalFrameDefault+0x10c7) [0x55f37242f147]\r\n[1,2]<stderr>:   42  python(+0x1918e4) [0x55f3724028e4]\r\n[1,2]<stderr>:   43  python(+0x192771) [0x55f372403771]\r\n[1,2]<stderr>:   44  python(+0x198505) [0x55f372409505]\r\n[1,2]<stderr>:   45  python(_PyEval_EvalFrameDefault+0x30a) [0x55f37242e38a]\r\n[1,2]<stderr>:   46  python(+0x1918e4) [0x55f3724028e4]\r\n[1,2]<stderr>:   47  python(+0x192771) [0x55f372403771]\r\n[1,2]<stderr>:   48  python(+0x198505) [0x55f372409505]\r\n[1,2]<stderr>:   49  python(_PyEval_EvalFrameDefault+0x10c7) [0x55f37242f147]\r\n[1,2]<stderr>:   50  python(+0x191a76) [0x55f372402a76]\r\n[1,2]<stderr>:   51  python(+0x192771) [0x55f372403771]\r\n[1,2]<stderr>:   52  python(+0x198505) [0x55f372409505]\r\n[1,2]<stderr>:   53  python(_PyEval_EvalFrameDefault+0x30a) [0x55f37242e38a]\r\n[1,2]<stderr>:   54  python(+0x191a76) [0x55f372402a76]\r\n[1,2]<stderr>:   55  python(+0x192771) [0x55f372403771]\r\n[1,2]<stderr>:   56  python(+0x198505) [0x55f372409505]\r\n[1,2]<stderr>:   57  python(_PyEval_EvalFrameDefault+0x30a) [0x55f37242e38a]\r\n[1,2]<stderr>:   58  python(+0x1918e4) [0x55f3724028e4]\r\n[1,2]<stderr>:   59  python(+0x192771) [0x55f372403771]\r\n[1,2]<stderr>:   60  python(+0x198505) [0x55f372409505]\r\n[1,2]<stderr>:===================\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun noticed that process rank 3 with PID 0 on node comput3 exited on signal 11 (Segmentation fault).\r\n--------------------------------------------------------------------------\r\n```\r\n\r\nThe key error is:\r\n```\r\nCaught signal 11 (Segmentation fault: address not mapped to object at address 0x88)\r\n```\r\n\r\nI search on google, no lucky results got.\r\n\r\nDoes anyone have any idea?\r\n\r\np.s. the pytorch demo works.\r\n```\r\n# pytorch 1.1.0\r\nhorovodrun -np 8 python pytorch_mnist.py\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1219/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1219/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1217", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1217/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1217/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1217/events", "html_url": "https://github.com/horovod/horovod/issues/1217", "id": 467652941, "node_id": "MDU6SXNzdWU0Njc2NTI5NDE=", "number": 1217, "title": "MXNet cu100-pre broke docker build on CPU machine", "user": {"login": "alsrgv", "id": 16640218, "node_id": "MDQ6VXNlcjE2NjQwMjE4", "avatar_url": "https://avatars.githubusercontent.com/u/16640218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alsrgv", "html_url": "https://github.com/alsrgv", "followers_url": "https://api.github.com/users/alsrgv/followers", "following_url": "https://api.github.com/users/alsrgv/following{/other_user}", "gists_url": "https://api.github.com/users/alsrgv/gists{/gist_id}", "starred_url": "https://api.github.com/users/alsrgv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alsrgv/subscriptions", "organizations_url": "https://api.github.com/users/alsrgv/orgs", "repos_url": "https://api.github.com/users/alsrgv/repos", "events_url": "https://api.github.com/users/alsrgv/events{/privacy}", "received_events_url": "https://api.github.com/users/alsrgv/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2019-07-13T01:32:52Z", "updated_at": "2019-07-22T23:14:24Z", "closed_at": "2019-07-22T23:14:24Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: MXNet\r\n2. Framework version: mxnet-cu100 --pre\r\n3. Horovod version: master\r\n4. MPI version: 3.0.0\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.7\r\n7. Python version: 2.7\r\n8. OS and version: Ubuntu 16.04\r\n9. GCC version: 5.4.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nhttps://buildkite.com/horovod/horovod/builds/710#7d3ba97d-0126-4117-b04a-cae10bdc9767\r\n\r\n```\r\n/usr/bin/g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wl,-Bsymbolic-functions -Wl,-z,relro -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security build/temp.linux-x86_64-2.7/horovod/common/common.o build/temp.linux-x86_64-2.7/horovod/common/fusion_buffer_manager.o build/temp.linux-x86_64-2.7/horovod/common/half.o build/temp.linux-x86_64-2.7/horovod/common/message.o build/temp.linux-x86_64-2.7/horovod/common/mpi_context.o build/temp.linux-x86_64-2.7/horovod/common/operations.o build/temp.linux-x86_64-2.7/horovod/common/parameter_manager.o build/temp.linux-x86_64-2.7/horovod/common/response_cache.o build/temp.linux-x86_64-2.7/horovod/common/timeline.o build/temp.linux-x86_64-2.7/horovod/common/ops/collective_operations.o build/temp.linux-x86_64-2.7/horovod/common/ops/mpi_operations.o build/temp.linux-x86_64-2.7/horovod/common/ops/operation_manager.o build/temp.linux-x86_64-2.7/horovod/common/optim/bayesian_optimization.o build/temp.linux-x86_64-2.7/horovod/common/optim/gaussian_process.o build/temp.linux-x86_64-2.7/horovod/common/logging.o build/temp.linux-x86_64-2.7/horovod/common/ops/cuda_operations.o build/temp.linux-x86_64-2.7/horovod/common/ops/mpi_cuda_operations.o build/temp.linux-x86_64-2.7/horovod/common/ops/nccl_operations.o build/temp.linux-x86_64-2.7/horovod/torch/mpi_ops_v2.o build/temp.linux-x86_64-2.7/horovod/torch/handle_manager.o build/temp.linux-x86_64-2.7/horovod/torch/ready_event.o build/temp.linux-x86_64-2.7/horovod/torch/cuda_util.o build/temp.linux-x86_64-2.7/horovod/torch/adapter_v2.o -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -L/usr/local/cuda/lib64 -lcudart -lnccl_static -lcudart -o build/lib.linux-x86_64-2.7/horovod/torch/mpi_lib_v2.so -Wl,--version-script=horovod.lds -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi\r\n--\r\n\u00a0 | terminate called after throwing an instance of 'dmlc::Error'\r\n\u00a0 | what():  [01:22:52] include/mxnet/base.h:427: Check failed: e == cudaSuccess (35 vs. 0) :  CUDA: CUDA driver version is insufficient for CUDA runtime version\r\n\u00a0 | Stack trace:\r\n\u00a0 | [bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x4b1deb) [0x7f4b76b93deb]\r\n\u00a0 | [bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x253cc04) [0x7f4b78c1ec04]\r\n\u00a0 | [bt] (2) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2725e1) [0x7f4b769545e1]\r\n\u00a0 | [bt] (3) /lib64/ld-linux-x86-64.so.2(+0x106ca) [0x7f4ce813f6ca]\r\n\u00a0 | [bt] (4) /lib64/ld-linux-x86-64.so.2(+0x107db) [0x7f4ce813f7db]\r\n\u00a0 | [bt] (5) /lib64/ld-linux-x86-64.so.2(+0x158f2) [0x7f4ce81448f2]\r\n\u00a0 | [bt] (6) /lib64/ld-linux-x86-64.so.2(+0x10574) [0x7f4ce813f574]\r\n\u00a0 | [bt] (7) /lib64/ld-linux-x86-64.so.2(+0x14db9) [0x7f4ce8143db9]\r\n\u00a0 | [bt] (8) /lib/x86_64-linux-gnu/libdl.so.2(+0xf09) [0x7f4ce7944f09]\r\n```\r\n\r\n@apeforest @yuxihu, could you take a look?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1217/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1217/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1204", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1204/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1204/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1204/events", "html_url": "https://github.com/horovod/horovod/issues/1204", "id": 466143547, "node_id": "MDU6SXNzdWU0NjYxNDM1NDc=", "number": 1204, "title": "MPI_ERR_OTHER: known error not in list", "user": {"login": "pyotr777", "id": 485462, "node_id": "MDQ6VXNlcjQ4NTQ2Mg==", "avatar_url": "https://avatars.githubusercontent.com/u/485462?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pyotr777", "html_url": "https://github.com/pyotr777", "followers_url": "https://api.github.com/users/pyotr777/followers", "following_url": "https://api.github.com/users/pyotr777/following{/other_user}", "gists_url": "https://api.github.com/users/pyotr777/gists{/gist_id}", "starred_url": "https://api.github.com/users/pyotr777/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pyotr777/subscriptions", "organizations_url": "https://api.github.com/users/pyotr777/orgs", "repos_url": "https://api.github.com/users/pyotr777/repos", "events_url": "https://api.github.com/users/pyotr777/events{/privacy}", "received_events_url": "https://api.github.com/users/pyotr777/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-10T07:23:31Z", "updated_at": "2019-07-13T14:10:45Z", "closed_at": "2019-07-13T14:07:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow 1.12.0, Keras 2.2.4\r\n2. Framework version: TensorFlow 1.12.0, Keras 2.2.4\r\n3. Horovod version: 0.16.4\r\n4. MPI version: Open MPI 2.1.1\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.7\r\n7. Python version: 2.7.15\r\n8. OS and version: Ubuntu 18.04.1 LTS\r\n9. GCC version: 7.4.0\r\n10. Hardware: Two NVIDIA Xaviers connected over Ethernet\r\n\r\n\r\n**Checklist:**\r\n1. [x] Did you search issues to find if somebody asked this question before? \r\n2. [x] If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. [x] If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. [x] Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nI have two identical NVIDIA Xaviers. I can SSH from one to another with\r\n`xavier$ ssh xavier2` and `xavier2$ ssh xavier`.\r\n\r\nI can run the keras mnist sample from Xavier2:\r\n```\r\nxavier2$ mpirun -np 2 -H localhost:1,xavier:1 -mca btl_tcp_if_include eth0 -x NCCL_SOCKET_IFNAME=eth0 -bind-to none -map-by slot python keras_mnist.py\r\nUsing TensorFlow backend.\r\nUsing TensorFlow backend.\r\nKeras 2.2.4\r\nKeras 2.2.4\r\n2019-07-10 16:16:42.987703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] ARM64 does not support NUMA - returning NUMA node zero\r\n2019-07-10 16:16:42.987876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:\r\nname: Xavier major: 7 minor: 2 memoryClockRate(GHz): 1.5\r\n...\r\n```\r\n\r\nBut when running the same from another machine I get an error\r\n```\r\nxavier$ mpirun -np 2 -H localhost:1,xavier2:1 -mca btl_tcp_if_include eth0 -x NCCL_SOCKET_IFNAME=eth0 -bind-to none -map-by slot python keras_mnist.py\r\nWarning: Permanently added 'xavier2.local,192.168.83.36' (ECDSA) to the list of known hosts.\r\nUsing TensorFlow backend.\r\nUsing TensorFlow backend.\r\nKeras 2.2.4\r\nKeras 2.2.4\r\n[xavier2:7609] *** An error occurred in MPI_Allreduce\r\n[xavier2:7609] *** reported by process [515244033,545460846593]\r\n[xavier2:7609] *** on communicator MPI COMMUNICATOR 3 DUP FROM 0\r\n[xavier2:7609] *** MPI_ERR_OTHER: known error not in list\r\n[xavier2:7609] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,\r\n[xavier2:7609] ***    and potentially your MPI job)\r\n--------------------------------------------------------------------------\r\nAn MPI communication peer process has unexpectedly disconnected.  This\r\nusually indicates a failure in the peer process (e.g., a crash or\r\notherwise exiting without calling MPI_FINALIZE first).\r\n\r\nAlthough this local MPI process will likely now behave unpredictably\r\n(it may even hang or crash), the root cause of this problem is the\r\nfailure of the peer -- that is what you need to investigate.  For\r\nexample, there may be a core file that you can examine.  More\r\ngenerally: such peer hangups are frequently caused by application bugs\r\nor other external events.\r\n\r\n  Local host: xavier\r\n  Local PID:  16335\r\n  Peer host:  xavier2\r\n--------------------------------------------------------------------------\r\n...\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1204/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1204/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1182", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1182/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1182/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1182/events", "html_url": "https://github.com/horovod/horovod/issues/1182", "id": 462365557, "node_id": "MDU6SXNzdWU0NjIzNjU1NTc=", "number": 1182, "title": "Horovod missing ranks (stuck at the MPI comm ?)", "user": {"login": "zrss", "id": 8072378, "node_id": "MDQ6VXNlcjgwNzIzNzg=", "avatar_url": "https://avatars.githubusercontent.com/u/8072378?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zrss", "html_url": "https://github.com/zrss", "followers_url": "https://api.github.com/users/zrss/followers", "following_url": "https://api.github.com/users/zrss/following{/other_user}", "gists_url": "https://api.github.com/users/zrss/gists{/gist_id}", "starred_url": "https://api.github.com/users/zrss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zrss/subscriptions", "organizations_url": "https://api.github.com/users/zrss/orgs", "repos_url": "https://api.github.com/users/zrss/repos", "events_url": "https://api.github.com/users/zrss/events{/privacy}", "received_events_url": "https://api.github.com/users/zrss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-30T04:16:26Z", "updated_at": "2019-07-01T07:52:45Z", "closed_at": "2019-07-01T07:52:45Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\nTensorFlow\r\n2. Framework version:\r\n1.8.0\r\n3. Horovod version:\r\n0.15.2\r\n4. MPI version:\r\nopenmpi 4.0.0\r\n5. CUDA version:\r\ncuda 9.0.176-1\r\n6. NCCL version:\r\n2.4.2\r\n7. Python version:\r\npython 3.6\r\n8. OS and version:\r\nubuntu 16.04\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nHi all, currently, i have a case about missing ranks, and it seems stuck at the MPI comm from the stacktrace view of the process\r\n\r\nrank 0 (partial backtrace)\r\n\r\n```\r\nThread 2 (Thread 0x7fe9be0b1700 (LWP 442)):\r\n#0  0x00007fe934790bce in mca_btl_smcuda_component_progress ()\r\n   from /usr/local/openmpi/lib/openmpi/mca_btl_smcuda.so\r\n#1  0x00007fe93edd3dac in opal_progress ()\r\n   from /usr/local/openmpi/lib/libopen-pal.so.40\r\n#2  0x00007fe934152a85 in mca_pml_ob1_recv ()\r\n   from /usr/local/openmpi/lib/openmpi/mca_pml_ob1.so\r\n#3  0x00007fe93f41b8ff in ompi_coll_base_gather_intra_basic_linear ()\r\n   from /usr/local/openmpi/lib/libmpi.so.40\r\n#4  0x00007fe93f3e518d in PMPI_Gather ()\r\n   from /usr/local/openmpi/lib/libmpi.so.40\r\n#5  0x00007fe93f6c4d46 in horovod::common::(anonymous namespace)::RunLoopOnce (\r\n    state=..., is_coordinator=is_coordinator@entry=true)\r\n    at horovod/common/operations.cc:1780\r\n#6  0x00007fe93f6c7cab in horovod::common::(anonymous namespace)::BackgroundThreadLoop (state=...) at horovod/common/operations.cc:1629\r\n```\r\n\r\nrank X (partial backtrace)\r\n\r\n```\r\nThread 2 (Thread 0x7fb7aa23a700 (LWP 439)):\r\n#0  0x00007fb7331df76c in mca_btl_vader_component_progress ()\r\n   from /usr/local/openmpi/lib/openmpi/mca_btl_vader.so\r\n#1  0x00007fb7473d4dac in opal_progress ()\r\n   from /usr/local/openmpi/lib/libopen-pal.so.40\r\n#2  0x00007fb7479bcbd5 in ompi_request_default_wait ()\r\n   from /usr/local/openmpi/lib/libmpi.so.40\r\n#3  0x00007fb747a12fbb in ompi_coll_base_bcast_intra_generic ()\r\n   from /usr/local/openmpi/lib/libmpi.so.40\r\n#4  0x00007fb747a13532 in ompi_coll_base_bcast_intra_binomial ()\r\n   from /usr/local/openmpi/lib/libmpi.so.40\r\n#5  0x00007fb7329be343 in ompi_coll_tuned_bcast_intra_dec_fixed ()\r\n   from /usr/local/openmpi/lib/openmpi/mca_coll_tuned.so\r\n#6  0x00007fb7479d50a9 in PMPI_Bcast ()\r\n   from /usr/local/openmpi/lib/libmpi.so.40\r\n#7  0x00007fb747cc7700 in horovod::common::(anonymous namespace)::RunLoopOnce (\r\n```\r\n\r\nand part of the horovod training log\r\n\r\n```\r\ntraining_1/Adam/DistributedAdam_Allreduce/HorovodAllreduce_training_1_Adam_gradients_res5c_branch2c_convolution_grad_Conv2DBackpropFilter_0 [missing ranks: 3]\r\ntraining_1/Adam/DistributedAdam_Allreduce/HorovodAllreduce_training_1_Adam_gradients_dense_class_8_BiasAdd_grad_BiasAddGrad_0 [missing ranks: 3]\r\ntraining_1/Adam/DistributedAdam_Allreduce/HorovodAllreduce_training_1_Adam_gradients_dense_class_8_MatMul_grad_MatMul_1_0 [missing ranks: 3]\r\ntraining_1/Adam/DistributedAdam_Allreduce/HorovodAllreduce_training_1_Adam_gradients_dense_regress_8_MatMul_grad_MatMul_1_0 [missing ranks: 3]\r\ntraining_1/Adam/DistributedAdam_Allreduce/HorovodAllreduce_training_1_Adam_gradients_dense_regress_8_BiasAdd_grad_BiasAddGrad_0 [missing ranks: 3]\r\n```\r\n\r\nbut it's very odd, rank 0 waits at the `MPI_Gather` and rank X waits at the `MPI_Bcast` ?\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1182/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1182/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1177", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1177/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1177/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1177/events", "html_url": "https://github.com/horovod/horovod/issues/1177", "id": 461813566, "node_id": "MDU6SXNzdWU0NjE4MTM1NjY=", "number": 1177, "title": "Horovod GradientTape performance for Tensorflow ", "user": {"login": "aj-prime", "id": 50178865, "node_id": "MDQ6VXNlcjUwMTc4ODY1", "avatar_url": "https://avatars.githubusercontent.com/u/50178865?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aj-prime", "html_url": "https://github.com/aj-prime", "followers_url": "https://api.github.com/users/aj-prime/followers", "following_url": "https://api.github.com/users/aj-prime/following{/other_user}", "gists_url": "https://api.github.com/users/aj-prime/gists{/gist_id}", "starred_url": "https://api.github.com/users/aj-prime/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aj-prime/subscriptions", "organizations_url": "https://api.github.com/users/aj-prime/orgs", "repos_url": "https://api.github.com/users/aj-prime/repos", "events_url": "https://api.github.com/users/aj-prime/events{/privacy}", "received_events_url": "https://api.github.com/users/aj-prime/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2019-06-28T01:21:03Z", "updated_at": "2020-01-08T03:36:05Z", "closed_at": "2019-07-08T23:29:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Tensorflow\r\n2. Framework version: 1.12\r\n3. Horovod version:0.16.4\r\n4. MPI version: Mvapich-GDR 2.3.1\r\n5. CUDA version: 9.2\r\n6. NCCL version:\r\n7. Python version: 3.6\r\n8. OS and version: Red Hat Enterprise Linux Server, 7.5 (Maipo)\r\n9. GCC version: xl/2019.02.07\r\n10. Architecture: Power9, V100 GPU\r\n\r\n\r\n**Your question:**\r\nI have modified tensorflow_mnist_eager.py script in the examples to print images per sec. \r\nBatch size: 32\r\n#GPUs    Perf(images/sec)\r\n1               2216\r\n2              425\r\n4              640 \r\n\r\nIt looks like there is an initial overhead of distributing the DNN training.\r\nIs it the expected behavior? \r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1177/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1177/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1165", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1165/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1165/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1165/events", "html_url": "https://github.com/horovod/horovod/issues/1165", "id": 459370006, "node_id": "MDU6SXNzdWU0NTkzNzAwMDY=", "number": 1165, "title": "Anyone using Horovod with IBM PowerAI 1.6.1 on Power8/Power9 machines?", "user": {"login": "denfromufa", "id": 7870949, "node_id": "MDQ6VXNlcjc4NzA5NDk=", "avatar_url": "https://avatars.githubusercontent.com/u/7870949?v=4", "gravatar_id": "", "url": "https://api.github.com/users/denfromufa", "html_url": "https://github.com/denfromufa", "followers_url": "https://api.github.com/users/denfromufa/followers", "following_url": "https://api.github.com/users/denfromufa/following{/other_user}", "gists_url": "https://api.github.com/users/denfromufa/gists{/gist_id}", "starred_url": "https://api.github.com/users/denfromufa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/denfromufa/subscriptions", "organizations_url": "https://api.github.com/users/denfromufa/orgs", "repos_url": "https://api.github.com/users/denfromufa/repos", "events_url": "https://api.github.com/users/denfromufa/events{/privacy}", "received_events_url": "https://api.github.com/users/denfromufa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-06-21T20:57:00Z", "updated_at": "2019-07-02T16:31:53Z", "closed_at": "2019-07-02T16:31:53Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PowerAI 1.6.1\r\n3. Horovod version: Master Branch\r\n4. MPI version: Spectrum MPI 10.03 or 10.1\r\n5. CUDA version: 10.1.168\r\n6. NCCL version: 2.4.7\r\n7. Python version: 3.6\r\n8. OS and version: CentOS 7.5\r\n9. GCC version: gxx_linux-ppc64le=7.3.0\r\n\r\nPowerAI 1.6.1 from IBM was released last week. \r\nhttps://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/linux-ppc64le/\r\n\r\nWe are having various issues with various combinations of Spectrum MPI, NCCL, DDL compilation for Horovod. Does anyone have a working setup?\r\n\r\nPowerAI 1.6.0 used to work fine!\r\n\r\nThanks,\r\nDenis\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1165/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1165/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1129", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1129/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1129/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1129/events", "html_url": "https://github.com/horovod/horovod/issues/1129", "id": 453518279, "node_id": "MDU6SXNzdWU0NTM1MTgyNzk=", "number": 1129, "title": "Nightly TF 1.14.1.dev20190607 breaks v0.16.3", "user": {"login": "byronyi", "id": 2613663, "node_id": "MDQ6VXNlcjI2MTM2NjM=", "avatar_url": "https://avatars.githubusercontent.com/u/2613663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byronyi", "html_url": "https://github.com/byronyi", "followers_url": "https://api.github.com/users/byronyi/followers", "following_url": "https://api.github.com/users/byronyi/following{/other_user}", "gists_url": "https://api.github.com/users/byronyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/byronyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byronyi/subscriptions", "organizations_url": "https://api.github.com/users/byronyi/orgs", "repos_url": "https://api.github.com/users/byronyi/repos", "events_url": "https://api.github.com/users/byronyi/events{/privacy}", "received_events_url": "https://api.github.com/users/byronyi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-07T13:37:17Z", "updated_at": "2019-06-09T05:42:15Z", "closed_at": "2019-06-09T05:42:15Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow \r\n2. Framework version: 1.14.1.dev20190607\r\n3. Horovod version: 0.16.3\r\n4. MPI version: 2.0.2\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.2\r\n7. Python version: 3.5m\r\n8. OS and version: Debian 9.8\r\n\r\n**Bug report:**\r\n\r\nBuild Horovod with latest TF nightly fails with the following error:\r\n\r\n```\r\n  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fdebug-prefix-map=/build/python3.5-3.5.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DEIGEN_MPL2_ONLY=1 -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/include/python3.5m -I/home/byronyi/.virtualenv/tf/include/python3.5m -c horovod/tensorflow/mpi_ops.cc -o build/temp.linux-x86_64-3.5/horovod/tensorflow/mpi_ops.o -std=c++11 -fPIC -O2 -Wall -I/usr/lib/x86_64-linux-gnu/openmpi/include/openmpi -I/usr/lib/x86_64-linux-gnu/openmpi/include/openmpi/opal/mca/event/libevent2022/libevent -I/usr/lib/x86_64-linux-gnu/openmpi/include/openmpi/opal/mca/event/libevent2022/libevent/include -I/usr/lib/x86_64-linux-gnu/openmpi/include -pthread -L/usr//lib -L/usr/lib/x86_64-linux-gnu/openmpi/lib -lmpi_cxx -lmpi -I/home/byronyi/.virtualenv/tf/lib/python3.5/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  horovod/tensorflow/mpi_ops.cc:22:42: fatal error: tensorflow/core/framework/op.h: No such file or directory\r\n   #include \"tensorflow/core/framework/op.h\"\r\n                                            ^\r\n  compilation terminated.\r\n  INFO: Unable to build TensorFlow plugin, will skip it.\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1129/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1129/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1102", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1102/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1102/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1102/events", "html_url": "https://github.com/horovod/horovod/issues/1102", "id": 449308125, "node_id": "MDU6SXNzdWU0NDkzMDgxMjU=", "number": 1102, "title": "hvd.shutdown() hangs in MPI_Finalize() for just one rank", "user": {"login": "maxhgerlach", "id": 1778667, "node_id": "MDQ6VXNlcjE3Nzg2Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/1778667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxhgerlach", "html_url": "https://github.com/maxhgerlach", "followers_url": "https://api.github.com/users/maxhgerlach/followers", "following_url": "https://api.github.com/users/maxhgerlach/following{/other_user}", "gists_url": "https://api.github.com/users/maxhgerlach/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxhgerlach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxhgerlach/subscriptions", "organizations_url": "https://api.github.com/users/maxhgerlach/orgs", "repos_url": "https://api.github.com/users/maxhgerlach/repos", "events_url": "https://api.github.com/users/maxhgerlach/events{/privacy}", "received_events_url": "https://api.github.com/users/maxhgerlach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 730732849, "node_id": "MDU6TGFiZWw3MzA3MzI4NDk=", "url": "https://api.github.com/repos/horovod/horovod/labels/update%20docs", "name": "update docs", "color": "78ed92", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-05-28T14:37:11Z", "updated_at": "2021-07-02T13:10:40Z", "closed_at": "2021-07-02T13:10:40Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.13.1, custom built without XLA\r\n3. Horovod version: 0.16.2\r\n4. MPI version: Open MPI 4.0.1\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.3.7-1+cuda10.0\r\n7. Python version: 2.7\r\n8. OS and version: Ubuntu 16.04.5 LTS\r\n\r\nMellanox OFED 4.4-2.0.7.0 is installed.\r\n\r\n**Bug report:**\r\nI am facing an issue in our custom Horovod-based training code. When I call `hvd.shutdown()` on all ranks, one of the ranks hangs and does not return. If I do not call `hvd.shutdown()` explicitly, I observe the same problem when it is called by the atexit handler.\r\n\r\nTo pinpoint the problem I added extra tracing log messages in BackgroundThreadLoop (https://github.com/maxhgerlach/horovod/commits/maxg-shutdown-tracing): It hangs inside `MPI_Finalize()` for that one rank. In this [example log](https://gist.github.com/maxhgerlach/2c7030198b86da5093c56272ede114b6) rank 0 never moves past `MPI_Finalize()`, but in other test runs some other rank hangs.\r\n\r\nThis is with Open MPI 4.0.1; previously I used version 3.1.2. With the older version, the problematic rank would not hang in `MPI_Finalize`, but abort the program with an exit code of 244. With either version 3.1.2 or version 4.0.1 setting a different error handler via `MPI_Comm_set_errhandler(MPI_COMM_WORLD, MPI_ERRORS_RETURN);` did not change the observed behaviour. (Supposedly this would cause any MPI routine to actually return a nonzero code on error, rather than directly terminate the whole program.)\r\n\r\nInserting an mpi4py `MPI.COMM_WORLD.barrier()` right before `hvd.shutdown()` makes no difference either.\r\n\r\nI am at a loss how to debug this.\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1102/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1102/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1099", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1099/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1099/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1099/events", "html_url": "https://github.com/horovod/horovod/issues/1099", "id": 449023285, "node_id": "MDU6SXNzdWU0NDkwMjMyODU=", "number": 1099, "title": "Duplicated Synchronization with Gradient Clipping?", "user": {"login": "ildoonet", "id": 1115758, "node_id": "MDQ6VXNlcjExMTU3NTg=", "avatar_url": "https://avatars.githubusercontent.com/u/1115758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ildoonet", "html_url": "https://github.com/ildoonet", "followers_url": "https://api.github.com/users/ildoonet/followers", "following_url": "https://api.github.com/users/ildoonet/following{/other_user}", "gists_url": "https://api.github.com/users/ildoonet/gists{/gist_id}", "starred_url": "https://api.github.com/users/ildoonet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ildoonet/subscriptions", "organizations_url": "https://api.github.com/users/ildoonet/orgs", "repos_url": "https://api.github.com/users/ildoonet/repos", "events_url": "https://api.github.com/users/ildoonet/events{/privacy}", "received_events_url": "https://api.github.com/users/ildoonet/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-05-28T01:10:09Z", "updated_at": "2019-05-30T01:58:55Z", "closed_at": "2019-05-30T01:58:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: pytorch\r\n2. Framework version: 1.0\r\n3. Horovod version: latest\r\n4. MPI version: -\r\n5. CUDA version: -\r\n6. NCCL version: -\r\n7. Python version: 3.6\r\n8. OS and version: Ubuntu 16.04\r\n\r\nhttps://github.com/horovod/horovod/blob/master/horovod/torch/__init__.py#L174\r\n\r\nIf you see this documentation, when using gradient clipping, there is duplicated(twice) synchronization. Once is when 'synchronize' is called and second one is when 'step' is called.\r\n\r\nAfter I followed this documentation with gradient clipping, training speed is slower.\r\n\r\nAny solusions?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1099/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1099/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1075", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1075/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1075/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1075/events", "html_url": "https://github.com/horovod/horovod/issues/1075", "id": 444169800, "node_id": "MDU6SXNzdWU0NDQxNjk4MDA=", "number": 1075, "title": "Run horovod on local machine without GPU", "user": {"login": "yselivonchyk", "id": 4716569, "node_id": "MDQ6VXNlcjQ3MTY1Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/4716569?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yselivonchyk", "html_url": "https://github.com/yselivonchyk", "followers_url": "https://api.github.com/users/yselivonchyk/followers", "following_url": "https://api.github.com/users/yselivonchyk/following{/other_user}", "gists_url": "https://api.github.com/users/yselivonchyk/gists{/gist_id}", "starred_url": "https://api.github.com/users/yselivonchyk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yselivonchyk/subscriptions", "organizations_url": "https://api.github.com/users/yselivonchyk/orgs", "repos_url": "https://api.github.com/users/yselivonchyk/repos", "events_url": "https://api.github.com/users/yselivonchyk/events{/privacy}", "received_events_url": "https://api.github.com/users/yselivonchyk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-05-14T23:29:27Z", "updated_at": "2019-05-17T16:58:33Z", "closed_at": "2019-05-17T16:58:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) mxnet\r\n2. Framework version: 1.4.0\r\n3. Horovod version: 0.16.1\r\n4. MPI version: 4.0.1\r\n5. CUDA version: N/A\r\n6. NCCL version: \r\n7. Python version: 3.7\r\n8. OS and version: 10.13.4\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nI run the 2 lines from the readme page:\r\n```\r\nimport mxnet as mx\r\nimport horovod.mxnet as hvd\r\n```\r\nand it fails on the second line asking for mxnet.so:\r\n```\r\n---------------------------------------------------------------------------\r\nOSError                                   Traceback (most recent call last)\r\n<ipython-input-8-7a9ad6e7861b> in <module>\r\n      1 import mxnet as mx\r\n----> 2 import horovod.mxnet as hvd\r\n      3 from mxnet import autograd\r\n      4 \r\n      5 # Initialize Horovod\r\n\r\n~/env/dev/lib/python3.7/site-packages/horovod/mxnet/__init__.py in <module>\r\n     23                 __file__, 'mpi_lib')\r\n     24 \r\n---> 25 from horovod.mxnet.mpi_ops import allgather\r\n     26 from horovod.mxnet.mpi_ops import allreduce, allreduce_\r\n     27 from horovod.mxnet.mpi_ops import broadcast, broadcast_\r\n\r\n~/env/dev/lib/python3.7/site-packages/horovod/mxnet/mpi_ops.py in <module>\r\n     27 from horovod.common import get_ext_suffix\r\n     28 from horovod.common import HorovodBasics as _HorovodBasics\r\n---> 29 _basics = _HorovodBasics(__file__, 'mpi_lib')\r\n     30 \r\n     31 # import basic methods\r\n\r\n~/env/dev/lib/python3.7/site-packages/horovod/common/__init__.py in __init__(self, pkg_path, *args)\r\n     54     def __init__(self, pkg_path, *args):\r\n     55         full_path = get_extension_full_path(pkg_path, *args)\r\n---> 56         self.MPI_LIB_CTYPES = ctypes.CDLL(full_path, mode=ctypes.RTLD_GLOBAL)\r\n     57 \r\n     58     def init(self, comm=None):\r\n\r\n/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ctypes/__init__.py in __init__(self, name, mode, handle, use_errno, use_last_error)\r\n    354 \r\n    355         if handle is None:\r\n--> 356             self._handle = _dlopen(self._name, mode)\r\n    357         else:\r\n    358             self._handle = handle\r\n\r\nOSError: dlopen(/Users/yauheni/env/dev/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-darwin.so, 10): Library not loaded: lib/libmxnet.so\r\n  Referenced from: /Users/yauheni/env/dev/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-darwin.so\r\n  Reason: image not found\r\n```\r\nI can run mxnet code, no problem. What can be the issue here?\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1075/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1075/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1072", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1072/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1072/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1072/events", "html_url": "https://github.com/horovod/horovod/issues/1072", "id": 443773010, "node_id": "MDU6SXNzdWU0NDM3NzMwMTA=", "number": 1072, "title": "failed to install hvd with TF 1.13.1", "user": {"login": "jackalcooper", "id": 5133557, "node_id": "MDQ6VXNlcjUxMzM1NTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5133557?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jackalcooper", "html_url": "https://github.com/jackalcooper", "followers_url": "https://api.github.com/users/jackalcooper/followers", "following_url": "https://api.github.com/users/jackalcooper/following{/other_user}", "gists_url": "https://api.github.com/users/jackalcooper/gists{/gist_id}", "starred_url": "https://api.github.com/users/jackalcooper/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jackalcooper/subscriptions", "organizations_url": "https://api.github.com/users/jackalcooper/orgs", "repos_url": "https://api.github.com/users/jackalcooper/repos", "events_url": "https://api.github.com/users/jackalcooper/events{/privacy}", "received_events_url": "https://api.github.com/users/jackalcooper/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-14T08:17:38Z", "updated_at": "2019-05-21T03:31:52Z", "closed_at": "2019-05-14T08:47:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.13.1\r\n3. Horovod version: not specified\r\n4. MPI version: 3.1.0\r\n5. CUDA version: 9.0\r\n6. NCCL version:\r\n7. Python version: 2.7\r\n8. OS and version: Amazon Linux\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.md)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.md)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\n```\r\n(tensorflow_p27_1_13_1) [ec2-user@ip-172-31-31-224 ~]$ HOROVOD_GPU_ALLREDUCE=NCCL pip install --no-cache-dir horovod -U --user --ignore-installed\r\nCollecting horovod\r\n  Downloading https://files.pythonhosted.org/packages/89/70/327e1ce9bee0fb8a879b98f8265fb7a41ae6d04a3ee019b2bafba8b66333/horovod-0.16.1.tar.gz (2.6MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.6MB 121.6MB/s                                                                                                            \r\nCollecting cffi>=1.4.0 (from horovod)\r\n  Downloading https://files.pythonhosted.org/packages/8d/e9/0c8afd1579e5cf7bc0f06fbcd7cdb954cbc0baadd505973949a99337da1c/cffi-1.12.3-cp27-cp27mu-manylinux1_x86_64.whl (415kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 419kB 115.1MB/s                                                                                                            \r\nCollecting cloudpickle (from horovod)\r\n  Downloading https://files.pythonhosted.org/packages/c6/d9/d45cdb70f3d86480f02f220bc2ec6da69a45de4a5bb61a49fd4a5106ada8/cloudpickle-1.0.0-py2.py3-none-any.whl\r\nCollecting psutil (from horovod)\r\n  Downloading https://files.pythonhosted.org/packages/c6/c1/beed5e4eaa1345901b595048fab1c85aee647ea0fc02d9e8bf9aceb81078/psutil-5.6.2.tar.gz (432kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 440kB 128.0MB/s                                                                                                            \r\nCollecting six (from horovod)\r\n  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\r\nCollecting pycparser (from cffi>=1.4.0->horovod)\r\n  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 163kB 118.6MB/s                                                                                                            \r\nInstalling collected packages: pycparser, cffi, cloudpickle, psutil, six, horovod\r\n  Running setup.py install for pycparser ... done\r\n  Running setup.py install for psutil ... done\r\n  Running setup.py install for horovod ... error\r\n    Complete output from command /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-VZlq_a/horovod/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-pCeskd/install-record.txt --single-version-externally-managed --compile --user --prefix=:\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-2.7\r\n    creating build/lib.linux-x86_64-2.7/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-2.7/horovod\r\n    creating build/lib.linux-x86_64-2.7/horovod/keras\r\n    copying horovod/keras/__init__.py -> build/lib.linux-x86_64-2.7/horovod/keras\r\n    copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-2.7/horovod/keras\r\n    creating build/lib.linux-x86_64-2.7/horovod/_keras\r\n    copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-2.7/horovod/_keras\r\n    copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-2.7/horovod/_keras\r\n    creating build/lib.linux-x86_64-2.7/horovod/run\r\n    copying horovod/run/run.py -> build/lib.linux-x86_64-2.7/horovod/run\r\n    copying horovod/run/__init__.py -> build/lib.linux-x86_64-2.7/horovod/run\r\n    copying horovod/run/task_fn.py -> build/lib.linux-x86_64-2.7/horovod/run\r\n    creating build/lib.linux-x86_64-2.7/horovod/mxnet\r\n    copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-2.7/horovod/mxnet\r\n    copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-2.7/horovod/mxnet\r\n    creating build/lib.linux-x86_64-2.7/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-2.7/horovod/spark\r\n    creating build/lib.linux-x86_64-2.7/horovod/common\r\n    copying horovod/common/__init__.py -> build/lib.linux-x86_64-2.7/horovod/common\r\n    creating build/lib.linux-x86_64-2.7/horovod/tensorflow\r\n    copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-2.7/horovod/tensorflow\r\n    copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-2.7/horovod/tensorflow\r\n    copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-2.7/horovod/tensorflow\r\n    copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-2.7/horovod/tensorflow\r\n    creating build/lib.linux-x86_64-2.7/horovod/torch\r\n    copying horovod/torch/__init__.py -> build/lib.linux-x86_64-2.7/horovod/torch\r\n    copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-2.7/horovod/torch\r\n    copying horovod/torch/compression.py -> build/lib.linux-x86_64-2.7/horovod/torch\r\n    creating build/lib.linux-x86_64-2.7/horovod/run/common\r\n    copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-2.7/horovod/run/common\r\n    creating build/lib.linux-x86_64-2.7/horovod/run/util\r\n    copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-2.7/horovod/run/util\r\n    copying horovod/run/util/network.py -> build/lib.linux-x86_64-2.7/horovod/run/util\r\n    copying horovod/run/util/threads.py -> build/lib.linux-x86_64-2.7/horovod/run/util\r\n    copying horovod/run/util/cache.py -> build/lib.linux-x86_64-2.7/horovod/run/util\r\n    creating build/lib.linux-x86_64-2.7/horovod/run/task\r\n    copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-2.7/horovod/run/task\r\n    copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-2.7/horovod/run/task\r\n    creating build/lib.linux-x86_64-2.7/horovod/run/driver\r\n    copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-2.7/horovod/run/driver\r\n    copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-2.7/horovod/run/driver\r\n    creating build/lib.linux-x86_64-2.7/horovod/run/common/util\r\n    copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-2.7/horovod/run/common/util\r\n    copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-2.7/horovod/run/common/util\r\n    copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-2.7/horovod/run/common/util\r\n    copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-2.7/horovod/run/common/util\r\n    copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-2.7/horovod/run/common/util\r\n    copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-2.7/horovod/run/common/util\r\n    copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-2.7/horovod/run/common/util\r\n    creating build/lib.linux-x86_64-2.7/horovod/run/common/service\r\n    copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-2.7/horovod/run/common/service\r\n    copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-2.7/horovod/run/common/service\r\n    copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-2.7/horovod/run/common/service\r\n    creating build/lib.linux-x86_64-2.7/horovod/spark/task\r\n    copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-2.7/horovod/spark/task\r\n    copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-2.7/horovod/spark/task\r\n    copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-2.7/horovod/spark/task\r\n    creating build/lib.linux-x86_64-2.7/horovod/spark/driver\r\n    copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-2.7/horovod/spark/driver\r\n    copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-2.7/horovod/spark/driver\r\n    copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-2.7/horovod/spark/driver\r\n    copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-2.7/horovod/spark/driver\r\n    creating build/lib.linux-x86_64-2.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-2.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-2.7/horovod/tensorflow/keras\r\n    creating build/lib.linux-x86_64-2.7/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-2.7/horovod/torch/mpi_lib_impl\r\n    creating build/lib.linux-x86_64-2.7/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-2.7/horovod/torch/mpi_lib\r\n    running build_ext\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c build/temp.linux-x86_64-2.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-2.7/test_compile/test_cpp_flags.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -shared -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,-rpath=/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-2.7/test_compile/test_cpp_flags.o -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -o build/temp.linux-x86_64-2.7/test_compile/test_cpp_flags.so\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c build/temp.linux-x86_64-2.7/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-2.7/test_compile/test_link_flags.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -shared -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,-rpath=/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,--version-script=horovod.lds build/temp.linux-x86_64-2.7/test_compile/test_link_flags.o -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -o build/temp.linux-x86_64-2.7/test_compile/test_link_flags.so\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/usr/local/cuda/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c build/temp.linux-x86_64-2.7/test_compile/test_cuda.cc -o build/temp.linux-x86_64-2.7/test_compile/test_cuda.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -shared -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,-rpath=/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-2.7/test_compile/test_cuda.o -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lcudart -o build/temp.linux-x86_64-2.7/test_compile/test_cuda.so\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/usr/local/cuda-9.0/include -I/usr/local/cuda/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c build/temp.linux-x86_64-2.7/test_compile/test_nccl.cc -o build/temp.linux-x86_64-2.7/test_compile/test_nccl.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -shared -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,-rpath=/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-2.7/test_compile/test_nccl.o -L/usr/local/cuda-9.0/lib -L/usr/local/cuda-9.0/lib64 -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lnccl_static -o build/temp.linux-x86_64-2.7/test_compile/test_nccl.so\r\n    building 'horovod.tensorflow.mpi_lib' extension\r\n    creating build/temp.linux-x86_64-2.7/horovod\r\n    creating build/temp.linux-x86_64-2.7/horovod/common\r\n    creating build/temp.linux-x86_64-2.7/horovod/common/ops\r\n    creating build/temp.linux-x86_64-2.7/horovod/common/optim\r\n    creating build/temp.linux-x86_64-2.7/horovod/tensorflow\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/common.cc -o build/temp.linux-x86_64-2.7/horovod/common/common.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/fusion_buffer_manager.cc -o build/temp.linux-x86_64-2.7/horovod/common/fusion_buffer_manager.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/half.cc -o build/temp.linux-x86_64-2.7/horovod/common/half.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/message.cc -o build/temp.linux-x86_64-2.7/horovod/common/message.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/mpi_context.cc -o build/temp.linux-x86_64-2.7/horovod/common/mpi_context.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/operations.cc -o build/temp.linux-x86_64-2.7/horovod/common/operations.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/parameter_manager.cc -o build/temp.linux-x86_64-2.7/horovod/common/parameter_manager.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/timeline.cc -o build/temp.linux-x86_64-2.7/horovod/common/timeline.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/ops/collective_operations.cc -o build/temp.linux-x86_64-2.7/horovod/common/ops/collective_operations.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/ops/mpi_operations.cc -o build/temp.linux-x86_64-2.7/horovod/common/ops/mpi_operations.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/ops/operation_manager.cc -o build/temp.linux-x86_64-2.7/horovod/common/ops/operation_manager.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/optim/bayesian_optimization.cc -o build/temp.linux-x86_64-2.7/horovod/common/optim/bayesian_optimization.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/optim/gaussian_process.cc -o build/temp.linux-x86_64-2.7/horovod/common/optim/gaussian_process.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/logging.cc -o build/temp.linux-x86_64-2.7/horovod/common/logging.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/ops/cuda_operations.cc -o build/temp.linux-x86_64-2.7/horovod/common/ops/cuda_operations.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/ops/mpi_cuda_operations.cc -o build/temp.linux-x86_64-2.7/horovod/common/ops/mpi_cuda_operations.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/common/ops/nccl_operations.cc -o build/temp.linux-x86_64-2.7/horovod/common/ops/nccl_operations.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    gcc -pthread -B /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/compiler_compat -Wl,--sysroot=/ -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DEIGEN_MPL2_ONLY=1 -DHAVE_CUDA=1 -DHAVE_NCCL=1 -DHOROVOD_GPU_ALLREDUCE='N' -Ithird_party/eigen -Ithird_party/lbfgs/include -Ithird_party/boost/assert/include -Ithird_party/boost/config/include -Ithird_party/boost/core/include -Ithird_party/boost/detail/include -Ithird_party/boost/iterator/include -Ithird_party/boost/lockfree/include -Ithird_party/boost/mpl/include -Ithird_party/boost/parameter/include -Ithird_party/boost/predef/include -Ithird_party/boost/preprocessor/include -Ithird_party/boost/static_assert/include -Ithird_party/boost/type_traits/include -Ithird_party/boost/utility/include -Ithird_party/flatbuffers/include -I/usr/local/cuda/include -I/usr/local/cuda-9.0/include -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include/python2.7 -c horovod/tensorflow/mpi_ops.cc -o build/temp.linux-x86_64-2.7/horovod/tensorflow/mpi_ops.o -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/include -pthread -Wl,-rpath -Wl,/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -Wl,--enable-new-dtags -L/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib -lmpi_cxx -lmpi -I/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++ [enabled by default]\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def_builder.h:24:0,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def.pb.h:33:0,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def_builder.h:24,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/attr_value.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/attr_value.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/attr_value.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/attr_value.pb.h:36:0,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def.pb.h:33,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def_builder.h:24,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/tensor.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/tensor.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/tensor.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/tensor.pb.h:33:0,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/attr_value.pb.h:36,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def.pb.h:33,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def_builder.h:24,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/resource_handle.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/resource_handle.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/resource_handle.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/tensor.pb.h:34:0,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/attr_value.pb.h:36,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def.pb.h:33,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def_builder.h:24,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/tensor.pb.h:35:0,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/attr_value.pb.h:36,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def.pb.h:33,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def_builder.h:24,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/types.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/types.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/types.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/lib/core/status.h:23:0,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def_builder.h:25,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op.h:23,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/lib/core/error_codes.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/lib/core/error_codes.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/lib/core/error_codes.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_def_util.h:23:0,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op.h:24,\r\n                     from horovod/tensorflow/mpi_ops.cc:22:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/api_def.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/api_def.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/api_def.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h:27:0,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/graph.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/graph.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/graph.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/graph.pb.h:33:0,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h:27,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/node_def.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/node_def.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/node_def.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/graph.pb.h:34:0,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h:27,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/function.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/function.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/function.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/graph.pb.h:35:0,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h:27,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/versions.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/versions.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/versions.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h:28:0,\r\n                     from horovod/tensorflow/mpi_ops.cc:23:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/kernel_def.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/kernel_def.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/kernel_def.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    In file included from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/stream_executor/dnn.h:34:0,\r\n                     from /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/stream_executor/stream.h:31,\r\n                     from horovod/tensorflow/mpi_ops.cc:29:\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/stream_executor/dnn.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n     #error This file was generated by a newer version of protoc which is\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/stream_executor/dnn.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n     #error incompatible with your Protocol Buffer headers.  Please update\r\n      ^\r\n    /home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/tensorflow/include/tensorflow/stream_executor/dnn.pb.h:14:2: error: #error your headers.\r\n     #error your headers.\r\n      ^\r\n    INFO: Unable to build TensorFlow plugin, will skip it.\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-VZlq_a/horovod/setup.py\", line 909, in build_extensions\r\n        build_tf_extension(self, options)\r\n      File \"/tmp/pip-install-VZlq_a/horovod/setup.py\", line 622, in build_tf_extension\r\n        build_ext.build_extension(tensorflow_mpi_lib)\r\n      File \"/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/site-packages/setuptools/command/build_ext.py\", line 199, in build_extension\r\n        _build_ext.build_extension(self, ext)\r\n      File \"/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/distutils/command/build_ext.py\", line 499, in build_extension\r\n        depends=ext.depends)\r\n      File \"/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/distutils/ccompiler.py\", line 574, in compile\r\n        self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\r\n      File \"/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/lib/python2.7/distutils/unixccompiler.py\", line 124, in _compile\r\n        raise CompileError, msg\r\n    CompileError: command 'gcc' failed with exit status 1\r\n    \r\n    INFO: Unable to build PyTorch plugin, will skip it.\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-VZlq_a/horovod/setup.py\", line 920, in build_extensions\r\n        torch_version = check_torch_version()\r\n      File \"/tmp/pip-install-VZlq_a/horovod/setup.py\", line 718, in check_torch_version\r\n        'import torch failed, is it installed?\\n\\n%s' % traceback.format_exc())\r\n    DistutilsPlatformError: import torch failed, is it installed?\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-VZlq_a/horovod/setup.py\", line 711, in check_torch_version\r\n        import torch\r\n    ImportError: No module named torch\r\n    \r\n    \r\n    INFO: Unable to build MXNet plugin, will skip it.\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-VZlq_a/horovod/setup.py\", line 935, in build_extensions\r\n        build_mx_extension(self, options)\r\n      File \"/tmp/pip-install-VZlq_a/horovod/setup.py\", line 672, in build_mx_extension\r\n        check_mx_version()\r\n      File \"/tmp/pip-install-VZlq_a/horovod/setup.py\", line 78, in check_mx_version\r\n        'import mxnet failed, is it installed?\\n\\n%s' % traceback.format_exc())\r\n    DistutilsPlatformError: import mxnet failed, is it installed?\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-VZlq_a/horovod/setup.py\", line 71, in check_mx_version\r\n        import mxnet as mx\r\n    ImportError: No module named mxnet\r\n    \r\n    \r\n    error: None of TensorFlow, PyTorch, or MXNet plugins were built. See errors above.\r\n    \r\n    ----------------------------------------\r\nCommand \"/home/ec2-user/anaconda3/envs/tensorflow_p27_1_13_1/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-VZlq_a/horovod/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-pCeskd/install-record.txt --single-version-externally-managed --compile --user --prefix=\" failed with error code 1 in /tmp/pip-install-VZlq_a/horovod/\r\nYou are using pip version 10.0.1, however version 19.1.1 is available.\r\nYou should consider upgrading via the 'pip install --upgrade pip' command.\r\n\r\n(tensorflow_p27_1_13_1) [ec2-user@ip-172-31-31-224 ~]$ python\r\nPython 2.7.15 |Anaconda custom (64-bit)| (default, May  1 2018, 23:32:55) \r\n[GCC 7.2.0] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\n>>> tensorflow.__version__                                                                                                                                             \r\n'1.13.1'\r\n>>> \r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1072/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1072/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1071", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1071/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1071/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1071/events", "html_url": "https://github.com/horovod/horovod/issues/1071", "id": 443625616, "node_id": "MDU6SXNzdWU0NDM2MjU2MTY=", "number": 1071, "title": "\"import horovod.tensorflow\" crash on latest version", "user": {"login": "ThrowMeForALoop", "id": 23578972, "node_id": "MDQ6VXNlcjIzNTc4OTcy", "avatar_url": "https://avatars.githubusercontent.com/u/23578972?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ThrowMeForALoop", "html_url": "https://github.com/ThrowMeForALoop", "followers_url": "https://api.github.com/users/ThrowMeForALoop/followers", "following_url": "https://api.github.com/users/ThrowMeForALoop/following{/other_user}", "gists_url": "https://api.github.com/users/ThrowMeForALoop/gists{/gist_id}", "starred_url": "https://api.github.com/users/ThrowMeForALoop/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ThrowMeForALoop/subscriptions", "organizations_url": "https://api.github.com/users/ThrowMeForALoop/orgs", "repos_url": "https://api.github.com/users/ThrowMeForALoop/repos", "events_url": "https://api.github.com/users/ThrowMeForALoop/events{/privacy}", "received_events_url": "https://api.github.com/users/ThrowMeForALoop/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 21, "created_at": "2019-05-13T22:16:00Z", "updated_at": "2019-05-18T08:08:17Z", "closed_at": "2019-05-17T18:04:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version: tensorflow-gpu(1.12)\r\n3. Horovod version: 0.16.1\r\n4. MPI version: 4.0.0\r\n5. CUDA version: 9.0\r\n6. NCCL version: 2.1.2\r\n7. Python version: 3.6.8\r\n8. OS and version: CENTOS 7\r\n\r\nI just try to test version 0.16.1 and 0.16.0 with tensorflow-gpu by using \"python -c ''import horovod.tensorflow' but it crashes intermediately: \"Illegal instruction\". I reverted to horovod 0.14.1 and it works fine. However I need \"horovod.spark\" which has not existed in lower version than 0.16.0.\r\n\r\nCan anyone help me, please? Thank you so much\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1071/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1071/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1040", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1040/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1040/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1040/events", "html_url": "https://github.com/horovod/horovod/issues/1040", "id": 439064638, "node_id": "MDU6SXNzdWU0MzkwNjQ2Mzg=", "number": 1040, "title": "FORCE-TERMINATE AT Data unpack would read past end of buffer:-26 - error grpcomm_direct.c", "user": {"login": "ddkang", "id": 1894961, "node_id": "MDQ6VXNlcjE4OTQ5NjE=", "avatar_url": "https://avatars.githubusercontent.com/u/1894961?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ddkang", "html_url": "https://github.com/ddkang", "followers_url": "https://api.github.com/users/ddkang/followers", "following_url": "https://api.github.com/users/ddkang/following{/other_user}", "gists_url": "https://api.github.com/users/ddkang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ddkang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ddkang/subscriptions", "organizations_url": "https://api.github.com/users/ddkang/orgs", "repos_url": "https://api.github.com/users/ddkang/repos", "events_url": "https://api.github.com/users/ddkang/events{/privacy}", "received_events_url": "https://api.github.com/users/ddkang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-05-01T04:22:41Z", "updated_at": "2019-05-17T02:17:43Z", "closed_at": "2019-05-17T02:17:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.0.1.post2\r\n3. Horovod version: 0.16.1\r\n4. MPI version: 4.0.0\r\n5. CUDA version: Cuda compilation tools, release 9.0, V9.0.176\r\n6. NCCL version: N/A\r\n7. Python version: 3.5.2\r\n8. OS and version: Ubuntu 16.04\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n\r\nYes, but there was no resolution: https://github.com/horovod/horovod/issues/368\r\n\r\n**Bug report:**\r\n\r\nI tried running the `pytorch_imagenet_resnet50.py` script and got the following error:\r\n\r\n```(fd) ddkang@future4:/lfs/1/ddkang/yeet/hvd-test$ time horovodrun -np 8 -H localhost:4,future5:4 python pytorch_imagenet_resnet50.py                                          \r\n--------------------------------------------------------------------------\r\nAn internal error has occurred in ORTE:\r\n\r\n[[25215,0],1] FORCE-TERMINATE AT Data unpack would read past end of buffer:-26 - error grpcomm_direct.c(359)\r\n\r\nThis is something that should be reported to the developers.\r\n--------------------------------------------------------------------------\r\n[future5.stanford.edu:12508] [[25215,0],1] ORTE_ERROR_LOG: Data unpack would read past end of buffer in file grpcomm_direct.c at line 355\r\n```\r\n\r\nI made sure to configure and install OpenMPI as in the dockerfile.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1040/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1040/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1018", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1018/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1018/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1018/events", "html_url": "https://github.com/horovod/horovod/issues/1018", "id": 434625388, "node_id": "MDU6SXNzdWU0MzQ2MjUzODg=", "number": 1018, "title": "segmentation fault when run horovod with mxnet", "user": {"login": "YouhuiBai", "id": 27176645, "node_id": "MDQ6VXNlcjI3MTc2NjQ1", "avatar_url": "https://avatars.githubusercontent.com/u/27176645?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YouhuiBai", "html_url": "https://github.com/YouhuiBai", "followers_url": "https://api.github.com/users/YouhuiBai/followers", "following_url": "https://api.github.com/users/YouhuiBai/following{/other_user}", "gists_url": "https://api.github.com/users/YouhuiBai/gists{/gist_id}", "starred_url": "https://api.github.com/users/YouhuiBai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YouhuiBai/subscriptions", "organizations_url": "https://api.github.com/users/YouhuiBai/orgs", "repos_url": "https://api.github.com/users/YouhuiBai/repos", "events_url": "https://api.github.com/users/YouhuiBai/events{/privacy}", "received_events_url": "https://api.github.com/users/YouhuiBai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-18T07:19:55Z", "updated_at": "2019-04-19T00:17:23Z", "closed_at": "2019-04-19T00:17:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: MXNet\r\n2. Framework version: 1.5.0b20190314\r\n3. Horovod version: 0.16.1\r\n4. MPI version: openmpi 3.1.2\r\n5. CUDA version: 9.2\r\n6. NCCL version: 2.3.7\r\n7. Python version: 3.6.6\r\n8. OS and version: centos 7.5\r\n9. GCC version: 5.4.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n    Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.md)?\r\n    Yes\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.md)?\r\n\r\n**Bug report:**\r\n\r\nIt is very strange that I ran horovod+mxnet successfully three weeks ago (Mar 22), I reinstalled horovod and mxnet yesterday then there were error when running.\r\n\r\nThe commands for installing mxnet and horovod are as follows:\r\n```\r\n$pip3 install mxnet-cu92==1.5.0b20190314 --pre\r\n$HOROVOD_WITHOUT_TENSORFLOW=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITH_MXNET=1 HOROVOD_NCCL_HOME=/usr/local/nccl_2.3.7 HOROVOD_GPU_ALLREDUCE=NCCL pip3 install --no-cache-dir horovod\r\n```\r\nI tried different openmpi version 3.1.2 and 4.0.1, the same error is still existing.\r\n\r\nI run distributed training using mpirun command like:\r\n```\r\nmpirun -np $1 \\\r\n    -H $2 \\\r\n    -bind-to none -map-by slot \\\r\n    -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x NCCL_IB_DISABLE=1 -x NCCL_SOCKET_IFNAME=ens14f1 \\\r\n    -mca pml ob1 -mca btl openib,vader,self -mca btl_openib_allow_ib 1 \\\r\n    \\\r\n    python3 $HOME/mxnet/horovod/examples/mxnet_imagenet_resnet50.py \\\r\n```\r\nThe error message is as follows:\r\n```\r\n[gpu8:3937 :0:4028] Caught signal 11 (Segmentation fault: address not mapped to object at address (nil))\r\n==== backtrace ====\r\n 0 0x0000000000045e92 ucs_debug_cleanup()  ???:0\r\n 1 0x000000000000f6d0 _L_unlock_13()  funlockfile.c:0\r\n 2 0x0000000000079807 _M_get_pointer()  /usr/local/include/c++/5.4.0/functional:1693\r\n 3 0x0000000000079807 _M_invoke()  /usr/local/include/c++/5.4.0/functional:1871\r\n 4 0x00000000030a45ce mxnet::Engine::Get()  ???:0\r\n 5 0x00000000030a8544 mxnet::Engine::Get()  ???:0\r\n 6 0x00000000030a4c7b mxnet::Engine::Get()  ???:0\r\n 7 0x00000000000b6680 execute_native_thread_routine()  /home/gbxu/download/gcc-5.4.0/build/x86_64-unknown-linux-gnu/libstdc++-v3/src/c++11/../../../../../libstdc++-v3/src/c++11/thread.cc:84\r\n 8 0x00000000000b6680 std::__shared_ptr<std::thread::_Impl_base, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr()  /home/gbxu/download/gcc-5.4.0/build/x86_64-unknown-linux-gnu/libstdc++-v3/include/bits/shared_ptr_base.h:925\r\n 9 0x00000000000b6680 std::shared_ptr<std::thread::_Impl_base>::~shared_ptr()  /home/gbxu/download/gcc-5.4.0/build/x86_64-unknown-linux-gnu/libstdc++-v3/include/bits/shared_ptr.h:93\r\n10 0x00000000000b6680 execute_native_thread_routine()  /home/gbxu/download/gcc-5.4.0/build/x86_64-unknown-linux-gnu/libstdc++-v3/src/c++11/../../../../../libstdc++-v3/src/c++11/thread.cc:79\r\n11 0x0000000000007e25 start_thread()  pthread_create.c:0\r\n12 0x00000000000febad __clone()  ???:0\r\n```\r\n\r\nI am grateful for any comments.\r\n\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/1018/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/1018/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/950", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/950/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/950/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/950/events", "html_url": "https://github.com/horovod/horovod/issues/950", "id": 424826610, "node_id": "MDU6SXNzdWU0MjQ4MjY2MTA=", "number": 950, "title": "In the run.py file,  the variable \"envs\" does not have a attribute \"ENV_IGNORE\"", "user": {"login": "memozhu", "id": 24536530, "node_id": "MDQ6VXNlcjI0NTM2NTMw", "avatar_url": "https://avatars.githubusercontent.com/u/24536530?v=4", "gravatar_id": "", "url": "https://api.github.com/users/memozhu", "html_url": "https://github.com/memozhu", "followers_url": "https://api.github.com/users/memozhu/followers", "following_url": "https://api.github.com/users/memozhu/following{/other_user}", "gists_url": "https://api.github.com/users/memozhu/gists{/gist_id}", "starred_url": "https://api.github.com/users/memozhu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/memozhu/subscriptions", "organizations_url": "https://api.github.com/users/memozhu/orgs", "repos_url": "https://api.github.com/users/memozhu/repos", "events_url": "https://api.github.com/users/memozhu/events{/privacy}", "received_events_url": "https://api.github.com/users/memozhu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-25T10:30:44Z", "updated_at": "2019-03-26T00:35:07Z", "closed_at": "2019-03-26T00:35:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n![image](https://user-images.githubusercontent.com/24536530/54912344-651b8080-4f2b-11e9-91fa-15d949f73843.png)\r\n\r\n![image](https://user-images.githubusercontent.com/24536530/54912371-75cbf680-4f2b-11e9-9f6f-40da57b82c70.png)\r\n\r\n![image](https://user-images.githubusercontent.com/24536530/54911665-ed008b00-4f29-11e9-993c-85975d954bba.png)\r\n\r\nMaybe there is something wrong with the \"env\" variable name. How can I solve it?\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/950/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/950/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/939", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/939/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/939/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/939/events", "html_url": "https://github.com/horovod/horovod/issues/939", "id": 423409548, "node_id": "MDU6SXNzdWU0MjM0MDk1NDg=", "number": 939, "title": "Symbol not found: __ZN10tensorflow12OpDefBuilder3DocESs", "user": {"login": "zhenghh04", "id": 5777773, "node_id": "MDQ6VXNlcjU3Nzc3NzM=", "avatar_url": "https://avatars.githubusercontent.com/u/5777773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhenghh04", "html_url": "https://github.com/zhenghh04", "followers_url": "https://api.github.com/users/zhenghh04/followers", "following_url": "https://api.github.com/users/zhenghh04/following{/other_user}", "gists_url": "https://api.github.com/users/zhenghh04/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhenghh04/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhenghh04/subscriptions", "organizations_url": "https://api.github.com/users/zhenghh04/orgs", "repos_url": "https://api.github.com/users/zhenghh04/repos", "events_url": "https://api.github.com/users/zhenghh04/events{/privacy}", "received_events_url": "https://api.github.com/users/zhenghh04/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-03-20T18:30:35Z", "updated_at": "2022-06-15T10:52:58Z", "closed_at": "2021-08-11T20:10:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\nTensorFlow\r\n\r\n2. Framework version: 1.13.1\r\n3. Horovod version: 0.16.1\r\n4. MPI version: MPICH 3.3\r\n5. CUDA version: Non\r\n6. NCCL version: Non\r\n7. Python version:3.6.5\r\n8. OS and version: macOS Mojave 10.14.3\r\n\r\n**Bug report:**\r\nHorovod was built successfully. But try to run it as\r\n\r\n$ python -c 'import horovod.tensorflow as hvd'\r\nI got the following error: \r\n\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/anaconda3/lib/python3.6/site-packages/horovod/tensorflow/__init__.py\", line 38, in <module>\r\n    from horovod.tensorflow.mpi_ops import allgather, broadcast, _allreduce\r\n  File \"/anaconda3/lib/python3.6/site-packages/horovod/tensorflow/mpi_ops.py\", line 59, in <module>\r\n    ['HorovodAllgather', 'HorovodAllreduce'])\r\n  File \"/anaconda3/lib/python3.6/site-packages/horovod/tensorflow/mpi_ops.py\", line 46, in _load_library\r\n    library = load_library.load_op_library(filename)\r\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py\", line 61, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: dlopen(/anaconda3/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-darwin.so, 6): Symbol not found: __ZN10tensorflow12OpDefBuilder3DocESs\r\n  Referenced from: /anaconda3/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-darwin.so\r\n  Expected in: flat namespace\r\n in /anaconda3/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-darwin.so\r\n\r\n=====\r\nI suspect that it might be due to incompatibility between Tensorflow 1.13.1 and Horovod 0.16.1. ", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/939/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/939/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/904", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/904/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/904/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/904/events", "html_url": "https://github.com/horovod/horovod/issues/904", "id": 419854254, "node_id": "MDU6SXNzdWU0MTk4NTQyNTQ=", "number": 904, "title": "Latest Horovod with PyTorch error with NCCL", "user": {"login": "jaliyae", "id": 12703337, "node_id": "MDQ6VXNlcjEyNzAzMzM3", "avatar_url": "https://avatars.githubusercontent.com/u/12703337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jaliyae", "html_url": "https://github.com/jaliyae", "followers_url": "https://api.github.com/users/jaliyae/followers", "following_url": "https://api.github.com/users/jaliyae/following{/other_user}", "gists_url": "https://api.github.com/users/jaliyae/gists{/gist_id}", "starred_url": "https://api.github.com/users/jaliyae/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jaliyae/subscriptions", "organizations_url": "https://api.github.com/users/jaliyae/orgs", "repos_url": "https://api.github.com/users/jaliyae/repos", "events_url": "https://api.github.com/users/jaliyae/events{/privacy}", "received_events_url": "https://api.github.com/users/jaliyae/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-03-12T08:18:58Z", "updated_at": "2019-03-14T07:32:41Z", "closed_at": "2019-03-14T07:32:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (PyTorch)\r\n2. Framework version: Source\r\n3. Horovod version: 0.16\r\n4. MPI version: openmpi:1.10.3\r\n5. CUDA version:90\r\n6. NCCL version:2.3.7-1+cuda9.0\r\n7. Python version:3.6\r\n8. OS and version:Ubuntu 16\r\n\r\nPyTorch with Horovod 0.16 produce the following error (repro all the time) on multi node setup with NCCL. Could not find a similar stack in previous questions. Is this a known issue? any workarounds, please let me know.\r\n\r\n```\r\n2019-03-12T01:47:15.000Z /      hvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\n2019-03-12T01:47:15.000Z /    File \"/opt/conda/lib/python3.6/site-packages/horovod/torch/__init__.py\", line 224, in broadcast_parameters\r\n2019-03-12T01:47:15.000Z /      handle = broadcast_async_(p, root_rank, name)\r\n2019-03-12T01:47:15.000Z /    File \"/opt/conda/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 380, in broadcast_async_\r\n2019-03-12T01:47:15.000Z /      return _broadcast_async(tensor, tensor, root_rank, name)\r\n2019-03-12T01:47:15.000Z /    File \"/opt/conda/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 290, in _broadcast_async\r\n2019-03-12T01:47:15.000Z /      tensor, output, root_rank, name.encode() if name is not None else _NULL)\r\n2019-03-12T01:47:15.000Z /  RuntimeError: CUDA error: an illegal memory access was encountered (copy_to_cpu at /opt/pytorch/aten/src/ATen/native/cuda/Copy.cu:189)\r\n2019-03-12T01:47:15.000Z /  frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x6a (0x7f72bcd5c88a in /opt/conda/lib/python3.6/site-packages/torch/lib/libc10.so)\r\n2019-03-12T01:47:15.000Z /  frame #1: (anonymous namespace)::copy_to_cpu(at::Tensor&, at::Tensor const&) + 0x433 (0x7f72c2544f63 in /opt/conda/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\r\n2019-03-12T01:47:15.000Z /  frame #2: void (anonymous namespace)::_copy__cuda<float>(at::Tensor&, at::Tensor const&, bool) + 0x944 (0x7f72c25d17c4 in /opt/conda/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\r\n2019-03-12T01:47:15.000Z /  frame #3: at::native::_s_copy__cuda(at::Tensor&, at::Tensor const&, bool) + 0x65 (0x7f72c2548325 in /opt/conda/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\r\n2019-03-12T01:47:15.000Z /  frame #4: at::native::_s_copy_from_cuda(at::Tensor const&, at::Tensor const&, bool) + 0x42 (0x7f72c25484e2 in /opt/conda/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\r\n2019-03-12T01:47:15.000Z /  frame #5: at::CUDAFloatType::_s_copy_from(at::Tensor const&, at::Tensor const&, bool) const + 0x8e (0x7f72c13066fe in /opt/conda/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\r\n2019-03-12T01:47:15.000Z /  frame #6: at::native::_s_copy__cpu(at::Tensor&, at::Tensor const&, bool) + 0x6d (0x7f72bd65bf0d in /opt/conda/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\r\n2019-03-12T01:47:15.000Z /  frame #7: <unknown function> + 0x9ca1c8 (0x7f72bd93a1c8 in /opt/conda/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\r\n2019-03-12T01:47:15.000Z /  frame #8: torch::autograd::VariableType::s_copy_(at::Tensor&, at::Tensor const&, bool) const + 0xcaa (0x7f72bc2b0a5a in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch.so.1)\r\n2019-03-12T01:47:15.000Z /  frame #9: at::TypeDefault::copy_(at::Tensor&, at::Tensor const&, bool) const + 0x118 (0x7f72bda89458 in /opt/conda/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\r\n2019-03-12T01:47:15.000Z /  frame #10: at::TypeDefault::copy(at::Tensor const&, bool, c10::optional<c10::Device>) const + 0x1db (0x7f72bda88edb in /opt/conda/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\r\n2019-03-12T01:47:15.000Z /  frame #11: at::native::to(at::Tensor const&, c10::TensorOptions const&, bool, bool) + 0x12fa (0x7f72bd7f48ca in /opt/conda/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\r\n2019-03-12T01:47:15.000Z /  frame #12: at::TypeDefault::to(at::Tensor const&, c10::TensorOptions const&, bool, bool) const + 0x2b (0x7f72bda5bb5b in /opt/conda/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\r\n2019-03-12T01:47:15.000Z /  frame #13: torch::autograd::VariableType::to(at::Tensor const&, c10::TensorOptions const&, bool, bool) const + 0x186 (0x7f72bc0ffc46 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch.so.1)\r\n2019-03-12T01:47:15.000Z /  frame #14: <unknown function> + 0x79c61 (0x7f7280f50c61 in /opt/conda/lib/python3.6/site-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\n2019-03-12T01:47:15.000Z /  frame #15: horovod::torch::DoBroadcastCudaOnCPU(at::Tensor, at::Tensor, int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xca (0x7f7280f4e4ea in /opt/conda/lib/python3.6/site-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\n2019-03-12T01:47:15.000Z /  frame #16: <unknown function> + 0x85d98 (0x7f7280f5cd98 in /opt/conda/lib/python3.6/site-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\n2019-03-12T01:47:15.000Z /  frame #17: <unknown function> + 0x85ece (0x7f7280f5cece in /opt/conda/lib/python3.6/site-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\n2019-03-12T01:47:15.000Z /  frame #18: <unknown function> + 0x82ff7 (0x7f7280f59ff7 in /opt/conda/lib/python3.6/site-packages/horovod/torch/mpi_lib_v2.cpython-36m-x86_64-linux-gnu.so)\r\n\r\n\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/904/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/904/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/895", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/895/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/895/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/895/events", "html_url": "https://github.com/horovod/horovod/issues/895", "id": 418627037, "node_id": "MDU6SXNzdWU0MTg2MjcwMzc=", "number": 895, "title": "mxnet+hvd with different random seed won't work with Gluon API", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-03-08T04:29:00Z", "updated_at": "2019-03-28T03:35:35Z", "closed_at": "2019-03-28T03:35:35Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (MXNet)\r\n2. Framework version: 1.4\r\n3. Horovod version: v0.16.0 \r\n4. MPI version: \r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version: 2.7/3.6\r\n8. OS and version: \r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.md)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.md)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nIf the shape of a parameter has to be inferred after a batch of data is seen, the parameter will not be broadcast. Therefore, the correctness of the program depends on whether all workers are initialized with the same random seed. So the following program will not work:\r\n\r\n```\r\nrandom.seed(hvd.local_rank())\r\ndata = ..\r\nmodel = mx.gluon.nn.Dense(10)\r\nmodel.initialize()\r\n\r\n// no parameters are broadcast, because initialization is deferred.\r\nhvd.broadcast_parameters(model.collect_parameters())\r\n\r\nfor batch in data:\r\n    // params are initialized after shape is known\r\n    pred = model(batch.data[0])\r\n    ...\r\n...\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/895/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/895/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/894", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/894/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/894/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/894/events", "html_url": "https://github.com/horovod/horovod/issues/894", "id": 418357564, "node_id": "MDU6SXNzdWU0MTgzNTc1NjQ=", "number": 894, "title": "Pip3 install error for Horovod 0.16.0 with intel compilers", "user": {"login": "casparvl", "id": 33718780, "node_id": "MDQ6VXNlcjMzNzE4Nzgw", "avatar_url": "https://avatars.githubusercontent.com/u/33718780?v=4", "gravatar_id": "", "url": "https://api.github.com/users/casparvl", "html_url": "https://github.com/casparvl", "followers_url": "https://api.github.com/users/casparvl/followers", "following_url": "https://api.github.com/users/casparvl/following{/other_user}", "gists_url": "https://api.github.com/users/casparvl/gists{/gist_id}", "starred_url": "https://api.github.com/users/casparvl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/casparvl/subscriptions", "organizations_url": "https://api.github.com/users/casparvl/orgs", "repos_url": "https://api.github.com/users/casparvl/repos", "events_url": "https://api.github.com/users/casparvl/events{/privacy}", "received_events_url": "https://api.github.com/users/casparvl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-07T15:04:28Z", "updated_at": "2019-03-12T16:01:42Z", "closed_at": "2019-03-12T16:01:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.13.1\r\n3. Horovod version: 0.16.0\r\n4. MPI version: 2018.3.222\r\n5. CUDA version: 10.0.130\r\n6. NCCL version: 2.3.5\r\n7. Python version: 3.6.6\r\n8. OS and version: RedHatEnterpriseServer 7.5\r\n9. Compilers: icc version 2018.3.222\r\n\r\n**Bug report:**\r\nRunning \r\n\r\n`pip3 install horovod`\r\n\r\nfails on the setup.py install:\r\n\r\n```\r\nRunning setup.py install for horovod ... error\r\n...\r\n\r\n    In file included from horovod/common/timeline.cc(22):\r\n    horovod/common/timeline.h(60): error: namespace \"std\" has no member \"atomic_bool\"\r\n        std::atomic_bool healthy_{false};\r\n             ^\r\n    \r\n    compilation aborted for horovod/common/timeline.cc (code 2)\r\n    INFO: Unable to build TensorFlow plugin, will skip it.\r\n```\r\n\r\nI have noticed that timeline.h does not have an \r\n```\r\n#include <atomic>\r\n```\r\ninclude. I downloaded the Horovod source code, added this include to horovod/common/timeline.h, tarred it again and then installed with\r\n\r\n```\r\npip3 install horovod-0.16.0.tar.gz\r\n```\r\nInstallation then completes without errors.\r\n\r\n**Suggested solution:**\r\nAdd `#include <atomic>` to `horovod/common/timeline.h`.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/894/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/894/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/884", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/884/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/884/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/884/events", "html_url": "https://github.com/horovod/horovod/issues/884", "id": 417522763, "node_id": "MDU6SXNzdWU0MTc1MjI3NjM=", "number": 884, "title": "Segmentation fault: running MXNet with Horovod on Ubuntu Linux 16.04", "user": {"login": "apeforest", "id": 6807113, "node_id": "MDQ6VXNlcjY4MDcxMTM=", "avatar_url": "https://avatars.githubusercontent.com/u/6807113?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apeforest", "html_url": "https://github.com/apeforest", "followers_url": "https://api.github.com/users/apeforest/followers", "following_url": "https://api.github.com/users/apeforest/following{/other_user}", "gists_url": "https://api.github.com/users/apeforest/gists{/gist_id}", "starred_url": "https://api.github.com/users/apeforest/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apeforest/subscriptions", "organizations_url": "https://api.github.com/users/apeforest/orgs", "repos_url": "https://api.github.com/users/apeforest/repos", "events_url": "https://api.github.com/users/apeforest/events{/privacy}", "received_events_url": "https://api.github.com/users/apeforest/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-03-05T22:03:36Z", "updated_at": "2019-04-19T15:31:48Z", "closed_at": "2019-04-19T05:09:07Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: MXNet\r\n2. Framework version: 1.4.0\r\n3. Horovod version: 0.16.0\r\n4. MPI version: 3.1.1\r\n5. CUDA version: 9.2\r\n6. NCCL version: 2.2.13\r\n7. Python version: 3.5\r\n8. OS and version: Linux Ubuntu 16.04\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\nYes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.md)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.md)?\r\n\r\n**Bug report:**\r\nWhen running Horovod with MXNet on Linux Ubuntu 16.04, there will be a segmentation fault.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/884/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/884/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/852", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/852/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/852/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/852/events", "html_url": "https://github.com/horovod/horovod/issues/852", "id": 413565676, "node_id": "MDU6SXNzdWU0MTM1NjU2NzY=", "number": 852, "title": "'float' object has no attribute 'detach' in pytorch imagenet example.", "user": {"login": "WangXin93", "id": 19688994, "node_id": "MDQ6VXNlcjE5Njg4OTk0", "avatar_url": "https://avatars.githubusercontent.com/u/19688994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WangXin93", "html_url": "https://github.com/WangXin93", "followers_url": "https://api.github.com/users/WangXin93/followers", "following_url": "https://api.github.com/users/WangXin93/following{/other_user}", "gists_url": "https://api.github.com/users/WangXin93/gists{/gist_id}", "starred_url": "https://api.github.com/users/WangXin93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WangXin93/subscriptions", "organizations_url": "https://api.github.com/users/WangXin93/orgs", "repos_url": "https://api.github.com/users/WangXin93/repos", "events_url": "https://api.github.com/users/WangXin93/events{/privacy}", "received_events_url": "https://api.github.com/users/WangXin93/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-02-22T20:26:43Z", "updated_at": "2019-02-22T22:15:02Z", "closed_at": "2019-02-22T22:15:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "I ran the [pytorch imagenet example](https://github.com/horovod/horovod/blob/master/examples/pytorch_imagenet_resnet50.py) but got an error that `float` number don't have `detach()` method. It seems that `loss.item()` lead to the `float` number, but I don't know how to fix that in `horovod` framework. \r\n\r\nCan anyone help me? Thanks a lot!\r\n\r\n```\r\nmpirun -np 4 \\\r\n  -H localhost:4 \\\r\n  -bind-to none -map-by slot \\\r\n  -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH \\\r\n  -mca pml ob1 -mca btl ^openib \\\r\n  python main_hvd.py --train-dir /datasets/ILSVRC2012/images/train --val-dir /datasets/ILSVRC2012/images/val\r\n```\r\n\r\n```\r\nTrain Epoch     #1:   0%|          | 0/10010 [00:00<?, ?it/s]Traceback (most recent call last):\r\n  File \"main_hvd.py\", line 272, in <module>\r\n    train(epoch)\r\n  File \"main_hvd.py\", line 179, in train\r\n    train_loss.update(loss.item())\r\n  File \"main_hvd.py\", line 263, in update\r\n    self.sum += hvd.allreduce(val.detach().cpu(), name=self.name)\r\nAttributeError: 'float' object has no attribute 'detach'\r\n```\r\n\r\nMy environment is:\r\n* pytorch==0.4.1\r\n* horovod==0.16.0", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/852/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/852/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/738", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/738/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/738/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/738/events", "html_url": "https://github.com/horovod/horovod/issues/738", "id": 396943234, "node_id": "MDU6SXNzdWUzOTY5NDMyMzQ=", "number": 738, "title": "Horovod build image failure still present", "user": {"login": "mr-ubik", "id": 16547060, "node_id": "MDQ6VXNlcjE2NTQ3MDYw", "avatar_url": "https://avatars.githubusercontent.com/u/16547060?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mr-ubik", "html_url": "https://github.com/mr-ubik", "followers_url": "https://api.github.com/users/mr-ubik/followers", "following_url": "https://api.github.com/users/mr-ubik/following{/other_user}", "gists_url": "https://api.github.com/users/mr-ubik/gists{/gist_id}", "starred_url": "https://api.github.com/users/mr-ubik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mr-ubik/subscriptions", "organizations_url": "https://api.github.com/users/mr-ubik/orgs", "repos_url": "https://api.github.com/users/mr-ubik/repos", "events_url": "https://api.github.com/users/mr-ubik/events{/privacy}", "received_events_url": "https://api.github.com/users/mr-ubik/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-01-08T14:57:25Z", "updated_at": "2019-01-09T02:55:02Z", "closed_at": "2019-01-09T02:55:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "Building the Docker via build-docker-images.sh:\r\n\r\n```\r\nThe following held packages will be changed:\r\n  libnccl2\r\nThe following packages will be upgraded:\r\n  ca-certificates\r\nThe following packages will be DOWNGRADED:\r\n  libnccl-dev libnccl2\r\n1 upgraded, 40 newly installed, 2 downgraded, 0 to remove and 36 not upgraded.\r\nE: Packages were downgraded and -y was used without --allow-downgrades.\r\nThe command '/bin/sh -c apt-get update && apt-get install -y --no-install-recommends         build-essential         cmake         git         curl         vim         wget         ca-certificates         libcudnn7=${CUDNN_VERSION}         libnccl2=${NCCL_VERSION}         libnccl-dev=${NCCL_VERSION}         libjpeg-dev         libpng-dev         python${PYTHON_VERSION}         python${PYTHON_VERSION}-dev' returned a non-zero code: 100\r\n```", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/738/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/738/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/724", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/724/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/724/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/724/events", "html_url": "https://github.com/horovod/horovod/issues/724", "id": 394498609, "node_id": "MDU6SXNzdWUzOTQ0OTg2MDk=", "number": 724, "title": "Crash when using Horovod with Torch0.4 and Py3", "user": {"login": "rahul003", "id": 3457240, "node_id": "MDQ6VXNlcjM0NTcyNDA=", "avatar_url": "https://avatars.githubusercontent.com/u/3457240?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rahul003", "html_url": "https://github.com/rahul003", "followers_url": "https://api.github.com/users/rahul003/followers", "following_url": "https://api.github.com/users/rahul003/following{/other_user}", "gists_url": "https://api.github.com/users/rahul003/gists{/gist_id}", "starred_url": "https://api.github.com/users/rahul003/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rahul003/subscriptions", "organizations_url": "https://api.github.com/users/rahul003/orgs", "repos_url": "https://api.github.com/users/rahul003/repos", "events_url": "https://api.github.com/users/rahul003/events{/privacy}", "received_events_url": "https://api.github.com/users/rahul003/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2018-12-27T22:14:24Z", "updated_at": "2019-01-03T19:14:42Z", "closed_at": "2019-01-03T07:00:09Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "There's a segfault which shows up in test_torch.py/test_broadcast_state when running tests (i.e. `pytest -v`). \r\nIf this test is run separately (i.e. `pytest -v test/test_torch.py` ), then it passes.\r\n\r\nCommit used to build Horovod: 4cf885f8807413720024543f853ff3af06413770\r\n[Crash message](https://pastebin.com/raw/xGzwu6jr)\r\n[Stacktrace from corefile](https://pastebin.com/raw/iifPG6tS)\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/724/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/724/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/709", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/709/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/709/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/709/events", "html_url": "https://github.com/horovod/horovod/issues/709", "id": 391818712, "node_id": "MDU6SXNzdWUzOTE4MTg3MTI=", "number": 709, "title": "import both horovod.tensorflow and horovod.torch cause issues", "user": {"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-12-17T17:37:23Z", "updated_at": "2021-03-27T15:47:37Z", "closed_at": "2021-03-27T15:47:36Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I hit an issue when the code import both horovod.tensorflow and horovod.torch and use the latter. It might not be a valid use case in batch jobs, but in interactive notebooks, it would cause issues. Is there a shared variable that causes this issue?\r\n\r\nEnv:\r\n* Python 3.6\r\n* TensorFlow 1.12\r\n* PyTorch 0.4.1\r\n* Horovod 0.15.0\r\n\r\nCode:\r\ntest_torch.py\r\n~~~python\r\nimport horovod.tensorflow\r\nimport torch\r\nimport horovod.torch as hvd\r\n\r\nhvd.init()\r\nhvd.broadcast(torch.tensor(0), root_rank=0)\r\n~~~\r\n\r\nRun:\r\n~~~\r\n$ python test_torch.py\r\n~~~\r\n\r\nError:\r\n~~~\r\nTraceback (most recent call last):\r\n  File \"test_pytorch.sh\", line 6, in <module>\r\n    hvd.broadcast(torch.tensor(0), root_rank=0)\r\n  File \"/opt/conda/envs/sparkdl/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 358, in broadcast\r\n    return HorovodBroadcast.apply(tensor, root_rank, name)\r\n  File \"/opt/conda/envs/sparkdl/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 324, in forward\r\n    handle = broadcast_async(tensor, root_rank, name)\r\n  File \"/opt/conda/envs/sparkdl/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 315, in broadcast_async\r\n    return _broadcast_async(tensor, output, root_rank, name)\r\n  File \"/opt/conda/envs/sparkdl/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 290, in _broadcast_async\r\n    tensor, output, root_rank, name.encode() if name is not None else _NULL)\r\n  File \"/opt/conda/envs/sparkdl/lib/python3.6/site-packages/torch/utils/ffi/__init__.py\", line 202, in safe_call\r\n    result = torch._C._safe_call(*args, **kwargs)\r\ntorch.FatalError: Horovod has not been initialized; use hvd.init().\r\n~~~\r\n\r\nWithout \"import tensorflow.horovod\", it runs successfully.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/709/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/709/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/702", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/702/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/702/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/702/events", "html_url": "https://github.com/horovod/horovod/issues/702", "id": 390544123, "node_id": "MDU6SXNzdWUzOTA1NDQxMjM=", "number": 702, "title": "Compilation failed on Ubuntu 16.04", "user": {"login": "Lyken17", "id": 7783214, "node_id": "MDQ6VXNlcjc3ODMyMTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/7783214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lyken17", "html_url": "https://github.com/Lyken17", "followers_url": "https://api.github.com/users/Lyken17/followers", "following_url": "https://api.github.com/users/Lyken17/following{/other_user}", "gists_url": "https://api.github.com/users/Lyken17/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lyken17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lyken17/subscriptions", "organizations_url": "https://api.github.com/users/Lyken17/orgs", "repos_url": "https://api.github.com/users/Lyken17/repos", "events_url": "https://api.github.com/users/Lyken17/events{/privacy}", "received_events_url": "https://api.github.com/users/Lyken17/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-12-13T07:02:30Z", "updated_at": "2018-12-14T19:39:40Z", "closed_at": "2018-12-14T19:39:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was compiling the master branch of horovod\r\n# gcc-4.8\r\n```bash\r\nhorovod/common/operations.cc: In function \u2018void horovod::common::{anonymous}::PerformOperation(horovod::common::{anonymous}::TensorTable&, horovod::common::MPIResponse)\u2019:\r\nhorovod/common/operations.cc:957:75: error: \u2018RECORD_EVENT\u2019 was not declared in this scope\r\n           RECORD_EVENT(entries, event_queue, MEMCPY_IN_HOST_BUFFER, stream)\r\n                                                                           ^\r\nhorovod/common/operations.cc:958:9: error: expected \u2018;\u2019 before \u2018}\u2019 token\r\n         }\r\n         ^\r\nhorovod/common/operations.cc:959:55: error: \u2018WAIT_FOR_EVENTS\u2019 was not declared in this scope\r\n         WAIT_FOR_EVENTS(entries, timeline, event_queue)\r\n                                                       ^\r\nhorovod/common/operations.cc:960:7: error: expected \u2018;\u2019 before \u2018}\u2019 token\r\n       } else {\r\n       ^\r\nhorovod/common/operations.cc:996:76: error: \u2018RECORD_EVENT\u2019 was not declared in this scope\r\n           RECORD_EVENT(entries, event_queue, MEMCPY_OUT_HOST_BUFFER, stream)\r\n                                                                            ^\r\nhorovod/common/operations.cc:997:9: error: expected \u2018;\u2019 before \u2018}\u2019 token\r\n         }\r\n         ^\r\nhorovod/common/operations.cc:998:55: error: \u2018WAIT_FOR_EVENTS\u2019 was not declared in this scope\r\n         WAIT_FOR_EVENTS(entries, timeline, event_queue)\r\n                                                       ^\r\nhorovod/common/operations.cc:999:7: error: expected \u2018;\u2019 before \u2018}\u2019 token\r\n       } else {\r\n       ^\r\nINFO: Unable to build PyTorch plugin, will skip it.\r\n```\r\n\r\n# gcc-5\r\n```bash\r\nhorovod/common/operations.cc: In function \u2018void horovod::common::{anonymous}::PerformOperation(horovod::common::{anonymous}::TensorTable&, horovod::common::MPIResponse)\u2019:\r\nhorovod/common/operations.cc:957:75: error: \u2018RECORD_EVENT\u2019 was not declared in this scope\r\n           RECORD_EVENT(entries, event_queue, MEMCPY_IN_HOST_BUFFER, stream)\r\n                                                                           ^\r\nhorovod/common/operations.cc:959:55: error: \u2018WAIT_FOR_EVENTS\u2019 was not declared in this scope\r\n         WAIT_FOR_EVENTS(entries, timeline, event_queue)\r\n                                                       ^\r\nhorovod/common/operations.cc:996:76: error: \u2018RECORD_EVENT\u2019 was not declared in this scope\r\n           RECORD_EVENT(entries, event_queue, MEMCPY_OUT_HOST_BUFFER, stream)\r\n                                                                            ^\r\nhorovod/common/operations.cc:998:55: error: \u2018WAIT_FOR_EVENTS\u2019 was not declared in this scope\r\n         WAIT_FOR_EVENTS(entries, timeline, event_queue)\r\n                                                       ^\r\nINFO: Unable to build PyTorch plugin, will skip it.\r\n```\r\n# gcc-6\r\n```bash\r\nhorovod/common/operations.cc: In function \u2018void horovod::common::{anonymous}::PerformOperation(horovod::common::{anonymous}::TensorTable&, horovod::common::MPIResponse)\u2019:\r\nhorovod/common/operations.cc:957:75: error: \u2018RECORD_EVENT\u2019 was not declared in this scope\r\n           RECORD_EVENT(entries, event_queue, MEMCPY_IN_HOST_BUFFER, stream)\r\n                                                                           ^\r\nhorovod/common/operations.cc:959:55: error: \u2018WAIT_FOR_EVENTS\u2019 was not declared in this scope\r\n         WAIT_FOR_EVENTS(entries, timeline, event_queue)\r\n                                                       ^\r\nhorovod/common/operations.cc:996:76: error: \u2018RECORD_EVENT\u2019 was not declared in this scope\r\n           RECORD_EVENT(entries, event_queue, MEMCPY_OUT_HOST_BUFFER, stream)\r\n                                                                            ^\r\nhorovod/common/operations.cc:998:55: error: \u2018WAIT_FOR_EVENTS\u2019 was not declared in this scope\r\n         WAIT_FOR_EVENTS(entries, timeline, event_queue)\r\n                                                       ^\r\nINFO: Unable to build PyTorch plugin, will skip it.\r\n```\r\n\r\n# gcc-7\r\n```bash\r\nhorovod/common/operations.cc: In function \u2018void horovod::common::{anonymous}::PerformOperation(horovod::common::{anonymous}::TensorTable&, horovod::common::MPIResponse)\u2019:\r\nhorovod/common/operations.cc:957:11: error: \u2018RECORD_EVENT\u2019 was not declared in this scope\r\n           RECORD_EVENT(entries, event_queue, MEMCPY_IN_HOST_BUFFER, stream)\r\n           ^~~~~~~~~~~~\r\nhorovod/common/operations.cc:957:11: note: suggested alternative: \u2018ECONNRESET\u2019\r\n           RECORD_EVENT(entries, event_queue, MEMCPY_IN_HOST_BUFFER, stream)\r\n           ^~~~~~~~~~~~\r\n           ECONNRESET\r\nhorovod/common/operations.cc:959:9: error: \u2018WAIT_FOR_EVENTS\u2019 was not declared in this scope\r\n         WAIT_FOR_EVENTS(entries, timeline, event_queue)\r\n         ^~~~~~~~~~~~~~~\r\nhorovod/common/operations.cc:959:9: note: suggested alternative: \u2018WAIT_FOR_DATA\u2019\r\n         WAIT_FOR_EVENTS(entries, timeline, event_queue)\r\n         ^~~~~~~~~~~~~~~\r\n         WAIT_FOR_DATA\r\nhorovod/common/operations.cc:996:11: error: \u2018RECORD_EVENT\u2019 was not declared in this scope\r\n           RECORD_EVENT(entries, event_queue, MEMCPY_OUT_HOST_BUFFER, stream)\r\n           ^~~~~~~~~~~~\r\nhorovod/common/operations.cc:996:11: note: suggested alternative: \u2018ECONNRESET\u2019\r\n           RECORD_EVENT(entries, event_queue, MEMCPY_OUT_HOST_BUFFER, stream)\r\n           ^~~~~~~~~~~~\r\n           ECONNRESET\r\nhorovod/common/operations.cc:998:9: error: \u2018WAIT_FOR_EVENTS\u2019 was not declared in this scope\r\n         WAIT_FOR_EVENTS(entries, timeline, event_queue)\r\n         ^~~~~~~~~~~~~~~\r\nhorovod/common/operations.cc:998:9: note: suggested alternative: \u2018WAIT_FOR_DATA\u2019\r\n         WAIT_FOR_EVENTS(entries, timeline, event_queue)\r\n         ^~~~~~~~~~~~~~~\r\n         WAIT_FOR_DATA\r\nINFO: Unable to build PyTorch plugin, will skip it.\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/702/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/702/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/642", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/642/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/642/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/642/events", "html_url": "https://github.com/horovod/horovod/issues/642", "id": 383347601, "node_id": "MDU6SXNzdWUzODMzNDc2MDE=", "number": 642, "title": "Horovod hangs on shutdown when a rank crashes", "user": {"login": "jeff-engineml", "id": 43305425, "node_id": "MDQ6VXNlcjQzMzA1NDI1", "avatar_url": "https://avatars.githubusercontent.com/u/43305425?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeff-engineml", "html_url": "https://github.com/jeff-engineml", "followers_url": "https://api.github.com/users/jeff-engineml/followers", "following_url": "https://api.github.com/users/jeff-engineml/following{/other_user}", "gists_url": "https://api.github.com/users/jeff-engineml/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeff-engineml/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeff-engineml/subscriptions", "organizations_url": "https://api.github.com/users/jeff-engineml/orgs", "repos_url": "https://api.github.com/users/jeff-engineml/repos", "events_url": "https://api.github.com/users/jeff-engineml/events{/privacy}", "received_events_url": "https://api.github.com/users/jeff-engineml/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-11-22T01:25:10Z", "updated_at": "2018-11-22T21:17:03Z", "closed_at": "2018-11-22T21:17:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "# Environment\r\nMPI Versions: 3.0.0, 3.1.2, & 4.0.0\r\nPytorch 0.4.1 & Tensorflow 1.8.0\r\nPython 2.7\r\n\r\n# Minimal Example\r\n```python\r\nfrom __future__ import print_function\r\n\r\nimport atexit\r\nimport sys\r\nimport time\r\ntry:\r\n  import horovod.torch as hvd\r\nexcept ImportError:\r\n  import horovod.tensorflow as hvd\r\n\r\nif __name__ == '__main__':\r\n  print('initializing')\r\n  hvd.init()\r\n  # Uncomment this to achieve the expected behavior\r\n  # atexit._exithandlers = []\r\n  time.sleep(3)\r\n  print('initialized')\r\n  if hvd.rank() == 0:\r\n    time.sleep(10)\r\n    print('exiting!')\r\n    sys.exit(1)\r\n  else:\r\n    print('Sleeping for', sys.argv[1])\r\n    time.sleep(int(sys.argv[1]))\r\n    print('done')\r\n```\r\n\r\n## Behavior\r\nAfter rank 0 exits, rank 1 continues to sleep. When rank 1 finishes sleeping, it prints `done` and mpi exits with an error. \r\n\r\n```bash\r\n$ mpirun -mca btl ^tcp -np 2 python sleep.py 50\r\ninitializing\r\ninitializing\r\ninitialized\r\nSleeping for 30\r\ninitialized\r\nexiting!\r\ndone\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun.real detected that one or more processes exited with non-zero status, thus causing\r\nthe job to be terminated. The first process to do so was:\r\n\r\n  Process name: [[39251,1],0]\r\n  Exit code:    1\r\n--------------------------------------------------------------------------\r\n```\r\n\r\n## Expected Behavior \r\nWhen rank 0 crashes it should shut down all mpi processes. Rank 1 should never print `done`. This can be achieved by uncommenting the atexit handler in the above example. \r\n```bash\r\n$ mpirun -mca btl ^tcp -np 2 python sleep.py 50\r\ninitializing\r\ninitializing\r\ninitialized\r\nSleeping for 50\r\ninitialized\r\nexiting!\r\n-------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n-------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun.real detected that one or more processes exited with non-zero status, thus causing\r\nthe job to be terminated. The first process to do so was:\r\n\r\n  Process name: [[42321,1],0]\r\n  Exit code:    1\r\n--------------------------------------------------------------------------\r\n```\r\n\r\n## Gdb Backtrace\r\nThis is the backtrace on the rank 0 process after rank 0 has exited and while rank 1 is sleeping. It looks like `ompi_mpi_finalize` polling for some event, but it is hard to tell.\r\n```\r\n(gdb) bt\r\n#0  0x00007f118e20430d in nanosleep () at ../sysdeps/unix/syscall-template.S:84\r\n#1  0x00007f118e235d94 in usleep (useconds=<optimized out>) at ../sysdeps/posix/usleep.c:32\r\n#2  0x00007f114abb9ea7 in ompi_mpi_finalize () from /usr/local/lib/libmpi.so.40\r\n#3  0x00007f114aed81ef in horovod::common::horovod_shutdown () at /tmp/pip-install-SZ9jbr/horovod/horovod/common/operations.cc:1981\r\n#4  0x00007f118d3e9e40 in ffi_call_unix64 () from /usr/lib/x86_64-linux-gnu/libffi.so.6\r\n#5  0x00007f118d3e98ab in ffi_call () from /usr/lib/x86_64-linux-gnu/libffi.so.6\r\n#6  0x00007f118d5f93df in _ctypes_callproc () from /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so\r\n#7  0x00007f118d5fdd82 in ?? () from /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so\r\n#8  0x00000000004c166d in PyEval_EvalFrameEx ()\r\n#9  0x00000000004b9b66 in PyEval_EvalCodeEx ()\r\n#10 0x00000000004d57a3 in ?? ()\r\n#11 0x00000000004a587e in PyObject_Call ()\r\n#12 0x00000000004be51e in PyEval_EvalFrameEx ()\r\n#13 0x00000000004b9b66 in PyEval_EvalCodeEx ()\r\n#14 0x00000000004d5669 in ?? ()\r\n#15 0x00000000004a587e in PyObject_Call ()\r\n#16 0x00000000004c5f3d in PyEval_CallObjectWithKeywords ()\r\n#17 0x00000000004351ad in ?? ()\r\n#18 0x000000000051ea38 in Py_Exit ()\r\n#19 0x000000000051bfd7 in ?? ()\r\n#20 0x000000000051b8fd in PyErr_PrintEx ()\r\n#21 0x0000000000430c25 in ?? ()\r\n#22 0x00000000004938ce in Py_Main ()\r\n#23 0x00007f118e158830 in __libc_start_main (main=0x493370 <main>, argc=3, argv=0x7ffd289908b8, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7ffd289908a8) at ../csu/libc-start.c:291\r\n#24 0x0000000000493299 in _start ()\r\n```\r\n\r\n## Python Backtrace\r\n```\r\nStack for thread 139999936075520\r\n  File \"/usr/lib/python2.7/threading.py\", line 774, in __bootstrap\r\n    self.__bootstrap_inner()\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"<string>\", line 167, in run\r\n  File \"/usr/lib/python2.7/code.py\", line 243, in interact\r\n    more = self.push(line)\r\n  File \"/usr/lib/python2.7/code.py\", line 265, in push\r\n    more = self.runsource(source, self.filename)\r\n  File \"/usr/lib/python2.7/code.py\", line 87, in runsource\r\n    self.runcode(code)\r\n  File \"/usr/lib/python2.7/code.py\", line 103, in runcode\r\n    exec code in self.locals\r\n  File \"<console>\", line 3, in <module>\r\n\r\nStack for thread 140000023533312\r\n  File \"/usr/lib/python2.7/atexit.py\", line 24, in _run_exitfuncs\r\n    func(*targs, **kargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/horovod/common/__init__.py\", line 88, in shutdown\r\n    return self.MPI_LIB_CTYPES.horovod_shutdown()\r\n```\r\n\r\nIs this the expected behavior?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/642/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/642/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/605", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/605/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/605/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/605/events", "html_url": "https://github.com/horovod/horovod/issues/605", "id": 376601182, "node_id": "MDU6SXNzdWUzNzY2MDExODI=", "number": 605, "title": "pytorch + horovod 0.15.1 distributed optimizer not working anymore", "user": {"login": "jotterbach", "id": 5595043, "node_id": "MDQ6VXNlcjU1OTUwNDM=", "avatar_url": "https://avatars.githubusercontent.com/u/5595043?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jotterbach", "html_url": "https://github.com/jotterbach", "followers_url": "https://api.github.com/users/jotterbach/followers", "following_url": "https://api.github.com/users/jotterbach/following{/other_user}", "gists_url": "https://api.github.com/users/jotterbach/gists{/gist_id}", "starred_url": "https://api.github.com/users/jotterbach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jotterbach/subscriptions", "organizations_url": "https://api.github.com/users/jotterbach/orgs", "repos_url": "https://api.github.com/users/jotterbach/repos", "events_url": "https://api.github.com/users/jotterbach/events{/privacy}", "received_events_url": "https://api.github.com/users/jotterbach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-11-01T22:51:26Z", "updated_at": "2018-11-03T01:28:25Z", "closed_at": "2018-11-03T01:28:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "I just upgraded horovod 0.15.0 -> 0.15.1 on a ubuntu image `4.4.0-137-generic #163-Ubuntu SMP Mon Sep 24 13:14:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux`. When using the DistributedOptimizer from horovod.torch I now encounter the error\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 641, in <module>\r\n    train_images(hps)\r\n  File \"train.py\", line 444, in train_images\r\n    train_step(batch, batch_idx, epoch, hps, model, opt, train_logger)\r\n  File \"train.py\", line 457, in train_step\r\n    opt.step()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/torch/__init__.py\", line 97, in step\r\n    return super(self.__class__, self).step(closure)\r\n  File \"/opt/conda/lib/python3.6/site-packages/torch/optim/adamax.py\", line 75, in step\r\n    exp_avg.mul_(beta1).add_(1 - beta1, grad)\r\nTypeError: mul_() received an invalid combination of arguments - got (numpy.float32), but expected one of:\r\n * (Tensor other)\r\n      didn't match because some of the arguments have invalid types: (numpy.float32)\r\n * (float other)\r\n      didn't match because some of the arguments have invalid types: (numpy.float32)\r\n```\r\n\r\nDowngrading to 0.15.0 fixes the issue. The behavior is independent of CPU, GPU or MultipleGPU training.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/605/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/605/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/549", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/549/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/549/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/549/events", "html_url": "https://github.com/horovod/horovod/issues/549", "id": 367701625, "node_id": "MDU6SXNzdWUzNjc3MDE2MjU=", "number": 549, "title": "Unexpected segmentation fault with PyTorch + Horovod", "user": {"login": "Jongchan", "id": 5811413, "node_id": "MDQ6VXNlcjU4MTE0MTM=", "avatar_url": "https://avatars.githubusercontent.com/u/5811413?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jongchan", "html_url": "https://github.com/Jongchan", "followers_url": "https://api.github.com/users/Jongchan/followers", "following_url": "https://api.github.com/users/Jongchan/following{/other_user}", "gists_url": "https://api.github.com/users/Jongchan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jongchan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jongchan/subscriptions", "organizations_url": "https://api.github.com/users/Jongchan/orgs", "repos_url": "https://api.github.com/users/Jongchan/repos", "events_url": "https://api.github.com/users/Jongchan/events{/privacy}", "received_events_url": "https://api.github.com/users/Jongchan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-08T09:19:51Z", "updated_at": "2019-02-02T19:09:50Z", "closed_at": "2018-10-15T18:30:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "System configuration\r\n- Azure VM of size NC24s_v2 (four P100)\r\n- Ubuntu 16.04\r\n- Docker image from [Horovod with Docker](https://github.com/uber/horovod/blob/master/docs/docker.md), skip Tensorflow/keras installation\r\n\r\nBefore beginning, I want to state that this problem is resolved for me. I am writing this issue for the record.\r\n\r\nFor learning rate decay, I define the optimizer every epoch\r\n```\r\ndef train(epoch):\r\n    net.train()\r\n    optimizer = optim.SGD(net.parameters(), lr=cf.learning_rate(args.lr, epoch)*hvd.size(), momentum=0.9, weight_decay=5e-4)\r\n    optimizer = hvd.DistributedOptimizer(optimizer, named_parameters=net.named_parameters())\r\n    ...\r\n```\r\nThe mpirun command was simply\r\n```\r\nmpirun -np 4 -H localhost:4 python <PYTHON_CODE_PATH> --datadir <DATA_DIR>\r\n```\r\nAt the very beginning of the 2nd epoch (during **the first** loss calculation and backprop), the code fails with the below stack trace\r\n```\r\n[fe535b5ccf9b:00019] *** Process received signal ***\r\n[fe535b5ccf9b:00019] Signal: Segmentation fault (11)\r\n[fe535b5ccf9b:00019] Signal code: Address not mapped (1)\r\n[fe535b5ccf9b:00019] Failing at address: 0x28\r\n[fe535b5ccf9b:00019] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7fbf2779c390]\r\n[fe535b5ccf9b:00019] [ 1] /usr/local/lib/python2.7/dist-packages/horovod/torch/mpi_lib_impl/_mpi_lib_impl.so(+0x58d71)[0x7fbeaabf4d71]\r\n[fe535b5ccf9b:00019] [ 2] /usr/local/lib/python2.7/dist-packages/horovod/torch/mpi_lib_impl/_mpi_lib_impl.so(+0x5de24)[0x7fbeaabf9e24]\r\n[fe535b5ccf9b:00019] [ 3] /usr/local/lib/python2.7/dist-packages/horovod/torch/mpi_lib_impl/_mpi_lib_impl.so(+0x692d8)[0x7fbeaac052d8]\r\n[fe535b5ccf9b:00019] [ 4] /usr/local/lib/python2.7/dist-packages/horovod/torch/mpi_lib_impl/_mpi_lib_impl.so(+0x6a65b)[0x7fbeaac0665b]\r\n[fe535b5ccf9b:00019] [ 5] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80)[0x7fbf1e97bc80]\r\n[fe535b5ccf9b:00019] [ 6] /lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba)[0x7fbf277926ba]\r\n[fe535b5ccf9b:00019] [ 7] /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7fbf274c841d]\r\n[fe535b5ccf9b:00019] *** End of error message ***\r\n-------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n-------------------------------------------------------\r\nfe535b5ccf9b:18:122 [0] INFO comm 0x7fc7381be150 rank 0 nranks 4\r\nfe535b5ccf9b:20:126 [2] INFO comm 0x7fbe601ba6e0 rank 2 nranks 4\r\n--------------------------------------------------------------------------\r\nmpirun.real noticed that process rank 1 with PID 0 on node fe535b5ccf9b exited on signal 11 (Segmentation fault).\r\n--------------------------------------------------------------------------\r\n```\r\nWhich means I am running this code in single node, 4 processes for 4 GPUs.\r\n***The question is - Is this an expected outcome?***\r\n\r\nIt is redundant to define optimizer every epoch, but I just kept the original baseline code.\r\nThis issue has been resolved for me, I just wanted to record this case in case other people may face a similar problem. This is not a problem in a native PyTorch code, but it is a problem with Horovod.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/549/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/549/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/418", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/418/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/418/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/418/events", "html_url": "https://github.com/horovod/horovod/issues/418", "id": 347127054, "node_id": "MDU6SXNzdWUzNDcxMjcwNTQ=", "number": 418, "title": "Horovod image build failure", "user": {"login": "andresfvilla", "id": 14841139, "node_id": "MDQ6VXNlcjE0ODQxMTM5", "avatar_url": "https://avatars.githubusercontent.com/u/14841139?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andresfvilla", "html_url": "https://github.com/andresfvilla", "followers_url": "https://api.github.com/users/andresfvilla/followers", "following_url": "https://api.github.com/users/andresfvilla/following{/other_user}", "gists_url": "https://api.github.com/users/andresfvilla/gists{/gist_id}", "starred_url": "https://api.github.com/users/andresfvilla/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andresfvilla/subscriptions", "organizations_url": "https://api.github.com/users/andresfvilla/orgs", "repos_url": "https://api.github.com/users/andresfvilla/repos", "events_url": "https://api.github.com/users/andresfvilla/events{/privacy}", "received_events_url": "https://api.github.com/users/andresfvilla/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-08-02T18:35:55Z", "updated_at": "2018-08-02T21:22:29Z", "closed_at": "2018-08-02T21:22:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "When attempting to build the horovod docker image following the steps in `docker.md`, the build fails due to the following error\r\n```\r\nThe following held packages will be changed:\r\n  libnccl2\r\nThe following packages will be DOWNGRADED:\r\n  libnccl-dev libnccl2\r\nE: Packages were downgraded and -y was used without --allow-downgrades.\r\n0 upgraded, 40 newly installed, 2 downgraded, 0 to remove and 13 not upgraded.\r\nThe command '/bin/sh -c apt-get update && apt-get install -y --no-install-recommends         build-essential         cmake         git         curl         vim         wget         ca-certificates         libcudnn7=${CUDNN_VERSION}         libnccl2=${NCCL_VERSION}         libnccl-dev=${NCCL_VERSION}         libjpeg-dev         libpng-dev         python${PYTHON_VERSION}         python${PYTHON_VERSION}-dev' returned a non-zero code: 100\r\n```\r\n\r\nWhen adding the `--allow-downgrades` it returns another error\r\n\r\n```\r\nThe following held packages will be changed:\r\n  libnccl2\r\nThe following packages will be DOWNGRADED:\r\n  libnccl-dev libnccl2\r\n0 upgraded, 40 newly installed, 2 downgraded, 0 to remove and 13 not upgraded.\r\nE: Held packages were changed and -y was used without --allow-change-held-packages.\r\nThe command '/bin/sh -c apt-get update && apt-get install -y --no-install-recommends --allow-downgrades         build-essential \t        cmake \t\t        git \t\t\t        curl \t\t\t\t        vim \t\t\t\t\t        wget \t\t\t\t\t\t        ca-certificates \t\t\t\t\t\t        libcudnn7=${CUDNN_VERSION} \t\t\t\t\t\t\t\t        libnccl2=${NCCL_VERSION} \t\t\t\t\t\t\t\t\t        libnccl-dev=${NCCL_VERSION} \t\t\t\t\t\t\t\t\t\t        libjpeg-dev \t\t\t\t\t\t\t\t\t\t        libpng-dev \t\t\t\t\t\t\t\t\t\t\t\t        python${PYTHON_VERSION}\r\n```\r\n\r\nit seems it requires `--allow-change-held-packages` as well but i am not sure if this flag is intended to be used. Is there a new NCCL version that should be used?", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/418/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/418/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/392", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/392/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/392/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/392/events", "html_url": "https://github.com/horovod/horovod/issues/392", "id": 343216288, "node_id": "MDU6SXNzdWUzNDMyMTYyODg=", "number": 392, "title": "Error broadcasting Adam optimizer parameters on PyTorch", "user": {"login": "andfoy", "id": 1878982, "node_id": "MDQ6VXNlcjE4Nzg5ODI=", "avatar_url": "https://avatars.githubusercontent.com/u/1878982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andfoy", "html_url": "https://github.com/andfoy", "followers_url": "https://api.github.com/users/andfoy/followers", "following_url": "https://api.github.com/users/andfoy/following{/other_user}", "gists_url": "https://api.github.com/users/andfoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/andfoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andfoy/subscriptions", "organizations_url": "https://api.github.com/users/andfoy/orgs", "repos_url": "https://api.github.com/users/andfoy/repos", "events_url": "https://api.github.com/users/andfoy/events{/privacy}", "received_events_url": "https://api.github.com/users/andfoy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-07-20T19:05:11Z", "updated_at": "2018-07-23T19:04:28Z", "closed_at": "2018-07-23T19:04:28Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Thanks for your great work on horovod, it is a great library that speeds up our training processes significatively. \r\n\r\nI've tried to use the novel ``hvd.broadcast_optimizer_state`` function introduced on 0.13.10, however, it seems to fail on optimizers different from ``torch.optim.SGD``, because they seem to define additional model parameters that are not necessarily of type ``torch.tensor``.\r\n\r\nFor instance, if I try to use Adam as optimizer (As shown on the example snippet), the function will fail with the following traceback:\r\n\r\n```python\r\noptimizer = optim.Adam(net.parameters(), lr=args.lr * args.nodes)\r\noptimizer = hvd.DistributedOptimizer(\r\n    optimizer, named_parameters=net.named_parameters())\r\n\r\nif osp.exists(args.optim_snapshot) and args.rank == 0:\r\n    optimizer.load_state_dict(torch.load(args.optim_snapshot))\r\n\r\nhvd.broadcast_optimizer_state(optimizer, root_rank=0)\r\n```\r\n\r\n```\r\nFile \"/media/SSD1/score-textseg/ref_score_net/train.py\", line 327, in <module>\r\n    hvd.broadcast_optimizer_state(optimizer, root_rank=0)\r\n  File \"/home/eamargffoy/anaconda3/envs/parallel/lib/python3.6/site-packages/horovod/torch/__init__.py\", line 199, in broadcast_optimizer_state\r\n    broadcast_parameters(params, root_rank)\r\n  File \"/home/eamargffoy/anaconda3/envs/parallel/lib/python3.6/site-packages/horovod/torch/__init__.py\", line 152, in broadcast_parameters\r\n    handle = broadcast_async_(p, root_rank, name)\r\n  File \"/home/eamargffoy/anaconda3/envs/parallel/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 348, in broadcast_async_\r\n    return _broadcast_async(tensor, tensor, root_rank, name)\r\n  File \"/home/eamargffoy/anaconda3/envs/parallel/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 256, in _broadcast_async\r\n    function = _check_function(_broadcast_function_factory, tensor)\r\n  File \"/home/eamargffoy/anaconda3/envs/parallel/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 39, in _check_function\r\n    function = function_factory(tensor)\r\n  File \"/home/eamargffoy/anaconda3/envs/parallel/lib/python3.6/site-packages/horovod/torch/mpi_ops.py\", line 252, in _broadcast_function_factory\r\n    return 'horovod_torch_broadcast_async_' + tensor.type().replace('.', '_')\r\nAttributeError: 'int' object has no attribute 'type'\r\n``` \r\n\r\nI would like to know if the above appreciation is the cause of such failure, and if it is, if I can contribute to the project by fixing it.\r\n\r\nThanks in advance.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/392/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/392/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/213", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/213/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/213/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/213/events", "html_url": "https://github.com/horovod/horovod/issues/213", "id": 305776340, "node_id": "MDU6SXNzdWUzMDU3NzYzNDA=", "number": 213, "title": "Error on using hvd.mpi_threads_supported()  error: undefined symbol: mpi_threads_supported", "user": {"login": "lkmokadam", "id": 8169825, "node_id": "MDQ6VXNlcjgxNjk4MjU=", "avatar_url": "https://avatars.githubusercontent.com/u/8169825?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lkmokadam", "html_url": "https://github.com/lkmokadam", "followers_url": "https://api.github.com/users/lkmokadam/followers", "following_url": "https://api.github.com/users/lkmokadam/following{/other_user}", "gists_url": "https://api.github.com/users/lkmokadam/gists{/gist_id}", "starred_url": "https://api.github.com/users/lkmokadam/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lkmokadam/subscriptions", "organizations_url": "https://api.github.com/users/lkmokadam/orgs", "repos_url": "https://api.github.com/users/lkmokadam/repos", "events_url": "https://api.github.com/users/lkmokadam/events{/privacy}", "received_events_url": "https://api.github.com/users/lkmokadam/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-16T01:50:28Z", "updated_at": "2018-03-16T18:02:22Z", "closed_at": "2018-03-16T18:02:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Error on using hvd.mpi_threads_supported() \r\n\r\nerror: undefined symbol: mpi_threads_supported\r\n\r\n`mpi_threads_supported = MPI_COMMON_LIB_CTYPES.mpi_threads_supported()`\r\n should be \r\n`mpi_threads_supported = MPI_COMMON_LIB_CTYPES.horovod_mpi_threads_supported()`\r\n", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/213/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/213/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/203", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/203/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/203/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/203/events", "html_url": "https://github.com/horovod/horovod/issues/203", "id": 304177112, "node_id": "MDU6SXNzdWUzMDQxNzcxMTI=", "number": 203, "title": "dockerfile need to downgrade cuDNN", "user": {"login": "TuranTimur", "id": 12987695, "node_id": "MDQ6VXNlcjEyOTg3Njk1", "avatar_url": "https://avatars.githubusercontent.com/u/12987695?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TuranTimur", "html_url": "https://github.com/TuranTimur", "followers_url": "https://api.github.com/users/TuranTimur/followers", "following_url": "https://api.github.com/users/TuranTimur/following{/other_user}", "gists_url": "https://api.github.com/users/TuranTimur/gists{/gist_id}", "starred_url": "https://api.github.com/users/TuranTimur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TuranTimur/subscriptions", "organizations_url": "https://api.github.com/users/TuranTimur/orgs", "repos_url": "https://api.github.com/users/TuranTimur/repos", "events_url": "https://api.github.com/users/TuranTimur/events{/privacy}", "received_events_url": "https://api.github.com/users/TuranTimur/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-11T17:34:41Z", "updated_at": "2018-03-13T00:02:18Z", "closed_at": "2018-03-13T00:02:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "if there is anyone who are faced with the error below,\r\n\r\n> \"Loaded runtime CuDNN library: 7101 (compatibility version 7100) but source was compiled with 7004 (compatibility version 7000). \"\r\n\r\nThe thread below can be pointer to resolve this issue, \r\nhttps://github.com/keras-team/keras/issues/9567\r\n\r\nand the command lines on the reply below could be added to the dockerfile of the current horovod until Keras supports new version cuDNN.\r\nhttps://github.com/keras-team/keras/issues/9567#issuecomment-371566669", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/203/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/203/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/192", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/192/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/192/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/192/events", "html_url": "https://github.com/horovod/horovod/issues/192", "id": 303018893, "node_id": "MDU6SXNzdWUzMDMwMTg4OTM=", "number": 192, "title": "an issue in the dockerfile, seems the cudnn version does't match.", "user": {"login": "GoodJoey", "id": 30927640, "node_id": "MDQ6VXNlcjMwOTI3NjQw", "avatar_url": "https://avatars.githubusercontent.com/u/30927640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GoodJoey", "html_url": "https://github.com/GoodJoey", "followers_url": "https://api.github.com/users/GoodJoey/followers", "following_url": "https://api.github.com/users/GoodJoey/following{/other_user}", "gists_url": "https://api.github.com/users/GoodJoey/gists{/gist_id}", "starred_url": "https://api.github.com/users/GoodJoey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GoodJoey/subscriptions", "organizations_url": "https://api.github.com/users/GoodJoey/orgs", "repos_url": "https://api.github.com/users/GoodJoey/repos", "events_url": "https://api.github.com/users/GoodJoey/events{/privacy}", "received_events_url": "https://api.github.com/users/GoodJoey/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-03-07T09:15:05Z", "updated_at": "2018-03-07T19:18:34Z", "closed_at": "2018-03-07T19:18:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "tensorflow/stream_executor/cuda/cuda_dnn.cc:378] Loaded runtime CuDNN library: 7101 (compatibility version 7100) but source was compiled with 7004 (compatibility version 7000).  If using a binary install, upgrade your CuDNN library to match.  \r\n\r\nmaybe it is because the nvidia/cuda image has been updated.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/192/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/192/timeline", "performed_via_github_app": null, "state_reason": "completed"}, {"url": "https://api.github.com/repos/horovod/horovod/issues/33", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/33/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/33/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/33/events", "html_url": "https://github.com/horovod/horovod/issues/33", "id": 264360205, "node_id": "MDU6SXNzdWUyNjQzNjAyMDU=", "number": 33, "title": "AttributeError: 'NoneType' object has no attribute 'dtype'", "user": {"login": "crizCraig", "id": 181225, "node_id": "MDQ6VXNlcjE4MTIyNQ==", "avatar_url": "https://avatars.githubusercontent.com/u/181225?v=4", "gravatar_id": "", "url": "https://api.github.com/users/crizCraig", "html_url": "https://github.com/crizCraig", "followers_url": "https://api.github.com/users/crizCraig/followers", "following_url": "https://api.github.com/users/crizCraig/following{/other_user}", "gists_url": "https://api.github.com/users/crizCraig/gists{/gist_id}", "starred_url": "https://api.github.com/users/crizCraig/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/crizCraig/subscriptions", "organizations_url": "https://api.github.com/users/crizCraig/orgs", "repos_url": "https://api.github.com/users/crizCraig/repos", "events_url": "https://api.github.com/users/crizCraig/events{/privacy}", "received_events_url": "https://api.github.com/users/crizCraig/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "alsrgv", "id": 16640218, "node_id": "MDQ6VXNlcjE2NjQwMjE4", "avatar_url": "https://avatars.githubusercontent.com/u/16640218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alsrgv", "html_url": "https://github.com/alsrgv", "followers_url": "https://api.github.com/users/alsrgv/followers", "following_url": "https://api.github.com/users/alsrgv/following{/other_user}", "gists_url": "https://api.github.com/users/alsrgv/gists{/gist_id}", "starred_url": "https://api.github.com/users/alsrgv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alsrgv/subscriptions", "organizations_url": "https://api.github.com/users/alsrgv/orgs", "repos_url": "https://api.github.com/users/alsrgv/repos", "events_url": "https://api.github.com/users/alsrgv/events{/privacy}", "received_events_url": "https://api.github.com/users/alsrgv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "alsrgv", "id": 16640218, "node_id": "MDQ6VXNlcjE2NjQwMjE4", "avatar_url": "https://avatars.githubusercontent.com/u/16640218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alsrgv", "html_url": "https://github.com/alsrgv", "followers_url": "https://api.github.com/users/alsrgv/followers", "following_url": "https://api.github.com/users/alsrgv/following{/other_user}", "gists_url": "https://api.github.com/users/alsrgv/gists{/gist_id}", "starred_url": "https://api.github.com/users/alsrgv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alsrgv/subscriptions", "organizations_url": "https://api.github.com/users/alsrgv/orgs", "repos_url": "https://api.github.com/users/alsrgv/repos", "events_url": "https://api.github.com/users/alsrgv/events{/privacy}", "received_events_url": "https://api.github.com/users/alsrgv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2017-10-10T20:12:06Z", "updated_at": "2017-10-12T00:59:51Z", "closed_at": "2017-10-12T00:59:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "Some models, like [RFCN](https://github.com/tensorflow/models/tree/master/research/object_detection) can return variables without gradients\r\n```Traceback (most recent call last):\r\n  File \"train.py\", line 249, in <module>\r\n    tf.app.run()\r\n  File \"/home/csq/.cache/bazel/_bazel_csq/0a3580d8ecd2fafe9cc9970e974f5dc4/execroot/source/bazel-out/release_links/lib/python_env/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"train.py\", line 229, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir, FLAGS.trace_every_n_steps)\r\n  File \"/home/csq/src/models/research/object_detection/trainer.py\", line 271, in train\r\n    for (gradient, var) in gradients]\r\n  File \"/home/csq/.cache/bazel/_bazel_csq/0a3580d8ecd2fafe9cc9970e974f5dc4/execroot/source/bazel-out/release_links/lib/python_env/horovod/tensorflow/__init__.py\", line 76, in allreduce\r\n    horovod_size = tf.cast(size(), tensor.dtype)\r\nAttributeError: 'NoneType' object has no attribute 'dtype'\r\n```\r\nI just work around it by replacing compute_gradients() with\r\n```\r\ngradients = (super(hvd.DistributedOptimizer, training_optimizer)\r\n             .compute_gradients(total_loss))\r\ngradients = [(g, v) for g, v in gradients if g is not None]\r\nif hvd.size() > 1:\r\n  with tf.name_scope(training_optimizer._name + \"_Allreduce\"):\r\n    grads_and_vars = [(hvd.allreduce(gradient, device_dense=training_optimizer._device_dense,\r\n                                                    device_sparse=training_optimizer._device_sparse), var)\r\n                      for (gradient, var) in gradients]\r\n```\r\nbut think adding\r\n```\r\ngradients = [(g, v) for g, v in gradients if g is not None]\r\n``` \r\nafter this line: https://github.com/uber/horovod/blob/64317537436ae4225a004043acaa37a205a18dc3/horovod/tensorflow/__init__.py#L166\r\n\r\ncould fix it for others.", "reactions": {"url": "https://api.github.com/repos/horovod/horovod/issues/33/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/horovod/horovod/issues/33/timeline", "performed_via_github_app": null, "state_reason": "completed"}]